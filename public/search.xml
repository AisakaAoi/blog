<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>个人博客平台和工具的对比与选择</title>
    <url>/5bdcf813.html</url>
    <content><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>作为一个程序员，拥有一个个人博客，是沉淀知识，打造影响力的必备要素。但是因为现在的写作平台实在是太多了，在选择一个适合自己的博客的时候，就像买东西一样，总是挑花了眼。每个博客平台各有各的优点和不足，这里就我自己的一些想法和性格，对目前市面上的写作平台做一个筛选，选出<strong>最适合自己</strong>的博客平台。</p>
<hr>
<span id="more"></span>

<h3 id="期望的博客的特点"><a href="#期望的博客的特点" class="headerlink" title="期望的博客的特点"></a>期望的博客的特点</h3><ul>
<li>稳定（可以活个几十年没问题）</li>
<li>安全（数据不能丢失）</li>
<li>支持markdown格式（我现在写作基本上都是使用md）</li>
<li>支持全文搜索（这个是必须的）</li>
<li>容易导出备份（方便一点）</li>
<li>发文方便（不需要编译啥的，手机电脑都可以发文就更好了）</li>
<li>阅读量、评论功能（最好有）</li>
<li>美观（外观党）</li>
</ul>
<hr>
<h3 id="简述市面主流写作平台"><a href="#简述市面主流写作平台" class="headerlink" title="简述市面主流写作平台"></a>简述市面主流写作平台</h3><h4 id="Github系列（程序员必备平台）"><a href="#Github系列（程序员必备平台）" class="headerlink" title="Github系列（程序员必备平台）"></a>Github系列（程序员必备平台）</h4><ul>
<li>类似Github的有Gitlab，Gitee等</li>
<li>基于Github：Hexo / Hugo / Vuepress / Jekyll</li>
</ul>
<h4 id="博客平台"><a href="#博客平台" class="headerlink" title="博客平台"></a>博客平台</h4><ul>
<li>CSDN</li>
<li>博客园</li>
<li>掘金</li>
<li>Segmentfault</li>
</ul>
<h4 id="笔记软件"><a href="#笔记软件" class="headerlink" title="笔记软件"></a>笔记软件</h4><ul>
<li>语雀</li>
<li>Notion / Wolai</li>
<li>印象笔记/有道云笔记</li>
<li>幕布</li>
<li>石墨文档 / 腾讯文档 / 飞书文档</li>
</ul>
<hr>
<h3 id="怎么把博客放到网上"><a href="#怎么把博客放到网上" class="headerlink" title="怎么把博客放到网上"></a>怎么把博客放到网上</h3><p>目前比较流行的博客实现可以分为三种方式，各有不同程度的技术门槛、功能支持、主题颜值等。</p>
<ul>
<li><strong>个人主页注册。</strong>指的是在现有的博客网站、论坛或社区上注册个人主页</li>
<li><strong>静态网站生成。</strong>通常是由jekyll、hugo或hexo等技术生成静态网站，然后通过git上传到Github Pages、Coding Pages等托管平台免费展示</li>
<li><strong>内容管理系统。</strong>带有后台管理的博客系统，需要配置空间（服务器）、数据库以及域名等，然后安装成熟的WordPress、ghost等内容管理系统</li>
</ul>
<hr>
<h4 id="个人主页注册"><a href="#个人主页注册" class="headerlink" title="个人主页注册"></a>个人主页注册</h4><p>注册形式的个人博客，优势是没有技术门槛，注册即用；拥有成熟的平台支持，方便推广。但是平台风格单一，不仅自定义程度低，而且还有许多形式限制（当然限制也有专心于内容的好处），推荐给嫌麻烦不喜欢折腾又不反感条条框框的人。</p>
<hr>
<h5 id="SegmentFault"><a href="#SegmentFault" class="headerlink" title="SegmentFault"></a>SegmentFault</h5><ul>
<li>中式StackOverFlow论坛，成熟的技术交流平台</li>
<li>网站提供文章专栏板块，并且有审核机制</li>
<li>功能： Markdown / 标签 / 评论 / 智能目录</li>
<li>颜值：正常 / 简洁</li>
</ul>
<img src="/5bdcf813/7.webp" class>

<hr>
<h5 id="CSDN"><a href="#CSDN" class="headerlink" title="CSDN"></a>CSDN</h5><ul>
<li>老牌技术论坛</li>
<li>关注公众号才能注册，8位数验证码等一堆反人类交互体验很不是能忍</li>
<li>功能：Markdown / 评论 / 标签 / 皮肤 / 老式文章管理</li>
<li>颜值：…</li>
</ul>
<img src="/5bdcf813/10.webp" class>

<p><strong>优点：</strong></p>
<ul>
<li><strong>SEO</strong>做得好，无论是百度还是google（尤其是百度）在搜索问题的时候排名靠前</li>
<li>阅读量高，从头开始写也不怕没人看，有排名，对于追求阅读量的作者会更有动力写</li>
<li>博客内容基本限定在计算机领域上</li>
<li>博客写完发表即可，不需要做额外的事情，还有要提的是支持<strong>数学公式</strong>和<strong>流程图</strong>编写，其他的博客我不太清楚</li>
<li>CSDN除了博客外还有很多其他资源，比如源代码下载、课程学习等，对有需求的作者有吸引力（要钱）</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>界面不够好看，无论PC端还是移动端</li>
<li>博客定制性差，基本只能调整下模块位置，换个固定的显示模板，最多加个友情链接</li>
<li><strong>广告多</strong>，右下角、左下角、文章下面经常有广告出现（广告聚集区，无法忍受有强迫症的同志一定要慎重）</li>
</ul>
<img src="/5bdcf813/1.jpg" class>

<hr>
<h5 id="博客园"><a href="#博客园" class="headerlink" title="博客园"></a>博客园</h5><ul>
<li>元老级技术论坛，申请博客需要人工审核（上班时间8分钟通过</li>
<li>功能：Markdown / 评论 / 标签 / 老式文章管理 / RSS / 年代感皮肤 / 相册 / 文件</li>
<li>颜值：Logo可以有不止3种Word渐变色3D投影展示，老得有味道</li>
</ul>
<img src="/5bdcf813/11.webp" class>

<p><strong>优点：</strong></p>
<ul>
<li>SEO不错，尤其是在百度上，博客园上面也经常有不错的专题类文章</li>
<li>阅读量有保证，和CSDN很像，不提供排名机制</li>
<li>博客内容基本限定在计算机领域上</li>
<li>界面好看了一些，给博客管理者较大的定制空间，见到过一些自己定制的博客，比CSDN强很多</li>
<li>广告在最下方不会很影响心情</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>平台给人一种陈旧论坛的感觉，博客园作为较早的技术博客空间提供者，即便界面上比CSDN上整齐了一些，但依然不够fashion</li>
<li>其他可用资源较少，除了写博客看文章之外，其他的业务不够吸引人</li>
<li>博客园定制的博客也不够fashion，甚至很多花花绿绿的，这种定制性某种程度反而造成了定制的博客也难看，而且不整齐，经常会访问了一个博客甚至不知道是博客园的（比如出现了格言出格的现象，移动端就更是惨不忍睹了，登陆页和首页，也是满满的陈旧感）</li>
</ul>
<img src="/5bdcf813/2.jpg" class>

<img src="/5bdcf813/3.jpg" class>

<img src="/5bdcf813/4.jpg" class>

<hr>
<h5 id="简书"><a href="#简书" class="headerlink" title="简书"></a>简书</h5><ul>
<li>专注文字的轻博客平台，定位清新</li>
<li>功能：Markdown / 评论 / 标签</li>
<li>颜值：正常 / 干净</li>
</ul>
<img src="/5bdcf813/8.webp" class>

<p><strong>优点：</strong></p>
<ul>
<li>界面是真的简洁、简单，和前面两个一比真是好看，从首页到文章页，包括markdown的字体、代码排版，都可以看出来是个现代化的网站设计风格</li>
<li>移动端适配的也非常好，因为其实移动端的流量某些时候要比PC端多得多，所以移动端漂亮是非常重要的</li>
</ul>
<img src="/5bdcf813/5.jpg" class>

<p><strong>缺点：</strong></p>
<ul>
<li>SEO不好，简书更多的想将文章做专栏分类，然后让读者在简书内部阅读到，所以在搜索引擎上的SEO要差很多</li>
<li>发完文章后要做专门的分类提交，比较麻烦，否则就是上一条的很少阅读量，以CSDN为例，发一篇文章解决一个报错时间长了也能有几千的阅读量，但是简书可能就达不到这个水平了</li>
<li>文章内容不专注于计算机技术领域，情感呀、八卦呀、鸡汤啊，这些某种程度才是简书上的主流，和微信公众号有点像，大部分情况都是蹭热点、标题党、大V的阅读量会较高，如果你只写技术博客，还希望更多人看到的话，那简书可能不是最好的选择</li>
<li>其他技术资源很少，除了阅读博客之外，可以考虑看看设计、看看故事，如果只是一心学技术的话那可能会失望了</li>
<li>没有个人定制性</li>
</ul>
<hr>
<h5 id="知乎专栏"><a href="#知乎专栏" class="headerlink" title="知乎专栏"></a>知乎专栏</h5><ul>
<li>泛娱乐化的专业知识交流平台，提供文章板块</li>
<li>功能：Markdown / 评论 / 标签</li>
<li>颜值：正常 / 大气</li>
</ul>
<img src="/5bdcf813/9.webp" class>

<p><strong>优点：</strong></p>
<ul>
<li>知乎这个平台好， 知乎积累了很多大V，而且由于内容的价值高，在知乎上得到更多的关注会有很高的商业价值</li>
<li>SEO一般，知乎的问答搜索引擎收录的非常好，但是专栏还差一截，但如果你是知乎的资深用户，那么吸引人阅读专栏也不是那么难的事情，也可以考虑多去回答问题给自己的博客打广告</li>
<li>知乎可以说就是现代前端的前驱，在我写了这样一段话之后，大家应该知道了，它的界面设计无论从产品还是技术的角度上都是非常棒的，某种程度上比简书还简书，页面很舒服漂亮</li>
<li>产品上，知乎专栏文章的简洁和简书比有过之而无不及，甚至更让人看着舒服，在细节上，PC端简书的导航栏一直在上方，但是知乎会自动隐藏让读者能看到更多有用信息</li>
<li>技术上，简书应该是使用了vue，知乎是完全react来构建的，响应式布局上知乎也是完全无缝对接，从下图就可见一斑，简书在界面变小的时候出现了下图中的问题，但是知乎没有</li>
</ul>
<img src="/5bdcf813/6.jpg" class>

<p><strong>缺点：</strong></p>
<ul>
<li>知乎上内容也不是只针对技术来做的，其他的内容也会混杂很多</li>
<li>没有定制性，都是知乎的那套简洁的界面</li>
<li>如果不常使用知乎这个平台去提问回答专栏可能很难被阅读和关注</li>
</ul>
<hr>
<p>注册形式的博客还有许多老牌供应商，如网易，新浪和搜狐博客等，有些可能已经不维护了，而且大多定位也不是技术类博客，这里就不介绍了。注册形式的博客当然还可以申请微信订阅号，或者在知乎、StackOverFlow或Quora等问答平台写以答案的形式，甚至百度贴吧搭楼也可以，<strong>虽然是不正经的博客，但确是正经的写博客初衷。</strong></p>
<hr>
<h4 id="静态网站生成技术"><a href="#静态网站生成技术" class="headerlink" title="静态网站生成技术"></a>静态网站生成技术</h4><p><strong>技术门槛： Markdown / Linux命令 / git / Github Pages / 域名解析</strong></p>
<p><strong>生成静态网站。</strong>文章以特定的标头格式书写，放置在指定的文件夹，执行命令快速生成完整的静态网站；通过git将文件上传至Github或Coding等代码托管平台，这些平台提供免费展示页面功能。</p>
<p><strong>快速搭建。</strong>静态网站生成的博客很轻，可以绑定自己的域名，适合中小型项目快速建站，省去服务器费用、免去搭建配置服务器等的繁琐过程。官网文档都有详细的教程，配置好所需环境后，理论上搭建一个静态网站到上线只需要输入<strong>10多行命令</strong>，不熟悉的话一般<strong>40分钟</strong>左右就可以上线（熟悉的话<strong>10分钟</strong>），并且这些技术都有贴心的本地预览功能。当然，也正因为轻，没有数据库的支持，所以对于有多图和高清图片、大体量博客等需求实现起来不是非常友好。</p>
<p><strong>自定义程度高。</strong>静态网站生成技术提供一系列可以配置CSS样式和修改网页行为的方式，有可供选择的大量插件，很容通过插件实现评论、搜索、分析等你想要的所有功能（标配并不带有这些功能）。</p>
<p><strong>主题丰富，高颜值。</strong>静态网站的主题不是简单的皮肤，而是一个静态网站的解决方案，一般会内置插件并且提供许多实用场景的解决方案，如代码高亮、图像支持等等。</p>
<p><strong>技术更新迭代快。</strong>静态网站升生成技术相关的讨论很活跃，因此更新维护及时，出现问题比较容易解决。反作用是因为更新换代非常快，而且官网提供各种技术间的快速迁移，所以如果入坑的话比较容易掉入深坑无法自拔，谨慎入坑。</p>
<p>目前比较流行的有jekyll、hugo以及hexo等方式，一般将网站搭在Github Pages或Coding Pages上。通过生成网站搭建博客的方式相对来说有一点点繁琐，因为每次发布文章都需要重新生成，虽然操作很简单（当然可以配置自动化部署），但也是需要那么几步操作。推荐给喜欢新技术，喜欢自定义，不折腾不痛快的人。</p>
<p><strong>优点：</strong></p>
<ul>
<li>定制性强，属于静态网站，博客代码都能看到，都是开源的，想怎么改怎么改，只怕使用者不会改，即便不会改也有非常多的开源代码提供使用，足够挑选，从nodejs出的hexo到ruby的jekyll，有大量的主题可供挑选，还可以关联自己的域名</li>
<li>能学习一下git和github的使用</li>
<li>能学习一下web开发</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>在百度上seo非常差，google上还好，github限制了百度的索引，所以github page上的博客不用想了，百度上很难被搜索到，能看到个主页就不错了，所以基本很少有人阅读你的博客，虽然还可以考虑把博客挂在coding.net上，但是由于要收费一年几百，所以也不是完美的解决方案</li>
<li>写博客比提供好的平台要麻烦很多，因为要在本地编辑然后部署代码，无论如何也比不上在网页上编辑一下就发出去的快速</li>
<li>有一定的开发难度，如果没做过web开发很多地方都要学习，周期会长很多</li>
</ul>
<hr>
<h5 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h5><p>本站即用hexo框架搭建</p>
<ul>
<li>基于Node技术实现快速生成，Github代码库12k+</li>
<li>安装过程一路流畅，没有波折，配置、发布人性化，十分贴心</li>
<li>社区活跃，对技术不熟且英文不要的人非常友好</li>
<li>主题155+，高颜值</li>
</ul>
<img src="/5bdcf813/12.webp" class>

<hr>
<h5 id="hugo"><a href="#hugo" class="headerlink" title="hugo"></a>hugo</h5><ul>
<li>基于GO语言实现，极速生成网站，Github代码库11k+</li>
<li>安装配置十分流畅，但是在部署发布时遇到一点坎坷（需要了解一点Shell脚本</li>
<li>相对来说中文不是很友好，中文社区不是很活跃</li>
<li>主题670+，品位和颜值</li>
</ul>
<hr>
<h5 id="jekyll"><a href="#jekyll" class="headerlink" title="jekyll"></a>jekyll</h5><ul>
<li>基础Ruby实现，Github官方推荐亲儿子，Github代码库30k+</li>
<li>因为有后台，所以可以任性不依赖本地环境配置，直接在网站上生成</li>
<li>本地环境配置上有一些坑位，高级但是不友好（反正我是踩坑了</li>
<li>主题只能说正常，总有一种不是官方在维护皮肤的感觉</li>
</ul>
<img src="/5bdcf813/13.webp" class>

<hr>
<ul>
<li>以上的3种技术的配置流程和搭建思路大同小异，彼此之间都提供低成本迁移办法</li>
<li>如果害怕国外服务器有时无法访问，以及对于搜索引擎收录有需求的话，建议搭在Coding Pages上，比较省心（会员等级不够高会有广告跳转，解决方式是主页上帮他作广告）</li>
<li>如果通过Github托管的话，另外推荐静态网站专业托管平台Netlify，虽然自动编译还有很多坑位，但是可以自动插入HTML代码到post、免费实现https、SSL / TLS等功能、DNS解析等等</li>
</ul>
<hr>
<h4 id="内容管理系统（个人建站）"><a href="#内容管理系统（个人建站）" class="headerlink" title="内容管理系统（个人建站）"></a>内容管理系统（个人建站）</h4><p><strong>技术门槛：服务器 / 域名解析 / 数据库 / Linux命令 / ftp</strong></p>
<p><strong>后台管理。</strong>具有贴心的后台界面，可以管理文章、相册、主题等。因为有数据库支持，所以可以实现多用户维护管理，高清大图上传等。</p>
<p><strong>高级还免费。</strong>内置搜索、评论等常用功能，还有丰富的插件市场可以轻松满足各种需求。免费使用系统，但是配置服务器需要支付一定的费用（低配年费要大几百）。</p>
<p><strong>丰富与臃肿。</strong>如今是用户体验当道和流行扁平化的时代，和往前大而多的需求不太一样，所以现在对于这种臃肿的博客系统是既爱又恨，爱他的丰富，又嫌弃人家的大脑袋。</p>
<p><strong>高门槛。</strong>搭建一个后台管理式博客系统需要了解比较多的web知识，例如服务器，域名解析，数据库等知识都需要简单了解。虽然各大服务器商均有提供WordPress服务器镜像，可以实现<strong>5分钟</strong>快速搭建，但是如果不了解一些基本的web知识，会比较容易在搭建和使用过程中摸不着头脑。</p>
<p><strong>优点：</strong></p>
<ul>
<li>定制性最强，可以搭建动态网站，这回连github这个平台都不用理了，服务器都是自己的，想怎么弄怎么弄，以wordpress为代表的博客平台一样有很多可供选择</li>
<li>可以自己想办法做seo，优化网站被收录</li>
<li>能好好学一下web开发</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>开发难度最高，从购买服务器、域名，到运行代码、修改代码、部署，再到后期做SEO，这一套下来估计web开发是什么样的心里也大概能有点数了</li>
<li>成本最高，上述所有的方案都是免费的，个人建站要花钱买服务器，买域名，花销最少也要几百块出去（学生认证除外）</li>
<li>乐趣很难在写博客上，可能会发生如下现象，基本都花时间折腾网站开发了，等弄好了发现SEO太差根本没人来看，还不如去上面找个平台写呢</li>
</ul>
<hr>
<h5 id="WordPress"><a href="#WordPress" class="headerlink" title="WordPress"></a>WordPress</h5><ul>
<li>15岁高龄，现在是从php编写到开源后采用各种流行语言重写的第二春</li>
<li>市场占有率超高的内容管理系统，做博客只是功能之一，搭企业级网站也是很轻松</li>
<li>中文最友好了，服务器镜像5分钟搭建网站，一键包安装也是轻松带微笑</li>
<li>颜值中上，形式非常丰富，可以适合各类工种的需求</li>
</ul>
<img src="/5bdcf813/14.webp" class>

<img src="/5bdcf813/15.webp" class>

<hr>
<h5 id="ghost"><a href="#ghost" class="headerlink" title="ghost"></a>ghost</h5><ul>
<li>基于Node实现的，社区活跃度高</li>
<li>相比WordPress去掉许多臃肿的功能，简洁大气</li>
<li>专为写作生产力的极致博客系统，WordPress良好替代品</li>
<li>有一定的搭建门槛，我用一键包也踩了很多坑位，花了90分钟才搭建完成</li>
<li>颜值是所有例子中最高的，好评</li>
</ul>
<img src="/5bdcf813/16.webp" class>

<img src="/5bdcf813/17.webp" class>

<hr>
<p>内容管理系统博客虽然重，但是整体来看比较省心，一次配置完即可以在后台界面实现各种操作，虽然要花一些时间了解技术门槛知识、花点费用去配置服务器，但是一劳永逸（花钱的会比较用心维护是真的），推荐给有频繁更新、多人维护等需求的人。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>其它比如说segmentFault、稀土掘金，如果喜欢哪个网站大胆的去写吧，个人见解基本就这些，如果有说的不对的地方还望指正！</p>
<p>其实说到最后每个方式都有自己的优缺点，没有十全十美的解决方案，当然最重要的是，不要分析了半天最后自己的博客还是一个字没动。。。。。。-_-！行动起来才是最重要的</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/390577393">https://zhuanlan.zhihu.com/p/390577393</a><br><a href="https://blog.csdn.net/grape875499765/article/details/79017906">https://blog.csdn.net/grape875499765/article/details/79017906</a><br><a href="https://segmentfault.com/a/1190000011661576">https://segmentfault.com/a/1190000011661576</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-软件设计模式概述</title>
    <url>/f153a0e3.html</url>
    <content><![CDATA[<h3 id="软件设计模式的产生背景"><a href="#软件设计模式的产生背景" class="headerlink" title="软件设计模式的产生背景"></a>软件设计模式的产生背景</h3><p>“设计模式”这个术语最初并不是出现在软件设计中，而是被用于建筑领域的设计中。</p>
<p>1977 年，美国著名建筑大师、加利福尼亚大学伯克利分校环境结构中心主任克里斯托夫·亚历山大（Christopher Alexander）在他的著作《建筑模式语言：城镇、建筑、构造（A Pattern Language: Towns Building Construction）中描述了一些常见的建筑设计问题，并提出了 253 种关于对城镇、邻里、住宅、花园和房间等进行设计的基本模式。</p>
<p>1979 年他的另一部经典著作《建筑的永恒之道》（The Timeless Way of Building）进一步强化了设计模式的思想，为后来的建筑设计指明了方向。</p>
<p>1987 年，肯特·贝克（Kent Beck）和沃德·坎宁安（Ward Cunningham）首先将克里斯托夫·亚历山大的模式思想应用在 Smalltalk 中的图形用户接口的生成中，但没有引起软件界的关注。</p>
<p>直到 1990 年，软件工程界才开始研讨设计模式的话题，后来召开了多次关于设计模式的研讨会。</p>
<p>1995 年，艾瑞克·伽马（ErichGamma）、理査德·海尔姆（Richard Helm）、拉尔夫·约翰森（Ralph Johnson）、约翰·威利斯迪斯（John Vlissides）等 4 位作者合作出版了《设计模式：可复用面向对象软件的基础》（Design Patterns: Elements of Reusable Object-Oriented Software）一书，在本教程中收录了 23 个设计模式，这是设计模式领域里程碑的事件，导致了软件设计模式的突破。这 4 位作者在软件开发领域里也以他们的“四人组”（Gang of Four，GoF）匿名著称。</p>
<p>直到今天，狭义的设计模式还是本文所介绍的 23 种经典设计模式。</p>
<hr>
<span id="more"></span>

<h3 id="软件设计模式的概念与意义"><a href="#软件设计模式的概念与意义" class="headerlink" title="软件设计模式的概念与意义"></a>软件设计模式的概念与意义</h3><p>有关软件设计模式的定义很多，有些从模式的特点来说明，有些从模式的作用来说明。本文给出的定义是大多数学者公认的，从以下两个方面来说明。</p>
<ol>
<li><p>软件设计模式的概念<br>软件设计模式（Software Design Pattern），又称设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。它描述了在软件设计过程中的一些不断重复发生的问题，以及该问题的解决方案。也就是说，它是解决特定问题的一系列套路，是前辈们的代码设计经验的总结，具有一定的普遍性，可以反复使用。其目的是为了提高代码的可重用性、代码的可读性和代码的可靠性。</p>
</li>
<li><p>学习设计模式的意义<br>设计模式的本质是面向对象设计原则的实际运用，是对类的封装性、继承性和多态性以及类的关联关系和组合关系的充分理解。正确使用设计模式具有以下优点。</p>
</li>
</ol>
<ul>
<li>可以提高程序员的思维能力、编程能力和设计能力。</li>
<li>使程序设计更加标准化、代码编制更加工程化，使软件开发效率大大提高，从而缩短软件的开发周期。</li>
<li>使设计的代码可重用性高、可读性强、可靠性高、灵活性好、可维护性强。</li>
</ul>
<p>当然，软件设计模式只是一个引导。在具体的软件幵发中，必须根据设计的应用系统的特点和要求来恰当选择。对于简单的程序开发，可能写一个简单的算法要比引入某种设计模式更加容易。但对大项目的开发或者框架设计，用设计模式来组织代码显然更好。</p>
<hr>
<h3 id="软件设计模式的基本要素"><a href="#软件设计模式的基本要素" class="headerlink" title="软件设计模式的基本要素"></a>软件设计模式的基本要素</h3><p>软件设计模式使人们可以更加简单方便地复用成功的设计和体系结构，它通常包含以下几个基本要素：模式名称、别名、动机、问题、解决方案、效果、结构、模式角色、合作关系、实现方法、适用性、已知应用、例程、模式扩展和相关模式等，其中最关键的元素包括以下 4 个主要部分。</p>
<ol>
<li><p>模式名称<br>每一个模式都有自己的名字，通常用一两个词来描述，可以根据模式的问题、特点、解决方案、功能和效果来命名。模式名称（PatternName）有助于我们理解和记忆该模式，也方便我们来讨论自己的设计。</p>
</li>
<li><p>问题<br>问题（Problem）描述了该模式的应用环境，即何时使用该模式。它解释了设计问题和问题存在的前因后果，以及必须满足的一系列先决条件。</p>
</li>
<li><p>解决方案<br>模式问题的解决方案（Solution）包括设计的组成成分、它们之间的相互关系及各自的职责和协作方式。因为模式就像一个模板，可应用于多种不同场合，所以解决方案并不描述一个特定而具体的设计或实现，而是提供设计问题的抽象描述和怎样用一个具有一般意义的元素组合（类或对象的组合）来解决这个问题。</p>
</li>
<li><p>效果<br>描述了模式的应用效果以及使用该模式应该权衡的问题，即模式的优缺点。主要是对时间和空间的衡量，以及该模式对系统的灵活性、扩充性、可移植性的影响，也考虑其实现问题。显式地列出这些效果（Consequence）对理解和评价这些模式有很大的帮助。</p>
</li>
</ol>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1317.html">http://c.biancheng.net/view/1317.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-GoF的23种设计模式</title>
    <url>/ad03970c.html</url>
    <content><![CDATA[<h3 id="GoF-的-23-种设计模式的分类和功能"><a href="#GoF-的-23-种设计模式的分类和功能" class="headerlink" title="GoF 的 23 种设计模式的分类和功能"></a>GoF 的 23 种设计模式的分类和功能</h3><p>设计模式有两种分类方法，即根据模式的目的来分和根据模式的作用的范围来分。</p>
<ol>
<li><p><strong>根据目的来分</strong></p>
<p> 根据模式是用来完成什么工作来划分，这种方式可分为创建型模式、结构型模式和行为型模式 3 种。</p>
<ol>
<li>创建型模式：用于描述“怎样创建对象”，它的主要特点是“将对象的创建与使用分离”。GoF 中提供了单例、原型、工厂方法、抽象工厂、建造者等 5 种创建型模式。</li>
<li>结构型模式：用于描述如何将类或对象按某种布局组成更大的结构，GoF 中提供了代理、适配器、桥接、装饰、外观、享元、组合等 7 种结构型模式。</li>
<li>行为型模式：用于描述类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，以及怎样分配职责。GoF 中提供了模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器等 11 种行为型模式。</li>
</ol>
</li>
</ol>
<ol start="2">
<li><p><strong>根据作用范围来分</strong></p>
<p> 根据模式是主要用于类上还是主要用于对象上来分，这种方式可分为类模式和对象模式两种。</p>
<ol>
<li>类模式：用于处理类与子类之间的关系，这些关系通过继承来建立，是静态的，在编译时刻便确定下来了。GoF中的工厂方法、（类）适配器、模板方法、解释器属于该模式。</li>
<li>对象模式：用于处理对象之间的关系，这些关系可以通过组合或聚合来实现，在运行时刻是可以变化的，更具动态性。GoF 中除了以上 4 种，其他的都是对象模式。</li>
</ol>
</li>
</ol>
<span id="more"></span>

<p>GoF 的 23 种设计模式的分类表</p>
<table>
<thead>
<tr>
<th>范围/目的</th>
<th>创建型模式</th>
<th>结构型模式</th>
<th>行为型模式</th>
</tr>
</thead>
<tbody><tr>
<td>类模式</td>
<td>工厂方法</td>
<td>(类）适配器</td>
<td>模板方法、解释器</td>
</tr>
<tr>
<td>对象模式</td>
<td>单例</td>
<td>代理</td>
<td>策略</td>
</tr>
<tr>
<td></td>
<td>原型</td>
<td>(对象）适配器</td>
<td>命令</td>
</tr>
<tr>
<td></td>
<td>抽象工厂</td>
<td>桥接</td>
<td>职责链</td>
</tr>
<tr>
<td></td>
<td>建造者</td>
<td>装饰</td>
<td>状态</td>
</tr>
<tr>
<td></td>
<td></td>
<td>外观</td>
<td>观察者</td>
</tr>
<tr>
<td></td>
<td></td>
<td>享元</td>
<td>中介者</td>
</tr>
<tr>
<td></td>
<td></td>
<td>组合</td>
<td>迭代器</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>访问者</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>备忘录</td>
</tr>
</tbody></table>
<ol start="3">
<li><p><strong>GoF的23种设计模式的功能</strong></p>
<p> 前面说明了 GoF 的 23 种设计模式的分类，现在对各个模式的功能进行介绍。</p>
<ol>
<li>单例（Singleton）模式：某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例，其拓展是有限多例模式。</li>
<li>原型（Prototype）模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。</li>
<li>工厂方法（Factory Method）模式：定义一个用于创建产品的接口，由子类决定生产什么产品。</li>
<li>抽象工厂（AbstractFactory）模式：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。</li>
<li>建造者（Builder）模式：将一个复杂对象分解成多个相对简单的部分，然后根据不同需要分别创建它们，最后构建成该复杂对象。</li>
<li>代理（Proxy）模式：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。</li>
<li>适配器（Adapter）模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。</li>
<li>桥接（Bridge）模式：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。</li>
<li>装饰（Decorator）模式：动态的给对象增加一些职责，即增加其额外的功能。</li>
<li>外观（Facade）模式：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。</li>
<li>享元（Flyweight）模式：运用共享技术来有效地支持大量细粒度对象的复用。</li>
<li>组合（Composite）模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。</li>
<li>模板方法（TemplateMethod）模式：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。</li>
<li>策略（Strategy）模式：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。</li>
<li>命令（Command）模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。</li>
<li>职责链（Chain of Responsibility）模式：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。</li>
<li>状态（State）模式：允许一个对象在其内部状态发生改变时改变其行为能力。</li>
<li>观察者（Observer）模式：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。</li>
<li>中介者（Mediator）模式：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。</li>
<li>迭代器（Iterator）模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。</li>
<li>访问者（Visitor）模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。</li>
<li>备忘录（Memento）模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。</li>
<li>解释器（Interpreter）模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。</li>
</ol>
</li>
</ol>
<p>这 23 种设计模式不是孤立存在的，很多模式之间存在一定的关联关系，在大的系统开发中常常同时使用多种设计模式。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1320.html">http://c.biancheng.net/view/1320.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-UML统一建模语言</title>
    <url>/421f316e.html</url>
    <content><![CDATA[<h3 id="UML统一建模语言是什么"><a href="#UML统一建模语言是什么" class="headerlink" title="UML统一建模语言是什么"></a>UML统一建模语言是什么</h3><p>UML（Unified Modeling Language，统一建模语言）是用来设计软件蓝图的可视化建模语言，是一种为面向对象系统的产品进行说明、可视化和编制文档的标准语言，独立于任何一种具体的程序设计语言。</p>
<p>1997 年 UML 被国际对象管理组织（OMG）采纳为面向对象的建模语言的国际标准。它的特点是简单、统一、图形化、能表达软件设计中的动态与静态信息。</p>
<hr>
<span id="more"></span>

<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>UML 能为软件开发的所有阶段提供模型化和可视化支持。而且融入了软件工程领域的新思想、新方法和新技术，使软件设计人员沟通更简明，进一步缩短了设计时间，减少开发成本。</p>
<p>UML 具有很宽的应用领域。其中最常用的是建立软件系统的模型，但它同样可以用于描述非软件领域的系统，如机械系统、企业机构或业务过程，以及处理复杂数据的信息系统、具有实时要求的工业系统或工业过程等。总之，UML 可以对任何具有静态结构和动态行为的系统进行建模，而且使用于从需求规格描述直至系统完成后的测试和维护等系统开发的各个阶段。</p>
<p>UML 模型大多以图表的方式表现出来，一份典型的建模图表通常包含几个块或框、连接线和作为模型附加信息的文本。这些虽简单却非常重要，在 UML 规则中相互联系和扩展。</p>
<p>在这里大家可能会疑问，UML 明明是一种图形，为什么说是语言呢？</p>
<p>语言是包括文字和图形的，有很多内容文字是无法表达的。你见过建筑设计图纸吗？里面还不是很多图形，光用文字能表达清楚建筑设计吗？在建筑界，有一套标准来描述设计，同样道理，在软件开发界，我们也需要一套标准来帮助我们做好软件开发的工作。UML 就是其中的一种标准，注意这可不是唯一标准，只是 UML 是大家比较推崇的一种标准而已。UML 并不是强制性标准，没有规定在软件开发中一定要用 UML，但是我们需要包括 UML 在内的各种标准，来提高我们软件开发的水平。</p>
<hr>
<h3 id="基本构件"><a href="#基本构件" class="headerlink" title="基本构件"></a>基本构件</h3><p>UML 建模的核心是模型，模型是现实的简化、真实系统的抽象。UML 提供了系统的设计蓝图。当给软件系统建模时，需要采用通用的符号语言，这种描述模型所使用的语言被称为建模语言。在 UML 中，所有的描述由事物、关系和图这些构件组成。下图完整地描述了所有构件的关系。</p>
<img src="/421f316e/1.png" class>

<hr>
<h4 id="事物"><a href="#事物" class="headerlink" title="事物"></a>事物</h4><p>事物是抽象化的最终结果，分为结构事物、行为事物、分组事物和注释事物。</p>
<ol>
<li><p><strong>结构事物</strong></p>
<p> 结构事物是模型中的静态部分，用以呈现概念或实体的表现元素，如下表所示。</p>
</li>
</ol>
<table>
<thead>
<tr>
<th>事物</th>
<th>解释</th>
<th>图例</th>
</tr>
</thead>
<tbody><tr>
<td>类（Class）</td>
<td>具有相同属性、方法、关系和语义的对象集合</td>
<td><img src="/421f316e/2.jpg" class></td>
</tr>
<tr>
<td>接口（Interface）</td>
<td>指一个类或构件的一个服务的操作集合，它仅仅定义了一组操作的规范，并没有给出这组操作的具体实现</td>
<td><img src="/421f316e/3.jpg" class></td>
</tr>
<tr>
<td>用例（User Case）</td>
<td>指对一组动作序列的描述，系统执行这些动作将产生一个对特定的参与者（Actor）有价值且可观察的结果</td>
<td><img src="/421f316e/4.jpg" class></td>
</tr>
<tr>
<td>协作（Collaboration）</td>
<td>定义元素之间的相互作用</td>
<td><img src="/421f316e/5.jpg" class></td>
</tr>
<tr>
<td>组件（Component）</td>
<td>描述物理系统的一部分</td>
<td><img src="/421f316e/6.jpg" class></td>
</tr>
<tr>
<td>活动类（Active Class）</td>
<td>指对象有一个或多个进程或线程。活动类和类很相象，只是它的对象代表的元素的行为和其他元素是同时存在的</td>
<td><img src="/421f316e/7.jpg" class></td>
</tr>
<tr>
<td>节点（Node）</td>
<td>定义为运行时存在的物理元素</td>
<td><img src="/421f316e/8.jpg" class></td>
</tr>
</tbody></table>
<ol start="2">
<li><p><strong>行为事物</strong></p>
<p> 行为事物指 UML 模型中的动态部分，如下表所示。</p>
</li>
</ol>
<table>
<thead>
<tr>
<th>事物</th>
<th>解释</th>
<th>用例</th>
</tr>
</thead>
<tbody><tr>
<td>交互（Interaction）</td>
<td>包括一组元素之间的消息交换</td>
<td><img src="/421f316e/9.jpg" class></td>
</tr>
<tr>
<td>状态机（State Machine）</td>
<td>由一系列对象的状态组成</td>
<td><img src="/421f316e/10.jpg" class></td>
</tr>
</tbody></table>
<ol start="3">
<li><p><strong>分组事物</strong></p>
<p> 目前只有一种分组事物，即包。包纯碎是概念上的，只存在于开发阶段，结构事物、行为事物甚至分组事物都有可能放在一个包中，如下表所示。</p>
</li>
</ol>
<table>
<thead>
<tr>
<th>事物</th>
<th>解释</th>
<th>用例</th>
</tr>
</thead>
<tbody><tr>
<td>包（Package）</td>
<td>UML中唯一的组织机制</td>
<td><img src="/421f316e/11.jpg" class></td>
</tr>
</tbody></table>
<ol start="4">
<li><p><strong>注释事物</strong></p>
<p> 注释事物是解释 UML 模型元素的部分，如下表所示。</p>
</li>
</ol>
<table>
<thead>
<tr>
<th>事物</th>
<th>解释</th>
<th>用例</th>
</tr>
</thead>
<tbody><tr>
<td>注释（Note）</td>
<td>用于解析说明 UML 元素</td>
<td><img src="/421f316e/12.jpg" class></td>
</tr>
</tbody></table>
<hr>
<h4 id="关系"><a href="#关系" class="headerlink" title="关系"></a>关系</h4><p>（在下一篇中讲述）</p>
<hr>
<h4 id="图"><a href="#图" class="headerlink" title="图"></a>图</h4><p>UML2.0 一共有 13 种图（UML1.5 定义了 9 种，UML2.0 增加了 4 种），分别是类图、对象图、构件图、部署图、活动图、状态图、用例图、时序图、协作图 9 种，以及包图、组合结构图、时间图、交互概览图 4 种。</p>
<table>
<thead>
<tr>
<th>图名称</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>类图（Class Diagrams）</td>
<td>用于定义系统中的类</td>
</tr>
<tr>
<td>对象图（Object Diagrams）</td>
<td>类图的一个实例，描述了系统在具体时间点上所包含的对象及各个对象之间的关系</td>
</tr>
<tr>
<td>构件图（Component Diagrams）</td>
<td>一种特殊的 UML 图，描述系统的静态实现视图</td>
</tr>
<tr>
<td>部署图（Deployment Diagrams）</td>
<td>定义系统中软硬件的物理体系结构</td>
</tr>
<tr>
<td>活动图（Activity Diagrams）</td>
<td>用来描述满足用例要求所要进行的活动及活动间的约束关系</td>
</tr>
<tr>
<td>状态图（State Chart Diagrams）</td>
<td>用来描述类的对象的所有可能的状态和时间发生时，状态的转移条件</td>
</tr>
<tr>
<td>用例图（Usecase Diagrams）</td>
<td>用来描述用户的需求，从用户的角度描述系统的功能，并指出各功能的执行者，强调谁在使用系统、系统为执行者完成哪些功能</td>
</tr>
<tr>
<td>时序图（Sequence Diagrams）</td>
<td>描述对象之间的交互顺序，着重体现对象间消息传递的时间顺序，强调对象之间消息的发送顺序，同时显示对象之间的交互过程</td>
</tr>
<tr>
<td>协作图（Collaboration Diagrams）</td>
<td>描述对象之间的合作关系，更侧重向用户对象说明哪些对象有消息的传递</td>
</tr>
<tr>
<td>包图（Package Diagrams）</td>
<td>对构成系统的模型元素进行分组整理的图</td>
</tr>
<tr>
<td>组合结构图（Composite Structure Diagrams）</td>
<td>表示类或者构建内部结构的图</td>
</tr>
<tr>
<td>时间图（Timing Diagrams）</td>
<td>用来显示随时间变化，一个或多个元素的值或状态的更改，也显示时间控制事件之间的交互及管理它们的时间和期限约束</td>
</tr>
<tr>
<td>交互概览图（Interaction Overview Diagrams）</td>
<td>用活动图来表示多个交互之间的控制关系的图</td>
</tr>
</tbody></table>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/8373.html">http://c.biancheng.net/view/8373.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-UML类图及类图之间的关系</title>
    <url>/44598158.html</url>
    <content><![CDATA[<p>在 UML 2.0 的 13 种图中，类图（Class Diagrams）是使用频率最高的 UML 图之一。类图描述系统中的类，以及各个类之间的关系的静态视图，能够让我们在正确编写代码之前对系统有一个全面的认识。类图是一种模型类型，确切地说，是一种静态模型类型。类图表示类、接口和它们之间的协作关系，用于系统设计阶段。</p>
<hr>
<span id="more"></span>

<h3 id="类、接口和类图"><a href="#类、接口和类图" class="headerlink" title="类、接口和类图"></a>类、接口和类图</h3><h4 id="类"><a href="#类" class="headerlink" title="类"></a>类</h4><p>类（Class）是指具有相同属性、方法和关系的对象的抽象，它封装了数据和行为，是面向对象程序设计（OOP）的基础，具有封装性、继承性和多态性等三大特性。在 UML 中，类使用包含类名、属性和操作且带有分隔线的矩形来表示。</p>
<p>(1) 类名（Name）是一个字符串，例如，Student。</p>
<p>(2) 属性（Attribute）是指类的特性，即类的成员变量。UML 按以下格式表示：[可见性]属性名:类型[=默认值]<br>    例如：-name:String</p>
<p>注意：“可见性”表示该属性对类外的元素是否可见，包括公有（Public）、私有（Private）、受保护（Protected）和朋友（Friendly）4 种，在类图中分别用符号+、-、#、~表示。</p>
<p>(3) 操作（Operations）是类的任意一个实例对象都可以使用的行为，是类的成员方法。UML 按以下格式表示：[可见性]名称(参数列表)[:返回类型]<br>例如：+display():void</p>
<p>如下所示是学生类的 UML 表示。</p>
<img src="/44598158/1.gif" class>

<p>类图用 3 个矩形拼接表示，最上面的部分标识类的名称，中间的部分标识类的属性，最下面的部分标识类的方法。</p>
<p>类图中，需注意以下几点：</p>
<ul>
<li>抽象类或抽象方法用斜体表示</li>
<li>如果是接口，则在类名上方加 &lt;&lt;Interface&gt;&gt;</li>
<li>字段和方法返回值的数据类型非必需</li>
<li>静态类或静态方法加下划线</li>
</ul>
<hr>
<h4 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h4><p>接口（Interface）是一种特殊的类，它具有类的结构但不可被实例化，只可以被子类实现。它包含抽象操作，但不包含属性。它描述了类或组件对外可见的动作。在 UML 中，接口使用一个带有名称的小圆圈来进行表示。</p>
<p>如下所示是图形类接口的 UML 表示。</p>
<img src="/44598158/2.gif" class>

<hr>
<h4 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h4><p>类图（ClassDiagram）是用来显示系统中的类、接口、协作以及它们之间的静态结构和关系的一种静态模型。它主要用于描述软件系统的结构化设计，帮助人们简化对软件系统的理解，它是系统分析与设计阶段的重要产物，也是系统编码与测试的重要模型依据。</p>
<p>类图中的类可以通过某种编程语言直接实现。类图在软件系统开发的整个生命周期都是有效的，它是面向对象系统的建模中最常见的图。如下所示是“计算长方形和圆形的周长与面积”的类图，图形接口有计算面积和周长的抽象方法，长方形和圆形实现这两个方法供访问类调用。</p>
<img src="/44598158/3.gif" class>

<hr>
<h3 id="类之间的关系"><a href="#类之间的关系" class="headerlink" title="类之间的关系"></a>类之间的关系</h3><p>UML 将事物之间的联系归纳为 6 种，并用对应的图形类表示。下面根据类与类之间的耦合度从弱到强排列。UML 中的类图有以下几种关系：<strong>依赖关系</strong>、<strong>关联关系</strong>、<strong>聚合关系</strong>、<strong>组合关系</strong>、<strong>泛化关系</strong>和<strong>实现关系</strong>。其中泛化和实现的耦合度相等，它们是最强的。</p>
<h4 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h4><p>依赖（Dependency）关系是一种使用关系，它是对象之间耦合度最弱的一种关联方式，是临时性的关联。在代码中，某个类的方法通过局部变量、方法的参数或者对静态方法的调用来访问另一个类（被依赖类）中的某些方法来完成一些职责。</p>
<p>在 UML 类图中，依赖关系使用带箭头的虚线来表示，箭头从使用类指向被依赖的类。如下是人与手机的关系图，人通过手机的语音传送方法打电话。</p>
<img src="/44598158/4.gif" class>

<hr>
<h4 id="关联关系"><a href="#关联关系" class="headerlink" title="关联关系"></a>关联关系</h4><p>关联（Association）关系是对象之间的一种引用关系，用于表示一类对象与另一类对象之间的联系，如老师和学生、师傅和徒弟、丈夫和妻子等。关联关系是类与类之间最常用的一种关系，分为一般关联关系、聚合关系和组合关系。我们先介绍一般关联。</p>
<p>关联可以是双向的，也可以是单向的。在 UML 类图中，双向的关联可以用带两个箭头或者没有箭头的实线来表示，单向的关联用带一个箭头的实线来表示，箭头从使用类指向被关联的类。也可以在关联线的两端标注角色名，代表两种不同的角色。</p>
<p>在代码中通常将一个类的对象作为另一个类的成员变量来实现关联关系。如下是老师和学生的关系图，每个老师可以教多个学生，每个学生也可向多个老师学，他们是双向关联。</p>
<img src="/44598158/5.gif" class>

<hr>
<h4 id="聚合关系"><a href="#聚合关系" class="headerlink" title="聚合关系"></a>聚合关系</h4><p>聚合（Aggregation）关系是关联关系的一种，是强关联关系，是整体和部分之间的关系，是 has-a 的关系。</p>
<p>聚合关系也是通过成员对象来实现的，其中成员对象是整体对象的一部分，但是成员对象可以脱离整体对象而独立存在。例如，学校与老师的关系，学校包含老师，但如果学校停办了，老师依然存在。</p>
<p>在 UML 类图中，聚合关系可以用带空心菱形的实线来表示，菱形指向整体。如下是大学和教师的关系图。</p>
<img src="/44598158/6.gif" class>

<hr>
<h4 id="组合关系"><a href="#组合关系" class="headerlink" title="组合关系"></a>组合关系</h4><p>组合（Composition）关系也是关联关系的一种，也表示类之间的整体与部分的关系，但它是一种更强烈的聚合关系，是 cxmtains-a 关系。</p>
<p>在组合关系中，整体对象可以控制部分对象的生命周期，一旦整体对象不存在，部分对象也将不存在，部分对象不能脱离整体对象而存在。例如，头和嘴的关系，没有了头，嘴也就不存在了。</p>
<p>在 UML 类图中，组合关系用带实心菱形的实线来表示，菱形指向整体。如下是头和嘴的关系图。</p>
<img src="/44598158/7.gif" class>

<hr>
<h4 id="泛化关系"><a href="#泛化关系" class="headerlink" title="泛化关系"></a>泛化关系</h4><p>泛化（Generalization）关系是对象之间耦合度最大的一种关系，表示一般与特殊的关系，是父类与子类之间的关系，是一种继承关系，是 is-a 的关系。</p>
<p>在 UML 类图中，泛化关系用带空心三角箭头的实线来表示，箭头从子类指向父类。在代码实现时，使用面向对象的继承机制来实现泛化关系。例如，Student 类和 Teacher 类都是 Person 类的子类，其类图如下所示。</p>
<img src="/44598158/8.gif" class>

<hr>
<h4 id="实现关系"><a href="#实现关系" class="headerlink" title="实现关系"></a>实现关系</h4><p>实现（Realization）关系是接口与实现类之间的关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的所有的抽象操作。</p>
<p>在 UML 类图中，实现关系使用带空心三角箭头的虚线来表示，箭头从实现类指向接口。例如，汽车和船实现了交通工具，其类图如下所示。</p>
<img src="/44598158/9.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/8374.html">http://c.biancheng.net/view/8374.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-类关系记忆技巧</title>
    <url>/f674b963.html</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>分类</th>
<th>箭头特征</th>
<th>记忆技巧</th>
</tr>
</thead>
<tbody><tr>
<td>箭头方向</td>
<td>从子类指向父类</td>
<td>1. 定义子类需要通过 extends 关键字指定父类； 2. 子类一定是知道父类定义的，但父类并不知道子类的定义； 3. 只有知道对方信息时才能指向对方； 4. 箭头的方向是从子类指向父类</td>
</tr>
<tr>
<td>继承/实现</td>
<td>用线条连接两个类；空心三角箭头表示继承或实现</td>
<td>实线表示继承，是is-a的关系，表示扩展，不虚，很结实</td>
</tr>
<tr>
<td></td>
<td></td>
<td>虚线表示实现，虚线代表“虚”无实体</td>
</tr>
<tr>
<td>关联/依赖</td>
<td>用线条连接两个类；普通箭头表示关联或依赖</td>
<td>1. 虚线表示依赖关系：临时用一下，若即若离，虚无缥缈，若有若无； 2. 表示一种使用关系，一个类需要借助另一个类来实现功能； 3. 一般一个类将另一个类作为参数使用，或作为返回值</td>
</tr>
<tr>
<td></td>
<td></td>
<td>1. 实线表示关联关系：关系稳定，实打实的关系，“铁哥们”； 2. 表示一个类对象和另一个类对象有关联； 3. 通常一个类中有另一个类对象作为属性</td>
</tr>
<tr>
<td>组合/聚合</td>
<td>用菱形表示：像一个盛东西的器皿（如盘子）</td>
<td>1. 聚合：空心菱形，代表空器皿里可以放很多相同的东西，聚集在一起（箭头方向所指的类）； 2. 整体和局部的关系，两者有独立的生命周期，是 has-a 的关系； 3. 弱关系，消极的词：弱-空</td>
</tr>
<tr>
<td></td>
<td></td>
<td>1. 组合：实心菱形，代表器皿里已经有实体结构的存在，生死与共； 2、 整体与局部的关系，和聚合关系对比，关系更加强烈，两者具有相同的生命周期，contains-a 的关系 3. 强关系，积极的词；强-满</td>
</tr>
</tbody></table>
<span id="more"></span>

<p>注意：UML 的标准类关系图中，没有实心箭头。有些 Java 编程的 IDE 自带类生成工具可能出现实心箭头，主要目的是降低理解难度。</p>
<p>下面用一个经典案例来加深和巩固对类图的理解。下图是对动物衍生关系描述的类图。这个图非常有技术含量也非常经典，大家可以好好理解一下。</p>
<img src="/f674b963/1.jpg" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/8375.html">http://c.biancheng.net/view/8375.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-优秀设计的特征</title>
    <url>/c31e5627.html</url>
    <content><![CDATA[<p>什么才是优秀的软件架构？</p>
<p>开始学习设计模式前，我们先来看看软件架构的设计过程，及需要达成的目标和尽量避免的陷阱。</p>
<hr>
<span id="more"></span>

<h3 id="代码复用"><a href="#代码复用" class="headerlink" title="代码复用"></a>代码复用</h3><p>无论是开发哪种软件产品，成本和时间都是最重要的。较少的开发时间意味着可以比竞争对手更早进入市场。较低的开发成本意味着能够留出更多的营销资金，覆盖更广泛的潜在客户。</p>
<p>其中，代码复用是减少开发成本最常用的方式之一，其目的非常明显，即：与其反复从头开发，不如在新对象中重用已有的代码。</p>
<p>这个想法表面看起来很棒，但实际上要让已有的代码在全新的代码中工作，还是需要付出额外努力的。组件间紧密的耦合、对具体类而非接口的依赖和硬编码的行为都会降低代码的灵活性，使得复用这些代码变得更加困难。</p>
<p>使用设计模式是增加软件组件灵活性并使其易于复用的方式之一。但是，这可能也会让组件变得更加复杂。</p>
<p>一般情况下，复用可以分为三个层次。在最底层，可以复用类、类库、容器，也许还有一些类的“团体（例如容器和迭代器）”。</p>
<p>框架位于最高层。它们能帮助你精简自己的设计，可以明确解决问题所需的抽象概念，然后用类来表示这些概念并定义其关系。例如，JUnit 是一个小型框架，也是框架的“Hello, world”，其中定义了 Test、TestCase 和 TestSuite 这几个类及其关系。框架通常比单个类的颗粒度要大。你可以通过在某处构建子类来与框架建立联系。这些子类信奉“Dont call us, we’ll call you.”</p>
<p>还有一个中间层次。这是我觉得设计模式所处的位置。设计模式比框架更小且更抽象。它们实际上是对一组类的关系及其互动方式的描述。当你从类转向模式，并最终到达框架的过程中，复用程度会不断增加。</p>
<p>中间层次的优点在于模式提供的复用方式要比框架的风险小。创建框架是一项投入重大且风险很高的工作，模式则能让你独立于具体代码来复用设计思想和理念。</p>
<hr>
<h3 id="扩展性"><a href="#扩展性" class="headerlink" title="扩展性"></a>扩展性</h3><p>需求变化是程序员生命中唯一不变的事情。比如以下几种场景：</p>
<ul>
<li>你在 Windows 平台上发布了一款游戏，现在人们想要 Mac OS 的版本。</li>
<li>你创建了一个使用方形按钮的 GUI 框架，但几个月后开始流行原型按钮。</li>
<li>你设计了一款优秀的电子商务网站，但仅仅几个月后，客户就要求新增电话订单的功能。</li>
</ul>
<p>每个软件开发者都经历过许多相似的故事，导致它们发生的原因也不少。</p>
<p>首先，在完成了第一版的程序后，我们就应该做好了从头开始优化重写代码的准备，因为现在你已经能在很多方面更好的理解问题了，同时在专业水平上也有所提高，所以之前的代码现在看上去可能会显得很糟糕。</p>
<p>其次，可能是在你掌控之外的某些事情发生了变化，这也是导致许多开发团队转变最初想法的原因。比如，每位在网络应用中使用 Flash 的开发者都必须重新开发或移植代码，因为不断地有浏览器停止对 Flash 格式地支持。</p>
<p>最后，可能是需求的改变，之前你的客户对当前版本的程序感到满意，但是现在希望对程序进行 11 个“小小”的改动，使其可完成原始计划阶段中完全没有提到的功能，新增或改变功能。</p>
<p>当然这也有好的一面，如果有人要求你对程序进行修改，至少说明还有人关心它。因此在设计程序架构时，有经验的开发者都会尽量选择支持未来任何可能变更的方式。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/8465.html">http://c.biancheng.net/view/8465.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-如何正确使用设计模式</title>
    <url>/f9eefb8d.html</url>
    <content><![CDATA[<p>设计模式不是为每个人准备的，而是基于业务来选择设计模式，需要时就能想到它。要明白一点，技术永远为业务服务，技术只是满足业务需要的一个工具。我们需要掌握每种设计模式的应用场景、特征、优缺点，以及每种设计模式的关联关系，这样就能够很好地满足日常业务的需要。</p>
<p>许多设计模式的功能类似，界限不是特别清楚（为了能让大家更好的理解，后面会列出类似功能设计模式之间的对比）。大家不要疑惑，设计模式不是为了特定场景而生的，而是为了让大家可以更好和更快地开发。</p>
<p>设计模式只是实现了七大设计原则的具体方式，套用太多设计模式只会陷入模式套路陷阱，最后代码写的凌乱不堪。</p>
<p>在实际工作中很少会规定必须使用哪种设计模式，这样只会限制别人。不能为了使用设计模式而去做架构，而是有了做架构的需求后，发现它符合某一类设计模式的结构，在将两者结合。</p>
<p>设计模式要活学活用，不要生搬硬套。想要游刃有余地使用设计模式，需要打下牢固的程序设计语言基础、夯实自己的编程思想、积累大量的时间经验、提高开发能力。目的都是让程序低耦合，高复用，高内聚，易扩展，易维护。</p>
<hr>
<span id="more"></span>

<h3 id="需求驱动"><a href="#需求驱动" class="headerlink" title="需求驱动"></a>需求驱动</h3><p>不仅仅是功能性需求，需求驱动还包括性能和运行时的需求，如软件的可维护性和可复用性等方面。设计模式是针对软件设计的，而软件设计是针对需求的，一定不要为了使用设计模式而使用设计模式，否则可能会使设计变得复杂，使软件难以调试和维护。</p>
<hr>
<h3 id="分析成功的模式应用项目"><a href="#分析成功的模式应用项目" class="headerlink" title="分析成功的模式应用项目"></a>分析成功的模式应用项目</h3><p>对现有的应用实例进行分析是一个很好的学习途径，应当注意学习已有的项目，而不仅是学习设计模式如何实现，更重要的是注意在什么场合使用设计模式。</p>
<hr>
<h3 id="充分了解所使用的开发平台"><a href="#充分了解所使用的开发平台" class="headerlink" title="充分了解所使用的开发平台"></a>充分了解所使用的开发平台</h3><p>设计模式大部分都是针对面向对象的软件设计，因此在理论上适合任何面向对象的语言，但随着技术的发展和编程环境的改善，设计模式的实现方式会有很大的差别。在一些平台下，某些设计模式是自然实现的。</p>
<p>不仅指编程语言，平台还包括平台引入的技术。例如，Java EE 引入了反射机制和依赖注入，这些技术的使用使设计模式的实现方式产生了改变。</p>
<hr>
<h3 id="在编程中领悟模式"><a href="#在编程中领悟模式" class="headerlink" title="在编程中领悟模式"></a>在编程中领悟模式</h3><p>软件开发是一项实践工作，最直接的方法就是编程。没有从来不下棋却熟悉定式的围棋高手，也没有不会编程就能成为架构设计师的先例。掌握设计模式是水到渠成的事情，除了理论只是和实践积累，可能会“渐悟”或者“顿悟”。</p>
<hr>
<h3 id="避免设计过度"><a href="#避免设计过度" class="headerlink" title="避免设计过度"></a>避免设计过度</h3><p>设计模式解决的是设计不足的问题，但同时也要避免设计过度。一定要牢记简洁原则，要知道设计模式是为了使设计简单，而不是更复杂。如果引入设计模式使得设计变得复杂，只能说我们把简单问题复杂化了，问题本身不需要设计模式。</p>
<p>这里需要把握的是需求变化的程度，一定要区分需求的稳定部分和可变部分。一个软件必然有稳定部分，这个部分就是核心业务逻辑。如果核心业务逻辑发生变化，软件就没有存在的必要，核心业务逻辑是我们需要固化的。对于可变的部分，需要判断可能发生变化的程度来确定设计策略和设计风险。要知道，设计过度与设计不足同样对项目有害。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>学习设计模式，死记硬背是没用的，还要从实践中理解。</p>
<p>需要特别声明的是，在日常应用中，设计模式从来都不是单个设计模式独立使用的。在实际应用中，通常多个设计模式混合使用，你中有我，我中有你。下图完整地描述了设计模式之间的混用关系，希望对大家有所帮助。</p>
<img src="/f9eefb8d/1.png" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/8465.html">http://c.biancheng.net/view/8465.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-开闭原则</title>
    <url>/6d8095ad.html</url>
    <content><![CDATA[<h3 id="开闭原则——面向对象设计原则"><a href="#开闭原则——面向对象设计原则" class="headerlink" title="开闭原则——面向对象设计原则"></a>开闭原则——面向对象设计原则</h3><p>在软件开发中，为了提高软件系统的可维护性和可复用性，增加软件的可扩展性和灵活性，程序员要尽量根据 7 条原则来开发程序，从而提高软件开发效率、节约软件开发成本和维护成本。</p>
<ol>
<li>开闭原则</li>
<li>里氏替换原则</li>
<li>依赖倒置原则</li>
<li>单一职责原则</li>
<li>接口隔离原则</li>
<li>迪米特法则</li>
<li>合成复用原则</li>
</ol>
<hr>
<h3 id="开闭原则的定义"><a href="#开闭原则的定义" class="headerlink" title="开闭原则的定义"></a>开闭原则的定义</h3><p>开闭原则（Open Closed Principle，OCP）由勃兰特·梅耶（Bertrand Meyer）提出，他在 1988 年的著作《面向对象软件构造》（Object Oriented Software Construction）中提出：软件实体应当对扩展开放，对修改关闭（Software entities should be open for extension，but closed for modification），这就是开闭原则的经典定义。</p>
<p>这里的软件实体包括以下几个部分：</p>
<ol>
<li>项目中划分出的模块</li>
<li>类与接口</li>
<li>方法</li>
</ol>
<p>开闭原则的含义是：当应用的需求改变时，在不修改软件实体的源代码或者二进制代码的前提下，可以扩展模块的功能，使其满足新的需求。</p>
<span id="more"></span>

<hr>
<h3 id="开闭原则的作用"><a href="#开闭原则的作用" class="headerlink" title="开闭原则的作用"></a>开闭原则的作用</h3><p>开闭原则是面向对象程序设计的终极目标，它使软件实体拥有一定的适应性和灵活性的同时具备稳定性和延续性。具体来说，其作用如下。</p>
<ol>
<li><p><strong>对软件测试的影响</strong></p>
<p> 软件遵守开闭原则的话，软件测试时只需要对扩展的代码进行测试就可以了，因为原有的测试代码仍然能够正常运行。</p>
</li>
<li><p><strong>可以提高代码的可复用性</strong></p>
<p> 粒度越小，被复用的可能性就越大；在面向对象的程序设计中，根据原子和抽象编程可以提高代码的可复用性。</p>
</li>
<li><p><strong>可以提高软件的可维护性</strong></p>
<p> 遵守开闭原则的软件，其稳定性高和延续性强，从而易于扩展和维护。</p>
</li>
</ol>
<hr>
<h3 id="开闭原则的实现方法"><a href="#开闭原则的实现方法" class="headerlink" title="开闭原则的实现方法"></a>开闭原则的实现方法</h3><p>可以通过“抽象约束、封装变化”来实现开闭原则，即通过接口或者抽象类为软件实体定义一个相对稳定的抽象层，而将相同的可变因素封装在相同的具体实现类中。</p>
<p>因为抽象灵活性好，适应性广，只要抽象的合理，可以基本保持软件架构的稳定。而软件中易变的细节可以从抽象派生来的实现类来进行扩展，当软件需要发生变化时，只需要根据需求重新派生一个实现类来扩展就可以了。</p>
<p>下面以 Windows 的桌面主题为例介绍开闭原则的应用。</p>
<p><strong>【例1】Windows 的桌面主题设计</strong></p>
<p>分析：Windows 的主题是桌面背景图片、窗口颜色和声音等元素的组合。用户可以根据自己的喜爱更换自己的桌面主题，也可以从网上下载新的主题。这些主题有共同的特点，可以为其定义一个抽象类（Abstract Subject），而每个具体的主题（Specific Subject）是其子类。用户窗体可以根据需要选择或者增加新的主题，而不需要修改原代码，所以它是满足开闭原则的，其类图如下图所示。</p>
<img src="/6d8095ad/1.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1322.html">http://c.biancheng.net/view/1322.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-里氏替换原则</title>
    <url>/fce73ba7.html</url>
    <content><![CDATA[<h3 id="里氏替换原则的定义"><a href="#里氏替换原则的定义" class="headerlink" title="里氏替换原则的定义"></a>里氏替换原则的定义</h3><p>里氏替换原则（Liskov Substitution Principle，LSP）由麻省理工学院计算机科学实验室的里斯科夫（Liskov）女士在 1987 年的“面向对象技术的高峰会议”（OOPSLA）上发表的一篇文章《数据抽象和层次》（Data Abstraction and Hierarchy）里提出来的，她提出：继承必须确保超类所拥有的性质在子类中仍然成立（Inheritance should ensure that any property proved about supertype objects also holds for subtype objects）。</p>
<p>里氏替换原则主要阐述了有关继承的一些原则，也就是什么时候应该使用继承，什么时候不应该使用继承，以及其中蕴含的原理。里氏替换原是继承复用的基础，它反映了基类与子类之间的关系，是对开闭原则的补充，是对实现抽象化的具体步骤的规范。</p>
<hr>
<span id="more"></span>

<h3 id="里氏替换原则的作用"><a href="#里氏替换原则的作用" class="headerlink" title="里氏替换原则的作用"></a>里氏替换原则的作用</h3><p>里氏替换原则的主要作用如下：</p>
<ol>
<li>里氏替换原则是实现开闭原则的重要方式之一。</li>
<li>它克服了继承中重写父类造成的可复用性变差的缺点。</li>
<li>它是动作正确性的保证。即类的扩展不会给已有的系统引入新的错误，降低了代码出错的可能性。</li>
<li>加强程序的健壮性，同时变更时可以做到非常好的兼容性，提高程序的维护性、可扩展性，降低需求变更时引入的风险。</li>
</ol>
<hr>
<h3 id="里氏替换原则的实现方法"><a href="#里氏替换原则的实现方法" class="headerlink" title="里氏替换原则的实现方法"></a>里氏替换原则的实现方法</h3><p>里氏替换原则通俗来讲就是：子类可以扩展父类的功能，但不能改变父类原有的功能。也就是说：子类继承父类时，除添加新的方法完成新增功能外，尽量不要重写父类的方法。</p>
<p>根据上述理解，对里氏替换原则的定义可以总结如下：</p>
<ul>
<li>子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法</li>
<li>子类中可以增加自己特有的方法</li>
<li>当子类的方法重载父类的方法时，方法的前置条件（即方法的输入参数）要比父类的方法更宽松</li>
<li>当子类的方法实现父类的方法时（重写/重载或实现抽象方法），方法的后置条件（即方法的的输出/返回值）要比父类的方法更严格或相等</li>
</ul>
<p>通过重写父类的方法来完成新的功能写起来虽然简单，但是整个继承体系的可复用性会比较差，特别是运用多态比较频繁时，程序运行出错的概率会非常大。</p>
<p>如果程序违背了里氏替换原则，则继承类的对象在基类出现的地方会出现运行错误。这时其修正方法是：取消原来的继承关系，重新设计它们之间的关系。</p>
<p>关于里氏替换原则的例子，最有名的是“正方形不是长方形”。当然，生活中也有很多类似的例子，例如，企鹅、鸵鸟和几维鸟从生物学的角度来划分，它们属于鸟类；但从类的继承关系来看，由于它们不能继承“鸟”会飞的功能，所以它们不能定义成“鸟”的子类。同样，由于“气球鱼”不会游泳，所以不能定义成“鱼”的子类；“玩具炮”炸不了敌人，所以不能定义成“炮”的子类等。</p>
<p>下面以“几维鸟不是鸟”为例来说明里氏替换原则。</p>
<p><strong>【例1】里氏替换原则在“几维鸟不是鸟”实例中的应用。</strong></p>
<p>分析：鸟一般都会飞行，如燕子的飞行速度大概是每小时 120 千米。但是新西兰的几维鸟由于翅膀退化无法飞行。假如要设计一个实例，计算这两种鸟飞行 300 千米要花费的时间。显然，拿燕子来测试这段代码，结果正确，能计算出所需要的时间；但拿几维鸟来测试，结果会发生“除零异常”或是“无穷大”，明显不符合预期，其类图如下图所示。</p>
<img src="/fce73ba7/1.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> principle;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LSPtest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Bird bird1 = <span class="keyword">new</span> Swallow();</span><br><span class="line">        Bird bird2 = <span class="keyword">new</span> BrownKiwi();</span><br><span class="line">        bird1.setSpeed(<span class="number">120</span>);</span><br><span class="line">        bird2.setSpeed(<span class="number">120</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;如果飞行300公里：&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;燕子将飞行&quot;</span> + bird1.getFlyTime(<span class="number">300</span>) + <span class="string">&quot;小时.&quot;</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;几维鸟将飞行&quot;</span> + bird2.getFlyTime(<span class="number">300</span>) + <span class="string">&quot;小时。&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception err) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;发生错误了!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 鸟类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bird</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> flySpeed;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpeed</span><span class="params">(<span class="keyword">double</span> speed)</span> </span>&#123;</span><br><span class="line">        flySpeed = speed;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getFlyTime</span><span class="params">(<span class="keyword">double</span> distance)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (distance / flySpeed);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 燕子类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Swallow</span> <span class="keyword">extends</span> <span class="title">Bird</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 几维鸟类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BrownKiwi</span> <span class="keyword">extends</span> <span class="title">Bird</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpeed</span><span class="params">(<span class="keyword">double</span> speed)</span> </span>&#123;</span><br><span class="line">        flySpeed = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">如果飞行300公里：</span><br><span class="line">燕子将飞行2.5小时.</span><br><span class="line">几维鸟将飞行Infinity小时。</span><br></pre></td></tr></table></figure>

<p>程序运行错误的原因是：几维鸟类重写了鸟类的 setSpeed(double speed) 方法，这违背了里氏替换原则。正确的做法是：取消几维鸟原来的继承关系，定义鸟和几维鸟的更一般的父类，如动物类，它们都有奔跑的能力。几维鸟的飞行速度虽然为 0，但奔跑速度不为 0，可以计算出其奔跑 300 千米所要花费的时间。其类图如下图所示。</p>
<img src="/fce73ba7/2.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1324.html">http://c.biancheng.net/view/1324.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-依赖倒置原则</title>
    <url>/50f99a66.html</url>
    <content><![CDATA[<h3 id="依赖倒置原则的定义"><a href="#依赖倒置原则的定义" class="headerlink" title="依赖倒置原则的定义"></a>依赖倒置原则的定义</h3><p>依赖倒置原则（Dependence Inversion Principle，DIP）是 Object Mentor 公司总裁罗伯特·马丁（Robert C.Martin）于 1996 年在 C++ Report 上发表的文章。</p>
<p>依赖倒置原则的原始定义为：高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象（High level modules shouldnot depend upon low level modules.Both should depend upon abstractions.Abstractions should not depend upon details. Details should depend upon abstractions）。其核心思想是：要面向接口编程，不要面向实现编程。</p>
<p>依赖倒置原则是实现开闭原则的重要途径之一，它降低了客户与实现模块之间的耦合。</p>
<p>由于在软件设计中，细节具有多变性，而抽象层则相对稳定，因此以抽象为基础搭建起来的架构要比以细节为基础搭建起来的架构要稳定得多。这里的抽象指的是接口或者抽象类，而细节是指具体的实现类。</p>
<p>使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把展现细节的任务交给它们的实现类去完成。</p>
<hr>
<span id="more"></span>

<h3 id="依赖、倒置原则的作用"><a href="#依赖、倒置原则的作用" class="headerlink" title="依赖、倒置原则的作用"></a>依赖、倒置原则的作用</h3><p>依赖倒置原则的主要作用如下：</p>
<ul>
<li>依赖倒置原则可以降低类间的耦合性。</li>
<li>依赖倒置原则可以提高系统的稳定性。</li>
<li>依赖倒置原则可以减少并行开发引起的风险。</li>
<li>依赖倒置原则可以提高代码的可读性和可维护性。</li>
</ul>
<hr>
<h3 id="依赖倒置原则的实现方法"><a href="#依赖倒置原则的实现方法" class="headerlink" title="依赖倒置原则的实现方法"></a>依赖倒置原则的实现方法</h3><p>依赖倒置原则的目的是通过要面向接口的编程来降低类间的耦合性，所以我们在实际编程中只要遵循以下4点，就能在项目中满足这个规则。</p>
<ol>
<li>每个类尽量提供接口或抽象类，或者两者都具备。</li>
<li>变量的声明类型尽量是接口或者是抽象类。</li>
<li>任何类都不应该从具体类派生。</li>
<li>使用继承时尽量遵循里氏替换原则。</li>
</ol>
<p>下面以“顾客购物程序”为例来说明依赖倒置原则的应用。</p>
<p><strong>【例1】依赖倒置原则在“顾客购物程序”中的应用。</strong></p>
<p>分析：本程序反映了 “顾客类”与“商店类”的关系。商店类中有 sell() 方法，顾客类通过该方法购物以下代码定义了顾客类通过韶关网店 ShaoguanShop 购物：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Customer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shopping</span><span class="params">(ShaoguanShop shop)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//购物</span></span><br><span class="line">        System.out.println(shop.sell());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是，这种设计存在缺点，如果该顾客想从另外一家商店（如婺源网店 WuyuanShop）购物，就要将该顾客的代码修改如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Customer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shopping</span><span class="params">(WuyuanShop shop)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//购物</span></span><br><span class="line">        System.out.println(shop.sell());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>顾客每更换一家商店，都要修改一次代码，这明显违背了开闭原则。存在以上缺点的原因是：顾客类设计时同具体的商店类绑定了，这违背了依赖倒置原则。解决方法是：定义“婺源网店”和“韶关网店”的共同接口 Shop，顾客类面向该接口编程，其代码修改如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Customer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shopping</span><span class="params">(Shop shop)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//购物</span></span><br><span class="line">        System.out.println(shop.sell());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样，不管顾客类 Customer 访问什么商店，或者增加新的商店，都不需要修改原有代码了，其类图如下图所示。</p>
<img src="/50f99a66/1.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> principle;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DIPtest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Customer wang = <span class="keyword">new</span> Customer();</span><br><span class="line">        System.out.println(<span class="string">&quot;顾客购买以下商品：&quot;</span>);</span><br><span class="line">        wang.shopping(<span class="keyword">new</span> ShaoguanShop());</span><br><span class="line">        wang.shopping(<span class="keyword">new</span> WuyuanShop());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//商店</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Shop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">sell</span><span class="params">()</span></span>; <span class="comment">//卖</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//韶关网店</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShaoguanShop</span> <span class="keyword">implements</span> <span class="title">Shop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">sell</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;韶关土特产：香菇、木耳……&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//婺源网店</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WuyuanShop</span> <span class="keyword">implements</span> <span class="title">Shop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">sell</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;婺源土特产：绿茶、酒糟鱼……&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//顾客</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Customer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shopping</span><span class="params">(Shop shop)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//购物</span></span><br><span class="line">        System.out.println(shop.sell());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">顾客购买以下商品：</span><br><span class="line">韶关土特产：香菇、木耳……</span><br><span class="line">婺源土特产：绿茶、酒糟鱼……</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1326.html">http://c.biancheng.net/view/1326.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-单一职责原则</title>
    <url>/875a393c.html</url>
    <content><![CDATA[<h3 id="单一职责原则的定义"><a href="#单一职责原则的定义" class="headerlink" title="单一职责原则的定义"></a>单一职责原则的定义</h3><p>单一职责原则（Single Responsibility Principle，SRP）又称单一功能原则，由罗伯特·C.马丁（Robert C. Martin）于《敏捷软件开发：原则、模式和实践》一书中提出的。这里的职责是指类变化的原因，单一职责原则规定一个类应该有且仅有一个引起它变化的原因，否则类应该被拆分（There should never be more than one reason for a class to change）。</p>
<p>该原则提出对象不应该承担太多职责，如果一个对象承担了太多的职责，至少存在以下两个缺点：</p>
<ol>
<li>一个职责的变化可能会削弱或者抑制这个类实现其他职责的能力；</li>
<li>当客户端需要该对象的某一个职责时，不得不将其他不需要的职责全都包含进来，从而造成冗余代码或代码的浪费。</li>
</ol>
<hr>
<span id="more"></span>

<h3 id="单一职责原则的优点"><a href="#单一职责原则的优点" class="headerlink" title="单一职责原则的优点"></a>单一职责原则的优点</h3><p>单一职责原则的核心就是控制类的粒度大小、将对象解耦、提高其内聚性。如果遵循单一职责原则将有以下优点。</p>
<ul>
<li>降低类的复杂度。一个类只负责一项职责，其逻辑肯定要比负责多项职责简单得多。</li>
<li>提高类的可读性。复杂性降低，自然其可读性会提高。</li>
<li>提高系统的可维护性。可读性提高，那自然更容易维护了。</li>
<li>变更引起的风险降低。变更是必然的，如果单一职责原则遵守得好，当修改一个功能时，可以显著降低对其他功能的影响。</li>
</ul>
<hr>
<h3 id="单一职责原则的实现方法"><a href="#单一职责原则的实现方法" class="headerlink" title="单一职责原则的实现方法"></a>单一职责原则的实现方法</h3><p>单一职责原则是最简单但又最难运用的原则，需要设计人员发现类的不同职责并将其分离，再封装到不同的类或模块中。而发现类的多重职责需要设计人员具有较强的分析设计能力和相关重构经验。下面以大学学生工作管理程序为例介绍单一职责原则的应用。</p>
<p><strong>【例1】大学学生工作管理程序。</strong></p>
<p>分析：大学学生工作主要包括学生生活辅导和学生学业指导两个方面的工作，其中生活辅导主要包括班委建设、出勤统计、心理辅导、费用催缴、班级管理等工作，学业指导主要包括专业引导、学习辅导、科研指导、学习总结等工作。如果将这些工作交给一位老师负责显然不合理，正确的做法是生活辅导由辅导员负责，学业指导由学业导师负责，其类图如下图所示。</p>
<img src="/875a393c/1.gif" class>

<p>注意：单一职责同样也适用于方法。一个方法应该尽可能做好一件事情。如果一个方法处理的事情太多，其颗粒度会变得很粗，不利于重用。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1327.html">http://c.biancheng.net/view/1327.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-接口隔离原则</title>
    <url>/21170d4c.html</url>
    <content><![CDATA[<h3 id="接口隔离原则的定义"><a href="#接口隔离原则的定义" class="headerlink" title="接口隔离原则的定义"></a>接口隔离原则的定义</h3><p>接口隔离原则（Interface Segregation Principle，ISP）要求程序员尽量将臃肿庞大的接口拆分成更小的和更具体的接口，让接口中只包含客户感兴趣的方法。</p>
<p>2002 年罗伯特·C.马丁给“接口隔离原则”的定义是：客户端不应该被迫依赖于它不使用的方法（Clients should not be forced to depend on methods they do not use）。该原则还有另外一个定义：一个类对另一个类的依赖应该建立在最小的接口上（The dependency of one class to another one should depend on the smallest possible interface）。</p>
<p>以上两个定义的含义是：要为各个类建立它们需要的专用接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。</p>
<p>接口隔离原则和单一职责都是为了提高类的内聚性、降低它们之间的耦合性，体现了封装的思想，但两者是不同的：</p>
<ul>
<li>单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离。</li>
<li>单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要约束接口，主要针对抽象和程序整体框架的构建。</li>
</ul>
<hr>
<span id="more"></span>

<h3 id="接口隔离原则的优点"><a href="#接口隔离原则的优点" class="headerlink" title="接口隔离原则的优点"></a>接口隔离原则的优点</h3><p>接口隔离原则是为了约束接口、降低类对接口的依赖性，遵循接口隔离原则有以下 5 个优点。</p>
<ul>
<li>将臃肿庞大的接口分解为多个粒度小的接口，可以预防外来变更的扩散，提高系统的灵活性和可维护性。</li>
<li>接口隔离提高了系统的内聚性，减少了对外交互，降低了系统的耦合性。</li>
<li>如果接口的粒度大小定义合理，能够保证系统的稳定性；但是，如果定义过小，则会造成接口数量过多，使设计复杂化；如果定义太大，灵活性降低，无法提供定制服务，给整体项目带来无法预料的风险。</li>
<li>使用多个专门的接口还能够体现对象的层次，因为可以通过接口的继承，实现对总接口的定义。</li>
<li>能减少项目工程中的代码冗余。过大的大接口里面通常放置许多不用的方法，当实现这个接口的时候，被迫设计冗余的代码。</li>
</ul>
<hr>
<h3 id="接口隔离原则的实现方法"><a href="#接口隔离原则的实现方法" class="headerlink" title="接口隔离原则的实现方法"></a>接口隔离原则的实现方法</h3><p>在具体应用接口隔离原则时，应该根据以下几个规则来衡量。</p>
<ul>
<li>接口尽量小，但是要有限度。一个接口只服务于一个子模块或业务逻辑。</li>
<li>为依赖接口的类定制服务。只提供调用者需要的方法，屏蔽不需要的方法。</li>
<li>了解环境，拒绝盲从。每个项目或产品都有选定的环境因素，环境不同，接口拆分的标准就不同深入了解业务逻辑。</li>
<li>提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。</li>
</ul>
<p>下面以学生成绩管理程序为例介绍接口隔离原则的应用。</p>
<p><strong>【例1】学生成绩管理程序。</strong></p>
<p>分析：学生成绩管理程序一般包含插入成绩、删除成绩、修改成绩、计算总分、计算均分、打印成绩信息、査询成绩信息等功能，如果将这些功能全部放到一个接口中显然不太合理，正确的做法是将它们分别放在输入模块、统计模块和打印模块等 3 个模块中，其类图如下图所示。</p>
<img src="/21170d4c/1.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> principle;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ISPtest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        InputModule input = StuScoreList.getInputModule();</span><br><span class="line">        CountModule count = StuScoreList.getCountModule();</span><br><span class="line">        PrintModule print = StuScoreList.getPrintModule();</span><br><span class="line">        input.insert();</span><br><span class="line">        count.countTotalScore();</span><br><span class="line">        print.printStuInfo();</span><br><span class="line">        <span class="comment">//print.delete();</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输入模块接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">InputModule</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">delete</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">modify</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//统计模块接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">CountModule</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">countTotalScore</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">countAverage</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//打印模块接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">PrintModule</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">printStuInfo</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">queryStuInfo</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//实现类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StuScoreList</span> <span class="keyword">implements</span> <span class="title">InputModule</span>, <span class="title">CountModule</span>, <span class="title">PrintModule</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">StuScoreList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> InputModule <span class="title">getInputModule</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (InputModule) <span class="keyword">new</span> StuScoreList();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CountModule <span class="title">getCountModule</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (CountModule) <span class="keyword">new</span> StuScoreList();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> PrintModule <span class="title">getPrintModule</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (PrintModule) <span class="keyword">new</span> StuScoreList();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;输入模块的insert()方法被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;输入模块的delete()方法被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">modify</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;输入模块的modify()方法被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">countTotalScore</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;统计模块的countTotalScore()方法被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">countAverage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;统计模块的countAverage()方法被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">printStuInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;打印模块的printStuInfo()方法被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryStuInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;打印模块的queryStuInfo()方法被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入模块的insert()方法被调用！</span><br><span class="line">统计模块的countTotalScore()方法被调用！</span><br><span class="line">打印模块的printStuInfo()方法被调用！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1330.html">http://c.biancheng.net/view/1330.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-迪米特法则</title>
    <url>/3f13f5b6.html</url>
    <content><![CDATA[<h3 id="迪米特法则的定义"><a href="#迪米特法则的定义" class="headerlink" title="迪米特法则的定义"></a>迪米特法则的定义</h3><p>迪米特法则（Law of Demeter，LoD）又叫作最少知识原则（Least Knowledge Principle，LKP)，产生于 1987 年美国东北大学（Northeastern University）的一个名为迪米特（Demeter）的研究项目，由伊恩·荷兰（Ian Holland）提出，被 UML 创始者之一的布奇（Booch）普及，后来又因为在经典著作《程序员修炼之道》（The Pragmatic Programmer）提及而广为人知。</p>
<p>迪米特法则的定义是：只与你的直接朋友交谈，不跟“陌生人”说话（Talk only to your immediate friends and not to strangers）。其含义是：如果两个软件实体无须直接通信，那么就不应当发生直接的相互调用，可以通过第三方转发该调用。其目的是降低类之间的耦合度，提高模块的相对独立性。</p>
<p>迪米特法则中的“朋友”是指：当前对象本身、当前对象的成员对象、当前对象所创建的对象、当前对象的方法参数等，这些对象同当前对象存在关联、聚合或组合关系，可以直接访问这些对象的方法。</p>
<hr>
<span id="more"></span>

<h3 id="迪米特法则的优点"><a href="#迪米特法则的优点" class="headerlink" title="迪米特法则的优点"></a>迪米特法则的优点</h3><p>迪米特法则要求限制软件实体之间通信的宽度和深度，正确使用迪米特法则将有以下两个优点。</p>
<ol>
<li>降低了类之间的耦合度，提高了模块的相对独立性。</li>
<li>由于亲合度降低，从而提高了类的可复用率和系统的扩展性。</li>
</ol>
<p>但是，过度使用迪米特法则会使系统产生大量的中介类，从而增加系统的复杂性，使模块之间的通信效率降低。所以，在釆用迪米特法则时需要反复权衡，确保高内聚和低耦合的同时，保证系统的结构清晰。</p>
<hr>
<h3 id="迪米特法则的实现方法"><a href="#迪米特法则的实现方法" class="headerlink" title="迪米特法则的实现方法"></a>迪米特法则的实现方法</h3><p>从迪米特法则的定义和特点可知，它强调以下两点：</p>
<ol>
<li>从依赖者的角度来说，只依赖应该依赖的对象。</li>
<li>从被依赖者的角度说，只暴露应该暴露的方法。</li>
</ol>
<p>所以，在运用迪米特法则时要注意以下 6 点。</p>
<ol>
<li>在类的划分上，应该创建弱耦合的类。类与类之间的耦合越弱，就越有利于实现可复用的目标。</li>
<li>在类的结构设计上，尽量降低类成员的访问权限。</li>
<li>在类的设计上，优先考虑将一个类设置成不变类。</li>
<li>在对其他类的引用上，将引用其他对象的次数降到最低。</li>
<li>不暴露类的属性成员，而应该提供相应的访问器（set 和 get 方法）。</li>
<li>谨慎使用序列化（Serializable）功能。</li>
</ol>
<p><strong>【例1】明星与经纪人的关系实例。</strong></p>
<p>分析：明星由于全身心投入艺术，所以许多日常事务由经纪人负责处理，如与粉丝的见面会，与媒体公司的业务洽淡等。这里的经纪人是明星的朋友，而粉丝和媒体公司是陌生人，所以适合使用迪米特法则，其类图如下图所示。</p>
<img src="/3f13f5b6/1.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> principle;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoDtest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Agent agent = <span class="keyword">new</span> Agent();</span><br><span class="line">        agent.setStar(<span class="keyword">new</span> Star(<span class="string">&quot;明星&quot;</span>));</span><br><span class="line">        agent.setFans(<span class="keyword">new</span> Fans(<span class="string">&quot;粉丝&quot;</span>));</span><br><span class="line">        agent.setCompany(<span class="keyword">new</span> Company(<span class="string">&quot;中国传媒有限公司&quot;</span>));</span><br><span class="line">        agent.meeting();</span><br><span class="line">        agent.business();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//经纪人</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Agent</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Star myStar;</span><br><span class="line">    <span class="keyword">private</span> Fans myFans;</span><br><span class="line">    <span class="keyword">private</span> Company myCompany;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setStar</span><span class="params">(Star myStar)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.myStar = myStar;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFans</span><span class="params">(Fans myFans)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.myFans = myFans;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCompany</span><span class="params">(Company myCompany)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.myCompany = myCompany;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">meeting</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(myFans.getName() + <span class="string">&quot;与&quot;</span> + myStar.getName() + <span class="string">&quot;见面了。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">business</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(myCompany.getName() + <span class="string">&quot;与&quot;</span> + myStar.getName() + <span class="string">&quot;洽淡业务。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 明星</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Star</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    Star(String name) &#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 粉丝</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Fans</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    Fans(String name) &#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 媒体公司</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Company</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    Company(String name) &#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">粉丝与明星见面了。</span><br><span class="line">中国传媒有限公司与明星洽淡业务。</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1331.html">http://c.biancheng.net/view/1331.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-合成复用原则</title>
    <url>/78e19c53.html</url>
    <content><![CDATA[<h3 id="合成复用原则的定义"><a href="#合成复用原则的定义" class="headerlink" title="合成复用原则的定义"></a>合成复用原则的定义</h3><p>合成复用原则（Composite Reuse Principle，CRP）又叫组合/聚合复用原则（Composition/Aggregate Reuse Principle，CARP）。它要求在软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。</p>
<p>如果要使用继承关系，则必须严格遵循里氏替换原则。合成复用原则同里氏替换原则相辅相成的，两者都是开闭原则的具体实现规范。</p>
<hr>
<span id="more"></span>

<h3 id="合成复用原则的重要性"><a href="#合成复用原则的重要性" class="headerlink" title="合成复用原则的重要性"></a>合成复用原则的重要性</h3><p>通常类的复用分为继承复用和合成复用两种，继承复用虽然有简单和易实现的优点，但它也存在以下缺点。</p>
<ol>
<li>继承复用破坏了类的封装性。因为继承会将父类的实现细节暴露给子类，父类对子类是透明的，所以这种复用又称为“白箱”复用。</li>
<li>子类与父类的耦合度高。父类的实现的任何改变都会导致子类的实现发生变化，这不利于类的扩展与维护。</li>
<li>它限制了复用的灵活性。从父类继承而来的实现是静态的，在编译时已经定义，所以在运行时不可能发生变化。</li>
</ol>
<p>采用组合或聚合复用时，可以将已有对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已有对象的功能，它有以下优点。</p>
<ol>
<li>它维持了类的封装性。因为成分对象的内部细节是新对象看不见的，所以这种复用又称为“黑箱”复用。</li>
<li>新旧类之间的耦合度低。这种复用所需的依赖较少，新对象存取成分对象的唯一方法是通过成分对象的接口。</li>
<li>复用的灵活性高。这种复用可以在运行时动态进行，新对象可以动态地引用与成分对象类型相同的对象。</li>
</ol>
<hr>
<h3 id="合成复用原则的实现方法"><a href="#合成复用原则的实现方法" class="headerlink" title="合成复用原则的实现方法"></a>合成复用原则的实现方法</h3><p>合成复用原则是通过将已有的对象纳入新对象中，作为新对象的成员对象来实现的，新对象可以调用已有对象的功能，从而达到复用。</p>
<p>下面以汽车分类管理程序为例来介绍合成复用原则的应用。</p>
<p><strong>【例1】汽车分类管理程序。</strong></p>
<p>分析：汽车按“动力源”划分可分为汽油汽车、电动汽车等；按“颜色”划分可分为白色汽车、黑色汽车和红色汽车等。如果同时考虑这两种分类，其组合就很多。下图所示是用继承关系实现的汽车分类的类图。</p>
<img src="/78e19c53/1.gif" class>

<p>从图可以看出用继承关系实现会产生很多子类，而且增加新的“动力源”或者增加新的“颜色”都要修改源代码，这违背了开闭原则，显然不可取。但如果改用组合关系实现就能很好地解决以上问题，其类图如下图所示。</p>
<img src="/78e19c53/2.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1333.html">http://c.biancheng.net/view/1333.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-一句话总结软件设计七大原则</title>
    <url>/f6573d14.html</url>
    <content><![CDATA[<p>我们一共介绍了 7 种设计原则，它们分别为开闭原则、里氏替换原则、依赖倒置原则、单一职责原则、接口隔离原则、迪米特法则和合成复用原则。</p>
<p>这 7 种设计原则是软件设计模式必须尽量遵循的原则，是设计模式的基础。在实际开发过程中，并不是一定要求所有代码都遵循设计原则，而是要综合考虑人力、时间、成本、质量，不刻意追求完美，要在适当的场景遵循设计原则。这体现的是一种平衡取舍，可以帮助我们设计出更加优雅的代码结构。</p>
<span id="more"></span>

<p>各种原则要求的侧重点不同，下面我们分别用一句话归纳总结软件设计模式的七大原则，如下表所示。</p>
<table>
<thead>
<tr>
<th>设计原则</th>
<th>一句话归纳</th>
<th>目的</th>
</tr>
</thead>
<tbody><tr>
<td>开闭原则</td>
<td>对扩展开放，对修改关闭</td>
<td>降低维护带来的新风险</td>
</tr>
<tr>
<td>依赖倒置原则</td>
<td>高层不应该依赖低层，要面向接口编程</td>
<td>更利于代码结构的升级扩展</td>
</tr>
<tr>
<td>单一职责原则</td>
<td>一个类只干一件事，实现类要单一</td>
<td>便于理解，提高代码的可读性</td>
</tr>
<tr>
<td>接口隔离原则</td>
<td>一个接口只干一件事，接口要精简单一</td>
<td>功能解耦，高聚合、低耦合</td>
</tr>
<tr>
<td>迪米特法则</td>
<td>不该知道的不要知道，一个类应该保持对其它对象最少的了解，降低耦合度</td>
<td>只和朋友交流，不和陌生人说话，减少代码臃肿</td>
</tr>
<tr>
<td>里氏替换原则</td>
<td>不要破坏继承体系，子类重写方法功能发生改变，不应该影响父类方法的含义</td>
<td>防止继承泛滥</td>
</tr>
<tr>
<td>合成复用原则</td>
<td>尽量使用组合或者聚合关系实现代码复用，少使用继承</td>
<td>降低代码耦合</td>
</tr>
</tbody></table>
<p>实际上，这些原则的目的只有一个：降低对象之间的耦合，增加程序的可复用性、可扩展性和可维护性。</p>
<p>记忆口诀：访问加限制，函数要节俭，依赖不允许，动态加接口，父类要抽象，扩展不更改。</p>
<p>在程序设计时，我们应该将程序功能最小化，每个类只干一件事。若有类似功能基础之上添加新功能，则要合理使用继承。对于多方法的调用，要会运用接口，同时合理设置接口功能与数量。最后类与类之间做到低耦合高内聚。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/8508.html">http://c.biancheng.net/view/8508.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-创建型模式-创建型模式概述</title>
    <url>/16af8552.html</url>
    <content><![CDATA[<p><strong>创建型模式</strong>的主要关注点是“怎样创建对象？”，它的主要特点是“将对象的创建与使用分离”。这样可以降低系统的耦合度，使用者不需要关注对象的创建细节，对象的创建由相关的工厂来完成。就像我们去商场购买商品时，不需要知道商品是怎么生产出来一样，因为它们由专门的厂商生产。</p>
<p>创建型模式分为以下几种：</p>
<ol>
<li><strong>单例（Singleton）模式：</strong>某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例，其拓展是有限多例模式。</li>
<li><strong>原型（Prototype）模式：</strong>将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。</li>
<li><strong>工厂方法（FactoryMethod）模式：</strong>定义一个用于创建产品的接口，由子类决定生产什么产品。</li>
<li><strong>抽象工厂（AbstractFactory）模式：</strong>提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。</li>
<li><strong>建造者（Builder）模式：</strong>将一个复杂对象分解成多个相对简单的部分，然后根据不同需要分别创建它们，最后构建成该复杂对象。</li>
</ol>
<span id="more"></span>

<p>以上 5 种创建型模式，除了工厂方法模式属于类创建型模式，其他的全部属于对象创建型模式，将在之后的博客中详细地介绍它们的特点、结构与应用。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1335.html">http://c.biancheng.net/view/1335.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-创建型模式-单例模式</title>
    <url>/81a0eabe.html</url>
    <content><![CDATA[<h3 id="单例模式（单例设计模式）"><a href="#单例模式（单例设计模式）" class="headerlink" title="单例模式（单例设计模式）"></a>单例模式（单例设计模式）</h3><p>在有些系统中，为了节省内存资源、保证数据内容的一致性，对某些类要求只能创建一个实例，这就是所谓的单例模式。</p>
<h3 id="单例模式的定义"><a href="#单例模式的定义" class="headerlink" title="单例模式的定义"></a>单例模式的定义</h3><p>Ensure a class has only one instance, and provide a global point of access to it.</p>
<p>确保一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。</p>
<hr>
<h3 id="单例模式的特点"><a href="#单例模式的特点" class="headerlink" title="单例模式的特点"></a>单例模式的特点</h3><ul>
<li><p>单例类只有一个实例对象。</p>
</li>
<li><p>该单例对象必须由单例类自行创建。</p>
</li>
<li><p>单例类对外提供一个访问该单例的全局访问点。</p>
</li>
</ul>
<span id="more"></span>

<hr>
<h3 id="单例模式的优点"><a href="#单例模式的优点" class="headerlink" title="单例模式的优点"></a>单例模式的优点</h3><ul>
<li><p>单例模式可以保证内存里只有一个实例，减少了内存的开销。</p>
</li>
<li><p>可以避免对资源的多重占用。</p>
</li>
<li><p>单例模式设置全局访问点，可以优化和共享资源的访问。</p>
</li>
</ul>
<hr>
<h3 id="单例模式的缺点"><a href="#单例模式的缺点" class="headerlink" title="单例模式的缺点"></a>单例模式的缺点</h3><ul>
<li><p>单例模式一般没有接口，扩展困难。如果要扩展，则除了修改原来的代码，没有第二种途径，违背开闭原则。</p>
</li>
<li><p>在并发测试中，单例模式不利于代码调试。在调试过程中，如果单例中的代码没有执行完，也不能模拟生成一个新的对象。</p>
</li>
<li><p>单例模式的功能代码通常写在一个类中，如果功能设计不合理，则很容易违背单一职责原则。</p>
</li>
</ul>
<hr>
<h3 id="单例模式的应用场景"><a href="#单例模式的应用场景" class="headerlink" title="单例模式的应用场景"></a>单例模式的应用场景</h3><p>对于 Java 来说，单例模式可以保证在一个 JVM 中只存在单一实例。</p>
<ul>
<li><p>需要频繁创建的一些类，使用单例可以降低系统的内存压力，减少 GC。</p>
</li>
<li><p>某类只要求生成一个对象的时候，如一个班中的班长、每个人的身份证号等。</p>
</li>
<li><p>某些类创建实例时占用资源较多，或实例化耗时较长，且经常使用。</p>
</li>
<li><p>某类需要频繁实例化，而创建的对象又频繁被销毁的时候，如多线程的线程池、网络连接池等。</p>
</li>
<li><p>频繁访问数据库或文件的对象。</p>
</li>
<li><p>对于一些控制硬件级别的操作，或者从系统上来讲应当是单一控制逻辑的操作，如果有多个实例，则系统会完全乱套。</p>
</li>
<li><p>当对象需要被共享的场合。由于单例模式只允许创建一个对象，共享该对象可以节省内存，并加快对象访问速度。如 Web 中的配置对象、数据库的连接池等。</p>
</li>
</ul>
<hr>
<h3 id="什么会应用单例模式"><a href="#什么会应用单例模式" class="headerlink" title="什么会应用单例模式"></a>什么会应用单例模式</h3><p>Windows中只能打开一个<strong>任务管理器</strong>，这样可以避免因打开不必要的多个任务管理器而造成内存资源的浪费，或出现多个窗口不同步等错误。</p>
<p>在计算机系统中，类似的，还有Windows的<strong>回收站</strong>、操作系统中的<strong>文件系统</strong>、多线程中的<strong>线程池</strong>、显卡的<strong>驱动对象</strong>、打印机的<strong>后台处理服务</strong>、应用程序的<strong>日志对象</strong>、数据库的<strong>连接池</strong>、网站的<strong>计数器</strong>、Web 应用的<strong>配置对象</strong>、应用程序中的<strong>对话框</strong>、系统中的<strong>缓存</strong>等常常被设计成单例。</p>
<p>在现实生活中，同样的，例如<strong>公司 CEO、部门经理</strong>等都属于单例模型。</p>
<p>J2EE 标准中的 <strong>ServletContext</strong> 和 <strong>ServletContextConfig</strong>、Spring 框架应用中的 <strong>ApplicationContext</strong>等也都是单例模式。</p>
<hr>
<h3 id="单例模式的结构"><a href="#单例模式的结构" class="headerlink" title="单例模式的结构"></a>单例模式的结构</h3><ul>
<li><p>单例类：包含一个实例且能自行创建这个实例的类。</p>
</li>
<li><p>访问类：使用单例的类。</p>
</li>
</ul>
<img src="/81a0eabe/1.jpg" class>

<hr>
<h3 id="单例模式各种实现方式"><a href="#单例模式各种实现方式" class="headerlink" title="单例模式各种实现方式"></a>单例模式各种实现方式</h3><ol>
<li><p>饿汉式实现</p>
<p> 该模式的特点是类一旦加载就创建一个单例，保证在调用 getInstance 方法之前单例已经存在了。</p>
<p> 饿汉式单例在类创建的同时就已经创建好一个静态的对象供系统使用，以后不再改变，所以是线程安全的，可以直接用于多线程而不会出现问题。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> singleton;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>懒汉式</p>
<p> 该模式的特点是类加载时没有生成单例，只有当第一次调用 getlnstance 方法时才去创建这个单例。</p>
<p> 优点：延迟加载（需要的时候才去加载）</p>
<p> 缺点：线程不安全，在多线程中很容易出现不同步的情况，如在数据库对象进行的频繁读写操作时。</p>
<p> 解决办法：</p>
<pre><code> 1. 加同步锁
 优点：解决了线程不安全的问题。
 缺点：效率有点低，每次调用实例都要判断同步锁。
 2. 双重检验锁
 优点：在并发量不多，安全性不高的情况下或许能很完美运行单例模式
 缺点：不同平台编译过程中可能会存在严重安全隐患。（用volatile或用Atomic可解决）
</code></pre>
</li>
</ol>
<pre><code><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton singleton;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Singleton <span class="title">getlnstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">                <span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> singleton;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre>
<ol start="3">
<li><p>内部类</p>
<p> 优点：延迟加载，线程安全（java中class加载时互斥的），也减少了内存消耗。</p>
<p> 内部类是一种很好的实现方式，目前公司内的项目大多都使用这种方式。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonInner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SingletonInner</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 内部类实现单例模式</span></span><br><span class="line"><span class="comment">    * 延迟加载，减少内存开销</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> SingletonInner instance = <span class="keyword">new</span> SingletonInner();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonInner <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SingletonHolder.instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>枚举类</p>
<p> 这是网上很多人推荐的一种做法，但是使用的好像广泛。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">SingletonEnum</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 1.从Java1.5开始支持;</span></span><br><span class="line"><span class="comment">    * 2.无偿提供序列化机制;</span></span><br><span class="line"><span class="comment">    * 3.绝对防止多次实例化，即使在面对复杂的序列化或者反射攻击的时候;</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    instance;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String others;</span><br><span class="line"></span><br><span class="line">    SingletonEnum() &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;SingletonEnum&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getOthers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> others;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setOthers</span><span class="params">(String others)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.others = others;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="单例模式的扩展"><a href="#单例模式的扩展" class="headerlink" title="单例模式的扩展"></a>单例模式的扩展</h3><p>单例模式可扩展为有限的多例（Multitcm）模式，这种模式可生成有限个实例并保存在 ArrayList 中，客户需要时可随机获取，其结构图如下图所示。</p>
<img src="/81a0eabe/2.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1338.html">http://c.biancheng.net/view/1338.html</a><br><a href="https://zhuanlan.zhihu.com/p/33102022">https://zhuanlan.zhihu.com/p/33102022</a><br><a href="https://blog.csdn.net/qq_35098526/article/details/79893628">https://blog.csdn.net/qq_35098526/article/details/79893628</a><br><a href="https://www.iteye.com/blog/cantellow-838473">https://www.iteye.com/blog/cantellow-838473</a><br><a href="https://www.bilibili.com/video/BV1af4y1y7sS">https://www.bilibili.com/video/BV1af4y1y7sS</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-创建型模式-原型模式</title>
    <url>/e16d6a63.html</url>
    <content><![CDATA[<h3 id="原型模式（原型设计模式）"><a href="#原型模式（原型设计模式）" class="headerlink" title="原型模式（原型设计模式）"></a>原型模式（原型设计模式）</h3><p>在有些系统中，存在大量相同或相似对象的创建问题，如果用传统的构造函数来创建对象，会比较复杂且耗时耗资源，用原型模式生成对象就很高效。</p>
<h3 id="原型模式的定义"><a href="#原型模式的定义" class="headerlink" title="原型模式的定义"></a>原型模式的定义</h3><p>用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或相似的新对象。</p>
<p>在这里，原型实例指定了要创建的对象的种类。用这种方式创建对象非常高效，根本无须知道对象创建的细节。例如，Windows 操作系统的安装通常较耗时，如果复制就快了很多。</p>
<hr>
<h3 id="原型模式的优点"><a href="#原型模式的优点" class="headerlink" title="原型模式的优点"></a>原型模式的优点</h3><ul>
<li><p>Java 自带的原型模式基于内存二进制流的复制，在性能上比直接 new 一个对象更加优良。</p>
</li>
<li><p>可以使用深克隆方式保存对象的状态，使用原型模式将对象复制一份，并将其状态保存起来，简化了创建对象的过程，以便在需要的时候使用（例如恢复到历史某一状态），可辅助实现撤销操作。</p>
</li>
</ul>
<span id="more"></span>

<hr>
<h3 id="原型模式的缺点"><a href="#原型模式的缺点" class="headerlink" title="原型模式的缺点"></a>原型模式的缺点</h3><ul>
<li><p>需要为每一个类都配置一个 clone 方法。</p>
</li>
<li><p>clone 方法位于类的内部，当对已有类进行改造的时候，需要修改代码，违背了开闭原则。</p>
</li>
<li><p>当实现深克隆时，需要编写较为复杂的代码，而且当对象之间存在多重嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦。因此，深克隆、浅克隆需要运用得当。</p>
</li>
</ul>
<hr>
<h3 id="原型模式的应用场景"><a href="#原型模式的应用场景" class="headerlink" title="原型模式的应用场景"></a>原型模式的应用场景</h3><ul>
<li>对象之间相同或相似，即只是个别的几个属性不同的时候。</li>
<li>创建对象成本较大，例如初始化时间长，占用CPU太多，或者占用网络资源太多等，需要优化资源。</li>
<li>创建一个对象需要繁琐的数据准备或访问权限等，需要提高性能或者提高安全性。</li>
<li>系统中大量使用该类对象，且各个调用者都需要给它的属性重新赋值。</li>
</ul>
<p>在 Spring 中，原型模式应用的非常广泛，例如 scope=’prototype’、JSON.parseObject() 等都是原型模式的具体应用。</p>
<hr>
<h3 id="原型模式的结构"><a href="#原型模式的结构" class="headerlink" title="原型模式的结构"></a>原型模式的结构</h3><ul>
<li><p>由于 Java 提供了对象的 clone() 方法，所以用 Java 实现原型模式很简单。</p>
</li>
<li><p>抽象原型类：规定了具体原型对象必须实现的接口。</p>
</li>
<li><p>具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象。</p>
</li>
<li><p>访问类：使用具体原型类中的 clone() 方法来复制新的对象。</p>
</li>
</ul>
<img src="/e16d6a63/1.jpg" class>

<hr>
<h3 id="原型模式的实现"><a href="#原型模式的实现" class="headerlink" title="原型模式的实现"></a>原型模式的实现</h3><p>原型模式的克隆分为浅克隆和深克隆。</p>
<p>Java 中的 Object 类提供了浅克隆的 clone() 方法，具体原型类只要实现 Cloneable 接口就可实现对象的浅克隆，这里的 Cloneable 接口就是抽象原型类。</p>
<ul>
<li><p>浅克隆：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。（即克隆对象内的对象仍是旧对象）</p>
</li>
<li><p>深克隆：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。</p>
</li>
</ul>
<img src="/e16d6a63/2.png" class>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 原型接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Prototype</span> </span>&#123;</span><br><span class="line">    <span class="function">Object <span class="title">clone</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 飞机类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Plane</span> <span class="keyword">implements</span> <span class="title">Prototype</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String type;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Plane</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        name = <span class="string">&quot;Name:&quot;</span> + Math.random();</span><br><span class="line">        type = <span class="string">&quot;Type:&quot;</span> + Math.random();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Plane</span><span class="params">(Plane plane)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = plane.name;</span><br><span class="line">        <span class="keyword">this</span>.type = plane.type;</span><br><span class="line">        <span class="comment">// 如果是引用类型则在构造函数里面new一个新的</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> type;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// return (Plane)super.clone();     // 浅克隆</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Plane(<span class="keyword">this</span>);             <span class="comment">// 深克隆</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrototypePattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> CloneNotSupportedException </span>&#123;</span><br><span class="line">        Plane plane = <span class="keyword">new</span> Plane();</span><br><span class="line">        System.out.println(plane.getName() + <span class="string">&quot; &quot;</span> + plane.getType());</span><br><span class="line">        Plane clone = (Plane)plane.clone();</span><br><span class="line">        System.out.println(clone.getName() + <span class="string">&quot; &quot;</span> + clone.getType());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="原型模式的扩展"><a href="#原型模式的扩展" class="headerlink" title="原型模式的扩展"></a>原型模式的扩展</h3><p>原型模式可扩展为带原型管理器的原型模式，它在原型模式的基础上增加了一个原型管理器 PrototypeManager 类。该类用 HashMap 保存多个复制的原型，Client 类可以通过管理器的 get(String id) 方法从中获取复制的原型。其结构图如下图所示。</p>
<img src="/e16d6a63/3.gif" class>

<p><strong>用带原型管理器的原型模式来生成包含“圆”和“正方形”等图形的原型，并计算其面积。</strong>分析：本实例中由于存在不同的图形类，例如，“圆”和“正方形”，它们计算面积的方法不一样，所以需要用一个原型管理器来管理它们，下图所示是其结构图。</p>
<img src="/e16d6a63/4.gif" class>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Shape</span> <span class="keyword">extends</span> <span class="title">Cloneable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span></span>;    <span class="comment">//拷贝</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">countArea</span><span class="params">()</span></span>;    <span class="comment">//计算面积</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Circle</span> <span class="keyword">implements</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Circle w = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            w = (Circle) <span class="keyword">super</span>.clone();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (CloneNotSupportedException e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;拷贝圆失败!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> w;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">countArea</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> r = <span class="number">0</span>;</span><br><span class="line">        System.out.print(<span class="string">&quot;这是一个圆，请输入圆的半径：&quot;</span>);</span><br><span class="line">        Scanner input = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        r = input.nextInt();</span><br><span class="line">        System.out.println(<span class="string">&quot;该圆的面积=&quot;</span> + <span class="number">3.1415</span> * r * r + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Square</span> <span class="keyword">implements</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Square b = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            b = (Square) <span class="keyword">super</span>.clone();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (CloneNotSupportedException e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;拷贝正方形失败!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> b;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">countArea</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line">        System.out.print(<span class="string">&quot;这是一个正方形，请输入它的边长：&quot;</span>);</span><br><span class="line">        Scanner input = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        a = input.nextInt();</span><br><span class="line">        System.out.println(<span class="string">&quot;该正方形的面积=&quot;</span> + a * a + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProtoTypeManager</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> HashMap&lt;String, Shape&gt; ht = <span class="keyword">new</span> HashMap&lt;String, Shape&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProtoTypeManager</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ht.put(<span class="string">&quot;Circle&quot;</span>, <span class="keyword">new</span> Circle());</span><br><span class="line">        ht.put(<span class="string">&quot;Square&quot;</span>, <span class="keyword">new</span> Square());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addshape</span><span class="params">(String key, Shape obj)</span> </span>&#123;</span><br><span class="line">        ht.put(key, obj);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Shape <span class="title">getShape</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">        Shape temp = ht.get(key);</span><br><span class="line">        <span class="keyword">return</span> (Shape) temp.clone();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProtoTypeShape</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ProtoTypeManager pm = <span class="keyword">new</span> ProtoTypeManager();</span><br><span class="line">        Shape obj1 = (Circle) pm.getShape(<span class="string">&quot;Circle&quot;</span>);</span><br><span class="line">        obj1.countArea();</span><br><span class="line">        Shape obj2 = (Shape) pm.getShape(<span class="string">&quot;Square&quot;</span>);</span><br><span class="line">        obj2.countArea();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行结果如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">这是一个圆，请输入圆的半径：3</span><br><span class="line">该圆的面积=28.2735</span><br><span class="line"></span><br><span class="line">这是一个正方形，请输入它的边长：3</span><br><span class="line">该正方形的面积=9</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1343.html">http://c.biancheng.net/view/1343.html</a><br><a href="https://blog.csdn.net/zhangjg_blog/article/details/18369201">https://blog.csdn.net/zhangjg_blog/article/details/18369201</a><br><a href="https://www.bilibili.com/video/BV1Tt4y1e7mk">https://www.bilibili.com/video/BV1Tt4y1e7mk</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>Hexo-静态博客框架Hexo插入本地图片</title>
    <url>/bc3be9b8.html</url>
    <content><![CDATA[<p>在Hexo插入本地图片上传到服务器，比调用外部链接节省一丢丢流量，也方便一些，避免图床失效导致失去图片等问题。</p>
<hr>
<h3 id="安装插件，在hexo项目根目录打开Git-Bash或cmd"><a href="#安装插件，在hexo项目根目录打开Git-Bash或cmd" class="headerlink" title="安装插件，在hexo项目根目录打开Git Bash或cmd"></a>安装插件，在hexo项目根目录打开Git Bash或cmd</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-asset-image</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="打开hexo的配置文件-config-yml"><a href="#打开hexo的配置文件-config-yml" class="headerlink" title="打开hexo的配置文件_config.yml"></a>打开hexo的配置文件_config.yml</h3><ul>
<li>找到 post_asset_folder，把这个选项从false改成true</li>
</ul>
<hr>
<span id="more"></span>

<h3 id="修改hexo-asset-image插件"><a href="#修改hexo-asset-image插件" class="headerlink" title="修改hexo-asset-image插件"></a>修改hexo-asset-image插件</h3><ul>
<li><p>打开/node_modules/hexo-asset-image/index.js</p>
</li>
<li><p>将内容更换为下面的代码（在此感谢Ericam_ 大神：<a href="https://blog.csdn.net/xjm850552586">https://blog.csdn.net/xjm850552586</a>）</p>
</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="meta">&#x27;use strict&#x27;</span>;</span><br><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">&#x27;cheerio&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getPosition</span>(<span class="params">str, m, i</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> str.split(m, i).join(m).length;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> version = <span class="built_in">String</span>(hexo.version).split(<span class="string">&#x27;.&#x27;</span>);</span><br><span class="line">hexo.extend.filter.register(<span class="string">&#x27;after_post_render&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> config = hexo.config;</span><br><span class="line">  <span class="keyword">if</span>(config.post_asset_folder)&#123;</span><br><span class="line">        <span class="keyword">var</span> link = data.permalink;</span><br><span class="line">    <span class="keyword">if</span>(version.length &gt; <span class="number">0</span> &amp;&amp; <span class="built_in">Number</span>(version[<span class="number">0</span>]) == <span class="number">3</span>)</span><br><span class="line">       <span class="keyword">var</span> beginPos = getPosition(link, <span class="string">&#x27;/&#x27;</span>, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">       <span class="keyword">var</span> beginPos = getPosition(link, <span class="string">&#x27;/&#x27;</span>, <span class="number">3</span>) + <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.</span></span><br><span class="line">    <span class="keyword">var</span> endPos = link.lastIndexOf(<span class="string">&#x27;/&#x27;</span>) + <span class="number">1</span>;</span><br><span class="line">    link = link.substring(beginPos, endPos);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> toprocess = [<span class="string">&#x27;excerpt&#x27;</span>, <span class="string">&#x27;more&#x27;</span>, <span class="string">&#x27;content&#x27;</span>];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; toprocess.length; i++)&#123;</span><br><span class="line">      <span class="keyword">var</span> key = toprocess[i];</span><br><span class="line"> </span><br><span class="line">      <span class="keyword">var</span> $ = cheerio.load(data[key], &#123;</span><br><span class="line">        <span class="attr">ignoreWhitespace</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">xmlMode</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">lowerCaseTags</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">decodeEntities</span>: <span class="literal">false</span></span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">      $(<span class="string">&#x27;img&#x27;</span>).each(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ($(<span class="built_in">this</span>).attr(<span class="string">&#x27;src&#x27;</span>))&#123;</span><br><span class="line">            <span class="comment">// For windows style path, we replace &#x27;\&#x27; to &#x27;/&#x27;.</span></span><br><span class="line">            <span class="keyword">var</span> src = $(<span class="built_in">this</span>).attr(<span class="string">&#x27;src&#x27;</span>).replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>);</span><br><span class="line">            <span class="keyword">if</span>(!<span class="regexp">/http[s]*.*|\/\/.*/</span>.test(src) &amp;&amp;</span><br><span class="line">               !<span class="regexp">/^\s*\//</span>.test(src)) &#123;</span><br><span class="line">              <span class="comment">// For &quot;about&quot; page, the first part of &quot;src&quot; can&#x27;t be removed.</span></span><br><span class="line">              <span class="comment">// In addition, to support multi-level local directory.</span></span><br><span class="line">              <span class="keyword">var</span> linkArray = link.split(<span class="string">&#x27;/&#x27;</span>).filter(<span class="function"><span class="keyword">function</span>(<span class="params">elem</span>)</span>&#123;</span><br><span class="line">                <span class="keyword">return</span> elem != <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">              &#125;);</span><br><span class="line">              <span class="keyword">var</span> srcArray = src.split(<span class="string">&#x27;/&#x27;</span>).filter(<span class="function"><span class="keyword">function</span>(<span class="params">elem</span>)</span>&#123;</span><br><span class="line">                <span class="keyword">return</span> elem != <span class="string">&#x27;&#x27;</span> &amp;&amp; elem != <span class="string">&#x27;.&#x27;</span>;</span><br><span class="line">              &#125;);</span><br><span class="line">              <span class="keyword">if</span>(srcArray.length &gt; <span class="number">1</span>)</span><br><span class="line">                srcArray.shift();</span><br><span class="line">              src = srcArray.join(<span class="string">&#x27;/&#x27;</span>);</span><br><span class="line">              $(<span class="built_in">this</span>).attr(<span class="string">&#x27;src&#x27;</span>, config.root + link + src);</span><br><span class="line">              <span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info(<span class="string">&quot;update link as:--&gt;&quot;</span>+config.root + link + src);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info(<span class="string">&quot;no src attr, skipped...&quot;</span>);</span><br><span class="line">            <span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info($(<span class="built_in">this</span>));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">      data[key] = $.html();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="已经可以插入图片了"><a href="#已经可以插入图片了" class="headerlink" title="已经可以插入图片了"></a>已经可以插入图片了</h3><ul>
<li>例如 hexo n “test” 在 source/_posts 生成 test.md 文件和 test 文件夹<br> 就在 test.md 文件里面按 markdown 的标准写(我的文件名是test.jpg)</li>
</ul>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">// 第一种方式 .md可预览 但在某些主题不显示 例如diaspora</span><br><span class="line">![<span class="string">这是代替图片的文字，随便写</span>](<span class="link">test.jpg</span>)</span><br><span class="line"></span><br><span class="line">// 第二种方式 .md不可预览 但什么主题都可使用</span><br><span class="line">&#123;% asset<span class="emphasis">_img example.jpg This is an example image %&#125;</span></span><br><span class="line"><span class="emphasis">or</span></span><br><span class="line"><span class="emphasis">&#123;% asset_</span>img example.jpg %&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><ul>
<li>以后 hexo n 后在 source/_posts 的 .md 文件的同名文件夹里，直接放入图片调用图片名即可</li>
</ul>
<hr>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><blockquote>
<p><a href="https://blog.csdn.net/xjm850552586/article/details/84101345">https://blog.csdn.net/xjm850552586/article/details/84101345</a><br><a href="https://blog.csdn.net/qq_38148394/article/details/79997971">https://blog.csdn.net/qq_38148394/article/details/79997971</a><br><a href="https://www.jianshu.com/p/f72aaad7b852">https://www.jianshu.com/p/f72aaad7b852</a><br><a href="https://blog.csdn.net/xjm850552586/article/details/84101345">https://blog.csdn.net/xjm850552586/article/details/84101345</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>Linux-部署Node.js和Express框架</title>
    <url>/e3e12799.html</url>
    <content><![CDATA[<h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><ul>
<li><p><a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/">putty</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/">腾讯云服务器或轻量应用服务器</a></p>
</li>
</ul>
<hr>
<h3 id="云服务器配置"><a href="#云服务器配置" class="headerlink" title="云服务器配置"></a>云服务器配置</h3><ul>
<li>镜像：系统镜像：CentOS 7.6</li>
</ul>
<hr>
<h3 id="云服务器准备"><a href="#云服务器准备" class="headerlink" title="云服务器准备"></a>云服务器准备</h3><ul>
<li>重置密码</li>
</ul>
<img src="/e3e12799/1.png" class>

<hr>
<span id="more"></span>

<h3 id="登录云服务器"><a href="#登录云服务器" class="headerlink" title="登录云服务器"></a>登录云服务器</h3><ul>
<li>使用 putty 输入公网ip地址登录云服务器</li>
</ul>
<img src="/e3e12799/2.png" class>

<ul>
<li>输入账号密码，登录 root</li>
</ul>
<hr>
<h3 id="配置Node-js"><a href="#配置Node-js" class="headerlink" title="配置Node.js"></a>配置Node.js</h3><ul>
<li>查看当前目录：输入pwd会发现此时默认在 /root</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# pwd</span><br></pre></td></tr></table></figure>

<ul>
<li>若不在 /root，我习惯是切换到 root (方便我之后代码统一)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# cd /root</span><br></pre></td></tr></table></figure>

<ul>
<li>下载node的镜像，此次使用 taobao 镜像的 node v14.15.2 版本（如果太慢了就在电脑上复制链接下载好，用WinSCP传过去）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# wget https://npm.taobao.org/mirrors/node/v14.15.2/node-v14.15.2-linux-x64.tar.xz</span><br></pre></td></tr></table></figure>

<ul>
<li>解压下载好的压缩包</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# tar -xvf ./node-v14.15.2-linux-x64.tar.xz</span><br></pre></td></tr></table></figure>

<ul>
<li>为了环境卫生，删除已解压的压缩包</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# rm -rf ./node-v14.15.2-linux-x64.tar.xz</span><br></pre></td></tr></table></figure>

<ul>
<li>配置node的环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# ln -s /root/node-v14.15.2-linux-x64/bin/node /usr/local/bin/</span><br><span class="line">[root@VM-8-3-centos ~]# ln -s /root/node-v14.15.2-linux-x64/bin/npm /usr/local/bin/</span><br></pre></td></tr></table></figure>

<ul>
<li>查看环境配置是否完成</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# node -v</span><br><span class="line">[root@VM-8-3-centos ~]# npm -v</span><br></pre></td></tr></table></figure>

<ul>
<li>注：低版本的npm下载依赖比较慢，若下载速度慢，可以使用以下命令可以将npm升级至最新版本</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# npm install -g npm</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="配置Express框架"><a href="#配置Express框架" class="headerlink" title="配置Express框架"></a>配置Express框架</h3><ul>
<li>下载 taobao 的 cnpm，比普通的 npm 翻墙下载快多了，并配置环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# npm install cnpm -g --registry=https://registry.npm.taobao.org</span><br><span class="line">[root@VM-8-3-centos ~]# ln -s /root/node-v14.15.2-linux-x64/bin/cnpm /usr/local/bin/</span><br></pre></td></tr></table></figure>

<ul>
<li>全局安装Express，并配置环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# cnpm install -g express </span><br><span class="line">[root@VM-8-3-centos ~]# cnpm install -g express-generator</span><br><span class="line">[root@VM-8-3-centos ~]# ln -s /root/node-v14.15.2-linux-x64/bin/express /usr/local/bin/</span><br></pre></td></tr></table></figure>

<ul>
<li>创建一个 express 站点 cloud</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# cd /home/</span><br><span class="line">[root@VM-8-3-centos ~]# express cloud</span><br></pre></td></tr></table></figure>

<ul>
<li>初始化完成后，进入到目录中，安装对应的依赖</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# cd cloud/</span><br><span class="line">[root@VM-8-3-centos ~]# cnpm install</span><br></pre></td></tr></table></figure>

<ul>
<li>测试Express（记得在云服务器安全组开放3000端口）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# DEBUG=cloud:* npm start</span><br></pre></td></tr></table></figure>

<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><blockquote>
<p><a href="https://www.cnblogs.com/liuqi/p/6483317.html">https://www.cnblogs.com/liuqi/p/6483317.html</a><br><a href="https://blog.csdn.net/weixin_42883636/article/details/87720104">https://blog.csdn.net/weixin_42883636/article/details/87720104</a><br><a href="https://blog.csdn.net/qq_38306688/article/details/80454896">https://blog.csdn.net/qq_38306688/article/details/80454896</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-创建型模式-简单工厂模式</title>
    <url>/9043dd53.html</url>
    <content><![CDATA[<p>现实生活中，原始社会自给自足（没有工厂），农耕社会小作坊（简单工厂，民间酒坊），工业革命流水线（工厂方法，自产自销），现代产业链代工厂（抽象工厂，富士康）。我们的项目代码同样是由简到繁一步一步迭代而来的，但对于调用者来说，却越来越简单。</p>
<p>在日常开发中，凡是需要生成复杂对象的地方，都可以尝试考虑使用工厂模式来代替。</p>
<pre><code>注意：上述复杂对象指的是类的构造函数参数过多等对类的构造有影响的情况，因为类的构造过于复杂，如果直接在其他业务类内使用，则两者的耦合过重，后续业务更改，就需要在任何引用该类的源代码内进行更改，光是查找所有依赖就很消耗时间了，更别说要一个一个修改了。
</code></pre>
<hr>
<h3 id="简单工厂模式"><a href="#简单工厂模式" class="headerlink" title="简单工厂模式"></a>简单工厂模式</h3><p><strong>工厂模式的定义：</strong>定义一个创建产品对象的工厂接口，将产品对象的实际创建工作推迟到具体子工厂类当中。这满足创建型模式中所要求的“创建与使用相分离”的特点。</p>
<p>按实际业务场景划分，工厂模式有 3 种不同的实现方式，分别是<strong>简单工厂模式</strong>、<strong>工厂方法模式</strong>和<strong>抽象工厂模式</strong>。</p>
<p>我们把被创建的对象称为“产品”，把创建产品的对象称为“工厂”。如果要创建的产品不多，只要<strong>一个工厂类</strong>就可以完成，这种模式叫“简单工厂模式”。</p>
<p>在简单工厂模式中创建实例的方法通常为<strong>静态（static）方法</strong>，因此<strong>简单工厂模式（Simple Factory Pattern）</strong>又叫作<strong>静态工厂方法模式（Static Factory Method Pattern）</strong>。</p>
<p>简单来说，简单工厂模式有一个具体的工厂类，可以生成多个不同的产品，属于创建型设计模式。<strong>简单工厂模式不在 GoF 23 种设计模式之列</strong>。</p>
<p>简单工厂模式每增加一个产品就要增加一个具体产品类和一个对应的具体工厂类，这增加了系统的复杂度，<strong>违背了“开闭原则”</strong>。</p>
<pre><code>“工厂方法模式”是对简单工厂模式的进一步抽象化，其好处是可以使系统在不修改原来代码的情况下引进新的产品，即满足开闭原则。
</code></pre>
<hr>
<span id="more"></span>

<h3 id="简单工厂模式的优点和缺点"><a href="#简单工厂模式的优点和缺点" class="headerlink" title="简单工厂模式的优点和缺点"></a>简单工厂模式的优点和缺点</h3><p><strong>优点：</strong></p>
<ol>
<li>工厂类包含必要的逻辑判断，可以决定在什么时候创建哪一个产品的实例。客户端可以免除直接创建产品对象的职责，很方便的创建出相应的产品。工厂和产品的职责区分明确。</li>
<li>客户端无需知道所创建具体产品的类名，只需知道参数即可。</li>
<li>也可以引入配置文件，在不修改客户端代码的情况下更换和添加新的具体产品类。</li>
</ol>
<p><strong>缺点：</strong></p>
<ol>
<li>简单工厂模式的工厂类单一，负责所有产品的创建，职责过重，一旦异常，整个系统将受影响。且工厂类代码会非常臃肿，违背高聚合原则。</li>
<li>使用简单工厂模式会增加系统中类的个数（引入新的工厂类），增加系统的复杂度和理解难度。</li>
<li>系统扩展困难，一旦增加新产品不得不修改工厂逻辑，在产品类型较多时，可能造成逻辑过于复杂。</li>
<li>简单工厂模式使用了 static 工厂方法，造成工厂角色无法形成基于继承的等级结构。</li>
</ol>
<p>这些缺点在工厂方法模式中得到了一定的克服。</p>
<p><strong>应用场景</strong></p>
<ol>
<li>工厂类负责创建的对象比较少。</li>
<li>客户只知道传入工厂类的参数，对于如何创建对象（逻辑）不关心。</li>
<li>由于简单工厂很容易违反高内聚责任分配原则，因此一般只在很简单的情况下应用。</li>
</ol>
<p>对于产品种类相对较少的情况，考虑使用简单工厂模式。使用简单工厂模式的客户端只需要传入工厂类的参数，不需要关心如何创建对象的逻辑，可以很方便地创建所需产品。</p>
<hr>
<h3 id="简单工厂模式的结构与实现"><a href="#简单工厂模式的结构与实现" class="headerlink" title="简单工厂模式的结构与实现"></a>简单工厂模式的结构与实现</h3><p>简单工厂模式的主要角色如下：</p>
<ul>
<li>简单工厂（SimpleFactory）：是简单工厂模式的核心，负责实现创建所有实例的内部逻辑。工厂类的创建产品类的方法可以被外界直接调用，创建所需的产品对象。</li>
<li>抽象产品（Product）：是简单工厂创建的所有对象的父类，负责描述所有实例共有的公共接口。</li>
<li>具体产品（ConcreteProduct）：是简单工厂模式的创建目标。</li>
</ul>
<p>其结构图如下图所示。</p>
<img src="/9043dd53/1.png" class>

<p>根据上图写出该模式的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 抽象产品</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 具体产品：ProductA</span></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteProduct1</span> <span class="keyword">implements</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;具体产品1显示...&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 具体产品：ProductB</span></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteProduct2</span> <span class="keyword">implements</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;具体产品2显示...&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PRODUCT_A = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PRODUCT_B = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PRODUCT_C = <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleFactory</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Product <span class="title">makeProduct</span><span class="params">(<span class="keyword">int</span> kind)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">switch</span> (kind) &#123;</span><br><span class="line">                <span class="keyword">case</span> Const.PRODUCT_A:</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct1();</span><br><span class="line">                <span class="keyword">case</span> Const.PRODUCT_B:</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct2();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/8385.html">http://c.biancheng.net/view/8385.html</a><br><a href="https://baike.baidu.com/item/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F">https://baike.baidu.com/item/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>Hexo-NexT主题添加pdf预览</title>
    <url>/182775a5.html</url>
    <content><![CDATA[<h3 id="Install-hexo-dependency"><a href="#Install-hexo-dependency" class="headerlink" title="Install hexo dependency"></a>Install hexo dependency</h3><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">$ npm install --save hexo-pdf</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p><strong>/_config.yml</strong> 中调整为 <strong>post_asset_folder: true</strong></p>
<p><strong>/themes/next/_config.yml</strong> 中的 <strong>pdf</strong> 调整为 <strong>enable: true</strong></p>
<hr>
<span id="more"></span>

<h4 id="第一种方法"><a href="#第一种方法" class="headerlink" title="第一种方法"></a>第一种方法</h4><p>源文件在 <strong>/themes/next/source</strong>，在要预览pdf的博客中写入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% pdf ./xxx.pdf %&#125;</span><br></pre></td></tr></table></figure>

<p>所以例如pdf文件的路径是 <strong>\themes\next\source\file\Deep_Residual_Learning_for_Image_Recognition.pdf</strong>，那么在博客中应为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% pdf ./file/Deep_Residual_Learning_for_Image_Recognition.pdf %&#125;</span><br></pre></td></tr></table></figure>

<img src="/182775a5/1.png" class>

<img src="/182775a5/2.png" class>

<hr>
<h4 id="第二种方法"><a href="#第二种方法" class="headerlink" title="第二种方法"></a>第二种方法</h4><p>这种是比较自定义的方法，用html解决</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">object</span> <span class="attr">data</span>=<span class="string">&quot;./xxx.pdf&quot;</span> <span class="attr">type</span>=<span class="string">&quot;application/pdf&quot;</span> <span class="attr">width</span>=<span class="string">&quot;100%&quot;</span> <span class="attr">height</span>=<span class="string">&quot;1000px&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>object可换成embed, iframe</p>
<hr>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-创建型模式-工厂方法模式</title>
    <url>/b321b3ea.html</url>
    <content><![CDATA[<h3 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h3><p>在现实生活中社会分工越来越细，越来越专业化。各种产品有专门的工厂生产，彻底告别了自给自足的小农经济时代，这大大缩短了产品的生产周期，提高了生产效率。同样，在软件开发中能否做到软件对象的生产和使用相分离呢？能否在满足“开闭原则”的前提下，客户随意增删或改变对软件相关对象的使用呢？</p>
<p>在《简单工厂模式》一节我们介绍了简单工厂模式，提到了简单工厂模式违背了开闭原则，而“工厂方法模式”是对简单工厂模式的进一步抽象化，其好处是可以使系统在不修改原来代码的情况下引进新的产品，即满足开闭原则。</p>
<span id="more"></span>

<p><strong>优点：</strong></p>
<ul>
<li>用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程。</li>
<li>灵活性增强，对于新产品的创建，只需多写一个相应的工厂类。</li>
<li>典型的解耦框架。高层模块只需要知道产品的抽象类，无须关心其他实现类，满足迪米特法则、依赖倒置原则和里氏替换原则。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>类的个数容易过多，增加复杂度</li>
<li>增加了系统的抽象性和理解难度</li>
<li>抽象产品只能生产一种产品，此弊端可使用抽象工厂模式解决。</li>
</ul>
<p><strong>应用场景：</strong></p>
<ul>
<li>客户只知道创建产品的工厂名，而不知道具体的产品名。如 TCL 电视工厂、海信电视工厂等。</li>
<li>创建对象的任务由多个具体子工厂中的某一个完成，而抽象工厂只提供创建产品的接口。</li>
<li>客户不关心创建产品的细节，只关心产品的品牌</li>
</ul>
<hr>
<h3 id="工厂模式的结构与实现"><a href="#工厂模式的结构与实现" class="headerlink" title="工厂模式的结构与实现"></a>工厂模式的结构与实现</h3><p>工厂方法模式由抽象工厂、具体工厂、抽象产品和具体产品等4个要素构成。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>工厂方法模式的主要角色如下：</p>
<ol>
<li>抽象工厂（Abstract Factory）：提供了创建产品的接口，调用者通过它访问具体工厂的工厂方法 newProduct() 来创建产品。</li>
<li>具体工厂（ConcreteFactory）：主要是实现抽象工厂中的抽象方法，完成具体产品的创建。</li>
<li>抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能。</li>
<li>具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应。</li>
</ol>
<img src="/b321b3ea/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>如图写出的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> FactoryMethod;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractFactoryTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Product a;</span><br><span class="line">            AbstractFactory af;</span><br><span class="line">            af = (AbstractFactory) ReadXML1.getObject();</span><br><span class="line">            a = af.newProduct();</span><br><span class="line">            a.show();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象产品：提供了产品的接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体产品1：实现抽象产品中的抽象方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteProduct1</span> <span class="keyword">implements</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体产品1显示...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体产品2：实现抽象产品中的抽象方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteProduct2</span> <span class="keyword">implements</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体产品2显示...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象工厂：提供了厂品的生成方法</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product <span class="title">newProduct</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体工厂1：实现了厂品的生成方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteFactory1</span> <span class="keyword">implements</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product <span class="title">newProduct</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体工厂1生成--&gt;具体产品1...&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct1();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体工厂2：实现了厂品的生成方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteFactory2</span> <span class="keyword">implements</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product <span class="title">newProduct</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体工厂2生成--&gt;具体产品2...&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct2();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> FactoryMethod;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.*;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReadXML1</span> </span>&#123;</span><br><span class="line">    <span class="comment">//该方法用于从XML配置文件中提取具体类类名，并返回一个实例对象</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">getObject</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//创建文档对象</span></span><br><span class="line">            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();</span><br><span class="line">            DocumentBuilder builder = dFactory.newDocumentBuilder();</span><br><span class="line">            Document doc;</span><br><span class="line">            doc = builder.parse(<span class="keyword">new</span> File(<span class="string">&quot;src/FactoryMethod/config1.xml&quot;</span>));</span><br><span class="line">            <span class="comment">//获取包含类名的文本节点</span></span><br><span class="line">            NodeList nl = doc.getElementsByTagName(<span class="string">&quot;className&quot;</span>);</span><br><span class="line">            Node classNode = nl.item(<span class="number">0</span>).getFirstChild();</span><br><span class="line">            String cName = <span class="string">&quot;FactoryMethod.&quot;</span> + classNode.getNodeValue();</span><br><span class="line">            <span class="comment">//System.out.println(&quot;新类名：&quot;+cName);</span></span><br><span class="line">            <span class="comment">//通过类名生成实例对象并将其返回</span></span><br><span class="line">            Class&lt;?&gt; c = Class.forName(cName);</span><br><span class="line">            Object obj = c.newInstance();</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">className</span>&gt;</span>ConcreteFactory1<span class="tag">&lt;/<span class="name">className</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体工厂1生成--&gt;具体产品1...</span><br><span class="line">具体产品1显示...</span><br></pre></td></tr></table></figure>

<p>如果将 XML 配置文件中的 ConcreteFactory1 改为 ConcreteFactory2，则程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体工厂2生成--&gt;具体产品2...</span><br><span class="line">具体产品2显示...</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="工厂模式的应用实例"><a href="#工厂模式的应用实例" class="headerlink" title="工厂模式的应用实例"></a>工厂模式的应用实例</h3><h4 id="【例1】用工厂方法模式设计畜牧场"><a href="#【例1】用工厂方法模式设计畜牧场" class="headerlink" title="【例1】用工厂方法模式设计畜牧场"></a>【例1】用工厂方法模式设计畜牧场</h4><p>分析：有很多种类的畜牧场，如养马场用于养马，养牛场用于养牛，所以该实例用工厂方法模式比较适合。</p>
<p>对养马场和养牛场等具体工厂类，只要定义一个生成动物的方法 newAnimal() 即可。由于要显示马类和牛类等具体产品类的图像，所以它们的构造函数中用到了 JPanel、JLabd 和 ImageIcon 等组件，并定义一个 show() 方法来显示它们。</p>
<p>客户端程序通过对象生成器类 ReadXML2 读取 XML 配置文件中的数据来决定养马还是养牛。其结构图如图所示。</p>
<img src="/b321b3ea/2.gif" class>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> FactoryMethod;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AnimalFarmTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Animal a;</span><br><span class="line">            AnimalFarm af;</span><br><span class="line">            af = (AnimalFarm) ReadXML2.getObject();</span><br><span class="line">            a = af.newAnimal();</span><br><span class="line">            a.show();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象产品：动物类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体产品：马类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Horse</span> <span class="keyword">implements</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    JScrollPane sp;</span><br><span class="line">    JFrame jf = <span class="keyword">new</span> JFrame(<span class="string">&quot;工厂方法模式测试&quot;</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Horse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Container contentPane = jf.getContentPane();</span><br><span class="line">        JPanel p1 = <span class="keyword">new</span> JPanel();</span><br><span class="line">        p1.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        p1.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;动物：马&quot;</span>));</span><br><span class="line">        sp = <span class="keyword">new</span> JScrollPane(p1);</span><br><span class="line">        contentPane.add(sp, BorderLayout.CENTER);</span><br><span class="line">        JLabel l1 = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/A_Horse.jpg&quot;</span>));</span><br><span class="line">        p1.add(l1);</span><br><span class="line">        jf.pack();</span><br><span class="line">        jf.setVisible(<span class="keyword">false</span>);</span><br><span class="line">        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);    <span class="comment">//用户点击窗口关闭</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        jf.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体产品：牛类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cattle</span> <span class="keyword">implements</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    JScrollPane sp;</span><br><span class="line">    JFrame jf = <span class="keyword">new</span> JFrame(<span class="string">&quot;工厂方法模式测试&quot;</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Cattle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Container contentPane = jf.getContentPane();</span><br><span class="line">        JPanel p1 = <span class="keyword">new</span> JPanel();</span><br><span class="line">        p1.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        p1.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;动物：牛&quot;</span>));</span><br><span class="line">        sp = <span class="keyword">new</span> JScrollPane(p1);</span><br><span class="line">        contentPane.add(sp, BorderLayout.CENTER);</span><br><span class="line">        JLabel l1 = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/A_Cattle.jpg&quot;</span>));</span><br><span class="line">        p1.add(l1);</span><br><span class="line">        jf.pack();</span><br><span class="line">        jf.setVisible(<span class="keyword">false</span>);</span><br><span class="line">        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);    <span class="comment">//用户点击窗口关闭</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        jf.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象工厂：畜牧场</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">AnimalFarm</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Animal <span class="title">newAnimal</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体工厂：养马场</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HorseFarm</span> <span class="keyword">implements</span> <span class="title">AnimalFarm</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Animal <span class="title">newAnimal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;新马出生！&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Horse();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体工厂：养牛场</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CattleFarm</span> <span class="keyword">implements</span> <span class="title">AnimalFarm</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Animal <span class="title">newAnimal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;新牛出生！&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Cattle();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> FactoryMethod;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.*;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReadXML2</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">getObject</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();</span><br><span class="line">            DocumentBuilder builder = dFactory.newDocumentBuilder();</span><br><span class="line">            Document doc;</span><br><span class="line">            doc = builder.parse(<span class="keyword">new</span> File(<span class="string">&quot;src/FactoryMethod/config2.xml&quot;</span>));</span><br><span class="line">            NodeList nl = doc.getElementsByTagName(<span class="string">&quot;className&quot;</span>);</span><br><span class="line">            Node classNode = nl.item(<span class="number">0</span>).getFirstChild();</span><br><span class="line">            String cName = <span class="string">&quot;FactoryMethod.&quot;</span> + classNode.getNodeValue();</span><br><span class="line">            System.out.println(<span class="string">&quot;新类名：&quot;</span> + cName);</span><br><span class="line">            Class&lt;?&gt; c = Class.forName(cName);</span><br><span class="line">            Object obj = c.newInstance();</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">className</span>&gt;</span>HorseFarm<span class="tag">&lt;/<span class="name">className</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>程序的运行结果如图所示：</p>
<img src="/b321b3ea/3.gif" class>

<p>注意：当需要生成的产品不多且不会增加，一个具体工厂类就可以完成任务时，可删除抽象工厂类。这时工厂方法模式将退化到简单工厂模式。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1348.html">http://c.biancheng.net/view/1348.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-创建型模式-抽象工厂模式</title>
    <url>/60055911.html</url>
    <content><![CDATA[<h3 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h3><p>前面介绍的工厂方法模式中考虑的是一类产品的生产，如畜牧场只养动物、电视机厂只生产电视机、计算机软件学院只培养计算机软件专业的学生等。</p>
<p>同种类称为同等级，也就是说：工厂方法模式只考虑生产同等级的产品，但是在现实生活中许多工厂是综合型的工厂，能生产多等级（种类） 的产品，如农场里既养动物又种植物，电器厂既生产电视机又生产洗衣机或空调，大学既有软件专业又有生物专业等。</p>
<p>这次要介绍的抽象工厂模式将考虑多等级产品的生产，将同一个具体工厂所生产的位于不同等级的一组产品称为一个产品族，下图所示的是海尔工厂和 TCL 工厂所生产的电视机与空调对应的关系图。</p>
<img src="/60055911/1.gif" class>

<hr>
<span id="more"></span>

<h3 id="抽象工厂模式的定义与特点"><a href="#抽象工厂模式的定义与特点" class="headerlink" title="抽象工厂模式的定义与特点"></a>抽象工厂模式的定义与特点</h3><p><strong>抽象工厂（AbstractFactory）模式的定义：</strong>是一种为访问类提供一个创建一组相关或相互依赖对象的接口，且访问类无须指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。</p>
<p>抽象工厂模式是工厂方法模式的升级版本，工厂方法模式只生产一个等级的产品，而抽象工厂模式可生产多个等级的产品。</p>
<p>使用抽象工厂模式一般要满足以下条件：</p>
<ul>
<li>系统中有多个产品族，每个具体工厂创建同一族但属于不同等级结构的产品。</li>
<li>系统一次只可能消费其中某一族产品，即同族的产品一起使用。</li>
</ul>
<p>抽象工厂模式除了具有工厂方法模式的优点外，其他主要优点如下：</p>
<ul>
<li>可以在类的内部对产品族中相关联的多等级产品共同管理，而不必专门引入多个新的类来进行管理。</li>
<li>当需要产品族时，抽象工厂可以保证客户端始终只使用同一个产品的产品组。</li>
<li>抽象工厂增强了程序的可扩展性，当增加一个新的产品族时，不需要修改原代码，满足开闭原则。</li>
</ul>
<p>抽象工厂模式的缺点是：</p>
<ul>
<li>当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改。增加了系统的抽象性和理解难度。</li>
</ul>
<hr>
<h3 id="抽象工厂模式的结构与实现"><a href="#抽象工厂模式的结构与实现" class="headerlink" title="抽象工厂模式的结构与实现"></a>抽象工厂模式的结构与实现</h3><p>抽象工厂模式同工厂方法模式一样，也是由抽象工厂、具体工厂、抽象产品和具体产品等 4 个要素构成，但抽象工厂中方法个数不同，抽象产品的个数也不同。现在我们来分析其基本结构和实现方法。</p>
<h4 id="抽象工厂模式的结构"><a href="#抽象工厂模式的结构" class="headerlink" title="抽象工厂模式的结构"></a>抽象工厂模式的结构</h4><p>抽象工厂模式的主要角色如下：</p>
<ol>
<li>抽象工厂（Abstract Factory）：提供了创建产品的接口，它包含多个创建产品的方法 newProduct()，可以创建多个不同等级的产品。</li>
<li>具体工厂（Concrete Factory）：主要是实现抽象工厂中的多个抽象方法，完成具体产品的创建。</li>
<li>抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能，抽象工厂模式有多个抽象产品。</li>
<li>具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间是多对一的关系。</li>
</ol>
<img src="/60055911/2.gif" class>

<h4 id="抽象工厂模式的实现"><a href="#抽象工厂模式的实现" class="headerlink" title="抽象工厂模式的实现"></a>抽象工厂模式的实现</h4><p>从图中可以看出抽象工厂模式的结构同工厂方法模式的结构相似，不同的是其产品的种类不止一个，所以创建产品的方法也不止一个。下面给出抽象工厂和具体工厂的代码。</p>
<p>(1) 抽象工厂：提供了产品的生成方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product1 <span class="title">newProduct1</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product2 <span class="title">newProduct2</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>(2) 具体工厂：实现了产品的生成方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteFactory1</span> <span class="keyword">implements</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product1 <span class="title">newProduct1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体工厂 1 生成--&gt;具体产品 11...&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct11();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product2 <span class="title">newProduct2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体工厂 1 生成--&gt;具体产品 21...&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct21();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="抽象工厂模式的应用实例"><a href="#抽象工厂模式的应用实例" class="headerlink" title="抽象工厂模式的应用实例"></a>抽象工厂模式的应用实例</h3><h4 id="【例1】用抽象工厂模式设计农场类"><a href="#【例1】用抽象工厂模式设计农场类" class="headerlink" title="【例1】用抽象工厂模式设计农场类"></a>【例1】用抽象工厂模式设计农场类</h4><p>分析：农场中除了像畜牧场一样可以养动物，还可以培养植物，如养马、养牛、种菜、种水果等，所以本实例比前面介绍的畜牧场类复杂，必须用抽象工厂模式来实现。</p>
<p>本例用抽象工厂模式来设计两个农场，一个是韶关农场用于养牛和种菜，一个是上饶农场用于养马和种水果，可以在以上两个农场中定义一个生成动物的方法 newAnimal() 和一个培养植物的方法 newPlant()。</p>
<p>对马类、牛类、蔬菜类和水果类等具体产品类，由于要显示它们的图像（点此下载图片），所以它们的构造函数中用到了 JPanel、JLabel 和 ImageIcon 等组件，并定义一个 show() 方法来显示它们。</p>
<p>客户端程序通过对象生成器类 ReadXML 读取 XML 配置文件中的数据来决定养什么动物和培养什么植物。</p>
<img src="/60055911/3.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> AbstractFactory;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FarmTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Farm f;</span><br><span class="line">            Animal a;</span><br><span class="line">            Plant p;</span><br><span class="line">            f = (Farm) ReadXML.getObject();</span><br><span class="line">            a = f.newAnimal();</span><br><span class="line">            p = f.newPlant();</span><br><span class="line">            a.show();</span><br><span class="line">            p.show();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象产品：动物类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体产品：马类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Horse</span> <span class="keyword">implements</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    JScrollPane sp;</span><br><span class="line">    JFrame jf = <span class="keyword">new</span> JFrame(<span class="string">&quot;抽象工厂模式测试&quot;</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Horse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Container contentPane = jf.getContentPane();</span><br><span class="line">        JPanel p1 = <span class="keyword">new</span> JPanel();</span><br><span class="line">        p1.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        p1.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;动物：马&quot;</span>));</span><br><span class="line">        sp = <span class="keyword">new</span> JScrollPane(p1);</span><br><span class="line">        contentPane.add(sp, BorderLayout.CENTER);</span><br><span class="line">        JLabel l1 = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/A_Horse.jpg&quot;</span>));</span><br><span class="line">        p1.add(l1);</span><br><span class="line">        jf.pack();</span><br><span class="line">        jf.setVisible(<span class="keyword">false</span>);</span><br><span class="line">        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);<span class="comment">//用户点击窗口关闭</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        jf.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体产品：牛类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cattle</span> <span class="keyword">implements</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    JScrollPane sp;</span><br><span class="line">    JFrame jf = <span class="keyword">new</span> JFrame(<span class="string">&quot;抽象工厂模式测试&quot;</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Cattle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Container contentPane = jf.getContentPane();</span><br><span class="line">        JPanel p1 = <span class="keyword">new</span> JPanel();</span><br><span class="line">        p1.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        p1.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;动物：牛&quot;</span>));</span><br><span class="line">        sp = <span class="keyword">new</span> JScrollPane(p1);</span><br><span class="line">        contentPane.add(sp, BorderLayout.CENTER);</span><br><span class="line">        JLabel l1 = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/A_Cattle.jpg&quot;</span>));</span><br><span class="line">        p1.add(l1);</span><br><span class="line">        jf.pack();</span><br><span class="line">        jf.setVisible(<span class="keyword">false</span>);</span><br><span class="line">        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);<span class="comment">//用户点击窗口关闭</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        jf.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象产品：植物类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Plant</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体产品：水果类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Fruitage</span> <span class="keyword">implements</span> <span class="title">Plant</span> </span>&#123;</span><br><span class="line">    JScrollPane sp;</span><br><span class="line">    JFrame jf = <span class="keyword">new</span> JFrame(<span class="string">&quot;抽象工厂模式测试&quot;</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Fruitage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Container contentPane = jf.getContentPane();</span><br><span class="line">        JPanel p1 = <span class="keyword">new</span> JPanel();</span><br><span class="line">        p1.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        p1.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;植物：水果&quot;</span>));</span><br><span class="line">        sp = <span class="keyword">new</span> JScrollPane(p1);</span><br><span class="line">        contentPane.add(sp, BorderLayout.CENTER);</span><br><span class="line">        JLabel l1 = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/P_Fruitage.jpg&quot;</span>));</span><br><span class="line">        p1.add(l1);</span><br><span class="line">        jf.pack();</span><br><span class="line">        jf.setVisible(<span class="keyword">false</span>);</span><br><span class="line">        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);<span class="comment">//用户点击窗口关闭</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        jf.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体产品：蔬菜类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vegetables</span> <span class="keyword">implements</span> <span class="title">Plant</span> </span>&#123;</span><br><span class="line">    JScrollPane sp;</span><br><span class="line">    JFrame jf = <span class="keyword">new</span> JFrame(<span class="string">&quot;抽象工厂模式测试&quot;</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Vegetables</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Container contentPane = jf.getContentPane();</span><br><span class="line">        JPanel p1 = <span class="keyword">new</span> JPanel();</span><br><span class="line">        p1.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        p1.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;植物：蔬菜&quot;</span>));</span><br><span class="line">        sp = <span class="keyword">new</span> JScrollPane(p1);</span><br><span class="line">        contentPane.add(sp, BorderLayout.CENTER);</span><br><span class="line">        JLabel l1 = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/P_Vegetables.jpg&quot;</span>));</span><br><span class="line">        p1.add(l1);</span><br><span class="line">        jf.pack();</span><br><span class="line">        jf.setVisible(<span class="keyword">false</span>);</span><br><span class="line">        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);<span class="comment">//用户点击窗口关闭</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        jf.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象工厂：农场类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Farm</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Animal <span class="title">newAnimal</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Plant <span class="title">newPlant</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体工厂：韶关农场类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SGfarm</span> <span class="keyword">implements</span> <span class="title">Farm</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Animal <span class="title">newAnimal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;新牛出生！&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Cattle();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Plant <span class="title">newPlant</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;蔬菜长成！&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Vegetables();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体工厂：上饶农场类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SRfarm</span> <span class="keyword">implements</span> <span class="title">Farm</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Animal <span class="title">newAnimal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;新马出生！&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Horse();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Plant <span class="title">newPlant</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;水果长成！&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Fruitage();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> AbstractFactory;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.*;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReadXML</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">getObject</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();</span><br><span class="line">            DocumentBuilder builder = dFactory.newDocumentBuilder();</span><br><span class="line">            Document doc;</span><br><span class="line">            doc = builder.parse(<span class="keyword">new</span> File(<span class="string">&quot;src/AbstractFactory/config.xml&quot;</span>));</span><br><span class="line">            NodeList nl = doc.getElementsByTagName(<span class="string">&quot;className&quot;</span>);</span><br><span class="line">            Node classNode = nl.item(<span class="number">0</span>).getFirstChild();</span><br><span class="line">            String cName = <span class="string">&quot;AbstractFactory.&quot;</span> + classNode.getNodeValue();</span><br><span class="line">            System.out.println(<span class="string">&quot;新类名：&quot;</span> + cName);</span><br><span class="line">            Class&lt;?&gt; c = Class.forName(cName);</span><br><span class="line">            Object obj = c.newInstance();</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">className</span>&gt;</span>SGfarm<span class="tag">&lt;/<span class="name">className</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/60055911/4.jpg" class>

<hr>
<h3 id="抽象工厂模式的应用场景"><a href="#抽象工厂模式的应用场景" class="headerlink" title="抽象工厂模式的应用场景"></a>抽象工厂模式的应用场景</h3><p>抽象工厂模式最早的应用是用于创建属于不同操作系统的视窗构件。如 Java 的 AWT 中的 Button 和 Text 等构件在 Windows 和 UNIX 中的本地实现是不同的。</p>
<p>抽象工厂模式通常适用于以下场景：</p>
<ol>
<li>当需要创建的对象是一系列相互关联或相互依赖的产品族时，如电器工厂中的电视机、洗衣机、空调等。</li>
<li>系统中有多个产品族，但每次只使用其中的某一族产品。如有人只喜欢穿某一个品牌的衣服和鞋。</li>
<li>系统中提供了产品的类库，且所有产品的接口相同，客户端不依赖产品实例的创建细节和内部结构。</li>
</ol>
<hr>
<h3 id="抽象工厂模式的扩展"><a href="#抽象工厂模式的扩展" class="headerlink" title="抽象工厂模式的扩展"></a>抽象工厂模式的扩展</h3><p>抽象工厂模式的扩展有一定的“开闭原则”倾斜性：</p>
<ol>
<li>当增加一个新的产品族时只需增加一个新的具体工厂，不需要修改原代码，满足开闭原则。</li>
<li>当产品族中需要增加一个新种类的产品时，则所有的工厂类都需要进行修改，不满足开闭原则。</li>
</ol>
<p>另一方面，当系统中只存在一个等级结构的产品时，抽象工厂模式将退化到工厂方法模式。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1351.html">http://c.biancheng.net/view/1351.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-创建型模式-建造者模式</title>
    <url>/c636f347.html</url>
    <content><![CDATA[<h3 id="建造者模式（Bulider模式）"><a href="#建造者模式（Bulider模式）" class="headerlink" title="建造者模式（Bulider模式）"></a>建造者模式（Bulider模式）</h3><p>在软件开发过程中有时需要创建一个复杂的对象，这个复杂对象通常由多个子部件按一定的步骤组合而成。例如，计算机是由 CPU、主板、内存、硬盘、显卡、机箱、显示器、键盘、鼠标等部件组装而成的，采购员不可能自己去组装计算机，而是将计算机的配置要求告诉计算机销售公司，计算机销售公司安排技术人员去组装计算机，然后再交给要买计算机的采购员。</p>
<p>生活中这样的例子很多，如游戏中的不同角色，其性别、个性、能力、脸型、体型、服装、发型等特性都有所差异；还有汽车中的方向盘、发动机、车架、轮胎等部件也多种多样；每封电子邮件的发件人、收件人、主题、内容、附件等内容也各不相同。</p>
<p>以上所有这些产品都是由多个部件构成的，各个部件可以灵活选择，但其创建步骤都大同小异。这类产品的创建无法用前面介绍的工厂模式描述，只有建造者模式可以很好地描述该类产品的创建。</p>
<hr>
<span id="more"></span>

<h3 id="建造者模式的定义与特点"><a href="#建造者模式的定义与特点" class="headerlink" title="建造者模式的定义与特点"></a>建造者模式的定义与特点</h3><p><strong>建造者（Builder）模式的定义：</strong>指将一个复杂对象的构造与它的表示分离，使同样的构建过程可以创建不同的表示，这样的设计模式被称为建造者模式。它是将一个复杂的对象分解为多个简单的对象，然后一步一步构建而成。它将变与不变相分离，即产品的组成部分是不变的，但每一部分是可以灵活选择的。</p>
<p>该模式的主要优点如下：</p>
<ul>
<li>封装性好，构建和表示分离。</li>
<li>扩展性好，各个具体的建造者相互独立，有利于系统的解耦。</li>
<li>客户端不必知道产品内部组成的细节，建造者可以对创建过程逐步细化，而不对其它模块产生任何影响，便于控制细节风险。</li>
</ul>
<p>其缺点如下：</p>
<ul>
<li>产品的组成部分必须相同，这限制了其使用范围。</li>
<li>如果产品的内部变化复杂，如果产品内部发生变化，则建造者也要同步修改，后期维护成本较大。</li>
</ul>
<p>建造者（Builder）模式和工厂模式的关注点不同：建造者模式注重零部件的组装过程，而工厂方法模式更注重零部件的创建过程，但两者可以结合使用。</p>
<hr>
<h3 id="建造者模式的结构与实现"><a href="#建造者模式的结构与实现" class="headerlink" title="建造者模式的结构与实现"></a>建造者模式的结构与实现</h3><p>建造者（Builder）模式由产品、抽象建造者、具体建造者、指挥者等 4 个要素构成，现在我们来分析其基本结构和实现方法。</p>
<h4 id="建造者模式的结构"><a href="#建造者模式的结构" class="headerlink" title="建造者模式的结构"></a>建造者模式的结构</h4><p>建造者（Builder）模式的主要角色如下：</p>
<ol>
<li>产品角色（Product）：它是包含多个组成部件的复杂对象，由具体建造者来创建其各个零部件。</li>
<li>抽象建造者（Builder）：它是一个包含创建产品各个子部件的抽象方法的接口，通常还包含一个返回复杂产品的方法 getResult()。</li>
<li>具体建造者(Concrete Builder）：实现 Builder 接口，完成复杂产品的各个部件的具体创建方法。</li>
<li>指挥者（Director）：它调用建造者对象中的部件构造与装配方法完成复杂对象的创建，在指挥者中不涉及具体产品的信息。</li>
</ol>
<img src="/c636f347/1.gif" class>

<h4 id="建造者模式的实现"><a href="#建造者模式的实现" class="headerlink" title="建造者模式的实现"></a>建造者模式的实现</h4><p>上图给出了建造者（Builder）模式的主要结构，其相关类的代码如下：</p>
<p>(1) 产品角色：包含多个组成部件的复杂对象。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String partA;</span><br><span class="line">    <span class="keyword">private</span> String partB;</span><br><span class="line">    <span class="keyword">private</span> String partC;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPartA</span><span class="params">(String partA)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.partA = partA;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPartB</span><span class="params">(String partB)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.partB = partB;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPartC</span><span class="params">(String partC)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.partC = partC;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 显示产品的特性</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>(2) 抽象建造者：包含创建产品各个子部件的抽象方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建产品对象</span></span><br><span class="line">    <span class="keyword">protected</span> Product product = <span class="keyword">new</span> Product();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">buildPartA</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">buildPartB</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">buildPartC</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">// 返回产品对象</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product <span class="title">getResult</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> product;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>(3) 具体建造者：实现了抽象建造者接口。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteBuilder</span> <span class="keyword">extends</span> <span class="title">Builder</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildPartA</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setPartA(<span class="string">&quot;建造 PartA&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildPartB</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setPartB(<span class="string">&quot;建造 PartB&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildPartC</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setPartC(<span class="string">&quot;建造 PartC&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>(4) 指挥者：调用建造者中的方法完成复杂对象的创建。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Director</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Builder builder;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Director</span><span class="params">(Builder builder)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.builder = builder;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//产品构建与组装方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product <span class="title">construct</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        builder.buildPartA();</span><br><span class="line">        builder.buildPartB();</span><br><span class="line">        builder.buildPartC();</span><br><span class="line">        <span class="keyword">return</span> builder.getResult();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>(5) 客户类。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Builder builder = <span class="keyword">new</span> ConcreteBuilder();</span><br><span class="line">        Director director = <span class="keyword">new</span> Director(builder);</span><br><span class="line">        Product product = director.construct();</span><br><span class="line">        product.show();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="建造者模式的应用实例"><a href="#建造者模式的应用实例" class="headerlink" title="建造者模式的应用实例"></a>建造者模式的应用实例</h3><h4 id="【例1：隐藏内部参数】用建造者（Builder）模式描述客厅装修"><a href="#【例1：隐藏内部参数】用建造者（Builder）模式描述客厅装修" class="headerlink" title="【例1：隐藏内部参数】用建造者（Builder）模式描述客厅装修"></a>【例1：隐藏内部参数】用建造者（Builder）模式描述客厅装修</h4><p>分析：客厅装修是一个复杂的过程，它包含墙体的装修、电视机的选择、沙发的购买与布局等。客户把装修要求告诉项目经理，项目经理指挥装修工人一步步装修，最后完成整个客厅的装修与布局，所以本实例用建造者模式实现比较适合。</p>
<p>这里客厅是产品，包括墙、电视和沙发等组成部分。具体装修工人是具体建造者，他们负责装修与墙、电视和沙发的布局。项目经理是指挥者，他负责指挥装修工人进行装修。</p>
<p>另外，客厅类中提供了 show() 方法，可以将装修效果图显示出来。客户端程序通过对象生成器类 ReadXML 读取 XML 配置文件中的装修方案数据，调用项目经理进行装修。</p>
<img src="/c636f347/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> Builder;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ParlourDecorator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Decorator d;</span><br><span class="line">            d = (Decorator) ReadXML.getObject();</span><br><span class="line">            ProjectManager m = <span class="keyword">new</span> ProjectManager(d);</span><br><span class="line">            Parlour p = m.decorate();</span><br><span class="line">            p.show();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 产品：客厅</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parlour</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String wall;    <span class="comment">//墙</span></span><br><span class="line">    <span class="keyword">private</span> String TV;    <span class="comment">//电视</span></span><br><span class="line">    <span class="keyword">private</span> String sofa;    <span class="comment">//沙发 </span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setWall</span><span class="params">(String wall)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.wall = wall;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTV</span><span class="params">(String TV)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.TV = TV;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSofa</span><span class="params">(String sofa)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sofa = sofa;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        JFrame jf = <span class="keyword">new</span> JFrame(<span class="string">&quot;建造者模式测试&quot;</span>);</span><br><span class="line">        Container contentPane = jf.getContentPane();</span><br><span class="line">        JPanel p = <span class="keyword">new</span> JPanel();</span><br><span class="line">        JScrollPane sp = <span class="keyword">new</span> JScrollPane(p);</span><br><span class="line">        String parlour = wall + TV + sofa;</span><br><span class="line">        JLabel l = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/&quot;</span> + parlour + <span class="string">&quot;.jpg&quot;</span>));</span><br><span class="line">        p.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        p.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;客厅&quot;</span>));</span><br><span class="line">        p.add(l);</span><br><span class="line">        contentPane.add(sp, BorderLayout.CENTER);</span><br><span class="line">        jf.pack();</span><br><span class="line">        jf.setVisible(<span class="keyword">true</span>);</span><br><span class="line">        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象建造者：装修工人</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Decorator</span> </span>&#123;</span><br><span class="line">    <span class="comment">//创建产品对象</span></span><br><span class="line">    <span class="keyword">protected</span> Parlour product = <span class="keyword">new</span> Parlour();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">buildWall</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">buildTV</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">buildSofa</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">//返回产品对象</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Parlour <span class="title">getResult</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> product;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体建造者：具体装修工人1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteDecorator1</span> <span class="keyword">extends</span> <span class="title">Decorator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildWall</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setWall(<span class="string">&quot;w1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildTV</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setTV(<span class="string">&quot;TV1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildSofa</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setSofa(<span class="string">&quot;sf1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体建造者：具体装修工人2</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteDecorator2</span> <span class="keyword">extends</span> <span class="title">Decorator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildWall</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setWall(<span class="string">&quot;w2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildTV</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setTV(<span class="string">&quot;TV2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildSofa</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        product.setSofa(<span class="string">&quot;sf2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 指挥者：项目经理</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProjectManager</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Decorator builder;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProjectManager</span><span class="params">(Decorator builder)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.builder = builder;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//产品构建与组装方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Parlour <span class="title">decorate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        builder.buildWall();</span><br><span class="line">        builder.buildTV();</span><br><span class="line">        builder.buildSofa();</span><br><span class="line">        <span class="keyword">return</span> builder.getResult();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> Builder;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.Document;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.Node;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.NodeList;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.DocumentBuilder;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.DocumentBuilderFactory;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReadXML</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">getObject</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();</span><br><span class="line">            DocumentBuilder builder = dFactory.newDocumentBuilder();</span><br><span class="line">            Document doc;</span><br><span class="line">            doc = builder.parse(<span class="keyword">new</span> File(<span class="string">&quot;src/Builder/config.xml&quot;</span>));</span><br><span class="line">            NodeList nl = doc.getElementsByTagName(<span class="string">&quot;className&quot;</span>);</span><br><span class="line">            Node classNode = nl.item(<span class="number">0</span>).getFirstChild();</span><br><span class="line">            String cName = <span class="string">&quot;Builder.&quot;</span> + classNode.getNodeValue();</span><br><span class="line">            System.out.println(<span class="string">&quot;新类名：&quot;</span> + cName);</span><br><span class="line">            Class&lt;?&gt; c = Class.forName(cName);</span><br><span class="line">            Object obj = c.newInstance();</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示:</p>
<img src="/c636f347/3.jpg" class>

<p>这种builder是隐藏的，内部的参数不受我们控制。</p>
<h4 id="【例2：自定义内部参数】用建造者（Builder）模式组装电脑"><a href="#【例2：自定义内部参数】用建造者（Builder）模式组装电脑" class="headerlink" title="【例2：自定义内部参数】用建造者（Builder）模式组装电脑"></a>【例2：自定义内部参数】用建造者（Builder）模式组装电脑</h4><p>当一个类的构造函数参数个数超过4个，而且这些参数有些是可选的参数，考虑使用构造者模式。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Computer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String cpu;<span class="comment">//必须</span></span><br><span class="line">    <span class="keyword">private</span> String ram;<span class="comment">//必须</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> usbCount;<span class="comment">//可选</span></span><br><span class="line">    <span class="keyword">private</span> String keyboard;<span class="comment">//可选</span></span><br><span class="line">    <span class="keyword">private</span> String display;<span class="comment">//可选</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第一：折叠构造函数模式（telescoping constructor pattern），这个我们经常用，如下代码所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Computer</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Computer</span><span class="params">(String cpu, String ram)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(cpu, ram, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Computer</span><span class="params">(String cpu, String ram, <span class="keyword">int</span> usbCount)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(cpu, ram, usbCount, <span class="string">&quot;罗技键盘&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Computer</span><span class="params">(String cpu, String ram, <span class="keyword">int</span> usbCount, String keyboard)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(cpu, ram, usbCount, keyboard, <span class="string">&quot;三星显示器&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Computer</span><span class="params">(String cpu, String ram, <span class="keyword">int</span> usbCount, String keyboard, String display)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.cpu = cpu;</span><br><span class="line">        <span class="keyword">this</span>.ram = ram;</span><br><span class="line">        <span class="keyword">this</span>.usbCount = usbCount;</span><br><span class="line">        <span class="keyword">this</span>.keyboard = keyboard;</span><br><span class="line">        <span class="keyword">this</span>.display = display;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第二种：Javabean 模式，如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Computer</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getCpu</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> cpu;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCpu</span><span class="params">(String cpu)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.cpu = cpu;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getRam</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ram;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setRam</span><span class="params">(String ram)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.ram = ram;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getUsbCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> usbCount;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这两种方式的弊端如下：</p>
<p>第一种主要是使用及阅读不方便。你可以想象一下，当你要调用一个类的构造函数时，你首先要决定使用哪一个，然后里面又是一堆参数，如果这些参数的类型很多又都一样，你还要搞清楚这些参数的含义，很容易就传混了。</p>
<p>第二种方式在构建过程中对象的状态容易发生变化，造成错误。因为那个类中的属性是分步设置的，所以就容易出错。</p>
<p>为了解决这两个痛点，可以使用builder模式。</p>
<ol>
<li>在Computer 中创建一个静态内部类 Builder，然后将Computer 中的参数都复制到Builder类中。</li>
<li>在Computer中创建一个private的构造函数，参数为Builder类型</li>
<li>在Builder中创建一个public的构造函数，参数为Computer中必填的那些参数，cpu 和ram。</li>
<li>在Builder中创建设置函数，对Computer中那些可选参数进行赋值，返回值为Builder类型的实例</li>
<li>在Builder中创建一个build()方法，在其中构建Computer的实例并返回</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Computer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String cpu;<span class="comment">//必须</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String ram;<span class="comment">//必须</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> usbCount;<span class="comment">//可选</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String keyboard;<span class="comment">//可选</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String display;<span class="comment">//可选</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Computer</span><span class="params">(Builder builder)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.cpu = builder.cpu;</span><br><span class="line">        <span class="keyword">this</span>.ram = builder.ram;</span><br><span class="line">        <span class="keyword">this</span>.usbCount = builder.usbCount;</span><br><span class="line">        <span class="keyword">this</span>.keyboard = builder.keyboard;</span><br><span class="line">        <span class="keyword">this</span>.display = builder.display;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String cpu;<span class="comment">//必须</span></span><br><span class="line">        <span class="keyword">private</span> String ram;<span class="comment">//必须</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> usbCount;<span class="comment">//可选</span></span><br><span class="line">        <span class="keyword">private</span> String keyboard;<span class="comment">//可选</span></span><br><span class="line">        <span class="keyword">private</span> String display;<span class="comment">//可选</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Builder</span><span class="params">(String cup, String ram)</span></span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.cpu = cup;</span><br><span class="line">            <span class="keyword">this</span>.ram = ram;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">setUsbCount</span><span class="params">(<span class="keyword">int</span> usbCount)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.usbCount = usbCount;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">setKeyboard</span><span class="params">(String keyboard)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.keyboard = keyboard;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">setDisplay</span><span class="params">(String display)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.display = display;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;        </span><br><span class="line">        <span class="function"><span class="keyword">public</span> Computer <span class="title">build</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Computer(<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 省略getter方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用的时候，在客户端使用链式调用，一步一步的把对象构建出来。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Computer computer=<span class="keyword">new</span> Computer.Builder(<span class="string">&quot;因特尔&quot;</span>,<span class="string">&quot;三星&quot;</span>)</span><br><span class="line">                .setDisplay(<span class="string">&quot;三星24寸&quot;</span>)</span><br><span class="line">                .setKeyboard(<span class="string">&quot;罗技&quot;</span>)</span><br><span class="line">                .setUsbCount(<span class="number">2</span>)</span><br><span class="line">                .build();</span><br></pre></td></tr></table></figure>

<p>建造者模式是一个非常实用而常见的创建类型的模式（creational design pattern)，在Android中例如图片处理框架Glide，网络请求框架Retrofit等都使用了此模式。</p>
<p>在上面这个常用的建造者模式变体中，4个角色表示如下：</p>
<ul>
<li>Product: 最终要生成的对象，例如 Computer实例。</li>
<li>Builder： 构建者的抽象基类（有时会使用接口代替）。其定义了构建Product的抽象步骤，其实体类需要实现这些步骤。其会包含一个用来返回最终产品的方法Product getProduct()。</li>
<li>ConcreteBuilder: Builder的实现类。</li>
<li>Director: 决定如何构建最终产品的算法. 其会包含一个负责组装的方法void Construct(Builder builder)， 在这个方法中通过调用builder的方法，就可以设置builder，等设置完成后，就可以通过builder的 getProduct() 方法获得最终的产品。</li>
</ul>
<p>当然了，我们也可以用<strong>例1</strong>那种传统方式来实现：</p>
<p>第一步：我们的目标Computer类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Computer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String cpu;<span class="comment">//必须</span></span><br><span class="line">    <span class="keyword">private</span> String ram;<span class="comment">//必须</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> usbCount;<span class="comment">//可选</span></span><br><span class="line">    <span class="keyword">private</span> String keyboard;<span class="comment">//可选</span></span><br><span class="line">    <span class="keyword">private</span> String display;<span class="comment">//可选</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Computer</span><span class="params">(String cpu, String ram)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.cpu = cpu;</span><br><span class="line">        <span class="keyword">this</span>.ram = ram;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUsbCount</span><span class="params">(<span class="keyword">int</span> usbCount)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.usbCount = usbCount;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setKeyboard</span><span class="params">(String keyboard)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.keyboard = keyboard;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDisplay</span><span class="params">(String display)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.display = display;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Computer&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;cpu=&#x27;&quot;</span> + cpu + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, ram=&#x27;&quot;</span> + ram + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, usbCount=&quot;</span> + usbCount +</span><br><span class="line">                <span class="string">&quot;, keyboard=&#x27;&quot;</span> + keyboard + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, display=&#x27;&quot;</span> + display + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第二步：抽象构建者类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ComputerBuilder</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">setUsbCount</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">setKeyboard</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">setDisplay</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> Computer <span class="title">getComputer</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第三步：实体构建者类，我们可以根据要构建的产品种类产生多了实体构建者类，这里我们需要构建两种品牌的电脑，苹果电脑和联想电脑，所以我们生成了两个实体构建者类。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MacComputerBuilder</span> <span class="keyword">extends</span> <span class="title">ComputerBuilder</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Computer computer;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MacComputerBuilder</span><span class="params">(String cpu, String ram)</span> </span>&#123;</span><br><span class="line">        computer = <span class="keyword">new</span> Computer(cpu, ram);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUsbCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        computer.setUsbCount(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setKeyboard</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        computer.setKeyboard(<span class="string">&quot;苹果键盘&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDisplay</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        computer.setDisplay(<span class="string">&quot;苹果显示器&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Computer <span class="title">getComputer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> computer;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LenovoComputerBuilder</span> <span class="keyword">extends</span> <span class="title">ComputerBuilder</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Computer computer;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LenovoComputerBuilder</span><span class="params">(String cpu, String ram)</span> </span>&#123;</span><br><span class="line">        computer=<span class="keyword">new</span> Computer(cpu,ram);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUsbCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        computer.setUsbCount(<span class="number">4</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setKeyboard</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        computer.setKeyboard(<span class="string">&quot;联想键盘&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDisplay</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        computer.setDisplay(<span class="string">&quot;联想显示器&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Computer <span class="title">getComputer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> computer;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第四步：指导者类（Director）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ComputerDirector</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">makeComputer</span><span class="params">(ComputerBuilder builder)</span></span>&#123;</span><br><span class="line">        builder.setUsbCount();</span><br><span class="line">        builder.setDisplay();</span><br><span class="line">        builder.setKeyboard();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用的时候，首先生成一个director (1)，然后生成一个目标builder (2)，接着使用director组装builder (3),组装完毕后使用builder创建产品实例 (4)。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    ComputerDirector director=<span class="keyword">new</span> ComputerDirector();<span class="comment">//1</span></span><br><span class="line">    ComputerBuilder builder=<span class="keyword">new</span> MacComputerBuilder(<span class="string">&quot;I5处理器&quot;</span>,<span class="string">&quot;三星125&quot;</span>);<span class="comment">//2</span></span><br><span class="line">    director.makeComputer(builder);<span class="comment">//3</span></span><br><span class="line">    Computer macComputer=builder.getComputer();<span class="comment">//4</span></span><br><span class="line">    System.out.println(<span class="string">&quot;mac computer:&quot;</span>+macComputer.toString());</span><br><span class="line"></span><br><span class="line">    ComputerBuilder lenovoBuilder=<span class="keyword">new</span> LenovoComputerBuilder(<span class="string">&quot;I7处理器&quot;</span>,<span class="string">&quot;海力士222&quot;</span>);</span><br><span class="line">    director.makeComputer(lenovoBuilder);</span><br><span class="line">    Computer lenovoComputer=lenovoBuilder.getComputer();</span><br><span class="line">    System.out.println(<span class="string">&quot;lenovo computer:&quot;</span>+lenovoComputer.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，例2最开始的使用方式是传统builder模式的变种， 首先其省略了director 这个角色，将构建算法交给了client端，其次将 builder 写到了要构建的产品类里面，最后采用了链式调用。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1354.html">http://c.biancheng.net/view/1354.html</a><br><a href="https://zhuanlan.zhihu.com/p/58093669">https://zhuanlan.zhihu.com/p/58093669</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-结构型模式-代理模式</title>
    <url>/c126f7f3.html</url>
    <content><![CDATA[<h3 id="代理模式（代理设计模式）"><a href="#代理模式（代理设计模式）" class="headerlink" title="代理模式（代理设计模式）"></a>代理模式（代理设计模式）</h3><p>在有些情况下，一个客户不能或者不想直接访问另一个对象，这时需要找一个中介帮忙完成某项任务，这个中介就是代理对象。例如，购买火车票不一定要去火车站买，可以通过 12306 网站或者去火车票代售点买。又如找女朋友、找保姆、找工作等都可以通过找中介完成。</p>
<p>在软件设计中，使用代理模式的例子也很多，例如，要访问的远程对象比较大（如视频或大图像等），其下载要花很多时间。还有因为安全原因需要屏蔽客户端直接访问真实对象，如某单位的内部数据库等。</p>
<hr>
<span id="more"></span>

<h3 id="代理模式的定义与特点"><a href="#代理模式的定义与特点" class="headerlink" title="代理模式的定义与特点"></a>代理模式的定义与特点</h3><p><strong>代理模式的定义：</strong>由于某些原因需要给某对象提供一个代理以控制对该对象的访问。这时，访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。</p>
<p>代理模式的主要优点有：</p>
<ul>
<li>代理模式在客户端与目标对象之间起到一个中介作用和保护目标对象的作用</li>
<li>代理对象可以扩展目标对象的功能</li>
<li>代理模式能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性</li>
</ul>
<p>其主要缺点是：</p>
<ul>
<li>代理模式会造成系统设计中类的数量增加</li>
<li>在客户端和目标对象之间增加一个代理对象，会造成请求处理速度变慢</li>
<li>增加了系统的复杂度</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">那么如何解决以上提到的缺点呢？答案是可以使用动态代理方式</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="代理模式的结构与实现"><a href="#代理模式的结构与实现" class="headerlink" title="代理模式的结构与实现"></a>代理模式的结构与实现</h3><p>代理模式的结构比较简单，主要是通过定义一个继承抽象主题的代理来包含真实主题，从而实现对真实主题的访问，下面来分析其基本结构和实现方法。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>代理模式的主要角色如下：</p>
<ol>
<li>抽象主题（Subject）类：通过接口或抽象类声明真实主题和代理对象实现的业务方法。</li>
<li>真实主题（Real Subject）类：实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象。</li>
<li>代理（Proxy）类：提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能。</li>
</ol>
<img src="/c126f7f3/1.gif" class>

<p>在代码中，一般代理会被理解为代码增强，实际上就是在原代码逻辑前后增加一些代码逻辑，而使调用者无感知。</p>
<p>根据代理的创建时期，代理模式分为静态代理和动态代理。</p>
<ul>
<li>静态：由程序员创建代理类或特定工具自动生成源代码再对其编译，在程序运行前代理类的 .class 文件就已经存在了。</li>
<li>动态：在程序运行时，运用反射机制动态创建而成</li>
</ul>
<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>代理模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> proxy;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProxyTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Proxy proxy = <span class="keyword">new</span> Proxy();</span><br><span class="line">        proxy.Request();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象主题</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Subject</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Request</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 真实主题</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RealSubject</span> <span class="keyword">implements</span> <span class="title">Subject</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Request</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;访问真实主题方法...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 代理</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Proxy</span> <span class="keyword">implements</span> <span class="title">Subject</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> RealSubject realSubject;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Request</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (realSubject == <span class="keyword">null</span>) &#123;</span><br><span class="line">            realSubject = <span class="keyword">new</span> RealSubject();</span><br><span class="line">        &#125;</span><br><span class="line">        preRequest();</span><br><span class="line">        realSubject.Request();</span><br><span class="line">        postRequest();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preRequest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;访问真实主题之前的预处理。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postRequest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;访问真实主题之后的后续处理。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行的结果如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">访问真实主题之前的预处理。</span><br><span class="line">访问真实主题方法...</span><br><span class="line">访问真实主题之后的后续处理。</span><br></pre></td></tr></table></figure>

<h3 id="代理模式的应用实例"><a href="#代理模式的应用实例" class="headerlink" title="代理模式的应用实例"></a>代理模式的应用实例</h3><h4 id="【例1】韶关“天街e角”公司是一家婺源特产公司的代理公司，用代理模式实现。"><a href="#【例1】韶关“天街e角”公司是一家婺源特产公司的代理公司，用代理模式实现。" class="headerlink" title="【例1】韶关“天街e角”公司是一家婺源特产公司的代理公司，用代理模式实现。"></a>【例1】韶关“天街e角”公司是一家婺源特产公司的代理公司，用代理模式实现。</h4><p>分析：本实例中的“婺源特产公司”经营许多婺源特产，它是真实主题，提供了显示特产的 display() 方法，可以用窗体程序实现。而韶关“天街e角”公司是婺源特产公司特产的代理，通过调用婺源特产公司的 display() 方法显示代理产品，当然它可以增加一些额外的处理，如包裝或加价等。客户可通过“天街e角”代理公司间接访问“婺源特产公司”的产品。</p>
<img src="/c126f7f3/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> proxy;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WySpecialtyProxy</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SgProxy proxy = <span class="keyword">new</span> SgProxy();</span><br><span class="line">        proxy.display();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象主题：特产</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Specialty</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 真实主题：婺源特产</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WySpecialty</span> <span class="keyword">extends</span> <span class="title">JFrame</span> <span class="keyword">implements</span> <span class="title">Specialty</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">WySpecialty</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;韶关代理婺源特产测试&quot;</span>);</span><br><span class="line">        <span class="keyword">this</span>.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        JLabel l1 = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/proxy/WuyuanSpecialty.jpg&quot;</span>));</span><br><span class="line">        <span class="keyword">this</span>.add(l1);</span><br><span class="line">        <span class="keyword">this</span>.pack();</span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 代理：韶关代理</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SgProxy</span> <span class="keyword">implements</span> <span class="title">Specialty</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> WySpecialty realSubject = <span class="keyword">new</span> WySpecialty();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        preRequest();</span><br><span class="line">        realSubject.display();</span><br><span class="line">        postRequest();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preRequest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;韶关代理婺源特产开始。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postRequest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;韶关代理婺源特产结束。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/c126f7f3/3.jpg" class>

<hr>
<h3 id="代理模式的应用场景"><a href="#代理模式的应用场景" class="headerlink" title="代理模式的应用场景"></a>代理模式的应用场景</h3><p>当无法或不想直接引用某个对象或访问某个对象存在困难时，可以通过代理对象来间接访问。使用代理模式主要有两个目的：一是保护目标对象，二是增强目标对象。</p>
<p>前面分析了代理模式的结构与特点，现在来分析以下的应用场景：</p>
<ul>
<li>远程代理，这种方式通常是为了隐藏目标对象存在于不同地址空间的事实，方便客户端访问。例如，用户申请某些网盘空间时，会在用户的文件系统中建立一个虚拟的硬盘，用户访问虚拟硬盘时实际访问的是网盘空间。</li>
<li>虚拟代理，这种方式通常用于要创建的目标对象开销很大时。例如，下载一幅很大的图像需要很长时间，因某种计算比较复杂而短时间无法完成，这时可以先用小比例的虚拟代理替换真实的对象，消除用户对服务器慢的感觉。</li>
<li>安全代理，这种方式通常用于控制不同种类客户对真实对象的访问权限。</li>
<li>智能指引，主要用于调用目标对象时，代理附加一些额外的处理功能。例如，增加计算真实对象的引用次数的功能，这样当该对象没有被引用时，就可以自动释放它。</li>
<li>延迟加载，指为了提高系统的性能，延迟对目标的加载。例如，Hibernate 中就存在属性的延迟加载和关联表的延时加载。</li>
</ul>
<hr>
<h3 id="代理模式的扩展"><a href="#代理模式的扩展" class="headerlink" title="代理模式的扩展"></a>代理模式的扩展</h3><p>在前面介绍的代理模式中，代理类中包含了对真实主题的引用，这种方式存在两个缺点。</p>
<ul>
<li>真实主题与代理主题一一对应，增加真实主题也要增加代理。</li>
<li>设计代理以前真实主题必须事先存在，不太灵活。采用动态代理模式可以解决以上问题，如 SpringAOP，其结构图如图所示。</li>
</ul>
<img src="/c126f7f3/4.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1359.html">http://c.biancheng.net/view/1359.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-结构型模式-结构型模式概述</title>
    <url>/a6277c23.html</url>
    <content><![CDATA[<h3 id="结构型模式概述"><a href="#结构型模式概述" class="headerlink" title="结构型模式概述"></a>结构型模式概述</h3><p>结构型模式描述如何将类或对象按某种布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者釆用组合或聚合来组合对象。</p>
<p>由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象结构型模式比类结构型模式具有更大的灵活性。</p>
<p>结构型模式分为以下 7 种：</p>
<ol>
<li><strong>代理（Proxy）模式：</strong>为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。</li>
<li><strong>适配器（Adapter）模式：</strong>将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。</li>
<li><strong>桥接（Bridge）模式：</strong>将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现的，从而降低了抽象和实现这两个可变维度的耦合度。</li>
<li><strong>装饰（Decorator）模式：</strong>动态地给对象增加一些职责，即增加其额外的功能。</li>
<li><strong>外观（Facade）模式：</strong>为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。</li>
<li><strong>享元（Flyweight）模式：</strong>运用共享技术来有效地支持大量细粒度对象的复用。</li>
<li><strong>组合（Composite）模式：</strong>将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。</li>
</ol>
<p>以上 7 种结构型模式，除了适配器模式分为类结构型模式和对象结构型模式两种，其他的全部属于对象结构型模式，之后的博客会分别、详细地介绍它们的特点、结构与应用。</p>
<span id="more"></span>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1357.html">http://c.biancheng.net/view/1357.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-结构型模式-适配器模式</title>
    <url>/557ee5c2.html</url>
    <content><![CDATA[<h3 id="适配器模式（Adapter模式）"><a href="#适配器模式（Adapter模式）" class="headerlink" title="适配器模式（Adapter模式）"></a>适配器模式（Adapter模式）</h3><p>在现实生活中，经常出现两个对象因接口不兼容而不能在一起工作的实例，这时需要第三者进行适配。例如，讲中文的人同讲英文的人对话时需要一个翻译，用直流电的笔记本电脑接交流电源时需要一个电源适配器，用计算机访问照相机的 SD 内存卡时需要一个读卡器等。</p>
<p>在软件设计中也可能出现：需要开发的具有某种业务功能的组件在现有的组件库中已经存在，但它们与当前系统的接口规范不兼容，如果重新开发这些组件成本又很高，这时用适配器模式能很好地解决这些问题。</p>
<hr>
<span id="more"></span>

<h3 id="模式的定义与特点"><a href="#模式的定义与特点" class="headerlink" title="模式的定义与特点"></a>模式的定义与特点</h3><p><strong>适配器模式（Adapter）的定义如下：</strong>将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。适配器模式分为类结构型模式和对象结构型模式两种，前者类之间的耦合度比后者高，且要求程序员了解现有组件库中的相关组件的内部结构，所以应用相对较少些。</p>
<p>该模式的主要优点如下:</p>
<ul>
<li>客户端通过适配器可以透明地调用目标接口。</li>
<li>复用了现存的类，程序员不需要修改原有代码而重用现有的适配者类。</li>
<li>将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题。</li>
<li>在很多业务场景中符合开闭原则。</li>
</ul>
<p>其缺点是：</p>
<ul>
<li>适配器编写过程需要结合业务场景全面考虑，可能会增加系统的复杂性。</li>
<li>增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱。</li>
</ul>
<hr>
<h3 id="模式的结构与实现"><a href="#模式的结构与实现" class="headerlink" title="模式的结构与实现"></a>模式的结构与实现</h3><p>类适配器模式可采用多重继承方式实现，如 C++ 可定义一个适配器类来同时继承当前系统的业务接口和现有组件库中已经存在的组件接口；Java 不支持多继承，但可以定义一个适配器类来实现当前系统的业务接口，同时又继承现有组件库中已经存在的组件。</p>
<p>对象适配器模式可釆用将现有组件库中已经实现的组件引入适配器类中，该类同时实现当前系统的业务接口。现在来介绍它们的基本结构。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>适配器模式（Adapter）包含以下主要角色：</p>
<ol>
<li>目标（Target）接口：当前系统业务所期待的接口，它可以是抽象类或接口。</li>
<li>适配者（Adaptee）类：它是被访问和适配的现存组件库中的组件接口。</li>
<li>适配器（Adapter）类：它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。</li>
</ol>
<p>类适配器模式的结构图如下：</p>
<img src="/557ee5c2/1.gif" class>

<p>对象适配器模式的结构图如下：</p>
<img src="/557ee5c2/2.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><ol>
<li>类适配器模式的代码如下：</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> adapter;</span><br><span class="line"><span class="comment">// 目标接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Target</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">request</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 适配者接口</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Adaptee</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">specificRequest</span><span class="params">()</span> </span>&#123;       </span><br><span class="line">        System.out.println(<span class="string">&quot;适配者中的业务代码被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 类适配器类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassAdapter</span> <span class="keyword">extends</span> <span class="title">Adaptee</span> <span class="keyword">implements</span> <span class="title">Target</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">request</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        specificRequest();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 客户端代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassAdapterTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;类适配器模式测试：&quot;</span>);</span><br><span class="line">        Target target = <span class="keyword">new</span> ClassAdapter();</span><br><span class="line">        target.request();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">类适配器模式测试：</span><br><span class="line">适配者中的业务代码被调用！</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>对象适配器模式的代码如下：</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> adapter;</span><br><span class="line"><span class="comment">// 对象适配器类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ObjectAdapter</span> <span class="keyword">implements</span> <span class="title">Target</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Adaptee adaptee;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ObjectAdapter</span><span class="params">(Adaptee adaptee)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.adaptee = adaptee;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">request</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        adaptee.specificRequest();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 客户端代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ObjectAdapterTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;对象适配器模式测试：&quot;</span>);</span><br><span class="line">        Adaptee adaptee = <span class="keyword">new</span> Adaptee();</span><br><span class="line">        Target target = <span class="keyword">new</span> ObjectAdapter(adaptee);</span><br><span class="line">        target.request();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>说明：对象适配器模式中的“目标接口”和“适配者类”的代码同类适配器模式一样，只要修改适配器类和客户端的代码即可。</p>
<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">对象适配器模式测试：</span><br><span class="line">适配者中的业务代码被调用！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】用适配器模式（Adapter）模拟新能源汽车的发动机。"><a href="#【例1】用适配器模式（Adapter）模拟新能源汽车的发动机。" class="headerlink" title="【例1】用适配器模式（Adapter）模拟新能源汽车的发动机。"></a>【例1】用适配器模式（Adapter）模拟新能源汽车的发动机。</h4><p>分析：新能源汽车的发动机有电能发动机（Electric Motor）和光能发动机（Optical Motor）等，各种发动机的驱动方法不同，例如，电能发动机的驱动方法 electricDrive() 是用电能驱动，而光能发动机的驱动方法 opticalDrive() 是用光能驱动，它们是适配器模式中被访问的适配者。</p>
<p>客户端希望用统一的发动机驱动方法 drive() 访问这两种发动机，所以必须定义一个统一的目标接口 Motor，然后再定义电能适配器（Electric Adapter）和光能适配器（Optical Adapter）去适配这两种发动机。</p>
<p>我们把客户端想访问的新能源发动机的适配器的名称放在 XML 配置文件中，客户端可以通过对象生成器类 ReadXML 去读取。这样，客户端就可以通过 Motor 接口随便使用任意一种新能源发动机去驱动汽车。</p>
<img src="/557ee5c2/3.gif" class>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> adapter;</span><br><span class="line"><span class="comment">// 目标：发动机</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Motor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drive</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 适配者1：电能发动机</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ElectricMotor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">electricDrive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;电能发动机驱动汽车！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 适配者2：光能发动机</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpticalMotor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">opticalDrive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;光能发动机驱动汽车！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 电能适配器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ElectricAdapter</span> <span class="keyword">implements</span> <span class="title">Motor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ElectricMotor emotor;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ElectricAdapter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        emotor = <span class="keyword">new</span> ElectricMotor();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        emotor.electricDrive();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 光能适配器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpticalAdapter</span> <span class="keyword">implements</span> <span class="title">Motor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> OpticalMotor omotor;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">OpticalAdapter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        omotor = <span class="keyword">new</span> OpticalMotor();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        omotor.opticalDrive();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 客户端代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MotorAdapterTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;适配器模式测试：&quot;</span>);</span><br><span class="line">        Motor motor = (Motor)ReadXML.getObject();</span><br><span class="line">        motor.drive();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> adapter;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.*;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReadXML</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">getObject</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();</span><br><span class="line">            DocumentBuilder builder = dFactory.newDocumentBuilder();</span><br><span class="line">            Document doc;                           </span><br><span class="line">            doc = builder.parse(<span class="keyword">new</span> File(<span class="string">&quot;src/adapter/config.xml&quot;</span>));</span><br><span class="line">            NodeList nl = doc.getElementsByTagName(<span class="string">&quot;className&quot;</span>);</span><br><span class="line">            Node classNode = nl.item(<span class="number">0</span>).getFirstChild();</span><br><span class="line">            String cName = <span class="string">&quot;adapter.&quot;</span>+classNode.getNodeValue();</span><br><span class="line">            Class&lt;?&gt; c = Class.forName(cName);</span><br><span class="line">                Object obj = c.newInstance();</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">className</span>&gt;</span>ElectricAdapter<span class="tag">&lt;/<span class="name">className</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">适配器模式测试：</span><br><span class="line">电能发动机驱动汽车！</span><br></pre></td></tr></table></figure>

<p>注意：如果将配置文件中的 ElectricAdapter 改为 OpticalAdapter，则运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">适配器模式测试：</span><br><span class="line">光能发动机驱动汽车！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>适配器模式（Adapter）通常适用于以下场景：</p>
<ul>
<li>以前开发的系统存在满足新系统功能需求的类，但其接口同新系统的接口不一致。</li>
<li>使用第三方提供的组件，但组件接口定义和自己要求的接口定义不同。</li>
</ul>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>适配器模式（Adapter）可扩展为双向适配器模式，双向适配器类既可以把适配者接口转换成目标接口，也可以把目标接口转换成适配者接口，其结构图如下：</p>
<img src="/557ee5c2/4.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> adapter;</span><br><span class="line"><span class="comment">// 目标接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">TwoWayTarget</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">request</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 适配者接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">TwoWayAdaptee</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">specificRequest</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 目标实现</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TargetRealize</span> <span class="keyword">implements</span> <span class="title">TwoWayTarget</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">request</span><span class="params">()</span> </span>&#123;       </span><br><span class="line">        System.out.println(<span class="string">&quot;目标代码被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 适配者实现</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdapteeRealize</span> <span class="keyword">implements</span> <span class="title">TwoWayAdaptee</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">specificRequest</span><span class="params">()</span> </span>&#123;       </span><br><span class="line">        System.out.println(<span class="string">&quot;适配者代码被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 双向适配器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoWayAdapter</span> <span class="keyword">implements</span> <span class="title">TwoWayTarget</span>,<span class="title">TwoWayAdaptee</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> TwoWayTarget target;</span><br><span class="line">    <span class="keyword">private</span> TwoWayAdaptee adaptee;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TwoWayAdapter</span><span class="params">(TwoWayTarget target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.target=target;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TwoWayAdapter</span><span class="params">(TwoWayAdaptee adaptee)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.adaptee=adaptee;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">request</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        adaptee.specificRequest();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">specificRequest</span><span class="params">()</span> </span>&#123;       </span><br><span class="line">        target.request();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 客户端代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TwoWayAdapterTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;目标通过双向适配器访问适配者：&quot;</span>);</span><br><span class="line">        TwoWayAdaptee adaptee=<span class="keyword">new</span> AdapteeRealize();</span><br><span class="line">        TwoWayTarget target=<span class="keyword">new</span> TwoWayAdapter(adaptee);</span><br><span class="line">        target.request();</span><br><span class="line">        System.out.println(<span class="string">&quot;-------------------&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;适配者通过双向适配器访问目标：&quot;</span>);</span><br><span class="line">        target=<span class="keyword">new</span> TargetRealize();</span><br><span class="line">        adaptee=<span class="keyword">new</span> TwoWayAdapter(target);</span><br><span class="line">        adaptee.specificRequest();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">目标通过双向适配器访问适配者：</span><br><span class="line">适配者代码被调用！</span><br><span class="line">-------------------</span><br><span class="line">适配者通过双向适配器访问目标：</span><br><span class="line">目标代码被调用！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1361.html">http://c.biancheng.net/view/1361.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-结构型模式-桥接模式</title>
    <url>/ec45913f.html</url>
    <content><![CDATA[<h3 id="桥接模式（Bridge模式）"><a href="#桥接模式（Bridge模式）" class="headerlink" title="桥接模式（Bridge模式）"></a>桥接模式（Bridge模式）</h3><p>在现实生活中，某些类具有两个或多个维度的变化，如图形既可按形状分，又可按颜色分。如何设计类似于 Photoshop 这样的软件，能画不同形状和不同颜色的图形呢？如果用继承方式，m 种形状和 n 种颜色的图形就有 m×n 种，不但对应的子类很多，而且扩展困难。</p>
<p>当然，这样的例子还有很多，如不同颜色和字体的文字、不同品牌和功率的汽车、不同性别和职业的男女、支持不同平台和不同文件格式的媒体播放器等。如果用桥接模式就能很好地解决这些问题。</p>
<hr>
<span id="more"></span>

<h3 id="桥接模式的定义与特点"><a href="#桥接模式的定义与特点" class="headerlink" title="桥接模式的定义与特点"></a>桥接模式的定义与特点</h3><p><strong>桥接（Bridge）模式的定义如下：</strong>将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。</p>
<p>通过上面的讲解，我们能很好的感觉到桥接模式遵循了里氏替换原则和依赖倒置原则，最终实现了开闭原则，对修改关闭，对扩展开放。这里将桥接模式的优缺点总结如下：</p>
<p>桥接（Bridge）模式的优点是：</p>
<ul>
<li>抽象与实现分离，扩展能力强</li>
<li>符合开闭原则</li>
<li>符合合成复用原则</li>
<li>其实现细节对客户透明</li>
</ul>
<p>缺点是：</p>
<ul>
<li>由于聚合关系建立在抽象层，要求开发者针对抽象化进行设计与编程，能正确地识别出系统中两个独立变化的维度，这增加了系统的理解与设计难度。</li>
</ul>
<hr>
<h3 id="桥接模式的结构与实现"><a href="#桥接模式的结构与实现" class="headerlink" title="桥接模式的结构与实现"></a>桥接模式的结构与实现</h3><p>可以将抽象化部分与实现化部分分开，取消二者的继承关系，改用组合关系。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>桥接（Bridge）模式包含以下主要角色：</p>
<ol>
<li>抽象化（Abstraction）角色：定义抽象类，并包含一个对实现化对象的引用。</li>
<li>扩展抽象化（Refined Abstraction）角色：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。</li>
<li>实现化（Implementor）角色：定义实现化角色的接口，供扩展抽象化角色调用。</li>
<li>具体实现化（Concrete Implementor）角色：给出实现化角色接口的具体实现。</li>
</ol>
<img src="/ec45913f/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>桥接模式的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> bridge;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BridgeTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Implementor imple = <span class="keyword">new</span> ConcreteImplementorA();</span><br><span class="line">        Abstraction abs = <span class="keyword">new</span> RefinedAbstraction(imple);</span><br><span class="line">        abs.Operation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 实现化角色</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Implementor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">OperationImpl</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体实现化角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteImplementorA</span> <span class="keyword">implements</span> <span class="title">Implementor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">OperationImpl</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体实现化(Concrete Implementor)角色被访问&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象化角色</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Abstraction</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> Implementor imple;</span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">Abstraction</span><span class="params">(Implementor imple)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.imple = imple;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">Operation</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 扩展抽象化角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RefinedAbstraction</span> <span class="keyword">extends</span> <span class="title">Abstraction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">RefinedAbstraction</span><span class="params">(Implementor imple)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(imple);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Operation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;扩展抽象化(Refined Abstraction)角色被访问&quot;</span>);</span><br><span class="line">        imple.OperationImpl();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">扩展抽象化(Refined Abstraction)角色被访问</span><br><span class="line">具体实现化(Concrete Implementor)角色被访问</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="桥接模式的应用实例"><a href="#桥接模式的应用实例" class="headerlink" title="桥接模式的应用实例"></a>桥接模式的应用实例</h3><h4 id="【例1】用桥接（Bridge）模式模拟女士皮包的选购。"><a href="#【例1】用桥接（Bridge）模式模拟女士皮包的选购。" class="headerlink" title="【例1】用桥接（Bridge）模式模拟女士皮包的选购。"></a>【例1】用桥接（Bridge）模式模拟女士皮包的选购。</h4><p>分析：女士皮包有很多种，可以按用途分、按皮质分、按品牌分、按颜色分、按大小分等，存在多个维度的变化，所以采用桥接模式来实现女士皮包的选购比较合适。</p>
<p>本实例按用途分可选钱包（Wallet）和挎包（HandBag），按颜色分可选黄色（Yellow）和红色（Red）。可以按两个维度定义为颜色类和包类。（点此下载本实例所要显示的包的图片）。</p>
<p>颜色类（Color）是一个维度，定义为实现化角色，它有两个具体实现化角色：黄色和红色，通过 getColor() 方法可以选择颜色；包类（Bag）是另一个维度，定义为抽象化角色，它有两个扩展抽象化角色：挎包和钱包，它包含了颜色类对象，通过 getName() 方法可以选择相关颜色的挎包和钱包。</p>
<p>客户类通过 ReadXML 类从 XML 配置文件中获取包信息，并把选到的产品通过窗体显示出现。</p>
<img src="/ec45913f/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> bridge;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.NodeList;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.DocumentBuilder;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.DocumentBuilderFactory;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BagManage</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Color color;</span><br><span class="line">        Bag bag;</span><br><span class="line">        color = (Color) ReadXML.getObject(<span class="string">&quot;color&quot;</span>);</span><br><span class="line">        bag = (Bag) ReadXML.getObject(<span class="string">&quot;bag&quot;</span>);</span><br><span class="line">        bag.setColor(color);</span><br><span class="line">        String name = bag.getName();</span><br><span class="line">        show(name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        JFrame jf = <span class="keyword">new</span> JFrame(<span class="string">&quot;桥接模式测试&quot;</span>);</span><br><span class="line">        Container contentPane = jf.getContentPane();</span><br><span class="line">        JPanel p = <span class="keyword">new</span> JPanel();</span><br><span class="line">        JLabel l = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/bridge/&quot;</span> + name + <span class="string">&quot;.jpg&quot;</span>));</span><br><span class="line">        p.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        p.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;女士皮包&quot;</span>));</span><br><span class="line">        p.add(l);</span><br><span class="line">        contentPane.add(p, BorderLayout.CENTER);</span><br><span class="line">        jf.pack();</span><br><span class="line">        jf.setVisible(<span class="keyword">true</span>);</span><br><span class="line">        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 实现化角色：颜色</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Color</span> </span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">getColor</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体实现化角色：黄色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Yellow</span> <span class="keyword">implements</span> <span class="title">Color</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getColor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;yellow&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体实现化角色：红色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Red</span> <span class="keyword">implements</span> <span class="title">Color</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getColor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;red&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象化角色：包</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Bag</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> Color color;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setColor</span><span class="params">(Color color)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.color = color;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 扩展抽象化角色：挎包</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HandBag</span> <span class="keyword">extends</span> <span class="title">Bag</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> color.getColor() + <span class="string">&quot;HandBag&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 扩展抽象化角色：钱包</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Wallet</span> <span class="keyword">extends</span> <span class="title">Bag</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> color.getColor() + <span class="string">&quot;Wallet&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> bridge;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.*;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReadXML</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">getObject</span><span class="params">(String args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();</span><br><span class="line">            DocumentBuilder builder = dFactory.newDocumentBuilder();</span><br><span class="line">            Document doc;</span><br><span class="line">            doc = builder.parse(<span class="keyword">new</span> File(<span class="string">&quot;src/bridge/config.xml&quot;</span>));</span><br><span class="line">            NodeList nl = doc.getElementsByTagName(<span class="string">&quot;className&quot;</span>);</span><br><span class="line">            Node classNode = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">if</span> (args.equals(<span class="string">&quot;color&quot;</span>)) &#123;</span><br><span class="line">                classNode = nl.item(<span class="number">0</span>).getFirstChild();</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (args.equals(<span class="string">&quot;bag&quot;</span>)) &#123;</span><br><span class="line">                classNode = nl.item(<span class="number">1</span>).getFirstChild();</span><br><span class="line">            &#125;</span><br><span class="line">            String cName = <span class="string">&quot;bridge.&quot;</span> + classNode.getNodeValue();</span><br><span class="line">            Class&lt;?&gt; c = Class.forName(cName);</span><br><span class="line">            Object obj = c.newInstance();</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">className</span>&gt;</span>Yellow<span class="tag">&lt;/<span class="name">className</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">className</span>&gt;</span>HandBag<span class="tag">&lt;/<span class="name">className</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>程序的运行结果如图所示：</p>
<img src="/ec45913f/3.jpg" class>

<p>如果将 XML 配置文件按如下修改：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">config</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">className</span>&gt;</span>Red<span class="tag">&lt;/<span class="name">className</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">className</span>&gt;</span>Wallet<span class="tag">&lt;/<span class="name">className</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>则程序的运行结果如图所示：</p>
<img src="/ec45913f/4.jpg" class>

<hr>
<h3 id="桥接模式的应用场景"><a href="#桥接模式的应用场景" class="headerlink" title="桥接模式的应用场景"></a>桥接模式的应用场景</h3><p>当一个类内部具备两种或多种变化维度时，使用桥接模式可以解耦这些变化的维度，使高层代码架构稳定。</p>
<p>桥接模式通常适用于以下场景：</p>
<ul>
<li>当一个类存在两个独立变化的维度，且这两个维度都需要进行扩展时。</li>
<li>当一个系统不希望使用继承或因为多层次继承导致系统类的个数急剧增加时。</li>
<li>当一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性时。</li>
</ul>
<p>桥接模式的一个常见使用场景就是替换继承。我们知道，继承拥有很多优点，比如，抽象、封装、多态等，父类封装共性，子类实现特性。继承可以很好的实现代码复用（封装）的功能，但这也是继承的一大缺点。</p>
<p>因为父类拥有的方法，子类也会继承得到，无论子类需不需要，这说明继承具备强侵入性（父类代码侵入子类），同时会导致子类臃肿。因此，在设计模式中，有一个原则为优先使用组合/聚合，而不是继承。</p>
<img src="/ec45913f/5.png" class>

<p>很多时候，我们分不清该使用继承还是组合/聚合或其他方式等，其实可以从现实语义进行思考。因为软件最终还是提供给现实生活中的人使用的，是服务于人类社会的，软件是具备现实场景的。当我们从纯代码角度无法看清问题时，现实角度可能会提供更加开阔的思路。</p>
<hr>
<h3 id="桥接模式模式的扩展"><a href="#桥接模式模式的扩展" class="headerlink" title="桥接模式模式的扩展"></a>桥接模式模式的扩展</h3><p>在软件开发中，有时桥接（Bridge）模式可与适配器模式联合使用。当桥接（Bridge）模式的实现化角色的接口与现有类的接口不一致时，可以在二者中间定义一个适配器将二者连接起来，其具体结构图如图所示。</p>
<img src="/ec45913f/6.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1364.html">http://c.biancheng.net/view/1364.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-结构型模式-装饰器模式</title>
    <url>/3b62e32e.html</url>
    <content><![CDATA[<h3 id="装饰器模式（装饰设计模式）"><a href="#装饰器模式（装饰设计模式）" class="headerlink" title="装饰器模式（装饰设计模式）"></a>装饰器模式（装饰设计模式）</h3><p>上班族大多都有睡懒觉的习惯，每天早上上班时间都很紧张，于是很多人为了多睡一会，就会用方便的方式解决早餐问题。有些人早餐可能会吃煎饼，煎饼中可以加鸡蛋，也可以加香肠，但是不管怎么“加码”，都还是一个煎饼。在现实生活中，常常需要对现有产品增加新的功能或美化其外观，如房子装修、相片加相框等，都是装饰器模式。</p>
<p>在软件开发过程中，有时想用一些现存的组件。这些组件可能只是完成了一些核心功能。但在不改变其结构的情况下，可以动态地扩展其功能。所有这些都可以釆用装饰器模式来实现。</p>
<hr>
<span id="more"></span>

<h3 id="装饰器模式的定义与特点"><a href="#装饰器模式的定义与特点" class="headerlink" title="装饰器模式的定义与特点"></a>装饰器模式的定义与特点</h3><p><strong>装饰器（Decorator）模式的定义：</strong>指在不改变现有对象结构的情况下，动态地给该对象增加一些职责（即增加其额外功能）的模式，它属于对象结构型模式。</p>
<p>装饰器模式的主要优点有：</p>
<ul>
<li>装饰器是继承的有力补充，比继承灵活，在不改变原有对象的情况下，动态的给一个对象扩展功能，即插即用</li>
<li>通过使用不用装饰类及这些装饰类的排列组合，可以实现不同效果</li>
<li>装饰器模式完全遵守开闭原则</li>
</ul>
<p>其主要缺点是：</p>
<ul>
<li>装饰器模式会增加许多子类，过度使用会增加程序得复杂性。</li>
</ul>
<hr>
<h3 id="装饰器模式的结构与实现"><a href="#装饰器模式的结构与实现" class="headerlink" title="装饰器模式的结构与实现"></a>装饰器模式的结构与实现</h3><p>通常情况下，扩展一个类的功能会使用继承方式来实现。但继承具有静态特征，耦合度高，并且随着扩展功能的增多，子类会很膨胀。如果使用组合关系来创建一个包装对象（即装饰对象）来包裹真实对象，并在保持真实对象的类结构不变的前提下，为其提供额外的功能，这就是装饰器模式的目标。下面来分析其基本结构和实现方法。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>装饰器模式主要包含以下角色：</p>
<ol>
<li>抽象构件（Component）角色：定义一个抽象接口以规范准备接收附加责任的对象。</li>
<li>具体构件（ConcreteComponent）角色：实现抽象构件，通过装饰角色为其添加一些职责。</li>
<li>抽象装饰（Decorator）角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。</li>
<li>具体装饰（ConcreteDecorator）角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。</li>
</ol>
<img src="/3b62e32e/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>装饰器模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> decorator;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DecoratorPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Component p = <span class="keyword">new</span> ConcreteComponent();</span><br><span class="line">        p.operation();</span><br><span class="line">        System.out.println(<span class="string">&quot;---------------------------------&quot;</span>);</span><br><span class="line">        Component d = <span class="keyword">new</span> ConcreteDecorator(p);</span><br><span class="line">        d.operation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象构件角色</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Component</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体构件角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteComponent</span> <span class="keyword">implements</span> <span class="title">Component</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ConcreteComponent</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;创建具体构件角色&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;调用具体构件角色的方法operation()&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象装饰角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decorator</span> <span class="keyword">implements</span> <span class="title">Component</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Component component;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Decorator</span><span class="params">(Component component)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.component = component;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        component.operation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体装饰角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteDecorator</span> <span class="keyword">extends</span> <span class="title">Decorator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ConcreteDecorator</span><span class="params">(Component component)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(component);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.operation();</span><br><span class="line">        addedFunction();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addedFunction</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;为具体构件角色增加额外的功能addedFunction()&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">创建具体构件角色</span><br><span class="line">调用具体构件角色的方法operation()</span><br><span class="line">---------------------------------</span><br><span class="line">调用具体构件角色的方法operation()</span><br><span class="line">为具体构件角色增加额外的功能addedFunction()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="装饰器模式的应用实例"><a href="#装饰器模式的应用实例" class="headerlink" title="装饰器模式的应用实例"></a>装饰器模式的应用实例</h3><h4 id="【例1】用装饰器模式实现游戏角色“莫莉卡·安斯兰”的变身"><a href="#【例1】用装饰器模式实现游戏角色“莫莉卡·安斯兰”的变身" class="headerlink" title="【例1】用装饰器模式实现游戏角色“莫莉卡·安斯兰”的变身"></a>【例1】用装饰器模式实现游戏角色“莫莉卡·安斯兰”的变身</h4><p>分析：在《恶魔战士》中，游戏角色“莫莉卡·安斯兰”的原身是一个可爱少女，但当她变身时，会变成头顶及背部延伸出蝙蝠状飞翼的女妖，当然她还可以变为穿着漂亮外衣的少女。这些都可用装饰器模式来实现，在本实例中的“莫莉卡”原身有 setImage(String t) 方法决定其显示方式，而其 变身“蝙蝠状女妖”和“着装少女”可以用 setChanger() 方法来改变其外观，原身与变身后的效果用 display() 方法来显示。</p>
<img src="/3b62e32e/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> decorator;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MorriganAensland</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Morrigan m0 = <span class="keyword">new</span> original();</span><br><span class="line">        m0.display();</span><br><span class="line">        Morrigan m1 = <span class="keyword">new</span> Succubus(m0);</span><br><span class="line">        m1.display();</span><br><span class="line">        Morrigan m2 = <span class="keyword">new</span> Girl(m0);</span><br><span class="line">        m2.display();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象构件角色：莫莉卡</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Morrigan</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体构件角色：原身</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">original</span> <span class="keyword">extends</span> <span class="title">JFrame</span> <span class="keyword">implements</span> <span class="title">Morrigan</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">private</span> String t = <span class="string">&quot;Morrigan0.jpg&quot;</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">original</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;《恶魔战士》中的莫莉卡·安斯兰&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setImage</span><span class="params">(String t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.t = t;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setLayout(<span class="keyword">new</span> FlowLayout());</span><br><span class="line">        JLabel l1 = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/decorator/&quot;</span> + t));</span><br><span class="line">        <span class="keyword">this</span>.add(l1);</span><br><span class="line">        <span class="keyword">this</span>.pack();</span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象装饰角色：变形</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Changer</span> <span class="keyword">implements</span> <span class="title">Morrigan</span> </span>&#123;</span><br><span class="line">    Morrigan m;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Changer</span><span class="params">(Morrigan m)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.m = m;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        m.display();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体装饰角色：女妖</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Succubus</span> <span class="keyword">extends</span> <span class="title">Changer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Succubus</span><span class="params">(Morrigan m)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(m);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        setChanger();</span><br><span class="line">        <span class="keyword">super</span>.display();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setChanger</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ((original) <span class="keyword">super</span>.m).setImage(<span class="string">&quot;Morrigan1.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体装饰角色：少女</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Girl</span> <span class="keyword">extends</span> <span class="title">Changer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Girl</span><span class="params">(Morrigan m)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(m);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        setChanger();</span><br><span class="line">        <span class="keyword">super</span>.display();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setChanger</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ((original) <span class="keyword">super</span>.m).setImage(<span class="string">&quot;Morrigan2.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/3b62e32e/3.gif" class>

<hr>
<h3 id="装饰器模式的应用场景"><a href="#装饰器模式的应用场景" class="headerlink" title="装饰器模式的应用场景"></a>装饰器模式的应用场景</h3><p>前面讲解了关于装饰器模式的结构与特点，下面介绍其适用的应用场景，装饰器模式通常在以下几种情况使用。</p>
<ul>
<li>当需要给一个现有类添加附加职责，而又不能采用生成子类的方法进行扩充时。例如，该类被隐藏或者该类是final类或者采用继承方式会产生大量的子类。</li>
<li>当需要通过对现有的一组基本功能进行排列组合而产生非常多的功能时，采用继承关系很难实现，而采用装饰器模式却很好实现。</li>
<li>当对象的功能要求可以动态地添加，也可以再动态地撤销时。</li>
</ul>
<p>装饰器模式在 Java 语言中的最著名的应用莫过于 Java I/O 标准库的设计了。例如，InputStream 的子类 FilterInputStream，OutputStream 的子类 FilterOutputStream，Reader 的子类 BufferedReader 以及 FilterReader，还有 Writer 的子类 BufferedWriter、FilterWriter 以及 PrintWriter 等，它们都是抽象装饰类。</p>
<p>下面代码是为 FileReader 增加缓冲区而采用的装饰类 BufferedReader 的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BufferedReader in = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(<span class="string">&quot;filename.txt&quot;</span>));</span><br><span class="line">String s = in.readLine();</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="装饰器模式的扩展"><a href="#装饰器模式的扩展" class="headerlink" title="装饰器模式的扩展"></a>装饰器模式的扩展</h3><p>装饰器模式所包含的 4 个角色不是任何时候都要存在的，在有些应用环境下模式是可以简化的，如以下两种情况：</p>
<ol>
<li>如果只有一个具体构件而没有抽象构件时，可以让抽象装饰继承具体构件：</li>
</ol>
<img src="/3b62e32e/4.gif" class>

<ol start="2">
<li>如果只有一个具体装饰时，可以将抽象装饰和具体装饰合并：</li>
</ol>
<img src="/3b62e32e/5.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1366.html">http://c.biancheng.net/view/1366.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-结构型模式-外观模式</title>
    <url>/4da9734b.html</url>
    <content><![CDATA[<h3 id="外观模式（Facade模式）"><a href="#外观模式（Facade模式）" class="headerlink" title="外观模式（Facade模式）"></a>外观模式（Facade模式）</h3><p>在现实生活中，常常存在办事较复杂的例子，如办房产证或注册一家公司，有时要同多个部门联系，这时要是有一个综合部门能解决一切手续问题就好了。</p>
<p>软件设计也是这样，当一个系统的功能越来越强，子系统会越来越多，客户对系统的访问也变得越来越复杂。这时如果系统内部发生改变，客户端也要跟着改变，这违背了“开闭原则”，也违背了“迪米特法则”，所以有必要为多个子系统提供一个统一的接口，从而降低系统的耦合度，这就是外观模式的目标。</p>
<hr>
<span id="more"></span>

<h3 id="外观模式的定义与特点"><a href="#外观模式的定义与特点" class="headerlink" title="外观模式的定义与特点"></a>外观模式的定义与特点</h3><p><strong>外观（Facade）模式</strong>又叫作门面模式，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。</p>
<p>在日常编码工作中，我们都在有意无意的大量使用外观模式。只要是高层模块需要调度多个子系统（2个以上的类对象），我们都会自觉地创建一个新的类封装这些子系统，提供精简的接口，让高层模块可以更加容易地间接调用这些子系统的功能。尤其是现阶段各种第三方SDK、开源类库，很大概率都会使用外观模式。</p>
<p>外观（Facade）模式是“迪米特法则”的典型应用，它有以下主要优点：</p>
<ol>
<li>降低了子系统与客户端之间的耦合度，使得子系统的变化不会影响调用它的客户类。</li>
<li>对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。</li>
<li>降低了大型软件系统中的编译依赖性，简化了系统在不同平台之间的移植过程，因为编译一个子系统不会影响其他的子系统，也不会影响外观对象。</li>
</ol>
<p>外观（Facade）模式的主要缺点如下：</p>
<ol>
<li>不能很好地限制客户使用子系统类，很容易带来未知风险。</li>
<li>增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。</li>
</ol>
<hr>
<h3 id="外观模式的结构与实现"><a href="#外观模式的结构与实现" class="headerlink" title="外观模式的结构与实现"></a>外观模式的结构与实现</h3><p>外观（Facade）模式的结构比较简单，主要是定义了一个高层接口。它包含了对各个子系统的引用，客户端可以通过它访问各个子系统的功能。现在来分析其基本结构和实现方法。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>外观（Facade）模式包含以下主要角色：</p>
<ol>
<li>外观（Facade）角色：为多个子系统对外提供一个共同的接口。</li>
<li>子系统（Sub System）角色：实现系统的部分功能，客户可以通过外观角色访问它。</li>
<li>客户（Client）角色：通过一个外观角色访问各个子系统的功能。</li>
</ol>
<img src="/4da9734b/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>外观模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> facade;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FacadePattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Facade f = <span class="keyword">new</span> Facade();</span><br><span class="line">        f.method();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 外观角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Facade</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SubSystem01 obj1 = <span class="keyword">new</span> SubSystem01();</span><br><span class="line">    <span class="keyword">private</span> SubSystem02 obj2 = <span class="keyword">new</span> SubSystem02();</span><br><span class="line">    <span class="keyword">private</span> SubSystem03 obj3 = <span class="keyword">new</span> SubSystem03();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        obj1.method1();</span><br><span class="line">        obj2.method2();</span><br><span class="line">        obj3.method3();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 子系统角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SubSystem01</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;子系统01的method1()被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 子系统角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SubSystem02</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;子系统02的method2()被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 子系统角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SubSystem03</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;子系统03的method3()被调用！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">子系统01的method1()被调用！</span><br><span class="line">子系统02的method2()被调用！</span><br><span class="line">子系统03的method3()被调用！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="外观模式的应用实例"><a href="#外观模式的应用实例" class="headerlink" title="外观模式的应用实例"></a>外观模式的应用实例</h3><h4 id="【例1】用“外观模式”设计一个婺源特产的选购界面"><a href="#【例1】用“外观模式”设计一个婺源特产的选购界面" class="headerlink" title="【例1】用“外观模式”设计一个婺源特产的选购界面"></a>【例1】用“外观模式”设计一个婺源特产的选购界面</h4><p>分析：本实例的外观角色 WySpecialty 是 JPanel 的子类，它拥有 8 个子系统角色 Specialty1~Specialty8，它们是图标类（ImageIcon）的子类对象，用来保存该婺源特产的图标。</p>
<p>外观类（WySpecialty）用 JTree 组件来管理婺源特产的名称，并定义一个事件处理方法 valueClianged(TreeSelectionEvent e)，当用户从树中选择特产时，该特产的图标对象保存在标签（JLabd）对象中。</p>
<p>客户窗体对象用分割面板来实现，左边放外观角色的目录树，右边放显示所选特产图像的标签。</p>
<img src="/4da9734b/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> facade;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.event.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.tree.DefaultMutableTreeNode;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WySpecialtyFacade</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        JFrame f = <span class="keyword">new</span> JFrame(<span class="string">&quot;外观模式: 婺源特产选择测试&quot;</span>);</span><br><span class="line">        Container cp = f.getContentPane();</span><br><span class="line">        WySpecialty wys = <span class="keyword">new</span> WySpecialty();</span><br><span class="line">        JScrollPane treeView = <span class="keyword">new</span> JScrollPane(wys.tree);</span><br><span class="line">        JScrollPane scrollpane = <span class="keyword">new</span> JScrollPane(wys.label);</span><br><span class="line">        JSplitPane splitpane = <span class="keyword">new</span> JSplitPane(JSplitPane.HORIZONTAL_SPLIT, <span class="keyword">true</span>, treeView, scrollpane); <span class="comment">//分割面版</span></span><br><span class="line">        splitpane.setDividerLocation(<span class="number">230</span>);     <span class="comment">//设置splitpane的分隔线位置</span></span><br><span class="line">        splitpane.setOneTouchExpandable(<span class="keyword">true</span>); <span class="comment">//设置splitpane可以展开或收起                      </span></span><br><span class="line">        cp.add(splitpane);</span><br><span class="line">        f.setSize(<span class="number">650</span>, <span class="number">350</span>);</span><br><span class="line">        f.setVisible(<span class="keyword">true</span>);</span><br><span class="line">        f.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WySpecialty</span> <span class="keyword">extends</span> <span class="title">JPanel</span> <span class="keyword">implements</span> <span class="title">TreeSelectionListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">final</span> JTree tree;</span><br><span class="line">    JLabel label;</span><br><span class="line">    <span class="keyword">private</span> Specialty1 s1 = <span class="keyword">new</span> Specialty1();</span><br><span class="line">    <span class="keyword">private</span> Specialty2 s2 = <span class="keyword">new</span> Specialty2();</span><br><span class="line">    <span class="keyword">private</span> Specialty3 s3 = <span class="keyword">new</span> Specialty3();</span><br><span class="line">    <span class="keyword">private</span> Specialty4 s4 = <span class="keyword">new</span> Specialty4();</span><br><span class="line">    <span class="keyword">private</span> Specialty5 s5 = <span class="keyword">new</span> Specialty5();</span><br><span class="line">    <span class="keyword">private</span> Specialty6 s6 = <span class="keyword">new</span> Specialty6();</span><br><span class="line">    <span class="keyword">private</span> Specialty7 s7 = <span class="keyword">new</span> Specialty7();</span><br><span class="line">    <span class="keyword">private</span> Specialty8 s8 = <span class="keyword">new</span> Specialty8();</span><br><span class="line">    WySpecialty() &#123;</span><br><span class="line">        DefaultMutableTreeNode top = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源特产&quot;</span>);</span><br><span class="line">        DefaultMutableTreeNode node1 = <span class="keyword">null</span>, node2 = <span class="keyword">null</span>, tempNode = <span class="keyword">null</span>;</span><br><span class="line">        node1 = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源四大特产（红、绿、黑、白）&quot;</span>);</span><br><span class="line">        tempNode = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源荷包红鲤鱼&quot;</span>);</span><br><span class="line">        node1.add(tempNode);</span><br><span class="line">        tempNode = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源绿茶&quot;</span>);</span><br><span class="line">        node1.add(tempNode);</span><br><span class="line">        tempNode = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源龙尾砚&quot;</span>);</span><br><span class="line">        node1.add(tempNode);</span><br><span class="line">        tempNode = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源江湾雪梨&quot;</span>);</span><br><span class="line">        node1.add(tempNode);</span><br><span class="line">        top.add(node1);</span><br><span class="line">        node2 = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源其它土特产&quot;</span>);</span><br><span class="line">        tempNode = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源酒糟鱼&quot;</span>);</span><br><span class="line">        node2.add(tempNode);</span><br><span class="line">        tempNode = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源糟米子糕&quot;</span>);</span><br><span class="line">        node2.add(tempNode);</span><br><span class="line">        tempNode = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源清明果&quot;</span>);</span><br><span class="line">        node2.add(tempNode);</span><br><span class="line">        tempNode = <span class="keyword">new</span> DefaultMutableTreeNode(<span class="string">&quot;婺源油煎灯&quot;</span>);</span><br><span class="line">        node2.add(tempNode);</span><br><span class="line">        top.add(node2);</span><br><span class="line">        tree = <span class="keyword">new</span> JTree(top);</span><br><span class="line">        tree.addTreeSelectionListener(<span class="keyword">this</span>);</span><br><span class="line">        label = <span class="keyword">new</span> JLabel();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">valueChanged</span><span class="params">(TreeSelectionEvent e)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (e.getSource() == tree) &#123;</span><br><span class="line">            DefaultMutableTreeNode node = (DefaultMutableTreeNode) tree.getLastSelectedPathComponent();</span><br><span class="line">            <span class="keyword">if</span> (node == <span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line">            <span class="keyword">if</span> (node.isLeaf()) &#123;</span><br><span class="line">                Object object = node.getUserObject();</span><br><span class="line">                String sele = object.toString();</span><br><span class="line">                label.setText(sele);</span><br><span class="line">                label.setHorizontalTextPosition(JLabel.CENTER);</span><br><span class="line">                label.setVerticalTextPosition(JLabel.BOTTOM);</span><br><span class="line">                sele = sele.substring(<span class="number">2</span>, <span class="number">4</span>);</span><br><span class="line">                <span class="keyword">if</span> (sele.equalsIgnoreCase(<span class="string">&quot;荷包&quot;</span>)) label.setIcon(s1);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sele.equalsIgnoreCase(<span class="string">&quot;绿茶&quot;</span>)) label.setIcon(s2);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sele.equalsIgnoreCase(<span class="string">&quot;龙尾&quot;</span>)) label.setIcon(s3);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sele.equalsIgnoreCase(<span class="string">&quot;江湾&quot;</span>)) label.setIcon(s4);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sele.equalsIgnoreCase(<span class="string">&quot;酒糟&quot;</span>)) label.setIcon(s5);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sele.equalsIgnoreCase(<span class="string">&quot;糟米&quot;</span>)) label.setIcon(s6);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sele.equalsIgnoreCase(<span class="string">&quot;清明&quot;</span>)) label.setIcon(s7);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (sele.equalsIgnoreCase(<span class="string">&quot;油煎&quot;</span>)) label.setIcon(s8);</span><br><span class="line">                label.setHorizontalAlignment(JLabel.CENTER);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Specialty1</span> <span class="keyword">extends</span> <span class="title">ImageIcon</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    Specialty1() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;src/facade/WyImage/Specialty11.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Specialty2</span> <span class="keyword">extends</span> <span class="title">ImageIcon</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    Specialty2() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;src/facade/WyImage/Specialty12.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Specialty3</span> <span class="keyword">extends</span> <span class="title">ImageIcon</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    Specialty3() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;src/facade/WyImage/Specialty13.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Specialty4</span> <span class="keyword">extends</span> <span class="title">ImageIcon</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    Specialty4() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;src/facade/WyImage/Specialty14.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Specialty5</span> <span class="keyword">extends</span> <span class="title">ImageIcon</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    Specialty5() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;src/facade/WyImage/Specialty21.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Specialty6</span> <span class="keyword">extends</span> <span class="title">ImageIcon</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    Specialty6() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;src/facade/WyImage/Specialty22.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Specialty7</span> <span class="keyword">extends</span> <span class="title">ImageIcon</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    Specialty7() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;src/facade/WyImage/Specialty23.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Specialty8</span> <span class="keyword">extends</span> <span class="title">ImageIcon</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    Specialty8() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;src/facade/WyImage/Specialty24.jpg&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/4da9734b/3.jpg" class>

<hr>
<h3 id="外观模式的应用场景"><a href="#外观模式的应用场景" class="headerlink" title="外观模式的应用场景"></a>外观模式的应用场景</h3><p>通常在以下情况下可以考虑使用外观模式：</p>
<ol>
<li>对分层结构系统构建时，使用外观模式定义子系统中每层的入口点可以简化子系统之间的依赖关系。</li>
<li>当一个复杂系统的子系统很多时，外观模式可以为系统设计一个简单的接口供外界访问。</li>
<li>当客户端与多个子系统之间存在很大的联系时，引入外观模式可将它们分离，从而提高子系统的独立性和可移植性。</li>
</ol>
<hr>
<h3 id="外观模式的扩展"><a href="#外观模式的扩展" class="headerlink" title="外观模式的扩展"></a>外观模式的扩展</h3><p>在外观模式中，当增加或移除子系统时需要修改外观类，这违背了“开闭原则”。如果引入抽象外观类，则在一定程度上解决了该问题。</p>
<img src="/4da9734b/4.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1369.html">http://c.biancheng.net/view/1369.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>MongoDB-基本操作</title>
    <url>/57e31a2c.html</url>
    <content><![CDATA[<h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><h3 id="mongod"><a href="#mongod" class="headerlink" title="mongod"></a><strong>mongod</strong></h3><ul>
<li>打开或者新建一个数据库dir</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">PS C:\Users\16218&gt; mongod --install --dbpath=D:/mongodb-win32-x86_64-windows-4.4.2/data --logpath=D:/mongodb-win32-x86_64-windows-4.4.2/logs/mongodb.log</span><br><span class="line">PS C:\Users\16218&gt; net start mongodb</span><br><span class="line"></span><br><span class="line">PS C:\Users\16218&gt; mongod --config &quot;D:\mongodb-win32-x86_64-windows-4.4.2\mongo.conf&quot;</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<ul>
<li>周边语法</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">PS C:\Users\16218&gt; bin/mongod.exe --install --dbpath 磁盘路径 --logpath 日志路径        // 创建服务</span><br><span class="line">PS C:\Users\16218&gt; bin/mongod.exe --remove      // 删除服务</span><br><span class="line">PS C:\Users\16218&gt; net start mongodb            // 启动服务</span><br><span class="line">PS C:\Users\16218&gt; net stop mongodb             // 关闭服务</span><br></pre></td></tr></table></figure>

<h3 id="mongoimport"><a href="#mongoimport" class="headerlink" title="mongoimport"></a><strong>mongoimport</strong></h3><ul>
<li><p>–db 导入到那个库</p>
</li>
<li><p>–collection 导入到哪个集合</p>
</li>
<li><p>–drop 加上就表示清空原有文档</p>
</li>
<li><p>–file 要导入的文件</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">PS C:\Users\16218&gt; mongoimport --db test --collection user --drop --file dir</span><br></pre></td></tr></table></figure>

<h3 id="mongo"><a href="#mongo" class="headerlink" title="mongo"></a><strong>mongo</strong></h3><h4 id="数据库（查看、创建、选择、删除）"><a href="#数据库（查看、创建、选择、删除）" class="headerlink" title="数据库（查看、创建、选择、删除）"></a><strong>数据库（查看、创建、选择、删除）</strong></h4><p>查看：show databases</p>
<p>创建：有单独的语法 但是忽略 隐式创建</p>
<p>选择：use 数据库名</p>
<p>删除：1.通过use选中数据库 2.通过db.dropDatabase()删除数据库</p>
<h4 id="集合（查看、创建、删除）"><a href="#集合（查看、创建、删除）" class="headerlink" title="集合（查看、创建、删除）"></a><strong>集合（查看、创建、删除）</strong></h4><p>查看：show collextions</p>
<p>创建：db.createCollection(‘集合名’)     多学一招：忽略 后期插入数据 隐式创建集合</p>
<p>删除：db.集合名.drop()</p>
<h4 id="C插入文档"><a href="#C插入文档" class="headerlink" title="C插入文档"></a><strong>C插入文档</strong></h4><p>语法：db.集合名.insert(JSON数据)</p>
<p>说明：集合存在 则直接插入数据 集合不存在 则隐式创建</p>
<p>练习：在test2数据库的c1集合中插入数据（姓名叫webopenfather年龄18岁）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; use test2</span><br><span class="line">&gt; db.c1.insert(&#123;uname: &quot;webopenfather&quot;, age: 18&#125;)</span><br><span class="line"></span><br><span class="line">留心1：数据库和集合不存在都隐式创建</span><br><span class="line">留心2：对象的键统一不加引号方便看，但是查看集合数据时系统会自动加</span><br></pre></td></tr></table></figure>

<p>思考1：是否可以自定义_id值？</p>
<p>回答：可以，只需要给插入的JSON数据增加_id键即可覆盖（但实战强烈不推荐）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.insert(&#123;_id: 1, uname: &quot;webopenfather&quot;, age: 18&#125;)</span><br></pre></td></tr></table></figure>

<p>思考2：如何一次性插入多条记录？</p>
<p>回答：传递数据，数组中写一个个JSON数据即可</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.insert([</span><br><span class="line">    &#123;uname: &quot;a&quot;, age: 1&#125;, </span><br><span class="line">    &#123;uname: &quot;b&quot;, age: 2&#125;, </span><br><span class="line">    &#123;uname: &quot;c&quot;, age: 3&#125;, </span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>思考3：如何快速插入10条数据？</p>
<p>回答：mongodb底层使用JS引擎实现的，所以支持部分js语法，因此可以写for循环</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; use test2</span><br><span class="line">&gt; for (let i = 1; i &lt;= 10; i++) &#123;</span><br><span class="line">    db.c2.insert(&#123;uname: &quot;a&quot;+i, age: i&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="R查询文档"><a href="#R查询文档" class="headerlink" title="R查询文档"></a><strong>R查询文档</strong></h4><p>语法：db.集合名.find(条件 [,查询的列])</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">条件</span><br><span class="line">    查询所有数据                &#123;&#125;或者不写</span><br><span class="line">    查询age=6的数据             &#123;age: 6&#125;</span><br><span class="line">    既要age=6又要性别=男        &#123;age: 6, sex: &#x27;男&#x27;&#125;</span><br><span class="line"></span><br><span class="line">查询的列（可选参数）</span><br><span class="line">    不写        只查询全部列（字段）</span><br><span class="line">    &#123;age: 1&#125;    只显示age列（字段）</span><br><span class="line">    &#123;age: 0&#125;    除了age列（字段都显示）</span><br><span class="line">    留心：不管怎么写 系统自定义的_id都会存在</span><br></pre></td></tr></table></figure>

<p>升级语法：db.集合名.find({键: {运算符: 值}})</p>
<p>说明：<br>| 运算符 | 作用 |<br>| :——: | :—-: |<br>| $gt | 大于 |<br>| $gte | 大于等于 |<br>| $lt | 小于 |<br>| $lte | 小于等于 |<br>| $ne | 不等于 |<br>| $in | in |<br>| $nin | not in |</p>
<p>练习1：查询所有数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.find()</span><br></pre></td></tr></table></figure>

<p>练习2：查询年龄大于5岁的数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.find(&#123;age: &#123;$gt: 5&#125;&#125;)</span><br></pre></td></tr></table></figure>

<p>练习3：查询年龄是5岁、8岁、10岁的数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.find(&#123;age: &#123;$in: [5, 8, 10]&#125;&#125;)</span><br></pre></td></tr></table></figure>

<p>练习4：只看年龄列，或者年龄以外的列（_id别管它）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.find(&#123;&#125;, &#123;age: 1&#125;)</span><br><span class="line">&gt; db.c1.find(&#123;&#125;, &#123;age: 0&#125;)</span><br></pre></td></tr></table></figure>

<h4 id="U修改文档"><a href="#U修改文档" class="headerlink" title="U修改文档"></a><strong>U修改文档</strong></h4><p>语法：db.集合名.update(条件, 新数据 [,是否新增，是否修改多条])</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">是否新增：指条件匹配不到数据则插入 true插入 false不插入（默认）</span><br><span class="line">是否修改多条：指将匹配成功的数据都修改 true修改多条 false不修改多条（默认）</span><br></pre></td></tr></table></figure>

<p>升级语法：db.集合名.update(条件, {修改器: {键: 值}})</p>
<p>说明：<br>| 运算符 | 作用 |<br>| :——: | :—-: |<br>| $inc | 递增 |<br>| $rename | 重命名列 |<br>| $set | 修改列值 |<br>| $unset | 删除列 |</p>
<p>练习1：将{uname: “zc1”}改为{uname: “zc2”}</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c3.update(&#123;uname: &quot;zc1&quot;&#125;, &#123;uname: &quot;zc2&quot;&#125;)              // 这是替换</span><br><span class="line">&gt; db.c3.update(&#123;uname: &quot;zc1&quot;&#125;, &#123;$set: &#123;uname: &quot;zc2&quot;&#125;&#125;)      // 这是修改</span><br></pre></td></tr></table></figure>

<p>练习2：给{uname: “zc10”}的年龄加2岁或减两岁</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c3.update(&#123;uname: &quot;zc1&quot;&#125;, &#123;$inc: &#123;age: 2&#125;&#125;)</span><br><span class="line">&gt; db.c3.update(&#123;uname: &quot;zc1&quot;&#125;, &#123;$inc: &#123;age: -2&#125;&#125;)</span><br></pre></td></tr></table></figure>

<p>练习3：修改器综合练习</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uname改成zc2</span><br><span class="line">&gt; db.c3.update(&#123;uname: &quot;zc1&quot;&#125;, &#123;$set: &#123;uname: &quot;zc2&quot;&#125;&#125;)</span><br><span class="line">age增加111</span><br><span class="line">&gt; db.c3.update(&#123;uname: &quot;zc2&quot;&#125;, &#123;$inc: &#123;age: 111&#125;&#125;)</span><br><span class="line">who改字段sex</span><br><span class="line">&gt; db.c3.update(&#123;uname: &quot;zc2&quot;&#125;, &#123;$rename: &#123;who: &quot;sex&quot;&#125;&#125;)</span><br><span class="line">other删除</span><br><span class="line">&gt; db.c3.update(&#123;uname: &quot;zc2&quot;&#125;, &#123;$unset: &#123;other: true&#125;&#125;)</span><br><span class="line">或者一起写</span><br><span class="line">db.c3.update(&#123;uname: &quot;zc1&quot;&#125;, &#123;</span><br><span class="line">    $set: &#123;uname: &quot;zc2&quot;&#125;, </span><br><span class="line">    $inc: &#123;age: 111&#125;, </span><br><span class="line">    $rename: &#123;who: &quot;sex&quot;&#125;, </span><br><span class="line">    $unset: &#123;other: true&#125;, </span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<h4 id="D删除文档"><a href="#D删除文档" class="headerlink" title="D删除文档"></a><strong>D删除文档</strong></h4><p>语法：db.集合名.remove(条件, [,是否删除一条])</p>
<p>注意：是否删除一条 true是 false否（默认）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c3.remove(&#123;&#125;, true)</span><br><span class="line">&gt; db.c3.remove(&#123;&#125;)</span><br></pre></td></tr></table></figure>

<h4 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a><strong>小总结</strong></h4><p>增Create</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名.insert(JSON数据)</span><br></pre></td></tr></table></figure>

<p>删Delete</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名.remove(条件, [,是否删除一条])</span><br></pre></td></tr></table></figure>

<p>改Update</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名.update(条件, 新数据 [,是否新增，是否修改多条])</span><br><span class="line">&gt; db.集合名.update(条件, &#123;修改器: &#123;键: 值&#125;&#125;)</span><br></pre></td></tr></table></figure>

<p>查Read</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名.find(条件 [,查询的列])</span><br></pre></td></tr></table></figure>

<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a><strong>排序</strong></h4><p>语法：db.集合名.find().sort(JSON数据)</p>
<p>说明：键 就是要排序的列/字段 值 1升序 -1降序</p>
<p>练习1：年龄升序&amp;降序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.find().sort(&#123;age: 1&#125;)</span><br><span class="line">&gt; db.c1.find().sort(&#123;age: -1&#125;)</span><br></pre></td></tr></table></figure>

<p>练习2：按照k1来排序 如果k1的值相同 按照k2来排序 1升序 -1降序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.collectionName.find().sort(&#123;k1: 1&#125;, &#123;k2: -1&#125;)</span><br></pre></td></tr></table></figure>

<h4 id="Limit与Skip方法"><a href="#Limit与Skip方法" class="headerlink" title="Limit与Skip方法"></a><strong>Limit与Skip方法</strong></h4><p>语法：db.集合名.find().sort().skip(数字).limit(数字)</p>
<p>说明：skip跳过指定数量（可选），limit限制查询的数量</p>
<p>练习1：降序查询2条</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.find().sort(&#123;age: -1&#125;).skip(0).limit(2)</span><br></pre></td></tr></table></figure>

<p>练习2：降序跳过2条并查询2条</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.c1.find().sort(&#123;age: -1&#125;).skip(2).limit(2)</span><br></pre></td></tr></table></figure>

<p>实战分页</p>
<p>需求：数据库 1 - 10 数据，每页显示2条（5页）</p>
<p>语法：db.集合名.find().skip().limit(2)</p>
<p>skip计算公式：(当前页 - 1) * 每页显示条数</p>
<h4 id="聚合查询"><a href="#聚合查询" class="headerlink" title="聚合查询"></a><strong>聚合查询</strong></h4><p>语法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名称.aggregate([</span><br><span class="line">    &#123;管道: &#123;表达式&#125;&#125;</span><br><span class="line">    ...</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>常用管道：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$group  将集合中的文档分组，用于统计结果</span><br><span class="line">$match  过滤数据，只要输出符合条件的文档</span><br><span class="line">$sort   聚合数据进一步排序</span><br><span class="line">$skip   跳过指定文档数</span><br><span class="line">$limit  限制集合数据返回文档数</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>常用表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$sum    总和 $sum:1同count表示统计</span><br><span class="line">$avg    平均</span><br><span class="line">$min    最小值</span><br><span class="line">$max    最大值</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>练习1：统计男生、女生的总年龄</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名称.aggregate([</span><br><span class="line">    &#123;</span><br><span class="line">        $group: &#123;</span><br><span class="line">            _id: &quot;$sex&quot;, </span><br><span class="line">            rs: &#123;$sum: &quot;$age&quot;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>练习2：统计男生、女生的总人数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名称.aggregate([</span><br><span class="line">    &#123;</span><br><span class="line">        $group: &#123;</span><br><span class="line">            _id: &quot;$sex&quot;, </span><br><span class="line">            rs: &#123;$sum: 1&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>练习3：求学生总数和平均年龄</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名称.aggregate([</span><br><span class="line">    &#123;</span><br><span class="line">        $group: &#123;</span><br><span class="line">            _id: null, </span><br><span class="line">            total_num: &#123;$sum: 1&#125;, </span><br><span class="line">            total_avg: &#123;$avg: &quot;$age&quot;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>练习4：查询男生、女生人数，按人数升序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; db.集合名称.aggregate([</span><br><span class="line">    &#123;</span><br><span class="line">        $group: &#123;</span><br><span class="line">            _id: &quot;$sex&quot;, </span><br><span class="line">            rs: &#123;$sum: 1&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        $sort: &#123;rs: 1&#125;</span><br><span class="line">    &#125;</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h2 id="Linux环境安装MongoDB"><a href="#Linux环境安装MongoDB" class="headerlink" title="Linux环境安装MongoDB"></a><strong>Linux环境安装MongoDB</strong></h2><ul>
<li>下载</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.4.2.tgz</span><br></pre></td></tr></table></figure>

<ul>
<li>解压</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# tar -zxvf mongodb-linux-x86_64-rhel70-4.4.2.tgz</span><br></pre></td></tr></table></figure>

<ul>
<li>将解压包拷贝到指定目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# mv mongodb-linux-x86_64-rhel70-4.4.2/ /usr/local/mongodb</span><br></pre></td></tr></table></figure>

<ul>
<li>创建数据存放目录与日志存放目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# mkdir -p /usr/local/mongodb/data /usr/local/mongodb/logs</span><br></pre></td></tr></table></figure>

<ul>
<li>启动MongoDB服务</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# /usr/local/mongodb/bin/mongod --dbpath=/usr/local/mongodb/data --logpath=/usr/local/mongodb/logs/mongodb.log --logappend --port=27017 --fork</span><br></pre></td></tr></table></figure>

<ul>
<li>后期登录即可</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@VM-8-3-centos ~]# /usr/local/mongodb/bin/mongo</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐MongoDB</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-结构型模式-享元模式</title>
    <url>/5bea50a9.html</url>
    <content><![CDATA[<h3 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h3><p>在面向对象程序设计过程中，有时会面临要创建大量相同或相似对象实例的问题。创建那么多的对象将会耗费很多的系统资源，它是系统性能提高的一个瓶颈。</p>
<p>例如，围棋和五子棋中的黑白棋子，图像中的坐标点或颜色，局域网中的路由器、交换机和集线器，教室里的桌子和凳子等。这些对象有很多相似的地方，如果能把它们相同的部分提取出来共享，则能节省大量的系统资源，这就是享元模式的产生背景。</p>
<hr>
<span id="more"></span>

<h3 id="享元模式的定义与特点"><a href="#享元模式的定义与特点" class="headerlink" title="享元模式的定义与特点"></a>享元模式的定义与特点</h3><p><strong>享元（Flyweight）模式的定义：</strong>运用共享技术来有效地支持大量细粒度对象的复用。它通过共享已经存在的对象来大幅度减少需要创建的对象数量、避免大量相似类的开销，从而提高系统资源的利用率。</p>
<p>享元模式的主要优点是：</p>
<ol>
<li>相同对象只要保存一份，这降低了系统中对象的数量，从而降低了系统中细粒度对象给内存带来的压力。</li>
</ol>
<p>其主要缺点是：</p>
<ol>
<li>为了使对象可以共享，需要将一些不能共享的状态外部化，这将增加程序的复杂性。</li>
<li>读取享元模式的外部状态会使得运行时间稍微变长。</li>
</ol>
<hr>
<h3 id="享元模式的结构与实现"><a href="#享元模式的结构与实现" class="headerlink" title="享元模式的结构与实现"></a>享元模式的结构与实现</h3><p>享元模式的定义提出了两个要求，细粒度和共享对象。因为要求细粒度，所以不可避免地会使对象数量多且性质相近，此时我们就将这些对象的信息分为两个部分：内部状态和外部状态。</p>
<ul>
<li>内部状态指对象共享出来的信息，存储在享元信息内部，并且不回随环境的改变而改变；</li>
<li>外部状态指对象得以依赖的一个标记，随环境的改变而改变，不可共享。</li>
</ul>
<p>比如，连接池中的连接对象，保存在连接对象中的用户名、密码、连接URL等信息，在创建对象的时候就设置好了，不会随环境的改变而改变，这些为内部状态。而当每个连接要被回收利用时，我们需要将它标记为可用状态，这些为外部状态。</p>
<p>享元模式的本质是缓存共享对象，降低内存消耗。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>享元模式的主要角色有如下：</p>
<ol>
<li>抽象享元角色（Flyweight）：是所有的具体享元类的基类，为具体享元规范需要实现的公共接口，非享元的外部状态以参数的形式通过方法传入。</li>
<li>具体享元（Concrete Flyweight）角色：实现抽象享元角色中所规定的接口。</li>
<li>非享元（Unsharable Flyweight)角色：是不可以共享的外部状态，它以参数的形式注入具体享元的相关方法中。</li>
<li>享元工厂（Flyweight Factory）角色：负责创建和管理享元角色。当客户对象请求一个享元对象时，享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。</li>
</ol>
<p>下图是享元模式的结构图，其中：</p>
<ul>
<li>UnsharedConcreteFlyweight 是非享元角色，里面包含了非共享的外部状态信息 info</li>
<li>Flyweight 是抽象享元角色，里面包含了享元方法 operation(UnsharedConcreteFlyweight state)，非享元的外部状态以参数的形式通过该方法传入</li>
<li>ConcreteFlyweight 是具体享元角色，包含了关键字 key，它实现了抽象享元接口</li>
<li>FlyweightFactory 是享元工厂角色，它是关键字 key 来管理具体享元</li>
<li>客户角色通过享元工厂获取具体享元，并访问具体享元的相关方法</li>
</ul>
<img src="/5bea50a9/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>享元模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlyweightPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        FlyweightFactory factory = <span class="keyword">new</span> FlyweightFactory();</span><br><span class="line">        Flyweight f01 = factory.getFlyweight(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">        Flyweight f02 = factory.getFlyweight(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">        Flyweight f03 = factory.getFlyweight(<span class="string">&quot;a&quot;</span>);</span><br><span class="line">        Flyweight f11 = factory.getFlyweight(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">        Flyweight f12 = factory.getFlyweight(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">        f01.operation(<span class="keyword">new</span> UnsharedConcreteFlyweight(<span class="string">&quot;第1次调用a。&quot;</span>));</span><br><span class="line">        f02.operation(<span class="keyword">new</span> UnsharedConcreteFlyweight(<span class="string">&quot;第2次调用a。&quot;</span>));</span><br><span class="line">        f03.operation(<span class="keyword">new</span> UnsharedConcreteFlyweight(<span class="string">&quot;第3次调用a。&quot;</span>));</span><br><span class="line">        f11.operation(<span class="keyword">new</span> UnsharedConcreteFlyweight(<span class="string">&quot;第1次调用b。&quot;</span>));</span><br><span class="line">        f12.operation(<span class="keyword">new</span> UnsharedConcreteFlyweight(<span class="string">&quot;第2次调用b。&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 非享元角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnsharedConcreteFlyweight</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String info;</span><br><span class="line">    UnsharedConcreteFlyweight(String info) &#123;</span><br><span class="line">        <span class="keyword">this</span>.info = info;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> info;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setInfo</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.info = info;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象享元角色</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Flyweight</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">(UnsharedConcreteFlyweight state)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体享元角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteFlyweight</span> <span class="keyword">implements</span> <span class="title">Flyweight</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String key;</span><br><span class="line">    ConcreteFlyweight(String key) &#123;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体享元&quot;</span> + key + <span class="string">&quot;被创建！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">(UnsharedConcreteFlyweight outState)</span> </span>&#123;</span><br><span class="line">        System.out.print(<span class="string">&quot;具体享元&quot;</span> + key + <span class="string">&quot;被调用，&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;非享元信息是:&quot;</span> + outState.getInfo());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 享元工厂角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlyweightFactory</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> HashMap&lt;String, Flyweight&gt; flyweights = <span class="keyword">new</span> HashMap&lt;String, Flyweight&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Flyweight <span class="title">getFlyweight</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">        Flyweight flyweight = (Flyweight) flyweights.get(key);</span><br><span class="line">        <span class="keyword">if</span> (flyweight != <span class="keyword">null</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;具体享元&quot;</span> + key + <span class="string">&quot;已经存在，被成功获取！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            flyweight = <span class="keyword">new</span> ConcreteFlyweight(key);</span><br><span class="line">            flyweights.put(key, flyweight);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> flyweight;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体享元a被创建！</span><br><span class="line">具体享元a已经存在，被成功获取！</span><br><span class="line">具体享元a已经存在，被成功获取！</span><br><span class="line">具体享元b被创建！</span><br><span class="line">具体享元b已经存在，被成功获取！</span><br><span class="line">具体享元a被调用，非享元信息是:第1次调用a。</span><br><span class="line">具体享元a被调用，非享元信息是:第2次调用a。</span><br><span class="line">具体享元a被调用，非享元信息是:第3次调用a。</span><br><span class="line">具体享元b被调用，非享元信息是:第1次调用b。</span><br><span class="line">具体享元b被调用，非享元信息是:第2次调用b。</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="享元模式的应用实例"><a href="#享元模式的应用实例" class="headerlink" title="享元模式的应用实例"></a>享元模式的应用实例</h3><h4 id="【例1】享元模式在五子棋游戏中的应用"><a href="#【例1】享元模式在五子棋游戏中的应用" class="headerlink" title="【例1】享元模式在五子棋游戏中的应用"></a>【例1】享元模式在五子棋游戏中的应用</h4><p>分析：五子棋同围棋一样，包含多个“黑”或“白”颜色的棋子，所以用享元模式比较好。</p>
<p>本实例中:</p>
<ul>
<li>棋子（ChessPieces）类是抽象享元角色，它包含了一个落子的 DownPieces(Graphics g,Point pt) 方法；</li>
<li>白子（WhitePieces）和黑子（BlackPieces）类是具体享元角色，它实现了落子方法；</li>
<li>Point 是非享元角色，它指定了落子的位置；</li>
<li>WeiqiFactory 是享元工厂角色，它通过 ArrayList 来管理棋子，并且提供了获取白子或者黑子的 getChessPieces(String type) 方法；</li>
<li>客户类（Chessboard）利用 Graphics 组件在框架窗体中绘制一个棋盘，并实现 mouseClicked(MouseEvent e) 事件处理方法，该方法根据用户的选择从享元工厂中获取白子或者黑子并落在棋盘上。</li>
</ul>
<img src="/5bea50a9/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.MouseAdapter;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.MouseEvent;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WzqGame</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Chessboard();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 棋盘</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Chessboard</span> <span class="keyword">extends</span> <span class="title">MouseAdapter</span> </span>&#123;</span><br><span class="line">    WeiqiFactory wf;</span><br><span class="line">    JFrame f;</span><br><span class="line">    Graphics g;</span><br><span class="line">    JRadioButton wz;</span><br><span class="line">    JRadioButton bz;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> x = <span class="number">50</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> y = <span class="number">50</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> w = <span class="number">40</span>;    <span class="comment">//小方格宽度和高度</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> rw = <span class="number">400</span>;    <span class="comment">//棋盘宽度和高度</span></span><br><span class="line">    Chessboard() &#123;</span><br><span class="line">        wf = <span class="keyword">new</span> WeiqiFactory();</span><br><span class="line">        f = <span class="keyword">new</span> JFrame(<span class="string">&quot;享元模式在五子棋游戏中的应用&quot;</span>);</span><br><span class="line">        f.setBounds(<span class="number">100</span>, <span class="number">100</span>, <span class="number">500</span>, <span class="number">550</span>);</span><br><span class="line">        f.setVisible(<span class="keyword">true</span>);</span><br><span class="line">        f.setResizable(<span class="keyword">false</span>);</span><br><span class="line">        f.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">        JPanel SouthJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        f.add(<span class="string">&quot;South&quot;</span>, SouthJP);</span><br><span class="line">        wz = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;白子&quot;</span>);</span><br><span class="line">        bz = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;黑子&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line">        ButtonGroup group = <span class="keyword">new</span> ButtonGroup();</span><br><span class="line">        group.add(wz);</span><br><span class="line">        group.add(bz);</span><br><span class="line">        SouthJP.add(wz);</span><br><span class="line">        SouthJP.add(bz);</span><br><span class="line">        JPanel CenterJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        CenterJP.setLayout(<span class="keyword">null</span>);</span><br><span class="line">        CenterJP.setSize(<span class="number">500</span>, <span class="number">500</span>);</span><br><span class="line">        CenterJP.addMouseListener(<span class="keyword">this</span>);</span><br><span class="line">        f.add(<span class="string">&quot;Center&quot;</span>, CenterJP);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">500</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        g = CenterJP.getGraphics();</span><br><span class="line">        g.setColor(Color.BLUE);</span><br><span class="line">        g.drawRect(x, y, rw, rw);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//绘制第i条竖直线</span></span><br><span class="line">            g.drawLine(x + (i * w), y, x + (i * w), y + rw);</span><br><span class="line">            <span class="comment">//绘制第i条水平线</span></span><br><span class="line">            g.drawLine(x, y + (i * w), x + rw, y + (i * w));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mouseClicked</span><span class="params">(MouseEvent e)</span> </span>&#123;</span><br><span class="line">        Point pt = <span class="keyword">new</span> Point(e.getX() - <span class="number">15</span>, e.getY() - <span class="number">15</span>);</span><br><span class="line">        <span class="keyword">if</span> (wz.isSelected()) &#123;</span><br><span class="line">            ChessPieces c1 = wf.getChessPieces(<span class="string">&quot;w&quot;</span>);</span><br><span class="line">            c1.DownPieces(g, pt);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (bz.isSelected()) &#123;</span><br><span class="line">            ChessPieces c2 = wf.getChessPieces(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">            c2.DownPieces(g, pt);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象享元角色：棋子</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">ChessPieces</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">DownPieces</span><span class="params">(Graphics g, Point pt)</span></span>;    <span class="comment">//下子</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体享元角色：白子</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WhitePieces</span> <span class="keyword">implements</span> <span class="title">ChessPieces</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">DownPieces</span><span class="params">(Graphics g, Point pt)</span> </span>&#123;</span><br><span class="line">        g.setColor(Color.WHITE);</span><br><span class="line">        g.fillOval(pt.x, pt.y, <span class="number">30</span>, <span class="number">30</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体享元角色：黑子</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BlackPieces</span> <span class="keyword">implements</span> <span class="title">ChessPieces</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">DownPieces</span><span class="params">(Graphics g, Point pt)</span> </span>&#123;</span><br><span class="line">        g.setColor(Color.BLACK);</span><br><span class="line">        g.fillOval(pt.x, pt.y, <span class="number">30</span>, <span class="number">30</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 享元工厂角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WeiqiFactory</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;ChessPieces&gt; qz;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">WeiqiFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        qz = <span class="keyword">new</span> ArrayList&lt;ChessPieces&gt;();</span><br><span class="line">        ChessPieces w = <span class="keyword">new</span> WhitePieces();</span><br><span class="line">        qz.add(w);</span><br><span class="line">        ChessPieces b = <span class="keyword">new</span> BlackPieces();</span><br><span class="line">        qz.add(b);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ChessPieces <span class="title">getChessPieces</span><span class="params">(String type)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (type.equalsIgnoreCase(<span class="string">&quot;w&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> (ChessPieces) qz.get(<span class="number">0</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (type.equalsIgnoreCase(<span class="string">&quot;b&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> (ChessPieces) qz.get(<span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/5bea50a9/3.gif" class>

<hr>
<h3 id="享元模式的应用场景"><a href="#享元模式的应用场景" class="headerlink" title="享元模式的应用场景"></a>享元模式的应用场景</h3><p>当系统中多处需要同一组信息时，可以把这些信息封装到一个对象中，然后对该对象进行缓存，这样，一个对象就可以提供给多出需要使用的地方，避免大量同一对象的多次创建，降低大量内存空间的消耗。</p>
<p>享元模式其实是工厂方法模式的一个改进机制，享元模式同样要求创建一个或一组对象，并且就是通过工厂方法模式生成对象的，只不过享元模式为工厂方法模式增加了缓存这一功能。</p>
<p>前面分析了享元模式的结构与特点，下面分析它适用的应用场景。享元模式是通过减少内存中对象的数量来节省内存空间的，所以以下几种情形适合采用享元模式。</p>
<ol>
<li>系统中存在大量相同或相似的对象，这些对象耗费大量的内存资源。</li>
<li>大部分的对象可以按照内部状态进行分组，且可将不同部分外部化，这样每一个组只需保存一个内部状态。</li>
<li>由于享元模式需要额外维护一个保存享元的数据结构，所以应当在有足够多的享元实例时才值得使用享元模式。</li>
</ol>
<hr>
<h3 id="享元模式的扩展"><a href="#享元模式的扩展" class="headerlink" title="享元模式的扩展"></a>享元模式的扩展</h3><p>在前面介绍的享元模式中，其结构图通常包含可以共享的部分和不可以共享的部分。在实际使用过程中，有时候会稍加改变，即存在两种特殊的享元模式：单纯享元模式和复合享元模式，下面分别对它们进行简单介绍。</p>
<ol>
<li>单纯享元模式，这种享元模式中的所有的具体享元类都是可以共享的，不存在非共享的具体享元类。</li>
</ol>
<img src="/5bea50a9/4.gif" class>

<ol start="2">
<li>复合享元模式，这种享元模式中的有些享元对象是由一些单纯享元对象组合而成的，它们就是复合享元对象。虽然复合享元对象本身不能共享，但它们可以分解成单纯享元对象再被共享。</li>
</ol>
<img src="/5bea50a9/5.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1371.html">http://c.biancheng.net/view/1371.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-结构型模式-组合模式</title>
    <url>/65f06e71.html</url>
    <content><![CDATA[<h3 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h3><p>在现实生活中，存在很多“部分-整体”的关系，例如，大学中的部门与学院、总公司中的部门与分公司、学习用品中的书与书包、生活用品中的衣服与衣柜、以及厨房中的锅碗瓢盆等。在软件开发中也是这样，例如，文件系统中的文件与文件夹、窗体程序中的简单控件与容器控件等。对这些简单对象与复合对象的处理，如果用组合模式来实现会很方便。</p>
<hr>
<span id="more"></span>

<h3 id="组合模式的定义与特点"><a href="#组合模式的定义与特点" class="headerlink" title="组合模式的定义与特点"></a>组合模式的定义与特点</h3><p><strong>组合（Composite Pattern）模式的定义：</strong>有时又叫作整体-部分（Part-Whole）模式，它是一种将对象组合成树状的层次结构的模式，用来表示“整体-部分”的关系，使用户对单个对象和组合对象具有一致的访问性，属于结构型设计模式。</p>
<p>组合模式一般用来描述整体与部分的关系，它将对象组织到树形结构中，顶层的节点被称为根节点，根节点下面可以包含树枝节点和叶子节点，树枝节点下面又可以包含树枝节点和叶子节点，树形结构图如下。</p>
<img src="/65f06e71/1.png" class>

<p>由上图可以看出，其实根节点和树枝节点本质上属于同一种数据类型，可以作为容器使用；而叶子节点与树枝节点在语义上不属于用一种类型。但是在组合模式中，会把树枝节点和叶子节点看作属于同一种数据类型（用统一接口定义），让它们具备一致行为。</p>
<p>这样，在组合模式中，整个树形结构中的对象都属于同一种类型，带来的好处就是用户不需要辨别是树枝节点还是叶子节点，可以直接进行操作，给用户的使用带来极大的便利。</p>
<p>组合模式的主要优点有：</p>
<ol>
<li>组合模式使得客户端代码可以一致地处理单个对象和组合对象，无须关心自己处理的是单个对象，还是组合对象，这简化了客户端代码</li>
<li>更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足“开闭原则”</li>
</ol>
<p>其主要缺点是：</p>
<ol>
<li>设计较复杂，客户端需要花更多时间理清类之间的层次关系</li>
<li>不容易限制容器中的构件</li>
<li>不容易用继承的方法来增加构件的新功能</li>
</ol>
<hr>
<h3 id="组合模式的结构与实现"><a href="#组合模式的结构与实现" class="headerlink" title="组合模式的结构与实现"></a>组合模式的结构与实现</h3><p>组合模式的结构不是很复杂，下面对它的结构和实现进行分析。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>组合模式包含以下主要角色：</p>
<ol>
<li>抽象构件（Component）角色：它的主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。（总的抽象类或接口，定义一些通用的方法，比如新增、删除）</li>
<li>树叶构件（Leaf）角色：是组合中的叶节点对象，它没有子节点，用于继承或实现抽象构件。</li>
<li>树枝构件（Composite）角色 / 中间构件：是组合中的分支节点对象，它有子节点，用于继承和实现抽象构件。它的主要作用是存储和管理子部件，通常包含 Add()、Remove()、GetChild() 等方法。</li>
</ol>
<p>组合模式分为透明式的组合模式和安全式的组合模式。</p>
<h5 id="透明方式"><a href="#透明方式" class="headerlink" title="透明方式"></a>透明方式</h5><p>在该方式中，由于抽象构件声明了所有子类中的全部方法，所以客户端无须区别树叶对象和树枝对象，对客户端来说是透明的。但其缺点是：树叶构件本来没有 Add()、Remove() 及 GetChild() 方法，却要实现它们（空实现或抛异常），这样会带来一些安全性问题。</p>
<img src="/65f06e71/2.gif" class>

<h5 id="安全方式"><a href="#安全方式" class="headerlink" title="安全方式"></a>安全方式</h5><p>在该方式中，将管理子构件的方法移到树枝构件中，抽象构件和树叶构件没有对子对象的管理方法，这样就避免了上一种方式的安全性问题，但由于叶子和分支有不同的接口，客户端在调用时要知道树叶对象和树枝对象的存在，所以失去了透明性。</p>
<img src="/65f06e71/3.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>假如要访问集合 c0 = {leaf1, {leaf2, leaf3}} 中的元素，其对应的树状图如图</p>
<img src="/65f06e71/4.gif" class>

<h5 id="透明组合模式"><a href="#透明组合模式" class="headerlink" title="透明组合模式"></a>透明组合模式</h5><p>下面为透明式的组合模式的实现代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CompositePattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Component c0 = <span class="keyword">new</span> Composite();</span><br><span class="line">        Component c1 = <span class="keyword">new</span> Composite();</span><br><span class="line">        Component leaf1 = <span class="keyword">new</span> Leaf(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">        Component leaf2 = <span class="keyword">new</span> Leaf(<span class="string">&quot;2&quot;</span>);</span><br><span class="line">        Component leaf3 = <span class="keyword">new</span> Leaf(<span class="string">&quot;3&quot;</span>);</span><br><span class="line">        c0.add(leaf1);</span><br><span class="line">        c0.add(c1);</span><br><span class="line">        c1.add(leaf2);</span><br><span class="line">        c1.add(leaf3);</span><br><span class="line">        c0.operation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象构件</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Component</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Component c)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Component c)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Component <span class="title">getChild</span><span class="params">(<span class="keyword">int</span> i)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 树叶构件</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Leaf</span> <span class="keyword">implements</span> <span class="title">Component</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Leaf</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Component c)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Component c)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Component <span class="title">getChild</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;树叶&quot;</span> + name + <span class="string">&quot;：被访问！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 树枝构件</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Composite</span> <span class="keyword">implements</span> <span class="title">Component</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;Component&gt; children = <span class="keyword">new</span> ArrayList&lt;Component&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Component c)</span> </span>&#123;</span><br><span class="line">        children.add(c);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Component c)</span> </span>&#123;</span><br><span class="line">        children.remove(c);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Component <span class="title">getChild</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> children.get(i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Object obj : children) &#123;</span><br><span class="line">            ((Component) obj).operation();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">树叶1：被访问！</span><br><span class="line">树叶2：被访问！</span><br><span class="line">树叶3：被访问！</span><br></pre></td></tr></table></figure>

<h5 id="安全组合模式"><a href="#安全组合模式" class="headerlink" title="安全组合模式"></a>安全组合模式</h5><p>安全式的组合模式与透明式组合模式的实现代码类似，只要对其做简单修改就可以了，代码如下:</p>
<p>首先修改 Component 代码，只保留层次的公共行为。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Component</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后修改客户端代码，将树枝构件类型更改为 Composite 类型，以便获取管理子类操作的方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CompositePattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Composite c0 = <span class="keyword">new</span> Composite();</span><br><span class="line">        Composite c1 = <span class="keyword">new</span> Composite();</span><br><span class="line">        Component leaf1 = <span class="keyword">new</span> Leaf(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">        Component leaf2 = <span class="keyword">new</span> Leaf(<span class="string">&quot;2&quot;</span>);</span><br><span class="line">        Component leaf3 = <span class="keyword">new</span> Leaf(<span class="string">&quot;3&quot;</span>);</span><br><span class="line">        c0.add(leaf1);</span><br><span class="line">        c0.add(c1);</span><br><span class="line">        c1.add(leaf2);</span><br><span class="line">        c1.add(leaf3);</span><br><span class="line">        c0.operation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="组合模式的应用实例"><a href="#组合模式的应用实例" class="headerlink" title="组合模式的应用实例"></a>组合模式的应用实例</h3><h4 id="【例1】用组合模式实现当用户在商店购物后，显示其所选商品信息，并计算所选商品总价的功能"><a href="#【例1】用组合模式实现当用户在商店购物后，显示其所选商品信息，并计算所选商品总价的功能" class="headerlink" title="【例1】用组合模式实现当用户在商店购物后，显示其所选商品信息，并计算所选商品总价的功能"></a>【例1】用组合模式实现当用户在商店购物后，显示其所选商品信息，并计算所选商品总价的功能</h4><p>说明：假如李先生到韶关“天街e角”生活用品店购物，用 1 个红色小袋子装了 2 包婺源特产（单价 7.9 元）、1 张婺源地图（单价 9.9 元）；用 1 个白色小袋子装了 2 包韶关香藉（单价 68 元）和 3 包韶关红茶（单价 180 元）；用 1 个中袋子装了前面的红色小袋子和 1 个景德镇瓷器（单价 380 元）；用 1 个大袋子装了前面的中袋子、白色小袋子和 1 双李宁牌运动鞋（单价 198 元）。</p>
<p>最后“大袋子”中的内容有：{1 双李宁牌运动鞋（单价 198 元）、白色小袋子{2 包韶关香菇（单价 68 元）、3 包韶关红茶（单价 180 元）}、中袋子{1 个景德镇瓷器（单价 380 元）、红色小袋子{2 包婺源特产（单价 7.9 元）、1 张婺源地图（单价 9.9 元）}}}，现在要求编程显示李先生放在大袋子中的所有商品信息并计算要支付的总价。</p>
<p>本实例可按安全组合模式设计，其结构图如图：</p>
<img src="/65f06e71/5.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> composite;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShoppingTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> s = <span class="number">0</span>;</span><br><span class="line">        Bags BigBag, mediumBag, smallRedBag, smallWhiteBag;</span><br><span class="line">        Goods sp;</span><br><span class="line">        BigBag = <span class="keyword">new</span> Bags(<span class="string">&quot;大袋子&quot;</span>);</span><br><span class="line">        mediumBag = <span class="keyword">new</span> Bags(<span class="string">&quot;中袋子&quot;</span>);</span><br><span class="line">        smallRedBag = <span class="keyword">new</span> Bags(<span class="string">&quot;红色小袋子&quot;</span>);</span><br><span class="line">        smallWhiteBag = <span class="keyword">new</span> Bags(<span class="string">&quot;白色小袋子&quot;</span>);</span><br><span class="line">        sp = <span class="keyword">new</span> Goods(<span class="string">&quot;婺源特产&quot;</span>, <span class="number">2</span>, <span class="number">7.9f</span>);</span><br><span class="line">        smallRedBag.add(sp);</span><br><span class="line">        sp = <span class="keyword">new</span> Goods(<span class="string">&quot;婺源地图&quot;</span>, <span class="number">1</span>, <span class="number">9.9f</span>);</span><br><span class="line">        smallRedBag.add(sp);</span><br><span class="line">        sp = <span class="keyword">new</span> Goods(<span class="string">&quot;韶关香菇&quot;</span>, <span class="number">2</span>, <span class="number">68</span>);</span><br><span class="line">        smallWhiteBag.add(sp);</span><br><span class="line">        sp = <span class="keyword">new</span> Goods(<span class="string">&quot;韶关红茶&quot;</span>, <span class="number">3</span>, <span class="number">180</span>);</span><br><span class="line">        smallWhiteBag.add(sp);</span><br><span class="line">        sp = <span class="keyword">new</span> Goods(<span class="string">&quot;景德镇瓷器&quot;</span>, <span class="number">1</span>, <span class="number">380</span>);</span><br><span class="line">        mediumBag.add(sp);</span><br><span class="line">        mediumBag.add(smallRedBag);</span><br><span class="line">        sp = <span class="keyword">new</span> Goods(<span class="string">&quot;李宁牌运动鞋&quot;</span>, <span class="number">1</span>, <span class="number">198</span>);</span><br><span class="line">        BigBag.add(sp);</span><br><span class="line">        BigBag.add(smallWhiteBag);</span><br><span class="line">        BigBag.add(mediumBag);</span><br><span class="line">        System.out.println(<span class="string">&quot;您选购的商品有：&quot;</span>);</span><br><span class="line">        BigBag.show();</span><br><span class="line">        s = BigBag.calculation();</span><br><span class="line">        System.out.println(<span class="string">&quot;要支付的总价是：&quot;</span> + s + <span class="string">&quot;元&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象构件：物品</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Articles</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">calculation</span><span class="params">()</span></span>; <span class="comment">// 计算</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 树叶构件：商品</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Goods</span> <span class="keyword">implements</span> <span class="title">Articles</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;     <span class="comment">// 名字</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> quantity;    <span class="comment">// 数量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">float</span> unitPrice; <span class="comment">// 单价</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Goods</span><span class="params">(String name, <span class="keyword">int</span> quantity, <span class="keyword">float</span> unitPrice)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.quantity = quantity;</span><br><span class="line">        <span class="keyword">this</span>.unitPrice = unitPrice;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">calculation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> quantity * unitPrice;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(name + <span class="string">&quot;(数量：&quot;</span> + quantity + <span class="string">&quot;，单价：&quot;</span> + unitPrice + <span class="string">&quot;元)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 树枝构件：袋子</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bags</span> <span class="keyword">implements</span> <span class="title">Articles</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;     <span class="comment">// 名字  </span></span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;Articles&gt; bags = <span class="keyword">new</span> ArrayList&lt;Articles&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Bags</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Articles c)</span> </span>&#123;</span><br><span class="line">        bags.add(c);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Articles c)</span> </span>&#123;</span><br><span class="line">        bags.remove(c);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Articles <span class="title">getChild</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> bags.get(i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">calculation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> s = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (Object obj : bags) &#123;</span><br><span class="line">            s += ((Articles) obj).calculation();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Object obj : bags) &#123;</span><br><span class="line">            ((Articles) obj).show();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">您选购的商品有：</span><br><span class="line">李宁牌运动鞋(数量：1，单价：198.0元)</span><br><span class="line">韶关香菇(数量：2，单价：68.0元)</span><br><span class="line">韶关红茶(数量：3，单价：180.0元)</span><br><span class="line">景德镇瓷器(数量：1，单价：380.0元)</span><br><span class="line">婺源特产(数量：2，单价：7.9元)</span><br><span class="line">婺源地图(数量：1，单价：9.9元)</span><br><span class="line">要支付的总价是：1279.7元</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="组合模式的应用场景"><a href="#组合模式的应用场景" class="headerlink" title="组合模式的应用场景"></a>组合模式的应用场景</h3><p>前面分析了组合模式的结构与特点，下面分析它适用的以下应用场景：</p>
<ol>
<li>在需要表示一个对象整体与部分的层次结构的场合。</li>
<li>要求对用户隐藏组合对象与单个对象的不同，用户可以用统一的接口使用组合结构中的所有对象的场合。</li>
</ol>
<hr>
<h3 id="组合模式的扩展"><a href="#组合模式的扩展" class="headerlink" title="组合模式的扩展"></a>组合模式的扩展</h3><p>如果对前面介绍的组合模式中的树叶节点和树枝节点进行抽象，也就是说树叶节点和树枝节点还有子节点，这时组合模式就扩展成复杂的组合模式了，如 Java AWT/Swing 中的简单组件 JTextComponent 有子类 JTextField、JTextArea，容器组件 Container 也有子类 Window、Panel。</p>
<img src="/65f06e71/6.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1373.html">http://c.biancheng.net/view/1373.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-行为型模式概述</title>
    <url>/448a6995.html</url>
    <content><![CDATA[<h3 id="行为型模式"><a href="#行为型模式" class="headerlink" title="行为型模式"></a>行为型模式</h3><p>行为型模式用于描述程序在运行时复杂的流程控制，即描述多个类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，它涉及算法与对象间职责的分配。</p>
<p>行为型模式分为类行为模式和对象行为模式，前者采用继承机制来在类间分派行为，后者采用组合或聚合在对象间分配行为。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象行为模式比类行为模式具有更大的灵活性。</p>
<p>行为型模式是 GoF 设计模式中最为庞大的一类，它包含以下 11 种模式。</p>
<ol>
<li><strong>模板方法（Template Method）模式：</strong>定义一个操作中的算法骨架，将算法的一些步骤延迟到子类中，使得子类在可以不改变该算法结构的情况下重定义该算法的某些特定步骤。</li>
<li><strong>策略（Strategy）模式：</strong>定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。</li>
<li><strong>命令（Command）模式：</strong>将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。</li>
<li><strong>职责链（Chain of Responsibility）模式：</strong>把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。</li>
<li><strong>状态（State）模式：</strong>允许一个对象在其内部状态发生改变时改变其行为能力。</li>
<li><strong>观察者（Observer）模式：</strong>多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。</li>
<li><strong>中介者（Mediator）模式：</strong>定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。</li>
<li><strong>迭代器（Iterator）模式：</strong>提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。</li>
<li><strong>访问者（Visitor）模式：</strong>在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。</li>
<li><strong>备忘录（Memento）模式：</strong>在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。</li>
<li><strong>解释器（Interpreter）模式：</strong>提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。</li>
</ol>
<p>以上 11 种行为型模式，除了模板方法模式和解释器模式是类行为型模式，其他的全部属于对象行为型模式，之后的博客将详细介绍它们的特点、结构与应用。</p>
<span id="more"></span>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1374.html">http://c.biancheng.net/view/1374.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-模板方法模式</title>
    <url>/832c4d9d.html</url>
    <content><![CDATA[<h3 id="模板方法模式（模板方法设计模式）"><a href="#模板方法模式（模板方法设计模式）" class="headerlink" title="模板方法模式（模板方法设计模式）"></a>模板方法模式（模板方法设计模式）</h3><p>在面向对象程序设计过程中，程序员常常会遇到这种情况：设计一个系统时知道了算法所需的关键步骤，而且确定了这些步骤的执行顺序，但某些步骤的具体实现还未知，或者说某些步骤的实现与具体的环境相关。</p>
<p>例如，去银行办理业务一般要经过以下4个流程：取号、排队、办理具体业务、对银行工作人员进行评分等，其中取号、排队和对银行工作人员进行评分的业务对每个客户是一样的，可以在父类中实现，但是办理具体业务却因人而异，它可能是存款、取款或者转账等，可以延迟到子类中实现。</p>
<p>这样的例子在生活中还有很多，例如，一个人每天会起床、吃饭、做事、睡觉等，其中“做事”的内容每天可能不同。我们把这些规定了流程或格式的实例定义成模板，允许使用者根据自己的需求去更新它，例如，简历模板、论文模板、Word 中模板文件等。</p>
<hr>
<span id="more"></span>

<h3 id="模板方法模式的定义与特点"><a href="#模板方法模式的定义与特点" class="headerlink" title="模板方法模式的定义与特点"></a>模板方法模式的定义与特点</h3><p><strong>模板方法（Template Method）模式的定义如下：</strong>定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。它是一种类行为型模式。</p>
<p>该模式的主要优点如下：</p>
<ul>
<li>它封装了不变部分，扩展可变部分。它把认为是不变部分的算法封装到父类中实现，而把可变部分算法由子类继承实现，便于子类继续扩展。</li>
<li>它在父类中提取了公共的部分代码，便于代码复用。</li>
<li>部分方法是由子类实现的，因此子类可以通过扩展方式增加相应的功能，符合开闭原则。</li>
</ul>
<p>该模式的主要缺点如下：</p>
<ul>
<li>对每个不同的实现都需要定义一个子类，这会导致类的个数增加，系统更加庞大，设计也更加抽象，间接地增加了系统实现的复杂度。</li>
<li>父类中的抽象方法由子类实现，子类执行的结果会影响父类的结果，这导致一种反向的控制结构，它提高了代码阅读的难度。</li>
<li>由于继承关系自身的缺点，如果父类添加新的抽象方法，则所有子类都要改一遍。</li>
</ul>
<hr>
<h3 id="模板方法模式的结构与实现"><a href="#模板方法模式的结构与实现" class="headerlink" title="模板方法模式的结构与实现"></a>模板方法模式的结构与实现</h3><p>模板方法模式需要注意抽象类与具体子类之间的协作。它用到了虚函数的多态性技术以及“不用调用我，让我来调用你”的反向控制技术。现在来介绍它们的基本结构。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>模板方法模式包含以下主要角色：</p>
<h5 id="抽象类-抽象模板（Abstract-Class）"><a href="#抽象类-抽象模板（Abstract-Class）" class="headerlink" title="抽象类/抽象模板（Abstract Class）"></a>抽象类/抽象模板（Abstract Class）</h5><p>抽象模板类，负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成。这些方法的定义如下：</p>
<ol>
<li>模板方法：定义了算法的骨架，按某种顺序调用其包含的基本方法。</li>
<li>基本方法：是整个算法中的一个步骤，包含以下几种类型：<ul>
<li>抽象方法：在抽象类中声明，由具体子类实现。</li>
<li>具体方法：在抽象类中已经实现，在具体子类中可以继承或重写它。</li>
<li>钩子方法：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。</li>
</ul>
</li>
</ol>
<h5 id="具体子类-具体实现（Concrete-Class）"><a href="#具体子类-具体实现（Concrete-Class）" class="headerlink" title="具体子类/具体实现（Concrete Class）"></a>具体子类/具体实现（Concrete Class）</h5><p>具体实现类，实现抽象类中所定义的抽象方法和钩子方法，它们是一个顶级逻辑的一个组成步骤。</p>
<img src="/832c4d9d/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>模板方法模式的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TemplateMethodPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        AbstractClass tm = <span class="keyword">new</span> ConcreteClass();</span><br><span class="line">        tm.TemplateMethod();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象类</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractClass</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 模板方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">TemplateMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        SpecificMethod();</span><br><span class="line">        abstractMethod1();</span><br><span class="line">        abstractMethod2();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 具体方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">SpecificMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;抽象类中的具体方法被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 抽象方法1</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">abstractMethod1</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">// 抽象方法2</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">abstractMethod2</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体子类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteClass</span> <span class="keyword">extends</span> <span class="title">AbstractClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">abstractMethod1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;抽象方法1的实现被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">abstractMethod2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;抽象方法2的实现被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">抽象类中的具体方法被调用...</span><br><span class="line">抽象方法1的实现被调用...</span><br><span class="line">抽象方法2的实现被调用...</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】用模板方法模式实现出国留学手续设计程序"><a href="#【例1】用模板方法模式实现出国留学手续设计程序" class="headerlink" title="【例1】用模板方法模式实现出国留学手续设计程序"></a>【例1】用模板方法模式实现出国留学手续设计程序</h4><p>分析：出国留学手续一般经过以下流程：索取学校资料，提出入学申请，办理因私出国护照、出境卡和公证，申请签证，体检、订机票、准备行装，抵达目标学校等，其中有些业务对各个学校是一样的，但有些业务因学校不同而不同，所以比较适合用模板方法模式来实现。</p>
<p>在本实例中，我们先定义一个出国留学的抽象类 StudyAbroad，里面包含了一个模板方法 TemplateMethod()，该方法中包含了办理出国留学手续流程中的各个基本方法，其中有些方法的处理由于各国都一样，所以在抽象类中就可以实现，但有些方法的处理各国是不同的，必须在其具体子类（如美国留学类 StudyInAmerica）中实现。如果再增加一个国家，只要增加一个子类就可以了。</p>
<img src="/832c4d9d/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StudyAbroadProcess</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        StudyAbroad tm = <span class="keyword">new</span> StudyInAmerica();</span><br><span class="line">        tm.TemplateMethod();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象类: 出国留学</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">StudyAbroad</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">TemplateMethod</span><span class="params">()</span> <span class="comment">//模板方法</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        LookingForSchool(); <span class="comment">//索取学校资料</span></span><br><span class="line">        ApplyForEnrol();    <span class="comment">//入学申请</span></span><br><span class="line">        ApplyForPassport(); <span class="comment">//办理因私出国护照、出境卡和公证</span></span><br><span class="line">        ApplyForVisa();     <span class="comment">//申请签证</span></span><br><span class="line">        ReadyGoAbroad();    <span class="comment">//体检、订机票、准备行装</span></span><br><span class="line">        Arriving();         <span class="comment">//抵达</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ApplyForPassport</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;三.办理因私出国护照、出境卡和公证：&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  1）持录取通知书、本人户口簿或身份证向户口所在地公安机关申请办理因私出国护照和出境卡。&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  2）办理出生公证书，学历、学位和成绩公证，经历证书，亲属关系公证，经济担保公证。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ApplyForVisa</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;四.申请签证：&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  1）准备申请国外境签证所需的各种资料，包括个人学历、成绩单、工作经历的证明；个人及家庭收入、资金和财产证明；家庭成员的关系证明等；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  2）向拟留学国家驻华使(领)馆申请入境签证。申请时需按要求填写有关表格，递交必需的证明材料，缴纳签证。有的国家(比如美国、英国、加拿大等)在申请签证时会要求申请人前往使(领)馆进行面试。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ReadyGoAbroad</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;五.体检、订机票、准备行装：&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  1）进行身体检查、免疫检查和接种传染病疫苗；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  2）确定机票时间、航班和转机地点。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">LookingForSchool</span><span class="params">()</span></span>;<span class="comment">//索取学校资料</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">ApplyForEnrol</span><span class="params">()</span></span>;   <span class="comment">//入学申请</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">Arriving</span><span class="params">()</span></span>;        <span class="comment">//抵达</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体子类: 美国留学</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StudyInAmerica</span> <span class="keyword">extends</span> <span class="title">StudyAbroad</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">LookingForSchool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;一.索取学校以下资料：&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  1）对留学意向国家的政治、经济、文化背景和教育体制、学术水平进行较为全面的了解；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  2）全面了解和掌握国外学校的情况，包括历史、学费、学制、专业、师资配备、教学设施、学术地位、学生人数等；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  3）了解该学校的住宿、交通、医疗保险情况如何；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  4）该学校在中国是否有授权代理招生的留学中介公司？&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  5）掌握留学签证情况；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  6）该国政府是否允许留学生合法打工？&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  8）毕业之后可否移民？&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  9）文凭是否受到我国认可？&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ApplyForEnrol</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;二.入学申请：&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  1）填写报名表；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  2）将报名表、个人学历证明、最近的学习成绩单、推荐信、个人简历、托福或雅思语言考试成绩单等资料寄往所申请的学校；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  3）为了给签证办理留有充裕的时间，建议越早申请越好，一般提前1年就比较从容。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Arriving</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;六.抵达目标学校：&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  1）安排住宿；&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  2）了解校园及周边环境。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一.索取学校以下资料：</span><br><span class="line">  1）对留学意向国家的政治、经济、文化背景和教育体制、学术水平进行较为全面的了解；</span><br><span class="line">  2）全面了解和掌握国外学校的情况，包括历史、学费、学制、专业、师资配备、教学设施、学术地位、学生人数等；</span><br><span class="line">  3）了解该学校的住宿、交通、医疗保险情况如何；</span><br><span class="line">  4）该学校在中国是否有授权代理招生的留学中介公司？</span><br><span class="line">  5）掌握留学签证情况；</span><br><span class="line">  6）该国政府是否允许留学生合法打工？</span><br><span class="line">  8）毕业之后可否移民？</span><br><span class="line">  9）文凭是否受到我国认可？</span><br><span class="line">二.入学申请：</span><br><span class="line">  1）填写报名表；</span><br><span class="line">  2）将报名表、个人学历证明、最近的学习成绩单、推荐信、个人简历、托福或雅思语言考试成绩单等资料寄往所申请的学校；</span><br><span class="line">  3）为了给签证办理留有充裕的时间，建议越早申请越好，一般提前1年就比较从容。</span><br><span class="line">三.办理因私出国护照、出境卡和公证：</span><br><span class="line">  1）持录取通知书、本人户口簿或身份证向户口所在地公安机关申请办理因私出国护照和出境卡。</span><br><span class="line">  2）办理出生公证书，学历、学位和成绩公证，经历证书，亲属关系公证，经济担保公证。</span><br><span class="line">四.申请签证：</span><br><span class="line">  1）准备申请国外境签证所需的各种资料，包括个人学历、成绩单、工作经历的证明；个人及家庭收入、资金和财产证明；家庭成员的关系证明等；</span><br><span class="line">  2）向拟留学国家驻华使(领)馆申请入境签证。申请时需按要求填写有关表格，递交必需的证明材料，缴纳签证。有的国家(比如美国、英国、加拿大等)在申请签证时会要求申请人前往使(领)馆进行面试。</span><br><span class="line">五.体检、订机票、准备行装：</span><br><span class="line">  1）进行身体检查、免疫检查和接种传染病疫苗；</span><br><span class="line">  2）确定机票时间、航班和转机地点。</span><br><span class="line">六.抵达目标学校：</span><br><span class="line">  1）安排住宿；</span><br><span class="line">  2）了解校园及周边环境。</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>模板方法模式通常适用于以下场景：</p>
<ol>
<li>算法的整体步骤很固定，但其中个别部分易变时，这时候可以使用模板方法模式，将容易变的部分抽象出来，供子类实现。</li>
<li>当多个子类存在公共的行为时，可以将其提取出来并集中到一个公共父类中以避免代码重复。首先，要识别现有代码中的不同之处，并且将不同之处分离为新的操作。最后，用一个调用这些新的操作的模板方法来替换这些不同的代码。</li>
<li>当需要控制子类的扩展时，模板方法只在特定点调用钩子操作，这样就只允许在这些点进行扩展。</li>
</ol>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>在模板方法模式中，基本方法包含：抽象方法、具体方法和钩子方法，正确使用“钩子方法”可以使得子类控制父类的行为。如下面例子中，可以通过在具体子类中重写钩子方法 HookMethod1() 和 HookMethod2() 来改变抽象父类中的运行结果。</p>
<img src="/832c4d9d/3.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HookTemplateMethod</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        HookAbstractClass tm = <span class="keyword">new</span> HookConcreteClass();</span><br><span class="line">        tm.TemplateMethod();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 含钩子方法的抽象类</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">HookAbstractClass</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 模板方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">TemplateMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        abstractMethod1();</span><br><span class="line">        HookMethod1();</span><br><span class="line">        <span class="keyword">if</span> (HookMethod2()) &#123;</span><br><span class="line">            SpecificMethod();</span><br><span class="line">        &#125;</span><br><span class="line">        abstractMethod2();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 具体方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">SpecificMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;抽象类中的具体方法被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 钩子方法1</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">HookMethod1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 钩子方法2</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">HookMethod2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 抽象方法1</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">abstractMethod1</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">// 抽象方法2</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">abstractMethod2</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 含钩子方法的具体子类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HookConcreteClass</span> <span class="keyword">extends</span> <span class="title">HookAbstractClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">abstractMethod1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;抽象方法1的实现被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">abstractMethod2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;抽象方法2的实现被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">HookMethod1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;钩子方法1被重写...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">HookMethod2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">抽象方法1的实现被调用...</span><br><span class="line">钩子方法1被重写...</span><br><span class="line">抽象方法2的实现被调用...</span><br></pre></td></tr></table></figure>

<p>如果钩子方法 HookMethod1() 和钩子方法 HookMethod2() 的代码改变，则程序的运行结果也会改变。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1376.html">http://c.biancheng.net/view/1376.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-策略模式</title>
    <url>/970d2369.html</url>
    <content><![CDATA[<h3 id="策略模式（策略设计模式）"><a href="#策略模式（策略设计模式）" class="headerlink" title="策略模式（策略设计模式）"></a>策略模式（策略设计模式）</h3><p>在现实生活中常常遇到实现某种目标存在多种策略可供选择的情况，例如，出行旅游可以乘坐飞机、乘坐火车、骑自行车或自己开私家车等，超市促销可以釆用打折、送商品、送积分等方法。</p>
<p>在软件开发中也常常遇到类似的情况，当实现某一个功能存在多种算法或者策略，我们可以根据环境或者条件的不同选择不同的算法或者策略来完成该功能，如数据排序策略有冒泡排序、选择排序、插入排序、二叉树排序等。</p>
<p>如果使用多重条件转移语句实现（即硬编码），不但使条件语句变得很复杂，而且增加、删除或更换算法要修改原代码，不易维护，违背开闭原则。如果采用策略模式就能很好解决该问题。</p>
<hr>
<span id="more"></span>

<h3 id="策略模式的定义与特点"><a href="#策略模式的定义与特点" class="headerlink" title="策略模式的定义与特点"></a>策略模式的定义与特点</h3><p><strong>策略（Strategy）模式的定义：</strong>该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。</p>
<p>策略模式的主要优点如下：</p>
<ol>
<li>多重条件语句不易维护，而使用策略模式可以避免使用多重条件语句，如 if…else 语句、switch…case 语句。</li>
<li>策略模式提供了一系列的可供重用的算法族，恰当使用继承可以把算法族的公共代码转移到父类里面，从而避免重复的代码。</li>
<li>策略模式可以提供相同行为的不同实现，客户可以根据不同时间或空间要求选择不同的。</li>
<li>策略模式提供了对开闭原则的完美支持，可以在不修改原代码的情况下，灵活增加新算法。</li>
<li>策略模式把算法的使用放到环境类中，而算法的实现移到具体策略类中，实现了二者的分离。</li>
</ol>
<p>其主要缺点如下：</p>
<ol>
<li>客户端必须理解所有策略算法的区别，以便适时选择恰当的算法类。</li>
<li>策略模式造成很多的策略类，增加维护难度。</li>
</ol>
<hr>
<h3 id="策略模式的结构与实现"><a href="#策略模式的结构与实现" class="headerlink" title="策略模式的结构与实现"></a>策略模式的结构与实现</h3><p>策略模式是准备一组算法，并将这组算法封装到一系列的策略类里面，作为一个抽象策略类的子类。策略模式的重心不是如何实现算法，而是如何组织这些算法，从而让程序结构更加灵活，具有更好的维护性和扩展性，现在我们来分析其基本结构和实现方法。</p>
<h4 id="策略模式的结构"><a href="#策略模式的结构" class="headerlink" title="策略模式的结构"></a>策略模式的结构</h4><p>策略模式的主要角色如下：</p>
<ol>
<li>抽象策略（Strategy）类：定义了一个公共接口，各种不同的算法以不同的方式实现这个接口，环境角色使用这2个接口调用不同的算法，一般使用接口或抽象类实现。</li>
<li>具体策略（Concrete Strategy）类：实现了抽象策略定义的接口，提供具体的算法实现。</li>
<li>环境（Context）类：持有一个策略类的引用，最终给客户端调用。</li>
</ol>
<img src="/970d2369/1.gif" class>

<h4 id="策略模式的实现"><a href="#策略模式的实现" class="headerlink" title="策略模式的实现"></a>策略模式的实现</h4><p>策略模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StrategyPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Context c = <span class="keyword">new</span> Context();</span><br><span class="line">        Strategy s = <span class="keyword">new</span> ConcreteStrategyA();</span><br><span class="line">        c.setStrategy(s);</span><br><span class="line">        c.strategyMethod();</span><br><span class="line">        System.out.println(<span class="string">&quot;-----------------&quot;</span>);</span><br><span class="line">        s = <span class="keyword">new</span> ConcreteStrategyB();</span><br><span class="line">        c.setStrategy(s);</span><br><span class="line">        c.strategyMethod();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象策略类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Strategy</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">strategyMethod</span><span class="params">()</span></span>;    <span class="comment">// 策略方法</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体策略类A</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteStrategyA</span> <span class="keyword">implements</span> <span class="title">Strategy</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">strategyMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体策略A的策略方法被访问！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体策略类B</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteStrategyB</span> <span class="keyword">implements</span> <span class="title">Strategy</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">strategyMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体策略B的策略方法被访问！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 环境类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Context</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Strategy strategy;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Strategy <span class="title">getStrategy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> strategy;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setStrategy</span><span class="params">(Strategy strategy)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.strategy = strategy;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">strategyMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        strategy.strategyMethod();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体策略A的策略方法被访问！</span><br><span class="line">-----------------</span><br><span class="line">具体策略B的策略方法被访问！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="策略模式的应用实例"><a href="#策略模式的应用实例" class="headerlink" title="策略模式的应用实例"></a>策略模式的应用实例</h3><h4 id="【例1】策略模式在“大闸蟹”做菜中的应用"><a href="#【例1】策略模式在“大闸蟹”做菜中的应用" class="headerlink" title="【例1】策略模式在“大闸蟹”做菜中的应用"></a>【例1】策略模式在“大闸蟹”做菜中的应用</h4><p>分析：关于大闸蟹的做法有很多种，我们以清蒸大闸蟹和红烧大闸蟹两种方法为例，介绍策略模式的应用。</p>
<p>首先，定义一个大闸蟹加工的抽象策略类（CrabCooking），里面包含了一个做菜的抽象方法 CookingMethod()；然后，定义清蒸大闸蟹（SteamedCrabs）和红烧大闸蟹（BraisedCrabs）的具体策略类，它们实现了抽象策略类中的抽象方法；由于本程序要显示做好的结果图，所以将具体策略类定义成 JLabel 的子类；最后，定义一个厨房（Kitchen）环境类，它具有设置和选择做菜策略的方法；客户类通过厨房类获取做菜策略，并把做菜结果图在窗体中显示出来。</p>
<img src="/970d2369/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.*;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CrabCookingStrategy</span> <span class="keyword">implements</span> <span class="title">ItemListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> JFrame f;</span><br><span class="line">    <span class="keyword">private</span> JRadioButton qz, hs;</span><br><span class="line">    <span class="keyword">private</span> JPanel CenterJP, SouthJP;</span><br><span class="line">    <span class="keyword">private</span> Kitchen cf;    <span class="comment">// 厨房</span></span><br><span class="line">    <span class="keyword">private</span> CrabCooking qzx, hsx;    <span class="comment">// 大闸蟹加工者  </span></span><br><span class="line">    CrabCookingStrategy() &#123;</span><br><span class="line">        f = <span class="keyword">new</span> JFrame(<span class="string">&quot;策略模式在大闸蟹做菜中的应用&quot;</span>);</span><br><span class="line">        f.setBounds(<span class="number">100</span>, <span class="number">100</span>, <span class="number">500</span>, <span class="number">400</span>);</span><br><span class="line">        f.setVisible(<span class="keyword">true</span>);</span><br><span class="line">        f.setResizable(<span class="keyword">false</span>);</span><br><span class="line">        f.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">        SouthJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        CenterJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        f.add(<span class="string">&quot;South&quot;</span>, SouthJP);</span><br><span class="line">        f.add(<span class="string">&quot;Center&quot;</span>, CenterJP);</span><br><span class="line">        qz = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;清蒸大闸蟹&quot;</span>);</span><br><span class="line">        hs = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;红烧大闸蟹&quot;</span>);</span><br><span class="line">        qz.addItemListener(<span class="keyword">this</span>);</span><br><span class="line">        hs.addItemListener(<span class="keyword">this</span>);</span><br><span class="line">        ButtonGroup group = <span class="keyword">new</span> ButtonGroup();</span><br><span class="line">        group.add(qz);</span><br><span class="line">        group.add(hs);</span><br><span class="line">        SouthJP.add(qz);</span><br><span class="line">        SouthJP.add(hs);</span><br><span class="line">        <span class="comment">//---------------------------------</span></span><br><span class="line">        cf = <span class="keyword">new</span> Kitchen();    <span class="comment">// 厨房</span></span><br><span class="line">        qzx = <span class="keyword">new</span> SteamedCrabs();    <span class="comment">// 清蒸大闸蟹类</span></span><br><span class="line">        hsx = <span class="keyword">new</span> BraisedCrabs();    <span class="comment">// 红烧大闸蟹类</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">itemStateChanged</span><span class="params">(ItemEvent e)</span> </span>&#123;</span><br><span class="line">        JRadioButton jc = (JRadioButton) e.getSource();</span><br><span class="line">        <span class="keyword">if</span> (jc == qz) &#123;</span><br><span class="line">            cf.setStrategy(qzx);</span><br><span class="line">            cf.CookingMethod(); <span class="comment">// 清蒸</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jc == hs) &#123;</span><br><span class="line">            cf.setStrategy(hsx);</span><br><span class="line">            cf.CookingMethod(); <span class="comment">// 红烧</span></span><br><span class="line">        &#125;</span><br><span class="line">        CenterJP.removeAll();</span><br><span class="line">        CenterJP.repaint();</span><br><span class="line">        CenterJP.add((Component) cf.getStrategy());</span><br><span class="line">        f.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> CrabCookingStrategy();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象策略类：大闸蟹加工类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">CrabCooking</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">CookingMethod</span><span class="params">()</span></span>;    <span class="comment">// 做菜方法</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体策略类：清蒸大闸蟹</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SteamedCrabs</span> <span class="keyword">extends</span> <span class="title">JLabel</span> <span class="keyword">implements</span> <span class="title">CrabCooking</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">CookingMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setIcon(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/strategy/SteamedCrabs.jpg&quot;</span>));</span><br><span class="line">        <span class="keyword">this</span>.setHorizontalAlignment(CENTER);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体策略类：红烧大闸蟹</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BraisedCrabs</span> <span class="keyword">extends</span> <span class="title">JLabel</span> <span class="keyword">implements</span> <span class="title">CrabCooking</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">CookingMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setIcon(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/strategy/BraisedCrabs.jpg&quot;</span>));</span><br><span class="line">        <span class="keyword">this</span>.setHorizontalAlignment(CENTER);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 环境类：厨房</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Kitchen</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> CrabCooking strategy;    <span class="comment">// 抽象策略</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setStrategy</span><span class="params">(CrabCooking strategy)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.strategy = strategy;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> CrabCooking <span class="title">getStrategy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> strategy;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">CookingMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        strategy.CookingMethod();    <span class="comment">// 做菜  </span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/970d2369/3.jpg" class>

<hr>
<h4 id="【例2】用策略模式实现从韶关去婺源旅游的出行方式"><a href="#【例2】用策略模式实现从韶关去婺源旅游的出行方式" class="headerlink" title="【例2】用策略模式实现从韶关去婺源旅游的出行方式"></a>【例2】用策略模式实现从韶关去婺源旅游的出行方式</h4><p>分析：从韶关去婺源旅游有以下几种出行方式：坐火车、坐汽车和自驾车，所以该实例用策略模式比较适合</p>
<img src="/970d2369/4.gif" class>

<hr>
<h3 id="策略模式的应用场景"><a href="#策略模式的应用场景" class="headerlink" title="策略模式的应用场景"></a>策略模式的应用场景</h3><p>策略模式在很多地方用到，如 Java SE 中的容器布局管理就是一个典型的实例，Java SE 中的每个容器都存在多种布局供用户选择。在程序设计中，通常在以下几种情况中使用策略模式较多：</p>
<ol>
<li>一个系统需要动态地在几种算法中选择一种时，可将每个算法封装到策略类中。</li>
<li>一个类定义了多种行为，并且这些行为在这个类的操作中以多个条件语句的形式出现，可将每个条件分支移入它们各自的策略类中以代替这些条件语句。</li>
<li>系统中各算法彼此完全独立，且要求对客户隐藏具体算法的实现细节时。</li>
<li>系统要求使用算法的客户不应该知道其操作的数据时，可使用策略模式来隐藏与算法相关的数据结构。</li>
<li>多个类只区别在表现行为不同，可以使用策略模式，在运行时动态选择具体要执行的行为。</li>
</ol>
<hr>
<h3 id="策略模式的扩展"><a href="#策略模式的扩展" class="headerlink" title="策略模式的扩展"></a>策略模式的扩展</h3><p>在一个使用策略模式的系统中，当存在的策略很多时，客户端管理所有策略算法将变得很复杂，如果在环境类中使用策略工厂模式来管理这些策略类将大大减少客户端的工作复杂度。</p>
<img src="/970d2369/5.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1378.html">http://c.biancheng.net/view/1378.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>软件系统设计与体系结构-知识点快速复习</title>
    <url>/219814b1.html</url>
    <content><![CDATA[<h2 id="第1章-软件体系结构概论"><a href="#第1章-软件体系结构概论" class="headerlink" title="第1章 软件体系结构概论"></a>第1章 软件体系结构概论</h2><h3 id="从软件危机说起"><a href="#从软件危机说起" class="headerlink" title="从软件危机说起"></a>从软件危机说起</h3><ul>
<li>软件危机是指在计算机软件的<u>开发</u>和<u>维护</u>过程中所遇到的一系列严重问题。</li>
</ul>
<h4 id="软件危机的表现"><a href="#软件危机的表现" class="headerlink" title="软件危机的表现"></a>软件危机的表现</h4><ol>
<li><p>软件（成本）日益增加</p>
</li>
<li><p>开发（进度）难以控制</p>
</li>
<li><p>软件（质量）差</p>
</li>
<li><p>软件（维护）困难</p>
</li>
</ol>
<span id="more"></span>

<h4 id="软件危机的原因"><a href="#软件危机的原因" class="headerlink" title="软件危机的原因"></a>软件危机的原因</h4><ol>
<li><p>用户需求不明确</p>
<p>用户在软件开发出来之前，自己也不清楚需求</p>
<p>用户对需求描述不清晰</p>
<p>在开发软件得过程中，用户修改需求</p>
<p>开发人员对需求得理解和用户的不一致</p>
</li>
<li><p>缺乏正确的理论指导</p>
</li>
<li><p>软件规模越来越大</p>
</li>
<li><p>软件复杂度越来越高</p>
</li>
</ol>
<h4 id="如何克服软件危机"><a href="#如何克服软件危机" class="headerlink" title="如何克服软件危机"></a>如何克服软件危机</h4><ul>
<li><p>技术问题、管理问题</p>
</li>
<li><p>软件工程包括三个要素：<u>方法</u>、<u>工具</u>和<u>过程</u></p>
<p>  方法指导软件技术怎么做</p>
<p>  工具为软件方法提供自动或者半自动的软件支撑环境</p>
<p>  过程将软件工程方法和软件工程工具合理结合</p>
</li>
</ul>
<h3 id="构件与软件重用"><a href="#构件与软件重用" class="headerlink" title="构件与软件重用"></a>构件与软件重用</h3><ul>
<li><p>软件重用是指在两次或多次不同的软件开发过程中重复使用相同或相近软件元素的过程。</p>
</li>
<li><p>软件元素包括<u>程序代码</u>、<u>测试用例</u>、<u>设计文档</u>、<u>设计过程</u>、<u>需求分析文档</u>甚至<u>领域知识</u></p>
</li>
<li><p>可重用的软件元素越大，称重用的粒度越大</p>
</li>
</ul>
<h4 id="构件模型及实现"><a href="#构件模型及实现" class="headerlink" title="构件模型及实现"></a>构件模型及实现</h4><ul>
<li><p>构件：语义完整、语法正确和有可重用价值的单位软件，是可以明确辨识的系统；结构上，它是语义描述、通信接口和实现代码的复合体。</p>
</li>
<li><p>构件模型</p>
<ol>
<li>CORBA：通用对象请求代理结构</li>
<li>EJB：Enterprise Java Bean</li>
<li>DCOM：分布式构件对象模型</li>
</ol>
</li>
</ul>
<h4 id="构件获取"><a href="#构件获取" class="headerlink" title="构件获取"></a>构件获取</h4><ul>
<li>建立基于构件的软件开发中，构件的获取途径<ol>
<li>现有构件<u>适应性修改</u></li>
<li>从<u>遗留工程</u>中获取</li>
<li><u>购买现成</u>的商业构件</li>
<li><u>开发</u>新的符合要求的构件</li>
</ol>
</li>
</ul>
<h4 id="构件管理"><a href="#构件管理" class="headerlink" title="构件管理"></a>构件管理</h4><ul>
<li><p>构建分类方法</p>
<ol>
<li>关键字分类法</li>
<li>刻面分类法</li>
<li>超文本组织方法</li>
</ol>
</li>
<li><p>构件有哪几种</p>
<ol>
<li>独立成熟的构件</li>
<li>有限制的构件</li>
<li>适应性构件</li>
<li>装配的构件</li>
<li>可修改的构件</li>
</ol>
</li>
<li><p>构件库系统的5类用户</p>
<ol>
<li>注册用户</li>
<li>公共用户</li>
<li>构建提交者</li>
<li>一般系统管理员</li>
<li>超级系统管理员</li>
</ol>
</li>
</ul>
<h4 id="构件重用"><a href="#构件重用" class="headerlink" title="构件重用"></a>构件重用</h4><ul>
<li><p>什么是构件组装<br>  将构件库中的构件做适应性修改并连接起来或者和当前开发项目的软件元素相连</p>
</li>
<li><p>构建组装</p>
<ol>
<li>基于<u>功能</u>的组装技术</li>
<li>基于<u>数据</u>的组装技术</li>
<li>基于<u>对象</u>的组装技术</li>
</ol>
</li>
</ul>
<h4 id="软件重用实例"><a href="#软件重用实例" class="headerlink" title="软件重用实例"></a>软件重用实例</h4><ul>
<li><p>软件重用分为哪几种重用</p>
<ol>
<li>需求重用</li>
<li>设计重用</li>
<li>代码重新</li>
<li>组织结构重用</li>
</ol>
</li>
<li><p>设计重用</p>
<ol>
<li>系统构建层：Java JDK类库</li>
<li>通用类构件层：工作流平台核心模块、组织管理模块、系统管理模块、页面风格函数、JSP的CSS JS等字符串处理、数据库连接、通用打印和查询、权限验证和日期处理等与业务逻辑无关的类</li>
<li>业务构件层：满足不同业务需求而设计的软件包（明确接口、大粒度构建重用）</li>
<li>表现层：JSP、Serverlet页面（只调用来展现业务流程界面）</li>
</ol>
</li>
<li><p>组织重用中包含了什么组织，各组织的功能是什么</p>
<ol>
<li>构建开发组：负责接受并分析来自协调层的构件设计规格说明</li>
<li>构建应用组：负责设计和实现构件逻辑</li>
<li>协调组：负责协调构件开发层和构件应用层，接受并分析来自构件应用层的构件需求</li>
</ol>
</li>
</ul>
<h3 id="软件体系结构的兴起和发展"><a href="#软件体系结构的兴起和发展" class="headerlink" title="软件体系结构的兴起和发展"></a>软件体系结构的兴起和发展</h3><h4 id="软件体系结构的定义"><a href="#软件体系结构的定义" class="headerlink" title="软件体系结构的定义"></a>软件体系结构的定义</h4><ul>
<li><p>软件体系结构为软件系统提供了一个<u>结构</u>、<u>行为</u>和<u>属性</u>的<u>高级抽象</u>，由构成系统的元素的<u>描述</u>、这些元素的<u>相互作用</u>、指导元素集成的<u>模式</u>以及这些模式的<u>约束</u>组成。</p>
</li>
<li><p>软件体系结构不仅指定了系统的<u>组织结构</u>和<u>拓扑结构</u>，并且显示了系统需求和构成系统的元素之间的对应关系，提供了一些<u>设计决策</u>的基本原理。</p>
</li>
</ul>
<h4 id="软件体系结构的意义"><a href="#软件体系结构的意义" class="headerlink" title="软件体系结构的意义"></a>软件体系结构的意义</h4><ol>
<li><p>体系结构是风险承担者进行交流的手段</p>
</li>
<li><p>体系结构是早期设计决策的体现</p>
<p> 软件体系结构明确了对系统实现的约束条件</p>
<p> 软件体系结构决定了开发和维护组织的组织结构</p>
<p> 软件体系结构制约着系统的质量属性</p>
<p> 通过研究软件体系结构可能预测软件的质量</p>
<p> 软件体系机构使推理和控制更改更简单</p>
<p> 软件体系结构有助于循序渐进的原型设计</p>
<p> 软件体系结构可以作为培训的基础</p>
</li>
<li><p>软件体系结构是可传递和可重用的模型</p>
</li>
</ol>
<h4 id="软件体系结构的发展史"><a href="#软件体系结构的发展史" class="headerlink" title="软件体系结构的发展史"></a>软件体系结构的发展史</h4><ul>
<li>软件体系结构的发展经历了哪几个阶段<ol>
<li>无体系设计阶段：以汇编语言进行小规模开发为特征</li>
<li>萌芽阶段：出现程序结构设计主题，以控制流图和数据流图构成软件结构为特征</li>
<li>初期阶段：出现从不同侧面描述系统的结构模型，以UML为典型代表</li>
<li>高级阶段：以描述系统的高层抽象结构为中心，不关心具体建模细节，划分了体系结构模型和传统软件结构的界限，以“4+1”模型为标志</li>
</ol>
</li>
</ul>
<h2 id="第2章-软件体系结构建模"><a href="#第2章-软件体系结构建模" class="headerlink" title="*第2章 软件体系结构建模"></a>*第2章 软件体系结构建模</h2><ul>
<li><p>软件体系结构模型有哪几种</p>
<ol>
<li><p>结构模型</p>
</li>
<li><p>过程模型</p>
</li>
<li><p>框架模型</p>
</li>
<li><p>功能模型</p>
</li>
<li><p>动态模型</p>
<p>最常用的是结构模型和动态模型</p>
</li>
</ol>
</li>
</ul>
<h3 id="“4-1”视图模型"><a href="#“4-1”视图模型" class="headerlink" title="“4+1”视图模型"></a>“4+1”视图模型</h3><ul>
<li>“4+1”视图模型有哪几个视图，功能分别是什么<ol>
<li>逻辑视图（静态）：支持系统的服务</li>
<li>开发视图（静态）：对软件模块进行组织和管理</li>
<li>进程视图（动态）：关注系统的运行特性，支持系统的非功能性</li>
<li>物理视图（动态）：考虑如何将软件映射到硬件上</li>
<li>场景视图</li>
</ol>
</li>
</ul>
<h4 id="逻辑视图"><a href="#逻辑视图" class="headerlink" title="逻辑视图"></a>逻辑视图</h4><ul>
<li>通过抽象、封装和继承，可以用对象模型来代表逻辑视图</li>
</ul>
<h4 id="开发视图"><a href="#开发视图" class="headerlink" title="开发视图"></a>开发视图</h4><h4 id="进程视图"><a href="#进程视图" class="headerlink" title="进程视图"></a>进程视图</h4><h4 id="物理视图"><a href="#物理视图" class="headerlink" title="物理视图"></a>物理视图</h4><h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><ul>
<li>场景的定义：重要的系统活动的抽象</li>
</ul>
<h3 id="软件体系结构的核心模型"><a href="#软件体系结构的核心模型" class="headerlink" title="软件体系结构的核心模型"></a>软件体系结构的核心模型</h3><ul>
<li><p>体系结构的核心模型有哪五种元素，基本元素是什么</p>
<ol>
<li><p>构件：是具有某种功能的可重用的软件模板单元，表示了系统中的计算元素和数据储存</p>
</li>
<li><p>配置：表示构件和连接件之间的拓扑逻辑和约束</p>
</li>
<li><p>连接件：表示了构件之间的交互</p>
</li>
<li><p>端口</p>
</li>
<li><p>角色</p>
<p>基本元素是：构件、配置、连接件</p>
</li>
</ol>
</li>
<li><p>构件分为哪两种</p>
<p>  原子构件和复合构件。复合构件由原子构件和其他复合构件组成</p>
</li>
</ul>
<h3 id="软件体系结构的生命周期模型"><a href="#软件体系结构的生命周期模型" class="headerlink" title="软件体系结构的生命周期模型"></a>软件体系结构的生命周期模型</h3><ul>
<li><p>软件体系结构建立在什么时候</p>
<p>  建立在需求分析之后，软件设计之前</p>
</li>
</ul>
<h4 id="各阶段之间的关系"><a href="#各阶段之间的关系" class="headerlink" title="各阶段之间的关系"></a>各阶段之间的关系</h4><ol>
<li>需求分析阶段</li>
<li>建立软件体系结构阶段</li>
<li>设计阶段</li>
<li>实现阶段</li>
</ol>
<h4 id="软件体系结构的生命周期"><a href="#软件体系结构的生命周期" class="headerlink" title="软件体系结构的生命周期"></a>软件体系结构的生命周期</h4><ol>
<li>软件体系结构的非形式描述</li>
<li>软件体系结构的规范描述和设计</li>
<li>软件体系结构的精化及其验证</li>
<li>软件体系结构的实施</li>
<li>软件体系结构的演化和扩展</li>
<li>软件体系结构的提供，评估和度量</li>
<li>软件体系结构的终结</li>
</ol>
<h2 id="第3章-软件体系结构风格"><a href="#第3章-软件体系结构风格" class="headerlink" title="*第3章 软件体系结构风格"></a>*第3章 软件体系结构风格</h2><ul>
<li><p>什么是软件体系结构风格</p>
<p>  描述在一种特定应用领域中系统设计的惯用模式</p>
</li>
</ul>
<h3 id="经典软件体系结构风格"><a href="#经典软件体系结构风格" class="headerlink" title="经典软件体系结构风格"></a>经典软件体系结构风格</h3><ol>
<li>数据流风格：批处理序列、管道与过滤器</li>
<li>调用返回风格：主程序与子程序、面向对象风格、层次结构</li>
<li>独立构件风格：进程通信、事件系统</li>
<li>虚拟机风格：解释器、基于规则的系统</li>
<li>仓库风格：数据库系统、超文本系统、黑板系统</li>
</ol>
<h4 id="管道与过滤器"><a href="#管道与过滤器" class="headerlink" title="管道与过滤器"></a>管道与过滤器</h4><ul>
<li><p>优点</p>
<ol>
<li>软件具有很高的隐蔽性和具有高内聚，低耦合的特点</li>
<li>方便设计师将整个系统的输入或输出看成是多个过滤器的行为的简单合成</li>
<li>支持重用</li>
<li>系统维护和增强系统性能简单</li>
<li>允许对一些属性分析</li>
<li>支持并行执行</li>
</ol>
</li>
<li><p>缺点</p>
<ol>
<li>使进程成为批处理的结构</li>
<li>不适合处理交互的应用</li>
<li>没有统一的数据传输标准，过滤器需要增加数据分析和合成的工作，降低了系统的性能，增加了编写过滤器的复杂度</li>
</ol>
</li>
</ul>
<h4 id="数据抽象和面向对象系统"><a href="#数据抽象和面向对象系统" class="headerlink" title="数据抽象和面向对象系统"></a>数据抽象和面向对象系统</h4><ul>
<li><p>优点</p>
<ol>
<li>对象对于其他对象的表示是隐藏的，一个对象的表示的改变不影响其他对象</li>
<li>设计师可以将一些数据的存取问题拆解为一些交互的代理程序的集合</li>
</ol>
</li>
<li><p>缺点</p>
<ol>
<li>一个对象和另外一个对象通过过程调用等进行交互，必须知道对象的标识</li>
<li>必须修改所有显式调用它的其他对象，并消除由此带来的副作用</li>
</ol>
</li>
</ul>
<h4 id="基于事件的系统（隐式调用）"><a href="#基于事件的系统（隐式调用）" class="headerlink" title="基于事件的系统（隐式调用）"></a>基于事件的系统（隐式调用）</h4><ul>
<li><p>优点</p>
<ol>
<li>为软件重用带来强大的支持</li>
<li>方便改进系统</li>
</ol>
</li>
<li><p>缺点</p>
<ol>
<li>构件放弃了系统计算的控制</li>
<li>数据交换存在问题</li>
<li>对于正确性的推理存在问题</li>
</ol>
</li>
</ul>
<h4 id="分层系统（层次系统风格）"><a href="#分层系统（层次系统风格）" class="headerlink" title="分层系统（层次系统风格）"></a>分层系统（层次系统风格）</h4><ul>
<li><p>优点</p>
<ol>
<li>支持软件重用</li>
<li>支持基于抽象程度递增的系统设计</li>
<li>支持功能增强</li>
</ol>
</li>
<li><p>缺点</p>
<ol>
<li>不是所有系统都能轻易划分为分层的模式</li>
<li>难以找到合适，正确的层次抽象方法</li>
</ol>
</li>
</ul>
<h4 id="仓库系统及知识库（黑板系统）"><a href="#仓库系统及知识库（黑板系统）" class="headerlink" title="仓库系统及知识库（黑板系统）"></a>仓库系统及知识库（黑板系统）</h4><ul>
<li>黑板系统的组成：知识源、黑板数据结构、控制</li>
</ul>
<h4 id="C2风格"><a href="#C2风格" class="headerlink" title="C2风格"></a>C2风格</h4><ul>
<li>C2风格的特点<ol>
<li>构件都可以实现需求应用，能将任意复杂度的功能封装</li>
<li>构件较为独立，构件之间依赖性少</li>
<li>构件之间的通信是通过以连接件作为中介的异步消息交换机制来实现的</li>
</ol>
</li>
</ul>
<h3 id="客户-服务器风格"><a href="#客户-服务器风格" class="headerlink" title="客户/服务器风格"></a>客户/服务器风格</h3><ul>
<li><p>服务器的任务</p>
<ol>
<li>数据库的安全性要求</li>
<li>数据库访问并发性的控制</li>
<li>数据库前端的客户应用程序的全局数据完整规则</li>
<li>数据库的备份与恢复</li>
</ol>
</li>
<li><p>客户应用程序的任务</p>
<ol>
<li>提供数据库与用户交互的界面</li>
<li>向数据库服务器提交用户请求和接收数据库服务器的信息</li>
<li>利用客户应用程序来对存于客户端的数据执行应用逻辑</li>
</ol>
</li>
<li><p>C/S体系结构的优缺点</p>
<p>  优点</p>
<ol>
<li><p>前后端分离</p>
</li>
<li><p>将大量的处理任务分布在客户机上，减少了花费</p>
<p>缺点</p>
</li>
<li><p>开发成本高</p>
</li>
<li><p>消息内容和形式单一</p>
</li>
<li><p>客户端程序设计复杂</p>
</li>
<li><p>界面风格不一，使用繁杂，难以推广</p>
</li>
<li><p>软件维护和升级困难</p>
</li>
<li><p>软件移植困难</p>
</li>
<li><p>不能轻易使用新技术</p>
</li>
</ol>
</li>
</ul>
<h3 id="三层C-S结构风格"><a href="#三层C-S结构风格" class="headerlink" title="三层C/S结构风格"></a>三层C/S结构风格</h3><ul>
<li>2层cs体系结构的局限性<ol>
<li>只有一个服务器和以局域网为核心，难以扩展至大型企业广域网和internet</li>
<li>软硬件的组合和集成能力有限</li>
<li>数据安全性不好</li>
<li>客户机负荷太重，难以管理大量的客户机，系统的性能容易变坏</li>
</ol>
</li>
</ul>
<h4 id="各层的功能"><a href="#各层的功能" class="headerlink" title="各层的功能"></a>各层的功能</h4><ol>
<li><p>表示层</p>
<p>功能：提供应用中的用户接口，负担用户和应用的对话功能</p>
</li>
<li><p>功能层</p>
<p>功能：将具体的业务处理逻辑编写到程序中</p>
</li>
<li><p>数据层</p>
<p>功能：管理数据库数据的读写</p>
</li>
</ol>
<h4 id="三层C-S结构应用实例"><a href="#三层C-S结构应用实例" class="headerlink" title="三层C/S结构应用实例"></a>三层C/S结构应用实例</h4><h4 id="三层C-S结构的优点"><a href="#三层C-S结构的优点" class="headerlink" title="三层C/S结构的优点"></a>三层C/S结构的优点</h4><ol>
<li>允许合理得划分三层结构的功能，使各层的逻辑相对独立</li>
<li>允许合理有效地选取相应地平台和硬件系统，使之在处理负荷能力和处理特性上适应划分的三层结构</li>
<li>各层可以并行开发，各层可以选自各自最适合的开发语言</li>
<li>利用功能层有效地隔离表示层和数据层，为严格的安全管理奠定基础。使整个系统层次更加合理和可控制</li>
</ol>
<h3 id="浏览-服务器风格"><a href="#浏览-服务器风格" class="headerlink" title="浏览/服务器风格"></a>浏览/服务器风格</h3><ul>
<li><p>优点：同三层C/S结构的优点</p>
</li>
<li><p>缺点</p>
<ol>
<li>对动态页面缺乏强力支持，没有集成的数据库处理功能</li>
<li>系统扩展能力差，安全性难以控制</li>
<li>采用bs结构，响应速度远低于采用cs结构</li>
<li>bs结构数据提交一般以页面为单位，缺乏数据动态交互性，不利已在线处理事务应用</li>
</ol>
</li>
</ul>
<h3 id="异构结构风格"><a href="#异构结构风格" class="headerlink" title="异构结构风格"></a>异构结构风格</h3><ul>
<li>C/S与B/S混合软件体系结构</li>
</ul>
<h4 id="异构结构的实例分析"><a href="#异构结构的实例分析" class="headerlink" title="异构结构的实例分析"></a>异构结构的实例分析</h4><ol>
<li>“内外有别”模型</li>
<li>“查改有别”模型</li>
</ol>
<h4 id="异构组合匹配问题"><a href="#异构组合匹配问题" class="headerlink" title="异构组合匹配问题"></a>异构组合匹配问题</h4><h2 id="第4章-软件体系结构描述"><a href="#第4章-软件体系结构描述" class="headerlink" title="第4章 软件体系结构描述"></a>第4章 软件体系结构描述</h2><h3 id="软件体系结构描述方法"><a href="#软件体系结构描述方法" class="headerlink" title="软件体系结构描述方法"></a>软件体系结构描述方法</h3><ul>
<li><p>软件体系结构的描述方法分为哪几种，学术界和产业界分别常用哪种</p>
<ol>
<li><p>图形表示工具</p>
</li>
<li><p>数学表示工具</p>
</li>
<li><p>文字表示工具</p>
<p>产业界常用图形表示工具，学术界常用数学表示工具</p>
</li>
</ol>
</li>
<li><p>软件体系结构的描述和表达方法有哪几种</p>
<ol>
<li>图形表示工具</li>
<li>模块内连接语言</li>
<li>基于软构件的系统描述语言</li>
<li>软件体系结构描述语言</li>
</ol>
</li>
</ul>
<h3 id="体系结构描述语言"><a href="#体系结构描述语言" class="headerlink" title="体系结构描述语言"></a>体系结构描述语言</h3><ul>
<li><p>体系结构描述语言ADL三个字母分别代表什么意思</p>
<p>  A:体系结构，D:描述，L:语言</p>
</li>
<li><p>ADL中的三个基本要素是什么</p>
<ol>
<li>构件：计算或数据存储单元</li>
<li>连接件：用于构件之间交互建模的体系结构构造块及其支配这些交互的规则</li>
<li>体系结构配置：描述体系结构的构件与连接件的连接图</li>
</ol>
</li>
</ul>
<h4 id="ADL与其他语言的比较"><a href="#ADL与其他语言的比较" class="headerlink" title="ADL与其他语言的比较"></a>ADL与其他语言的比较</h4><ul>
<li>ADL的能力<ol>
<li>构造能力</li>
<li>抽象能力</li>
<li>重用能力</li>
<li>组合能力</li>
<li>异构能力</li>
<li>分析和推理能力</li>
</ol>
</li>
</ul>
<h4 id="ADL的构成要素"><a href="#ADL的构成要素" class="headerlink" title="ADL的构成要素"></a>ADL的构成要素</h4><ol>
<li>构件</li>
<li>连接件</li>
<li>体系结构配置</li>
</ol>
<h3 id="典型的软件体系结构描述语言"><a href="#典型的软件体系结构描述语言" class="headerlink" title="典型的软件体系结构描述语言"></a>典型的软件体系结构描述语言</h3><h4 id="C2"><a href="#C2" class="headerlink" title="C2"></a>C2</h4><h2 id="第6章-可扩展标记语言"><a href="#第6章-可扩展标记语言" class="headerlink" title="第6章 可扩展标记语言"></a>第6章 可扩展标记语言</h2><ul>
<li><p>XML的定义和全称</p>
<p>  定义：XML是一套定义语义标记的规则</p>
<p>  全称：可扩展标记语言</p>
</li>
</ul>
<h3 id="XML概述"><a href="#XML概述" class="headerlink" title="XML概述"></a>XML概述</h3><ol>
<li>能直接应用在Internet上</li>
<li>能被各式应用软件使用</li>
<li>能与SGML兼容</li>
<li>能轻易发展XML相关软件</li>
<li>能简化SGML</li>
<li>XML文件可读性高</li>
<li>XML规范能尽快完成</li>
<li>XML规范必须简洁</li>
<li>XML文件易于建立</li>
<li>语法不可模糊不清</li>
</ol>
<h4 id="XML的特点"><a href="#XML的特点" class="headerlink" title="XML的特点"></a>XML的特点</h4><ol>
<li>简介有效</li>
<li>易学易用</li>
<li>开放的国际标准</li>
<li>高效且可扩充</li>
</ol>
<h4 id="XML的作用"><a href="#XML的作用" class="headerlink" title="XML的作用"></a>XML的作用</h4><ol>
<li>使得搜索更加有意义</li>
<li>开发灵活的Web应用软件</li>
<li>实现不同数据的集成</li>
<li>使用于多种应用环境</li>
<li>客户端数据处理与计算</li>
<li>数据显示多样化</li>
<li>局部数据更新</li>
<li>与现有Web发布机制相兼容</li>
<li>可升级性</li>
<li>压缩性能高</li>
</ol>
<h4 id="XML的应用"><a href="#XML的应用" class="headerlink" title="XML的应用"></a>XML的应用</h4><ol>
<li>应用于客户需要与不同的数据源进行交互时</li>
<li>应用于将大量运算负荷分布在客户端</li>
<li>应用于将同一数据以不同的面貌展现给不同的用户</li>
<li>应用于网络代理对所取得的信息进行编辑、增减以适应个人用户的需要</li>
</ol>
<h3 id="解析XML"><a href="#解析XML" class="headerlink" title="解析XML"></a>解析XML</h3><h4 id="XML与HTML的区别"><a href="#XML与HTML的区别" class="headerlink" title="XML与HTML的区别"></a>XML与HTML的区别</h4><ol>
<li>和HTML的区别：XML是元标记语言可以用于定义其他标记语言。XML是“纯”数据。</li>
<li>XSL是专门用于XML文档的样式单语言</li>
</ol>
<h4 id="XML文档"><a href="#XML文档" class="headerlink" title="XML文档"></a>XML文档</h4><h4 id="CSS与XML"><a href="#CSS与XML" class="headerlink" title="CSS与XML"></a>CSS与XML</h4><h2 id="第8章-基于服务的体系结构"><a href="#第8章-基于服务的体系结构" class="headerlink" title="*第8章 基于服务的体系结构"></a>*第8章 基于服务的体系结构</h2><ul>
<li>SOA全称：面向服务的体系结构(Service-Oriented Architecture)</li>
</ul>
<h3 id="SOA概述"><a href="#SOA概述" class="headerlink" title="SOA概述"></a>SOA概述</h3><ul>
<li><p>SOA定义：是一种在计算环境中设计，开发，部署和管理离散逻辑单元模型的方法</p>
</li>
<li><p>SOA的特征</p>
<ol>
<li>松散耦合</li>
<li>粗粒度服务</li>
<li>标准化接口</li>
</ol>
</li>
</ul>
<h3 id="面向服务的分析与设计"><a href="#面向服务的分析与设计" class="headerlink" title="面向服务的分析与设计"></a>面向服务的分析与设计</h3><ol>
<li>基础设计层</li>
<li>体系结构层</li>
<li>业务层</li>
</ol>
<ul>
<li>三个抽象级别：操作，服务和业务流程</li>
</ul>
<h3 id="SOA的关键技术"><a href="#SOA的关键技术" class="headerlink" title="SOA的关键技术"></a>SOA的关键技术</h3><ul>
<li><p>SOA的服务栈中包含哪几层，功能分别是</p>
<ol>
<li><p>发现服务层</p>
<p> 主要用来帮助客户端应用程序解析远程服务的位置</p>
</li>
<li><p>描述服务层</p>
<p> 为客户端应用程序提供正确地与远程服务交互的描述信息</p>
</li>
<li><p>消息格式层</p>
<p> 保证客户端应用程序和服务器端在格式设置上保持一致</p>
</li>
<li><p>编码格式层</p>
<p> 为客户端和服务器之间提供一个标准的、独立于平台的数据交换编码格式</p>
</li>
<li><p>传输协议层</p>
<p> 为客户端和服务器之间提供网络通信协议</p>
</li>
</ol>
</li>
</ul>
<h3 id="SOA的实现方法"><a href="#SOA的实现方法" class="headerlink" title="SOA的实现方法"></a>SOA的实现方法</h3><ol>
<li><p>Web Service</p>
<p> 三种工作角色：服务提供者、服务请求者和服务注册中心（可选）</p>
<p> Web Service模型中的操作包括发布、查找和绑定</p>
<ul>
<li>使用webservice方法时，应用系统分为哪几个层次<ol>
<li>底层传输层</li>
<li>服务通信层</li>
<li>服务描述层</li>
<li>服务层</li>
<li>业务流程层</li>
<li>服务注册层</li>
</ol>
</li>
</ul>
</li>
<li><p>服务注册表</p>
</li>
<li><p>ESB</p>
</li>
</ol>
<h3 id="服务描述语言"><a href="#服务描述语言" class="headerlink" title="服务描述语言"></a>服务描述语言</h3><h4 id="WSDL概述"><a href="#WSDL概述" class="headerlink" title="WSDL概述"></a>WSDL概述</h4><ul>
<li><p>WSDL(Web Services Description Language)是对服务进行描述的语言，它有一套基于XML的语法定义</p>
</li>
<li><p>WSDL子元素：types,message,operation,portType,binding,port,service</p>
</li>
</ul>
<h4 id="使用WSDL文档"><a href="#使用WSDL文档" class="headerlink" title="使用WSDL文档"></a>使用WSDL文档</h4><h4 id="WSDL文档结构"><a href="#WSDL文档结构" class="headerlink" title="WSDL文档结构"></a>WSDL文档结构</h4><h3 id="统一描述、发现和集成协议"><a href="#统一描述、发现和集成协议" class="headerlink" title="统一描述、发现和集成协议"></a>统一描述、发现和集成协议</h3><ul>
<li><p>UDDI(Universal Description Discovery and Integration*)是一种用户描述，发现，集成Web服务的技术，他是Web服务协议栈的一个重要部分。</p>
</li>
<li><p>UDDI技术规范中，包含的三个部分内容</p>
<ol>
<li>UDDI数据模型</li>
<li>UDDI API</li>
<li>UDDI注册服务</li>
</ol>
</li>
</ul>
<h4 id="UDDI数据模型"><a href="#UDDI数据模型" class="headerlink" title="UDDI数据模型"></a>UDDI数据模型</h4><ul>
<li>数据结构：businessEntity ,businessService ,bindingTemplate , tModel</li>
</ul>
<h4 id="注册Web服务"><a href="#注册Web服务" class="headerlink" title="注册Web服务"></a>注册Web服务</h4><h4 id="调用Web服务"><a href="#调用Web服务" class="headerlink" title="调用Web服务"></a>调用Web服务</h4><h3 id="消息封装协议"><a href="#消息封装协议" class="headerlink" title="消息封装协议"></a>消息封装协议</h3><ul>
<li>SOAP的定义</li>
</ul>
<p>​   SOAP（Simple Object Access Protocol）以XML形式提供一个简单，轻量的用于在分散或分布环境中交换结构化和类型信息的机制</p>
<ul>
<li>SOAP主要包括哪几个部分<ol>
<li>SOAP封装结构</li>
<li>SOAP编码规则</li>
<li>SOAP PRC表示</li>
<li>SOAP绑定</li>
</ol>
</li>
</ul>
<h4 id="消息封装和编码规则"><a href="#消息封装和编码规则" class="headerlink" title="消息封装和编码规则"></a>消息封装和编码规则</h4><ul>
<li><p>SOAP消息包括哪几个部分</p>
<ol>
<li>封装</li>
<li>SOAP头</li>
<li>SOAP体</li>
</ol>
</li>
<li><p>SOAP的编码规则</p>
<ol>
<li>值</li>
<li>简单值</li>
<li>复合值</li>
<li>数组</li>
<li>结构</li>
<li>简单类型</li>
<li>复合类型</li>
</ol>
</li>
</ul>
<h4 id="SOAP应用"><a href="#SOAP应用" class="headerlink" title="SOAP应用"></a>SOAP应用</h4><h4 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h4><h2 id="第9章-富互联网应用体系结构"><a href="#第9章-富互联网应用体系结构" class="headerlink" title="第9章 富互联网应用体系结构"></a>第9章 富互联网应用体系结构</h2><h3 id="RIA的概念"><a href="#RIA的概念" class="headerlink" title="RIA的概念"></a>RIA的概念</h3><ul>
<li>RIA的概念：RIA（Rich Internet Application）富互联网应用体系结构</li>
</ul>
<h4 id="RIA的提出"><a href="#RIA的提出" class="headerlink" title="RIA的提出"></a>RIA的提出</h4><ul>
<li>富：丰富的数据模型、丰富的用户界面</li>
</ul>
<h4 id="丰富的含义"><a href="#丰富的含义" class="headerlink" title="丰富的含义"></a>丰富的含义</h4><h4 id="RIA的优点"><a href="#RIA的优点" class="headerlink" title="RIA的优点"></a>RIA的优点</h4><h2 id="缩写"><a href="#缩写" class="headerlink" title="缩写"></a>缩写</h2><ul>
<li><p>ADL：软件体系结构描述语言</p>
</li>
<li><p>软件重用：指在两次或多次不同的软件开发过程中重复使用相同或相近软件元素的过程</p>
</li>
<li><p>场景：重要的系统活动的抽象</p>
</li>
<li><p>构件组装：将构件库中的构件做适应性修改并连接起来或者和当前开发项目的软件元素相连</p>
</li>
<li><p>XML：可扩展标记语言，是一套定义语义标记的规则</p>
</li>
<li><p>XSL：可扩展样式语言，是XML的应用</p>
</li>
<li><p>SOA：面向服务的体系结构,是一种在计算环境中设计，开发，部署和管理离散逻辑单元模型的方法</p>
</li>
<li><p>WSDL：对服务进行描述的语言，它有一套基于XML的语法定义</p>
</li>
<li><p>UDDI：是一种用户描述、发现、集成Web服务的技术，他是Web服务协议栈的一个重要部分</p>
</li>
<li><p>SOAP：消息封装协议，以XML形式提供一个简单，轻量的用于在分散或分布环境中交换结构化和类型信息的机制</p>
</li>
</ul>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐软件系统设计与体系结构</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-命令模式</title>
    <url>/9dfddb1f.html</url>
    <content><![CDATA[<h3 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h3><p>在软件开发系统中，“方法的请求者”与“方法的实现者”之间经常存在紧密的耦合关系，这不利于软件功能的扩展与维护。例如，想对方法进行“撤销、重做、记录”等处理都很不方便，因此“如何将方法的请求者与实现者解耦？”变得很重要，命令模式就能很好地解决这个问题。</p>
<p>在现实生活中，命令模式的例子也很多。比如看电视时，我们只需要轻轻一按遥控器就能完成频道的切换，这就是命令模式，将换台请求和换台处理完全解耦了。电视机遥控器（命令发送者）通过按钮（具体命令）来遥控电视机（命令接收者）。</p>
<p>再比如，我们去餐厅吃饭，菜单不是等到客人来了之后才定制的，而是已经预先配置好的。这样，客人来了就只需要点菜，而不是任由客人临时定制。餐厅提供的菜单就相当于把请求和处理进行了解耦，这就是命令模式的体现。</p>
<hr>
<span id="more"></span>

<h3 id="命令模式的定义与特点"><a href="#命令模式的定义与特点" class="headerlink" title="命令模式的定义与特点"></a>命令模式的定义与特点</h3><p><strong>命令（Command）模式的定义如下：</strong>将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。</p>
<p>命令模式的主要优点如下：</p>
<ol>
<li>通过引入中间件（抽象接口）降低系统的耦合度。</li>
<li>扩展性良好，增加或删除命令非常方便。采用命令模式增加与删除命令不会影响其他类，且满足“开闭原则”。</li>
<li>可以实现宏命令。命令模式可以与组合模式结合，将多个命令装配成一个组合命令，即宏命令。</li>
<li>方便实现 Undo 和 Redo 操作。命令模式可以与后面介绍的备忘录模式结合，实现命令的撤销与恢复。</li>
<li>可以在现有命令的基础上，增加额外功能。比如日志记录，结合装饰器模式会更加灵活。</li>
</ol>
<p>其缺点是：</p>
<ol>
<li>可能产生大量具体的命令类。因为每一个具体操作都需要设计一个具体命令类，这会增加系统的复杂性。</li>
<li>命令模式的结果其实就是接收方的执行结果，但是为了以命令的形式进行架构、解耦请求与实现，引入了额外类型结构（引入了请求方与抽象命令接口），增加了理解上的困难。不过这也是设计模式的通病，抽象必然会额外增加类的数量，代码抽离肯定比代码聚合更加难理解。</li>
</ol>
<hr>
<h3 id="命令模式的结构与实现"><a href="#命令模式的结构与实现" class="headerlink" title="命令模式的结构与实现"></a>命令模式的结构与实现</h3><p>可以将系统中的相关操作抽象成命令，使调用者与实现者相关分离，其结构如下。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>命令模式包含以下主要角色：</p>
<ol>
<li>抽象命令类（Command）角色：声明执行命令的接口，拥有执行命令的抽象方法 execute()。</li>
<li>具体命令类（Concrete Command）角色：是抽象命令类的具体实现类，它拥有接收者对象，并通过调用接收者的功能来完成命令要执行的操作。</li>
<li>实现者/接收者（Receiver）角色：执行命令功能的相关操作，是具体命令对象业务的真正实现者。</li>
<li>调用者/请求者（Invoker）角色：是请求的发送者，它通常拥有很多的命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者。</li>
</ol>
<img src="/9dfddb1f/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>命令模式的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> command;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CommandPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Command cmd = <span class="keyword">new</span> ConcreteCommand();</span><br><span class="line">        Invoker ir = <span class="keyword">new</span> Invoker(cmd);</span><br><span class="line">        System.out.println(<span class="string">&quot;客户访问调用者的call()方法...&quot;</span>);</span><br><span class="line">        ir.call();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 调用者</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Invoker</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Command command;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Invoker</span><span class="params">(Command command)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.command = command;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCommand</span><span class="params">(Command command)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.command = command;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;调用者执行命令command...&quot;</span>);</span><br><span class="line">        command.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象命令</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Command</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体命令</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteCommand</span> <span class="keyword">implements</span> <span class="title">Command</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Receiver receiver;</span><br><span class="line">    ConcreteCommand() &#123;</span><br><span class="line">        receiver = <span class="keyword">new</span> Receiver();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        receiver.action();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 接收者</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Receiver</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;接收者的action()方法被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">客户访问调用者的call()方法...</span><br><span class="line">调用者执行命令command...</span><br><span class="line">接收者的action()方法被调用...</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="命令模式的应用实例"><a href="#命令模式的应用实例" class="headerlink" title="命令模式的应用实例"></a>命令模式的应用实例</h3><h4 id="【例1】用命令模式实现客户去餐馆吃早餐的实例"><a href="#【例1】用命令模式实现客户去餐馆吃早餐的实例" class="headerlink" title="【例1】用命令模式实现客户去餐馆吃早餐的实例"></a>【例1】用命令模式实现客户去餐馆吃早餐的实例</h4><p>分析：客户去餐馆可选择的早餐有肠粉、河粉和馄饨等，客户可向服务员选择以上早餐中的若干种，服务员将客户的请求交给相关的厨师去做。这里的点早餐相当于“命令”，服务员相当于“调用者”，厨师相当于“接收者”，所以用命令模式实现比较合适。</p>
<ul>
<li>首先，定义一个早餐类（Breakfast），它是抽象命令类，有抽象方法 cooking()，说明要做什么；</li>
<li>再定义其子类肠粉类（ChangFen）、馄饨类（HunTun）和河粉类（HeFen），它们是具体命令类，实现早餐类的 cooking() 方法，但它们不会具体做，而是交给具体的厨师去做；</li>
<li>具体厨师类有肠粉厨师（ChangFenChef）、馄饨厨师（HunTunChef）和河粉厨师（HeFenChef），他们是命令的接收者。</li>
</ul>
<p>由于本实例要显示厨师做菜的效果图，所以把每个厨师类定义为 JFrame 的子类；最后，定义服务员类（Waiter），它接收客户的做菜请求，并发出做菜的命令。客户类是通过服务员类来点菜的。</p>
<img src="/9dfddb1f/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> command;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CookingCommand</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Breakfast food1 = <span class="keyword">new</span> ChangFen();</span><br><span class="line">        Breakfast food2 = <span class="keyword">new</span> HunTun();</span><br><span class="line">        Breakfast food3 = <span class="keyword">new</span> HeFen();</span><br><span class="line">        Waiter fwy = <span class="keyword">new</span> Waiter();</span><br><span class="line">        fwy.setChangFen(food1);<span class="comment">//设置肠粉菜单</span></span><br><span class="line">        fwy.setHunTun(food2);  <span class="comment">//设置河粉菜单</span></span><br><span class="line">        fwy.setHeFen(food3);   <span class="comment">//设置馄饨菜单</span></span><br><span class="line">        fwy.chooseChangFen();  <span class="comment">//选择肠粉</span></span><br><span class="line">        fwy.chooseHeFen();     <span class="comment">//选择河粉</span></span><br><span class="line">        fwy.chooseHunTun();    <span class="comment">//选择馄饨</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 调用者：服务员</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Waiter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Breakfast changFen, hunTun, heFen;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setChangFen</span><span class="params">(Breakfast f)</span> </span>&#123;</span><br><span class="line">        changFen = f;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setHunTun</span><span class="params">(Breakfast f)</span> </span>&#123;</span><br><span class="line">        hunTun = f;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setHeFen</span><span class="params">(Breakfast f)</span> </span>&#123;</span><br><span class="line">        heFen = f;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">chooseChangFen</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        changFen.cooking();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">chooseHunTun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        hunTun.cooking();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">chooseHeFen</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        heFen.cooking();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象命令：早餐</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Breakfast</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">cooking</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体命令：肠粉</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChangFen</span> <span class="keyword">implements</span> <span class="title">Breakfast</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ChangFenChef receiver;</span><br><span class="line">    ChangFen() &#123;</span><br><span class="line">        receiver = <span class="keyword">new</span> ChangFenChef();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cooking</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        receiver.cooking();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体命令：馄饨</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HunTun</span> <span class="keyword">implements</span> <span class="title">Breakfast</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> HunTunChef receiver;</span><br><span class="line">    HunTun() &#123;</span><br><span class="line">        receiver = <span class="keyword">new</span> HunTunChef();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cooking</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        receiver.cooking();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体命令：河粉</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HeFen</span> <span class="keyword">implements</span> <span class="title">Breakfast</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> HeFenChef receiver;</span><br><span class="line">    HeFen() &#123;</span><br><span class="line">        receiver = <span class="keyword">new</span> HeFenChef();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cooking</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        receiver.cooking();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 接收者：肠粉厨师</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChangFenChef</span> <span class="keyword">extends</span> <span class="title">JFrame</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    JLabel l = <span class="keyword">new</span> JLabel();</span><br><span class="line">    ChangFenChef() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;煮肠粉&quot;</span>);</span><br><span class="line">        l.setIcon(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/command/ChangFen.jpg&quot;</span>));</span><br><span class="line">        <span class="keyword">this</span>.add(l);</span><br><span class="line">        <span class="keyword">this</span>.setLocation(<span class="number">30</span>, <span class="number">30</span>);</span><br><span class="line">        <span class="keyword">this</span>.pack();</span><br><span class="line">        <span class="keyword">this</span>.setResizable(<span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cooking</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 接收者：馄饨厨师</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HunTunChef</span> <span class="keyword">extends</span> <span class="title">JFrame</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    JLabel l = <span class="keyword">new</span> JLabel();</span><br><span class="line">    HunTunChef() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;煮馄饨&quot;</span>);</span><br><span class="line">        l.setIcon(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/command/HunTun.jpg&quot;</span>));</span><br><span class="line">        <span class="keyword">this</span>.add(l);</span><br><span class="line">        <span class="keyword">this</span>.setLocation(<span class="number">350</span>, <span class="number">50</span>);</span><br><span class="line">        <span class="keyword">this</span>.pack();</span><br><span class="line">        <span class="keyword">this</span>.setResizable(<span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cooking</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 接收者：河粉厨师</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HeFenChef</span> <span class="keyword">extends</span> <span class="title">JFrame</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    JLabel l = <span class="keyword">new</span> JLabel();</span><br><span class="line">    HeFenChef() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;煮河粉&quot;</span>);</span><br><span class="line">        l.setIcon(<span class="keyword">new</span> ImageIcon(<span class="string">&quot;src/command/HeFen.jpg&quot;</span>));</span><br><span class="line">        <span class="keyword">this</span>.add(l);</span><br><span class="line">        <span class="keyword">this</span>.setLocation(<span class="number">200</span>, <span class="number">280</span>);</span><br><span class="line">        <span class="keyword">this</span>.pack();</span><br><span class="line">        <span class="keyword">this</span>.setResizable(<span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cooking</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如图所示：</p>
<img src="/9dfddb1f/3.jpg" class>

<hr>
<h3 id="命令模式的应用场景"><a href="#命令模式的应用场景" class="headerlink" title="命令模式的应用场景"></a>命令模式的应用场景</h3><p>当系统的某项操作具备命令语义，且命令实现不稳定（变化）时，可以通过命令模式解耦请求与实现。使用抽象命令接口使请求方的代码架构稳定，封装接收方具体命令的实现细节。接收方与抽象命令呈现弱耦合（内部方法无需一致），具备良好的扩展性。</p>
<p>命令模式通常适用于以下场景：</p>
<ol>
<li>请求调用者需要与请求接收者解耦时，命令模式可以使调用者和接收者不直接交互。</li>
<li>系统随机请求命令或经常增加、删除命令时，命令模式可以方便地实现这些功能。</li>
<li>当系统需要执行一组操作时，命令模式可以定义宏命令来实现该功能。</li>
<li>当系统需要支持命令的撤销（Undo）操作和恢复（Redo）操作时，可以将命令对象存储起来，采用备忘录模式来实现。</li>
</ol>
<hr>
<h3 id="命令模式的扩展"><a href="#命令模式的扩展" class="headerlink" title="命令模式的扩展"></a>命令模式的扩展</h3><p>在软件开发中，有时将命令模式与前面学的组合模式联合使用，这就构成了宏命令模式，也叫组合命令模式。宏命令包含了一组命令，它充当了具体命令与调用者的双重角色，执行它时将递归调用它所包含的所有命令，其具体结构图如图所示。</p>
<img src="/9dfddb1f/4.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> command;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CompositeCommandPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        AbstractCommand cmd1 = <span class="keyword">new</span> ConcreteCommand1();</span><br><span class="line">        AbstractCommand cmd2 = <span class="keyword">new</span> ConcreteCommand2();</span><br><span class="line">        CompositeInvoker ir = <span class="keyword">new</span> CompositeInvoker();</span><br><span class="line">        ir.add(cmd1);</span><br><span class="line">        ir.add(cmd2);</span><br><span class="line">        System.out.println(<span class="string">&quot;客户访问调用者的execute()方法...&quot;</span>);</span><br><span class="line">        ir.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象命令</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">AbstractCommand</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 树叶构件: 具体命令1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteCommand1</span> <span class="keyword">implements</span> <span class="title">AbstractCommand</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> CompositeReceiver receiver;</span><br><span class="line">    ConcreteCommand1() &#123;</span><br><span class="line">        receiver = <span class="keyword">new</span> CompositeReceiver();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        receiver.action1();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 树叶构件: 具体命令2</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteCommand2</span> <span class="keyword">implements</span> <span class="title">AbstractCommand</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> CompositeReceiver receiver;</span><br><span class="line">    ConcreteCommand2() &#123;</span><br><span class="line">        receiver = <span class="keyword">new</span> CompositeReceiver();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        receiver.action2();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 树枝构件: 调用者</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CompositeInvoker</span> <span class="keyword">implements</span> <span class="title">AbstractCommand</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;AbstractCommand&gt; children = <span class="keyword">new</span> ArrayList&lt;AbstractCommand&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(AbstractCommand c)</span> </span>&#123;</span><br><span class="line">        children.add(c);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(AbstractCommand c)</span> </span>&#123;</span><br><span class="line">        children.remove(c);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> AbstractCommand <span class="title">getChild</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> children.get(i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Object obj : children) &#123;</span><br><span class="line">            ((AbstractCommand) obj).execute();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 接收者</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CompositeReceiver</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;接收者的action1()方法被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;接收者的action2()方法被调用...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">客户访问调用者的execute()方法...</span><br><span class="line">接收者的action1()方法被调用...</span><br><span class="line">接收者的action2()方法被调用...</span><br></pre></td></tr></table></figure>

<p>当然，命令模式还可以同备忘录（Memento）模式组合使用，这样就变成了可撤销的命令模式，这将在后面介绍。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1380.html">http://c.biancheng.net/view/1380.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-责任链模式</title>
    <url>/3bb92173.html</url>
    <content><![CDATA[<h3 id="责任链模式（职责链模式）"><a href="#责任链模式（职责链模式）" class="headerlink" title="责任链模式（职责链模式）"></a>责任链模式（职责链模式）</h3><p>在现实生活中，一个事件需要经过多个对象处理是很常见的场景。例如，采购审批流程、请假流程等。公司员工请假，可批假的领导有部门负责人、副总经理、总经理等，但每个领导能批准的天数不同，员工必须根据需要请假的天数去找不同的领导签名，也就是说员工必须记住每个领导的姓名、电话和地址等信息，这无疑增加了难度。</p>
<p>在计算机软硬件中也有相关例子，如总线网中数据报传送，每台计算机根据目标地址是否同自己的地址相同来决定是否接收；还有异常处理中，处理程序根据异常的类型决定自己是否处理该异常；还有 Struts2 的拦截器、JSP 和 Servlet 的 Filter 等，所有这些，都可以考虑使用责任链模式来实现。</p>
<hr>
<span id="more"></span>

<h3 id="责任链模式的定义与特点"><a href="#责任链模式的定义与特点" class="headerlink" title="责任链模式的定义与特点"></a>责任链模式的定义与特点</h3><p><strong>责任链（Chain of Responsibility）模式的定义：</strong>为了避免请求发送者与多个请求处理者耦合在一起，于是将所有请求的处理者通过前一对象记住其下一个对象的引用而连成一条链；当有请求发生时，可将请求沿着这条链传递，直到有对象处理它为止。</p>
<p>注意：责任链模式也叫职责链模式。</p>
<p>在责任链模式中，客户只需要将请求发送到责任链上即可，无须关心请求的处理细节和请求的传递过程，请求会自动进行传递。所以责任链将请求的发送者和请求的处理者解耦了。</p>
<p>责任链模式是一种对象行为型模式，其主要优点如下：</p>
<ol>
<li>降低了对象之间的耦合度。该模式使得一个对象无须知道到底是哪一个对象处理其请求以及链的结构，发送者和接收者也无须拥有对方的明确信息。</li>
<li>增强了系统的可扩展性。可以根据需要增加新的请求处理类，满足开闭原则。</li>
<li>增强了给对象指派职责的灵活性。当工作流程发生变化，可以动态地改变链内的成员或者调动它们的次序，也可动态地新增或者删除责任。</li>
<li>责任链简化了对象之间的连接。每个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的 if 或者 if···else 语句。</li>
<li>责任分担。每个类只需要处理自己该处理的工作，不该处理的传递给下一个对象完成，明确各类的责任范围，符合类的单一职责原则。</li>
</ol>
<p>其主要缺点如下：</p>
<ol>
<li>不能保证每个请求一定被处理。由于一个请求没有明确的接收者，所以不能保证它一定会被处理，该请求可能一直传到链的末端都得不到处理。</li>
<li>对比较长的职责链，请求的处理可能涉及多个处理对象，系统性能将受到一定影响。</li>
<li>职责链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于职责链的错误设置而导致系统出错，如可能会造成循环调用。</li>
</ol>
<hr>
<h3 id="模式的结构与实现"><a href="#模式的结构与实现" class="headerlink" title="模式的结构与实现"></a>模式的结构与实现</h3><p>通常情况下，可以通过数据链表来实现职责链模式的数据结构。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>职责链模式主要包含以下角色：</p>
<ol>
<li>抽象处理者（Handler）角色：定义一个处理请求的接口，包含抽象处理方法和一个后继连接。</li>
<li>具体处理者（Concrete Handler）角色：实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者。</li>
<li>客户类（Client）角色：创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。</li>
</ol>
<p>责任链模式的本质是解耦请求与处理，让请求在处理链中能进行传递与被处理；理解责任链模式应当理解其模式，而不是其具体实现。责任链模式的独到之处是将其节点处理者组合成了链式结构，并允许节点自身决定是否进行请求处理或转发，相当于让请求流动起来。</p>
<img src="/3bb92173/1.gif" class>

<img src="/3bb92173/2.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>职责链模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> chainOfResponsibility;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ChainOfResponsibilityPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 组装责任链</span></span><br><span class="line">        Handler handler1 = <span class="keyword">new</span> ConcreteHandler1();</span><br><span class="line">        Handler handler2 = <span class="keyword">new</span> ConcreteHandler2();</span><br><span class="line">        handler1.setNext(handler2);</span><br><span class="line">        <span class="comment">// 提交请求</span></span><br><span class="line">        handler1.handleRequest(<span class="string">&quot;two&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象处理者角色</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Handler</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Handler next;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setNext</span><span class="params">(Handler next)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.next = next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Handler <span class="title">getNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 处理请求的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(String request)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体处理者角色1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteHandler1</span> <span class="keyword">extends</span> <span class="title">Handler</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(String request)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (request.equals(<span class="string">&quot;one&quot;</span>)) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;具体处理者1负责处理该请求！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (getNext() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                getNext().handleRequest(request);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;没有人处理该请求！&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体处理者角色2</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteHandler2</span> <span class="keyword">extends</span> <span class="title">Handler</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(String request)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (request.equals(<span class="string">&quot;two&quot;</span>)) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;具体处理者2负责处理该请求！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (getNext() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                getNext().handleRequest(request);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;没有人处理该请求！&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体处理者2负责处理该请求！</span><br></pre></td></tr></table></figure>

<p>在上面代码中，我们把消息硬编码为 String 类型，而在真实业务中，消息是具备多样性的，可以是 int、String 或者自定义类型。因此，在上面代码的基础上，可以对消息类型进行抽象 Request，增强了消息的兼容性。</p>
<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】用责任链模式设计一个请假条审批模块"><a href="#【例1】用责任链模式设计一个请假条审批模块" class="headerlink" title="【例1】用责任链模式设计一个请假条审批模块"></a>【例1】用责任链模式设计一个请假条审批模块</h4><p>分析：假如规定学生请假小于或等于 2 天，班主任可以批准；小于或等于 7 天，系主任可以批准；小于或等于 10 天，院长可以批准；其他情况不予批准；这个实例适合使用职责链模式实现。</p>
<p>首先，定义一个领导类（Leader），它是抽象处理者，包含了一个指向下一位领导的指针 next 和一个处理假条的抽象处理方法 handleRequest(int LeaveDays)；然后，定义班主任类（ClassAdviser）、系主任类（DepartmentHead）和院长类（Dean），它们是抽象处理者的子类，是具体处理者，必须根据自己的权力去实现父类的 handleRequest(int LeaveDays) 方法，如果无权处理就将假条交给下一位具体处理者，直到最后；客户类负责创建处理链，并将假条交给链头的具体处理者（班主任）。</p>
<img src="/3bb92173/3.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> chainOfResponsibility;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LeaveApprovalTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 组装责任链</span></span><br><span class="line">        Leader teacher1 = <span class="keyword">new</span> ClassAdviser();</span><br><span class="line">        Leader teacher2 = <span class="keyword">new</span> DepartmentHead();</span><br><span class="line">        Leader teacher3 = <span class="keyword">new</span> Dean();</span><br><span class="line">        <span class="comment">// Leader teacher4=new DeanOfStudies();</span></span><br><span class="line">        teacher1.setNext(teacher2);</span><br><span class="line">        teacher2.setNext(teacher3);</span><br><span class="line">        <span class="comment">// teacher3.setNext(teacher4);</span></span><br><span class="line">        <span class="comment">// 提交请求</span></span><br><span class="line">        teacher1.handleRequest(<span class="number">8</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象处理者：领导类</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Leader</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Leader next;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setNext</span><span class="params">(Leader next)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.next = next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Leader <span class="title">getNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 处理请求的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(<span class="keyword">int</span> LeaveDays)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体处理者1：班主任类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassAdviser</span> <span class="keyword">extends</span> <span class="title">Leader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(<span class="keyword">int</span> LeaveDays)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (LeaveDays &lt;= <span class="number">2</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;班主任批准您请假&quot;</span> + LeaveDays + <span class="string">&quot;天。&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (getNext() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                getNext().handleRequest(LeaveDays);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;请假天数太多，没有人批准该假条！&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体处理者2：系主任类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DepartmentHead</span> <span class="keyword">extends</span> <span class="title">Leader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(<span class="keyword">int</span> LeaveDays)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (LeaveDays &lt;= <span class="number">7</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;系主任批准您请假&quot;</span> + LeaveDays + <span class="string">&quot;天。&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (getNext() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                getNext().handleRequest(LeaveDays);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;请假天数太多，没有人批准该假条！&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体处理者3：院长类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dean</span> <span class="keyword">extends</span> <span class="title">Leader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(<span class="keyword">int</span> LeaveDays)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (LeaveDays &lt;= <span class="number">10</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;院长批准您请假&quot;</span> + LeaveDays + <span class="string">&quot;天。&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (getNext() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                getNext().handleRequest(LeaveDays);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;请假天数太多，没有人批准该假条！&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体处理者4：教务处长类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeanOfStudies</span> <span class="keyword">extends</span> <span class="title">Leader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(<span class="keyword">int</span> LeaveDays)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (LeaveDays &lt;= <span class="number">20</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;教务处长批准您请假&quot;</span> + LeaveDays + <span class="string">&quot;天。&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (getNext() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                getNext().handleRequest(LeaveDays);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;请假天数太多，没有人批准该假条！&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">院长批准您请假8天。</span><br></pre></td></tr></table></figure>

<p>假如增加一个教务处长类，可以批准学生请假 20 天，也非常简单，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 具体处理者4:教务处长类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeanOfStudies</span> <span class="keyword">extends</span> <span class="title">Leader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleRequest</span><span class="params">(<span class="keyword">int</span> LeaveDays)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (LeaveDays &lt;= <span class="number">20</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;教务处长批准您请假&quot;</span> + LeaveDays + <span class="string">&quot;天。&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (getNext() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                getNext().handleRequest(LeaveDays);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;请假天数太多，没有人批准该假条！&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>前边已经讲述了关于责任链模式的结构与特点，下面介绍其应用场景，责任链模式通常在以下几种情况使用：</p>
<ol>
<li>多个对象可以处理一个请求，但具体由哪个对象处理该请求在运行时自动确定。</li>
<li>可动态指定一组对象处理请求，或添加新的处理者。</li>
<li>需要在不明确指定请求处理者的情况下，向多个处理者中的一个提交请求。</li>
</ol>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>职责链模式存在以下两种情况：</p>
<ol>
<li>纯的职责链模式：一个请求必须被某一个处理者对象所接收，且一个具体处理者对某个请求的处理只能采用以下两种行为之一：自己处理（承担责任）；把责任推给下家处理。</li>
<li>不纯的职责链模式：允许出现某一个具体处理者对象在承担了请求的一部分责任后又将剩余的责任传给下家的情况，且一个请求可以最终不被任何接收端对象所接收。</li>
</ol>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1383.html">http://c.biancheng.net/view/1383.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-状态模式</title>
    <url>/6f258c6e.html</url>
    <content><![CDATA[<h3 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h3><p>在软件开发过程中，应用程序中的部分对象可能会根据不同的情况做出不同的行为，我们把这种对象称为有状态的对象，而把影响对象行为的一个或多个动态变化的属性称为状态。当有状态的对象与外部事件产生互动时，其内部状态就会发生改变，从而使其行为也发生改变。如人都有高兴和伤心的时候，不同的情绪有不同的行为，当然外界也会影响其情绪变化。</p>
<p>对这种有状态的对象编程，传统的解决方案是：将这些所有可能发生的情况全都考虑到，然后使用 if-else 或 switch-case 语句来做状态判断，再进行不同情况的处理。但是显然这种做法对复杂的状态判断存在天然弊端，条件判断语句会过于臃肿，可读性差，且不具备扩展性，维护难度也大。且增加新的状态时要添加新的 if-else 语句，这违背了“开闭原则”，不利于程序的扩展。</p>
<p>以上问题如果采用“状态模式”就能很好地得到解决。状态模式的解决思想是：当控制一个对象状态转换的条件表达式过于复杂时，把相关“判断逻辑”提取出来，用各个不同的类进行表示，系统处于哪种情况，直接使用相应的状态类对象进行处理，这样能把原来复杂的逻辑判断简单化，消除了 if-else、switch-case 等冗余语句，代码更有层次性，并且具备良好的扩展力。</p>
<hr>
<span id="more"></span>

<h3 id="状态模式的定义与特点"><a href="#状态模式的定义与特点" class="headerlink" title="状态模式的定义与特点"></a>状态模式的定义与特点</h3><p><strong>状态（State）模式的定义：</strong>对有状态的对象，把复杂的“判断逻辑”提取到不同的状态对象中，允许状态对象在其内部状态发生改变时改变其行为。</p>
<p>状态模式是一种对象行为型模式，其主要优点如下：</p>
<ol>
<li>结构清晰，状态模式将与特定状态相关的行为局部化到一个状态中，并且将不同状态的行为分割开来，满足“单一职责原则”。</li>
<li>将状态转换显示化，减少对象间的相互依赖。将不同的状态引入独立的对象中会使得状态转换变得更加明确，且减少对象间的相互依赖。</li>
<li>状态类职责明确，有利于程序的扩展。通过定义新的子类很容易地增加新的状态和转换。</li>
</ol>
<p>状态模式的主要缺点如下：</p>
<ol>
<li>状态模式的使用必然会增加系统的类与对象的个数。</li>
<li>状态模式的结构与实现都较为复杂，如果使用不当会导致程序结构和代码的混乱。</li>
<li>状态模式对开闭原则的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源码，否则无法切换到新增状态，而且修改某个状态类的行为也需要修改对应类的源码。</li>
</ol>
<hr>
<h3 id="状态模式的结构与实现"><a href="#状态模式的结构与实现" class="headerlink" title="状态模式的结构与实现"></a>状态模式的结构与实现</h3><p>状态模式把受环境改变的对象行为包装在不同的状态对象里，其意图是让一个对象在其内部状态改变的时候，其行为也随之改变。现在我们来分析其基本结构和实现方法。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>状态模式包含以下主要角色：</p>
<ol>
<li>环境类（Context）角色：也称为上下文，它定义了客户端需要的接口，内部维护一个当前状态，并负责具体状态的切换。</li>
<li>抽象状态（State）角色：定义一个接口，用以封装环境对象中的特定状态所对应的行为，可以有一个或多个行为。</li>
<li>具体状态（Concrete State）角色：实现抽象状态所对应的行为，并且在需要的情况下进行状态切换。</li>
</ol>
<img src="/6f258c6e/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>状态模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StatePatternClient</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Context context = <span class="keyword">new</span> Context();    <span class="comment">//创建环境      </span></span><br><span class="line">        context.Handle();    <span class="comment">//处理请求</span></span><br><span class="line">        context.Handle();</span><br><span class="line">        context.Handle();</span><br><span class="line">        context.Handle();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 环境类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Context</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> State state;</span><br><span class="line">    <span class="comment">// 定义环境类的初始状态</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Context</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = <span class="keyword">new</span> ConcreteStateA();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 设置新状态</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(State state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 读取状态</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> State <span class="title">getState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (state);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 对请求做处理</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Handle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        state.Handle(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象状态类</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">State</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">Handle</span><span class="params">(Context context)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态A类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteStateA</span> <span class="keyword">extends</span> <span class="title">State</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Handle</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前状态是 A.&quot;</span>);</span><br><span class="line">        context.setState(<span class="keyword">new</span> ConcreteStateB());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态B类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteStateB</span> <span class="keyword">extends</span> <span class="title">State</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Handle</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前状态是 B.&quot;</span>);</span><br><span class="line">        context.setState(<span class="keyword">new</span> ConcreteStateA());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">当前状态是 A.</span><br><span class="line">当前状态是 B.</span><br><span class="line">当前状态是 A.</span><br><span class="line">当前状态是 B.</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="状态模式的应用实例"><a href="#状态模式的应用实例" class="headerlink" title="状态模式的应用实例"></a>状态模式的应用实例</h3><h4 id="【例1】用“状态模式”设计一个学生成绩的状态转换程序"><a href="#【例1】用“状态模式”设计一个学生成绩的状态转换程序" class="headerlink" title="【例1】用“状态模式”设计一个学生成绩的状态转换程序"></a>【例1】用“状态模式”设计一个学生成绩的状态转换程序</h4><p>分析：本实例包含了“不及格”“中等”和“优秀” 3 种状态，当学生的分数小于 60 分时为“不及格”状态，当分数大于等于 60 分且小于 90 分时为“中等”状态，当分数大于等于 90 分时为“优秀”状态，我们用状态模式来实现这个程序。</p>
<p>首先，定义一个抽象状态类（AbstractState），其中包含了环境属性、状态名属性和当前分数属性，以及加减分方法 addScore(intx) 和检查当前状态的抽象方法 checkState()。</p>
<p>然后，定义“不及格”状态类 LowState、“中等”状态类 MiddleState 和“优秀”状态类 HighState，它们是具体状态类，实现 checkState() 方法，负责检査自己的状态，并根据情况转换。</p>
<p>最后，定义环境类（ScoreContext），其中包含了当前状态对象和加减分的方法 add(int score)，客户类通过该方法来改变成绩状态。</p>
<img src="/6f258c6e/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScoreStateTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ScoreContext account = <span class="keyword">new</span> ScoreContext();</span><br><span class="line">        System.out.println(<span class="string">&quot;学生成绩状态测试：&quot;</span>);</span><br><span class="line">        account.add(<span class="number">30</span>);</span><br><span class="line">        account.add(<span class="number">40</span>);</span><br><span class="line">        account.add(<span class="number">25</span>);</span><br><span class="line">        account.add(-<span class="number">15</span>);</span><br><span class="line">        account.add(-<span class="number">25</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 环境类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScoreContext</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> AbstractState state;</span><br><span class="line">    ScoreContext() &#123;</span><br><span class="line">        state = <span class="keyword">new</span> LowState(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(AbstractState state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> AbstractState <span class="title">getState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> score)</span> </span>&#123;</span><br><span class="line">        state.addScore(score);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象状态类</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractState</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> ScoreContext hj;  <span class="comment">// 环境</span></span><br><span class="line">    <span class="keyword">protected</span> String stateName; <span class="comment">// 状态名</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> score; <span class="comment">// 分数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">checkState</span><span class="params">()</span></span>; <span class="comment">// 检查当前状态</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addScore</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        score += x;</span><br><span class="line">        System.out.print(<span class="string">&quot;加上：&quot;</span> + x + <span class="string">&quot;分，\t当前分数：&quot;</span> + score);</span><br><span class="line">        checkState();</span><br><span class="line">        System.out.println(<span class="string">&quot;分，\t当前状态：&quot;</span> + hj.getState().stateName);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态类：不及格</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LowState</span> <span class="keyword">extends</span> <span class="title">AbstractState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LowState</span><span class="params">(ScoreContext h)</span> </span>&#123;</span><br><span class="line">        hj = h;</span><br><span class="line">        stateName = <span class="string">&quot;不及格&quot;</span>;</span><br><span class="line">        score = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LowState</span><span class="params">(AbstractState state)</span> </span>&#123;</span><br><span class="line">        hj = state.hj;</span><br><span class="line">        stateName = <span class="string">&quot;不及格&quot;</span>;</span><br><span class="line">        score = state.score;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (score &gt;= <span class="number">90</span>) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> HighState(<span class="keyword">this</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (score &gt;= <span class="number">60</span>) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> MiddleState(<span class="keyword">this</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态类：中等</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MiddleState</span> <span class="keyword">extends</span> <span class="title">AbstractState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MiddleState</span><span class="params">(AbstractState state)</span> </span>&#123;</span><br><span class="line">        hj = state.hj;</span><br><span class="line">        stateName = <span class="string">&quot;中等&quot;</span>;</span><br><span class="line">        score = state.score;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (score &lt; <span class="number">60</span>) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> LowState(<span class="keyword">this</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (score &gt;= <span class="number">90</span>) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> HighState(<span class="keyword">this</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态类：优秀</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HighState</span> <span class="keyword">extends</span> <span class="title">AbstractState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HighState</span><span class="params">(AbstractState state)</span> </span>&#123;</span><br><span class="line">        hj = state.hj;</span><br><span class="line">        stateName = <span class="string">&quot;优秀&quot;</span>;</span><br><span class="line">        score = state.score;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (score &lt; <span class="number">60</span>) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> LowState(<span class="keyword">this</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (score &lt; <span class="number">90</span>) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> MiddleState(<span class="keyword">this</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">学生成绩状态测试：</span><br><span class="line">加上：30分，    当前分数：30分，    当前状态：不及格</span><br><span class="line">加上：40分，    当前分数：70分，    当前状态：中等</span><br><span class="line">加上：25分，    当前分数：95分，    当前状态：优秀</span><br><span class="line">加上：-15分，    当前分数：80分，    当前状态：中等</span><br><span class="line">加上：-25分，    当前分数：55分，    当前状态：不及格</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="【例2】用“状态模式”设计一个多线程的状态转换程序"><a href="#【例2】用“状态模式”设计一个多线程的状态转换程序" class="headerlink" title="【例2】用“状态模式”设计一个多线程的状态转换程序"></a>【例2】用“状态模式”设计一个多线程的状态转换程序</h3><p>分析：多线程存在 5 种状态，分别为新建状态、就绪状态、运行状态、阻塞状态和死亡状态，各个状态当遇到相关方法调用或事件触发时会转换到其他状态。</p>
<img src="/6f258c6e/3.gif" class>

<p>现在先定义一个抽象状态类（TheadState），然后为图 3 所示的每个状态设计一个具体状态类，它们是新建状态（New）、就绪状态（Runnable ）、运行状态（Running）、阻塞状态（Blocked）和死亡状态（Dead），每个状态中有触发它们转变状态的方法，环境类（ThreadContext）中先生成一个初始状态（New），并提供相关触发方法。</p>
<img src="/6f258c6e/4.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScoreStateTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ThreadContext context = <span class="keyword">new</span> ThreadContext();</span><br><span class="line">        context.start();</span><br><span class="line">        context.getCPU();</span><br><span class="line">        context.suspend();</span><br><span class="line">        context.resume();</span><br><span class="line">        context.getCPU();</span><br><span class="line">        context.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 环境类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThreadContext</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ThreadState state;</span><br><span class="line">    ThreadContext() &#123;</span><br><span class="line">        state = <span class="keyword">new</span> New();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(ThreadState state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ThreadState <span class="title">getState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ((New) state).start(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getCPU</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ((Runnable) state).getCPU(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">suspend</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ((Running) state).suspend(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ((Running) state).stop(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resume</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ((Blocked) state).resume(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象状态类：线程状态</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadState</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> String stateName; <span class="comment">// 状态名</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态类：新建状态</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">New</span> <span class="keyword">extends</span> <span class="title">ThreadState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">New</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        stateName = <span class="string">&quot;新建状态&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前线程处于：新建状态.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">(ThreadContext hj)</span> </span>&#123;</span><br><span class="line">        System.out.print(<span class="string">&quot;调用start()方法--&gt;&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (stateName.equals(<span class="string">&quot;新建状态&quot;</span>)) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> Runnable());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;当前线程不是新建状态，不能调用start()方法.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态类：就绪状态</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Runnable</span> <span class="keyword">extends</span> <span class="title">ThreadState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Runnable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        stateName = <span class="string">&quot;就绪状态&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前线程处于：就绪状态.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getCPU</span><span class="params">(ThreadContext hj)</span> </span>&#123;</span><br><span class="line">        System.out.print(<span class="string">&quot;获得CPU时间--&gt;&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (stateName.equals(<span class="string">&quot;就绪状态&quot;</span>)) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> Running());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;当前线程不是就绪状态，不能获取CPU.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态类：运行状态</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Running</span> <span class="keyword">extends</span> <span class="title">ThreadState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Running</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        stateName = <span class="string">&quot;运行状态&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前线程处于：运行状态.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">suspend</span><span class="params">(ThreadContext hj)</span> </span>&#123;</span><br><span class="line">        System.out.print(<span class="string">&quot;调用suspend()方法--&gt;&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (stateName.equals(<span class="string">&quot;运行状态&quot;</span>)) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> Blocked());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;当前线程不是运行状态，不能调用suspend()方法.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stop</span><span class="params">(ThreadContext hj)</span> </span>&#123;</span><br><span class="line">        System.out.print(<span class="string">&quot;调用stop()方法--&gt;&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (stateName.equals(<span class="string">&quot;运行状态&quot;</span>)) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> Dead());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;当前线程不是运行状态，不能调用stop()方法.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态类：阻塞状态</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blocked</span> <span class="keyword">extends</span> <span class="title">ThreadState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Blocked</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        stateName = <span class="string">&quot;阻塞状态&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前线程处于：阻塞状态.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resume</span><span class="params">(ThreadContext hj)</span> </span>&#123;</span><br><span class="line">        System.out.print(<span class="string">&quot;调用resume()方法--&gt;&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (stateName.equals(<span class="string">&quot;阻塞状态&quot;</span>)) &#123;</span><br><span class="line">            hj.setState(<span class="keyword">new</span> Runnable());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;当前线程不是阻塞状态，不能调用resume()方法.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态类：死亡状态</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dead</span> <span class="keyword">extends</span> <span class="title">ThreadState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Dead</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        stateName = <span class="string">&quot;死亡状态&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前线程处于：死亡状态.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">当前线程处于：新建状态.</span><br><span class="line">调用start()方法--&gt;当前线程处于：就绪状态.</span><br><span class="line">获得CPU时间--&gt;当前线程处于：运行状态.</span><br><span class="line">调用suspend()方法--&gt;当前线程处于：阻塞状态.</span><br><span class="line">调用resume()方法--&gt;当前线程处于：就绪状态.</span><br><span class="line">获得CPU时间--&gt;当前线程处于：运行状态.</span><br><span class="line">调用stop()方法--&gt;当前线程处于：死亡状态.</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="状态模式的应用场景"><a href="#状态模式的应用场景" class="headerlink" title="状态模式的应用场景"></a>状态模式的应用场景</h3><p>通常在以下情况下可以考虑使用状态模式。</p>
<ul>
<li>当一个对象的行为取决于它的状态，并且它必须在运行时根据状态改变它的行为时，就可以考虑使用状态模式。</li>
<li>一个操作中含有庞大的分支结构，并且这些分支决定于对象的状态时。</li>
</ul>
<hr>
<h3 id="状态模式的扩展"><a href="#状态模式的扩展" class="headerlink" title="状态模式的扩展"></a>状态模式的扩展</h3><p>在有些情况下，可能有多个环境对象需要共享一组状态，这时需要引入享元模式，将这些具体状态对象放在集合中供程序共享。</p>
<img src="/6f258c6e/5.gif" class>

<p>分析：共享状态模式的不同之处是在环境类中增加了一个 HashMap 来保存相关状态，当需要某种状态时可以从中获取，其程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> state;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlyweightStatePattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ShareContext context = <span class="keyword">new</span> ShareContext(); <span class="comment">// 创建环境      </span></span><br><span class="line">        context.Handle(); <span class="comment">// 处理请求</span></span><br><span class="line">        context.Handle();</span><br><span class="line">        context.Handle();</span><br><span class="line">        context.Handle();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 环境类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShareContext</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ShareState state;</span><br><span class="line">    <span class="keyword">private</span> HashMap&lt;String, ShareState&gt; stateSet = <span class="keyword">new</span> HashMap&lt;String, ShareState&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ShareContext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        state = <span class="keyword">new</span> ConcreteState1();</span><br><span class="line">        stateSet.put(<span class="string">&quot;1&quot;</span>, state);</span><br><span class="line">        state = <span class="keyword">new</span> ConcreteState2();</span><br><span class="line">        stateSet.put(<span class="string">&quot;2&quot;</span>, state);</span><br><span class="line">        state = getState(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 设置新状态</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(ShareState state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 读取状态</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ShareState <span class="title">getState</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">        ShareState s = (ShareState) stateSet.get(key);</span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 对请求做处理</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Handle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        state.Handle(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象状态类</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ShareState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">Handle</span><span class="params">(ShareContext context)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态1类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteState1</span> <span class="keyword">extends</span> <span class="title">ShareState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Handle</span><span class="params">(ShareContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前状态是： 状态1&quot;</span>);</span><br><span class="line">        context.setState(context.getState(<span class="string">&quot;2&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体状态2类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteState2</span> <span class="keyword">extends</span> <span class="title">ShareState</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Handle</span><span class="params">(ShareContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;当前状态是： 状态2&quot;</span>);</span><br><span class="line">        context.setState(context.getState(<span class="string">&quot;1&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">当前状态是： 状态1</span><br><span class="line">当前状态是： 状态2</span><br><span class="line">当前状态是： 状态1</span><br><span class="line">当前状态是： 状态2</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><h4 id="状态模式与责任链模式的区别"><a href="#状态模式与责任链模式的区别" class="headerlink" title="状态模式与责任链模式的区别"></a>状态模式与责任链模式的区别</h4><p>状态模式和责任链模式都能消除 if-else 分支过多的问题。但在某些情况下，状态模式中的状态可以理解为责任，那么在这种情况下，两种模式都可以使用。</p>
<p>从定义来看，状态模式强调的是一个对象内在状态的改变，而责任链模式强调的是外部节点对象间的改变。</p>
<p>从代码实现上来看，两者最大的区别就是状态模式的各个状态对象知道自己要进入的下一个状态对象，而责任链模式并不清楚其下一个节点处理对象，因为链式组装由客户端负责。</p>
<h4 id="状态模式与策略模式的区别"><a href="#状态模式与策略模式的区别" class="headerlink" title="状态模式与策略模式的区别"></a>状态模式与策略模式的区别</h4><p>状态模式和策略模式的 UML 类图架构几乎完全一样，但两者的应用场景是不一样的。策略模式的多种算法行为择其一都能满足，彼此之间是独立的，用户可自行更换策略算法，而状态模式的各个状态间存在相互关系，彼此之间在一定条件下存在自动切换状态的效果，并且用户无法指定状态，只能设置初始状态。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1388.html">http://c.biancheng.net/view/1388.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-中介者模式</title>
    <url>/89874411.html</url>
    <content><![CDATA[<h3 id="中介者模式"><a href="#中介者模式" class="headerlink" title="中介者模式"></a>中介者模式</h3><p>在现实生活中，常常会出现好多对象之间存在复杂的交互关系，这种交互关系常常是“网状结构”，它要求每个对象都必须知道它需要交互的对象。例如，每个人必须记住他（她）所有朋友的电话；而且，朋友中如果有人的电话修改了，他（她）必须让其他所有的朋友一起修改，这叫作“牵一发而动全身”，非常复杂。</p>
<p>如果把这种“网状结构”改为“星形结构”的话，将大大降低它们之间的“耦合性”，这时只要找一个“中介者”就可以了。如前面所说的“每个人必须记住所有朋友电话”的问题，只要在网上建立一个每个朋友都可以访问的“通信录”就解决了。这样的例子还有很多，例如，你刚刚参加工作想租房，可以找“房屋中介”；或者，自己刚刚到一个陌生城市找工作，可以找“人才交流中心”帮忙。</p>
<p>在软件的开发过程中，这样的例子也很多，例如，在 MVC 框架中，控制器（C）就是模型（M）和视图（V）的中介者；还有大家常用的 QQ 聊天程序的“中介者”是 QQ 服务器。所有这些，都可以采用“中介者模式”来实现，它将大大降低对象之间的耦合性，提高系统的灵活性。</p>
<hr>
<span id="more"></span>

<h3 id="模式的定义与特点"><a href="#模式的定义与特点" class="headerlink" title="模式的定义与特点"></a>模式的定义与特点</h3><p><strong>中介者（Mediator）模式的定义：</strong>定义一个中介对象来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。</p>
<p>中介者模式是一种对象行为型模式，其主要优点如下：</p>
<ol>
<li>类之间各司其职，符合迪米特法则。</li>
<li>降低了对象之间的耦合性，使得对象易于独立地被复用。</li>
<li>将对象间的一对多关联转变为一对一的关联，提高系统的灵活性，使得系统易于维护和扩展。</li>
</ol>
<p>其主要缺点是：</p>
<ol>
<li>中介者模式将原本多个对象直接的相互依赖变成了中介者和多个同事类的依赖关系。当同事类越多时，中介者就会越臃肿，变得复杂且难以维护。</li>
</ol>
<hr>
<h3 id="模式的结构与实现"><a href="#模式的结构与实现" class="headerlink" title="模式的结构与实现"></a>模式的结构与实现</h3><p>中介者模式实现的关键是找出“中介者”，下面对它的结构和实现进行分析。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>中介者模式包含以下主要角色：</p>
<ol>
<li>抽象中介者（Mediator）角色：它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法。</li>
<li>具体中介者（Concrete Mediator）角色：实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色。</li>
<li>抽象同事类（Colleague）角色：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能。</li>
<li>具体同事类（Concrete Colleague）角色：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互。</li>
</ol>
<img src="/89874411/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>中介者模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.mediator;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MediatorPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Mediator md = <span class="keyword">new</span> ConcreteMediator();</span><br><span class="line">        Colleague c1, c2;</span><br><span class="line">        c1 = <span class="keyword">new</span> ConcreteColleague1();</span><br><span class="line">        c2 = <span class="keyword">new</span> ConcreteColleague2();</span><br><span class="line">        md.register(c1);</span><br><span class="line">        md.register(c2);</span><br><span class="line">        c1.send();</span><br><span class="line">        System.out.println(<span class="string">&quot;-------------&quot;</span>);</span><br><span class="line">        c2.send();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象中介者</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Mediator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(Colleague colleague)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">relay</span><span class="params">(Colleague cl)</span></span>; <span class="comment">// 转发</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体中介者</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteMediator</span> <span class="keyword">extends</span> <span class="title">Mediator</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;Colleague&gt; colleagues = <span class="keyword">new</span> ArrayList&lt;Colleague&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(Colleague colleague)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!colleagues.contains(colleague)) &#123;</span><br><span class="line">            colleagues.add(colleague);</span><br><span class="line">            colleague.setMedium(<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">relay</span><span class="params">(Colleague cl)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Colleague ob : colleagues) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!ob.equals(cl)) &#123;</span><br><span class="line">                ((Colleague) ob).receive();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象同事类</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Colleague</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> Mediator mediator;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMedium</span><span class="params">(Mediator mediator)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.mediator = mediator;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体同事类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteColleague1</span> <span class="keyword">extends</span> <span class="title">Colleague</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体同事类1收到请求。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体同事类1发出请求。&quot;</span>);</span><br><span class="line">        mediator.relay(<span class="keyword">this</span>); <span class="comment">// 请中介者转发</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体同事类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteColleague2</span> <span class="keyword">extends</span> <span class="title">Colleague</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体同事类2收到请求。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体同事类2发出请求。&quot;</span>);</span><br><span class="line">        mediator.relay(<span class="keyword">this</span>); <span class="comment">// 请中介者转发</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体同事类1发出请求。</span><br><span class="line">具体同事类2收到请求。</span><br><span class="line">-------------</span><br><span class="line">具体同事类2发出请求。</span><br><span class="line">具体同事类1收到请求。</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】用中介者模式编写一个“韶关房地产交流平台”程序"><a href="#【例1】用中介者模式编写一个“韶关房地产交流平台”程序" class="headerlink" title="【例1】用中介者模式编写一个“韶关房地产交流平台”程序"></a>【例1】用中介者模式编写一个“韶关房地产交流平台”程序</h4><p>说明：韶关房地产交流平台是“房地产中介公司”提供给“卖方客户”与“买方客户”进行信息交流的平台，比较适合用中介者模式来实现。</p>
<p>首先，定义一个中介公司（Medium）接口，它是抽象中介者，它包含了客户注册方法 register(Customer member) 和信息转发方法 relay(String from,String ad)；再定义一个韶关房地产中介（EstateMedium）公司，它是具体中介者类，它包含了保存客户信息的 List 对象，并实现了中介公司中的抽象方法。</p>
<p>然后，定义一个客户（Customer）类，它是抽象同事类，其中包含了中介者的对象，和发送信息的 send(String ad) 方法与接收信息的 receive(String from，String ad) 方法的接口，由于本程序是窗体程序，所以本类继承 JPmme 类，并实现动作事件的处理方法 actionPerformed(ActionEvent e)。</p>
<p>最后，定义卖方（Seller）类和买方（Buyer）类，它们是具体同事类，是客户（Customer）类的子类，它们实现了父类中的抽象方法，通过中介者类进行信息交流。</p>
<img src="/89874411/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.mediator;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.ActionEvent;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.ActionListener;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DatingPlatform</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Medium md = <span class="keyword">new</span> EstateMedium();    <span class="comment">// 房产中介</span></span><br><span class="line">        Customer member1, member2;</span><br><span class="line">        member1 = <span class="keyword">new</span> Seller(<span class="string">&quot;张三(卖方)&quot;</span>);</span><br><span class="line">        member2 = <span class="keyword">new</span> Buyer(<span class="string">&quot;李四(买方)&quot;</span>);</span><br><span class="line">        md.register(member1); <span class="comment">// 客户注册</span></span><br><span class="line">        md.register(member2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象中介者：中介公司</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Medium</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">register</span><span class="params">(Customer member)</span></span>; <span class="comment">// 客户注册</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">relay</span><span class="params">(String from, String ad)</span></span>; <span class="comment">// 转发</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体中介者：房地产中介</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EstateMedium</span> <span class="keyword">implements</span> <span class="title">Medium</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;Customer&gt; members = <span class="keyword">new</span> ArrayList&lt;Customer&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(Customer member)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!members.contains(member)) &#123;</span><br><span class="line">            members.add(member);</span><br><span class="line">            member.setMedium(<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">relay</span><span class="params">(String from, String ad)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Customer ob : members) &#123;</span><br><span class="line">            String name = ob.getName();</span><br><span class="line">            <span class="keyword">if</span> (!name.equals(from)) &#123;</span><br><span class="line">                ((Customer) ob).receive(from, ad);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象同事类：客户</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Customer</span> <span class="keyword">extends</span> <span class="title">JFrame</span> <span class="keyword">implements</span> <span class="title">ActionListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">7219939540794786080L</span>;</span><br><span class="line">    <span class="keyword">protected</span> Medium medium;</span><br><span class="line">    <span class="keyword">protected</span> String name;</span><br><span class="line">    JTextField SentText;</span><br><span class="line">    JTextArea ReceiveArea;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Customer</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(name);</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">ClientWindow</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        Container cp;</span><br><span class="line">        JScrollPane sp;</span><br><span class="line">        JPanel p1, p2;</span><br><span class="line">        cp = <span class="keyword">this</span>.getContentPane();</span><br><span class="line">        SentText = <span class="keyword">new</span> JTextField(<span class="number">18</span>);</span><br><span class="line">        ReceiveArea = <span class="keyword">new</span> JTextArea(<span class="number">10</span>, <span class="number">18</span>);</span><br><span class="line">        ReceiveArea.setEditable(<span class="keyword">false</span>);</span><br><span class="line">        p1 = <span class="keyword">new</span> JPanel();</span><br><span class="line">        p1.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;接收内容：&quot;</span>));</span><br><span class="line">        p1.add(ReceiveArea);</span><br><span class="line">        sp = <span class="keyword">new</span> JScrollPane(p1);</span><br><span class="line">        cp.add(sp, BorderLayout.NORTH);</span><br><span class="line">        p2 = <span class="keyword">new</span> JPanel();</span><br><span class="line">        p2.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;发送内容：&quot;</span>));</span><br><span class="line">        p2.add(SentText);</span><br><span class="line">        cp.add(p2, BorderLayout.SOUTH);</span><br><span class="line">        SentText.addActionListener(<span class="keyword">this</span>);</span><br><span class="line">        <span class="keyword">this</span>.setLocation(x, y);</span><br><span class="line">        <span class="keyword">this</span>.setSize(<span class="number">250</span>, <span class="number">330</span>);</span><br><span class="line">        <span class="keyword">this</span>.setResizable(<span class="keyword">false</span>); <span class="comment">// 窗口大小不可调整</span></span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">actionPerformed</span><span class="params">(ActionEvent e)</span> </span>&#123;</span><br><span class="line">        String tempInfo = SentText.getText().trim();</span><br><span class="line">        SentText.setText(<span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="keyword">this</span>.send(tempInfo);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMedium</span><span class="params">(Medium medium)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.medium = medium;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(String ad)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">(String from, String ad)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体同事类：卖方</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seller</span> <span class="keyword">extends</span> <span class="title">Customer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">1443076716629516027L</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Seller</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(name);</span><br><span class="line">        ClientWindow(<span class="number">50</span>, <span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(String ad)</span> </span>&#123;</span><br><span class="line">        ReceiveArea.append(<span class="string">&quot;我(卖方)说: &quot;</span> + ad + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        <span class="comment">// 使滚动条滚动到最底端</span></span><br><span class="line">        ReceiveArea.setCaretPosition(ReceiveArea.getText().length());</span><br><span class="line">        medium.relay(name, ad);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">(String from, String ad)</span> </span>&#123;</span><br><span class="line">        ReceiveArea.append(from + <span class="string">&quot;说: &quot;</span> + ad + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        <span class="comment">// 使滚动条滚动到最底端</span></span><br><span class="line">        ReceiveArea.setCaretPosition(ReceiveArea.getText().length());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体同事类：买方</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Buyer</span> <span class="keyword">extends</span> <span class="title">Customer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">474879276076308825L</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Buyer</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(name);</span><br><span class="line">        ClientWindow(<span class="number">350</span>, <span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(String ad)</span> </span>&#123;</span><br><span class="line">        ReceiveArea.append(<span class="string">&quot;我(买方)说: &quot;</span> + ad + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        <span class="comment">// 使滚动条滚动到最底端</span></span><br><span class="line">        ReceiveArea.setCaretPosition(ReceiveArea.getText().length());</span><br><span class="line">        medium.relay(name, ad);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">(String from, String ad)</span> </span>&#123;</span><br><span class="line">        ReceiveArea.append(from + <span class="string">&quot;说: &quot;</span> + ad + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        <span class="comment">// 使滚动条滚动到最底端</span></span><br><span class="line">        ReceiveArea.setCaretPosition(ReceiveArea.getText().length());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如图所示：</p>
<img src="/89874411/3.gif" class>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>前面分析了中介者模式的结构与特点，下面分析其以下应用场景：</p>
<ul>
<li>当对象之间存在复杂的网状结构关系而导致依赖关系混乱且难以复用时。</li>
<li>当想创建一个运行于多个类之间的对象，又不想生成新的子类时。</li>
</ul>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>在实际开发中，通常采用以下两种方法来简化中介者模式，使开发变得更简单。</p>
<ol>
<li>不定义中介者接口，把具体中介者对象实现成为单例。</li>
<li>同事对象不持有中介者，而是在需要的时候直接获取中介者对象并调用。</li>
</ol>
<img src="/89874411/4.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.mediator;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleMediatorPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SimpleColleague c1, c2;</span><br><span class="line">        c1 = <span class="keyword">new</span> SimpleConcreteColleague1();</span><br><span class="line">        c2 = <span class="keyword">new</span> SimpleConcreteColleague2();</span><br><span class="line">        c1.send();</span><br><span class="line">        System.out.println(<span class="string">&quot;-----------------&quot;</span>);</span><br><span class="line">        c2.send();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 简单单例中介者</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleMediator</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> SimpleMediator smd = <span class="keyword">new</span> SimpleMediator();</span><br><span class="line">    <span class="keyword">private</span> List&lt;SimpleColleague&gt; colleagues = <span class="keyword">new</span> ArrayList&lt;SimpleColleague&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SimpleMediator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SimpleMediator <span class="title">getMedium</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (smd);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(SimpleColleague colleague)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!colleagues.contains(colleague)) &#123;</span><br><span class="line">            colleagues.add(colleague);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">relay</span><span class="params">(SimpleColleague scl)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (SimpleColleague ob : colleagues) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!ob.equals(scl)) &#123;</span><br><span class="line">                ((SimpleColleague) ob).receive();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象同事类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SimpleColleague</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">receive</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">send</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体同事类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleConcreteColleague1</span> <span class="keyword">implements</span> <span class="title">SimpleColleague</span> </span>&#123;</span><br><span class="line">    SimpleConcreteColleague1() &#123;</span><br><span class="line">        SimpleMediator smd = SimpleMediator.getMedium();</span><br><span class="line">        smd.register(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体同事类1：收到请求。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        SimpleMediator smd = SimpleMediator.getMedium();</span><br><span class="line">        System.out.println(<span class="string">&quot;具体同事类1：发出请求...&quot;</span>);</span><br><span class="line">        smd.relay(<span class="keyword">this</span>); <span class="comment">// 请中介者转发</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体同事类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleConcreteColleague2</span> <span class="keyword">implements</span> <span class="title">SimpleColleague</span> </span>&#123;</span><br><span class="line">    SimpleConcreteColleague2() &#123;</span><br><span class="line">        SimpleMediator smd = SimpleMediator.getMedium();</span><br><span class="line">        smd.register(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体同事类2：收到请求。&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        SimpleMediator smd = SimpleMediator.getMedium();</span><br><span class="line">        System.out.println(<span class="string">&quot;具体同事类2：发出请求...&quot;</span>);</span><br><span class="line">        smd.relay(<span class="keyword">this</span>); <span class="comment">// 请中介者转发</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体同事类1：发出请求...</span><br><span class="line">具体同事类2：收到请求。</span><br><span class="line">-----------------</span><br><span class="line">具体同事类2：发出请求...</span><br><span class="line">具体同事类1：收到请求。</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1393.html">http://c.biancheng.net/view/1393.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-观察者模式</title>
    <url>/c395211b.html</url>
    <content><![CDATA[<h3 id="观察者模式（Observer模式）"><a href="#观察者模式（Observer模式）" class="headerlink" title="观察者模式（Observer模式）"></a>观察者模式（Observer模式）</h3><p>在现实世界中，许多对象并不是独立存在的，其中一个对象的行为发生改变可能会导致一个或者多个其他对象的行为也发生改变。例如，某种商品的物价上涨时会导致部分商家高兴，而消费者伤心；还有，当我们开车到交叉路口时，遇到红灯会停，遇到绿灯会行。这样的例子还有很多，例如，股票价格与股民、微信公众号与微信用户、气象局的天气预报与听众、小偷与警察等。</p>
<p>在软件世界也是这样，例如，Excel 中的数据与折线图、饼状图、柱状图之间的关系；MVC 模式中的模型与视图的关系；事件模型中的事件源与事件处理者。所有这些，如果用观察者模式来实现就非常方便。</p>
<hr>
<span id="more"></span>

<h3 id="模式的定义与特点"><a href="#模式的定义与特点" class="headerlink" title="模式的定义与特点"></a>模式的定义与特点</h3><p><strong>观察者（Observer）模式的定义：</strong>指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。这种模式有时又称作发布-订阅模式、模型-视图模式，它是对象行为型模式。</p>
<p>观察者模式是一种对象行为型模式，其主要优点如下：</p>
<ol>
<li>降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则。</li>
<li>目标与观察者之间建立了一套触发机制。</li>
</ol>
<p>它的主要缺点如下：</p>
<ol>
<li>目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用。</li>
<li>当观察者对象很多时，通知的发布会花费很多时间，影响程序的效率。</li>
</ol>
<hr>
<h3 id="模式的结构与实现"><a href="#模式的结构与实现" class="headerlink" title="模式的结构与实现"></a>模式的结构与实现</h3><p>实现观察者模式时要注意具体目标对象和具体观察者对象之间不能直接调用，否则将使两者之间紧密耦合起来，这违反了面向对象的设计原则。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>观察者模式的主要角色如下：</p>
<ol>
<li>抽象主题（Subject）角色：也叫抽象目标类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法。</li>
<li>具体主题（Concrete Subject）角色：也叫具体目标类，它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象。</li>
<li>抽象观察者（Observer）角色：它是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用。</li>
<li>具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态。</li>
</ol>
<img src="/c395211b/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>观察者模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.observer;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ObserverPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Subject subject = <span class="keyword">new</span> ConcreteSubject();</span><br><span class="line">        Observer obs1 = <span class="keyword">new</span> ConcreteObserver1();</span><br><span class="line">        Observer obs2 = <span class="keyword">new</span> ConcreteObserver2();</span><br><span class="line">        subject.add(obs1);</span><br><span class="line">        subject.add(obs2);</span><br><span class="line">        subject.notifyObserver();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象目标</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Subject</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> List&lt;Observer&gt; observers = <span class="keyword">new</span> ArrayList&lt;Observer&gt;();</span><br><span class="line">    <span class="comment">// 增加观察者方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Observer observer)</span> </span>&#123;</span><br><span class="line">        observers.add(observer);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 删除观察者方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Observer observer)</span> </span>&#123;</span><br><span class="line">        observers.remove(observer);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">notifyObserver</span><span class="params">()</span></span>; <span class="comment">// 通知观察者方法</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体目标</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteSubject</span> <span class="keyword">extends</span> <span class="title">Subject</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">notifyObserver</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体目标发生改变...&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;--------------&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (Object obs : observers) &#123;</span><br><span class="line">            ((Observer) obs).response();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象观察者</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Observer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">response</span><span class="params">()</span></span>; <span class="comment">// 反应</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体观察者1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteObserver1</span> <span class="keyword">implements</span> <span class="title">Observer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">response</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体观察者1作出反应！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体观察者2</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteObserver2</span> <span class="keyword">implements</span> <span class="title">Observer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">response</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体观察者2作出反应！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体目标发生改变...</span><br><span class="line">--------------</span><br><span class="line">具体观察者1作出反应！</span><br><span class="line">具体观察者2作出反应！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】利用观察者模式设计一个程序，分析“人民币汇率”的升值或贬值对进口公司进口产品成本或出口公司的出口产品收入以及公司利润率的影响"><a href="#【例1】利用观察者模式设计一个程序，分析“人民币汇率”的升值或贬值对进口公司进口产品成本或出口公司的出口产品收入以及公司利润率的影响" class="headerlink" title="【例1】利用观察者模式设计一个程序，分析“人民币汇率”的升值或贬值对进口公司进口产品成本或出口公司的出口产品收入以及公司利润率的影响"></a>【例1】利用观察者模式设计一个程序，分析“人民币汇率”的升值或贬值对进口公司进口产品成本或出口公司的出口产品收入以及公司利润率的影响</h4><p>分析：当“人民币汇率”升值时，进口公司的进口产品成本降低且利润率提升，出口公司的出口产品收入降低且利润率降低；当“人民币汇率”贬值时，进口公司的进口产品成本提升且利润率降低，出口公司的出口产品收入提升且利润率提升。</p>
<p>这里的汇率（Rate）类是抽象目标类，它包含了保存观察者（Company）的 List 和增加/删除观察者的方法，以及有关汇率改变的抽象方法 change(int number)；而人民币汇率（RMBrate）类是具体目标， 它实现了父类的 change(int number) 方法，即当人民币汇率发生改变时通过相关公司；公司（Company）类是抽象观察者，它定义了一个有关汇率反应的抽象方法 response(int number)；进口公司（ImportCompany）类和出口公司（ExportCompany）类是具体观察者类，它们实现了父类的 response(int number) 方法，即当它们接收到汇率发生改变的通知时作为相应的反应。</p>
<img src="/c395211b/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.observer;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RMBrateTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Rate rate = <span class="keyword">new</span> RMBrate();</span><br><span class="line">        Company watcher1 = <span class="keyword">new</span> ImportCompany();</span><br><span class="line">        Company watcher2 = <span class="keyword">new</span> ExportCompany();</span><br><span class="line">        rate.add(watcher1);</span><br><span class="line">        rate.add(watcher2);</span><br><span class="line">        rate.change(<span class="number">10</span>);</span><br><span class="line">        rate.change(-<span class="number">9</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象目标：汇率</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Rate</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> List&lt;Company&gt; companys = <span class="keyword">new</span> ArrayList&lt;Company&gt;();</span><br><span class="line">    <span class="comment">// 增加观察者方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Company company)</span> </span>&#123;</span><br><span class="line">        companys.add(company);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 删除观察者方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Company company)</span> </span>&#123;</span><br><span class="line">        companys.remove(company);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">change</span><span class="params">(<span class="keyword">int</span> number)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体目标：人民币汇率</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RMBrate</span> <span class="keyword">extends</span> <span class="title">Rate</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">change</span><span class="params">(<span class="keyword">int</span> number)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Company obs : companys) &#123;</span><br><span class="line">            ((Company) obs).response(number);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象观察者：公司</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Company</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">response</span><span class="params">(<span class="keyword">int</span> number)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体观察者1：进口公司</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImportCompany</span> <span class="keyword">implements</span> <span class="title">Company</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">response</span><span class="params">(<span class="keyword">int</span> number)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (number &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;人民币汇率升值&quot;</span> + number + <span class="string">&quot;个基点，降低了进口产品成本，提升了进口公司利润率。&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (number &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;人民币汇率贬值&quot;</span> + (-number) + <span class="string">&quot;个基点，提升了进口产品成本，降低了进口公司利润率。&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体观察者2：出口公司</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExportCompany</span> <span class="keyword">implements</span> <span class="title">Company</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">response</span><span class="params">(<span class="keyword">int</span> number)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (number &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;人民币汇率升值&quot;</span> + number + <span class="string">&quot;个基点，降低了出口产品收入，降低了出口公司的销售利润率。&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (number &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;人民币汇率贬值&quot;</span> + (-number) + <span class="string">&quot;个基点，提升了出口产品收入，提升了出口公司的销售利润率。&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">人民币汇率升值10个基点，降低了进口产品成本，提升了进口公司利润率。</span><br><span class="line">人民币汇率升值10个基点，降低了出口产品收入，降低了出口公司的销售利润率。</span><br><span class="line">人民币汇率贬值9个基点，提升了进口产品成本，降低了进口公司利润率。</span><br><span class="line">人民币汇率贬值9个基点，提升了出口产品收入，提升了出口公司的销售利润率。</span><br></pre></td></tr></table></figure>

<p>观察者模式在软件幵发中用得最多的是窗体程序设计中的事件处理，窗体中的所有组件都是“事件源”，也就是目标对象，而事件处理程序类的对象是具体观察者对象。下面以一个学校铃声的事件处理程序为例，介绍 Windows 中的“事件处理模型”的工作原理。</p>
<hr>
<h4 id="【例2】利用观察者模式设计一个学校铃声的事件处理程序"><a href="#【例2】利用观察者模式设计一个学校铃声的事件处理程序" class="headerlink" title="【例2】利用观察者模式设计一个学校铃声的事件处理程序"></a>【例2】利用观察者模式设计一个学校铃声的事件处理程序</h4><p>分析：在本实例中，学校的“铃”是事件源和目标，“老师”和“学生”是事件监听器和具体观察者，“铃声”是事件类。学生和老师来到学校的教学区，都会注意学校的铃，这叫事件绑定；当上课时间或下课时间到，会触发铃发声，这时会生成“铃声”事件；学生和老师听到铃声会开始上课或下课，这叫事件处理。这个实例非常适合用观察者模式实现。</p>
<img src="/c395211b/3.gif" class>

<p>现在用“观察者模式”来实现该事件处理模型。</p>
<p>首先，定义一个铃声事件（RingEvent）类，它记录了铃声的类型（上课铃声/下课铃声）。</p>
<p>再定义一个学校的铃（BellEventSource）类，它是事件源，是观察者目标类，该类里面包含了监听器容器 listener，可以绑定监听者（学生或老师），并且有产生铃声事件和通知所有监听者的方法。</p>
<p>然后，定义铃声事件监听者（BellEventListener）类，它是抽象观察者，它包含了铃声事件处理方法 heardBell(RingEvent e)。</p>
<p>最后，定义老师类（TeachEventListener）和学生类（StuEventListener），它们是事件监听器，是具体观察者，听到铃声会去上课或下课。</p>
<img src="/c395211b/4.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.observer;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BellEventTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        BellEventSource bell = <span class="keyword">new</span> BellEventSource();    <span class="comment">// 铃（事件源）</span></span><br><span class="line">        bell.addPersonListener(<span class="keyword">new</span> TeachEventListener()); <span class="comment">// 注册监听器（老师）</span></span><br><span class="line">        bell.addPersonListener(<span class="keyword">new</span> StuEventListener());    <span class="comment">// 注册监听器（学生）</span></span><br><span class="line">        bell.ring(<span class="keyword">true</span>);   <span class="comment">// 打上课铃声</span></span><br><span class="line">        System.out.println(<span class="string">&quot;------------&quot;</span>);</span><br><span class="line">        bell.ring(<span class="keyword">false</span>);  <span class="comment">// 打下课铃声</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 铃声事件类：用于封装事件源及一些与事件相关的参数</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RingEvent</span> <span class="keyword">extends</span> <span class="title">EventObject</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> sound;    <span class="comment">// true表示上课铃声,false表示下课铃声</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RingEvent</span><span class="params">(Object source, <span class="keyword">boolean</span> sound)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(source);</span><br><span class="line">        <span class="keyword">this</span>.sound = sound;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSound</span><span class="params">(<span class="keyword">boolean</span> sound)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sound = sound;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">getSound</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sound;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 目标类：事件源，铃</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BellEventSource</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;BellEventListener&gt; listener; <span class="comment">// 监听器容器</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BellEventSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        listener = <span class="keyword">new</span> ArrayList&lt;BellEventListener&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 给事件源绑定监听器</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addPersonListener</span><span class="params">(BellEventListener ren)</span> </span>&#123;</span><br><span class="line">        listener.add(ren);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 事件触发器：敲钟，当铃声sound的值发生变化时，触发事件。</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ring</span><span class="params">(<span class="keyword">boolean</span> sound)</span> </span>&#123;</span><br><span class="line">        String type = sound ? <span class="string">&quot;上课铃&quot;</span> : <span class="string">&quot;下课铃&quot;</span>;</span><br><span class="line">        System.out.println(type + <span class="string">&quot;响！&quot;</span>);</span><br><span class="line">        RingEvent event = <span class="keyword">new</span> RingEvent(<span class="keyword">this</span>, sound);</span><br><span class="line">        notifies(event);    <span class="comment">// 通知注册在该事件源上的所有监听器</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 当事件发生时,通知绑定在该事件源上的所有监听器做出反应（调用事件处理方法）</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">notifies</span><span class="params">(RingEvent e)</span> </span>&#123;</span><br><span class="line">        BellEventListener ren = <span class="keyword">null</span>;</span><br><span class="line">        Iterator&lt;BellEventListener&gt; iterator = listener.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">            ren = iterator.next();</span><br><span class="line">            ren.heardBell(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象观察者类：铃声事件监听器</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">BellEventListener</span> <span class="keyword">extends</span> <span class="title">EventListener</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 事件处理方法，听到铃声</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">heardBell</span><span class="params">(RingEvent e)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体观察者类：老师事件监听器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TeachEventListener</span> <span class="keyword">implements</span> <span class="title">BellEventListener</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">heardBell</span><span class="params">(RingEvent e)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (e.getSound()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;老师上课了...&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;老师下课了...&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体观察者类：学生事件监听器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StuEventListener</span> <span class="keyword">implements</span> <span class="title">BellEventListener</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">heardBell</span><span class="params">(RingEvent e)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (e.getSound()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;同学们，上课了...&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;同学们，下课了...&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">上课铃响！</span><br><span class="line">老师上课了...</span><br><span class="line">同学们，上课了...</span><br><span class="line">------------</span><br><span class="line">下课铃响！</span><br><span class="line">老师下课了...</span><br><span class="line">同学们，下课了...</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>在软件系统中，当系统一方行为依赖另一方行为的变动时，可使用观察者模式松耦合联动双方，使得一方的变动可以通知到感兴趣的另一方对象，从而让另一方对象对此做出响应。</p>
<p>通过前面的分析与应用实例可知观察者模式适合以下几种情形：</p>
<ol>
<li>对象间存在一对多关系，一个对象的状态发生改变会影响其他对象。</li>
<li>当一个抽象模型有两个方面，其中一个方面依赖于另一方面时，可将这二者封装在独立的对象中以使它们可以各自独立地改变和复用。</li>
<li>实现类似广播机制的功能，不需要知道具体收听者，只需分发广播，系统中感兴趣的对象会自动接收该广播。</li>
<li>多层级嵌套使用，形成一种链式触发机制，使得事件具备跨域（跨越两种观察者类型）通知。</li>
</ol>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>在 Java 中，通过 java.util.Observable 类和 java.util.Observer 接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。</p>
<h4 id="Observable类"><a href="#Observable类" class="headerlink" title="Observable类"></a>Observable类</h4><p>Observable 类是抽象目标类，它有一个 Vector 向量，用于保存所有要通知的观察者对象，下面来介绍它最重要的 3 个方法：</p>
<ol>
<li>void addObserver(Observer o) 方法：用于将新的观察者对象添加到向量中。</li>
<li>void notifyObservers(Object arg) 方法：调用向量中的所有观察者对象的 update() 方法，通知它们数据发生改变。通常越晚加入向量的观察者越先得到通知。</li>
<li>void setChange() 方法：用来设置一个 boolean 类型的内部标志位，注明目标对象发生了变化。当它为真时，notifyObservers() 才会通知观察者。</li>
</ol>
<h4 id="Observer-接口"><a href="#Observer-接口" class="headerlink" title="Observer 接口"></a>Observer 接口</h4><p>Observer 接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用 void update(Observable o,Object arg) 方法，进行相应的工作。</p>
<h4 id="【例3】利用-Observable-类和-Observer-接口实现原油期货的观察者模式实例"><a href="#【例3】利用-Observable-类和-Observer-接口实现原油期货的观察者模式实例" class="headerlink" title="【例3】利用 Observable 类和 Observer 接口实现原油期货的观察者模式实例"></a>【例3】利用 Observable 类和 Observer 接口实现原油期货的观察者模式实例</h4><p>分析：当原油价格上涨时，空方伤心，多方局兴；当油价下跌时，空方局兴，多方伤心。本实例中的抽象目标（Observable）类在 Java 中已经定义，可以直接定义其子类，即原油期货（OilFutures）类，它是具体目标类，该类中定义一个 SetPriCe(float price) 方法，当原油数据发生变化时调用其父类的 notifyObservers(Object arg) 方法来通知所有观察者；另外，本实例中的抽象观察者接口（Observer）在 Java 中已经定义，只要定义其子类，即具体观察者类（包括多方类 Bull 和空方类 Bear），并实现 update(Observable o,Object arg) 方法即可。</p>
<img src="/c395211b/5.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.observer;</span><br><span class="line"><span class="keyword">import</span> java.util.Observer;</span><br><span class="line"><span class="keyword">import</span> java.util.Observable;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CrudeOilFutures</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        OilFutures oil = <span class="keyword">new</span> OilFutures();</span><br><span class="line">        Observer bull = <span class="keyword">new</span> Bull(); <span class="comment">// 多方</span></span><br><span class="line">        Observer bear = <span class="keyword">new</span> Bear(); <span class="comment">// 空方</span></span><br><span class="line">        oil.addObserver(bull);</span><br><span class="line">        oil.addObserver(bear);</span><br><span class="line">        oil.setPrice(<span class="number">10</span>);</span><br><span class="line">        oil.setPrice(-<span class="number">8</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体目标类：原油期货</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OilFutures</span> <span class="keyword">extends</span> <span class="title">Observable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">float</span> price;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">getPrice</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.price;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrice</span><span class="params">(<span class="keyword">float</span> price)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.setChanged();  <span class="comment">// 设置内部标志位，注明数据发生变化</span></span><br><span class="line">        <span class="keyword">super</span>.notifyObservers(price);    <span class="comment">// 通知观察者价格改变了</span></span><br><span class="line">        <span class="keyword">this</span>.price = price;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体观察者类：多方</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bull</span> <span class="keyword">implements</span> <span class="title">Observer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">(Observable o, Object arg)</span> </span>&#123;</span><br><span class="line">        Float price = ((Float) arg).floatValue();</span><br><span class="line">        <span class="keyword">if</span> (price &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;油价上涨&quot;</span> + price + <span class="string">&quot;元，多方高兴了！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;油价下跌&quot;</span> + (-price) + <span class="string">&quot;元，多方伤心了！&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体观察者类：空方</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bear</span> <span class="keyword">implements</span> <span class="title">Observer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">(Observable o, Object arg)</span> </span>&#123;</span><br><span class="line">        Float price = ((Float) arg).floatValue();</span><br><span class="line">        <span class="keyword">if</span> (price &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;油价上涨&quot;</span> + price + <span class="string">&quot;元，空方伤心了！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;油价下跌&quot;</span> + (-price) + <span class="string">&quot;元，空方高兴了！&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">油价上涨10.0元，空方伤心了！</span><br><span class="line">油价上涨10.0元，多方高兴了！</span><br><span class="line">油价下跌8.0元，空方高兴了！</span><br><span class="line">油价下跌8.0元，多方伤心了！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1390.html">http://c.biancheng.net/view/1390.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-迭代器模式</title>
    <url>/c9e4911a.html</url>
    <content><![CDATA[<h3 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h3><p>在现实生活以及程序设计中，经常要访问一个聚合对象中的各个元素，如“数据结构”中的链表遍历，通常的做法是将链表的创建和遍历都放在同一个类中，但这种方式不利于程序的扩展，如果要更换遍历方法就必须修改程序源代码，这违背了 “开闭原则”。</p>
<p>既然将遍历方法封装在聚合类中不可取，那么聚合类中不提供遍历方法，将遍历方法由用户自己实现是否可行呢？答案是同样不可取，因为这种方式会存在两个缺点：<br>暴露了聚合类的内部表示，使其数据不安全；<br>增加了客户的负担。</p>
<p>“迭代器模式”能较好地克服以上缺点，它在客户访问类与聚合类之间插入一个迭代器，这分离了聚合对象与其遍历行为，对客户也隐藏了其内部细节，且满足“单一职责原则”和“开闭原则”，如 Java 中的 Collection、List、Set、Map 等都包含了迭代器。</p>
<p>迭代器模式在生活中应用的比较广泛，比如：物流系统中的传送带，不管传送的是什么物品，都会被打包成一个个箱子，并且有一个统一的二维码。这样我们不需要关心箱子里是什么，在分发时只需要一个个检查发送的目的地即可。再比如，我们平时乘坐交通工具，都是统一刷卡或者刷脸进站，而不需要关心是男性还是女性、是残疾人还是正常人等信息。</p>
<hr>
<span id="more"></span>

<h3 id="模式的定义与特点"><a href="#模式的定义与特点" class="headerlink" title="模式的定义与特点"></a>模式的定义与特点</h3><p><strong>迭代器（Iterator）模式的定义：</strong>提供一个对象来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。</p>
<p>迭代器模式是一种对象行为型模式，其主要优点如下：</p>
<ol>
<li>访问一个聚合对象的内容而无须暴露它的内部表示。</li>
<li>遍历任务交由迭代器完成，这简化了聚合类。</li>
<li>它支持以不同方式遍历一个聚合，甚至可以自定义迭代器的子类以支持新的遍历。</li>
<li>增加新的聚合类和迭代器类都很方便，无须修改原有代码。</li>
<li>封装性良好，为遍历不同的聚合结构提供一个统一的接口。</li>
</ol>
<p>其主要缺点是：</p>
<ol>
<li>增加了类的个数，这在一定程度上增加了系统的复杂性。</li>
</ol>
<p>在日常开发中，我们几乎不会自己写迭代器。除非需要定制一个自己实现的数据结构对应的迭代器，否则，开源框架提供的 API 完全够用。</p>
<hr>
<h3 id="模式的结构与实现"><a href="#模式的结构与实现" class="headerlink" title="模式的结构与实现"></a>模式的结构与实现</h3><p>迭代器模式是通过将聚合对象的遍历行为分离出来，抽象成迭代器类来实现的，其目的是在不暴露聚合对象的内部结构的情况下，让外部代码透明地访问聚合的内部数据。现在我们来分析其基本结构与实现方法。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>迭代器模式主要包含以下角色：</p>
<ol>
<li>抽象聚合（Aggregate）角色：定义存储、添加、删除聚合对象以及创建迭代器对象的接口。</li>
<li>具体聚合（ConcreteAggregate）角色：实现抽象聚合类，返回一个具体迭代器的实例。</li>
<li>抽象迭代器（Iterator）角色：定义访问和遍历聚合元素的接口，通常包含 hasNext()、first()、next() 等方法。</li>
<li>具体迭代器（Concretelterator）角色：实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。</li>
</ol>
<img src="/c9e4911a/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>迭代器模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IteratorPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Aggregate ag = <span class="keyword">new</span> ConcreteAggregate();</span><br><span class="line">        ag.add(<span class="string">&quot;中山大学&quot;</span>);</span><br><span class="line">        ag.add(<span class="string">&quot;华南理工&quot;</span>);</span><br><span class="line">        ag.add(<span class="string">&quot;韶关学院&quot;</span>);</span><br><span class="line">        System.out.print(<span class="string">&quot;聚合的内容有：&quot;</span>);</span><br><span class="line">        Iterator it = ag.getIterator();</span><br><span class="line">        <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">            Object ob = it.next();</span><br><span class="line">            System.out.print(ob.toString() + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Object ob = it.first();</span><br><span class="line">        System.out.println(<span class="string">&quot;\nFirst：&quot;</span> + ob.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象聚合</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Aggregate</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Object obj)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Object obj)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Iterator <span class="title">getIterator</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体聚合</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteAggregate</span> <span class="keyword">implements</span> <span class="title">Aggregate</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;Object&gt; list = <span class="keyword">new</span> ArrayList&lt;Object&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Object obj)</span> </span>&#123;</span><br><span class="line">        list.add(obj);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Object obj)</span> </span>&#123;</span><br><span class="line">        list.remove(obj);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Iterator <span class="title">getIterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">new</span> ConcreteIterator(list));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象迭代器</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Iterator</span> </span>&#123;</span><br><span class="line">    <span class="function">Object <span class="title">first</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">Object <span class="title">next</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体迭代器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteIterator</span> <span class="keyword">implements</span> <span class="title">Iterator</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;Object&gt; list = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> index = -<span class="number">1</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ConcreteIterator</span><span class="params">(List&lt;Object&gt; list)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.list = list;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (index &lt; list.size() - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">first</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        index = <span class="number">0</span>;</span><br><span class="line">        Object obj = list.get(index);</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Object obj = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.hasNext()) &#123;</span><br><span class="line">            obj = list.get(++index);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">聚合的内容有：中山大学    华南理工    韶关学院   </span><br><span class="line">First：中山大学</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】用迭代器模式编写一个浏览婺源旅游风景图的程序"><a href="#【例1】用迭代器模式编写一个浏览婺源旅游风景图的程序" class="headerlink" title="【例1】用迭代器模式编写一个浏览婺源旅游风景图的程序"></a>【例1】用迭代器模式编写一个浏览婺源旅游风景图的程序</h4><p>分析：婺源的名胜古迹较多，要设计一个查看相关景点图片和简介的程序，用“迭代器模式”设计比较合适。</p>
<p>首先，设计一个婺源景点（WyViewSpot）类来保存每张图片的名称与简介；再设计一个景点集（ViewSpotSet）接口，它是抽象聚合类，提供了增加和删除婺源景点的方法，以及获取迭代器的方法。</p>
<p>然后，定义一个婺源景点集（WyViewSpotSet）类，它是具体聚合类，用 ArrayList 来保存所有景点信息，并实现父类中的抽象方法；再定义婺源景点的抽象迭代器（ViewSpotltemtor）接口，其中包含了查看景点信息的相关方法。</p>
<p>最后，定义婺源景点的具体迭代器（WyViewSpotlterator）类，它实现了父类的抽象方法；客户端程序设计成窗口程序，它初始化婺源景点集（ViewSpotSet）中的数据，并实现 ActionListener 接口，它通过婺源景点迭代器（ViewSpotlterator）来査看婺源景点（WyViewSpot）的信息。</p>
<img src="/c9e4911a/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.iterator;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.ActionEvent;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.ActionListener;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PictureIterator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> PictureFrame();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 相框类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PictureFrame</span> <span class="keyword">extends</span> <span class="title">JFrame</span> <span class="keyword">implements</span> <span class="title">ActionListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    ViewSpotSet ag; <span class="comment">// 婺源景点集接口</span></span><br><span class="line">    ViewSpotIterator it; <span class="comment">// 婺源景点迭代器接口</span></span><br><span class="line">    WyViewSpot ob;    <span class="comment">// 婺源景点类</span></span><br><span class="line">    PictureFrame() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;中国最美乡村“婺源”的部分风景图&quot;</span>);</span><br><span class="line">        <span class="keyword">this</span>.setResizable(<span class="keyword">false</span>);</span><br><span class="line">        ag = <span class="keyword">new</span> WyViewSpotSet();</span><br><span class="line">        ag.add(<span class="keyword">new</span> WyViewSpot(<span class="string">&quot;江湾&quot;</span>, <span class="string">&quot;江湾景区是婺源的一个国家5A级旅游景区，景区内有萧江宗祠、永思街、滕家老屋、婺源人家、乡贤园、百工坊等一大批古建筑，精美绝伦，做工精细。&quot;</span>));</span><br><span class="line">        ag.add(<span class="keyword">new</span> WyViewSpot(<span class="string">&quot;李坑&quot;</span>, <span class="string">&quot;李坑村是一个以李姓聚居为主的古村落，是国家4A级旅游景区，其建筑风格独特，是著名的徽派建筑，给人一种安静、祥和的感觉。&quot;</span>));</span><br><span class="line">        ag.add(<span class="keyword">new</span> WyViewSpot(<span class="string">&quot;思溪延村&quot;</span>, <span class="string">&quot;思溪延村位于婺源县思口镇境内，始建于南宋庆元五年（1199年），当时建村者俞氏以（鱼）思清溪水而名。&quot;</span>));</span><br><span class="line">        ag.add(<span class="keyword">new</span> WyViewSpot(<span class="string">&quot;晓起村&quot;</span>, <span class="string">&quot;晓起有“中国茶文化第一村”与“国家级生态示范村”之美誉，村屋多为清代建筑，风格各具特色，村中小巷均铺青石，曲曲折折，回环如棋局。&quot;</span>));</span><br><span class="line">        ag.add(<span class="keyword">new</span> WyViewSpot(<span class="string">&quot;菊径村&quot;</span>, <span class="string">&quot;菊径村形状为山环水绕型，小河成大半圆型，绕村庄将近一周，四周为高山环绕，符合中国的八卦“后山前水”设计，当地人称“脸盆村”。&quot;</span>));</span><br><span class="line">        ag.add(<span class="keyword">new</span> WyViewSpot(<span class="string">&quot;篁岭&quot;</span>, <span class="string">&quot;篁岭是著名的“晒秋”文化起源地，也是一座距今近六百历史的徽州古村；篁岭属典型山居村落，民居围绕水口呈扇形梯状错落排布。&quot;</span>));</span><br><span class="line">        ag.add(<span class="keyword">new</span> WyViewSpot(<span class="string">&quot;彩虹桥&quot;</span>, <span class="string">&quot;彩虹桥是婺源颇有特色的带顶的桥——廊桥，其不仅造型优美，而且它可在雨天里供行人歇脚，其名取自唐诗“两水夹明镜，双桥落彩虹”。&quot;</span>));</span><br><span class="line">        ag.add(<span class="keyword">new</span> WyViewSpot(<span class="string">&quot;卧龙谷&quot;</span>, <span class="string">&quot;卧龙谷是国家4A级旅游区，这里飞泉瀑流泄银吐玉、彩池幽潭碧绿清新、山峰岩石挺拔奇巧，活脱脱一幅天然泼墨山水画。&quot;</span>));</span><br><span class="line">        it = ag.getIterator(); <span class="comment">// 获取婺源景点迭代器</span></span><br><span class="line">        ob = it.first();</span><br><span class="line">        <span class="keyword">this</span>.showPicture(ob.getName(), ob.getIntroduce());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 显示图片</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">showPicture</span><span class="params">(String Name, String Introduce)</span> </span>&#123;</span><br><span class="line">        Container cp = <span class="keyword">this</span>.getContentPane();</span><br><span class="line">        JPanel picturePanel = <span class="keyword">new</span> JPanel();</span><br><span class="line">        JPanel controlPanel = <span class="keyword">new</span> JPanel();</span><br><span class="line">        String FileName = <span class="string">&quot;src/iterator/Picture/&quot;</span> + Name + <span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        JLabel lb = <span class="keyword">new</span> JLabel(Name, <span class="keyword">new</span> ImageIcon(FileName), JLabel.CENTER);</span><br><span class="line">        JTextArea ta = <span class="keyword">new</span> JTextArea(Introduce);</span><br><span class="line">        lb.setHorizontalTextPosition(JLabel.CENTER);</span><br><span class="line">        lb.setVerticalTextPosition(JLabel.TOP);</span><br><span class="line">        lb.setFont(<span class="keyword">new</span> Font(<span class="string">&quot;宋体&quot;</span>, Font.BOLD, <span class="number">20</span>));</span><br><span class="line">        ta.setLineWrap(<span class="keyword">true</span>);</span><br><span class="line">        ta.setEditable(<span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">//ta.setBackground(Color.orange);</span></span><br><span class="line">        picturePanel.setLayout(<span class="keyword">new</span> BorderLayout(<span class="number">5</span>, <span class="number">5</span>));</span><br><span class="line">        picturePanel.add(<span class="string">&quot;Center&quot;</span>, lb);</span><br><span class="line">        picturePanel.add(<span class="string">&quot;South&quot;</span>, ta);</span><br><span class="line">        JButton first, last, next, previous;</span><br><span class="line">        first = <span class="keyword">new</span> JButton(<span class="string">&quot;第一张&quot;</span>);</span><br><span class="line">        next = <span class="keyword">new</span> JButton(<span class="string">&quot;下一张&quot;</span>);</span><br><span class="line">        previous = <span class="keyword">new</span> JButton(<span class="string">&quot;上一张&quot;</span>);</span><br><span class="line">        last = <span class="keyword">new</span> JButton(<span class="string">&quot;最末张&quot;</span>);</span><br><span class="line">        first.addActionListener(<span class="keyword">this</span>);</span><br><span class="line">        next.addActionListener(<span class="keyword">this</span>);</span><br><span class="line">        previous.addActionListener(<span class="keyword">this</span>);</span><br><span class="line">        last.addActionListener(<span class="keyword">this</span>);</span><br><span class="line">        controlPanel.add(first);</span><br><span class="line">        controlPanel.add(next);</span><br><span class="line">        controlPanel.add(previous);</span><br><span class="line">        controlPanel.add(last);</span><br><span class="line">        cp.add(<span class="string">&quot;Center&quot;</span>, picturePanel);</span><br><span class="line">        cp.add(<span class="string">&quot;South&quot;</span>, controlPanel);</span><br><span class="line">        <span class="keyword">this</span>.setSize(<span class="number">630</span>, <span class="number">550</span>);</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">actionPerformed</span><span class="params">(ActionEvent arg0)</span> </span>&#123;</span><br><span class="line">        String command = arg0.getActionCommand();</span><br><span class="line">        <span class="keyword">if</span> (command.equals(<span class="string">&quot;第一张&quot;</span>)) &#123;</span><br><span class="line">            ob = it.first();</span><br><span class="line">            <span class="keyword">this</span>.showPicture(ob.getName(), ob.getIntroduce());</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (command.equals(<span class="string">&quot;下一张&quot;</span>)) &#123;</span><br><span class="line">            ob = it.next();</span><br><span class="line">            <span class="keyword">this</span>.showPicture(ob.getName(), ob.getIntroduce());</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (command.equals(<span class="string">&quot;上一张&quot;</span>)) &#123;</span><br><span class="line">            ob = it.previous();</span><br><span class="line">            <span class="keyword">this</span>.showPicture(ob.getName(), ob.getIntroduce());</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (command.equals(<span class="string">&quot;最末张&quot;</span>)) &#123;</span><br><span class="line">            ob = it.last();</span><br><span class="line">            <span class="keyword">this</span>.showPicture(ob.getName(), ob.getIntroduce());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 婺源景点类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WyViewSpot</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String Name;</span><br><span class="line">    <span class="keyword">private</span> String Introduce;</span><br><span class="line">    WyViewSpot(String Name, String Introduce) &#123;</span><br><span class="line">        <span class="keyword">this</span>.Name = Name;</span><br><span class="line">        <span class="keyword">this</span>.Introduce = Introduce;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getIntroduce</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Introduce;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象聚合：婺源景点集接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">ViewSpotSet</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(WyViewSpot obj)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">remove</span><span class="params">(WyViewSpot obj)</span></span>;</span><br><span class="line">    <span class="function">ViewSpotIterator <span class="title">getIterator</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体聚合：婺源景点集</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WyViewSpotSet</span> <span class="keyword">implements</span> <span class="title">ViewSpotSet</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;WyViewSpot&gt; list = <span class="keyword">new</span> ArrayList&lt;WyViewSpot&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(WyViewSpot obj)</span> </span>&#123;</span><br><span class="line">        list.add(obj);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(WyViewSpot obj)</span> </span>&#123;</span><br><span class="line">        list.remove(obj);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ViewSpotIterator <span class="title">getIterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">new</span> WyViewSpotIterator(list));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象迭代器：婺源景点迭代器接口</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">ViewSpotIterator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">WyViewSpot <span class="title">first</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">WyViewSpot <span class="title">next</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">WyViewSpot <span class="title">previous</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">WyViewSpot <span class="title">last</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体迭代器：婺源景点迭代器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WyViewSpotIterator</span> <span class="keyword">implements</span> <span class="title">ViewSpotIterator</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;WyViewSpot&gt; list = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> index = -<span class="number">1</span>;</span><br><span class="line">    WyViewSpot obj = <span class="keyword">null</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">WyViewSpotIterator</span><span class="params">(ArrayList&lt;WyViewSpot&gt; list)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.list = list;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (index &lt; list.size() - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> WyViewSpot <span class="title">first</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        index = <span class="number">0</span>;</span><br><span class="line">        obj = list.get(index);</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> WyViewSpot <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.hasNext()) &#123;</span><br><span class="line">            obj = list.get(++index);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> WyViewSpot <span class="title">previous</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (index &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            obj = list.get(--index);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> WyViewSpot <span class="title">last</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        index = list.size() - <span class="number">1</span>;</span><br><span class="line">        obj = list.get(index);</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/c9e4911a/3.jpg" class>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>前面介绍了关于迭代器模式的结构与特点，下面介绍其应用场景，迭代器模式通常在以下几种情况使用：</p>
<ol>
<li>当需要为聚合对象提供多种遍历方式时。</li>
<li>当需要为遍历不同的聚合结构提供一个统一的接口时。</li>
<li>当访问一个聚合对象的内容而无须暴露其内部细节的表示时。</li>
</ol>
<p>由于聚合与迭代器的关系非常密切，所以大多数语言在实现聚合类时都提供了迭代器类，因此大数情况下使用语言中已有的聚合类的迭代器就已经够了。</p>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>迭代器模式常常与组合模式结合起来使用，在对组合模式中的容器构件进行访问时，经常将迭代器潜藏在组合模式的容器构成类中。当然，也可以构造一个外部迭代器来对容器构件进行访问。</p>
<img src="/c9e4911a/4.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1395.html">http://c.biancheng.net/view/1395.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-访问者模式</title>
    <url>/3d045dd4.html</url>
    <content><![CDATA[<h3 id="访问者模式（Visitor模式）"><a href="#访问者模式（Visitor模式）" class="headerlink" title="访问者模式（Visitor模式）"></a>访问者模式（Visitor模式）</h3><p>在现实生活中，有些集合对象存在多种不同的元素，且每种元素也存在多种不同的访问者和处理方式。例如，公园中存在多个景点，也存在多个游客，不同的游客对同一个景点的评价可能不同；医院医生开的处方单中包含多种药元素，査看它的划价员和药房工作人员对它的处理方式也不同，划价员根据处方单上面的药品名和数量进行划价，药房工作人员根据处方单的内容进行抓药。</p>
<p>这样的例子还有很多，例如，电影或电视剧中的人物角色，不同的观众对他们的评价也不同；还有顾客在商场购物时放在“购物车”中的商品，顾客主要关心所选商品的性价比，而收银员关心的是商品的价格和数量。</p>
<p>这些被处理的数据元素相对稳定而访问方式多种多样的数据结构，如果用“访问者模式”来处理比较方便。访问者模式能把处理方法从数据结构中分离出来，并可以根据需要增加新的处理方法，且不用修改原来的程序代码与数据结构，这提高了程序的扩展性和灵活性。</p>
<hr>
<span id="more"></span>

<h3 id="模式的定义与特点"><a href="#模式的定义与特点" class="headerlink" title="模式的定义与特点"></a>模式的定义与特点</h3><p><strong>访问者（Visitor）模式的定义：</strong>将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离，是行为类模式中最复杂的一种模式。</p>
<p>访问者（Visitor）模式是一种对象行为型模式，其主要优点如下：</p>
<ol>
<li>扩展性好。能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。</li>
<li>复用性好。可以通过访问者来定义整个对象结构通用的功能，从而提高系统的复用程度。</li>
<li>灵活性好。访问者模式将数据结构与作用于结构上的操作解耦，使得操作集合可相对自由地演化而不影响系统的数据结构。</li>
<li>符合单一职责原则。访问者模式把相关的行为封装在一起，构成一个访问者，使每一个访问者的功能都比较单一。</li>
</ol>
<p>访问者（Visitor）模式的主要缺点如下：</p>
<ol>
<li>增加新的元素类很困难。在访问者模式中，每增加一个新的元素类，都要在每一个具体访问者类中增加相应的具体操作，这违背了“开闭原则”。</li>
<li>破坏封装。访问者模式中具体元素对访问者公布细节，这破坏了对象的封装性。</li>
<li>违反了依赖倒置原则。访问者模式依赖了具体类，而没有依赖抽象类。</li>
</ol>
<hr>
<h3 id="模式的结构与实现"><a href="#模式的结构与实现" class="headerlink" title="模式的结构与实现"></a>模式的结构与实现</h3><p>访问者（Visitor）模式实现的关键是如何将作用于元素的操作分离出来封装成独立的类，其基本结构与实现方法如下。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>访问者模式包含以下主要角色：</p>
<ol>
<li>抽象访问者（Visitor）角色：定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作 visit() ，该操作中的参数类型标识了被访问的具体元素。</li>
<li>具体访问者（ConcreteVisitor）角色：实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时该做什么。</li>
<li>抽象元素（Element）角色：声明一个包含接受操作 accept() 的接口，被接受的访问者对象作为 accept() 方法的参数。</li>
<li>具体元素（ConcreteElement）角色：实现抽象元素角色提供的 accept() 操作，其方法体通常都是 visitor.visit(this) ，另外具体元素中可能还包含本身业务逻辑的相关操作。</li>
<li>对象结构（Object Structure）角色：是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法，通常由 List、Set、Map 等聚合类实现。</li>
</ol>
<img src="/3d045dd4/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>访问者模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.visitor;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VisitorPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ObjectStructure os = <span class="keyword">new</span> ObjectStructure();</span><br><span class="line">        os.add(<span class="keyword">new</span> ConcreteElementA());</span><br><span class="line">        os.add(<span class="keyword">new</span> ConcreteElementB());</span><br><span class="line">        Visitor visitor = <span class="keyword">new</span> ConcreteVisitorA();</span><br><span class="line">        os.accept(visitor);</span><br><span class="line">        System.out.println(<span class="string">&quot;------------------------&quot;</span>);</span><br><span class="line">        visitor = <span class="keyword">new</span> ConcreteVisitorB();</span><br><span class="line">        os.accept(visitor);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象访问者</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Visitor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">visit</span><span class="params">(ConcreteElementA element)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">visit</span><span class="params">(ConcreteElementB element)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体访问者A类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteVisitorA</span> <span class="keyword">implements</span> <span class="title">Visitor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(ConcreteElementA element)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体访问者A访问--&gt;&quot;</span> + element.operationA());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(ConcreteElementB element)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体访问者A访问--&gt;&quot;</span> + element.operationB());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体访问者B类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteVisitorB</span> <span class="keyword">implements</span> <span class="title">Visitor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(ConcreteElementA element)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体访问者B访问--&gt;&quot;</span> + element.operationA());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(ConcreteElementB element)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;具体访问者B访问--&gt;&quot;</span> + element.operationB());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象元素类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Element</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">accept</span><span class="params">(Visitor visitor)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体元素A类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteElementA</span> <span class="keyword">implements</span> <span class="title">Element</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(Visitor visitor)</span> </span>&#123;</span><br><span class="line">        visitor.visit(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">operationA</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;具体元素A的操作。&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体元素B类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcreteElementB</span> <span class="keyword">implements</span> <span class="title">Element</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(Visitor visitor)</span> </span>&#123;</span><br><span class="line">        visitor.visit(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">operationB</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;具体元素B的操作。&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 对象结构角色</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ObjectStructure</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;Element&gt; list = <span class="keyword">new</span> ArrayList&lt;Element&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(Visitor visitor)</span> </span>&#123;</span><br><span class="line">        Iterator&lt;Element&gt; i = list.iterator();</span><br><span class="line">        <span class="keyword">while</span> (i.hasNext()) &#123;</span><br><span class="line">            ((Element) i.next()).accept(visitor);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Element element)</span> </span>&#123;</span><br><span class="line">        list.add(element);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Element element)</span> </span>&#123;</span><br><span class="line">        list.remove(element);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体访问者A访问--&gt;具体元素A的操作。</span><br><span class="line">具体访问者A访问--&gt;具体元素B的操作。</span><br><span class="line">------------------------</span><br><span class="line">具体访问者B访问--&gt;具体元素A的操作。</span><br><span class="line">具体访问者B访问--&gt;具体元素B的操作。</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】利用“访问者（Visitor）模式”模拟艺术公司与造币公司的功能"><a href="#【例1】利用“访问者（Visitor）模式”模拟艺术公司与造币公司的功能" class="headerlink" title="【例1】利用“访问者（Visitor）模式”模拟艺术公司与造币公司的功能"></a>【例1】利用“访问者（Visitor）模式”模拟艺术公司与造币公司的功能</h4><p>分析：艺术公司利用“铜”可以设计出铜像，利用“纸”可以画出图画；造币公司利用“铜”可以印出铜币，利用“纸”可以印出纸币（点此下载运行该程序后所要显示的图片）。对“铜”和“纸”这两种元素，两个公司的处理方法不同，所以该实例用访问者模式来实现比较适合。</p>
<p>首先，定义一个公司（Company）接口，它是抽象访问者，提供了两个根据纸（Paper）或铜（Cuprum）这两种元素创建作品的方法；再定义艺术公司（ArtCompany）类和造币公司（Mint）类，它们是具体访问者，实现了父接口的方法。</p>
<p>然后，定义一个材料（Material）接口，它是抽象元素，提供了 accept（Company visitor）方法来接受访问者（Company）对象访问；再定义纸（Paper）类和铜（Cuprum）类，它们是具体元素类，实现了父接口中的方法。</p>
<p>最后，定义一个材料集（SetMaterial）类，它是对象结构角色，拥有保存所有元素的容器 List，并提供让访问者对象遍历容器中的所有元素的 accept（Company visitor）方法；客户类设计成窗体程序，它提供材料集（SetMaterial）对象供访问者（Company）对象访问，实现了 ItemListener 接口，处理用户的事件请求。</p>
<img src="/3d045dd4/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.visitor;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.ItemEvent;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.ItemListener;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VisitorProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> MaterialWin();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 窗体类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MaterialWin</span> <span class="keyword">extends</span> <span class="title">JFrame</span> <span class="keyword">implements</span> <span class="title">ItemListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    JPanel CenterJP;</span><br><span class="line">    SetMaterial os;    <span class="comment">// 材料集对象</span></span><br><span class="line">    Company visitor1, visitor2;    <span class="comment">// 访问者对象</span></span><br><span class="line">    String[] select;</span><br><span class="line">    MaterialWin() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;利用访问者模式设计艺术公司和造币公司&quot;</span>);</span><br><span class="line">        JRadioButton Art;</span><br><span class="line">        JRadioButton mint;</span><br><span class="line">        os = <span class="keyword">new</span> SetMaterial();</span><br><span class="line">        os.add(<span class="keyword">new</span> Cuprum());</span><br><span class="line">        os.add(<span class="keyword">new</span> Paper());</span><br><span class="line">        visitor1 = <span class="keyword">new</span> ArtCompany();<span class="comment">// 艺术公司</span></span><br><span class="line">        visitor2 = <span class="keyword">new</span> Mint(); <span class="comment">// 造币公司</span></span><br><span class="line">        <span class="keyword">this</span>.setBounds(<span class="number">10</span>, <span class="number">10</span>, <span class="number">750</span>, <span class="number">350</span>);</span><br><span class="line">        <span class="keyword">this</span>.setResizable(<span class="keyword">false</span>);</span><br><span class="line">        CenterJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        <span class="keyword">this</span>.add(<span class="string">&quot;Center&quot;</span>, CenterJP);</span><br><span class="line">        JPanel SouthJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        JLabel yl = <span class="keyword">new</span> JLabel(<span class="string">&quot;原材料有：铜和纸，请选择生产公司：&quot;</span>);</span><br><span class="line">        Art = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;艺术公司&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line">        mint = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;造币公司&quot;</span>);</span><br><span class="line">        Art.addItemListener(<span class="keyword">this</span>);</span><br><span class="line">        mint.addItemListener(<span class="keyword">this</span>);</span><br><span class="line">        ButtonGroup group = <span class="keyword">new</span> ButtonGroup();</span><br><span class="line">        group.add(Art);</span><br><span class="line">        group.add(mint);</span><br><span class="line">        SouthJP.add(yl);</span><br><span class="line">        SouthJP.add(Art);</span><br><span class="line">        SouthJP.add(mint);</span><br><span class="line">        <span class="keyword">this</span>.add(<span class="string">&quot;South&quot;</span>, SouthJP);</span><br><span class="line">        select = (os.accept(visitor1)).split(<span class="string">&quot; &quot;</span>);    <span class="comment">// 获取产品名</span></span><br><span class="line">        showPicture(select[<span class="number">0</span>], select[<span class="number">1</span>]);    <span class="comment">// 显示产品</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 显示图片</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">showPicture</span><span class="params">(String Cuprum, String paper)</span> </span>&#123;</span><br><span class="line">        CenterJP.removeAll();    <span class="comment">// 清除面板内容</span></span><br><span class="line">        CenterJP.repaint();    <span class="comment">// 刷新屏幕</span></span><br><span class="line">        String FileName1 = <span class="string">&quot;src/visitor/Picture/&quot;</span> + Cuprum + <span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        String FileName2 = <span class="string">&quot;src/visitor/Picture/&quot;</span> + paper + <span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        JLabel lb = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(FileName1), JLabel.CENTER);</span><br><span class="line">        JLabel rb = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(FileName2), JLabel.CENTER);</span><br><span class="line">        CenterJP.add(lb);</span><br><span class="line">        CenterJP.add(rb);</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">itemStateChanged</span><span class="params">(ItemEvent arg0)</span> </span>&#123;</span><br><span class="line">        JRadioButton jc = (JRadioButton) arg0.getSource();</span><br><span class="line">        <span class="keyword">if</span> (jc.isSelected()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (jc.getText() == <span class="string">&quot;造币公司&quot;</span>) &#123;</span><br><span class="line">                select = (os.accept(visitor2)).split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                select = (os.accept(visitor1)).split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            showPicture(select[<span class="number">0</span>], select[<span class="number">1</span>]);    <span class="comment">// 显示选择的产品</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象访问者:公司</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Company</span> </span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">create</span><span class="params">(Paper element)</span></span>;</span><br><span class="line">    <span class="function">String <span class="title">create</span><span class="params">(Cuprum element)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体访问者：艺术公司</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArtCompany</span> <span class="keyword">implements</span> <span class="title">Company</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">create</span><span class="params">(Paper element)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;讲学图&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">create</span><span class="params">(Cuprum element)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;朱熹铜像&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体访问者：造币公司</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mint</span> <span class="keyword">implements</span> <span class="title">Company</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">create</span><span class="params">(Paper element)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;纸币&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">create</span><span class="params">(Cuprum element)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;铜币&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象元素：材料</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Material</span> </span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">accept</span><span class="params">(Company visitor)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体元素：纸</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Paper</span> <span class="keyword">implements</span> <span class="title">Material</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">accept</span><span class="params">(Company visitor)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (visitor.create(<span class="keyword">this</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 具体元素：铜</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cuprum</span> <span class="keyword">implements</span> <span class="title">Material</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">accept</span><span class="params">(Company visitor)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (visitor.create(<span class="keyword">this</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 对象结构角色:材料集</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SetMaterial</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;Material&gt; list = <span class="keyword">new</span> ArrayList&lt;Material&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">accept</span><span class="params">(Company visitor)</span> </span>&#123;</span><br><span class="line">        Iterator&lt;Material&gt; i = list.iterator();</span><br><span class="line">        String tmp = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">while</span> (i.hasNext()) &#123;</span><br><span class="line">            tmp += ((Material) i.next()).accept(visitor) + <span class="string">&quot; &quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> tmp; <span class="comment">// 返回某公司的作品集</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Material element)</span> </span>&#123;</span><br><span class="line">        list.add(element);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Material element)</span> </span>&#123;</span><br><span class="line">        list.remove(element);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/3d045dd4/3.jpg" class>

<img src="/3d045dd4/4.jpg" class>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>当系统中存在类型数量稳定（固定）的一类数据结构时，可以使用访问者模式方便地实现对该类型所有数据结构的不同操作，而又不会对数据产生任何副作用（脏数据）。</p>
<p>简而言之，就是当对集合中的不同类型数据（类型数量稳定）进行多种操作时，使用访问者模式。</p>
<p>通常在以下情况可以考虑使用访问者（Visitor）模式：</p>
<ol>
<li>对象结构相对稳定，但其操作算法经常变化的程序。</li>
<li>对象结构中的对象需要提供多种不同且不相关的操作，而且要避免让这些操作的变化影响对象的结构。</li>
<li>对象结构包含很多类型的对象，希望对这些对象实施一些依赖于其具体类型的操作。</li>
</ol>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>访问者（Visitor）模式是使用频率较高的一种设计模式，它常常同以下两种设计模式联用：</p>
<ol>
<li><p>与“迭代器模式”联用。因为访问者模式中的“对象结构”是一个包含元素角色的容器，当访问者遍历容器中的所有元素时，常常要用迭代器。如【例1】中的对象结构是用 List 实现的，它通过 List 对象的 Iterator() 方法获取迭代器。如果对象结构中的聚合类没有提供迭代器，也可以用迭代器模式自定义一个。</p>
</li>
<li><p>访问者（Visitor）模式同“组合模式”联用。因为访问者（Visitor）模式中的“元素对象”可能是叶子对象或者是容器对象，如果元素对象包含容器对象，就必须用到组合模式。</p>
</li>
</ol>
<img src="/3d045dd4/5.gif" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1397.html">http://c.biancheng.net/view/1397.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-备忘录模式</title>
    <url>/9aa62758.html</url>
    <content><![CDATA[<h3 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h3><p>每个人都有犯错误的时候，都希望有种“后悔药”能弥补自己的过失，让自己重新开始，但现实是残酷的。在计算机应用中，客户同样会常常犯错误，能否提供“后悔药”给他们呢？当然是可以的，而且是有必要的。这个功能由“备忘录模式”来实现。</p>
<p>其实很多应用软件都提供了这项功能，如 Word、记事本、Photoshop、Eclipse 等软件在编辑时按 Ctrl+Z 组合键时能撤销当前操作，使文档恢复到之前的状态；还有在 IE 中的后退键、数据库事务管理中的回滚操作、玩游戏时的中间结果存档功能、数据库与操作系统的备份操作、棋类游戏中的悔棋功能等都属于这类。</p>
<p>备忘录模式能记录一个对象的内部状态，当用户后悔时能撤销当前操作，使数据恢复到它原先的状态。</p>
<hr>
<span id="more"></span>

<h3 id="模式的定义与特点"><a href="#模式的定义与特点" class="headerlink" title="模式的定义与特点"></a>模式的定义与特点</h3><p><strong>备忘录（Memento）模式的定义：</strong>在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫快照模式。</p>
<p>备忘录模式是一种对象行为型模式，其主要优点如下：</p>
<ul>
<li>提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态。</li>
<li>实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息。</li>
<li>简化了发起人类。发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，这符合单一职责原则。</li>
</ul>
<p>其主要缺点是：</p>
<ul>
<li>资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源。</li>
</ul>
<hr>
<h3 id="模式的结构与实现"><a href="#模式的结构与实现" class="headerlink" title="模式的结构与实现"></a>模式的结构与实现</h3><p>备忘录模式的核心是设计备忘录类以及用于管理备忘录的管理者类，现在我们来学习其结构与实现。</p>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>备忘录模式的主要角色如下：</p>
<ol>
<li>发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。</li>
<li>备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。</li>
<li>管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。</li>
</ol>
<img src="/9aa62758/1.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>备忘录模式的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.memento;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MementoPattern</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Originator or = <span class="keyword">new</span> Originator();</span><br><span class="line">        Caretaker cr = <span class="keyword">new</span> Caretaker();</span><br><span class="line">        or.setState(<span class="string">&quot;S0&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;初始状态:&quot;</span> + or.getState());</span><br><span class="line">        cr.setMemento(or.createMemento()); <span class="comment">// 保存状态</span></span><br><span class="line">        or.setState(<span class="string">&quot;S1&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;新的状态:&quot;</span> + or.getState());</span><br><span class="line">        or.restoreMemento(cr.getMemento()); <span class="comment">// 恢复状态</span></span><br><span class="line">        System.out.println(<span class="string">&quot;恢复状态:&quot;</span> + or.getState());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 备忘录</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Memento</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String state;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Memento</span><span class="params">(String state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(String state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> state;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 发起人</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Originator</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String state;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(String state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Memento <span class="title">createMemento</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Memento(state);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">restoreMemento</span><span class="params">(Memento m)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setState(m.getState());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 管理者</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Caretaker</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Memento memento;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMemento</span><span class="params">(Memento m)</span> </span>&#123;</span><br><span class="line">        memento = m;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Memento <span class="title">getMemento</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> memento;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">初始状态:S0</span><br><span class="line">新的状态:S1</span><br><span class="line">恢复状态:S0</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】利用备忘录模式设计相亲游戏"><a href="#【例1】利用备忘录模式设计相亲游戏" class="headerlink" title="【例1】利用备忘录模式设计相亲游戏"></a>【例1】利用备忘录模式设计相亲游戏</h4><p>分析：假如有西施、王昭君、貂蝉、杨玉环四大美女同你相亲，你可以选择其中一位作为你的爱人；当然，如果你对前面的选择不满意，还可以重新选择，但希望你不要太花心；这个游戏提供后悔功能，用“备忘录模式”设计比较合适。</p>
<p>首先，先设计一个美女（Girl）类，它是备忘录角色，提供了获取和存储美女信息的功能；然后，设计一个相亲者（You）类，它是发起人角色，它记录当前时刻的内部状态信息（临时妻子的姓名），并提供创建备忘录和恢复备忘录数据的功能；最后，定义一个美女栈（GirlStack）类，它是管理者角色，负责对备忘录进行管理，用于保存相亲者（You）前面选过的美女信息，不过最多只能保存 4 个，提供后悔功能。</p>
<p>客户类设计成窗体程序，它包含美女栈（GirlStack）对象和相亲者（You）对象，它实现了 ActionListener 接口的事件处理方法 actionPerformed(ActionEvent e)，并将 4 大美女图像和相亲者（You）选择的美女图像在窗体中显示出来。</p>
<img src="/9aa62758/2.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.memento;</span><br><span class="line"><span class="keyword">import</span> javax.swing.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.*;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.ActionEvent;</span><br><span class="line"><span class="keyword">import</span> java.awt.event.ActionListener;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DatingGame</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> DatingGameWin();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 客户窗体类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DatingGameWin</span> <span class="keyword">extends</span> <span class="title">JFrame</span> <span class="keyword">implements</span> <span class="title">ActionListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    JPanel CenterJP, EastJP;</span><br><span class="line">    JRadioButton girl1, girl2, girl3, girl4;</span><br><span class="line">    JButton button1, button2;</span><br><span class="line">    String FileName;</span><br><span class="line">    JLabel g;</span><br><span class="line">    You you;</span><br><span class="line">    GirlStack girls;</span><br><span class="line">    DatingGameWin() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">&quot;利用备忘录模式设计相亲游戏&quot;</span>);</span><br><span class="line">        you = <span class="keyword">new</span> You();</span><br><span class="line">        girls = <span class="keyword">new</span> GirlStack();</span><br><span class="line">        <span class="keyword">this</span>.setBounds(<span class="number">0</span>, <span class="number">0</span>, <span class="number">900</span>, <span class="number">380</span>);</span><br><span class="line">        <span class="keyword">this</span>.setResizable(<span class="keyword">false</span>);</span><br><span class="line">        FileName = <span class="string">&quot;src/memento/Photo/四大美女.jpg&quot;</span>;</span><br><span class="line">        g = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(FileName), JLabel.CENTER);</span><br><span class="line">        CenterJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        CenterJP.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">4</span>));</span><br><span class="line">        CenterJP.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;四大美女如下：&quot;</span>));</span><br><span class="line">        CenterJP.add(g);</span><br><span class="line">        <span class="keyword">this</span>.add(<span class="string">&quot;Center&quot;</span>, CenterJP);</span><br><span class="line">        EastJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        EastJP.setLayout(<span class="keyword">new</span> GridLayout(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">        EastJP.setBorder(BorderFactory.createTitledBorder(<span class="string">&quot;您选择的爱人是：&quot;</span>));</span><br><span class="line">        <span class="keyword">this</span>.add(<span class="string">&quot;East&quot;</span>, EastJP);</span><br><span class="line">        JPanel SouthJP = <span class="keyword">new</span> JPanel();</span><br><span class="line">        JLabel info = <span class="keyword">new</span> JLabel(<span class="string">&quot;四大美女有“沉鱼落雁之容、闭月羞花之貌”，您选择谁？&quot;</span>);</span><br><span class="line">        girl1 = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;西施&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line">        girl2 = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;貂蝉&quot;</span>);</span><br><span class="line">        girl3 = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;王昭君&quot;</span>);</span><br><span class="line">        girl4 = <span class="keyword">new</span> JRadioButton(<span class="string">&quot;杨玉环&quot;</span>);</span><br><span class="line">        button1 = <span class="keyword">new</span> JButton(<span class="string">&quot;确定&quot;</span>);</span><br><span class="line">        button2 = <span class="keyword">new</span> JButton(<span class="string">&quot;返回&quot;</span>);</span><br><span class="line">        ButtonGroup group = <span class="keyword">new</span> ButtonGroup();</span><br><span class="line">        group.add(girl1);</span><br><span class="line">        group.add(girl2);</span><br><span class="line">        group.add(girl3);</span><br><span class="line">        group.add(girl4);</span><br><span class="line">        SouthJP.add(info);</span><br><span class="line">        SouthJP.add(girl1);</span><br><span class="line">        SouthJP.add(girl2);</span><br><span class="line">        SouthJP.add(girl3);</span><br><span class="line">        SouthJP.add(girl4);</span><br><span class="line">        SouthJP.add(button1);</span><br><span class="line">        SouthJP.add(button2);</span><br><span class="line">        button1.addActionListener(<span class="keyword">this</span>);</span><br><span class="line">        button2.addActionListener(<span class="keyword">this</span>);</span><br><span class="line">        <span class="keyword">this</span>.add(<span class="string">&quot;South&quot;</span>, SouthJP);</span><br><span class="line">        showPicture(<span class="string">&quot;空白&quot;</span>);</span><br><span class="line">        you.setWife(<span class="string">&quot;空白&quot;</span>);</span><br><span class="line">        girls.push(you.createMemento());    <span class="comment">// 保存状态</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 显示图片</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">showPicture</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        EastJP.removeAll(); <span class="comment">// 清除面板内容</span></span><br><span class="line">        EastJP.repaint(); <span class="comment">// 刷新屏幕</span></span><br><span class="line">        you.setWife(name);</span><br><span class="line">        FileName = <span class="string">&quot;src/memento/Photo/&quot;</span> + name + <span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        g = <span class="keyword">new</span> JLabel(<span class="keyword">new</span> ImageIcon(FileName), JLabel.CENTER);</span><br><span class="line">        EastJP.add(g);</span><br><span class="line">        <span class="keyword">this</span>.setVisible(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">actionPerformed</span><span class="params">(ActionEvent e)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> ok = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (e.getSource() == button1) &#123;</span><br><span class="line">            ok = girls.push(you.createMemento());    <span class="comment">// 保存状态</span></span><br><span class="line">            <span class="keyword">if</span> (ok &amp;&amp; girl1.isSelected()) &#123;</span><br><span class="line">                showPicture(<span class="string">&quot;西施&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ok &amp;&amp; girl2.isSelected()) &#123;</span><br><span class="line">                showPicture(<span class="string">&quot;貂蝉&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ok &amp;&amp; girl3.isSelected()) &#123;</span><br><span class="line">                showPicture(<span class="string">&quot;王昭君&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ok &amp;&amp; girl4.isSelected()) &#123;</span><br><span class="line">                showPicture(<span class="string">&quot;杨玉环&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e.getSource() == button2) &#123;</span><br><span class="line">            you.restoreMemento(girls.pop()); <span class="comment">// 恢复状态</span></span><br><span class="line">            showPicture(you.getWife());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 备忘录：美女</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Girl</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Girl</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 发起人：您</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">You</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String wifeName;    <span class="comment">// 妻子</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setWife</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        wifeName = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getWife</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> wifeName;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Girl <span class="title">createMemento</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Girl(wifeName);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">restoreMemento</span><span class="params">(Girl p)</span> </span>&#123;</span><br><span class="line">        setWife(p.getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 管理者：美女栈</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GirlStack</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Girl girl[];</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> top;</span><br><span class="line">    GirlStack() &#123;</span><br><span class="line">        girl = <span class="keyword">new</span> Girl[<span class="number">5</span>];</span><br><span class="line">        top = -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">push</span><span class="params">(Girl p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (top &gt;= <span class="number">4</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;你太花心了，变来变去的！&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            girl[++top] = p;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Girl <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (top &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;美女栈空了！&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> girl[<span class="number">0</span>];</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">return</span> girl[top--];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如图所示：</p>
<img src="/9aa62758/3.jpg" class>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>前面学习了备忘录模式的定义与特点、结构与实现，现在来看该模式的以下应用场景：</p>
<ol>
<li>需要保存与恢复数据的场景，如玩游戏时的中间结果的存档功能。</li>
<li>需要提供一个可回滚操作的场景，如 Word、记事本、Photoshop，Eclipse 等软件在编辑时按 Ctrl+Z 组合键，还有数据库中事务操作。</li>
</ol>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>在前面介绍的备忘录模式中，有单状态备份的例子，也有多状态备份的例子。下面介绍备忘录模式如何同原型模式混合使用。在备忘录模式中，通过定义“备忘录”来备份“发起人”的信息，而原型模式的 clone() 方法具有自备份功能，所以，如果让发起人实现 Cloneable 接口就有备份自己的功能，这时可以删除备忘录类。</p>
<img src="/9aa62758/4.gif" class>

<p>实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.memento;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrototypeMemento</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        OriginatorPrototype or = <span class="keyword">new</span> OriginatorPrototype();</span><br><span class="line">        PrototypeCaretaker cr = <span class="keyword">new</span> PrototypeCaretaker();</span><br><span class="line">        or.setState(<span class="string">&quot;S0&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;初始状态:&quot;</span> + or.getState());</span><br><span class="line">        cr.setMemento(or.createMemento()); <span class="comment">// 保存状态</span></span><br><span class="line">        or.setState(<span class="string">&quot;S1&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;新的状态:&quot;</span> + or.getState());</span><br><span class="line">        or.restoreMemento(cr.getMemento()); <span class="comment">// 恢复状态</span></span><br><span class="line">        System.out.println(<span class="string">&quot;恢复状态:&quot;</span> + or.getState());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 发起人原型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OriginatorPrototype</span> <span class="keyword">implements</span> <span class="title">Cloneable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String state;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(String state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> OriginatorPrototype <span class="title">createMemento</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.clone();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">restoreMemento</span><span class="params">(OriginatorPrototype opt)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setState(opt.getState());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> OriginatorPrototype <span class="title">clone</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> (OriginatorPrototype) <span class="keyword">super</span>.clone();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (CloneNotSupportedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 原型管理者</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrototypeCaretaker</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> OriginatorPrototype opt;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMemento</span><span class="params">(OriginatorPrototype opt)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.opt = opt;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> OriginatorPrototype <span class="title">getMemento</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> opt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">初始状态:S0</span><br><span class="line">新的状态:S1</span><br><span class="line">恢复状态:S0</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1400.html">http://c.biancheng.net/view/1400.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-一句话归纳设计模式</title>
    <url>/d3e0084b.html</url>
    <content><![CDATA[<p>下面总结一下这 23 种设计模式，方便日后复习和查阅。</p>
<span id="more"></span>

<table>
<thead>
<tr>
<th>分类</th>
<th>设计模式</th>
<th>简述</th>
<th>一句话归纳</th>
<th>目的</th>
<th>生活案例</th>
</tr>
</thead>
<tbody><tr>
<td>创建型设计模式<br>（简单来说就是用来创建对象的）</td>
<td>工厂模式（Factory Pattern）</td>
<td>不同条件下创建不同实例</td>
<td>产品标准化，生产更高效</td>
<td>封装创建细节</td>
<td>实体工厂</td>
</tr>
<tr>
<td></td>
<td>单例模式（Singleton Pattern）</td>
<td>保证一个类仅有一个实例，并且提供一个全局访问点</td>
<td>世上只有一个我</td>
<td>保证独一无二</td>
<td>CEO</td>
</tr>
<tr>
<td></td>
<td>原型模式（Prototype Pattern）</td>
<td>通过拷贝原型创建新的对象</td>
<td>拔一根猴毛，吹出千万个</td>
<td>高效创建对象</td>
<td>克隆</td>
</tr>
<tr>
<td></td>
<td>建造者模式（Builder Pattern）</td>
<td>用来创建复杂的复合对象</td>
<td>高配中配和低配，想选哪配就哪配</td>
<td>开放个性配置步骤</td>
<td>选配</td>
</tr>
<tr>
<td>结构型设计模式<br>（关注类和对象的组合）</td>
<td>代理模式（Proxy Pattern）</td>
<td>为其他对象提供一种代理以控制对这个对象的访问</td>
<td>没有资源没时间，得找别人来帮忙</td>
<td>增强职责</td>
<td>媒婆</td>
</tr>
<tr>
<td></td>
<td>外观模式（Facade Pattern）</td>
<td>对外提供一个统一的接口用来访问子系统</td>
<td>打开一扇门，通向全世界</td>
<td>统一访问入口</td>
<td>前台</td>
</tr>
<tr>
<td></td>
<td>装饰器模式（Decorator Pattern）</td>
<td>为对象添加新功能</td>
<td>他大舅他二舅都是他舅</td>
<td>灵活扩展、同宗同源</td>
<td>煎饼</td>
</tr>
<tr>
<td></td>
<td>享元模式（Flyweight Pattern）</td>
<td>使用对象池来减少重复对象的创建</td>
<td>优化资源配置，减少重复浪费</td>
<td>共享资源池</td>
<td>全国社保联网</td>
</tr>
<tr>
<td></td>
<td>组合模式（Composite Pattern）</td>
<td>将整体与局部（树形结构）进行递归组合，让客户端能够以一种的方式对其进行处理</td>
<td>人在一起叫团伙，心在一起叫团队</td>
<td>统一整体和个体</td>
<td>组织架构树</td>
</tr>
<tr>
<td></td>
<td>适配器模式（Adapter Pattern）</td>
<td>将原来不兼容的两个类融合在一起</td>
<td>万能充电器</td>
<td>兼容转换</td>
<td>电源适配</td>
</tr>
<tr>
<td></td>
<td>桥接模式（Bridge Pattern）</td>
<td>将两个能够独立变化的部分分离开来</td>
<td>约定优于配置</td>
<td>不允许用继承</td>
<td>桥</td>
</tr>
<tr>
<td>行为型设计模式<br>（关注对象之间的通信）</td>
<td>模板模式（Template Pattern）    定义一套流程模板，根据需要实现模板中的操作    流程全部标准化，需要微调请覆盖    逻辑复用    把大象装进冰箱</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>策略模式（Strategy Pattern）</td>
<td>封装不同的算法，算法之间能互相替换</td>
<td>条条大道通罗马，具体哪条你来定</td>
<td>把选择权交给用户</td>
<td>选择支付方式</td>
</tr>
<tr>
<td></td>
<td>责任链模式（Chain of Responsibility Pattern）</td>
<td>拦截的类都实现统一接口，每个接收者都包含对下一个接收者的引用。将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。</td>
<td>各人自扫门前雪，莫管他们瓦上霜</td>
<td>解耦处理逻辑</td>
<td>踢皮球</td>
</tr>
<tr>
<td></td>
<td>迭代器模式（Iterator Pattern）</td>
<td>提供一种方法顺序访问一个聚合对象中的各个元素</td>
<td>流水线上坐一天，每个包裹扫一遍</td>
<td>统一对集合的访问方式</td>
<td>逐个检票进站</td>
</tr>
<tr>
<td></td>
<td>命令模式（Command Pattern）</td>
<td>将请求封装成命令，并记录下来，能够撤销与重做</td>
<td>运筹帷幄之中，决胜千里之外</td>
<td>解耦请求和处理</td>
<td>遥控器</td>
</tr>
<tr>
<td></td>
<td>状态模式（State Pattern）</td>
<td>根据不同的状态做出不同的行为</td>
<td>状态驱动行为，行为决定状态</td>
<td>绑定状态和行为</td>
<td>订单状态跟踪</td>
</tr>
<tr>
<td></td>
<td>备忘录模式（Memento Pattern）</td>
<td>保存对象的状态，在需要时进行恢复</td>
<td>失足不成千古恨，想重来时就重来</td>
<td>备份、后悔机制</td>
<td>草稿箱</td>
</tr>
<tr>
<td></td>
<td>中介者模式（Mediator Pattern）</td>
<td>将对象之间的通信关联关系封装到一个中介类中单独处理，从而使其耦合松散</td>
<td>联系方式我给你，怎么搞定我不管</td>
<td>统一管理网状资源</td>
<td>朋友圈</td>
</tr>
<tr>
<td></td>
<td>解释器模式（Interpreter Pattern）</td>
<td>给定一个语言，定义它的语法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子</td>
<td>我想说”方言“，一切解释权都归我</td>
<td>实现特定语法解析</td>
<td>摩斯密码</td>
</tr>
<tr>
<td></td>
<td>观察者模式（Observer Pattern）</td>
<td>状态发生改变时通知观察者，一对多的关系</td>
<td>到点就通知我</td>
<td>解耦观察者与被观察者</td>
<td>闹钟</td>
</tr>
<tr>
<td></td>
<td>访问者模式（Visitor Pattern）</td>
<td>稳定数据结构，定义新的操作行为</td>
<td>横看成岭侧成峰，远近高低各不同</td>
<td>解耦数据结构和数据操作</td>
<td>KPI考核</td>
</tr>
<tr>
<td></td>
<td>委派模式（Delegate Pattern）</td>
<td>允许对象组合实现与继承相同的代码重用，负责任务的调用和分配</td>
<td>这个需求很简单，怎么实现我不管</td>
<td>只对结果负责</td>
<td>授权委托书</td>
</tr>
</tbody></table>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1402.html">http://c.biancheng.net/view/1402.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-行为型模式-解释器模式</title>
    <url>/697e4fdf.html</url>
    <content><![CDATA[<h3 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h3><p>在软件开发中，会遇到有些问题多次重复出现，而且有一定的相似性和规律性。如果将它们归纳成一种简单的语言，那么这些问题实例将是该语言的一些句子，这样就可以用“编译原理”中的解释器模式来实现了。</p>
<p>虽然使用解释器模式的实例不是很多，但对于满足以上特点，且对运行效率要求不是很高的应用实例，如果用解释器模式来实现，其效果是非常好的，本文将介绍其工作原理与使用方法。</p>
<hr>
<span id="more"></span>

<h3 id="模式的定义与特点"><a href="#模式的定义与特点" class="headerlink" title="模式的定义与特点"></a>模式的定义与特点</h3><p>解释器（Interpreter）模式的定义：给分析对象定义一个语言，并定义该语言的文法表示，再设计一个解析器来解释语言中的句子。也就是说，用编译语言的方式来分析应用中的实例。这种模式实现了文法表达式处理的接口，该接口解释一个特定的上下文。</p>
<p>这里提到的文法和句子的概念同编译原理中的描述相同，“文法”指语言的语法规则，而“句子”是语言集中的元素。例如，汉语中的句子有很多，“我是中国人”是其中的一个句子，可以用一棵语法树来直观地描述语言中的句子。</p>
<p>解释器模式是一种类行为型模式，其主要优点如下：</p>
<ol>
<li>扩展性好。由于在解释器模式中使用类来表示语言的文法规则，因此可以通过继承等机制来改变或扩展文法。</li>
<li>容易实现。在语法树中的每个表达式节点类都是相似的，所以实现其文法较为容易。</li>
</ol>
<p>解释器模式的主要缺点如下：</p>
<ol>
<li>执行效率较低。解释器模式中通常使用大量的循环和递归调用，当要解释的句子较复杂时，其运行速度很慢，且代码的调试过程也比较麻烦。</li>
<li>会引起类膨胀。解释器模式中的每条规则至少需要定义一个类，当包含的文法规则很多时，类的个数将急剧增加，导致系统难以管理与维护。</li>
<li>可应用的场景比较少。在软件开发中，需要定义语言文法的应用实例非常少，所以这种模式很少被使用到。</li>
</ol>
<hr>
<h3 id="模式的结构与实现"><a href="#模式的结构与实现" class="headerlink" title="模式的结构与实现"></a>模式的结构与实现</h3><p>解释器模式常用于对简单语言的编译或分析实例中，为了掌握好它的结构与实现，必须先了解编译原理中的“文法、句子、语法树”等相关概念。</p>
<ul>
<li><p>文法</p>
<p>  文法是用于描述语言的语法结构的形式规则。没有规矩不成方圆，例如，有些人认为完美爱情的准则是“相互吸引、感情专一、任何一方都没有恋爱经历”，虽然最后一条准则较苛刻，但任何事情都要有规则，语言也一样，不管它是机器语言还是自然语言，都有它自己的文法规则。例如，中文中的“句子”的文法如下：</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">〈句子〉::=〈主语〉〈谓语〉〈宾语〉</span><br><span class="line">〈主语〉::=〈代词〉|〈名词〉</span><br><span class="line">〈谓语〉::=〈动词〉</span><br><span class="line">〈宾语〉::=〈代词〉|〈名词〉</span><br><span class="line">〈代词〉你|我|他</span><br><span class="line">〈名词〉7大学生I筱霞I英语</span><br><span class="line">〈动词〉::=是|学习</span><br></pre></td></tr></table></figure>

<p>  注：这里的符号“::=”表示“定义为”的意思，用“〈”和“〉”括住的是非终结符，没有括住的是终结符。</p>
</li>
<li><p>句子</p>
<p>  句子是语言的基本单位，是语言集中的一个元素，它由终结符构成，能由“文法”推导出。例如，上述文法可以推出“我是大学生”，所以它是句子。</p>
</li>
<li><p>语法树</p>
<p>  语法树是句子结构的一种树型表示，它代表了句子的推导结果，它有利于理解句子语法结构的层次。下图所示是“我是大学生”的语法树。</p>
  <img src="/697e4fdf/1.gif" class>

<p>  有了以上基础知识，现在来介绍解释器模式的结构就简单了。解释器模式的结构与组合模式相似，不过其包含的组成元素比组合模式多，而且组合模式是对象结构型模式，而解释器模式是类行为型模式。</p>
</li>
</ul>
<h4 id="模式的结构"><a href="#模式的结构" class="headerlink" title="模式的结构"></a>模式的结构</h4><p>解释器模式包含以下主要角色：</p>
<ol>
<li>抽象表达式（Abstract Expression）角色：定义解释器的接口，约定解释器的解释操作，主要包含解释方法 interpret()。</li>
<li>终结符表达式（Terminal Expression）角色：是抽象表达式的子类，用来实现文法中与终结符相关的操作，文法中的每一个终结符都有一个具体终结表达式与之相对应。</li>
<li>非终结符表达式（Nonterminal Expression）角色：也是抽象表达式的子类，用来实现文法中与非终结符相关的操作，文法中的每条规则都对应于一个非终结符表达式。</li>
<li>环境（Context）角色：通常包含各个解释器需要的数据或是公共的功能，一般用来传递被所有解释器共享的数据，后面的解释器可以从这里获取这些值。</li>
<li>客户端（Client）：主要任务是将需要分析的句子或表达式转换成使用解释器对象描述的抽象语法树，然后调用解释器的解释方法，当然也可以通过环境角色间接访问解释器的解释方法。</li>
</ol>
<img src="/697e4fdf/2.gif" class>

<h4 id="模式的实现"><a href="#模式的实现" class="headerlink" title="模式的实现"></a>模式的实现</h4><p>解释器模式实现的关键是定义文法规则、设计终结符类与非终结符类、画出结构图，必要时构建语法树，其代码结构如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.interpreter;</span><br><span class="line"><span class="comment">// 抽象表达式类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">AbstractExpression</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">interpret</span><span class="params">(String info)</span></span>;    <span class="comment">// 解释方法</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 终结符表达式类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TerminalExpression</span> <span class="keyword">implements</span> <span class="title">AbstractExpression</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">interpret</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 对终结符表达式的处理</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 非终结符表达式类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NonterminalExpression</span> <span class="keyword">implements</span> <span class="title">AbstractExpression</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> AbstractExpression exp1;</span><br><span class="line">    <span class="keyword">private</span> AbstractExpression exp2;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">interpret</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 非对终结符表达式的处理</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 环境类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Context</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> AbstractExpression exp;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Context</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 数据初始化</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 调用相关表达式类的解释方法</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用实例"><a href="#模式的应用实例" class="headerlink" title="模式的应用实例"></a>模式的应用实例</h3><h4 id="【例1】用解释器模式设计一个“韶粵通”公交车卡的读卡器程序"><a href="#【例1】用解释器模式设计一个“韶粵通”公交车卡的读卡器程序" class="headerlink" title="【例1】用解释器模式设计一个“韶粵通”公交车卡的读卡器程序"></a>【例1】用解释器模式设计一个“韶粵通”公交车卡的读卡器程序</h4><p>说明：假如“韶粵通”公交车读卡器可以判断乘客的身份，如果是“韶关”或者“广州”的“老人” “妇女”“儿童”就可以免费乘车，其他人员乘车一次扣 2 元。</p>
<p>分析：本实例用“解释器模式”设计比较适合，首先设计其文法规则如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;expression&gt; ::= &lt;city&gt;的&lt;person&gt;</span><br><span class="line">&lt;city&gt; ::= 韶关|广州</span><br><span class="line">&lt;person&gt; ::= 老人|妇女|儿童</span><br></pre></td></tr></table></figure>

<p>然后，根据文法规则按以下步骤设计公交车卡的读卡器程序的类图。</p>
<ul>
<li>定义一个抽象表达式（Expression）接口，它包含了解释方法 interpret(String info)。</li>
<li>定义一个终结符表达式（Terminal Expression）类，它用集合（Set）类来保存满足条件的城市或人，并实现抽象表达式接口中的解释方法 interpret(Stringinfo)，用来判断被分析的字符串是否是集合中的终结符。</li>
<li>定义一个非终结符表达式（AndExpressicm）类，它也是抽象表达式的子类，它包含满足条件的城市的终结符表达式对象和满足条件的人员的终结符表达式对象，并实现 interpret(String info) 方法，用来判断被分析的字符串是否是满足条件的城市中的满足条件的人员。</li>
<li>最后，定义一个环境（Context）类，它包含解释器需要的数据，完成对终结符表达式的初始化，并定义一个方法 freeRide(String info) 调用表达式对象的解释方法来对被分析的字符串进行解释。</li>
</ul>
<img src="/697e4fdf/3.gif" class>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.interpreter;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="comment">/*文法规则</span></span><br><span class="line"><span class="comment">  &lt;expression&gt; ::= &lt;city&gt;的&lt;person&gt;</span></span><br><span class="line"><span class="comment">  &lt;city&gt; ::= 韶关|广州</span></span><br><span class="line"><span class="comment">  &lt;person&gt; ::= 老人|妇女|儿童</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterpreterPatternDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Context bus = <span class="keyword">new</span> Context();</span><br><span class="line">        bus.freeRide(<span class="string">&quot;韶关的老人&quot;</span>);</span><br><span class="line">        bus.freeRide(<span class="string">&quot;韶关的年轻人&quot;</span>);</span><br><span class="line">        bus.freeRide(<span class="string">&quot;广州的妇女&quot;</span>);</span><br><span class="line">        bus.freeRide(<span class="string">&quot;广州的儿童&quot;</span>);</span><br><span class="line">        bus.freeRide(<span class="string">&quot;山东的儿童&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 抽象表达式类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Expression</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">interpret</span><span class="params">(String info)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 终结符表达式类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TerminalExpression</span> <span class="keyword">implements</span> <span class="title">Expression</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Set&lt;String&gt; set = <span class="keyword">new</span> HashSet&lt;String&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TerminalExpression</span><span class="params">(String[] data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; data.length; i++) set.add(data[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">interpret</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (set.contains(info)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 非终结符表达式类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AndExpression</span> <span class="keyword">implements</span> <span class="title">Expression</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Expression city = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> Expression person = <span class="keyword">null</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">AndExpression</span><span class="params">(Expression city, Expression person)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.city = city;</span><br><span class="line">        <span class="keyword">this</span>.person = person;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">interpret</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">        String s[] = info.split(<span class="string">&quot;的&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> city.interpret(s[<span class="number">0</span>]) &amp;&amp; person.interpret(s[<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 环境类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Context</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String[] citys = &#123;<span class="string">&quot;韶关&quot;</span>, <span class="string">&quot;广州&quot;</span>&#125;;</span><br><span class="line">    <span class="keyword">private</span> String[] persons = &#123;<span class="string">&quot;老人&quot;</span>, <span class="string">&quot;妇女&quot;</span>, <span class="string">&quot;儿童&quot;</span>&#125;;</span><br><span class="line">    <span class="keyword">private</span> Expression cityPerson;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Context</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Expression city = <span class="keyword">new</span> TerminalExpression(citys);</span><br><span class="line">        Expression person = <span class="keyword">new</span> TerminalExpression(persons);</span><br><span class="line">        cityPerson = <span class="keyword">new</span> AndExpression(city, person);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">freeRide</span><span class="params">(String info)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> ok = cityPerson.interpret(info);</span><br><span class="line">        <span class="keyword">if</span> (ok) System.out.println(<span class="string">&quot;您是&quot;</span> + info + <span class="string">&quot;，您本次乘车免费！&quot;</span>);</span><br><span class="line">        <span class="keyword">else</span> System.out.println(info + <span class="string">&quot;，您不是免费人员，本次乘车扣费2元！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">您是韶关的老人，您本次乘车免费！</span><br><span class="line">韶关的年轻人，您不是免费人员，本次乘车扣费2元！</span><br><span class="line">您是广州的妇女，您本次乘车免费！</span><br><span class="line">您是广州的儿童，您本次乘车免费！</span><br><span class="line">山东的儿童，您不是免费人员，本次乘车扣费2元！</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="模式的应用场景"><a href="#模式的应用场景" class="headerlink" title="模式的应用场景"></a>模式的应用场景</h3><p>前面介绍了解释器模式的结构与特点，下面分析它的应用场景：</p>
<ol>
<li>当语言的文法较为简单，且执行效率不是关键问题时。</li>
<li>当问题重复出现，且可以用一种简单的语言来进行表达时。</li>
<li>当一个语言需要解释执行，并且语言中的句子可以表示为一个抽象语法树的时候，如 XML 文档解释。</li>
</ol>
<p>注意：解释器模式在实际的软件开发中使用比较少，因为它会引起效率、性能以及维护等问题。如果碰到对表达式的解释，在 Java 中可以用 Expression4J 或 Jep 等来设计。</p>
<hr>
<h3 id="模式的扩展"><a href="#模式的扩展" class="headerlink" title="模式的扩展"></a>模式的扩展</h3><p>在项目开发中，如果要对数据表达式进行分析与计算，无须再用解释器模式进行设计了，Java 提供了以下强大的数学公式解析器：Expression4J、MESP(Math Expression String Parser) 和 Jep 等，它们可以解释一些复杂的文法，功能强大，使用简单。</p>
<p>现在以 Jep 为例来介绍该工具包的使用方法。Jep 是 Java expression parser 的简称，即 Java 表达式分析器，它是一个用来转换和计算数学表达式的 Java 库。通过这个程序库，用户可以以字符串的形式输入一个任意的公式，然后快速地计算出其结果。而且 Jep 支持用户自定义变量、常量和函数，它包括许多常用的数学函数和常量。</p>
<p>使用前先下载 Jep 压缩包，解压后，将 jep-x.x.x.jar 文件移到选择的目录中，在 Eclipse 的“Java 构建路径”对话框的“库”选项卡中选择“添加外部 JAR(X)…”，将该 Jep 包添加项目中后即可使用其中的类库。</p>
<p>下面以计算存款利息为例来介绍。存款利息的计算公式是：本金x利率x时间=利息，其相关代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.biancheng.c.interpreter;</span><br><span class="line"><span class="keyword">import</span> com.singularsys.jep.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JepDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> JepException </span>&#123;</span><br><span class="line">        Jep jep = <span class="keyword">new</span> Jep();</span><br><span class="line">        <span class="comment">// 定义要计算的数据表达式</span></span><br><span class="line">        String 存款利息 = <span class="string">&quot;本金*利率*时间&quot;</span>;</span><br><span class="line">        <span class="comment">// 给相关变量赋值</span></span><br><span class="line">        jep.addVariable(<span class="string">&quot;本金&quot;</span>, <span class="number">10000</span>);</span><br><span class="line">        jep.addVariable(<span class="string">&quot;利率&quot;</span>, <span class="number">0.038</span>);</span><br><span class="line">        jep.addVariable(<span class="string">&quot;时间&quot;</span>, <span class="number">2</span>);</span><br><span class="line">        jep.parse(存款利息);    <span class="comment">//解析表达式</span></span><br><span class="line">        Object accrual = jep.evaluate();    <span class="comment">//计算</span></span><br><span class="line">        System.out.println(<span class="string">&quot;存款利息：&quot;</span> + accrual);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">存款利息：760.0</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://c.biancheng.net/view/1402.html">http://c.biancheng.net/view/1402.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART I)</title>
    <url>/f99e6ad2.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="00-预告"><a href="#00-预告" class="headerlink" title="00 预告"></a>00 预告</h3><iframe src="//player.bilibili.com/player.html?aid=289532467&bvid=BV1if4y147hS&cid=330208219&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="01-课程安排"><a href="#01-课程安排" class="headerlink" title="01 课程安排"></a>01 课程安排</h3><iframe src="//player.bilibili.com/player.html?aid=714717789&bvid=BV1oX4y137bC&cid=313097645&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="02-深度学习介绍"><a href="#02-深度学习介绍" class="headerlink" title="02 深度学习介绍"></a>02 深度学习介绍</h3><h4 id="深度学习介绍"><a href="#深度学习介绍" class="headerlink" title="深度学习介绍"></a>深度学习介绍</h4><iframe src="//player.bilibili.com/player.html?aid=844692297&bvid=BV1J54y187f9&cid=313098241&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=844692297&bvid=BV1J54y187f9&cid=315208857&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="03-安装"><a href="#03-安装" class="headerlink" title="03 安装"></a>03 安装</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><iframe src="//player.bilibili.com/player.html?aid=972150557&bvid=BV18p4y1h7Dr&cid=313098817&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=972150557&bvid=BV18p4y1h7Dr&cid=315210492&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="04-数据操作-数据预处理"><a href="#04-数据操作-数据预处理" class="headerlink" title="04 数据操作 + 数据预处理"></a>04 数据操作 + 数据预处理</h3><h4 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h4><iframe src="//player.bilibili.com/player.html?aid=417143579&bvid=BV1CV411Y7i4&cid=313098862&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="数据操作实现"><a href="#数据操作实现" class="headerlink" title="数据操作实现"></a>数据操作实现</h4><iframe src="//player.bilibili.com/player.html?aid=417143579&bvid=BV1CV411Y7i4&cid=315213848&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="数据预处理实现"><a href="#数据预处理实现" class="headerlink" title="数据预处理实现"></a>数据预处理实现</h4><iframe src="//player.bilibili.com/player.html?aid=417143579&bvid=BV1CV411Y7i4&cid=315243179&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=417143579&bvid=BV1CV411Y7i4&cid=315221402&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="05-线性代数"><a href="#05-线性代数" class="headerlink" title="05 线性代数"></a>05 线性代数</h3><h4 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h4><iframe src="//player.bilibili.com/player.html?aid=929681632&bvid=BV1eK4y1U7Qy&cid=313099180&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="线性代数实现"><a href="#线性代数实现" class="headerlink" title="线性代数实现"></a>线性代数实现</h4><iframe src="//player.bilibili.com/player.html?aid=929681632&bvid=BV1eK4y1U7Qy&cid=315218005&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="按特定轴求和"><a href="#按特定轴求和" class="headerlink" title="按特定轴求和"></a>按特定轴求和</h4><iframe src="//player.bilibili.com/player.html?aid=929681632&bvid=BV1eK4y1U7Qy&cid=315221013&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-3"><a href="#QA-3" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=929681632&bvid=BV1eK4y1U7Qy&cid=315224660&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="06-矩阵计算"><a href="#06-矩阵计算" class="headerlink" title="06 矩阵计算"></a>06 矩阵计算</h3><h4 id="矩阵计算"><a href="#矩阵计算" class="headerlink" title="矩阵计算"></a>矩阵计算</h4><iframe src="//player.bilibili.com/player.html?aid=374679815&bvid=BV1eZ4y1w7PY&cid=313590482&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-4"><a href="#QA-4" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=374679815&bvid=BV1eZ4y1w7PY&cid=315218355&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="07-自动求导"><a href="#07-自动求导" class="headerlink" title="07 自动求导"></a>07 自动求导</h3><h4 id="自动求导"><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h4><iframe src="//player.bilibili.com/player.html?aid=332144138&bvid=BV1KA411N7Px&cid=313590656&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="自动求导实现"><a href="#自动求导实现" class="headerlink" title="自动求导实现"></a>自动求导实现</h4><iframe src="//player.bilibili.com/player.html?aid=332144138&bvid=BV1KA411N7Px&cid=315208016&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-5"><a href="#QA-5" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=332144138&bvid=BV1KA411N7Px&cid=315230365&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="08-线性回归-基础优化算法"><a href="#08-线性回归-基础优化算法" class="headerlink" title="08 线性回归 + 基础优化算法"></a>08 线性回归 + 基础优化算法</h3><h4 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h4><iframe src="//player.bilibili.com/player.html?aid=714872301&bvid=BV1PX4y1g7KC&cid=316178659&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="基础优化算法"><a href="#基础优化算法" class="headerlink" title="基础优化算法"></a>基础优化算法</h4><iframe src="//player.bilibili.com/player.html?aid=714872301&bvid=BV1PX4y1g7KC&cid=316180334&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="线性回归的从零开始实现"><a href="#线性回归的从零开始实现" class="headerlink" title="线性回归的从零开始实现"></a>线性回归的从零开始实现</h4><iframe src="//player.bilibili.com/player.html?aid=714872301&bvid=BV1PX4y1g7KC&cid=316182241&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="线性回归的简洁实现"><a href="#线性回归的简洁实现" class="headerlink" title="线性回归的简洁实现"></a>线性回归的简洁实现</h4><iframe src="//player.bilibili.com/player.html?aid=714872301&bvid=BV1PX4y1g7KC&cid=316183341&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-6"><a href="#QA-6" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=714872301&bvid=BV1PX4y1g7KC&cid=316641980&page=5" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART II)</title>
    <url>/9d6931d4.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="09-Softmax-回归-损失函数-图片分类数据集"><a href="#09-Softmax-回归-损失函数-图片分类数据集" class="headerlink" title="09 Softmax 回归 + 损失函数 + 图片分类数据集"></a>09 Softmax 回归 + 损失函数 + 图片分类数据集</h3><h4 id="Softmax-回归"><a href="#Softmax-回归" class="headerlink" title="Softmax 回归"></a>Softmax 回归</h4><iframe src="//player.bilibili.com/player.html?aid=757278510&bvid=BV1K64y1Q7wu&cid=316629827&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><iframe src="//player.bilibili.com/player.html?aid=757278510&bvid=BV1K64y1Q7wu&cid=316630803&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="图片分类数据集"><a href="#图片分类数据集" class="headerlink" title="图片分类数据集"></a>图片分类数据集</h4><iframe src="//player.bilibili.com/player.html?aid=757278510&bvid=BV1K64y1Q7wu&cid=316630964&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Softmax-回归从零开始实现"><a href="#Softmax-回归从零开始实现" class="headerlink" title="Softmax 回归从零开始实现"></a>Softmax 回归从零开始实现</h4><iframe src="//player.bilibili.com/player.html?aid=757278510&bvid=BV1K64y1Q7wu&cid=316631255&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Softmax-回归简洁实现"><a href="#Softmax-回归简洁实现" class="headerlink" title="Softmax 回归简洁实现"></a>Softmax 回归简洁实现</h4><iframe src="//player.bilibili.com/player.html?aid=757278510&bvid=BV1K64y1Q7wu&cid=316631805&page=5" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=757278510&bvid=BV1K64y1Q7wu&cid=316642595&page=6" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="10-多层感知机-代码实现"><a href="#10-多层感知机-代码实现" class="headerlink" title="10 多层感知机 + 代码实现"></a>10 多层感知机 + 代码实现</h3><h4 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h4><iframe src="//player.bilibili.com/player.html?aid=205035027&bvid=BV1hh411U7gn&cid=322558120&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h4><iframe src="//player.bilibili.com/player.html?aid=205035027&bvid=BV1hh411U7gn&cid=322559403&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><iframe src="//player.bilibili.com/player.html?aid=205035027&bvid=BV1hh411U7gn&cid=322560011&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=205035027&bvid=BV1hh411U7gn&cid=322567213&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="11-模型选择-过拟合和欠拟合"><a href="#11-模型选择-过拟合和欠拟合" class="headerlink" title="11 模型选择 + 过拟合和欠拟合"></a>11 模型选择 + 过拟合和欠拟合</h3><h4 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h4><iframe src="//player.bilibili.com/player.html?aid=715001153&bvid=BV1kX4y1g7jp&cid=323012979&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="过拟合与欠拟合"><a href="#过拟合与欠拟合" class="headerlink" title="过拟合与欠拟合"></a>过拟合与欠拟合</h4><iframe src="//player.bilibili.com/player.html?aid=715001153&bvid=BV1kX4y1g7jp&cid=323012412&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=715001153&bvid=BV1kX4y1g7jp&cid=323009112&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=715001153&bvid=BV1kX4y1g7jp&cid=323016361&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="12-权重衰退"><a href="#12-权重衰退" class="headerlink" title="12 权重衰退"></a>12 权重衰退</h3><h4 id="权重衰退"><a href="#权重衰退" class="headerlink" title="权重衰退"></a>权重衰退</h4><iframe src="//player.bilibili.com/player.html?aid=930245248&bvid=BV1UK4y1o7dy&cid=325655483&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h4><iframe src="//player.bilibili.com/player.html?aid=930245248&bvid=BV1UK4y1o7dy&cid=325680074&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-3"><a href="#QA-3" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=930245248&bvid=BV1UK4y1o7dy&cid=325655537&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="13-丢弃法"><a href="#13-丢弃法" class="headerlink" title="13 丢弃法"></a>13 丢弃法</h3><h4 id="丢弃法"><a href="#丢弃法" class="headerlink" title="丢弃法"></a>丢弃法</h4><iframe src="//player.bilibili.com/player.html?aid=460159349&bvid=BV1Y5411c7aY&cid=325656869&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h4><iframe src="//player.bilibili.com/player.html?aid=460159349&bvid=BV1Y5411c7aY&cid=325657525&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-4"><a href="#QA-4" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=460159349&bvid=BV1Y5411c7aY&cid=325666689&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="14-数值稳定性-模型初始化和激活函数"><a href="#14-数值稳定性-模型初始化和激活函数" class="headerlink" title="14 数值稳定性 + 模型初始化和激活函数"></a>14 数值稳定性 + 模型初始化和激活函数</h3><h4 id="数值稳定性"><a href="#数值稳定性" class="headerlink" title="数值稳定性"></a>数值稳定性</h4><iframe src="//player.bilibili.com/player.html?aid=760127756&bvid=BV1u64y1i75a&cid=326162337&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="模型初始化和激活函数"><a href="#模型初始化和激活函数" class="headerlink" title="模型初始化和激活函数"></a>模型初始化和激活函数</h4><iframe src="//player.bilibili.com/player.html?aid=760127756&bvid=BV1u64y1i75a&cid=326162532&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-5"><a href="#QA-5" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=760127756&bvid=BV1u64y1i75a&cid=326162451&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="15-实战：Kaggle房价预测-课程竞赛：加州2020年房价预测"><a href="#15-实战：Kaggle房价预测-课程竞赛：加州2020年房价预测" class="headerlink" title="15 实战：Kaggle房价预测 + 课程竞赛：加州2020年房价预测"></a>15 实战：Kaggle房价预测 + 课程竞赛：加州2020年房价预测</h3><h4 id="实战：Kaggle房价预测"><a href="#实战：Kaggle房价预测" class="headerlink" title="实战：Kaggle房价预测"></a>实战：Kaggle房价预测</h4><iframe src="//player.bilibili.com/player.html?aid=887640424&bvid=BV1NK4y1P7Tu&cid=326160260&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="课程竞赛：加州2020年房价预测"><a href="#课程竞赛：加州2020年房价预测" class="headerlink" title="课程竞赛：加州2020年房价预测"></a>课程竞赛：加州2020年房价预测</h4><iframe src="//player.bilibili.com/player.html?aid=887640424&bvid=BV1NK4y1P7Tu&cid=326140971&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-6"><a href="#QA-6" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=887640424&bvid=BV1NK4y1P7Tu&cid=326159111&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>JavaScript-一些手写js函数</title>
    <url>/67f3b903.html</url>
    <content><![CDATA[<h2 id="手写instanceof"><a href="#手写instanceof" class="headerlink" title="手写instanceof"></a>手写instanceof</h2><h3 id="instanceof作用"><a href="#instanceof作用" class="headerlink" title="instanceof作用"></a>instanceof作用</h3><p>判断一个实例是否是其父类或者祖先类型的实例。</p>
<p>instanceof 在查找的过程中会遍历左边变量的原型链，直到找到右边变量的 prototype 查找失败，返回 false</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> myInstanceof = <span class="function">(<span class="params">target,origin</span>) =&gt;</span> &#123;</span><br><span class="line">   <span class="keyword">while</span> (target) &#123;</span><br><span class="line">      <span class="keyword">if</span> (target.__proto__ === origin.prototype) &#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">      target = target.__proto__</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">console</span>.log(myInstanceof(a, <span class="built_in">Array</span>));  <span class="comment">// true</span></span><br><span class="line"><span class="built_in">console</span>.log(myInstanceof(a, <span class="built_in">Object</span>));  <span class="comment">// true</span></span><br></pre></td></tr></table></figure>

<span id="more"></span>

<hr>
<h2 id="实现数组的map方法"><a href="#实现数组的map方法" class="headerlink" title="实现数组的map方法"></a>实现数组的map方法</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Array</span>.prototype.myMap = <span class="function">(<span class="params">fn, thisValue</span>) =&gt;</span> &#123;</span><br><span class="line">   <span class="keyword">let</span> res = []</span><br><span class="line">   thisValue = thisValue || []</span><br><span class="line">   <span class="keyword">let</span> arr = <span class="built_in">this</span></span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">let</span> i <span class="keyword">in</span> arr) &#123;</span><br><span class="line">      res.push(fn(arr[i]))</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="reduce实现数组的map方法"><a href="#reduce实现数组的map方法" class="headerlink" title="reduce实现数组的map方法"></a>reduce实现数组的map方法</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Array</span>.prototype.myMap = <span class="function">(<span class="params">fn,thisValue</span>) =&gt;</span> &#123;</span><br><span class="line">   <span class="keyword">var</span> res = [];</span><br><span class="line">   thisValue = thisValue||[];</span><br><span class="line">   <span class="built_in">this</span>.reduce(<span class="function"><span class="keyword">function</span>(<span class="params">pre, cur, index, arr</span>)</span>&#123;</span><br><span class="line">      <span class="keyword">return</span> res.push(fn.call(thisValue, cur, index, arr));</span><br><span class="line">   &#125;,[]);</span><br><span class="line">   <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> arr = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">5</span>];</span><br><span class="line">arr.myMap(<span class="function">(<span class="params">item, index, arr</span>) =&gt;</span> &#123;</span><br><span class="line">   <span class="built_in">console</span>.log(item, index, arr);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="手写数组的reduce方法"><a href="#手写数组的reduce方法" class="headerlink" title="手写数组的reduce方法"></a>手写数组的reduce方法</h2><p>reduce() 方法接收一个函数作为累加器，数组中的每个值（从左到右）开始缩减，最终为一个值，是ES5中新增的又一个数组逐项处理方法</p>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><ul>
<li>callback（一个在数组中每一项上调用的函数，接受四个函数：）</li>
<li>previousValue（上一次调用回调函数时的返回值，或者初始值）</li>
<li>currentValue（当前正在处理的数组元素）</li>
<li>currentIndex（当前正在处理的数组元素下标）</li>
<li>array（调用reduce()方法的数组）</li>
<li>initialValue（可选的初始值。作为第一次调用回调函数时传给previousValue的值）</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">reduce</span>(<span class="params">arr, cb, initialValue</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">var</span> num = initValue == <span class="literal">undefined</span> ? num = arr[<span class="number">0</span>] : initValue;</span><br><span class="line">   <span class="keyword">var</span> i = initValue == <span class="literal">undefined</span> ? <span class="number">1</span> : <span class="number">0</span></span><br><span class="line">   <span class="keyword">for</span> (i; i &lt; arr.length; i++) &#123;</span><br><span class="line">      num = cb(num, arr[i], i)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> num</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fn</span>(<span class="params">result, currentValue, index</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> result + currentValue</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">var</span> arr = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="keyword">var</span> b = reduce(arr, fn, <span class="number">10</span>) </span><br><span class="line"><span class="keyword">var</span> c = reduce(arr, fn)</span><br><span class="line"><span class="built_in">console</span>.log(b)   <span class="comment">// 24</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="数组扁平化"><a href="#数组扁平化" class="headerlink" title="数组扁平化"></a>数组扁平化</h2><p>数组扁平化就是把多维数组转化成一维数组</p>
<ol>
<li><p>es6提供的新方法 flat(depth)</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> a = [<span class="number">1</span>, [<span class="number">2</span>, <span class="number">3</span>]]; </span><br><span class="line">a.flat();   <span class="comment">// [1,2,3] </span></span><br><span class="line">a.flat(<span class="number">1</span>);  <span class="comment">// [1,2,3]</span></span><br></pre></td></tr></table></figure>

<p>其实还有一种更简单的办法，无需知道数组的维度，直接将目标数组变成1维数组。depth的值设置为Infinity</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> a = [<span class="number">1</span>, [<span class="number">2</span>, <span class="number">3</span>, [<span class="number">4</span>, [<span class="number">5</span>]]]]; </span><br><span class="line">a.flat(<span class="literal">Infinity</span>); <span class="comment">// [1,2,3,4,5]  a是4维数组</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>利用cancat</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]]];</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">flatten</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">var</span> res = [];</span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>, length = arr.length; i &lt; length; i++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">Array</span>.isArray(arr[i])) &#123;</span><br><span class="line">         res = res.concat(flatten(arr[i])); <span class="comment">// concat 并不会改变原数组</span></span><br><span class="line">         <span class="comment">// res.push(...flatten(arr[i])); //扩展运算符 </span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         res.push(arr[i]);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line">flatten(arr1); <span class="comment">// [1, 2, 3, 1, 2, 3, 4, 2, 3, 4]</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h2 id="函数柯里化"><a href="#函数柯里化" class="headerlink" title="函数柯里化"></a>函数柯里化</h2><p>柯里化的定义：接收一部分参数，返回一个函数接收剩余参数，接收足够参数后，执行原函数。</p>
<p>当柯里化函数接收到足够参数后，就会执行原函数，如何去确定何时达到足够的参数呢？</p>
<p>有两种思路：</p>
<p>1.通过函数的 length 属性，获取函数的形参个数，形参的个数就是所需的参数个数</p>
<p>2.在调用柯里化工具函数时，手动指定所需的参数个数</p>
<p>将这两点结合一下，实现一个简单 curry 函数：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将函数柯里化</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>fn    待柯里化的原函数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>len   所需的参数个数，默认为原函数的形参个数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">curry</span>(<span class="params">fn, len = fn.length</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> _curry.call(<span class="built_in">this</span>, fn, len)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 中转函数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>fn    待柯里化的原函数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>len   所需的参数个数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>args  已接收的参数列表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_curry</span>(<span class="params">fn, len, ...args</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="function"><span class="keyword">function</span> (<span class="params">...params</span>) </span>&#123;</span><br><span class="line">      <span class="keyword">let</span> _args = [...args, ...params];</span><br><span class="line">      <span class="keyword">if</span> (_args.length &gt;= len) &#123;</span><br><span class="line">         <span class="keyword">return</span> fn.apply(<span class="built_in">this</span>, _args);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         <span class="keyword">return</span> _curry.call(<span class="built_in">this</span>, fn, len, ..._args)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们来验证一下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> _fn = curry(<span class="function"><span class="keyword">function</span>(<span class="params">a, b, c, d, e</span>)</span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log(a, b, c, d, e)</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">_fn(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);     <span class="comment">// print: 1,2,3,4,5</span></span><br><span class="line">_fn(<span class="number">1</span>)(<span class="number">2</span>)(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);     <span class="comment">// print: 1,2,3,4,5</span></span><br><span class="line">_fn(<span class="number">1</span>, <span class="number">2</span>)(<span class="number">3</span>, <span class="number">4</span>)(<span class="number">5</span>);     <span class="comment">// print: 1,2,3,4,5</span></span><br><span class="line">_fn(<span class="number">1</span>)(<span class="number">2</span>)(<span class="number">3</span>)(<span class="number">4</span>)(<span class="number">5</span>);     <span class="comment">// print: 1,2,3,4,5</span></span><br></pre></td></tr></table></figure>

<p>我们常用的工具库 lodash 也提供了 curry 方法，并且增加了非常好玩的 placeholder 功能，通过占位符的方式来改变传入参数的顺序。</p>
<p>比如说，我们传入一个占位符，本次调用传递的参数略过占位符， 占位符所在的位置由下次调用的参数来填充，比如这样：</p>
<p>直接看一下官网的例子：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> abc = <span class="function"><span class="keyword">function</span>(<span class="params">a, b, c</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> [a, b, c];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> curried = _.curry(abc);</span><br><span class="line"></span><br><span class="line">curried(<span class="number">1</span>)(<span class="number">2</span>)(<span class="number">3</span>);</span><br><span class="line"><span class="comment">// =&gt; [1, 2, 3]</span></span><br><span class="line"></span><br><span class="line">curried(<span class="number">1</span>, <span class="number">2</span>)(<span class="number">3</span>);</span><br><span class="line"><span class="comment">// =&gt; [1, 2, 3]</span></span><br><span class="line"></span><br><span class="line">curried(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">// =&gt; [1, 2, 3]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Curried with placeholders.</span></span><br><span class="line">curried(<span class="number">1</span>)(_, <span class="number">3</span>)(<span class="number">2</span>);</span><br><span class="line"><span class="comment">// =&gt; [1, 2, 3]</span></span><br></pre></td></tr></table></figure>

<p>接下来我们来思考，如何实现占位符的功能。</p>
<p>对于 lodash 的 curry 函数来说，curry 函数挂载在 lodash 对象上，所以将 lodash 对象当做默认占位符来使用。</p>
<p>而我们的自己实现的 curry 函数，本身并没有挂载在任何对象上，所以将 curry 函数当做默认占位符</p>
<p>使用占位符，目的是改变参数传递的顺序，所以在 curry 函数实现中，每次需要记录是否使用了占位符，并且记录占位符所代表的参数位置。</p>
<p>直接上代码：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param  </span>fn           待柯里化的函数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param  </span>length       需要的参数个数，默认为函数的形参个数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param  </span>holder       占位符，默认当前柯里化函数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return <span class="type">&#123;Function&#125;</span>   </span>柯里化后的函数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">curry</span>(<span class="params">fn, length = fn.length, holder = curry</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> _curry.call(<span class="built_in">this</span>, fn, length, holder, [], [])</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 中转函数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>fn            柯里化的原函数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>length        原函数需要的参数个数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>holder        接收的占位符</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>args          已接收的参数列表</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param </span>holders       已接收的占位符位置列表</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return <span class="type">&#123;Function&#125;</span>   </span>继续柯里化的函数 或 最终结果</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_curry</span>(<span class="params">fn, length, holder, args, holders</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params">..._args</span>) </span>&#123;</span><br><span class="line">      <span class="comment">// 将参数复制一份，避免多次操作同一函数导致参数混乱</span></span><br><span class="line">      <span class="keyword">let</span> params = args.slice();</span><br><span class="line">      <span class="comment">// 将占位符位置列表复制一份，新增加的占位符增加至此</span></span><br><span class="line">      <span class="keyword">let</span> _holders = holders.slice();</span><br><span class="line">      <span class="comment">// 循环入参，追加参数 或 替换占位符</span></span><br><span class="line">      _args.forEach(<span class="function">(<span class="params">arg,i</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="comment">// 真实参数 之前存在占位符 将占位符替换为真实参数</span></span><br><span class="line">         <span class="keyword">if</span> (arg !== holder &amp;&amp; holders.length) &#123;</span><br><span class="line">            <span class="keyword">let</span> index = holders.shift();</span><br><span class="line">            _holders.splice(_holders.indexOf(index), <span class="number">1</span>);</span><br><span class="line">            params[index] = arg;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 真实参数 之前不存在占位符 将参数追加到参数列表中</span></span><br><span class="line">         <span class="keyword">else</span> <span class="keyword">if</span>(arg !== holder &amp;&amp; !holders.length) &#123;</span><br><span class="line">            params.push(arg);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 传入的是占位符,之前不存在占位符 记录占位符的位置</span></span><br><span class="line">         <span class="keyword">else</span> <span class="keyword">if</span>(arg === holder &amp;&amp; !holders.length) &#123;</span><br><span class="line">            params.push(arg);</span><br><span class="line">            _holders.push(params.length - <span class="number">1</span>);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 传入的是占位符,之前存在占位符 删除原占位符位置</span></span><br><span class="line">         <span class="keyword">else</span> <span class="keyword">if</span>(arg === holder &amp;&amp; holders.length) &#123;</span><br><span class="line">            holders.shift();</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="comment">// params 中前 length 条记录中不包含占位符，执行函数</span></span><br><span class="line">      <span class="keyword">if</span> (params.length &gt;= length &amp;&amp; params.slice(<span class="number">0</span>, length).every(<span class="function"><span class="params">i</span> =&gt;</span> i !== holder)) &#123;</span><br><span class="line">         <span class="keyword">return</span> fn.apply(<span class="built_in">this</span>, params);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         <span class="keyword">return</span> _curry.call(<span class="built_in">this</span>, fn, length, holder, params, _holders)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>验证一下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> fn = <span class="function"><span class="keyword">function</span>(<span class="params">a, b, c, d, e</span>) </span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log([a, b, c, d, e]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> _ = &#123;&#125;; <span class="comment">// 定义占位符</span></span><br><span class="line"><span class="keyword">let</span> _fn = curry(fn, <span class="number">5</span>, _);  <span class="comment">// 将函数柯里化，指定所需的参数个数，指定所需的占位符</span></span><br><span class="line"></span><br><span class="line">_fn(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);                 <span class="comment">// print: 1,2,3,4,5</span></span><br><span class="line">_fn(_, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)(<span class="number">1</span>);              <span class="comment">// print: 1,2,3,4,5</span></span><br><span class="line">_fn(<span class="number">1</span>, _, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)(<span class="number">2</span>);              <span class="comment">// print: 1,2,3,4,5</span></span><br><span class="line">_fn(<span class="number">1</span>, _, <span class="number">3</span>)(_, <span class="number">4</span>,_)(<span class="number">2</span>)(<span class="number">5</span>);         <span class="comment">// print: 1,2,3,4,5</span></span><br><span class="line">_fn(<span class="number">1</span>, _, _, <span class="number">4</span>)(_, <span class="number">3</span>)(<span class="number">2</span>)(<span class="number">5</span>);        <span class="comment">// print: 1,2,3,4,5</span></span><br><span class="line">_fn(_, <span class="number">2</span>)(_, _, <span class="number">4</span>)(<span class="number">1</span>)(<span class="number">3</span>)(<span class="number">5</span>);        <span class="comment">// print: 1,2,3,4,5</span></span><br></pre></td></tr></table></figure>

<p>至此，我们已经完整实现了一个 curry 函数</p>
<hr>
<h2 id="实现深拷贝"><a href="#实现深拷贝" class="headerlink" title="实现深拷贝"></a>实现深拷贝</h2><p><strong>浅拷贝和深拷贝的区别：</strong></p>
<p>浅拷贝：只拷贝一层，更深层的对象级别的只拷贝引用</p>
<p>深拷贝：拷贝多层，每一级别的数据都会拷贝。这样更改拷贝值就不影响另外的对象</p>
<p>ES6浅拷贝方法：Object.assign(target, …sources)</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> obj = &#123;</span><br><span class="line">   <span class="attr">id</span>: <span class="number">1</span>,</span><br><span class="line">   <span class="attr">name</span>: <span class="string">&#x27;Tom&#x27;</span>,</span><br><span class="line">   <span class="attr">msg</span>: &#123;</span><br><span class="line">      <span class="attr">age</span>: <span class="number">18</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> o = &#123;&#125;</span><br><span class="line"><span class="comment">// 实现深拷贝 递归 可以用于生命游戏那个题对二维数组的拷贝</span></span><br><span class="line"><span class="comment">// 但比较麻烦，因为已知元素都是值，直接复制就行，无需判断</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">deepCopy</span>(<span class="params">newObj, oldObj</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">for</span>(<span class="keyword">let</span> k <span class="keyword">in</span> oldObj) &#123;</span><br><span class="line">      <span class="keyword">let</span> item = oldObj[k]</span><br><span class="line">      <span class="comment">//判断是数组？对象？简单类型？</span></span><br><span class="line">      <span class="keyword">if</span> (item <span class="keyword">instanceof</span> <span class="built_in">Array</span>) &#123;</span><br><span class="line">         newObj[k] = []</span><br><span class="line">         deepCopy(newObj[k], item)</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (item <span class="keyword">instanceof</span> <span class="built_in">Object</span>) &#123;</span><br><span class="line">         newObj[k] = &#123;&#125;</span><br><span class="line">         deepCopy(newObj[k], item)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         <span class="comment">//简单数据类型，直接赋值</span></span><br><span class="line">         newObj[k] = item</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="手写call-apply-bind"><a href="#手写call-apply-bind" class="headerlink" title="手写call, apply, bind"></a>手写call, apply, bind</h2><p>手写call</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Function</span>.prototype.myCall = <span class="function"><span class="keyword">function</span>(<span class="params">context = <span class="built_in">window</span></span>) </span>&#123;    <span class="comment">// 函数的方法，所以写在Fuction原型对象上</span></span><br><span class="line">   <span class="comment">// 这里if其实没必要，会自动抛出错误</span></span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">typeof</span> <span class="built_in">this</span> !== <span class="string">&quot;function&quot;</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">&quot;不是函数&quot;</span>)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// 这里可用ES6方法，为参数添加默认值，js严格模式全局作用域this为undefined</span></span><br><span class="line">   <span class="keyword">const</span> obj = context || <span class="built_in">window</span></span><br><span class="line">   <span class="comment">// this为调用的上下文,this此处为函数，将这个函数作为obj的方法</span></span><br><span class="line">   obj.fn = <span class="built_in">this</span></span><br><span class="line">   <span class="comment">// 第一个为obj所以删除,伪数组转为数组</span></span><br><span class="line">   <span class="keyword">const</span> arg = [...arguments].slice(<span class="number">1</span>)</span><br><span class="line">   res = obj.fn(...arg)</span><br><span class="line">   <span class="comment">// 不删除会导致context属性越来越多</span></span><br><span class="line">   <span class="keyword">delete</span> obj.fn</span><br><span class="line">   <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 用法：f.call(obj,arg1)</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">a, b</span>) </span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log(a + b)</span><br><span class="line">   <span class="built_in">console</span>.log(<span class="built_in">this</span>.name)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> obj = &#123;</span><br><span class="line">   <span class="attr">name</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line">f.myCall(obj, <span class="number">1</span>, <span class="number">2</span>)     <span class="comment">// 否则this指向window</span></span><br><span class="line"></span><br><span class="line">obj.greet.call(&#123;<span class="attr">name</span>: <span class="string">&#x27;Spike&#x27;</span>&#125;) <span class="comment">// 打出来的是 Spike</span></span><br></pre></td></tr></table></figure>

<p>手写apply(arguments[this, [参数1，参数2…..] ])</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 箭头函数从不具有参数对象！！！！！这里不能写成箭头函数</span></span><br><span class="line"><span class="built_in">Function</span>.prototype.myApply = <span class="function"><span class="keyword">function</span>(<span class="params">context</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">let</span> obj = context || <span class="built_in">window</span></span><br><span class="line">   obj.fn = <span class="built_in">this</span></span><br><span class="line">   <span class="keyword">const</span> arg = <span class="built_in">arguments</span>[<span class="number">1</span>] || []    <span class="comment">// 若有参数，得到的是数组</span></span><br><span class="line">   <span class="keyword">let</span> res = obj.fn(...arg)</span><br><span class="line">   <span class="keyword">delete</span> obj.fn</span><br><span class="line">   <span class="keyword">return</span> res</span><br><span class="line">&#125; </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">a, b</span>) </span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log(a, b)</span><br><span class="line">   <span class="built_in">console</span>.log(<span class="built_in">this</span>.name)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> obj = &#123;</span><br><span class="line">   <span class="attr">name</span>: <span class="string">&#x27;张三&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">f.myApply(obj, [<span class="number">1</span>, <span class="number">2</span>])     <span class="comment">// arguments[1]</span></span><br></pre></td></tr></table></figure>

<p>手写bind</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">this</span>.value = <span class="number">2</span></span><br><span class="line"><span class="keyword">var</span> foo = &#123;</span><br><span class="line">   <span class="attr">value</span>: <span class="number">1</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">var</span> bar = <span class="function"><span class="keyword">function</span>(<span class="params">name, age, school</span>) </span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log(name)                <span class="comment">// &#x27;An&#x27;</span></span><br><span class="line">   <span class="built_in">console</span>.log(age)                 <span class="comment">// 22</span></span><br><span class="line">   <span class="built_in">console</span>.log(school)              <span class="comment">// &#x27;家里蹲大学&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> result = bar.bind(foo, <span class="string">&#x27;An&#x27;</span>)    <span class="comment">// 预置了部分参数&#x27;An&#x27;</span></span><br><span class="line">result(<span class="number">22</span>, <span class="string">&#x27;家里蹲大学&#x27;</span>)            <span class="comment">// 这个参数会和预置的参数合并到一起放入bar中</span></span><br></pre></td></tr></table></figure>

<p>简单版本</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Function</span>.prototype.bind = <span class="function"><span class="keyword">function</span>(<span class="params">context, ...outerArgs</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">var</span> fn = <span class="built_in">this</span>;</span><br><span class="line">   <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params">...innerArgs</span>) </span>&#123;   <span class="comment">// 返回了一个函数，...rest为实际调用时传入的参数</span></span><br><span class="line">      <span class="keyword">return</span> fn.apply(context, [...outerArgs, ...innerArgs]);  <span class="comment">// 返回改变了this的函数，</span></span><br><span class="line">   <span class="comment">// 参数合并</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>new失败的原因：</p>
<p>例：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 声明一个上下文</span></span><br><span class="line"><span class="keyword">let</span> thovino = &#123;</span><br><span class="line">   <span class="attr">name</span>: <span class="string">&#x27;thovino&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 声明一个构造函数</span></span><br><span class="line"><span class="keyword">let</span> eat = <span class="function"><span class="keyword">function</span> (<span class="params">food</span>) </span>&#123;</span><br><span class="line">   <span class="built_in">this</span>.food = food</span><br><span class="line">   <span class="built_in">console</span>.log(<span class="string">`<span class="subst">$&#123;<span class="built_in">this</span>.name&#125;</span> eat <span class="subst">$&#123;<span class="built_in">this</span>.food&#125;</span>`</span>)</span><br><span class="line">&#125;</span><br><span class="line">eat.prototype.sayFuncName = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log(<span class="string">&#x27;func name : eat&#x27;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// bind一下</span></span><br><span class="line"><span class="keyword">let</span> thovinoEat = eat.bind(thovino)</span><br><span class="line"><span class="keyword">let</span> instance = <span class="keyword">new</span> thovinoEat(<span class="string">&#x27;orange&#x27;</span>)   <span class="comment">// 实际上orange放到了thovino里面</span></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;instance:&#x27;</span>, instance)        <span class="comment">// &#123;&#125;</span></span><br></pre></td></tr></table></figure>

<p>生成的实例是个空对象</p>
<p>在new操作符执行时，我们的thovinoEat函数可以看作是这样：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">thovinoEat</span> (<span class="params">...innerArgs</span>) </span>&#123;</span><br><span class="line">   eat.call(thovino, ...outerArgs, ...innerArgs)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在new操作符进行到第三步的操作thovinoEat.call(obj, …args)时，这里的obj是new操作符自己创建的那个简单空对象{}，但它其实并没有替换掉thovinoEat函数内部的那个上下文对象thovino。这已经超出了call的能力范围，因为这个时候要替换的已经不是thovinoEat函数内部的this指向，而应该是thovino对象。</p>
<p><strong>换句话说，我们希望的是new操作符将eat内的this指向操作符自己创建的那个空对象。但是实际上指向了thovino，new操作符的第三步动作并没有成功！</strong></p>
<p>可new可继承版本</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Function</span>.prototype.bind = <span class="function"><span class="keyword">function</span> (<span class="params">context, ...outerArgs</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">let</span> that = <span class="built_in">this</span>;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">function</span> <span class="title">res</span> (<span class="params">...innerArgs</span>) </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">this</span> <span class="keyword">instanceof</span> res) &#123;</span><br><span class="line">         <span class="comment">// new操作符执行时</span></span><br><span class="line">         <span class="comment">// 这里的this在new操作符第三步操作时，会指向new自身创建的那个简单空对象&#123;&#125;</span></span><br><span class="line">         that.call(<span class="built_in">this</span>, ...outerArgs, ...innerArgs)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         <span class="comment">// 普通bind</span></span><br><span class="line">         that.call(context, ...outerArgs, ...innerArgs)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   res.prototype = <span class="built_in">this</span>.prototype   <span class="comment">// ！！！</span></span><br><span class="line">   <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="手动实现new"><a href="#手动实现new" class="headerlink" title="手动实现new"></a>手动实现new</h2><p><strong>new的过程文字描述：</strong></p>
<ol>
<li>创建一个空对象 obj;</li>
<li>将空对象的隐式原型（proto）指向构造函数的prototype。</li>
<li>使用 call 改变 this 的指向</li>
<li>如果无返回值或者返回一个非对象值，则将 obj 返回作为新对象；如果返回值是一个新对象的话那么直接直接返回该对象。</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params">name, age</span>) </span>&#123;</span><br><span class="line">   <span class="built_in">this</span>.name = name</span><br><span class="line">   <span class="built_in">this</span>.age = age</span><br><span class="line">&#125;</span><br><span class="line">Person.prototype.sayHi = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">   <span class="built_in">console</span>.log(<span class="string">&#x27;Hi！我是&#x27;</span> + <span class="built_in">this</span>.name)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> p1 = <span class="keyword">new</span> Person(<span class="string">&#x27;张三&#x27;</span>, <span class="number">18</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 手动实现new</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">create</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">   <span class="keyword">let</span> obj = &#123;&#125;</span><br><span class="line">   <span class="comment">// 获取构造函数</span></span><br><span class="line">   <span class="keyword">let</span> fn = [].shift.call(<span class="built_in">arguments</span>)  <span class="comment">// 将arguments对象提出来转化为数组，arguments并不是数组而是对象    ！！！这种方法删除了arguments数组的第一个元素，！！这里的空数组里面填不填元素都没关系，不影响arguments的结果      或者let arg = [].slice.call(arguments,1)</span></span><br><span class="line">   obj.__proto__ = fn.prototype</span><br><span class="line">   <span class="keyword">let</span> res = fn.apply(obj, <span class="built_in">arguments</span>)    <span class="comment">// 改变this指向，为实例添加方法和属性</span></span><br><span class="line">   <span class="comment">// 确保返回的是一个对象(万一fn不是构造函数)</span></span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">typeof</span> res === <span class="string">&#x27;object&#x27;</span> ? res : obj</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> p2 = create(Person, <span class="string">&#x27;李四&#x27;</span>, <span class="number">19</span>)</span><br><span class="line">p2.sayHi()</span><br></pre></td></tr></table></figure>

<p>细节：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">[].shift.call(<span class="built_in">arguments</span>)   <span class="comment">// 也可写成：</span></span><br><span class="line"><span class="keyword">let</span> arg = [...arguments]</span><br><span class="line"><span class="keyword">let</span> fn = arg.shift()  <span class="comment">// 使得arguments能调用数组方法,第一个参数为构造函数</span></span><br><span class="line">obj.__proto__ = fn.prototype</span><br><span class="line"><span class="comment">// 改变this指向，为实例添加方法和属性</span></span><br><span class="line"><span class="keyword">let</span> res = fn.apply(obj, arg)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="手写promise-常见promise-all-promise-race"><a href="#手写promise-常见promise-all-promise-race" class="headerlink" title="手写promise(常见promise.all, promise.race)"></a>手写promise(常见promise.all, promise.race)</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Promise/A+ 规范规定的三种状态</span></span><br><span class="line"><span class="keyword">const</span> STATUS = &#123;</span><br><span class="line">   <span class="attr">PENDING</span>: <span class="string">&#x27;pending&#x27;</span>,</span><br><span class="line">   <span class="attr">FULFILLED</span>: <span class="string">&#x27;fulfilled&#x27;</span>,</span><br><span class="line">   <span class="attr">REJECTED</span>: <span class="string">&#x27;rejected&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPromise</span> </span>&#123;</span><br><span class="line">   <span class="comment">// 构造函数接收一个执行回调</span></span><br><span class="line">   <span class="function"><span class="title">constructor</span>(<span class="params">executor</span>)</span> &#123;</span><br><span class="line">      <span class="built_in">this</span>._status = STATUS.PENDING    <span class="comment">// Promise初始状态</span></span><br><span class="line">      <span class="built_in">this</span>._value = <span class="literal">undefined</span>          <span class="comment">// then回调的值</span></span><br><span class="line">      <span class="built_in">this</span>._resolveQueue = []          <span class="comment">// resolve时触发的成功队列</span></span><br><span class="line">      <span class="built_in">this</span>._rejectQueue = []           <span class="comment">// reject时触发的失败队列</span></span><br><span class="line">    </span><br><span class="line">   <span class="comment">// 使用箭头函数固定this（resolve函数在executor中触发，不然找不到this）</span></span><br><span class="line">   <span class="keyword">const</span> resolve = <span class="function"><span class="params">value</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">const</span> run = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">         <span class="comment">// Promise/A+ 规范规定的Promise状态只能从pending触发，变成fulfilled</span></span><br><span class="line">         <span class="keyword">if</span> (<span class="built_in">this</span>._status === STATUS.PENDING) &#123;</span><br><span class="line">            <span class="built_in">this</span>._status = STATUS.FULFILLED <span class="comment">// 更改状态</span></span><br><span class="line">            <span class="built_in">this</span>._value = value <span class="comment">// 储存当前值，用于then回调</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行resolve回调</span></span><br><span class="line">            <span class="keyword">while</span> (<span class="built_in">this</span>._resolveQueue.length) &#123;</span><br><span class="line">               <span class="keyword">const</span> callback = <span class="built_in">this</span>._resolveQueue.shift()</span><br><span class="line">               callback(value)</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 把resolve执行回调的操作封装成一个函数,放进setTimeout里,以实现promise异步调用的特性（规范上是微任务，这里是宏任务）</span></span><br><span class="line">      <span class="built_in">setTimeout</span>(run)</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 同 resolve</span></span><br><span class="line">   <span class="keyword">const</span> reject = <span class="function"><span class="params">value</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">const</span> run = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">         <span class="keyword">if</span> (<span class="built_in">this</span>._status === STATUS.PENDING) &#123;</span><br><span class="line">            <span class="built_in">this</span>._status = STATUS.REJECTED</span><br><span class="line">            <span class="built_in">this</span>._value = value</span><br><span class="line">        </span><br><span class="line">            <span class="keyword">while</span> (<span class="built_in">this</span>._rejectQueue.length) &#123;</span><br><span class="line">               <span class="keyword">const</span> callback = <span class="built_in">this</span>._rejectQueue.shift()</span><br><span class="line">               callback(value)</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="built_in">setTimeout</span>(run)</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// new Promise()时立即执行executor,并传入resolve和reject</span></span><br><span class="line">   executor(resolve, reject)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// then方法,接收一个成功的回调和一个失败的回调</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">then</span>(<span class="params">onFulfilled, onRejected</span>) </span>&#123;</span><br><span class="line">   <span class="comment">// 根据规范，如果then的参数不是function，则忽略它, 让值继续往下传递，链式调用继续往下执行</span></span><br><span class="line">   <span class="keyword">typeof</span> onFulfilled !== <span class="string">&#x27;function&#x27;</span> ? onFulfilled = <span class="function"><span class="params">value</span> =&gt;</span> value : <span class="literal">null</span></span><br><span class="line">   <span class="keyword">typeof</span> onRejected !== <span class="string">&#x27;function&#x27;</span> ? onRejected = <span class="function"><span class="params">error</span> =&gt;</span> error : <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">// then 返回一个新的promise</span></span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">new</span> MyPromise(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">const</span> resolveFn = <span class="function"><span class="params">value</span> =&gt;</span> &#123;</span><br><span class="line">         <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">const</span> x = onFulfilled(value)</span><br><span class="line">            <span class="comment">// 分类讨论返回值,如果是Promise,那么等待Promise状态变更,否则直接resolve</span></span><br><span class="line">            x <span class="keyword">instanceof</span> MyPromise ? x.then(resolve, reject) : resolve(x)</span><br><span class="line">         &#125; <span class="keyword">catch</span> (error) &#123;</span><br><span class="line">         reject(error)</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> rejectFn = <span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">const</span> x = onRejected(error)</span><br><span class="line">      x <span class="keyword">instanceof</span> MyPromise ? x.then(resolve, reject) : resolve(x)</span><br><span class="line">   &#125; <span class="keyword">catch</span> (error) &#123;</span><br><span class="line">      reject(error)</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> (<span class="built_in">this</span>._status) &#123;</span><br><span class="line">   <span class="keyword">case</span> STATUS.PENDING:</span><br><span class="line">      <span class="built_in">this</span>._resolveQueue.push(resolveFn)</span><br><span class="line">      <span class="built_in">this</span>._rejectQueue.push(rejectFn)</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">case</span> STATUS.FULFILLED:</span><br><span class="line">      resolveFn(<span class="built_in">this</span>._value)</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">   <span class="keyword">case</span> STATUS.REJECTED:</span><br><span class="line">      rejectFn(<span class="built_in">this</span>._value)</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">catch</span>(rejectFn) &#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="built_in">this</span>.then(<span class="literal">undefined</span>, rejectFn)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// promise.finally方法</span></span><br><span class="line"><span class="function"><span class="title">finally</span>(<span class="params">callback</span>)</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="built_in">this</span>.then(<span class="function"><span class="params">value</span> =&gt;</span> MyPromise.resolve(callback()).then(<span class="function">() =&gt;</span> value), <span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">      MyPromise.resolve(callback()).then(<span class="function">() =&gt;</span> error)</span><br><span class="line">   &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 静态resolve方法</span></span><br><span class="line"><span class="keyword">static</span> <span class="function"><span class="title">resolve</span>(<span class="params">value</span>)</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> value <span class="keyword">instanceof</span> MyPromise ? value : <span class="keyword">new</span> MyPromise(<span class="function"><span class="params">resolve</span> =&gt;</span> resolve(value))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 静态reject方法</span></span><br><span class="line"><span class="keyword">static</span> <span class="function"><span class="title">reject</span>(<span class="params">error</span>)</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">new</span> MyPromise(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> reject(error))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 静态all方法</span></span><br><span class="line"><span class="keyword">static</span> <span class="function"><span class="title">all</span>(<span class="params">promiseArr</span>)</span> &#123;</span><br><span class="line">   <span class="keyword">let</span> count = <span class="number">0</span></span><br><span class="line">   <span class="keyword">let</span> result = []</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">new</span> MyPromise(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (!promiseArr.length) &#123;</span><br><span class="line">         <span class="keyword">return</span> resolve(result)</span><br><span class="line">      &#125;</span><br><span class="line">      promiseArr.forEach(<span class="function">(<span class="params">p, i</span>) =&gt;</span> &#123;</span><br><span class="line">         MyPromise.resolve(p).then(<span class="function"><span class="params">value</span> =&gt;</span> &#123;</span><br><span class="line">            count++</span><br><span class="line">            result[i] = value</span><br><span class="line">            <span class="keyword">if</span> (count === promiseArr.length) &#123;</span><br><span class="line">               resolve(result)</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;, <span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">            reject(error)</span><br><span class="line">         &#125;)</span><br><span class="line">      &#125;)</span><br><span class="line">   &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 静态race方法</span></span><br><span class="line"><span class="keyword">static</span> <span class="function"><span class="title">race</span>(<span class="params">promiseArr</span>)</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">new</span> MyPromise(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">      promiseArr.forEach(<span class="function"><span class="params">p</span> =&gt;</span> &#123;</span><br><span class="line">         MyPromise.resolve(p).then(<span class="function"><span class="params">value</span> =&gt;</span> &#123;</span><br><span class="line">            resolve(value)</span><br><span class="line">         &#125;, <span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">            reject(error)</span><br><span class="line">         &#125;)</span><br><span class="line">      &#125;)</span><br><span class="line">   &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="手写原生AJAX"><a href="#手写原生AJAX" class="headerlink" title="手写原生AJAX"></a>手写原生AJAX</h2><p>步骤</p>
<ol>
<li>创建 XMLHttpRequest 实例</li>
<li>发出 HTTP 请求</li>
<li>服务器返回 XML 格式的字符串</li>
<li>JS 解析 XML，并更新局部页面</li>
</ol>
<p>不过随着历史进程的推进，XML 已经被淘汰，取而代之的是 JSON。</p>
<p>了解了属性和方法之后，根据 AJAX 的步骤，手写最简单的 GET 请求。<br>version 1.0：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">myButton.addEventListener(<span class="string">&#x27;click&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">  ajax()</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">ajax</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">   <span class="keyword">let</span> xhr = <span class="keyword">new</span> XMLHttpRequest() <span class="comment">//实例化，以调用方法</span></span><br><span class="line">   xhr.open(<span class="string">&#x27;get&#x27;</span>, <span class="string">&#x27;https://www.google.com&#x27;</span>)  <span class="comment">//参数2，url。参数三：异步</span></span><br><span class="line">   xhr.onreadystatechange = <span class="function">() =&gt;</span> &#123;  <span class="comment">//每当 readyState 属性改变时，就会调用该函数。</span></span><br><span class="line">      <span class="keyword">if</span> (xhr.readyState === <span class="number">4</span>) &#123;  <span class="comment">//XMLHttpRequest 代理当前所处状态。</span></span><br><span class="line">         <span class="keyword">if</span> (xhr.status &gt;= <span class="number">200</span> &amp;&amp; xhr.status &lt; <span class="number">300</span>) &#123;  <span class="comment">//200-300请求成功</span></span><br><span class="line">            <span class="keyword">let</span> string = request.responseText</span><br><span class="line">            <span class="comment">//JSON.parse() 方法用来解析JSON字符串，构造由字符串描述的JavaScript值或对象</span></span><br><span class="line">            <span class="keyword">let</span> object = <span class="built_in">JSON</span>.parse(string)</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   request.send() <span class="comment">//用于实际发出 HTTP 请求。不带参数为GET请求</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>promise实现</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">ajax</span>(<span class="params">url</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">const</span> p = <span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">let</span> xhr = <span class="keyword">new</span> XMLHttpRequest()</span><br><span class="line">      xhr.open(<span class="string">&#x27;get&#x27;</span>, url)</span><br><span class="line">      xhr.onreadystatechange = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (xhr.readyState == <span class="number">4</span>) &#123;</span><br><span class="line">         <span class="keyword">if</span> (xhr.status &gt;= <span class="number">200</span> &amp;&amp; xhr.status &lt;= <span class="number">300</span>) &#123;</span><br><span class="line">            resolve(<span class="built_in">JSON</span>.parse(xhr.responseText))</span><br><span class="line">         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            reject(<span class="string">&#x27;请求出错&#x27;</span>)</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   xhr.send()  <span class="comment">//发送hppt请求</span></span><br><span class="line">   &#125;)</span><br><span class="line">   <span class="keyword">return</span> p</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> url = <span class="string">&#x27;/data.json&#x27;</span></span><br><span class="line">ajax(url)</span><br><span class="line">.then(<span class="function"><span class="params">res</span> =&gt;</span> <span class="built_in">console</span>.log(res))</span><br><span class="line">.catch(<span class="function"><span class="params">reason</span> =&gt;</span> <span class="built_in">console</span>.log(reason))</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="手写节流防抖函数"><a href="#手写节流防抖函数" class="headerlink" title="手写节流防抖函数"></a>手写节流防抖函数</h2><p>防抖：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">debounce</span>(<span class="params">fn, delay</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">typeof</span> fn!==<span class="string">&#x27;function&#x27;</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">TypeError</span>(<span class="string">&#x27;fn不是函数&#x27;</span>)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">let</span> timer; <span class="comment">// 维护一个 timer</span></span><br><span class="line">   <span class="keyword">return</span> <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">      <span class="keyword">var</span> _this = <span class="built_in">this</span>; <span class="comment">// 取debounce执行作用域的this(原函数挂载到的对象)</span></span><br><span class="line">      <span class="keyword">var</span> args = <span class="built_in">arguments</span>;</span><br><span class="line">      <span class="keyword">if</span> (timer) &#123;</span><br><span class="line">         <span class="built_in">clearTimeout</span>(timer);</span><br><span class="line">      &#125;</span><br><span class="line">      timer = <span class="built_in">setTimeout</span>(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">         fn.apply(_this, args); <span class="comment">// 用apply指向调用debounce的对象，相当于_this.fn(args);</span></span><br><span class="line">      &#125;, delay);</span><br><span class="line">   &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">input1.addEventListener(<span class="string">&#x27;keyup&#x27;</span>, debounce(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">   <span class="built_in">console</span>.log(input1.value)</span><br><span class="line">&#125;), <span class="number">600</span>)</span><br></pre></td></tr></table></figure>

<p>节流：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">throttle</span>(<span class="params">fn, delay</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">let</span> timer;</span><br><span class="line">   <span class="keyword">return</span> <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">      <span class="keyword">var</span> _this = <span class="built_in">this</span>;</span><br><span class="line">      <span class="keyword">var</span> args = <span class="built_in">arguments</span>;</span><br><span class="line">      <span class="keyword">if</span> (timer) &#123;</span><br><span class="line">         <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      timer = <span class="built_in">setTimeout</span>(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">         fn.apply(_this, args); <span class="comment">// 这里args接收的是外边返回的函数的参数，不能用arguments</span></span><br><span class="line">         <span class="comment">// fn.apply(_this, arguments); 需要注意：Chrome 14 以及 Internet Explorer 9 仍然不接受类数组对象。如果传入类数组对象，它们会抛出异常。</span></span><br><span class="line">         timer = <span class="literal">null</span>; <span class="comment">// 在delay后执行完fn之后清空timer，此时timer为假，throttle触发可以进入计时器</span></span><br><span class="line">      &#125;, delay)</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">div1.addEventListener(<span class="string">&#x27;drag&#x27;</span>, throttle(<span class="function">(<span class="params">e</span>) =&gt;</span> &#123;</span><br><span class="line">   <span class="built_in">console</span>.log(e.offsetX, e.offsetY)</span><br><span class="line">&#125;, <span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="手写Promise加载图片"><a href="#手写Promise加载图片" class="headerlink" title="手写Promise加载图片"></a>手写Promise加载图片</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getData</span>(<span class="params">url</span>) </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(<span class="function">(<span class="params">resolve, reject</span>) =&gt;</span> &#123;</span><br><span class="line">      $.ajax(&#123;</span><br><span class="line">         url,</span><br><span class="line">         <span class="function"><span class="title">success</span>(<span class="params">data</span>)</span> &#123;</span><br><span class="line">         resolve(data)</span><br><span class="line">         &#125;,</span><br><span class="line">         <span class="function"><span class="title">error</span>(<span class="params">err</span>)</span> &#123;</span><br><span class="line">         reject(err)</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">   &#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">const</span> url1 = <span class="string">&#x27;./data1.json&#x27;</span></span><br><span class="line"><span class="keyword">const</span> url2 = <span class="string">&#x27;./data2.json&#x27;</span></span><br><span class="line"><span class="keyword">const</span> url3 = <span class="string">&#x27;./data3.json&#x27;</span></span><br><span class="line">getData(url1)</span><br><span class="line">.then(<span class="function"><span class="params">data1</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(data1)</span><br><span class="line">  <span class="keyword">return</span> getData(url2)</span><br><span class="line">&#125;)</span><br><span class="line">.then(<span class="function"><span class="params">data2</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(data2)</span><br><span class="line">  <span class="keyword">return</span> getData(url3)</span><br><span class="line">&#125;)</span><br><span class="line">.then(<span class="function"><span class="params">data3</span> =&gt;</span> &#123;</span><br><span class="line">   <span class="built_in">console</span>.log(data3)</span><br><span class="line">&#125;)</span><br><span class="line">.catch(<span class="function"><span class="params">err</span> =&gt;</span> &#123;</span><br><span class="line">   <span class="built_in">console</span>.error(err)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="函数实现一秒钟输出一个数"><a href="#函数实现一秒钟输出一个数" class="headerlink" title="函数实现一秒钟输出一个数"></a>函数实现一秒钟输出一个数</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt;= <span class="number">10</span>; i++)&#123;   <span class="comment">//用var打印的都是11</span></span><br><span class="line">   <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">      <span class="built_in">console</span>.log(i);</span><br><span class="line">   &#125;, <span class="number">1000</span>*i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="创建10个标签，点击的时候弹出来对应的序号"><a href="#创建10个标签，点击的时候弹出来对应的序号" class="headerlink" title="创建10个标签，点击的时候弹出来对应的序号"></a>创建10个标签，点击的时候弹出来对应的序号</h2><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">   a = <span class="built_in">document</span>.createElement(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">   a.innerHTML = i + <span class="string">&#x27;&lt;br&gt;&#x27;</span></span><br><span class="line">   a.addEventListener(<span class="string">&#x27;click&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">e</span>) </span>&#123;</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="built_in">this</span>)    <span class="comment">//this为当前点击的&lt;a&gt;</span></span><br><span class="line">      e.preventDefault()   <span class="comment">//如果调用这个方法，默认事件行为将不再触发。</span></span><br><span class="line">      <span class="comment">//例如，在执行这个方法后，如果点击一个链接（a标签），浏览器不会跳转到新的 URL 去了。我们可以用 event.isDefaultPrevented() 来确定这个方法是否(在那个事件对象上)被调用过了。</span></span><br><span class="line">      alert(i)</span><br><span class="line">   &#125;)</span><br><span class="line">   <span class="keyword">const</span> d = <span class="built_in">document</span>.querySelector(<span class="string">&#x27;div&#x27;</span>)</span><br><span class="line">   d.appendChild(a)  <span class="comment">//append向一个已存在的元素追加该元素。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐JavaScript</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART III)</title>
    <url>/746e63ba.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="16-PyTorch-神经网络基础"><a href="#16-PyTorch-神经网络基础" class="headerlink" title="16 PyTorch 神经网络基础"></a>16 PyTorch 神经网络基础</h3><h4 id="模型构造"><a href="#模型构造" class="headerlink" title="模型构造"></a>模型构造</h4><iframe src="//player.bilibili.com/player.html?aid=887637315&bvid=BV1AK4y1P7vs&cid=328773796&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="参数管理"><a href="#参数管理" class="headerlink" title="参数管理"></a>参数管理</h4><iframe src="//player.bilibili.com/player.html?aid=887637315&bvid=BV1AK4y1P7vs&cid=328778474&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h4><iframe src="//player.bilibili.com/player.html?aid=887637315&bvid=BV1AK4y1P7vs&cid=328784234&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h4><iframe src="//player.bilibili.com/player.html?aid=887637315&bvid=BV1AK4y1P7vs&cid=328785272&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=887637315&bvid=BV1AK4y1P7vs&cid=328800705&page=5" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="17-使用和购买-GPU"><a href="#17-使用和购买-GPU" class="headerlink" title="17 使用和购买 GPU"></a>17 使用和购买 GPU</h3><h4 id="使用GPU"><a href="#使用GPU" class="headerlink" title="使用GPU"></a>使用GPU</h4><iframe src="//player.bilibili.com/player.html?aid=460180427&bvid=BV1z5411c7C1&cid=328810562&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="购买GPU"><a href="#购买GPU" class="headerlink" title="购买GPU"></a>购买GPU</h4><iframe src="//player.bilibili.com/player.html?aid=460180427&bvid=BV1z5411c7C1&cid=328811729&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=460180427&bvid=BV1z5411c7C1&cid=328814546&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="18-预测房价竞赛总结"><a href="#18-预测房价竞赛总结" class="headerlink" title="18 预测房价竞赛总结"></a>18 预测房价竞赛总结</h3><h4 id="竞赛总结"><a href="#竞赛总结" class="headerlink" title="竞赛总结"></a>竞赛总结</h4><iframe src="//player.bilibili.com/player.html?aid=715547166&bvid=BV15Q4y1o7vc&cid=339186268&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=715547166&bvid=BV15Q4y1o7vc&cid=339188344&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="19-卷积层"><a href="#19-卷积层" class="headerlink" title="19 卷积层"></a>19 卷积层</h3><h4 id="从全连接到卷积"><a href="#从全连接到卷积" class="headerlink" title="从全连接到卷积"></a>从全连接到卷积</h4><iframe src="//player.bilibili.com/player.html?aid=758101639&bvid=BV1L64y1m7Nh&cid=339191747&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><iframe src="//player.bilibili.com/player.html?aid=758101639&bvid=BV1L64y1m7Nh&cid=339193886&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=758101639&bvid=BV1L64y1m7Nh&cid=339194753&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-3"><a href="#QA-3" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=758101639&bvid=BV1L64y1m7Nh&cid=339195845&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="20-卷积层里的填充和步幅"><a href="#20-卷积层里的填充和步幅" class="headerlink" title="20 卷积层里的填充和步幅"></a>20 卷积层里的填充和步幅</h3><h4 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h4><iframe src="//player.bilibili.com/player.html?aid=205518852&bvid=BV1Th411U7UN&cid=339698670&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><iframe src="//player.bilibili.com/player.html?aid=205518852&bvid=BV1Th411U7UN&cid=339703512&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-4"><a href="#QA-4" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=205518852&bvid=BV1Th411U7UN&cid=339704905&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="21-卷积层里的多输入多输出通道"><a href="#21-卷积层里的多输入多输出通道" class="headerlink" title="21 卷积层里的多输入多输出通道"></a>21 卷积层里的多输入多输出通道</h3><h4 id="多输入多输出通道"><a href="#多输入多输出通道" class="headerlink" title="多输入多输出通道"></a>多输入多输出通道</h4><iframe src="//player.bilibili.com/player.html?aid=588058788&bvid=BV1MB4y1F7of&cid=339699427&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h4><iframe src="//player.bilibili.com/player.html?aid=588058788&bvid=BV1MB4y1F7of&cid=339709745&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-5"><a href="#QA-5" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=588058788&bvid=BV1MB4y1F7of&cid=339711414&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="22-池化层"><a href="#22-池化层" class="headerlink" title="22 池化层"></a>22 池化层</h3><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><iframe src="//player.bilibili.com/player.html?aid=418134600&bvid=BV1EV411j7nX&cid=342422678&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><iframe src="//player.bilibili.com/player.html?aid=418134600&bvid=BV1EV411j7nX&cid=342425342&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-6"><a href="#QA-6" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=418134600&bvid=BV1EV411j7nX&cid=342427718&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART IV)</title>
    <url>/50333f4a.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="23-经典卷积神经网络-LeNet"><a href="#23-经典卷积神经网络-LeNet" class="headerlink" title="23 经典卷积神经网络 LeNet"></a>23 经典卷积神经网络 LeNet</h3><h4 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h4><iframe src="//player.bilibili.com/player.html?aid=973192378&bvid=BV1t44y1r7ct&cid=342424736&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=973192378&bvid=BV1t44y1r7ct&cid=342429710&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=973192378&bvid=BV1t44y1r7ct&cid=342433519&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="24-深度卷积神经网络-AlexNet"><a href="#24-深度卷积神经网络-AlexNet" class="headerlink" title="24 深度卷积神经网络 AlexNet"></a>24 深度卷积神经网络 AlexNet</h3><h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><iframe src="//player.bilibili.com/player.html?aid=845665724&bvid=BV1h54y1L7oe&cid=342934163&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=845665724&bvid=BV1h54y1L7oe&cid=342941316&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=845665724&bvid=BV1h54y1L7oe&cid=342947127&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="25-使用块的网络-VGG"><a href="#25-使用块的网络-VGG" class="headerlink" title="25 使用块的网络 VGG"></a>25 使用块的网络 VGG</h3><h4 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h4><iframe src="//player.bilibili.com/player.html?aid=375682529&bvid=BV1Ao4y117Pd&cid=342942152&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=375682529&bvid=BV1Ao4y117Pd&cid=342950623&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=375682529&bvid=BV1Ao4y117Pd&cid=342952293&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="26-网络中的网络-NiN"><a href="#26-网络中的网络-NiN" class="headerlink" title="26 网络中的网络 NiN"></a>26 网络中的网络 NiN</h3><h4 id="NiN"><a href="#NiN" class="headerlink" title="NiN"></a>NiN</h4><iframe src="//player.bilibili.com/player.html?aid=248254059&bvid=BV1Uv411G71b&cid=345704720&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=248254059&bvid=BV1Uv411G71b&cid=345707726&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-3"><a href="#QA-3" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=248254059&bvid=BV1Uv411G71b&cid=345709379&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="27-含并行连结的网络-GoogLeNet-Inception-V3"><a href="#27-含并行连结的网络-GoogLeNet-Inception-V3" class="headerlink" title="27 含并行连结的网络 GoogLeNet / Inception V3"></a>27 含并行连结的网络 GoogLeNet / Inception V3</h3><h4 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h4><iframe src="//player.bilibili.com/player.html?aid=460824062&bvid=BV1b5411g7Xo&cid=345710662&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=460824062&bvid=BV1b5411g7Xo&cid=345717219&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-4"><a href="#QA-4" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=460824062&bvid=BV1b5411g7Xo&cid=345718588&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="28-批量归一化"><a href="#28-批量归一化" class="headerlink" title="28 批量归一化"></a>28 批量归一化</h3><h4 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h4><iframe src="//player.bilibili.com/player.html?aid=973300661&bvid=BV1X44y1r77r&cid=346236353&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-5"><a href="#代码-5" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=973300661&bvid=BV1X44y1r77r&cid=346242830&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-5"><a href="#QA-5" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=973300661&bvid=BV1X44y1r77r&cid=346245495&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="29-残差网络-ResNet"><a href="#29-残差网络-ResNet" class="headerlink" title="29 残差网络 ResNet"></a>29 残差网络 ResNet</h3><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><iframe src="//player.bilibili.com/player.html?aid=418363999&bvid=BV1bV41177ap&cid=346237766&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-6"><a href="#代码-6" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=418363999&bvid=BV1bV41177ap&cid=346247194&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-6"><a href="#QA-6" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=418363999&bvid=BV1bV41177ap&cid=346248634&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="29-2-ResNet为什么能训练出1000层的模型"><a href="#29-2-ResNet为什么能训练出1000层的模型" class="headerlink" title="29.2 ResNet为什么能训练出1000层的模型"></a>29.2 ResNet为什么能训练出1000层的模型</h3><h4 id="ResNet的梯度计算"><a href="#ResNet的梯度计算" class="headerlink" title="ResNet的梯度计算"></a>ResNet的梯度计算</h4><iframe src="//player.bilibili.com/player.html?aid=845908060&bvid=BV1554y157E3&cid=349736004&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-7"><a href="#QA-7" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=845908060&bvid=BV1554y157E3&cid=349737277&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="30-第二部分完结竞赛：图片分类"><a href="#30-第二部分完结竞赛：图片分类" class="headerlink" title="30 第二部分完结竞赛：图片分类"></a>30 第二部分完结竞赛：图片分类</h3><h4 id="竞赛"><a href="#竞赛" class="headerlink" title="竞赛"></a>竞赛</h4><iframe src="//player.bilibili.com/player.html?aid=758363663&bvid=BV1z64y1o7iz&cid=346238399&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART V)</title>
    <url>/34c4644c.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="31-深度学习硬件：CPU-和-GPU"><a href="#31-深度学习硬件：CPU-和-GPU" class="headerlink" title="31 深度学习硬件：CPU 和 GPU"></a>31 深度学习硬件：CPU 和 GPU</h3><h4 id="CPU-和-GPU"><a href="#CPU-和-GPU" class="headerlink" title="CPU 和 GPU"></a>CPU 和 GPU</h4><iframe src="//player.bilibili.com/player.html?aid=673440227&bvid=BV1TU4y1j7Wd&cid=349230699&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=673440227&bvid=BV1TU4y1j7Wd&cid=349236760&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="32-深度学习硬件：TPU和其他"><a href="#32-深度学习硬件：TPU和其他" class="headerlink" title="32 深度学习硬件：TPU和其他"></a>32 深度学习硬件：TPU和其他</h3><h4 id="更多的芯片"><a href="#更多的芯片" class="headerlink" title="更多的芯片"></a>更多的芯片</h4><iframe src="//player.bilibili.com/player.html?aid=418495005&bvid=BV1VV41147PC&cid=349737728&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=418495005&bvid=BV1VV41147PC&cid=349742249&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="33-单机多卡并行"><a href="#33-单机多卡并行" class="headerlink" title="33 单机多卡并行"></a>33 单机多卡并行</h3><h4 id="单机多卡并行"><a href="#单机多卡并行" class="headerlink" title="单机多卡并行"></a>单机多卡并行</h4><iframe src="//player.bilibili.com/player.html?aid=673475005&bvid=BV1vU4y1V7rd&cid=349741612&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=673475005&bvid=BV1vU4y1V7rd&cid=349742102&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="34-多GPU训练实现"><a href="#34-多GPU训练实现" class="headerlink" title="34 多GPU训练实现"></a>34 多GPU训练实现</h3><h4 id="从零开始"><a href="#从零开始" class="headerlink" title="从零开始"></a>从零开始</h4><iframe src="//player.bilibili.com/player.html?aid=716153757&bvid=BV1MQ4y1R7Qg&cid=356484743&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h4><iframe src="//player.bilibili.com/player.html?aid=716153757&bvid=BV1MQ4y1R7Qg&cid=356489308&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-3"><a href="#QA-3" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=716153757&bvid=BV1MQ4y1R7Qg&cid=356491300&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="35-分布式训练"><a href="#35-分布式训练" class="headerlink" title="35 分布式训练"></a>35 分布式训练</h3><h4 id="分布式训练"><a href="#分布式训练" class="headerlink" title="分布式训练"></a>分布式训练</h4><iframe src="//player.bilibili.com/player.html?aid=673739196&bvid=BV1jU4y1G7iu&cid=356491827&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-4"><a href="#QA-4" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=673739196&bvid=BV1jU4y1G7iu&cid=356491978&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="36-数据增广"><a href="#36-数据增广" class="headerlink" title="36 数据增广"></a>36 数据增广</h3><h4 id="数据增广"><a href="#数据增广" class="headerlink" title="数据增广"></a>数据增广</h4><iframe src="//player.bilibili.com/player.html?aid=803728933&bvid=BV17y4y1g76q&cid=356993232&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=803728933&bvid=BV17y4y1g76q&cid=356996025&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-5"><a href="#QA-5" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=803728933&bvid=BV17y4y1g76q&cid=356999447&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="37-微调"><a href="#37-微调" class="headerlink" title="37 微调"></a>37 微调</h3><h4 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h4><iframe src="//player.bilibili.com/player.html?aid=631134930&bvid=BV1Sb4y1d7CR&cid=357000346&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=631134930&bvid=BV1Sb4y1d7CR&cid=357000451&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-6"><a href="#QA-6" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=631134930&bvid=BV1Sb4y1d7CR&cid=357000547&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="38-第二次竞赛-树叶分类结果"><a href="#38-第二次竞赛-树叶分类结果" class="headerlink" title="38 第二次竞赛 树叶分类结果"></a>38 第二次竞赛 树叶分类结果</h3><iframe src="//player.bilibili.com/player.html?aid=631276695&bvid=BV1Eb4y1C7Fn&cid=359960472&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="39-实战-Kaggle-比赛：图像分类（CIFAR-10）"><a href="#39-实战-Kaggle-比赛：图像分类（CIFAR-10）" class="headerlink" title="39 实战 Kaggle 比赛：图像分类（CIFAR-10）"></a>39 实战 Kaggle 比赛：图像分类（CIFAR-10）</h3><h4 id="Kaggle-CIFAR-10"><a href="#Kaggle-CIFAR-10" class="headerlink" title="Kaggle CIFAR-10"></a>Kaggle CIFAR-10</h4><iframe src="//player.bilibili.com/player.html?aid=803807574&bvid=BV1Gy4y1M7Cu&cid=359962250&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-7"><a href="#QA-7" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=803807574&bvid=BV1Gy4y1M7Cu&cid=359967377&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="40-实战-Kaggle-比赛：狗的品种识别（ImageNet-Dogs）"><a href="#40-实战-Kaggle-比赛：狗的品种识别（ImageNet-Dogs）" class="headerlink" title="40 实战 Kaggle 比赛：狗的品种识别（ImageNet Dogs）"></a>40 实战 Kaggle 比赛：狗的品种识别（ImageNet Dogs）</h3><h4 id="Kaggle-ImageNet-Dog"><a href="#Kaggle-ImageNet-Dog" class="headerlink" title="Kaggle ImageNet Dog"></a>Kaggle ImageNet Dog</h4><iframe src="//player.bilibili.com/player.html?aid=461272350&bvid=BV1j5411T7wx&cid=359967655&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-8"><a href="#QA-8" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=461272350&bvid=BV1j5411T7wx&cid=359970791&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART VI)</title>
    <url>/8a13d599.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="41-物体检测和数据集"><a href="#41-物体检测和数据集" class="headerlink" title="41 物体检测和数据集"></a>41 物体检测和数据集</h3><h4 id="物体检测"><a href="#物体检测" class="headerlink" title="物体检测"></a>物体检测</h4><iframe src="//player.bilibili.com/player.html?aid=206250574&bvid=BV1Lh411Y7LX&cid=360492982&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="边缘框实现"><a href="#边缘框实现" class="headerlink" title="边缘框实现"></a>边缘框实现</h4><iframe src="//player.bilibili.com/player.html?aid=206250574&bvid=BV1Lh411Y7LX&cid=360494934&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><iframe src="//player.bilibili.com/player.html?aid=206250574&bvid=BV1Lh411Y7LX&cid=360495626&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=206250574&bvid=BV1Lh411Y7LX&cid=360497382&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="42-锚框"><a href="#42-锚框" class="headerlink" title="42 锚框"></a>42 锚框</h3><h4 id="锚框"><a href="#锚框" class="headerlink" title="锚框"></a>锚框</h4><iframe src="//player.bilibili.com/player.html?aid=588787564&bvid=BV1aB4y1K7za&cid=360496513&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=588787564&bvid=BV1aB4y1K7za&cid=360505070&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=588787564&bvid=BV1aB4y1K7za&cid=360509177&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="43-树叶分类竞赛技术总结"><a href="#43-树叶分类竞赛技术总结" class="headerlink" title="43 树叶分类竞赛技术总结"></a>43 树叶分类竞赛技术总结</h3><iframe src="//player.bilibili.com/player.html?aid=803995705&bvid=BV1by4y1K7SE&cid=363602710&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="44-物体检测算法：R-CNN，SSD，YOLO"><a href="#44-物体检测算法：R-CNN，SSD，YOLO" class="headerlink" title="44 物体检测算法：R-CNN，SSD，YOLO"></a>44 物体检测算法：R-CNN，SSD，YOLO</h3><h4 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h4><iframe src="//player.bilibili.com/player.html?aid=631383373&bvid=BV1Db4y1C71g&cid=364137722&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=631383373&bvid=BV1Db4y1C71g&cid=363606575&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="45-SSD实现"><a href="#45-SSD实现" class="headerlink" title="45 SSD实现"></a>45 SSD实现</h3><h4 id="多尺度锚框"><a href="#多尺度锚框" class="headerlink" title="多尺度锚框"></a>多尺度锚框</h4><iframe src="//player.bilibili.com/player.html?aid=716443297&bvid=BV1ZX4y1c7Sw&cid=364138290&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h4><iframe src="//player.bilibili.com/player.html?aid=716443297&bvid=BV1ZX4y1c7Sw&cid=364144536&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-3"><a href="#QA-3" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=716443297&bvid=BV1ZX4y1c7Sw&cid=364144643&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="46-语义分割和数据集"><a href="#46-语义分割和数据集" class="headerlink" title="46 语义分割和数据集"></a>46 语义分割和数据集</h3><h4 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h4><iframe src="//player.bilibili.com/player.html?aid=889059767&bvid=BV1BK4y1M7Rd&cid=367422597&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="语义分割数据集"><a href="#语义分割数据集" class="headerlink" title="语义分割数据集"></a>语义分割数据集</h4><iframe src="//player.bilibili.com/player.html?aid=889059767&bvid=BV1BK4y1M7Rd&cid=369439542&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-4"><a href="#QA-4" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=889059767&bvid=BV1BK4y1M7Rd&cid=367434860&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="47-转置卷积"><a href="#47-转置卷积" class="headerlink" title="47 转置卷积"></a>47 转置卷积</h3><h4 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h4><iframe src="//player.bilibili.com/player.html?aid=376538965&bvid=BV17o4y1X7Jn&cid=367441828&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=376538965&bvid=BV17o4y1X7Jn&cid=367443595&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-5"><a href="#QA-5" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=376538965&bvid=BV17o4y1X7Jn&cid=367446029&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="47-2-转置卷积是一种卷积"><a href="#47-2-转置卷积是一种卷积" class="headerlink" title="47.2 转置卷积是一种卷积"></a>47.2 转置卷积是一种卷积</h3><iframe src="//player.bilibili.com/player.html?aid=931730690&bvid=BV1CM4y1K7r7&cid=368908786&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="48-全连接卷积神经网络-FCN"><a href="#48-全连接卷积神经网络-FCN" class="headerlink" title="48 全连接卷积神经网络 FCN"></a>48 全连接卷积神经网络 FCN</h3><h4 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h4><iframe src="//player.bilibili.com/player.html?aid=291566726&bvid=BV1af4y1L7Zu&cid=367982799&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=291566726&bvid=BV1af4y1L7Zu&cid=367985837&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-6"><a href="#QA-6" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=291566726&bvid=BV1af4y1L7Zu&cid=367989549&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="49-样式迁移"><a href="#49-样式迁移" class="headerlink" title="49 样式迁移"></a>49 样式迁移</h3><h4 id="样式迁移"><a href="#样式迁移" class="headerlink" title="样式迁移"></a>样式迁移</h4><iframe src="//player.bilibili.com/player.html?aid=206577894&bvid=BV1Eh41167GN&cid=367986330&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=206577894&bvid=BV1Eh41167GN&cid=367996398&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-7"><a href="#QA-7" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=206577894&bvid=BV1Eh41167GN&cid=367993134&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="50-课程竞赛：牛仔行头检测"><a href="#50-课程竞赛：牛仔行头检测" class="headerlink" title="50 课程竞赛：牛仔行头检测"></a>50 课程竞赛：牛仔行头检测</h3><iframe src="//player.bilibili.com/player.html?aid=761854141&bvid=BV1F64y1x7xP&cid=372624177&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>软件过程管理-知识点快速复习</title>
    <url>/e0d395a6.html</url>
    <content><![CDATA[<h2 id="选择题"><a href="#选择题" class="headerlink" title="选择题"></a>选择题</h2><ul>
<li>福师</li>
</ul>
<hr>
<h2 id="概念了解"><a href="#概念了解" class="headerlink" title="概念了解"></a>概念了解</h2><h3 id="软件成熟度"><a href="#软件成熟度" class="headerlink" title="软件成熟度"></a>软件成熟度</h3><ul>
<li>CMM描述一条从无序的、混乱的过程到成熟的、有纪律的过程的改进途径，描绘出软件组织如何增加对软件开发和维护的过程控制，如何向软件工程和管理的优秀文化演变等方面的指导。</li>
</ul>
<h3 id="软件生命周期"><a href="#软件生命周期" class="headerlink" title="软件生命周期"></a>软件生命周期</h3><ul>
<li>软件生命周期是软件的产生直到报废或停止使用的生命周期。软件生命周期内有问题定义、可行性分析、总体描述、系统设计、编码、调试和测试、验收与运行、维护升级到废弃等阶段，也有将以上阶段的活动组合在内的迭代阶段，即迭代作为生命周期的阶段。</li>
</ul>
<span id="more"></span>

<h3 id="代码重构"><a href="#代码重构" class="headerlink" title="代码重构"></a>代码重构</h3><ul>
<li>在不改变系统行为的前提下，重新调整优化系统的内部结构以减少复杂性，消除冗余，提高系统的灵活性和性能。</li>
</ul>
<h3 id="集成项目管理"><a href="#集成项目管理" class="headerlink" title="集成项目管理"></a>集成项目管理</h3><ul>
<li>是在用来实现项目具体目标的规定时间内，对组织机构资源进行计划、引导和控制工作。</li>
</ul>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul>
<li>配置是在技术文档中明确说明最终组成软件产品的功能或物理属性。</li>
</ul>
<h3 id="过程评估"><a href="#过程评估" class="headerlink" title="过程评估"></a>过程评估</h3><ul>
<li>软件过程评估所关注的是软件组织自身内部软件过程的改进问题，目的在于发现缺陷，提出改进的方向。</li>
</ul>
<h3 id="项目风险"><a href="#项目风险" class="headerlink" title="项目风险"></a>项目风险</h3><ul>
<li>管理软件开发项目过程中的风险，即潜在的风险因素：技术风险、外部风险、组织风险、管理风险。</li>
</ul>
<h3 id="质量管理"><a href="#质量管理" class="headerlink" title="质量管理"></a>质量管理</h3><ul>
<li>质量管理就是为了实现项目的质量目标，对项目的质量所做的全面规划。</li>
</ul>
<h3 id="过程规范"><a href="#过程规范" class="headerlink" title="过程规范"></a>过程规范</h3><ul>
<li>过程规范就是对输入/输出和活动所构成的过程进行明文规定或约定俗成的标准。软件过程规范是软件开发组织行动的准则与指南，可以依据上述各类过程的特点而建立相应的规范，如软件[基本/支持/组织]过程规范。</li>
</ul>
<h3 id="软件过程"><a href="#软件过程" class="headerlink" title="软件过程"></a>软件过程</h3><ul>
<li>软件过程是指软件开发人员开发和维护软件及相关产品，如项目计划、设计文档、代码、测试用例、用户手册等的一套行为、方法、实践及变换过程。</li>
</ul>
<h3 id="剪裁"><a href="#剪裁" class="headerlink" title="剪裁"></a>剪裁</h3><ul>
<li>目标是在企业过程管理框架下，对过程标准及规范进行裁剪，在有限的资源和时间内实现项目目标。</li>
</ul>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><ul>
<li>指验证或检验软件是否已正确地实现了产品规格书所定义的系统功能和特性，验证过程提供证据表明，软件相关产品与所有生命周期活动的要求相一致。</li>
</ul>
<h3 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h3><ul>
<li>在用来实现项目具体目标的规定时间内，对组织机构资源进行计划、引导和控制工作。</li>
</ul>
<h3 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h3><ul>
<li>基线是评审过的一个或多个软件配置项，每一个基线都是下一步开发的出发点和基础。</li>
</ul>
<h3 id="需求开发"><a href="#需求开发" class="headerlink" title="需求开发"></a>需求开发</h3><ul>
<li>包括需求获取、需求分析、需求定义和需求验证。目的是通过调查与分析，获取用户需求并定义产品需求。</li>
</ul>
<h3 id="需求管理"><a href="#需求管理" class="headerlink" title="需求管理"></a>需求管理</h3><ul>
<li>包括变更控制、版本控制、需求跟踪和需求状态跟踪。</li>
</ul>
<h3 id="PSP"><a href="#PSP" class="headerlink" title="PSP"></a>PSP</h3><ul>
<li>PSP（个体软件过程）着重于软件开发人员的个人能力提升，体现在估算能力、计划能力、计划执行以及质量管理等方面。</li>
</ul>
<h3 id="TSP"><a href="#TSP" class="headerlink" title="TSP"></a>TSP</h3><ul>
<li>TSP（团体软件过程）提供一个已经定义的团队构建过程；一个团队作业框架；一个有效的管理环境。</li>
</ul>
<hr>
<h2 id="简答"><a href="#简答" class="headerlink" title="简答"></a>简答</h2><h3 id="TSP原则"><a href="#TSP原则" class="headerlink" title="TSP原则"></a>TSP原则</h3><ul>
<li><p>循序渐进的原则，首先在PSP的基础上提出一个简单的过程框架，然后逐步完善；</p>
</li>
<li><p>迭代开发的原则，选用增量式迭代开发方法，通过几个循环开发—个产品；</p>
</li>
<li><p>质量优先的原则，对按TSP开发的软件产品，建立质量和性能的度量标准；</p>
</li>
<li><p>目标明确的原则，对实施TSP的群组及其成员的工作效果提供准确的度量；</p>
</li>
<li><p>定期评审的原则，在TSP的实施过程中，对角色和群组进行定期的评价；</p>
</li>
<li><p>过程规范的原则，对每一个项目的TSP规定明确的过程规范；</p>
</li>
<li><p>指令明确的原则，对实施TSP中可能遇到的问题提供解决问题的指南。</p>
</li>
</ul>
<h3 id="CMM中可重复级与已定义级的差异与联系"><a href="#CMM中可重复级与已定义级的差异与联系" class="headerlink" title="CMM中可重复级与已定义级的差异与联系"></a>CMM中可重复级与已定义级的差异与联系</h3><ul>
<li><p>可重复级关注于项目级别的管理，以每个里程碑的管理为重点，期望项目能够按照计划达到项目的目标。</p>
</li>
<li><p>已定义级关注于组织的所有项目按照统一的标准过程执行项目，使用和维护组织过程财富库，以项目的里程碑的内部可见性的管理为重点，期望组织能持续稳定的产出高质量的工作产品为目标。</p>
</li>
</ul>
<h3 id="需求变更控制流程"><a href="#需求变更控制流程" class="headerlink" title="需求变更控制流程"></a>需求变更控制流程</h3><ul>
<li>1.提出变更请求；2.CCB进行评估，若CCB决定不做变更则取消变更；3.进行需求验证，若通过则实施变更，否则重新修改和验证。</li>
</ul>
<h3 id="知识传递与有效方法"><a href="#知识传递与有效方法" class="headerlink" title="知识传递与有效方法"></a>知识传递与有效方法</h3><ul>
<li><p>纵向传递是一个具有很强时间顺序性的接力过程,指软件产品和技术知识从需求分析阶段到设计阶段、从设计阶段到编程阶段、从开发阶段到维护阶段、从产品上一个版本到当前版本的知识传递过程。</p>
</li>
<li><p>横向传递是指软件产品和技术知识在不同团队之间的传递过程。</p>
</li>
<li><p>培训是知识转移的过程，也是解决这一问题最主要的手段。（适当扩写）</p>
</li>
</ul>
<h3 id="软件过程评估目标"><a href="#软件过程评估目标" class="headerlink" title="软件过程评估目标"></a>软件过程评估目标</h3><ul>
<li><p>测试的目的是为了发现尽可能多的缺陷，不是为了说明软件中没有缺陷。</p>
</li>
<li><p>成功的测试在于发现了迄今尚未发现的缺陷。所以测试人员的职责是设计这样的测试用例，它能有效地揭示潜伏在软件里的缺陷。</p>
</li>
</ul>
<h3 id="软件产品工程从传统产业获得的启示"><a href="#软件产品工程从传统产业获得的启示" class="headerlink" title="软件产品工程从传统产业获得的启示"></a>软件产品工程从传统产业获得的启示</h3><ul>
<li><p>每一个构件的接口统一，事先有明确定义。</p>
</li>
<li><p>产品集成的过程是循序渐进的过程管理。</p>
</li>
<li><p>分工明确，有专业生产配件的，也有专门从事组装的。</p>
</li>
<li><p>每一个环节都得到严格的质量控制，保证构件的质量合格。</p>
</li>
</ul>
<hr>
<h2 id="论述"><a href="#论述" class="headerlink" title="论述"></a>论述</h2><h3 id="软件过程的作用"><a href="#软件过程的作用" class="headerlink" title="软件过程的作用"></a>软件过程的作用</h3><ul>
<li>（即为什么要用软件过程原理的一堆模型来入手，便于管理、便于迭代、便于开发、便于维护等）</li>
</ul>
<h3 id="与上课讨论题类似（敏捷开发、MSF、软件过程）"><a href="#与上课讨论题类似（敏捷开发、MSF、软件过程）" class="headerlink" title="与上课讨论题类似（敏捷开发、MSF、软件过程）"></a>与上课讨论题类似（敏捷开发、MSF、软件过程）</h3>]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐软件过程管理</category>
      </categories>
  </entry>
  <entry>
    <title>Android-四大组件-Activity生命周期</title>
    <url>/13b8c915.html</url>
    <content><![CDATA[<h3 id="Activity生命周期"><a href="#Activity生命周期" class="headerlink" title="Activity生命周期"></a>Activity生命周期</h3><p>小程序的生命周期（左图）与Android Activity生命周期（右图）类似</p>
<img src="/13b8c915/1.png" class>

<img src="/13b8c915/2.png" class>

<span id="more"></span>

<p>生命周期：onCreate() -&gt; onStart() - &gt; onResume() -&gt; onPause() -&gt; onStop() -&gt; onDestroy()</p>
<ol>
<li><p>onCreate()（必须实现）</p>
<p> 系统首次创建Activity时触发，Activity会在创建后进入“已创建”状态。该逻辑在Activity的整个生命周期中只发生一次，所以只需执行基本的应用启动逻辑，例如将数据绑定到列表、将Activity与ViewModel关联的initView()方法、实例化某些类作用域变量、实现点击事件的initListener()方法等。</p>
<p> 若有生命周期感知型组件与Activity生命周期相关联，则组件会收到ON_CREATE事件，系统将调用带有@OnLifecycleEvent注释的方法。（这个还未实操过）</p>
<p> 官方示例中，在onCreate()里声明界面（通过资源ID R.layout.*传递给setContentView()来指定XML布局文件）、定义成员变量、配置某些界面。</p>
<p> 调用onCreate()后，Activity进入”已开始“状态，系统会相继调用onStart()和onResume()方法。</p>
</li>
<li><p>onStart()</p>
<p> Activity进入”已开始“状态后，系统会调用此回调方法。onStart()调用使Activity对用户可见，应用会为Activity进入前台并支持互动做准备，比如通过此方法来初始化维护界面的代码。</p>
<p> 同理，相关联的生命周期感知型组件会受到ON_START事件。</p>
<p> 此方法会非常快速完成，并与”已开始“状态一样不会长时间处于该状态。一旦回调结束，Activity便进入”已恢复“状态，调用onResume()方法。</p>
</li>
<li><p>onResume()</p>
<p> 处于该”已恢复“状态时，Activity来到前台，调用onResume()回调。此时是应用与用户互动的状态，会一直保持该状态直至某些事件发生让应用失焦，比如手机来电、跳转至另一个Activity、设备屏幕关闭等。</p>
<p> 同理，相关联的生命周期感知型组件会受到ON_RESUME事件。此时，生命周期组件可以启用组件可见并位于前台时需要运行的任何功能，例如启动相机预览。</p>
<p> 当发生中断事件时，Activity进入”已暂停“状态，调用onPause()回调。</p>
<p> 从”已暂停“状态返回”已恢复“状态时，会重新调用onResume()方法。所以应在onResume()中初始化onPause()释放的组件，以及其它必须完成的初始化操作。</p>
<p> 此部分不够熟悉，加一份代码巩固一下，以下是生命周期感知型组件收到ON_RESUME事件时访问相机：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CameraComponent</span> <span class="keyword">implements</span> <span class="title">LifecycleObserver</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_RESUME)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeCamera</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (camera == <span class="keyword">null</span>) &#123;</span><br><span class="line">            getCamera();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 无论在哪个方法中执行初始化操作，都务必使用相对应的生命周期事件来释放资源。例如ON_START事件后初始化某些内容，则需要在ON_STOP事件后释放或终止相应内容；ON_RESUME事件后初始化某些内容，则需要在ON_PAUSE事件后释放或终止相应内容。</p>
</li>
<li><p>onPause()</p>
<p> 此方法视为用户将要离开此Activity的第一个标志，但不意味着Activity会被销毁，而是表示Activity不再位于前台（虽然多窗口下依然可见）。文档中，使用onPause()方法暂停或调整Activity处于“已暂停”时不应继续或受限的操作以及希望很快恢复的操作。</p>
<p> 进入此状态的原因：某些事件中断应用执行；应用失焦；可见但未处于焦点之中。</p>
<p> 同理，相关联的生命周期感知型组件会受到ON_PAUSE事件。此时，生命周期组件可以停止组件未位于前台时无需运行的任何功能，例如停止相机预览。</p>
<p> 还可使用该方法释放系统资源、传感器（例如GPS）手柄，或Activity暂停且用户不需要时影响电池续航时间的任何资源。在多窗口模式中，因“已暂停”的Activity可能仍完全可见，因此需要用onStop()来完全释放、调整与界面相关的资源与操作，提高多窗口模式的用户体验。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaCameraComponent</span> <span class="keyword">implements</span> <span class="title">LifecycleObserver</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_PAUSE)</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">releaseCamera</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (camera != <span class="keyword">null</span>) &#123;</span><br><span class="line">                camera.release();</span><br><span class="line">                camera = <span class="keyword">null</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> onPause()调用完毕后Activity会保持此状态，直至恢复为“已恢复”触发onResume()或对用户完全不可见触发onStop()。</p>
</li>
<li><p>onStop()</p>
<p> 若Activity不再对用户可见，说明其进入“已停止”状态，系统调用onStop()回调。例如，新启动的Activity覆盖整个屏幕时，以及Activity已结束运行并即将终止。</p>
<p> 同理，相关联的生命周期感知型组件会受到ON_STOP事件。此时，生命周期组件可以停止组件未显示在屏幕上时无需运行的任何功能。</p>
<p> 在onStop()中，应用应释放或调整在应用对用户不可见时的无用资源。例如，应用暂停动画效果、从精确的位置更新切换为粗略位置更新。在多窗口模式下，使用onStop()而非onPause()可确保与界面相关的工作继续进行。</p>
<p> 应使用onStop()执行CPU相对密集的关闭操作。例如信息保存到数据库（未找到更好时机时）。</p>
<p> 当Activity进入“已停止“状态时，Activity要么返回与用户互动，要么结束运行并消失。若Activity返回，系统将调用onRestart()；如果Activity结束运行，系统将调用onDestroy()。</p>
</li>
<li><p>onDestroy()</p>
<p> 销毁Activity之前，系统会调用onDestroy()。例如，Activity即将结束（用户彻底关闭Activity或系统为Activity调用finish()），由于配置变更使得系统暂时销毁Activity（例如设备旋转或多窗口模式）。</p>
<p> 应使用ViewModel对象来包含Activity的相关视图数据，而不是在Activity中加入逻辑来确定Activity被销毁的原因。如果因配置变更而重新创建Activity，ViewModel不必执行任何操作，因为系统将保留ViewModel并将其提供给下一个Activity实例。若不重新创建Activity，ViewModel将调用onCleared()方法，在Activity被销毁前清除所需的任何数据。</p>
<p> 如果Activity即将结束，onDestroy()是Activity收到的最后一个生命周期回调。如果由于配置变更而调用onDestroy()，系统会立即新建Activity实例，然后在新配置中为新实例调用onCreate()。</p>
<p> onDestroy()回调应释放先前的回调（例如onStop()）尚未释放的所有资源。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART VII)</title>
    <url>/7c142473.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="51-序列模型"><a href="#51-序列模型" class="headerlink" title="51 序列模型"></a>51 序列模型</h3><h4 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h4><iframe src="//player.bilibili.com/player.html?aid=974353636&bvid=BV1L44y1m768&cid=372627423&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=974353636&bvid=BV1L44y1m768&cid=372631176&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=974353636&bvid=BV1L44y1m768&cid=372634724&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="52-文本预处理"><a href="#52-文本预处理" class="headerlink" title="52 文本预处理"></a>52 文本预处理</h3><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=376812972&bvid=BV1Fo4y1Q79L&cid=372631893&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=376812972&bvid=BV1Fo4y1Q79L&cid=372637890&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="53-语言模型"><a href="#53-语言模型" class="headerlink" title="53 语言模型"></a>53 语言模型</h3><h4 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h4><iframe src="//player.bilibili.com/player.html?aid=716796428&bvid=BV1ZX4y1F7K3&cid=372644536&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=716796428&bvid=BV1ZX4y1F7K3&cid=372649428&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=716796428&bvid=BV1ZX4y1F7K3&cid=372658897&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="54-循环神经网络-RNN"><a href="#54-循环神经网络-RNN" class="headerlink" title="54 循环神经网络 RNN"></a>54 循环神经网络 RNN</h3><h4 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h4><iframe src="//player.bilibili.com/player.html?aid=759282928&bvid=BV1D64y1z7CA&cid=372645527&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-3"><a href="#QA-3" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=759282928&bvid=BV1D64y1z7CA&cid=372655152&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="55-循环神经网络-RNN-的实现"><a href="#55-循环神经网络-RNN-的实现" class="headerlink" title="55 循环神经网络 RNN 的实现"></a>55 循环神经网络 RNN 的实现</h3><h4 id="从零开始实现"><a href="#从零开始实现" class="headerlink" title="从零开始实现"></a>从零开始实现</h4><iframe src="//player.bilibili.com/player.html?aid=546870213&bvid=BV1kq4y1H7sw&cid=375716632&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h4><iframe src="//player.bilibili.com/player.html?aid=546870213&bvid=BV1kq4y1H7sw&cid=375753563&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-4"><a href="#QA-4" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=546870213&bvid=BV1kq4y1H7sw&cid=375755169&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="56-门控循环单元（GRU）"><a href="#56-门控循环单元（GRU）" class="headerlink" title="56 门控循环单元（GRU）"></a>56 门控循环单元（GRU）</h3><h4 id="门控循环单元（GRU）"><a href="#门控循环单元（GRU）" class="headerlink" title="门控循环单元（GRU）"></a>门控循环单元（GRU）</h4><iframe src="//player.bilibili.com/player.html?aid=291912508&bvid=BV1mf4y157N2&cid=376274927&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=291912508&bvid=BV1mf4y157N2&cid=376277753&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-5"><a href="#QA-5" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=291912508&bvid=BV1mf4y157N2&cid=376284748&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="57-长短期记忆网络（LSTM）"><a href="#57-长短期记忆网络（LSTM）" class="headerlink" title="57 长短期记忆网络（LSTM）"></a>57 长短期记忆网络（LSTM）</h3><h4 id="长短期记忆网络（LSTM）"><a href="#长短期记忆网络（LSTM）" class="headerlink" title="长短期记忆网络（LSTM）"></a>长短期记忆网络（LSTM）</h4><iframe src="//player.bilibili.com/player.html?aid=674456973&bvid=BV1JU4y1H7PC&cid=376278081&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=674456973&bvid=BV1JU4y1H7PC&cid=376282732&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-6"><a href="#QA-6" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=674456973&bvid=BV1JU4y1H7PC&cid=376285542&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>Android-四大组件-Activity启动模式</title>
    <url>/ee465568.html</url>
    <content><![CDATA[<h3 id="Activity启动模式"><a href="#Activity启动模式" class="headerlink" title="Activity启动模式"></a>Activity启动模式</h3><ol>
<li><p>&lt;activity android:name=”.FirstActivity” android:launchMode=”standard”&gt;</p>
<p> standard模式会创建新的任务，并把新Activity置于当前栈顶，点击返回键相当于移除栈顶Activity，栈空时销毁Task。</p>
<p> 使用场景：默认的启动模式，大多数场景都是用该模式。</p>
</li>
<li><p>&lt;activity android:name=”.FirstActivity” android:launchMode=”singleTop”&gt;</p>
<p> singleTop模式在standard模式的基础上，表示如果当前栈顶为该Activity，则不会创建新的Activity（防止栈顶Activity重复创建）。</p>
<p> 使用场景：一般来说，为保证只有一个任务，而不被创建多个时需要此模式。例如，浏览器的书签被动调用的界面）、应用的推送通知、配置及配置里的内容等。</p>
 <span id="more"></span>
</li>
<li><p>&lt;activity android:name=”.FirstActivity” android:launchMode=”singleTask”&gt;</p>
<p> singleTask模式在singleTop的基础上，表示如果Task中已存在该Activity但不在栈顶，则会移除栈顶Activity直至该Activity成为栈顶（保证仅有一个该Activity）。跨app时则会在此基础上把原有的Task压到当前Task顶。</p>
<p> 使用场景：Task或Activity占的资源相对比较大时，使用该模式。（唯一性）</p>
<p> （只有一个Task里有这个Activity，同时这个Activity里最多只有一个这个Activity。）</p>
<p> 【补充知识：当不同Task在前台堆叠时，进入后台就会分开，例如按home⚪键以及最近任务■键的瞬间。】</p>
</li>
<li><p>&lt;activity android:name=”.FirstActivity” android:launchMode=”singleInstance”&gt;</p>
<p> singleInstance模式在singleTask的基础上，但该Activity会单独一个Task并压到当前栈顶。若此时打开有singleInstance模式的app的其它Activity，则会在原有Task里创建并压到当前Task顶（三个Task压成一个，但⚪/■后分离）。（唯一性与独占性）</p>
<p> 使用场景：在整个系统中只有唯一一个实例，例如，Launcher，有道词典的取词。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-四大组件-Broadcast</title>
    <url>/8b83a4cc.html</url>
    <content><![CDATA[<h3 id="Broadcast动态注册与静态注册"><a href="#Broadcast动态注册与静态注册" class="headerlink" title="Broadcast动态注册与静态注册"></a>Broadcast动态注册与静态注册</h3><ol>
<li><p>动态注册</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在onCreate()中注册registerBatteryReceiver();</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">registerBatteryReceiver</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 收听的频道是 电量变化</span></span><br><span class="line">    IntentFilter intentFilter = <span class="keyword">new</span> IntentFilter();</span><br><span class="line">    <span class="comment">// 设置频道</span></span><br><span class="line">    intentFilter.addAction(Intent.ACTION_BATTERY_CHANGED);</span><br><span class="line">    <span class="comment">// 创建一个广播接收者</span></span><br><span class="line">    mBatteryLevelReceiver = <span class="keyword">new</span> BatteryLevelReceiver();</span><br><span class="line">    <span class="comment">// 注册</span></span><br><span class="line">    <span class="keyword">this</span>.registerReceiver(mBatteryLevelReceiver, intentFilter);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建一个广播接收者</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">BatteryLevelReceiver</span> <span class="keyword">extends</span> <span class="title">BroadcastReceiver</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onReceive</span><span class="params">(Context context, Intent intent)</span> </span>&#123;</span><br><span class="line">        String action = intent.getAction();</span><br><span class="line">        <span class="keyword">if</span> (Intent.ACTION_BATTERY_CHANGED.equals(action)) &#123;</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;Battery change action is == &quot;</span> + action);</span><br><span class="line">            <span class="keyword">int</span> currentLevel = intent.getIntExtra(BatteryManager.EXTRA_LEVEL, <span class="number">0</span>);</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;当前电量：&quot;</span> + currentLevel);</span><br><span class="line">            <span class="keyword">if</span> (mBatteryLevelText != <span class="keyword">null</span>) &#123;</span><br><span class="line">                mBatteryLevelText.setText(<span class="string">&quot;当前电量：&quot;</span> + currentLevel);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> maxLevel = intent.getIntExtra(BatteryManager.EXTRA_SCALE, <span class="number">0</span>);</span><br><span class="line">            <span class="keyword">float</span> percent = currentLevel * <span class="number">1.0f</span> / maxLevel * <span class="number">100</span>;</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;当前电量百分比为：&quot;</span> + percent + <span class="string">&quot;%&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在onDestroy()中取消广播注册</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">    <span class="comment">// 取消广播注册</span></span><br><span class="line">    <span class="keyword">if</span> (mBatteryLevelReceiver != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">this</span>.unregisterReceiver(mBatteryLevelReceiver);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

 <span id="more"></span>
</li>
<li><p>静态注册</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在AndroidManifest.xml对静态广播进行注册</span></span><br><span class="line"></span><br><span class="line">&lt;receiver android:name=<span class="string">&quot;.AppStateChangeReceiver&quot;</span>&gt;</span><br><span class="line">    &lt;intent-filter&gt;</span><br><span class="line">        &lt;action android:name=<span class="string">&quot;android.intent.action.PACKAGE_ADDED&quot;</span> /&gt;</span><br><span class="line">        &lt;action android:name=<span class="string">&quot;android.intent.action.PACKAGE_REMOVED&quot;</span> /&gt;</span><br><span class="line">        &lt;data android:scheme=<span class="string">&quot;package&quot;</span> /&gt;</span><br><span class="line">        &lt;/intent-filter&gt;</span><br><span class="line">&lt;/receiver&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 其余与动态类似，但无需在onCreate()与onDestroy()注册与销毁，仅需设置广播接收者即可</span></span><br></pre></td></tr></table></figure>

<hr>
</li>
</ol>
<h3 id="自定义Broadcast广播与接收"><a href="#自定义Broadcast广播与接收" class="headerlink" title="自定义Broadcast广播与接收"></a>自定义Broadcast广播与接收</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 例如本次在按钮中设置发送广播，仅在上述部分多添加一个发送intent并设置发送频道与内容即可</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendBroadcastMsg</span><span class="params">(View view)</span> </span>&#123;</span><br><span class="line">    String content = mInputBox.getText().toString().trim();</span><br><span class="line">    Intent intent = <span class="keyword">new</span> Intent();</span><br><span class="line">    intent.setAction(Constants.ACTION_SEND_MSG);</span><br><span class="line">    intent.putExtra(Constants.KEY_CONTENT, content);</span><br><span class="line">    <span class="comment">// 注意：Android8.0后对静态广播的使用上做了一些限制 具体点击详情</span></span><br><span class="line">    <span class="comment">// 解决办法 1.使用动态广播代替静态广播 2.保留原来的静态广播但加入Component参数如下：参数一是包名，参数二是接收器的路径</span></span><br><span class="line">    intent.setComponent(<span class="keyword">new</span> ComponentName(getPackageName(), <span class="string">&quot;com.example.a11_broadcastdemoforcourse.MessageReceiver&quot;</span>));</span><br><span class="line">    sendBroadcast(intent);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="有序广播"><a href="#有序广播" class="headerlink" title="有序广播"></a>有序广播</h3><p>上述部分为无序广播，即任何应用只要有对应的action就可以接收。（Android8.0后静态注册无法有序，需用动态注册）</p>
<p>有序广播的特点：有序、可以终止向下传达、可以修改广播的内容。</p>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-四大组件-Service</title>
    <url>/2421557f.html</url>
    <content><![CDATA[<h3 id="开启服务和绑定服务的区别-优缺点"><a href="#开启服务和绑定服务的区别-优缺点" class="headerlink" title="开启服务和绑定服务的区别/优缺点"></a>开启服务和绑定服务的区别/优缺点</h3><p>开启服务：startService() → stopService()（其生命周期为onCreate() → onStartCommand() → onDestroy()）</p>
<p>绑定服务：bindService() → unBindService()（其生命周期为onCreate() → onBind() → onUnbind() → onDestroy()）</p>
<p>区别：startService()可以长期在后台运行，bindService()不可以在后台长期运行；bindService()启动服务可以跟服务进行通讯，startService()启动服务不可以跟服务进行通讯。</p>
<p>解决方法：混合两种启动方式，先startService()再bindService()，这样又可以长期运行又可以跟服务进行通讯。</p>
<hr>
<span id="more"></span>

<h3 id="Service混合开启模式"><a href="#Service混合开启模式" class="headerlink" title="Service混合开启模式"></a>Service混合开启模式</h3><p><strong>生命周期：</strong></p>
<ol>
<li><p>开启服务 → 绑定服务，如果不取消绑定，则无法停止服务</p>
</li>
<li><p>开启服务 → 多次绑定/解绑服务，服务不会被停止，只能通过stopService()来停止服务</p>
</li>
</ol>
<p><strong>推荐的混合开启服务的方式：</strong></p>
<ol>
<li><p>开启服务 → 为了确保服务可以长期处于后台</p>
</li>
<li><p>绑定服务 → 为了可以进行通讯</p>
</li>
<li><p>调用服务的内部方法，例如控制音乐的播放/暂停/停止/快进。</p>
</li>
<li><p>退出Activity，要记得解绑服务 → 释放资源</p>
</li>
<li><p>若不使用服务了，要让服务停止，那么就调用stopService()</p>
</li>
</ol>
<hr>
<h3 id="Android服务（Service）"><a href="#Android服务（Service）" class="headerlink" title="Android服务（Service）"></a>Android服务（Service）</h3><p>服务是一个后台运行的组件，执行长时间运行且不需要用户交互的任务，即使应用被销毁也依然可以工作。因此，服务适合执行一段时间不需要显示界面的后台耗时操作（需要另启子线程），比如下载网络数据、播放音乐等。</p>
<p>Service并不是运行在一个独立的进程当中，而是依赖于创建服务时所在的应用程序进程，即Service运行在主线程中。当某个应用程序被杀掉时，所有依赖于该进程的服务都会停止运行。</p>
<p>Service并不会自动开启线程，所有的代码都是默认允许在主线程当中的，也就是说需要在服务的内部手动创建子线程，并在里面执行具体的任务，否则就会出现主线程被阻塞的情况。</p>
<img src="/2421557f/1.png" class>

<p><strong>服务适用场景：</strong></p>
<ol>
<li><p>下载网络数据（在Android3.0之后，只支持子线程下载，因此此功能应该在子线程中启动服务）</p>
</li>
<li><p>播放音乐。</p>
</li>
<li><p>访问文件、数据库等一些业务逻辑功能，可以让Service来实现。</p>
</li>
</ol>
<p><strong>服务基本上包含两种状态：</strong></p>
<p>Started：Android的应用程序组件，如活动，通过startService()启动了服务，则服务是Started状态。一旦启动，服务可以在后台无限期运行，即使启动它的组件已经被销毁。</p>
<p>Bound：当Android的应用程序组件通过bindService()绑定了服务，则服务是Bound状态。Bound状态的服务提供了一个客户服务器接口来允许组件与服务进行交互，如发送请求、获取结果，甚至通过IPC来进行跨进程通信。</p>
<p><strong>服务生命周期：</strong></p>
<p>服务拥有生命周期方法，可以实现监控服务状态的改变，可以在适合的阶段执行工作。左图为服务通过startService()被创建时的生命周期（onStart()被弃用，现在用onStartCommand()），右图则显示了服务通过bindService()被创建时的生命周期：</p>
<img src="/2421557f/2.jpg" class>

<p><strong>服务的回调函数：</strong></p>
<p><strong>onStartCommand()：</strong>其他组件（如活动）通过调用startService()来请求启动服务时，系统调用该方法。如果你实现该方法，你有责任在工作完成时通过stopSelf()或者stopService()方法来停止服务。</p>
<p><strong>onBind()：</strong>当其他组件想要通过bindService()来绑定服务时，系统调用该方法。如果你实现该方法，你需要返回IBinder对象来提供一个接口，以便客户来与服务通信。你必须实现该方法，如果你不允许绑定，则直接返回null。</p>
<p><strong>onUnbind()：</strong>当客户中断所有服务发布的特殊接口时，系统调用该方法。</p>
<p><strong>onRebind()：</strong>当新的客户端与服务连接，且此前它已经通过onUnbind(Intent)通知断开连接时，系统调用该方法。</p>
<p><strong>onCreate()：</strong>当服务通过onStartCommand()和onBind()被第一次创建的时候，系统调用该方法。该调用要求执行一次性安装。</p>
<p><strong>onDestroy()：</strong>当服务不再有用或者被销毁时，系统调用该方法。你的服务需要实现该方法来清理任何资源，如线程，已注册的监听器，接收器等。</p>
<hr>
<h3 id="BUG修改"><a href="#BUG修改" class="headerlink" title="BUG修改"></a>BUG修改</h3><p>应用调起第三方支付的模拟alipay服务进行支付（该demo写完有bug，绑定alipay服务失败）</p>
<img src="/2421557f/3.png" class>

<p><strong>BUG原因：</strong></p>
<p>Android 8.0版本对后台服务做了更加严格的限制（官方Android 8.0更新文档：后台执行限制）</p>
<p>“后台Service限制：处于空闲状态时，应用可以使用的后台 Service 存在限制。 这些限制不适用于前台 Service，因为前台 Service 更容易引起用户注意。”</p>
<p>“在这些情况下，后台应用将被置于一个临时白名单中并持续数分钟。 位于白名单中时，应用可以无限制地启动 Service，并且其后台 Service 也可以运行。”</p>
<p><strong>解决方法：</strong></p>
<ol>
<li><p>把alipay这个Service加入系统的服务白名单</p>
</li>
<li><p>这个demo降低SDK版本运行（在24版本即Android 7.0版本下运行正常）</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-四大组件-Content Provider</title>
    <url>/6826dd2.html</url>
    <content><![CDATA[<h3 id="Android-内容提供者-Content-Provider"><a href="#Android-内容提供者-Content-Provider" class="headerlink" title="Android - 内容提供者(Content Provider)"></a>Android - 内容提供者(Content Provider)</h3><p>内容提供者组件通过请求从一个应用程序向其他的应用程序提供数据。这些请求由类 ContentResolver 的方法来处理。内容提供者可以使用不同的方式来存储数据。数据可以被存放在数据库，文件，甚至是网络。</p>
<img src="/6826dd2/1.jpg" class>

<span id="more"></span>

<p>有时候需要在应用程序之间共享数据，这时内容提供者变得非常有用。</p>
<p>内容提供者可以让内容集中，必要时可以有多个不同的应用程序来访问。内容提供者的行为和数据库很像。你可以查询，编辑它的内容，使用 insert()， update()， delete() 和 query() 来添加或者删除内容。多数情况下数据被存储在 SQLite 数据库。</p>
<p>内容提供者被实现为类 ContentProvider 类的子类。需要实现一系列标准的 API，以便其他的应用程序来执行事务。</p>
<hr>
<h3 id="内容URI"><a href="#内容URI" class="headerlink" title="内容URI"></a>内容URI</h3><p>要查询内容提供者，需要以如下格式的URI的形式来指定查询字符串：&lt;prefix&gt;://&lt;authority&gt;/&lt;data_type&gt;/&lt;id&gt;</p>
<p>以下是URL中各部分的具体说明：</p>
<p><strong>prefix：</strong>前缀，一直被设置为content://</p>
<p><strong>thority：</strong>授权，指定内容提供者的名称，例如联系人，浏览器等。第三方的内容提供者可以是全名，如：cn.programmer.statusprovider</p>
<p><strong>data_type：</strong>数据类型，这个表明这个特殊的内容提供者中的数据的类型。例如：你要通过内容提供者Contacts来获取所有的通讯录，数据路径是people，那么URI将是下面这样：content://contacts/people</p>
<p><strong>id：</strong>这个指定特定的请求记录。例如：你在内容提供者Contacts中查找联系人的ID号为5，那么URI看起来是这样：content://contacts/people/5</p>
<img src="/6826dd2/2.jpg" class>

<hr>
<h3 id="创建内容提供者"><a href="#创建内容提供者" class="headerlink" title="创建内容提供者"></a>创建内容提供者</h3><ol>
<li><p>需要继承类ContentProviderbase来创建一个内容提供者类。</p>
</li>
<li><p>需要定义用于访问内容的你的内容提供者URI地址。</p>
</li>
<li><p>需要创建数据库来保存内容。通常，Android使用SQLite数据库，并在框架中重写onCreate()方法来使用SQLiteOpenHelper的方法创建或者打开提供者的数据库。当你的应用程序被启动，它的每个内容提供者的onCreate()方法将在应用程序主线程中被调用。</p>
</li>
<li><p>使用&lt;provider…/&gt;标签在AndroidManifest.xml中注册内容提供者。</p>
</li>
</ol>
<img src="/6826dd2/3.jpg" class>

<p>以下是让内容提供者正常工作，需要在类ContentProvider中重写的一些方法：</p>
<ol>
<li><p>onCreate()：当提供者被启动时调用。</p>
</li>
<li><p>query()：该方法从客户端接受请求。结果是返回指针(Cursor)对象。</p>
</li>
<li><p>insert()：该方法向内容提供者插入新的记录。</p>
</li>
<li><p>delete()：该方法从内容提供者中删除已存在的记录。</p>
</li>
<li><p>update()：该方法更新内容提供者中已存在的记录。</p>
</li>
<li><p>getType()：该方法为给定的URI返回元数据类型。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART VIII)</title>
    <url>/3c3d28e4.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="58-深层循环神经网络"><a href="#58-深层循环神经网络" class="headerlink" title="58 深层循环神经网络"></a>58 深层循环神经网络</h3><h4 id="深层循环神经网络"><a href="#深层循环神经网络" class="headerlink" title="深层循环神经网络"></a>深层循环神经网络</h4><iframe src="//player.bilibili.com/player.html?aid=931877179&bvid=BV1JM4y1T7N4&cid=376279066&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=931877179&bvid=BV1JM4y1T7N4&cid=376282968&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=931877179&bvid=BV1JM4y1T7N4&cid=376287501&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="59-双向循环神经网络"><a href="#59-双向循环神经网络" class="headerlink" title="59 双向循环神经网络"></a>59 双向循环神经网络</h3><h4 id="双向循环神经网络"><a href="#双向循环神经网络" class="headerlink" title="双向循环神经网络"></a>双向循环神经网络</h4><iframe src="//player.bilibili.com/player.html?aid=716963264&bvid=BV12X4y1c71W&cid=376279969&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=716963264&bvid=BV12X4y1c71W&cid=376285640&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=716963264&bvid=BV12X4y1c71W&cid=376287509&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="60-机器翻译数据集"><a href="#60-机器翻译数据集" class="headerlink" title="60 机器翻译数据集"></a>60 机器翻译数据集</h3><iframe src="//player.bilibili.com/player.html?aid=762218228&bvid=BV1H64y1s7TH&cid=384691473&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="61-编码器-解码器架构"><a href="#61-编码器-解码器架构" class="headerlink" title="61 编码器-解码器架构"></a>61 编码器-解码器架构</h3><h4 id="编码器-解码器架构"><a href="#编码器-解码器架构" class="headerlink" title="编码器-解码器架构"></a>编码器-解码器架构</h4><iframe src="//player.bilibili.com/player.html?aid=847202723&bvid=BV1c54y1E7YP&cid=384691545&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=847202723&bvid=BV1c54y1E7YP&cid=384693376&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="62-序列到序列学习（seq2seq）"><a href="#62-序列到序列学习（seq2seq）" class="headerlink" title="62 序列到序列学习（seq2seq）"></a>62 序列到序列学习（seq2seq）</h3><h4 id="Seq2Seq"><a href="#Seq2Seq" class="headerlink" title="Seq2Seq"></a>Seq2Seq</h4><iframe src="//player.bilibili.com/player.html?aid=504678491&bvid=BV16g411L7FG&cid=385253874&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=504678491&bvid=BV16g411L7FG&cid=385256109&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=504678491&bvid=BV16g411L7FG&cid=385264314&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="63-束搜索"><a href="#63-束搜索" class="headerlink" title="63 束搜索"></a>63 束搜索</h3><iframe src="//player.bilibili.com/player.html?aid=974667399&bvid=BV1B44y1C7m1&cid=385254837&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-快速眼动睡眠调控模型进展和两种相关典型疾病治疗的可能应对策略</title>
    <url>/17879999.html</url>
    <content><![CDATA[<p>人一生将近三分之一的时间都在睡觉，人的睡眠可分为快速眼动(REM)睡眠和非快速眼动(NREM)睡眠两大部分。REM和NREM组成一个睡眠周期，大约为90分钟，人们每晚的睡眠通常经历4<del>6个睡眠周期。REM和NREM在脑活动方面极不相同。REM在睡眠时候的表现为：脑电波频率变快，振幅变低，同时还表现出心率加快、血压升高、肌肉松弛，最奇怪的是眼球不停地左右摆动，该阶段约占总睡眠时间的20</del>25%，为此科学家们把这一阶段的睡眠，称为快速眼动睡眠。把快速眼动以外的其它睡眠，称为慢波睡眠。慢波睡眠时的一般表现为：各种感觉功能减退，骨骼肌反射活动和肌紧张减退、自主神经功能普遍下降，但胃液分泌和发汗功能增强，生长激素分泌明显增多。慢波睡眠有利于促进生长和恢复体力。</p>
<span id="more"></span>

<img src="/17879999/1.png" class>

<p>复旦大学王毅群博士等人在REM睡眠的神经回路基础上，提出了睡眠调控模型进展的一些总结，并提出了对REM睡眠行为障碍（REM sleep Behavior Disorder，RBD）和发作性睡病（Narcolepsy）两种神经疾病治疗的可能应对策略。</p>
<img src="/17879999/2.jpg" class>

<hr>
<h3 id="REM睡眠回路的睡眠调控模型的来源"><a href="#REM睡眠回路的睡眠调控模型的来源" class="headerlink" title="REM睡眠回路的睡眠调控模型的来源"></a>REM睡眠回路的睡眠调控模型的来源</h3><p>REM睡眠调节主要由几个神经回路调节，包括去甲肾上腺素能、5-羟色胺能、胆碱能、甘氨酸能、GABA能和谷氨酸能神经元，这些发现促进了几种动物模型的发展。</p>
<img src="/17879999/3.jpg" class>

<hr>
<h3 id="REM睡眠回路的睡眠调控模型的发展和作用"><a href="#REM睡眠回路的睡眠调控模型的发展和作用" class="headerlink" title="REM睡眠回路的睡眠调控模型的发展和作用"></a>REM睡眠回路的睡眠调控模型的发展和作用</h3><p>这几种动物模型可以用来阐明REM睡眠调节的潜在机制。例如：交互作用模型（用来解释REM开启和REM关闭状态之间的转换）、极限环模型（是一种交互作用模型，在交互作用模型上进行了改进，考虑了REM振荡器的昼夜节律影响和局部GABA能神经元的作用）、触发器模型（该开关的主要功能是稳定REM on或REM off状态，其中REM on状态是表示个体睡眠状态即将过渡到快速眼动态，REM off则相反）等。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>作者综述了快速眼动睡眠的神经生物学机制和快速眼动睡眠相关疾病的最新研究进展，并提出了这一方向的一些医学方面可能可行的解决方式。尽管这一领域的最新进展令人兴奋，但需要进一步的发展和临床应用来阐明相应机制的更多细节及其对患者的影响，最重要的瓶颈是成功地将基础研究成果转化为REM相关疾病的临床治疗。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p>&lt;WangYQ, Liu WY, Li L, Qu WM, Huang ZL*.Neural circuitry underlying REM sleep: A review of the literature and currentconcepts. Prog Neurobiol. 2021 Jun 15;102106. doi:10.1016/j.pneurobio.2021.102.103.&gt;</p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10258">https://www.scholat.com/teamwork/showPostMessage.html?id=10258</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>Android-性能优化-内存泄漏</title>
    <url>/8c27d4dd.html</url>
    <content><![CDATA[<h2 id="Android内存泄漏原因"><a href="#Android内存泄漏原因" class="headerlink" title="Android内存泄漏原因"></a>Android内存泄漏原因</h2><p>从Java上看，主要有3个原因：</p>
<ol>
<li><p>listener：设置监听，在一个类中设置成员变量并把另一个类作为listener给set进去：mListener = setListener(listener);，但在不需要时没有set为null，导致一直持有该对象强引用无法被回收。外部的类没有被回收，所以内部的listener也没有被回收。</p>
</li>
<li><p>inner-class：内部类持有外部的引用，例如持有Acticity的this，解决方法是对应的需要什么就传什么，避免持有外部引用无法被销毁。</p>
</li>
<li><p>thread：无论是内部类的thread还是外部的thread，根本原因还是由1、2造成，例如等待网络回调等，导致持有对象无法被销毁。</p>
</li>
</ol>
<span id="more"></span>

<p>从Android上看，主要有2个原因：</p>
<ol>
<li><p>全局进程（process-global）的static变量。这个无视应用的状态，持有Activity的强引用。</p>
</li>
<li><p>活在Activity生命周期之外的线程。没有清空对Activity的强引用。</p>
</li>
</ol>
<hr>
<h2 id="Android内存泄漏的可能的八种情况"><a href="#Android内存泄漏的可能的八种情况" class="headerlink" title="Android内存泄漏的可能的八种情况"></a>Android内存泄漏的可能的八种情况</h2><p>以下情况需关注是否会内存泄漏：Static Activities、Static Views、Inner Classes、Anonymous Classes、Handler、Threads、TimerTask、Sensor Manager</p>
<p>一般内存泄漏：忘记释放分配的内存，例如cursor</p>
<p>逻辑内存泄漏：当应用不再需要这个对象或结束生命周期，仍未释放该对象的所有引用</p>
<p>在Android中，导致潜在内存泄漏的陷阱：</p>
<ol>
<li><p>全局进程的static变量，这个无视应用的状态，持有Activity的强引用</p>
</li>
<li><p>活在Activity生命周期外的线程，没有清空对Activity的强引用</p>
</li>
</ol>
<h3 id="Static-Activities"><a href="#Static-Activities" class="headerlink" title="Static Activities"></a>Static Activities</h3><p>在类中定义了静态Activity变量，把当前运行的Activity实例赋值于这个静态变量。这个静态变量在Activity生命周期结束后没有被清空就导致了内存泄漏，因为static变量是贯穿这个应用的生命周期的，所以被泄漏的Activity就会一直存在于应用的进程中，不会被垃圾回收器回收。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> Activity activity;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">setStaticActivity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    activity = <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line">View sButton = findViewById(R.id.button);</span><br><span class="line">sButton.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        setStaticActivity();</span><br><span class="line">        nextActivity();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<img src="/8c27d4dd/StaticActivities.jpg" class>

<p>解决办法：弱引用不会阻止对象的内存释放，所以即使有弱引用的存在，该对象也可以被回收。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> WeakReference&lt;MainActivity&gt; activityReference;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">setStaticActivity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    activityReference = <span class="keyword">new</span> WeakReference&lt;MainActivity&gt;(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Static-Views"><a href="#Static-Views" class="headerlink" title="Static Views"></a>Static Views</h3><p>常发生在单例模式中，如果Activity经常被用到，那么在内存中保存一个实例是很实用的。但脱离Activity生命周期的操作是很危险的。</p>
<p>特殊情况：如果一个View初始化耗费大量资源，而且在一个Activity生命周期内保持不变，那么可以把它变成static加载到视图树上（View Hierarchy）。但在Activity被onDestroy()时，应当将这个static view置null。（虽然但是，不建议使用static view）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> View view;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">setStaticView</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    view = findViewById(R.id.button);</span><br><span class="line">&#125;</span><br><span class="line">View sButton = findViewById(R.id.button);</span><br><span class="line">sButton.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        setStaticView();</span><br><span class="line">        nextActivity();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<img src="/8c27d4dd/StaticViews.jpg" class>

<p>解决办法：弱引用是个有效的解决方法，然而还有另一种方法是在生命周期结束时清除引用，Activity#onDestroy()方法就很适合把引用置空。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> View view;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">    <span class="keyword">if</span> (view != <span class="keyword">null</span>) &#123;</span><br><span class="line">        unsetStaticView();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">unsetStaticView</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    view = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Inner-Classes"><a href="#Inner-Classes" class="headerlink" title="Inner Classes"></a>Inner Classes</h3><p>Activity中有个内部类，这样做可以提高可读性和封装性。但如果这个内部类持有一个静态变量的引用，便很容易内存泄漏（除非销毁时置null）。内部类的优势之一就是可以访问外部类，不幸的是，导致内存泄漏的原因，就是内部类持有外部类实例的强引用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Object inner;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createInnerClass</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">InnerClass</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    inner = <span class="keyword">new</span> InnerClass();</span><br><span class="line">&#125;</span><br><span class="line">View icButton = findViewById(R.id.ic_button);</span><br><span class="line">icButton.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        createInnerClass();</span><br><span class="line">        nextActivity();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<img src="/8c27d4dd/InnerClasses.jpg" class>

<p>解决办法：开发者必须注意少用非静态内部类，因为非静态内部类持有外部类的隐式引用，容易导致意料之外的泄漏。然而内部类可以访问外部类的私有变量，只要我们注意引用的生命周期，就可以避免意外的发生。避免静态变量。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> Object inner;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createInnerClass</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">InnerClass</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    inner = <span class="keyword">new</span> InnerClass();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Anonymous-Classes"><a href="#Anonymous-Classes" class="headerlink" title="Anonymous Classes"></a>Anonymous Classes</h3><p>如果匿名类也维护了外部类的引用，在Activity中定义了匿名的AsyncTask，就容易发生内存泄漏。当异步任务在后台执行耗时任务期间，Activity被销毁了（用户退出、系统回收），这个被AsyncTask持有的Activity实例就不会被GC回收，直到异步任务结束。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">startAsyncTask</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">new</span> AsyncTask&lt;Void, Void, Void&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> Void <span class="title">doInBackground</span><span class="params">(Void... params)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;.execute();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">super</span>.onCreate(savedInstanceState);</span><br><span class="line">setContentView(R.layout.activity_main);</span><br><span class="line">View aicButton = findViewById(R.id.at_button);</span><br><span class="line">aicButton.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        startAsyncTask();</span><br><span class="line">        nextActivity();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<img src="/8c27d4dd/AnonymousClasses.jpg" class>

<p>解决办法：匿名类和内部类一样，只要不跨越生命周期是完全没问题的。但是，这些类是用于产生后台线程的，这些Java线程是全局的，而且持有创建者的引用（即匿名类的引用），而匿名类又持有外部类的引用。线程是可能长时间运行的，所以一直持有Activity的引用导致当销毁时无法回收。我们不能通过移除静态成员变量解决，因为线程是于应用生命周期相关的。为了避免泄漏，必须舍弃简洁偷懒的写法，把子类声明为静态内部类。（静态内部类不持有外部类的引用，打破了链式引用。）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NimbleTask</span> <span class="keyword">extends</span> <span class="title">AsyncTask</span>&lt;<span class="title">Void</span>, <span class="title">VoiVoid</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> Void <span class="title">doInBackground</span><span class="params">(Void... params)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">startAsyncTask</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">new</span> NimbleTask().execute();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Handler"><a href="#Handler" class="headerlink" title="Handler"></a>Handler</h3><p>定义了匿名的Runnable，用匿名类Handler执行。Runnable内部类会持有外部类的隐式引用，被传递到Handler的消息队列MessageQueue中，在Message消息没有被处理之前，Activity销毁导致了内存泄漏。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createHandler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">new</span> Handler() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleMessage</span><span class="params">(Message message)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">super</span>.handleMessage(message);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;.postDelayed(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, Long.MAX_VALUE &gt;&gt; <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">View hButton = findViewById(R.id.h_button);</span><br><span class="line">hButton.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        createHandler();</span><br><span class="line">        nextActivity();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<img src="/8c27d4dd/Handler.jpg" class>

<p>解决办法：匿名类和内部类一样，只要不跨越生命周期是完全没问题的。但是，这些类是用于产生后台线程的，这些Java线程是全局的，而且持有创建者的引用（即匿名类的引用），而匿名类又持有外部类的引用。线程是可能长时间运行的，所以一直持有Activity的引用导致当销毁时无法回收。我们不能通过移除静态成员变量解决，因为线程是于应用生命周期相关的。为了避免泄漏，必须舍弃简洁偷懒的写法，把子类声明为静态内部类。（静态内部类不持有外部类的引用，打破了链式引用。）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NimbleHandler</span> <span class="keyword">extends</span> <span class="title">Handler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleMessage</span><span class="params">(Message message)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.handleMessage(message);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NimbleRunnable</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createHandler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">new</span> NimbleHandler().postDelayed(<span class="keyword">new</span> NimbleRunnable(), Long.MAX_VALUE &gt;&gt; <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Threads"><a href="#Threads" class="headerlink" title="Threads"></a>Threads</h3><p>通过Thread和TimerTask来展现内存泄漏</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">spawnThread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">        <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;.start();</span><br><span class="line">&#125;</span><br><span class="line">View tButton = findViewById(R.id.t_button);</span><br><span class="line">tButton.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        spawnThread();</span><br><span class="line">        nextActivity();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<img src="/8c27d4dd/Threads.jpg" class>

<p>解决办法：使用静态内部类，不持有外部类的引用，打破了链式引用。但是，如果坚持使用匿名类，只要在生命周期结束时中断线程就可以。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> Thread thread;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">    <span class="keyword">if</span> (thread != <span class="keyword">null</span>) &#123;</span><br><span class="line">        thread.interrupt();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">spawnThread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    thread = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!isInterrupted()) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    thread.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="TimerTask"><a href="#TimerTask" class="headerlink" title="TimerTask"></a>TimerTask</h3><p>只要是匿名类的实例，不管是不是在工作线程，都会持有Activity的引用，导致内存泄漏。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">scheduleTimer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">new</span> Timer().schedule(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, Long.MAX_VALUE &gt;&gt; <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">View ttButton = findViewById(R.id.tt_button);</span><br><span class="line">ttButton.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        scheduleTimer();</span><br><span class="line">        nextActivity();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<img src="/8c27d4dd/TimerTask.jpg" class>

<p>解决办法：匿名类和内部类一样，只要不跨越生命周期是完全没问题的。但是，这些类是用于产生后台线程的，这些Java线程是全局的，而且持有创建者的引用（即匿名类的引用），而匿名类又持有外部类的引用。线程是可能长时间运行的，所以一直持有Activity的引用导致当销毁时无法回收。我们不能通过移除静态成员变量解决，因为线程是于应用生命周期相关的。为了避免泄漏，必须舍弃简洁偷懒的写法，把子类声明为静态内部类。（静态内部类不持有外部类的引用，打破了链式引用。）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NimbleTimerTask</span> <span class="keyword">extends</span> <span class="title">TimerTask</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">scheduleTimer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">new</span> Timer().schedule(<span class="keyword">new</span> NimbleTimerTask(), Long.MAX_VALUE &gt;&gt; <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Sensor-Manager"><a href="#Sensor-Manager" class="headerlink" title="Sensor Manager"></a>Sensor Manager</h3><p>通过Context.getSystemService(int name)可以获取系统服务。这些服务工作在各自的进程中，帮助应用处理后台任务，处理硬件交互。如果需要使用这些服务，可以注册监听器，这会导致服务持有了Context的引用，如果在Activity销毁的时候没有注销这些监听器，会导致内存泄漏。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">registerListener</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    SensorManager sensorManager = (SensorManager) getSystemService(SENSOR_SERVICE);</span><br><span class="line">    Sensor sensor = sensorManager.getDefaultSensor(Sensor.TYPE_ALL);</span><br><span class="line">    sensorManager.registerListener(<span class="keyword">this</span>, sensor, SensorManager.SENSOR_DELAY_FASTEST);</span><br><span class="line">&#125;</span><br><span class="line">View smButton = findViewById(R.id.sm_button);</span><br><span class="line">smButton.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        registerListener();</span><br><span class="line">        nextActivity();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<img src="/8c27d4dd/SensorManager.jpg" class>

<p>解决办法：在Activity结束时注销监听器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> SensorManager sensorManager;</span><br><span class="line"><span class="keyword">private</span> Sensor sensor;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">    <span class="keyword">if</span> (sensor != <span class="keyword">null</span>) &#123;</span><br><span class="line">        unregisterListener();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">unregisterListener</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    sensorManager.unregisterListener(<span class="keyword">this</span>, sensor);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-脑机接口的伦理与立法</title>
    <url>/aee7886e.html</url>
    <content><![CDATA[<p>美国时间2021年7月29日Neuralink宣布已在C轮融资中从Google Ventures、Peter Thiel的创始人基金和OpenAI首席执行官Sam Altman在内的投资者那里筹集了 2.05 亿美元，其表示：“本轮融资将用于Neuralink的第一个产品推向市场，并加快未来产品的研发速度。该设备以高带宽与自然的方式使四肢瘫痪的人能够与电脑、手机交互，享受数字自由。”也就是说，脑机接口设备即将在市场上推广使用。但是，随着脑机接口应用的数量的增多和领域的扩展,带来了一些亟待解决的技术和伦理问题。</p>
<span id="more"></span>

<hr>
<h3 id="安全问题"><a href="#安全问题" class="headerlink" title="安全问题"></a>安全问题</h3><p>侵入式或半侵入式脑机接口需要在脑部进行芯片等硬件植入，会破坏脑部的天然物理防护；如果相关硬件设备被非法使用（如输入恶意信号、更改信号阈值），可能会产生严重后果，甚至威胁生命安全。同理，如果电子设备被攻击会带来非常严重的安全问题，尤其是在医疗领域。</p>
<hr>
<h3 id="个人隐私安全问题"><a href="#个人隐私安全问题" class="headerlink" title="个人隐私安全问题"></a>个人隐私安全问题</h3><p>在这个大数据时代，个人信息泄露一直困扰着所有人，当你在淘宝、京东等知购物网站上搜索特定商品并浏览后，在其他网站浏览新闻时，网页的广告位竟然是类似商品或促销活动，这样精准的广告推送实在让人不得不担心，更别说前段时间传出各大招聘网站出售用户简历了。相较而言，脑机接口所引发的隐私问题更为突出，此技术已经不只限于人的行为了，还包括存储在大脑的健康状况、生活经历、财产状况、婚恋、社会关系、信仰、心理特征等隐私信息，同时，还要防备黑客攻击。植入式设备的每一个单点，包括植入体、程控设备、计算机等，都是可以通过信息手段访问到的实体，随着5G技术的发展，每个单点的通讯接口都有可能成为黑客攻击的目标，传统信息安全领域中的认证安全、协议安全、甚至远程溢出等问题都有可能会出现。所以，我们不得不限制脑机接口技术对人类隐私的收集、分析、传播与使用。</p>
<hr>
<h3 id="知情权问题"><a href="#知情权问题" class="headerlink" title="知情权问题"></a>知情权问题</h3><p>残障人士（如闭锁综合症患者）等是脑机接口的重点应用对象之一，将面临知情同意权问题。在应用脑机接口技术之前，如何充分保障患者的自主权？在技术应用过程中，如何正确解释应用对象的意愿？</p>
<p>对于这些问题，法律的基本任务是，给科技报以掌声，为风险出示红牌。为防止脑机接口技术过度侵犯基本人权，法律需要提前设置好伦理底线。国外立法已经开始保护神经权利，防范技术抹杀个人意识。2020年10月份，智利宪法修正案（草案）规定了保护神经权利的条款，西班牙政府最新监管新规也涉及了神经权利内容。第一，立法的目的是推动脑机接口技术的合理发展。第二，立法的重点是确立脑机接口技术的适用禁区。第三，立法的过程应当循序渐进，合理解释现行法律，适时出台新法保护新型权利。一方面，监管者可以合理解释现行法律，将大脑数据作为公民个人信息加以保护；另一方面，立法应当确立神经权利，形成完整法律保护体系。社会发展史就是一部个人权利扩张史，隐私权、个人信息权等都是随着技术的进步而成为特别权利。</p>
<p>生产性的法律理论认为，作为上层建筑的法律需要对新型生产方式进行回应，并确保生产资料与新生产关系的合法性。在此过程中，经济和社会价值被不断生产和再生产出来，通过以生产资料财产权利为核心的法律制度加以确认；同时，以技术为表现形态的生产系统逐渐嵌入市场与社会，成为我们日常生活的默认设置，直至下一次经由新的“破坏式创新”技术出现，不断以非法兴起的方式对既有稳定系统发起挑战。在每次挑战过程中，新型技术的特殊性被作为普遍性写入法律规范，自互联网以来的核心法律问题也会一直延伸，涉及身份认证、数据权属、算法黑箱、竞争政策、数字基础设施以及价值分配机制等，它们构成了我们所处信息时代的独有法律问题。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://observer.com/2021/07/elon-musk-neuralink-raise-fund-peter-thiel-brain-chip-human-test/">https://observer.com/2021/07/elon-musk-neuralink-raise-fund-peter-thiel-brain-chip-human-test/</a><br><a href="https://k.sina.cn/article_1686546714_6486a91a02001a8ht.html">https://k.sina.cn/article_1686546714_6486a91a02001a8ht.html</a><br><a href="http://vr.sina.com.cn/news/hz/2020-11-20/doc-iiznctke2360478.shtml">http://vr.sina.com.cn/news/hz/2020-11-20/doc-iiznctke2360478.shtml</a><br><a href="http://www.jyb.cn/rmtzcg/xwy/wzxw/201908/t20190828_255559.html">http://www.jyb.cn/rmtzcg/xwy/wzxw/201908/t20190828_255559.html</a><br>&lt;胡凌.理解技术规制的一般模式：以脑机接口为例[J].东方法学,2021(04):38-48.&gt;</p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10266">https://www.scholat.com/teamwork/showPostMessage.html?id=10266</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-AI评分辅助系统在2021年东京奥运会上的应用</title>
    <url>/cdc4e36d.html</url>
    <content><![CDATA[<p>2021年的东京奥运会从7月23开始到现在正在火热的进行中，此次奥运会一大亮点是运用了AI评分辅助系统技术来对比赛运动员的表现打分，<strong>AI评分系统和人类动作评估的研究方向与应用关系密切</strong>，评分系统在动作捕捉、辅助评分多个环节发挥了作用，AI评分系统有助力于裁判公正性。</p>
<span id="more"></span>

<p>体操竞技的动作华丽炫目、动态感十足，且技术难度大，所以对于裁判而言，评分也愈发困难。历届奥运会上质疑裁判员评分不公的情况多有发生。为了让赛事评分更加公正，此次东京奥运会在体操项目上引进了由日本富士通公司开发的AI评分辅助系统，在之前的世锦赛，国际体操协会就应用了该评分系统。据悉，本届东京奥运会运动员的最终得分，就是结合AI和裁判的判断，再经裁判综合判断后，最终打出的分数。评分辅助系统如图所示。</p>
<img src="/cdc4e36d/1.jpg" class>

<p>AI用于检测选手的姿势，审查运动员的技术动作。当运动员翻转和跳跃时，评委会根据体操运动员身体的精确位置来加分或扣分。裁判员需要密切评估体操运动员关节的角度，例如膝盖和肘部，但人眼有时还是难以在瞬间的动作变换中看出那一丁点瑕疵，比如准确测量关节的弯曲角度，而AI评分辅助系统可以捕捉运动员瞬间的动作和身体扭转角度，并展现出来辅助裁判评估。辅助评分画面如图所示，左上是相机画面，左下是时间轴，中间四张图是AI捕捉的选手动作，右边是每种技术的裁判员看点。</p>
<img src="/cdc4e36d/2.jpg" class>

<p>面对AI评分系统，也有人表示了担忧。曾在体操历史上第一个获得10分满分的纳迪亚·科马内奇表示，如果运动员做出的动作不在人工智能算法范围之内，AI会怎么打分呢？AI评分能否真能保证赛事评分的公正性？这也是许多运动员想知道的问题。据了解，AI评分系统通过向选手的身体及其周边投射红外线，追踪运动员的动作，并且将其实时转换成三维立体图像。<strong>以该图像为基础，AI可以对运动员身体的旋转和扭动等动作做出分析，并结合过去的比赛数据，遵照评分标准，判断运动员技术动作的完成度。</strong>不仅如此，AI评分系统还可捕捉运动员的瞬间动作和身体扭转角度，并清晰展现给观众，让观众通过画面了解更多比赛细节，提高比赛的娱乐性。“用AI技术进行评判，可以大大降低判罚不公之类的情况。”</p>
<p><strong>AI对以后体育赛事有何进展呢？</strong></p>
<p>AI将推动体育赛事变革。“在大型赛事中使用AI技术是很有必要的”。“不仅如此，AI将推动体育赛事传媒行业的变革”。在谈到AI的发展，华东交通大学人工智能学院院长赵军辉认为，AI+体育赛事正在改变未来，AI摄像头可以根据观众的注意力焦点随时调整，每个观众看到的可能都不一样。体育赛事的录制不再受制于转播导演和摄影师，而完全是基于大数据和人工智能算法的选择。因此，人工智能技术将彻底改变传统的体育赛事的传媒业态。</p>
<p>“AI训练系统可以分析运动员在体育赛事中的行为和表现，给出智能化的面向更高成绩的训练建议，从而进一步提高运动员的成绩上限，甚至预测竞争对手的可能动作，有利于运动员在大型赛事中的更好发挥。就比如说这次的AI视觉追踪技术，这也是AI赋能裁判系统的代表作之一。这项技术的出现就解决了摄像头没有及时捕捉到关键得分的问题，后续很有必要拓展到其他赛事中。”赵军辉认为，本届东京奥运会中多项AI技术的引入，是AI很好的一个落地应用案例，相信这类技术可以彻底改变行业的发展，促成更公平、公正的体育赛事。</p>
<p><strong>人体动作评估</strong>在现实世界中有越来越多的更广泛的应用，如图所示，比如有：医疗保健和物理康复，专门知识学习技能培训，以及<strong>比赛体育活动评分</strong>。所以人体动作评估已成为各种计算机视觉应用中的一个重要问题，并且关于这门领域的研究最近开始多样化。</p>
<img src="/cdc4e36d/3.jpg" class>

<p>人体动作评估的几个重要应用领域：（a）医疗保健和康复； (b)专业技能训练； (c)运动技能训练； (d)体育活动评分</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.sohu.com/a/480994747_120690910">https://www.sohu.com/a/480994747_120690910</a><br><a href="https://baijiahao.baidu.com/s?id=1706328767144484828">https://baijiahao.baidu.com/s?id=1706328767144484828</a><br><a href="https://xw.qq.com/cmsid/20210729A0DJ7J00">https://xw.qq.com/cmsid/20210729A0DJ7J00</a><br><a href="https://baijiahao.baidu.com/s?id=1707151671670975031">https://baijiahao.baidu.com/s?id=1707151671670975031</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10273">https://www.scholat.com/teamwork/showPostMessage.html?id=10273</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>Android-Retrofit（OkHttp）踩坑：为何response.body().string()只能调用一次</title>
    <url>/83555fbc.html</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>api接口返回的body读值为空导致空指针崩溃，但Log却有显示内容</p>
<img src="/83555fbc/1.png" class>

<span id="more"></span>

<img src="/83555fbc/2.png" class>

<hr>
<h3 id="问题定位"><a href="#问题定位" class="headerlink" title="问题定位"></a>问题定位</h3><p>通过断点调试发现Log能正常输出内容，可下一行的result却为空值</p>
<img src="/83555fbc/3.png" class>

<p>而当将Log注释后便能正常显示</p>
<img src="/83555fbc/4.png" class>

<hr>
<h3 id="原因排查"><a href="#原因排查" class="headerlink" title="原因排查"></a>原因排查</h3><p>由是否有log导致问题，进而推断出是注释的response.body().string()有问题，进而分析该函数源码</p>
<p>response是public final class Response&lt;T&gt;类，其中的body()得到ResponseBody对象：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="meta">@Nullable</span> <span class="function">T <span class="title">body</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> body;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="meta">@Nullable</span> T body;</span><br></pre></td></tr></table></figure>

<p>body()没什么问题，所以接着看string()：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">string</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> (BufferedSource source = source()) &#123;</span><br><span class="line">        Charset charset = Util.bomAwareCharset(source, charset());</span><br><span class="line">        <span class="keyword">return</span> source.readString(charset);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>点进去看readString()，是个接口，Ctrl+H查看实现类，找到是RealBufferedSource：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> String <span class="title">readString</span><span class="params">(Charset charset)</span> thrIOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (charset == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;charset == null&quot;</span>);</span><br><span class="line">    buffer.writeAll(source);</span><br><span class="line">    <span class="keyword">return</span> buffer.readString(charset);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到将数据用public final Buffer buffer = new Buffer()的writeAll和readString送走了，点进readString，跳进几个Override后：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Segment s = head;</span><br><span class="line"><span class="keyword">if</span> (s.pos + byteCount &gt; s.limit) &#123;</span><br><span class="line">    <span class="comment">// If the string spans multiple segments, delegate readBytes().</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> String(readByteArray(byteCount), charset);</span><br><span class="line">&#125;</span><br><span class="line">String result = <span class="keyword">new</span> String(s.data, s.pos, (<span class="keyword">int</span>) byteCouncharset);</span><br><span class="line">s.pos += byteCount;</span><br><span class="line">size -= byteCount;</span><br><span class="line"><span class="keyword">if</span> (s.pos == s.limit) &#123;</span><br><span class="line">    head = s.pop();</span><br><span class="line">    SegmentPool.recycle(s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>即通过类似于指针的方式，将response的消息读进缓存再把把消息读出，所以response.body().string()只能读一次，就不再含有消息了。</p>
<hr>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>读出string后若需多次使用则需要用变量进行保存</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在实际开发中，响应主体ResponseBody持有的资源可能会很大，所以OkHttp并不会将其直接保存到内存中，只是持有数据流连接。只有当我们需要时，才会从服务器获取数据并返回。同时，考虑到应用重复读取数据的可能性很小，所以将其设计为一次性流（one-shot），读取后即“关闭并释放资源”。</p>
<ol>
<li><p>响应体只能被使用一次</p>
</li>
<li><p>响应体必须关闭：值得注意的是，在下载文件等场景下response.body().byteStream()形式获取输入流时，务必通过Respoclose()来手动关闭响应体</p>
</li>
<li><p>获取响应体数据的方法：使用bytes()或string()将整个响应读或者使用source()，byteStream()，charStream()方法以流的形据</p>
</li>
<li><p>以下方法会触发关闭响应体：<br> Response.close()<br> Response.body().close()<br> Response.body().source().close()<br> Response.body().charStream().close()<br> Response.body().byteString().close()<br> Response.body().bytes()<br> Response.body().string()</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-旋转屏幕导致Activity重建解决方法</title>
    <url>/23d10eaa.html</url>
    <content><![CDATA[<h3 id="禁止旋转屏幕"><a href="#禁止旋转屏幕" class="headerlink" title="禁止旋转屏幕"></a>禁止旋转屏幕</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;activity</span><br><span class="line">    android:name=<span class="string">&quot;.MyActivity&quot;</span></span><br><span class="line">    android:screenOrientation=<span class="string">&quot;portrait&quot;</span></span><br><span class="line">    android:label=<span class="string">&quot;@string/app_name&quot;</span>/&gt;</span><br></pre></td></tr></table></figure>

<h3 id="旋转后恢复现场"><a href="#旋转后恢复现场" class="headerlink" title="旋转后恢复现场"></a>旋转后恢复现场</h3><p>“持久化/恢复现场”来解决。即在onPause()里将用户当前已经输入的内容保存到数据库或Preference，在onCreate()方法里读取并填充到表单中，这也是官方推荐的方法。</p>
<span id="more"></span>

<p>如果Activity重建需要耗费大量资源或需要访问网络导致时间很长，可以实现onRetainNonConfigurationInstance()方法将所需数据先保存到一个对象里，像下面这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">onRetainNonConfigurationInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> MyDataObject data = collectMyLoadedData();</span><br><span class="line">    <span class="keyword">return</span> data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>重建时，在onCreate()方法里通过getLastNonConfigurationInstance()方法获得之前保存的数据，如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onCreate(savedInstanceState);</span><br><span class="line">    setContentView(R.layout.main);</span><br><span class="line">    <span class="keyword">final</span> MyDataObject data = (MyDataObject) getLastNonConfigurationInstance();</span><br><span class="line">    <span class="keyword">if</span> (data == <span class="keyword">null</span>) &#123;    <span class="comment">//表示不是由于Configuration改变触发的onCreate()</span></span><br><span class="line">        data = loadMyData();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="手工处理旋转"><a href="#手工处理旋转" class="headerlink" title="手工处理旋转"></a>手工处理旋转</h3><p>一般情况下Configuration的改变会导致Activity被销毁重建，但也有办法让指定的Configuration改变时不重建Activity，方法是在AndroidManifest.xml里通过android:configChanges属性指定需要忽略的Configuration名字，例如下面这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;activity</span><br><span class="line">    android:name=<span class="string">&quot;.MyActivity&quot;</span></span><br><span class="line">    android:configChanges=<span class="string">&quot;orientation|keyboardHidden&quot;</span></span><br><span class="line">    android:label=<span class="string">&quot;@string/app_name&quot;</span>/&gt;</span><br></pre></td></tr></table></figure>

<p>当屏幕旋转时Activity对象不会被销毁——作为替代，Activity的onConfigurationChanged()方法被触发，在这里开发者可以获取到当前的屏幕方向以便做必要的更新。既然这种情况下的Activity不会被销毁，旋转后Activity里正显示的信息（例如文本框中的文字）也就不会丢失了。假如你的应用里，横屏和竖屏使用同一个layout资源文件，onConfigurationChanged()里甚至可以什么都不做。但如果横屏与竖屏使用不同的layout资源文件，例如横屏用res/layout-land/main.xml，竖屏用res/layout-port/main.xml，则必须在onConfigurationChanged()里重新调用setContentView()方法以便新的layout能够生效，这时虽然Activity对象没有销毁，但界面上的各种控件都被销毁重建了，你需要写额外的代码来恢复界面信息。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onConfigurationChanged</span><span class="params">(Configuration newConfig)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onConfigurationChanged(newConfig);</span><br><span class="line">    <span class="comment">// Checks the orientation of the screen</span></span><br><span class="line">    <span class="keyword">if</span> (newConfig.orientation == Configuration.ORIENTATION_LANDSCAPE) &#123;</span><br><span class="line">        Toast.makeText(<span class="keyword">this</span>, <span class="string">&quot;横屏模式&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (newConfig.orientation == Configuration.ORIENTATION_PORTRAIT)&#123;</span><br><span class="line">        Toast.makeText(<span class="keyword">this</span>, <span class="string">&quot;竖屏模式&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>考虑到旋转屏幕并不是使Activity被销毁重建的唯一因素，仍然推荐前文介绍过的方法：在onPause()里持久化Activity状态，在onCreate()里恢复现场，可以做到一举多得；虽然Google不推荐设置android:configChanges属性的方式，但如果你的Activity横向纵向共用同一个layout文件，方法3无疑是最省事的。</p>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-onTouch()和onTouchEvent()的区别</title>
    <url>/6f0911e6.html</url>
    <content><![CDATA[<h3 id="onTouch-方法"><a href="#onTouch-方法" class="headerlink" title="onTouch()方法"></a>onTouch()方法</h3><p>当把手放到View上后，onTouch方法被一遍一遍的调用</p>
<p>onTouch方式是View的onTouchListener接口中定义的方法。当一个View绑定了onTouchListener后，当有Touch事件触发时，就会调用onTouch方法。</p>
<hr>
<h3 id="onTouchEvent-方法"><a href="#onTouchEvent-方法" class="headerlink" title="onTouchEvent()方法"></a>onTouchEvent()方法</h3><p>当把手放到Activity上时，onTouchEvent方法会一遍一遍的被调用</p>
<p>onTouchEvent方法时重载的Activity的方法。重写了Acitivity的onTouchEvent方法后，当屏幕有Touch事件时，此方法就会被调用。</p>
<span id="more"></span>

<hr>
<h3 id="Touch事件的传递"><a href="#Touch事件的传递" class="headerlink" title="Touch事件的传递"></a>Touch事件的传递</h3><p>在一个Activity里面放一个TextView的实例tv，并且这个tv的属性设定为march_parent，在这种情况下，当手放到屏幕上的时候，首先会是tv响应Touch事件，执行onTouch方法。</p>
<p>如果onTouch返回值为true，表示这个Touch事件被onTouch方法处理完毕，不会把Touch事件再传递给Activity，也就是说onTouchEvent方法不会被调用。（手放到屏幕上后，onTouch方法会被一遍一遍的调用）</p>
<p>如果onTouch返回值为false,表示这个Touch事件没有被tv完全处理，onTouch返回以后，Touch事件被传递给Activity，onTouchEvent方法调用（当把手放到屏幕上后，onTouch方法调用一次后，onTouchEvent方法被一遍一遍的调用）</p>
<img src="/6f0911e6/1.png" class>

<img src="/6f0911e6/2.png" class>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>dispatchTouchEvent返回值的意义跟onTouch返回值的区别：两者返回true的时候ACTION都会传递到ACTION_DOWN，其中onTouch返回true的时候由于不会执行到onTouchEvent所以不会执行到onClick，dispatchTouchEvent返回值为true对会不会执行onClick没有影响；onTouch返回false的时候执行onTouchEvent，如果此时该控件是可点击的就发执行onClick，而dispatchTouchEvent返回false就停止ACTION传递。</p>
<ol>
<li><p>Android事件分发是先传递到ViewGroup，再由ViewGroup传递到的。</p>
</li>
<li><p>在ViewGroup中可以通过onInterceptTouchEvent方法对事件拦截，onInterceptTouchEvent方法返回true代表不允许事件继续向子传递，返回false代表不对事件进行拦截，默认返回false。</p>
</li>
<li><p>子View中如果将传递的事件消费掉，ViewGroup中将无法接收到任何事件。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-runOnUiThread()和handler的区别</title>
    <url>/4fab8125.html</url>
    <content><![CDATA[<p>在Android开发过程中，常需要更新界面的UI，而更新UI是要主线程来更新的，即UI线程更新。Android中的View不是线程安全的，如果在主线程之外的线程中直接更新页面显示会报错。runOnUithread(Runnale)和Handler.post(Runnable)都是将更新UI的操作提交到主线程/UI线程中执行。</p>
<p>非主UI线程更新视图的两种方法：一种是Handler，一种是Activity中的runOnUiThread(Runnable)方法。</p>
<span id="more"></span>

<hr>
<h3 id="Handler"><a href="#Handler" class="headerlink" title="Handler"></a>Handler</h3><p>对于Handler是采用传递消息的方式，调用Handler中方法来处理消息更新视图，这种方式对于不是很频繁的调用是可取的。如果更新的较快，则消息处理会一直排队处理，这样显示会相对滞后。</p>
<p>在主线程中使用：（本身主线程就可以，没必要这样用Handler）【慢慢排队】</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> Handler().post(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        mTest.setText(<span class="string">&quot;post&quot;</span>);<span class="comment">//更新UI</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>在子线程中使用：（使用handler方法切回主线程时，注意handler的实例化要放在主线程中，而不能在新开的子线程中）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Handler handler = <span class="keyword">new</span> Handler();</span><br><span class="line"><span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">           耗时操作</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        handler.post(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                   更新UI</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).start();</span><br></pre></td></tr></table></figure>

<h3 id="runOnUiThread"><a href="#runOnUiThread" class="headerlink" title="runOnUiThread()"></a>runOnUiThread()</h3><p>实时性较高则用runOnUiThread()，将需要执行的代码放到Runnable的run方法中，然后调用runOnUiThread()这个方法将Runnable的对象传入即可。【在主线程就插队，不然还是排队】</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">runOnUiThread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// do something</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>流程：事件响应→开启线程→runOnUiThread→判断是否当前线程为主UI线程（是就立刻执行，不是就通过handler.post()发送到动作序列中，等到是主UI线程再立刻执行）</p>
<h3 id="结论与三种常见更新方式"><a href="#结论与三种常见更新方式" class="headerlink" title="结论与三种常见更新方式"></a>结论与三种常见更新方式</h3><p>runOnUiThread()这个方法比较适合在异步线程之前去更新进度条之类的UI操作，在线程执行过程之中动态更新UI的方法最好还是选用Handler.post()这一种方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Handler handler = <span class="keyword">new</span> Handler();</span><br><span class="line"><span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 素描算法处理 耗时操作</span></span><br><span class="line">        <span class="keyword">final</span> Bitmap bitmap = SketchUtil.testGaussBlur(finalBitmap,<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 三种切回主线程更新UI的方法</span></span><br><span class="line">        imageView.post(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                imageView.setImageBitmap(bitmap); <span class="comment">// 素描图</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        runOnUiThread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                orignView.setImageBitmap(bitmap); <span class="comment">// 素描图</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        handler.post(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                threeView.setImageBitmap(bitmap); <span class="comment">// 素描图</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).start();</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-动手学深度学习 PyTorch版(PART IX)</title>
    <url>/ceb012c4.html</url>
    <content><![CDATA[<h3 id="《动手学深度学习》v2-课本"><a href="#《动手学深度学习》v2-课本" class="headerlink" title="《动手学深度学习》v2 课本"></a>《动手学深度学习》v2 课本</h3><p><a href="http://zh.d2l.ai/">《动手学深度学习》v2 课本</a></p>
<span id="more"></span>

<hr>
<h3 id="64-注意力机制"><a href="#64-注意力机制" class="headerlink" title="64 注意力机制"></a>64 注意力机制</h3><h4 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h4><iframe src="//player.bilibili.com/player.html?aid=759726865&bvid=BV1264y1i7R1&cid=385255191&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=759726865&bvid=BV1264y1i7R1&cid=385260280&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="65-注意力分数"><a href="#65-注意力分数" class="headerlink" title="65 注意力分数"></a>65 注意力分数</h3><h4 id="注意力分数"><a href="#注意力分数" class="headerlink" title="注意力分数"></a>注意力分数</h4><iframe src="//player.bilibili.com/player.html?aid=632233659&bvid=BV1Tb4y167rb&cid=385255705&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=632233659&bvid=BV1Tb4y167rb&cid=385266581&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=632233659&bvid=BV1Tb4y167rb&cid=385267673&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="66-使用注意力机制的seq2seq"><a href="#66-使用注意力机制的seq2seq" class="headerlink" title="66 使用注意力机制的seq2seq"></a>66 使用注意力机制的seq2seq</h3><h4 id="使用注意力机制的seq2seq"><a href="#使用注意力机制的seq2seq" class="headerlink" title="使用注意力机制的seq2seq"></a>使用注意力机制的seq2seq</h4><iframe src="//player.bilibili.com/player.html?aid=974654755&bvid=BV1v44y1C7Tg&cid=385256207&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=974654755&bvid=BV1v44y1C7Tg&cid=385261079&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=974654755&bvid=BV1v44y1C7Tg&cid=385264671&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="67-自注意力"><a href="#67-自注意力" class="headerlink" title="67 自注意力"></a>67 自注意力</h3><h4 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h4><iframe src="//player.bilibili.com/player.html?aid=377288232&bvid=BV19o4y1m7mo&cid=389959396&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><iframe src="//player.bilibili.com/player.html?aid=377288232&bvid=BV19o4y1m7mo&cid=389965605&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=377288232&bvid=BV19o4y1m7mo&cid=390164164&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="68-Transformer"><a href="#68-Transformer" class="headerlink" title="68 Transformer"></a>68 Transformer</h3><h4 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h4><iframe src="//player.bilibili.com/player.html?aid=547307796&bvid=BV1Kq4y1H7FL&cid=389959471&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="多头注意力代码"><a href="#多头注意力代码" class="headerlink" title="多头注意力代码"></a>多头注意力代码</h4><iframe src="//player.bilibili.com/player.html?aid=547307796&bvid=BV1Kq4y1H7FL&cid=390067269&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Transformer代码"><a href="#Transformer代码" class="headerlink" title="Transformer代码"></a>Transformer代码</h4><iframe src="//player.bilibili.com/player.html?aid=547307796&bvid=BV1Kq4y1H7FL&cid=390113203&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-3"><a href="#QA-3" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=547307796&bvid=BV1Kq4y1H7FL&cid=390148823&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="69-BERT预训练"><a href="#69-BERT预训练" class="headerlink" title="69 BERT预训练"></a>69 BERT预训练</h3><h4 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h4><iframe src="//player.bilibili.com/player.html?aid=674970301&bvid=BV1yU4y1E7Ns&cid=391389645&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="BERT代码"><a href="#BERT代码" class="headerlink" title="BERT代码"></a>BERT代码</h4><iframe src="//player.bilibili.com/player.html?aid=674970301&bvid=BV1yU4y1E7Ns&cid=390698726&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="BERT预训练数据代码"><a href="#BERT预训练数据代码" class="headerlink" title="BERT预训练数据代码"></a>BERT预训练数据代码</h4><iframe src="//player.bilibili.com/player.html?aid=674970301&bvid=BV1yU4y1E7Ns&cid=390702167&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="BERT预训练代码"><a href="#BERT预训练代码" class="headerlink" title="BERT预训练代码"></a>BERT预训练代码</h4><iframe src="//player.bilibili.com/player.html?aid=674970301&bvid=BV1yU4y1E7Ns&cid=390886713&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-4"><a href="#QA-4" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=674970301&bvid=BV1yU4y1E7Ns&cid=391361827&page=5" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="70-BERT微调"><a href="#70-BERT微调" class="headerlink" title="70 BERT微调"></a>70 BERT微调</h3><h4 id="BERT微调"><a href="#BERT微调" class="headerlink" title="BERT微调"></a>BERT微调</h4><iframe src="//player.bilibili.com/player.html?aid=847491605&bvid=BV15L4y1v7ts&cid=391537047&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="自然语言推理数据集"><a href="#自然语言推理数据集" class="headerlink" title="自然语言推理数据集"></a>自然语言推理数据集</h4><iframe src="//player.bilibili.com/player.html?aid=847491605&bvid=BV15L4y1v7ts&cid=391417954&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="BERT微调代码"><a href="#BERT微调代码" class="headerlink" title="BERT微调代码"></a>BERT微调代码</h4><iframe src="//player.bilibili.com/player.html?aid=847491605&bvid=BV15L4y1v7ts&cid=390695130&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-5"><a href="#QA-5" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=847491605&bvid=BV15L4y1v7ts&cid=391418872&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="71-目标检测竞赛总结"><a href="#71-目标检测竞赛总结" class="headerlink" title="71 目标检测竞赛总结"></a>71 目标检测竞赛总结</h3><iframe src="//player.bilibili.com/player.html?aid=632558188&bvid=BV13b4y1m7y8&cid=394176568&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="72-优化算法"><a href="#72-优化算法" class="headerlink" title="72 优化算法"></a>72 优化算法</h3><h4 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h4><iframe src="//player.bilibili.com/player.html?aid=890094855&bvid=BV1bP4y1p7Gq&cid=394179010&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-6"><a href="#QA-6" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=890094855&bvid=BV1bP4y1p7Gq&cid=394953619&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="73-课程总结和进阶学习"><a href="#73-课程总结和进阶学习" class="headerlink" title="73 - 课程总结和进阶学习"></a>73 - 课程总结和进阶学习</h3><h4 id="课程总结和进阶学习"><a href="#课程总结和进阶学习" class="headerlink" title="课程总结和进阶学习"></a>课程总结和进阶学习</h4><iframe src="//player.bilibili.com/player.html?aid=847592146&bvid=BV1AL4y1Y7gu&cid=395491197&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="QA-7"><a href="#QA-7" class="headerlink" title="QA"></a>QA</h4><iframe src="//player.bilibili.com/player.html?aid=847592146&bvid=BV1AL4y1Y7gu&cid=395496630&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>Android-LayoutInflater与inflate()</title>
    <url>/bc5422d5.html</url>
    <content><![CDATA[<p>在开发中，我们经常需要使用到LayoutInflater，通过该对象的inflate()方法，将一个layout布局文件实例化为View对象。</p>
<h3 id="LayoutInflater"><a href="#LayoutInflater" class="headerlink" title="LayoutInflater"></a>LayoutInflater</h3><p>对于LayoutInflater的定义，我们来看一下官方文档：</p>
<p>Instantiates a layout XML file into its corresponding android.view.View objects.</p>
<p>意思是，将一个XML文件实例化为对应的View对象。</p>
<span id="more"></span>

<p>在实际开发中，我们避免不了需要使用到LayoutInflater类中的inflate()方法。对于LayoutInflater对象的获取，有三种方式。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 第一种方式</span></span><br><span class="line">LayoutInflater inflater = (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第二种方式</span></span><br><span class="line">LayoutInflater inflater = LayoutInflater.from(context);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第三种方式</span></span><br><span class="line">LayoutInflater inflater = activity.getLayoutInflater();</span><br></pre></td></tr></table></figure>

<h4 id="context-getSystemService"><a href="#context-getSystemService" class="headerlink" title="context.getSystemService()"></a>context.getSystemService()</h4><p>getSystemService()是Android很重要的一个API，它是Context类的一个方法，根据传入的name来取得对应的Object，然后转换成相应的服务对象。Context.LAYOUT_INFLATER_SERVICE表示我们取得的是实例化layout的服务对象。</p>
<h4 id="LayoutInflater-from"><a href="#LayoutInflater-from" class="headerlink" title="LayoutInflater.from()"></a>LayoutInflater.from()</h4><p>它的内部实现如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Obtains the LayoutInflater from the given context.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> LayoutInflater <span class="title">from</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">    LayoutInflater LayoutInflater =</span><br><span class="line">    (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE);</span><br><span class="line">    <span class="keyword">if</span> (LayoutInflater == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> AssertionError(<span class="string">&quot;LayoutInflater not found.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> LayoutInflater;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>from()是LayoutInflater中的一个静态方法，返回LayoutInflater对象。我们可以看到，方法内部其实使用的是context.getSystemService()，也就是上述第一种方式。</p>
<h4 id="activity-getLayoutInflater"><a href="#activity-getLayoutInflater" class="headerlink" title="activity.getLayoutInflater()"></a>activity.getLayoutInflater()</h4><p>getLayoutInflater()是Activity类的一个方法，也就是说只有通过Activity类的引用才能调用，相比于第一种和第二种方式，此种方式存在一定的使用局限。我们来看一下它的内部实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Window类的关键代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> android.app;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Activity</span> <span class="keyword">extends</span> <span class="title">ContextThemeWrapper</span> <span class="keyword">implements</span> ... </span>&#123;</span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">    <span class="keyword">private</span> Window mWindow;</span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@NonNull</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LayoutInflater <span class="title">getLayoutInflater</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> getWindow().getLayoutInflater();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Window <span class="title">getWindow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mWindow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">attach</span><span class="params">(...)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// ......</span></span><br><span class="line">        mWindow = <span class="keyword">new</span> PhoneWindow(<span class="keyword">this</span>);</span><br><span class="line">        <span class="comment">// ......</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从源码可以看到，当我们调用getLayoutInflater()方法时，方法内部先调用了getWindow()方法，而getWindow()返回的是Activity类的mWindow成员变量，mWindow是Window类的引用。当Activity被创建时，会调用attach()方法，在attach()方法里面完成mWindow成员变量赋值，mWindow实际上是PhoneWindow类的对象。Window是一个抽象类，其内部的getLayoutInflater()方法是abstract的，PhoneWindow类继承自Window类，实现了getLayoutInflater()方法，即我们最终调用的是PhoneWindow类的getLayoutInflater()方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Window类的关键代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> android.view;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Window</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@NonNull</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> LayoutInflater <span class="title">getLayoutInflater</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// PhoneWindow类的关键代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.android.internal.policy;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PhoneWindow</span> <span class="keyword">extends</span> <span class="title">Window</span> <span class="keyword">implements</span> <span class="title">MenuBuilder</span>.<span class="title">Callback</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> LayoutInflater mLayoutInflater;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PhoneWindow</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(context);</span><br><span class="line">        mLayoutInflater = LayoutInflater.from(context);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LayoutInflater <span class="title">getLayoutInflater</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mLayoutInflater;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>PhoneWindow类的getLayoutInflater()方法，内部使用的其实是LayoutInflater.from(context)，即上述第二种方式。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>获取LayoutInflater对象，最终都是通过调用Context类的getSystemService()方法来实现的。</p>
<h3 id="inflate"><a href="#inflate" class="headerlink" title="inflate()"></a>inflate()</h3><p>inflate方法的主要作用就是将xml转换成一个View对象，用于动态的创建布局。</p>
<p>它有四种重载形式，但最终都只会调用下面的第四种。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> View <span class="title">inflate</span><span class="params">(<span class="keyword">int</span> resource, ViewGroup root)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> View <span class="title">inflate</span><span class="params">(<span class="keyword">int</span> resource, ViewGroup root, <span class="keyword">boolean</span> attachToRoot)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> View <span class="title">inflate</span><span class="params">(XmlPullParser parser, ViewGroup root)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> View <span class="title">inflate</span><span class="params">(XmlPullParser parser, ViewGroup root, <span class="keyword">boolean</span> attachToRoot)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">// 常见方式</span></span></span><br><span class="line"><span class="function">inflater.<span class="title">inflate</span><span class="params">(R.layout.test, <span class="keyword">null</span>)</span></span>;</span><br><span class="line">inflater.inflate(R.layout.test, root, <span class="keyword">false</span>);</span><br><span class="line">inflater.inflate(R.layout.test, root);  <span class="comment">// 不指定则默认为true</span></span><br><span class="line">inflater.inflate(R.layout.test, root, <span class="keyword">true</span>);</span><br></pre></td></tr></table></figure>

<p>第四种方法的内部实现原理就是利用Pull解析器，对Xml文件进行解析，然后返回View对象。</p>
<h4 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h4><ol>
<li><p>resource 布局的资源id</p>
</li>
<li><p>root 填充的根视图</p>
</li>
<li><p>attachToRoot 是否将载入的视图绑定到根视图中</p>
</li>
</ol>
<h4 id="应用详解"><a href="#应用详解" class="headerlink" title="应用详解"></a>应用详解</h4><ol>
<li><p>如果root == null，attachToRoot将失去作用，设置任何值都没有意义。ResourceId的根节点没有依赖的父布局（容器），所以width和height属性失效。</p>
</li>
<li><p>如果root != null，attachToRoot == true，则会给加载的布局文件的指定一个父布局，即root。并将root返回，resourceId中的width和height属性有效。</p>
</li>
<li><p>如果root != null，attachToRoot == false，不添加到root中。会将布局文件最外层的所有layout属性进行设置，当该view被添加到父view当中时，这些layout属性会自动生效。</p>
</li>
</ol>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><ol>
<li><p>如果root != null，布局文件最外层的layout关于LayoutParams设置的属性和其他属性都会被保留下来。</p>
</li>
<li><p>attachToRoot == true，则会给加载的布局文件的指定一个父布局，我们不需要自己在addView，否则会报错。</p>
</li>
<li><p>attachToRoot == false，需要我们自己addView，root为null时，被加载的布局LayoutParams的属性会被改变，但是其它属性例如背景颜色什么的会被保留。</p>
</li>
</ol>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://blog.csdn.net/ruancoder/article/details/51760942">https://blog.csdn.net/ruancoder/article/details/51760942</a><br><a href="https://www.cnblogs.com/quanziheng/p/13527871.html">https://www.cnblogs.com/quanziheng/p/13527871.html</a><br><a href="https://www.cnblogs.com/x-bing/p/6744471.html">https://www.cnblogs.com/x-bing/p/6744471.html</a><br><a href="https://www.jianshu.com/p/83438249ae91">https://www.jianshu.com/p/83438249ae91</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-RecyclerView-缓存复用与数据更新</title>
    <url>/f1832120.html</url>
    <content><![CDATA[<h2 id="一、RecyclerView与ListView、ViewPager"><a href="#一、RecyclerView与ListView、ViewPager" class="headerlink" title="一、RecyclerView与ListView、ViewPager"></a>一、RecyclerView与ListView、ViewPager</h2><h3 id="RecyclerView"><a href="#RecyclerView" class="headerlink" title="RecyclerView"></a>RecyclerView</h3><p>A flexible view for providing a limited window into a large data set.</p>
<img src="/f1832120/1.jpg" class>

<img src="/f1832120/2.jpg" class>

<img src="/f1832120/3.png" class>

<span id="more"></span>

<p>一般步骤：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mRecyclerView.setLayoutManager(layoutManager); </span><br><span class="line">mRecyclerView.setAdapter(galleryAdapter); </span><br><span class="line"><span class="keyword">new</span> PagerSnapHelper().attachToRecyclerView(mGalleryRecyclerView);</span><br></pre></td></tr></table></figure>

<h3 id="ListView和RecyclerView"><a href="#ListView和RecyclerView" class="headerlink" title="ListView和RecyclerView"></a>ListView和RecyclerView</h3><p>Recyclerview通过内部类Recycler管理的缓存，缓存的是ViewHolder（内部包含子View），这样在滑动时可以复用子View，在某些情况下，还可以复用子View绑定的数据。所以<strong>本质上缓存是为了减少重复绘制View和绑定数据的时间，从而提高了滑动时的性能。</strong></p>
<p>ListView缓存机制，对应到屏幕上：</p>
<img src="/f1832120/4.jpg" class>

<img src="/f1832120/5.jpg" class>

<p>RecyclerView缓存机制，对应到屏幕上，以及可自定义部分：</p>
<img src="/f1832120/6.jpg" class>

<img src="/f1832120/7.jpg" class>

<table>
<thead>
<tr>
<th>ListView的局限</th>
<th>RecyclerView的优势</th>
</tr>
</thead>
<tbody><tr>
<td>1. 纵向列表一种布局</td>
<td>1.默认支持Linear, Grid, Staggered Grid三种布局</td>
</tr>
<tr>
<td>2. 没有支持动画的API</td>
<td>2. ItemAnimator动画API</td>
</tr>
<tr>
<td>3. 接口设计和系统不一致</td>
<td>3. 强制实现ViewHolder</td>
</tr>
<tr>
<td>4. 没有强制实现ViewHolder</td>
<td>4. 解耦架构设计</td>
</tr>
<tr>
<td>5. 性能不如RecyclerView</td>
<td>5. 相比ListView更好的性能</td>
</tr>
</tbody></table>
<p><strong>相似点：</strong></p>
<ol>
<li><p>mActiveViews和mAttachedScrap功能相似，意义在于快速重用屏幕上可见的列表项ItemView，而不需要重新createView()和bindView()</p>
</li>
<li><p>mScrapView和mCachedViews+mReyclerViewPool功能相似，意义在于缓存离开屏幕的ItemView，目的是让即将进入屏幕的ItemView重用</p>
</li>
<li><p>RecyclerView的优势在于【mCacheViews的使用，可以做到屏幕外的列表项ItemView进入屏幕内时也无须bindView快速重用】；【mRecyclerPool可以供多个RecyclerView共同使用】，在特定场景下，如viewpager+多个列表页下有优势</p>
</li>
</ol>
<ul>
<li>总的来说，RecyclerView在特定场景下对ListView的缓存机制进行完善。</li>
</ul>
<p><strong>不同点：</strong></p>
<ol>
<li><p>RecyclerView缓存RecyclerView.ViewHolder，抽象可理解为：View+ViewHolder（避免每次createView时调用findViewById）+flag（标识状态）</p>
</li>
<li><p>ListView缓存View</p>
</li>
</ol>
<h3 id="ViewPager和ViewPager2（RecyclerView）"><a href="#ViewPager和ViewPager2（RecyclerView）" class="headerlink" title="ViewPager和ViewPager2（RecyclerView）"></a>ViewPager和ViewPager2（RecyclerView）</h3><p>ViewPager2 底层是用 RecycleView 实现（RecyclerView.Adapter）</p>
<p>RecyclerView的Adapter可以针对不同Item的ViewType来缓存不同的Item</p>
<p>例子：TabLayout 与 ViewPager2</p>
<hr>
<h2 id="二、RecyclerView在TV上的应用"><a href="#二、RecyclerView在TV上的应用" class="headerlink" title="二、RecyclerView在TV上的应用"></a>二、RecyclerView在TV上的应用</h2><h3 id="原生RecyclerView使用时的局限性"><a href="#原生RecyclerView使用时的局限性" class="headerlink" title="原生RecyclerView使用时的局限性"></a>原生RecyclerView使用时的局限性</h3><p>在手机端使用RecyclerView比较简单，但是在TV端就会出现不少的问题，例如焦点显示不全，无法定位到某个position等等</p>
<img src="/f1832120/8.png" class>

<h4 id="RecyclerView刷新数据的时候，焦点错乱问题"><a href="#RecyclerView刷新数据的时候，焦点错乱问题" class="headerlink" title="RecyclerView刷新数据的时候，焦点错乱问题"></a>RecyclerView刷新数据的时候，焦点错乱问题</h4><p><strong>原因：</strong></p>
<p>（自认为是viewHolder复用的问题，跟数据刷新位置错乱类似）</p>
<p><strong>解决办法：</strong></p>
<ol>
<li><p>adapter调用setHasStableIds(true)方法</p>
<p> 等同于调用了viewholder中的view的requestFocus()方法。</p>
<p> 相当于加了一个tag，tag不变的话，不用重新加载。但是set true后会使得列表的数据项重复，所以需要在Adapter里面重写getItemId。同时RecyclerView的notify方法图片加载时不闪烁。</p>
</li>
<li><p>重写getItemId()方法,让每个view都有各自的id</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getItemId</span><span class="params">(<span class="keyword">int</span> position)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> position;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>RecyclerView的去掉动画</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mRecyclerView.setItemAnimator(<span class="keyword">null</span>);</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="长按遥控器RecyclerView快速滑动，焦点错乱问题"><a href="#长按遥控器RecyclerView快速滑动，焦点错乱问题" class="headerlink" title="长按遥控器RecyclerView快速滑动，焦点错乱问题"></a>长按遥控器RecyclerView快速滑动，焦点错乱问题</h4><p><strong>原因：</strong></p>
<p>RecyclerView在长按遥控器的情况下会导致Item的焦点丢失或者说是飞到别的控件上。主要是因为RecyclerView设置适配器，将数据全部填充进去之后，并不会将所有的item的view创建出来，只会创建出显示和需要的item的View，没有显示的View很可能没有被创建。在滑动的过程中，下一个要获取焦点的view，还处于绘制渲染阶段（PFLAG_INVALIDATED，PFLAG_DIRTY_MASK），这个阶段的view是无法获取焦点的。</p>
<p><strong>解决办法：</strong></p>
<ol>
<li><p>自定义RecyclerView，拦截dispatchkeyEvent事件，对按键进行过滤，取消一些view还处于不能获取焦点的按键事件，并根据遥控器按钮操作来获取焦点</p>
</li>
<li><p>比如监听了下键，判断展示数据的RecyclerView是否获得焦点了，接着判断了数据size是否为空，算出数据数量，最后一个item获取到焦点就拦截遥控下键，让焦点一直停留在最后一个item上，就不会出现焦点乱跑了</p>
</li>
</ol>
<h4 id="解决RecyclerView-定位到某个item不获取焦点问题"><a href="#解决RecyclerView-定位到某个item不获取焦点问题" class="headerlink" title="解决RecyclerView 定位到某个item不获取焦点问题"></a>解决RecyclerView 定位到某个item不获取焦点问题</h4><p><strong>原因：</strong></p>
<p>RecyclerView提供了一个smoothScrollToPosition(int position)方法，该方法能滑到指定的position位置，但是实际该position处的item并没有获取焦点。</p>
<p><strong>解决办法：</strong></p>
<ol>
<li><p>定位到指定位置的item后，找到目标的item，并让其主动请求焦点</p>
</li>
<li><p>RecyclerView弹性滑动SmoothScroller中有onStart和onStop的回调，在onStop滑动结束的回调找到targetView，并让其请求焦点</p>
</li>
</ol>
<h4 id="Android-TV-中RecyclerView聚焦Item实现居中功能"><a href="#Android-TV-中RecyclerView聚焦Item实现居中功能" class="headerlink" title="Android TV 中RecyclerView聚焦Item实现居中功能"></a>Android TV 中RecyclerView聚焦Item实现居中功能</h4><p><strong>需求：</strong></p>
<p>实现一种节目列表选中自动居中放大的功能</p>
<img src="/f1832120/9.png" class>

<p><strong>方法1：</strong> 重写RecyclerView的layoutManager的smoothScrollToPosition函数，该方法通过修改滑动Scroller里面的偏移量来达到居中的效果</p>
<p><strong>方法2：</strong> 在adapter中给item添加一个聚焦的监听，然后对当前Item的坐标以及RecyclerView的位置计算出需要偏移的长度，最后调用RecyclerView的smoothScrollBy函数进行滚动。</p>
<hr>
<h2 id="三、RecyclerView缓存与复用原理"><a href="#三、RecyclerView缓存与复用原理" class="headerlink" title="三、RecyclerView缓存与复用原理"></a>三、RecyclerView缓存与复用原理</h2><h3 id="四级缓存"><a href="#四级缓存" class="headerlink" title="四级缓存"></a>四级缓存</h3><p>优先级又高到低依次是：</p>
<p><strong>ArrayList mAttachedScrap</strong> → 缓存屏幕中可见范围的ViewHolder</p>
<p><strong>ArrayList mCachedViews</strong> → 缓存滑动时即将与RecyclerView分离的ViewHolder，按子View的position或id缓存，默认最多存放2个</p>
<p><strong>ViewCacheExtension mViewCacheExtension</strong> → 开发者自行实现的缓存</p>
<p><strong>RecycledViewPool mRecycledViewPool</strong> → ViewHolder缓存池，本质上是一个SparseArray，其中Key是ViewType（Int类型），value存放的是ArrayList<ViewHolder>，默认每个ArrayList中最多存放5个ViewHolder</ViewHolder></p>
<img src="/f1832120/10.jpg" class>

<p>通过mAttachedScrap（1）、mCachedViews（2）获取的ViewHolder不需要重新创建布局及绑定数据</p>
<p>通过缓存池mRecyclerPool（4）获取的ViewHolder不需要重新创建布局，但是需要重新绑定数据</p>
<p>如果上述缓存中都没有获取到目标ViewHolder，那么就会回调Adapter#onCreateViewHolder创建布局，以及回调Adapter#onBindViewHolder来绑定数据。</p>
<table>
<thead>
<tr>
<th>缓存等级</th>
<th>是否需要回调createView()</th>
<th>是否需要回调bindView()</th>
<th>生命周期</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>mAttachedScrap</td>
<td>否</td>
<td>否</td>
<td>onLayout()周期内</td>
<td>用于屏幕内ItemView快速重用</td>
</tr>
<tr>
<td>mCacheViews</td>
<td>否</td>
<td>否</td>
<td>与mAdapter一致，当mAdapter被更换时，mCacheViews即被缓存至mRecyclerPool</td>
<td>默认上限为2，即缓存屏幕外2个ItemView</td>
</tr>
<tr>
<td>mViewCacheExtension</td>
<td></td>
<td></td>
<td></td>
<td>不直接使用，需要用户自己定制，默认不实现</td>
</tr>
<tr>
<td>mRecyclerPool</td>
<td>否</td>
<td>是</td>
<td>与自身生命周期一致，不再被引用时即被释放</td>
<td>默认上限为5，技术上可以实现所有RecyclerViewPool共用同一个</td>
</tr>
</tbody></table>
<h3 id="源码走查"><a href="#源码走查" class="headerlink" title="源码走查"></a>源码走查</h3><ol>
<li><p>复用</p>
<table>
<thead>
<tr>
<th>布局</th>
<th>滑动</th>
</tr>
</thead>
<tbody><tr>
<td>RecyclerView.onLayout(…)</td>
<td>RecyclerView.onTouchEvent(…)</td>
</tr>
<tr>
<td>-&gt; RecyclerView.dispatchLayout()</td>
<td>-&gt; MotionEvent.ACTION_MOVE</td>
</tr>
<tr>
<td>-&gt; RecyclerView.dispatchLayoutStep2()</td>
<td>-&gt; RecyclerView.scrollByInternal(…)</td>
</tr>
<tr>
<td>-&gt; mLayout.onLayoutChildren(mRecycler, mState)</td>
<td>-&gt; RecyclerView.scrollStep(…)</td>
</tr>
<tr>
<td>-&gt; LinearLayoutManager.onLayoutChildren(…)</td>
<td>-&gt; LinearLayoutManager.scrollHorizontallyBy(…)</td>
</tr>
<tr>
<td>-&gt; LinearLayoutManager.fill(…)</td>
<td>-&gt; LinearLayoutManager.scrollBy(…)</td>
</tr>
<tr>
<td>-&gt; LinearLayoutManager.layoutChunk(recycler, layoutState)</td>
<td>-&gt; LinearLayoutManager.fill(…)</td>
</tr>
<tr>
<td>-&gt; LinearLayoutManager.LayoutState.next(recycler)</td>
<td>-&gt; ……</td>
</tr>
<tr>
<td>-&gt; RecyclerView.Recycler.getViewForPosition(int)</td>
<td></td>
</tr>
<tr>
<td>-&gt; Recycler.getViewForPosition(int, boolean)</td>
<td></td>
</tr>
<tr>
<td>-&gt; Recycler.tryGetViewHolderForPositionByDeadline(…)</td>
<td></td>
</tr>
</tbody></table>
 <img src="/f1832120/11.png" class>
</li>
<li><p>缓存</p>
<p> 没有缓存那怎么复用？所以去fill()复用前找缓存的方法函数。</p>
<table>
<thead>
<tr>
<th>布局</th>
</tr>
</thead>
<tbody><tr>
<td>LinearLayoutManager.fill(…)之前</td>
</tr>
<tr>
<td>-&gt; RecyclerView.detachAndScrapAttachedViews(…)</td>
</tr>
<tr>
<td>-&gt; RecyclerView.scrapOrRecycleView()</td>
</tr>
<tr>
<td>-&gt; recycler.recycleViewHolderInternal()和recycler.scrapView()</td>
</tr>
<tr>
<td>-&gt; 后者是有效时，加进第一级缓存，非本次重点</td>
</tr>
<tr>
<td>-&gt; recycler.recycleViewHolderInternal()</td>
</tr>
<tr>
<td>-&gt; (cachedViewSize、recycleCachedViewAt())</td>
</tr>
<tr>
<td>-&gt; addViewHolderToRecycledViewPool()</td>
</tr>
<tr>
<td>-&gt; getRecycledViewPool().putRecycledView()</td>
</tr>
<tr>
<td>-&gt; 已满直接return，未满就清除数据后add</td>
</tr>
</tbody></table>
 <img src="/f1832120/12.png" class>

</li>
</ol>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><h4 id="ViewCacheExtension的使用场景与实现"><a href="#ViewCacheExtension的使用场景与实现" class="headerlink" title="ViewCacheExtension的使用场景与实现"></a>ViewCacheExtension的使用场景与实现</h4><p>RecyclerView中的其他缓存：第一级缓存mAttachedScrap用来处理可见屏幕的缓存；第二级缓存mCachedViews里存储的数据虽然是根据position来缓存，但是里面的数据随时可能会被替换的；第四级缓存mRecyclerPool里按viewType去存储ArrayList<ViewHolder>，所以mRecyclerPool并不能按position去存储ViewHolder，而且从mRecyclerPool取出的View每次都要去走Adapter#onBindViewHolder去重新绑定数据。</ViewHolder></p>
<p>所以假如现在需要在一个特定的位置（比如position=0位置）一直展示某个View，且里面的内容是不变的，那么最好的情况就是在特定位置时，既不需要每次重新创建View，也不需要每次都去重新绑定数据，上面的几种缓存显然都是不适用的，这种情况可以通过自定义缓存ViewCacheExtension实现上述需求。</p>
<p>ViewCacheExtension适用场景：ViewHolder位置固定、内容固定、数量有限时使用。</p>
<h4 id="SparseArray"><a href="#SparseArray" class="headerlink" title="SparseArray"></a>SparseArray</h4><p>SparseArray是Android里为&lt;Interger,Object&gt;这样的Hashmap而专门写的类，目的是提高内存效率，其核心是折半查找函数。</p>
<p>SparseArray有两个优点：1. 避免了自动装箱（类似enum）2. 数据结构不会依赖于外部对象映射（数组数据结构来保存映射）。</p>
<hr>
<h2 id="四、RecyclerView刷新列表数据的notifyDatasetChange-为什么消耗资源比其他刷新方法多"><a href="#四、RecyclerView刷新列表数据的notifyDatasetChange-为什么消耗资源比其他刷新方法多" class="headerlink" title="四、RecyclerView刷新列表数据的notifyDatasetChange()为什么消耗资源比其他刷新方法多"></a>四、RecyclerView刷新列表数据的notifyDatasetChange()为什么消耗资源比其他刷新方法多</h2><h3 id="RecyclerView-Adapter中刷新数据的方法"><a href="#RecyclerView-Adapter中刷新数据的方法" class="headerlink" title="RecyclerView.Adapter中刷新数据的方法"></a>RecyclerView.Adapter中刷新数据的方法</h3><ol>
<li><p>notifyDataSetChanged()</p>
<p> 此方法跟ListView的Adapter的方法一样</p>
</li>
<li><p>notifyItemChanged(int position)</p>
<p> 当position位置的数据发生了改变时就会调用这个方法，就会回调对应position的onBindViewHolder()方法了，当然，因为ViewHolder是复用的，所以如果position在当前屏幕以外，因为没有意义也就不会回调了，下次position滚动会当前屏幕以内的时候同样会调用onBindViewHolder()方法刷新数据了。其他的方法也是同样的道理。</p>
<p> 其它：notifyItemRangeChanged(int positionStart, int itemCount)……（包括插入、移动、删除、批量操作）</p>
<p> 当列表数据变更时，调用notifyDataSetChanged()是最省事的。无需关心变更的细节，但这样做也是最昂贵的。</p>
</li>
</ol>
<h3 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h3><ol>
<li><p>Adapter.notifyDataSetChanged() 将刷新操作委托给 AdapterDataObservable</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Adapter</span>&lt;<span class="title">VH</span> <span class="keyword">extends</span> <span class="title">ViewHolder</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AdapterDataObservable mObservable = <span class="keyword">new</span> AdapterDataObservable();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">notifyDataSetChanged</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        mObservable.notifyChanged();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>AdapterDataObservable 是 RecyclerView 的静态内部类，它继承自Observable：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">AdapterDataObservable</span> <span class="keyword">extends</span> <span class="title">Observable</span>&lt;<span class="title">AdapterDataObserver</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">notifyChanged</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 遍历所有观察者并委托之</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = mObservers.size() - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">            mObservers.get(i).onChanged();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Adapter 数据的观察者的注册时间：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAdapter</span><span class="params">(<span class="meta">@Nullable</span> Adapter adapter)</span> </span>&#123;</span><br><span class="line">    setLayoutFrozen(<span class="keyword">false</span>);</span><br><span class="line">    setAdapterInternal(adapter, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">    processDataSetCompletelyChanged(<span class="keyword">false</span>);</span><br><span class="line">    requestLayout();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为 RecyclerView 设置 Adapter</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setAdapterInternal</span><span class="params">(<span class="meta">@Nullable</span> Adapter adapter, <span class="keyword">boolean</span> compatibleWithPrevious, <span class="keyword">boolean</span> removeAndRecycleViews)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (mAdapter != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 移除之前的观察者</span></span><br><span class="line">        mAdapter.unregisterAdapterDataObserver(mObserver);</span><br><span class="line">        mAdapter.onDetachedFromRecyclerView(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">final</span> Adapter oldAdapter = mAdapter;</span><br><span class="line">    mAdapter = adapter;</span><br><span class="line">    <span class="keyword">if</span> (adapter != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 注册新的观察者</span></span><br><span class="line">        adapter.registerAdapterDataObserver(mObserver);</span><br><span class="line">        adapter.onAttachedToRecyclerView(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Adapter</span>&lt;<span class="title">VH</span> <span class="keyword">extends</span> <span class="title">ViewHolder</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 注册观察者</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerAdapterDataObserver</span><span class="params">(<span class="meta">@NonNull</span> AdapterDataObserver observer)</span> </span>&#123;</span><br><span class="line">        mObservable.registerObserver(observer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Observable是一个抽象的可被观察者：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 被观察者, 泛型表示观察者的类型</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Observable</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 观察者列表</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> ArrayList&lt;T&gt; mObservers = <span class="keyword">new</span> ArrayList&lt;T&gt;();</span><br><span class="line">    <span class="comment">// 注册观察者</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerObserver</span><span class="params">(T observer)</span> </span>&#123;</span><br><span class="line">        ...</span><br><span class="line">        mObservers.add(observer);</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 注销观察者</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unregisterObserver</span><span class="params">(T observer)</span> </span>&#123;</span><br><span class="line">        ...</span><br><span class="line">        mObservers.remove(index);</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 移除所有观察者</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unregisterAll</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ...</span><br><span class="line">        mObservers.clear();</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在为 RecyclerView 绑定 Adapter 的时候，一个观察者实例RecyclerViewDataObserver被注册了：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">RecyclerViewDataObserver</span> <span class="keyword">extends</span> <span class="title">AdapterDataObserver</span> </span>&#123;</span><br><span class="line">    RecyclerViewDataObserver() &#123;&#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onChanged</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        assertNotInLayoutOrScroll(<span class="keyword">null</span>);</span><br><span class="line">        mState.mStructureChanged = <span class="keyword">true</span>;</span><br><span class="line">        processDataSetCompletelyChanged(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">if</span> (!mAdapterHelper.hasPendingUpdates()) &#123;</span><br><span class="line">            requestLayout();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="onChange-更新前的全量无效化"><a href="#onChange-更新前的全量无效化" class="headerlink" title="onChange()更新前的全量无效化"></a>onChange()更新前的全量无效化</h3><ol>
<li><p>RecyclerView 遍历了当前所有已经被加载的表项，并为其 ViewHolder 添加 FLAG_UPDATE 和 FLAT_INVALID 标志位。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">processDataSetCompletelyChanged</span><span class="params">(<span class="keyword">boolean</span> dispatchItemsChanged)</span> </span>&#123;</span><br><span class="line">    mDispatchItemsChangedEvent |= dispatchItemsChanged;</span><br><span class="line">    mDataSetHasChangedAfterLayout = <span class="keyword">true</span>;</span><br><span class="line">    <span class="comment">// 将当前所有表项无效化</span></span><br><span class="line">    markKnownViewsInvalid();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">markKnownViewsInvalid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 遍历列表所有表项</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> childCount = mChildHelper.getUnfilteredChildCount();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; childCount; i++) &#123;</span><br><span class="line">        <span class="keyword">final</span> ViewHolder holder = getChildViewHolderInt(mChildHelper.getUnfilteredChildAt(i));</span><br><span class="line">        <span class="comment">// 列表中每个表项的 ViewHolder 添加 FLAG_UPDATE 和 FLAG_INVALID 标志位</span></span><br><span class="line">        <span class="keyword">if</span> (holder != <span class="keyword">null</span> &amp;&amp; !holder.shouldIgnore()) &#123;</span><br><span class="line">            holder.addFlags(ViewHolder.FLAG_UPDATE | ViewHolder.FLAG_INVALID);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    markItemDecorInsetsDirty();</span><br><span class="line">    <span class="comment">// 将缓存中表项无效化</span></span><br><span class="line">    mRecycler.markKnownViewsInvalid();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>RecyclerView 将所有离屏缓存中的 ViewHolder 也都做了无效化处理，回收到缓存池。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Recycler</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">markKnownViewsInvalid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 遍历所有离屏缓存</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> cachedCount = mCachedViews.size();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; cachedCount; i++) &#123;</span><br><span class="line">            <span class="keyword">final</span> ViewHolder holder = mCachedViews.get(i);</span><br><span class="line">            <span class="comment">// 将每个离屏缓存中的 ViewHolder 也添加 FLAG_UPDATE 和 FLAG_INVALID 标志位</span></span><br><span class="line">            <span class="keyword">if</span> (holder != <span class="keyword">null</span>) &#123;</span><br><span class="line">                holder.addFlags(ViewHolder.FLAG_UPDATE | ViewHolder.FLAG_INVALID);</span><br><span class="line">                holder.addChangePayload(<span class="keyword">null</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (mAdapter == <span class="keyword">null</span> || !mAdapter.hasStableIds()) &#123;</span><br><span class="line">            <span class="comment">// 将离屏缓存中的 ViewHolder 存入缓存池</span></span><br><span class="line">            recycleAndClearCachedViews();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="真正的刷新"><a href="#真正的刷新" class="headerlink" title="真正的刷新"></a>真正的刷新</h3><p>在将一切都无效化后，调用了View.requestLayout()，即请求重新布局，该请求会不断地向父控件传递</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">View</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requestLayout</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// 添加两个标志位</span></span><br><span class="line">        mPrivateFlags |= PFLAG_FORCE_LAYOUT;</span><br><span class="line">        mPrivateFlags |= PFLAG_INVALIDATED;</span><br><span class="line">        <span class="comment">// 向父控件传递重绘请求</span></span><br><span class="line">        <span class="keyword">if</span> (mParent != <span class="keyword">null</span> &amp;&amp; !mParent.isLayoutRequested()) &#123;</span><br><span class="line">            mParent.requestLayout();</span><br><span class="line">        &#125;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>列表的重新布局意味着重新布局其中的每一个表项，体现在代码上即是LinearLayoutManager.onLayoutChildren()（holder.needsUpdate() || holder.isInvalid()）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinearLayoutManager</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onLayoutChildren</span><span class="params">(RecyclerView.Recycler recycler, RecyclerView.State state)</span> </span>&#123;</span><br><span class="line">        ...</span><br><span class="line">        fill();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>总结</li>
</ul>
<ol>
<li><p>RecyclerView 使用观察者模式刷新自己，刷新即是通知所有的观察者。</p>
</li>
<li><p>观察者是RecyclerViewDataObserver（抽象为AdapterDataObserver），它们维护在RecyclerView的静态内部类AdapterDataObservable中，储存的数据结构是ArrayList<T>。</T></p>
</li>
<li><p>RecyclerView 在真正刷新列表之前，使用processDataSetCompletelyChanged(true);将一切都无效化了，包括当前所有被填充表项及离屏缓存中的 ViewHolder 实例。无效化体现在代码上即是为 ViewHolder 添加 FLAG_UPDATE 和 FLAG_INVALID 标志位。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">holder.addFlags(ViewHolder.FLAG_UPDATE | ViewHolder.FLAG_INVALID);</span><br></pre></td></tr></table></figure>
</li>
<li><p>RecyclerView.requestLayout();是驱动列表刷新的源头，该方法会从根视图自顶向下进行重绘。RecyclerView的重绘表现为重新布局所有表项。</p>
</li>
<li><p>RecyclerView重新布局所有表项：先回收现有表项到缓存池，再重新填充他们。因为回收时ViewHolder都被添加了无效化的两个标志位，所以重绘时即使数据没变也需要重新绑定数据，导致资源消耗比较昂贵。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式-MVC、MVP、MVVM</title>
    <url>/c28ee0e2.html</url>
    <content><![CDATA[<h3 id="MVC"><a href="#MVC" class="headerlink" title="MVC"></a>MVC</h3><p>MVC（模型(model)–视图(view)–控制器(controller)）</p>
<p>Model层处理数据，业务逻辑等；View层处理界面的显示结果；Controller层起到桥梁的作用，来控制View层和Model层通信以此来达到分离视图显示和业务逻辑层。</p>
<h4 id="关键点"><a href="#关键点" class="headerlink" title="关键点"></a>关键点</h4><p>View是把控制权交移给Controller，自己不执行业务逻辑。</p>
<p>Controller执行业务逻辑并且操作Model，但不会直接操作View，可以说它是对View无感知的。</p>
<p>View和Model的同步消息是通过观察者模式进行，而同步操作是由View自己请求Model的数据然后对视图进行更新。</p>
<p>我们往往把Android中界面部分的实现也理解为采用了MVC框架，常常把Activity理解为MVC模式中的Controller。</p>
<span id="more"></span>

<img src="/c28ee0e2/1.png" class>

<img src="/c28ee0e2/2.png" class>

<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol>
<li><p>把业务逻辑全部分离到Controller中，模块化程度高。当业务逻辑变更的时候，不需要变更View和Model，只需要Controller 换成另外一个Controller就行了（Swappable Controller）。</p>
</li>
<li><p>观察者模式可以做到多视图同时更新。</p>
</li>
</ol>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol>
<li><p>Controller测试困难。因为视图同步操作是由View自己执行，而View只能在有UI的环境下运行。在没有UI环境下对Controller进行单元测试的时候， Controller业务逻辑的正确性是无法验证的：Controller更新Model的时候，无法对View的更新操作进行断言。</p>
</li>
<li><p>View无法组件化。View强依赖特定的Model，不同程序的Domain Model是不一样的，如果需要把这个View抽出来作为一个另外一个应用程序可复用的组件就困难了。</p>
</li>
</ol>
<h3 id="MVP"><a href="#MVP" class="headerlink" title="MVP"></a>MVP</h3><p>MVP其实是MVC的一种演进版本，它更简单，将MVC中的Controller改为了Presenter，View通过接口与Presenter进行交互，降低耦合，方便进行单元测试。</p>
<p>View：负责绘制UI元素、与用户进行交互(Activity、View、Fragment都可以做为View层)</p>
<p>Model：对数据的操作、对网络等的操作，和业务相关的逻辑处理</p>
<p>Presenter：作为View与Model交互的中间纽带，处理与用户交互的逻辑。可以把Presenter理解为一个中间层的角色，它接受Model层的数据，并且处理之后传递给View层，还需要处理View层的用户交互等操作。</p>
<h4 id="关键点-1"><a href="#关键点-1" class="headerlink" title="关键点"></a>关键点</h4><p>View不再负责同步的逻辑，而是由Presenter负责。Presenter中既有业务逻辑也有同步逻辑。</p>
<p>View需要提供操作界面的接口给Presenter进行调用。</p>
<p>对比在MVC中，Controller是不能操作View的，View也没有提供相应的接口；而在MVP当中，Presenter可以操作View，View需要提供一组对界面操作的接口给Presenter进行调用；Model仍然通过事件广播自己的变更，但由Presenter监听而不是View。</p>
<img src="/c28ee0e2/3.png" class>

<img src="/c28ee0e2/4.png" class>

<h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ol>
<li><p>便于测试。Presenter对View是通过接口进行，在对Presenter进行不依赖UI环境的单元测试的时候。可以通过Mock一个View对象，这个对象只需要实现了View的接口即可。然后依赖注入到Presenter中，单元测试的时候就可以完整的测试Presenter业务逻辑的正确性。</p>
</li>
<li><p>View可以进行组件化。在MVP当中，View不依赖Model。这样就可以让View从特定的业务场景中脱离出来，可以说View可以做到对业务逻辑完全无感知。它只需要提供一系列接口提供给上层操作。这样就可以做高度可复用的View组件。</p>
</li>
</ol>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ol>
<li>UI更新麻烦。Presenter中除了业务逻辑以外，还有大量的View-&gt;Model，Model-&gt;View的手动同步逻辑，造成Presenter比较笨重，维护起来会比较困难。</li>
</ol>
<h3 id="MVVM"><a href="#MVVM" class="headerlink" title="MVVM"></a>MVVM</h3><p>MVVM（Model–View–ViewModel）</p>
<p>和MVP模式相比，MVVM 模式用ViewModel替换了Presenter ，其他层基本上与 MVP 模式一致，ViewModel可以理解成是View的数据模型和Presenter的合体。</p>
<p>MVVM采用双向绑定（data-binding）：View的变动，自动反映在ViewModel，反之亦然，这种模式实际上是框架替应用开发者做了一些工作（相当于ViewModel类是由库帮我们生成的），开发者只需要较少的代码就能实现比较复杂的交互。</p>
<h4 id="关键点-2"><a href="#关键点-2" class="headerlink" title="关键点"></a>关键点</h4><p>MVVM把View和Model的同步逻辑自动化了。以前Presenter负责的View和Model同步不再手动地进行操作，而是交由框架所提供的Binder进行负责，只需要告诉Binder，View显示的数据对应的是Model哪一部分即可。</p>
<img src="/c28ee0e2/5.png" class>

<h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><ol>
<li><p>提高可维护性。解决了MVP大量的手动View和Model同步的问题，提供双向绑定机制。提高了代码的可维护性。</p>
</li>
<li><p>简化测试。因为同步逻辑是交由Binder做的，View跟着Model同时变更，所以只需要保证Model的正确性，View就正确。大大减少了对View同步更新的测试。</p>
</li>
</ol>
<h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ol>
<li><p>对于过于简单的图形界面不适用。</p>
</li>
<li><p>对于大型的图形应用程序，视图状态较多，ViewModel的构建和维护的成本都会比较高。</p>
</li>
<li><p>数据绑定的声明是指令式地写在View的模版当中的，这些内容是没办法去打断点debug的。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐设计模式</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-神经科学新发现，大脑声音和语言处理是独立且同时进行的</title>
    <url>/f4eccbfe.html</url>
    <content><![CDATA[<p>经过多年的研究，神经科学家近日发现了一种在人脑中处理声音和语言的新途径。研究结果表明，声音和语言处理是并行发生的，这与传统的大脑处理生理学信息然后将其转化为语言信息的理论相矛盾。</p>
<p>长期以来，大部分科学家们认为听觉皮层中的声音处理遵循一个串行路径。首先，听觉皮层处理简单的声学信息，例如声音的频率。然后，被称为颞上回(STG)的相邻区域提取对语音更重要的特征，如辅音和元音，将声音转化为有意义的单词。</p>
<p>但是，因为缺乏听觉皮层十分详细的神经生理学记录，所以对于这个猜想一直无法证实。来自旧金山加州大学圣保罗分校的神经科学家和神经外科医生Edward Chang和他的团队为了找到相关证据进行了一项研究。在七年时间里，他们研究了九名因为医疗原因接受脑部手术的参与者，使用小电极阵列覆盖整个听觉皮层，电极收集语言和癫痫映射的神经信号。参与者自愿对录音进行分析，以了解听觉皮层处理声音和语言的方式。</p>
<span id="more"></span>

<p>人类听觉皮层颞叶区域的解剖切片和电极覆盖</p>
<img src="/f4eccbfe/1.jpg" class>

<ul>
<li>(A)一例参与者左半球颞叶的感兴趣解剖区域。STG =颞上回，MTG =颞中回。</li>
<li>(B)所有9名参与者的解剖区域电极计数。</li>
<li>(C)仅发病模式和光谱时间模式之间的比较表明，一个种群仅由一个单一的发病特征描述。</li>
<li>(D)所有参与者的电极投射到蒙特利尔神经研究所(MNI)图谱脑(cvs_avg35_inMNI152)上。电极尺寸反映了我们分析中测试的编码模型所解释的最大方差(R2)。电极部位根据其解剖位置着色</li>
</ul>
<p>当为参与者播放短语或者句子的时候，研究人员发现，位于STG中的某些区域的反应速度与初级听觉皮层一样快，这表明两个区域同时开始处理声学信息。另外，研究人员使用小电流刺激了参与者的初级听觉皮层，参与者经历了刺激引起的听觉和幻觉，但是他们仍然能够清楚的听到和重复说的话。当STG受到刺激时，参与者说他们可以听到说话，但是无法辨认出内容。初级听觉皮层和STG收到刺激的结果不同，研究人员推测，传统的传统模型中的串行处理路径可能并不准确。</p>
<p>局部消融左脑汞柱而未损伤前脑汞柱对言语感知和语言理解无影响</p>
<img src="/f4eccbfe/2.png" class>

<p>磁共振(MR)图像显示手术消融的范围沿HG轴向，而对pSTG没有影响。图像以放射方向显示。</p>
<p>他们认为语言知觉依赖于一个皮层前馈序列转换的声音到语言表征。通过对整个人类听觉皮层的颅内记录、电皮层刺激和外科消融的研究，他们发现，跨区域的皮层处理不符合连续的层次组织。相反，反应潜伏期和感受场分析表明，初级和非初级听觉皮质的信息处理是平行和不同的。当初级听觉皮层的刺激引起幻听，但不扭曲或干扰语言知觉时，也观察到这种功能分离。刺激颞上回非初级皮质可观察到相反的效果。初级听觉皮层的消融并不影响语言知觉。这些结果建立了平行信息处理在人类听觉皮层的分布功能组织，并证明非初级听觉皮层在语音处理中具有重要的独立作用。</p>
<p>虽然目前对于听觉系统的了解尚不完全，但是当前研究的发现让我们对听觉系统的了解迈出了重要的一步，这将为医生提供新的治疗阅读障碍等难以识别语音的疾病提供新的思路。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.sciencedaily.com/releases/2021/08/210818130509.htm">https://www.sciencedaily.com/releases/2021/08/210818130509.htm</a><br><a href="https://www.cell.com/cell/fulltext/S0092-8674(21)00878-3">https://www.cell.com/cell/fulltext/S0092-8674(21)00878-3</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10339">https://www.scholat.com/teamwork/showPostMessage.html?id=10339</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-2021年过了大半了，脑机接口取得哪些进展？</title>
    <url>/ffae7f4c.html</url>
    <content><![CDATA[<p>2021年已经成为脑机接口(BCI)融资创纪录的一年。BCI将人类的脑电波转换成机器可以理解的指令，允许人们可以用他们的大脑来操作计算机。就在最近，埃隆·马斯克(Elon Musk)的BCI公司Neuralink宣布获得2.05亿美元的C轮融资，而几天前，另一家BCI公司Paradromics宣布获得2000万美元的种子轮融资。几乎在同一时间，Neuralink的竞争对手 Synchron宣布已获得FDA的突破性批准，可以对其旗舰产品 Stentrode 进行人类患者的临床试验。</p>
<img src="/ffae7f4c/1.jpg" class>

<span id="more"></span>

<p>然而，许多人对Neuralink 的进展以及 BCI 即将到来的说法持怀疑态度。我建议从不同的角度来理解另一个领域的突破如何使 BCI 的承诺比以前更加切实可行。为此我们要先明白BCI的核心在于扩展我们人类的能力或补偿失去的能力，例如对于瘫痪的人。这一领域的公司通过两种形式的BCI来实现这一目标—侵入式和非侵入式。在这两种情况下，大脑活动都被记录下来，以将神经信号转换成指令，如用机械臂移动物品、头脑打字或通过意念说话等。这些强大翻译背后的引擎是机器学习，它从大脑数据中识别模式，并能够在许多人类大脑中归纳这些模式。</p>
<hr>
<h3 id="模式识别与迁移学习"><a href="#模式识别与迁移学习" class="headerlink" title="模式识别与迁移学习"></a>模式识别与迁移学习</h3><p>早在几十年前就已经实现了将大脑活动转化为行动的能力。如今，私营企业面临的主要挑战是为大众打造商业产品，让它们能够在不同的大脑中找到共同的信号，并转化为类似的动作，比如表示“移动我的右臂”的脑电波模式。</p>
<p>想要实现这一点，可能微调才能做到。幸运的是，人工智能在模式识别方面的研究取得了巨大进步，特别是在视觉、音频和文本领域，产生了更强大的技术和架构，使人工智能应用程序能够泛化。</p>
<p>开创性的论文《Attentionis all you need》提出的“Transformer”架构激发了许多其他激动人心的论文。它于 2017 年底发布，带来了跨领域和模式的多项突破，例如谷歌的 ViT、DeepMind 的多模式感知器和 Facebook 的 wav2vec 2.0。每一个都在各自的基准测试中取得了最先进的结果。</p>
<p>基于Transformer模型的Encoder-Decoder模型示意图</p>
<img src="/ffae7f4c/2.jpg" class>

<p>Transformer 架构的一个关键特征是其零样本和少样本学习能力，这使得 AI 模型可以泛化。</p>
<hr>
<h3 id="丰富的数据"><a href="#丰富的数据" class="headerlink" title="丰富的数据"></a>丰富的数据</h3><p>最先进的深度学习模型，如上述Google、DeepMind 和 Facebook的模型，需要大量的数据。而在线数据是推动计算机生成的自然语言应用程序最近爆炸式增长的主要催化剂之一。当然，脑电图(EEG)数据不像维基百科(Wikipedia)页面那么容易获得，但这种情况正在发生改变。</p>
<p>世界各地的研究机构正在发布越来越多的BCI相关数据集，使研究人员可以在彼此的学习基础上进行研究。例如，多伦多大学的研究人员使用了天普大学医院脑电图语料库(TUEG)数据集，该数据集包含了超过10000人的临床记录。</p>
<p>研究实验室收集的数据是一个很好的开始，但在现实世界的应用中可能还不够。如果BCI要加速发展，我们需要看到人们可以在日常生活中使用的商业产品出现。随着OpenBCI这样的项目使人们可以买得起硬件，以及其他商业公司现在向公众推出他们的非侵入性产品，数据可能很快就会变得更容易获取。</p>
<hr>
<h3 id="硬件和边缘计算"><a href="#硬件和边缘计算" class="headerlink" title="硬件和边缘计算"></a>硬件和边缘计算</h3><p>BCI应用程序具有实时操作的限制，比如打字或玩游戏。如果从想法到行动的延迟超过1秒，那么用户体验就会变得难以接受，因为交互将会变得迟缓且不一致(比如:想想一款延迟1秒的第一人称射击游戏)。将原始EEG数据发送到远程推理服务器，然后将其解码为具体的动作，并将响应返回给BCI设备，就会引入这种延迟。</p>
<p>最近AI芯片的发展可以解决这些问题。像英伟达和谷歌这样的巨头都在打造更小、功能更强大的芯片，并在边缘进行了优化。这进而可以使BCI设备脱机运行，避免发送数据，消除与之相关的延迟问题。</p>
<hr>
<h3 id="最后的想法"><a href="#最后的想法" class="headerlink" title="最后的想法"></a>最后的想法</h3><p>几千年来，人类的大脑并没有太大的进化，而我们周围的世界在过去的十年里发生了巨大的变化。人类已经达到了一个转折点，它必须增强其大脑能力，以跟上我们周围的技术创新。</p>
<p>BCI仍处于起步阶段，有许多挑战需要解决，还有许多障碍需要克服。然而，对于一些人来说，这应该已经足够令人兴奋，可以放下一切并开始构建。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/dLJcXzbsIuz7BjvSUu3DmQ">https://mp.weixin.qq.com/s/dLJcXzbsIuz7BjvSUu3DmQ</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10344">https://www.scholat.com/teamwork/showPostMessage.html?id=10344</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>Android-ADB常用命令</title>
    <url>/da31a3cc.html</url>
    <content><![CDATA[<p>把文件推到Android系统中：<strong>adb pull 内部文件地址 外部目录</strong></p>
<p>把文件从系统中拖到电脑：<strong>adb push 目标文件 内部目录</strong></p>
<p>抓取Log：<strong>adb logcat &gt; log文件名称：logcat &gt; crash.log</strong></p>
<p>获取包名：<strong>adb shell → logcat | grep START</strong></p>
<span id="more"></span>

<p>应用安装：<strong>adb install apk全路径名称</strong></p>
<p>应用卸载：<strong>adb uninstall 包名</strong></p>
<p>启动应用：<strong>adb shell am start -n 包名</strong></p>
<p>发送广播：<strong>adb shell broadcast -a action</strong> 参数见文档</p>
<p>ADB截图：<strong>adb shell screencap -p /sdcard/screen.png</strong> → <strong>adb pull /sdcard/screen.png ./</strong></p>
<p>模拟按键：<strong>adb shell input keyevent 键码（keyCode）</strong></p>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-什么是ANR</title>
    <url>/7496070b.html</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>ANR的全称是Application Not Respond，意思就是程序未响应，类似于我们在windows上见到的程序未响应。</p>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>Android系统中，ActivityManagerService（简称AMS）和WindowManagerService（简称WMS）会检测App的响应时间，如果App在特定时间无法相应屏幕触摸或键盘输入时间，或者特定事件没有处理完毕，就会出现ANR。</p>
<p>无论是四大组件或者进程等只要发生ANR，最终都会调用AMS.appNotResponding()方法。</p>
<p>以下四个条件都可以造成ANR发生：</p>
<p><strong>InputDispatching Timeout</strong>：5秒内无法响应屏幕触摸事件或键盘输入事件。</p>
<p><strong>BroadcastQueue Timeout</strong>：在执行前台广播（BroadcastReceiver）的onReceive()函数时10秒没有处理完成，后台为60秒。</p>
<p><strong>Service Timeout</strong>：前台服务20秒内，后台服务在200秒内没有执行完毕。</p>
<p><strong>ContentProvider Timeout</strong>：ContentProvider的publish在10s内没进行完。</p>
<span id="more"></span>

<ol>
<li><p>只有主线程（UI线程）才会产生ANR</p>
</li>
<li><p>必须发生某些输入事件或特定操作，比如按键或触屏等输入事件，在BroadcastReceiver或Service的各个生命周期调用函数</p>
</li>
<li><p>上述事件响应超时，不同的context规定的上限时间不同</p>
</li>
</ol>
<h3 id="ANR的根本原因"><a href="#ANR的根本原因" class="headerlink" title="ANR的根本原因"></a>ANR的根本原因</h3><ol>
<li><p>耗时的网络访问</p>
</li>
<li><p>大量的数据读写</p>
</li>
<li><p>数据库操作</p>
</li>
<li><p>硬件操作（比如camera)</p>
</li>
<li><p>调用thread的join()方法、sleep()方法、wait()方法或者等待线程锁的时候</p>
</li>
<li><p>service binder的数量达到上限无法和和System Server通信</p>
</li>
<li><p>system server中发生WatchDog ANR</p>
</li>
<li><p>service忙导致超时无响应</p>
</li>
<li><p>其他线程持有锁，导致主线程等待超时</p>
</li>
<li><p>其它线程终止或崩溃导致主线程一直等待</p>
</li>
</ol>
<h3 id="避免ANR及ANR的解决办法"><a href="#避免ANR及ANR的解决办法" class="headerlink" title="避免ANR及ANR的解决办法"></a>避免ANR及ANR的解决办法</h3><ol>
<li><p>主线程阻塞或主线程数据读取</p>
<p> 避免死锁的出现；</p>
<p> 避免在主线程执行耗时操作，所有耗时操作应新开一个子线程完成，然后再在主线程更新UI；</p>
<p> 尽量避免在主线程query provider、不要滥用SharePreferences。</p>
</li>
<li><p>CPU满负荷，I/O阻塞</p>
<p> 文件读写或数据库操作放在子线程异步操作。</p>
</li>
<li><p>内存不足</p>
<p> AndroidManifest.xml文件&lt;applicatiion&gt;中可以设置 android:largeHeap=”true”，以此增大App使用内存（不过<strong>不建议使用此法</strong>，从根本上防止内存泄漏，优化内存使用才是正道）</p>
</li>
<li><p>各大组件ANR</p>
<p> 各大组件生命周期中也应避免耗时操作，注意BroadcastReciever的onRecieve()、后台Service和ContentProvider也不要执行太长时间的任务；</p>
<p> BroadcastReceiver要执行耗时操作时应启动一个service，将耗时操作交给service来完成；</p>
<p> 避免在Intent Receiver里启动一个Activity，因为它会创建一个新的画面，并从当前用户正在运行的程序上抢夺焦点。如果应用程序在响应Intent广播时需要向用户展示什么，应该使用Notification Manager来实现。</p>
</li>
</ol>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.jianshu.com/p/388166988cef">https://www.jianshu.com/p/388166988cef</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Java-面试基础内容</title>
    <url>/66c0bec6.html</url>
    <content><![CDATA[<h2 id="JAVA"><a href="#JAVA" class="headerlink" title="JAVA"></a>JAVA</h2><h3 id="⭐-java八种基本数据类型"><a href="#⭐-java八种基本数据类型" class="headerlink" title="⭐ java八种基本数据类型"></a>⭐ java八种基本数据类型</h3><p>byte、short、int、long、float、double、char、boolean</p>
<h3 id="⭐-string、stringBuilder、stringBuffer"><a href="#⭐-string、stringBuilder、stringBuffer" class="headerlink" title="⭐ string、stringBuilder、stringBuffer"></a>⭐ string、stringBuilder、stringBuffer</h3><p>final byte[]， byte[]， synchronized</p>
<img src="/66c0bec6/string.png" class>

<span id="more"></span>

<h3 id="⭐-四种引用的区别和作用"><a href="#⭐-四种引用的区别和作用" class="headerlink" title="⭐ 四种引用的区别和作用"></a>⭐ 四种引用的区别和作用</h3><p>强引用：最常见、即使当前内存空间不足，JVM也不会回收它，而是抛出 OutOfMemoryError 错误，使程序异常终止。如果想中断强引用和某个对象之间的关联，可以显式地将引用赋值为null，这样一来的话，JVM在合适的时间就会回收该对象。</p>
<p>软引用：如果内存的空间足够，软引用就能继续被使用，而不会被垃圾回收器回收；只有在内存空间不足时，软引用才会被垃圾回收器回收。</p>
<p>弱引用：拥有的生命周期更短暂。因为当 JVM 进行垃圾回收，一旦发现弱引用对象，无论当前内存空间是否充足，都会将弱引用回收。不过由于垃圾回收器是一个优先级较低的线程，所以并不一定能迅速发现弱引用对象。</p>
<p>虚引用：如果一个对象仅持有虚引用，那么它相当于没有引用，在任何时候都可能被垃圾回收器回收。虚引用必须和引用队列关联使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。</p>
<h3 id="⭐⭐-hashmap的数据结构"><a href="#⭐⭐-hashmap的数据结构" class="headerlink" title="⭐⭐ hashmap的数据结构"></a>⭐⭐ hashmap的数据结构</h3><p>数组+链表(6)/红黑树(8)，头插，hashcode模运算位运算，默认1&lt;&lt;4桶负载因子0.75扩容&lt;&lt;1</p>
<h3 id="⭐⭐-什么是可达性分析"><a href="#⭐⭐-什么是可达性分析" class="headerlink" title="⭐⭐ 什么是可达性分析"></a>⭐⭐ 什么是可达性分析</h3><p>GC，引用计数法和可达性分析，Root节点：栈引用、static、final、native</p>
<h3 id="⭐⭐-类加载机制"><a href="#⭐⭐-类加载机制" class="headerlink" title="⭐⭐ 类加载机制"></a>⭐⭐ 类加载机制</h3><ul>
<li><p>类加载的时机</p>
<ul>
<li>隐式加载 new 创建类的实例</li>
<li>显式加载：loaderClass,forName等</li>
<li>访问类的静态变量，或者为静态变量赋值</li>
<li>调用类的静态方法</li>
<li>使用反射方式创建某个类或者接口对象的Class对象。</li>
<li>初始化某个类的子类</li>
<li>直接使用java.exe命令来运行某个主类</li>
</ul>
</li>
<li><p>类加载的过程</p>
<ul>
<li>加载：ClassLoader通过一个类的完全限定名查找此类字节码文件，并利用字节码文件创建一个class对象。</li>
<li>验证：确保class文件的字节流中包含信息符合当前虚拟机要求，不会危害虚拟机自身的安全，主要包括四种验证：文件格式的验证，元数据的验证，字节码验证，符号引用验证。</li>
<li>准备：类变量（static修饰的字段变量）分配内存并且设置该类变量的初始值，（如static int i = 5 这里只是将 i 赋值为0，在初始化的阶段再把 i 赋值为5)，这里不包含final修饰的static ，因为final在编译的时候就已经分配了。这里不会为实例变量分配初始化，类变量会分配在方法区中，实例变量会随着对象分配到Java堆中。</li>
<li>解析：把常量池中的符号引用替换成直接引用</li>
<li>初始化：如果该类具有父类就进行对父类进行初始化，执行其静态初始化器（静态代码块）和静态初始化成员变量。（前面已经对static 初始化了默认值，这里我们对它进行赋值，成员变量也将被初始化）</li>
</ul>
<img src="/66c0bec6/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E8%BF%87%E7%A8%8B.png" class>
</li>
<li><p>双亲委派机制</p>
<ul>
<li>如果一个类收到了类加载的请求，它并不会自己先去加载，而是把这个请求委托给父类加载器去执行，如果父类加载器还存在父类加载器，则进一步向上委托，依次递归，请求最后到达顶层的启动类加载器，如果能够完成类的加载任务，就会成功返回，倘若父类加载器无法完成任务，子类加载器才会尝试自己去加载。</li>
</ul>
</li>
</ul>
<h3 id="⭐⭐-线程同步"><a href="#⭐⭐-线程同步" class="headerlink" title="⭐⭐ 线程同步"></a>⭐⭐ 线程同步</h3><p>java允许多线程并发控制，当多个线程同时操作一个可共享的资源变量时（如数据的增删改查），将会导致数据不准确，相互之间产生冲突。</p>
<ol>
<li><p>synchronized：java的每个对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。也可以修饰语句块会，从而实现同步。</p>
</li>
<li><p>volatile：使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新，同时防止指令重排</p>
</li>
<li><p>重入锁：ReentrantLock类是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。</p>
</li>
<li><p>局部变量：使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。</p>
</li>
<li><p>阻塞队列：前面5种同步方式都是在底层实现的线程同步，但是我们在实际开发当中，应当尽量远离底层结构。使用java.util.concurrent包LinkedBlockingQueue<E>来实现线程的同步，队列是先进先出的顺序（FIFO）。</E></p>
</li>
<li><p>原子变量：java.util.concurrent.atomic包提供了创建了原子类型变量的工具类。其中AtomicInteger可以用原子方式更新int的值，可用在应用程序中(如以原子方式增加的计数器)，但不能用于替换Integer；可扩展Number，允许那些处理基于数字类的工具和实用工具进行统一访问。</p>
</li>
</ol>
<h3 id="⭐⭐-线程中断"><a href="#⭐⭐-线程中断" class="headerlink" title="⭐⭐ 线程中断"></a>⭐⭐ 线程中断</h3><ol>
<li><p>interrupt()：仅设置中断标识位</p>
</li>
<li><p>isInterrupted()：只测试线程是否已经中断，中断标识位的状态并不受到该方法的影响</p>
</li>
<li><p>static interrupted()：测试当前线程是否已经中断，线程的中断标识位由该方法清除。interrupted()方法和isInterrupted()方法调用的是同一个native方法，无非这个方法传入的是true，表示清除中断标识位</p>
</li>
</ol>
<h3 id="⭐⭐⭐-设计一个可重入锁"><a href="#⭐⭐⭐-设计一个可重入锁" class="headerlink" title="⭐⭐⭐ 设计一个可重入锁"></a>⭐⭐⭐ 设计一个可重入锁</h3><p>主要关键是lock()和unlock()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyLock</span> <span class="keyword">implements</span> <span class="title">Lock</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> isLocked = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(isLocked) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                wait();</span><br><span class="line">            &#125;<span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        isLocked = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        isLocked = <span class="keyword">false</span>;</span><br><span class="line">        notifyAll();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h2><h3 id="⭐-TCP-IP模型几层"><a href="#⭐-TCP-IP模型几层" class="headerlink" title="⭐ TCP/IP模型几层"></a>⭐ TCP/IP模型几层</h3><img src="/66c0bec6/TCPIP.png" class>

<h3 id="⭐⭐-端口号位于哪一层？如果TCP和UDP访问同一个端口号会怎么样？"><a href="#⭐⭐-端口号位于哪一层？如果TCP和UDP访问同一个端口号会怎么样？" class="headerlink" title="⭐⭐ 端口号位于哪一层？如果TCP和UDP访问同一个端口号会怎么样？"></a>⭐⭐ 端口号位于哪一层？如果TCP和UDP访问同一个端口号会怎么样？</h3><p>传输层（TCP、UDP），可以，在ip报文里有个叫做协议的字段，指出了上层协议是TCP还是UDP还是其他P。</p>
<h3 id="⭐⭐-TCP如何保证其可靠"><a href="#⭐⭐-TCP如何保证其可靠" class="headerlink" title="⭐⭐ TCP如何保证其可靠"></a>⭐⭐ TCP如何保证其可靠</h3><p>校验和，确认应答+序列号，超时重传，三次握手四次挥手，流量控制（滑动窗口），拥塞控制（慢开始、拥塞避免、快重传、快恢复）</p>
<h3 id="⭐⭐-HTTP哪些操作是幂等的"><a href="#⭐⭐-HTTP哪些操作是幂等的" class="headerlink" title="⭐⭐ HTTP哪些操作是幂等的"></a>⭐⭐ HTTP哪些操作是幂等的</h3><p>http幂等操作：get/put/delete</p>
<p>http非幂等操作：post/patch</p>
<hr>
<h2 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h2><h3 id="⭐-什么是缺页中断"><a href="#⭐-什么是缺页中断" class="headerlink" title="⭐ 什么是缺页中断"></a>⭐ 什么是缺页中断</h3><p>缺页中断就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。</p>
<p>页面置换算法：先进先出置换算法（FIFO）、最近最久未使用算法（LRU）、最少使用置换算法（LFU）、最佳置换算法（OPT）……</p>
<h3 id="⭐-什么是虚拟内存"><a href="#⭐-什么是虚拟内存" class="headerlink" title="⭐ 什么是虚拟内存"></a>⭐ 什么是虚拟内存</h3><p>虚拟内存是一种计算机系统内存管理技术。它使得应用程序认为它拥有连续可用的内存，即一个连续完整的地址空间。而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。</p>
<p>电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致内存消耗殆尽。为了解决这个问题，WINDOWS运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用，这部分空间即称为虚拟内存。</p>
<h3 id="⭐-为什么要区分用户态和内核态"><a href="#⭐-为什么要区分用户态和内核态" class="headerlink" title="⭐ 为什么要区分用户态和内核态"></a>⭐ 为什么要区分用户态和内核态</h3><p>CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。</p>
<hr>
<h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><h3 id="⭐-什么是索引及索引的作用"><a href="#⭐-什么是索引及索引的作用" class="headerlink" title="⭐ 什么是索引及索引的作用"></a>⭐ 什么是索引及索引的作用</h3><p>索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构。</p>
<p>快速取数据；保证数据记录的唯一性；实现表与表之间的参照完整性；在使用order by、group by子句进行数据检索时，利用索引可以减少排序和分组的时间</p>
<h3 id="⭐-数据库事务ACID"><a href="#⭐-数据库事务ACID" class="headerlink" title="⭐ 数据库事务ACID"></a>⭐ 数据库事务ACID</h3><ol>
<li><p>原子性（Atomicity）：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。</p>
</li>
<li><p>一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。</p>
</li>
<li><p>隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。</p>
</li>
<li><p>持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p>
</li>
</ol>
<h3 id="⭐-数据库隔离级别"><a href="#⭐-数据库隔离级别" class="headerlink" title="⭐ 数据库隔离级别"></a>⭐ 数据库隔离级别</h3><table>
<thead>
<tr>
<th>事务的隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody><tr>
<td>读未提交(Read uncommitted)</td>
<td>✔</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td>读提交(Read committed–Sql Server , Oracle)</td>
<td>×</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td>重复读(Repeatable read–MySQL)</td>
<td>×</td>
<td>×</td>
<td>✔</td>
</tr>
<tr>
<td>序列化(Serializable)</td>
<td>×</td>
<td>×</td>
<td>×</td>
</tr>
</tbody></table>
<hr>
<h2 id="Android"><a href="#Android" class="headerlink" title="Android"></a>Android</h2><h3 id="⭐-怎么查看是否内存泄漏"><a href="#⭐-怎么查看是否内存泄漏" class="headerlink" title="⭐ 怎么查看是否内存泄漏"></a>⭐ 怎么查看是否内存泄漏</h3><p>Android Profiler、LeakCanary</p>
<h3 id="⭐-Activity启动模式"><a href="#⭐-Activity启动模式" class="headerlink" title="⭐ Activity启动模式"></a>⭐ Activity启动模式</h3><p>Standard、SingleTop、SingleTask、SingleInstance</p>
<p><a href="https://www.bilibili.com/video/BV1CA41177Se">https://www.bilibili.com/video/BV1CA41177Se</a></p>
<h3 id="⭐⭐-内存泄漏的原因及如何避免"><a href="#⭐⭐-内存泄漏的原因及如何避免" class="headerlink" title="⭐⭐ 内存泄漏的原因及如何避免"></a>⭐⭐ 内存泄漏的原因及如何避免</h3><p>以下情况需关注是否会内存泄漏：Static Activities、Static Views、Inner Classes、Anonymous Classes、Handler、Threads、TimerTask、Sensor Manager</p>
<p>一般内存泄漏：忘记释放分配的内存，例如cursor</p>
<p>逻辑内存泄漏：当应用不再需要这个对象或结束生命周期，仍未释放该对象的所有引用</p>
<p>在Android中，导致潜在内存泄漏的陷阱：</p>
<ol>
<li><p>全局进程的static变量，这个无视应用的状态，持有Activity的强引用</p>
</li>
<li><p>活在Activity生命周期外的线程，没有清空对Activity的强引用</p>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Java</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-ICCV 2021 多任务模型训练又有新的突破！</title>
    <url>/2a0dc116.html</url>
    <content><![CDATA[<p>近期，来自德国ZF（ZF Friedrichshafen AG）集团人工智能实验室的团队在ICCV2021上提出了一种用于多任务学习的新方法——MultiTask-CenterNet (MCN)。</p>
<p>具体信息如下：</p>
<img src="/2a0dc116/1.jpg" class>

<p>论文地址：<a href="https://arxiv.org/ftp/arxiv/papers/2108/2108.05060.pdf">https://arxiv.org/ftp/arxiv/papers/2108/2108.05060.pdf</a></p>
<span id="more"></span>

<p>多任务学习能大大节省时间，降低内存占用，提高运行效率，但是感知相关的多任务学习网络更适用于相互之间有密切关系的多任务对象，面对各种相互关系不够紧密的学习目标，作者用一个增强了anchor-free 的CenterNet方法同时训练多个不同类型的任务，如目标检测、语义分割及人体姿态估计等。如下图所示：</p>
<img src="/2a0dc116/2.png" class>

<p>研究表明，当和语义分割任务一起训练时，MCN在目标检测数据集MSCOCO（Microsoft COCO: Common Objects in Context）进行姿态估计训练比在单一模型上取得更好的效果。</p>
<img src="/2a0dc116/3.jpg" class>

<p>随后，Google Brain Team 也提出了一种单一通用模型——多任务自训练( multi-task self-training，MuST)模型，通过在不同数据集和任务上训练的多个相互独立的专业教师模型（如ImageNet分类模型）来训练一个多任务学生模型。</p>
<p>详细信息如下：</p>
<img src="/2a0dc116/4.jpg" class>

<p>论文地址：<a href="https://arxiv.org/pdf/2108.11353.pdf">https://arxiv.org/pdf/2108.11353.pdf</a></p>
<p>通过训练模型在多个任务上一起训练，可以学习泛化能力强的特征，增强模型的泛化能力，例如，在ImageNet上用分类任务训练的特征并不一定适用于COCO的实例分割任务，但是，从Object 365检测数据集学习的特征在很大程度上提高了COCO实例分割的性能。</p>
<p>然而，为同一图像数据集收集各种标注（如实例分割、关键点、图像标题）具有一定难度，并且使用标签标注图像耗时长，多任务学习能力受限。为解决这一问题，作者提出自训练的方法，使用伪标签来实现多任务特征学习。利用COCO或Object 365等数据集来训练教师模型，以在未标记的图像上生成伪标签。研究发现，一个只使用这些伪标签训练的学生模型保留了其专业教师模型的大部分迁移学习性能。因此，可以使用伪标签将特征从多个教师模型转移到单个学生模型来进行表示学习。</p>
<p>主要分为三步：</p>
<img src="/2a0dc116/5.jpg" class>

<ol>
<li>在标记的数据集上独立训练专业教师模型 。</li>
<li>专业教师模型被用来标记一个更大的未标记数据集，以创建一个多任务伪标签数据集。例如，这些教师可以在Object 365检测数据集中生成图像分类和深度估计的伪标签。</li>
<li>最后，用这些在不同数据集、任务上训练的教师模型的伪标签训练具有多任务学习的学生模型，此时，深度估计和图像分类任务可以同时进行。</li>
</ol>
<p>论文实验包括四种教师模型：分类、语义分割、目标检测和深度估计，提供各种训练参数和伪标签。</p>
<p>多任务学习的学生模型则是一个简单的基于ResNet和特征金字塔网络（FPN）的主干模型，如下图所示：</p>
<img src="/2a0dc116/6.jpg" class>

<p>本文的实验表明，这种简单的模型架构能够学习共享不同任务的特征，在迁移学习任务中，多任务的学生模型性能不比专业教师模型的性能差。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p>&lt;Ghiasi G, Zoph B, Cubuk E D, et al. Multi-Task Self-Training for Learning General Representations[J]. arXiv preprint arXiv:2108.11353, 2021.&gt;<br>&lt;Heuer F, Mantowsky S, Bukhari S S, et al. MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning using an Anchor Free Approach[J]. arXiv preprint arXiv:2108.05060, 2021. &gt;<br><a href="https://mp.weixin.qq.com/s/nhv1l9xBSaZceibIn5fhqw">https://mp.weixin.qq.com/s/nhv1l9xBSaZceibIn5fhqw</a><br><a href="https://zhuanlan.zhihu.com/p/405008318">https://zhuanlan.zhihu.com/p/405008318</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10379">https://www.scholat.com/teamwork/showPostMessage.html?id=10379</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>Android-RecyclerView-正确获取item位置</title>
    <url>/190959e8.html</url>
    <content><![CDATA[<h2 id="RecyclerView中正确获取item位置"><a href="#RecyclerView中正确获取item位置" class="headerlink" title="RecyclerView中正确获取item位置"></a>RecyclerView中正确获取item位置</h2><p>上次走读仕宝哥的Contact us代码，学到了一招ConcatAdapter，稍微查了学习一下做个总结：</p>
<p>使用RecyclerView时，总需要知道其ItemView的位置来实现各种需求：设置点击事件、滚动列表至指定的Item位置</p>
<p>为此RecyclerView提供给我们获取位置的API：</p>
<ol>
<li><p>onBindViewHolder(ViewHolder holder, int position)</p>
</li>
<li><p>getAdapterPosition</p>
</li>
<li><p>getBindingAdapterPosition</p>
</li>
<li><p>getAbsoluteAdapterPosition</p>
</li>
<li><p>getLayoutPosition</p>
</li>
</ol>
<span id="more"></span>

<h3 id="onBindViewHolder-中的-position-参数"><a href="#onBindViewHolder-中的-position-参数" class="headerlink" title="onBindViewHolder 中的 position 参数"></a>onBindViewHolder 中的 position 参数</h3><p>通常我们会在onBindViewHolder中通过postion参数绑定 data 和 View</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onBindViewHolder</span><span class="params">(<span class="meta">@NonNull</span> RecyclerView.ViewHolder holder, <span class="keyword">int</span> position)</span> </span>&#123;</span><br><span class="line">    ((InnerHolder) holder).setData(mGalleryData.get(position), position);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是如果在这里使用position参数来处理点击事件就会有点不合适了，比如这样子</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">itemView.setOnClickListener(<span class="keyword">new</span> View.OnClickListener() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mOnItemClickListener != <span class="keyword">null</span>) &#123;</span><br><span class="line">            mOnItemClickListener.onItemClick(mGalleryData.get(mPosition), mPosition);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>然后我们加入一个按钮，移除列表的第一个数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">removeFirstItem</span><span class="params">()</span></span>&#123;</span><br><span class="line">    list.removeAt(<span class="number">0</span>);</span><br><span class="line">    notifyItemRemoved(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这时候就会出现以下效果：</p>
<img src="/190959e8/1.gif" class>

<p>按照预期，应该是点击哪个位置，就弹出那个位置的position的toast，可是当我们调用removeFirstItem方法移除列表的第一个item后，就会出现 item 和 position 对不上号的情况（点击了postion：1弹出的toast显示点击了：2），<strong>这就是在onBindViewHolder中直接使用position参数设置点击事件可能引发的问题</strong>。</p>
<p>原因：使用notifyItem*()此类方法来删除/添加/更改RecyclerView的数据中的任何一条数据时，RecyclerView并不会调用所有Item的onBindViewHolder方法更新item的位置，它只会更新notifyItem*()的位置，所以导致了显示的数据和真实的数据 Position 对应不上的问题。</p>
<p>为此，源码注释给出了解释和解决方案：使用getAdapterPosition</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">*</span> Note that unlike &#123;@link android.widget.ListView&#125;, RecyclerView will not call this method</span><br><span class="line"><span class="bullet">*</span> again if the position of the item changes in the data set unless the item itself is</span><br><span class="line"><span class="bullet">*</span> invalidated or the new position cannot be determined. For this reason, you should only</span><br><span class="line"><span class="bullet">*</span> use the <span class="xml"><span class="tag">&lt;<span class="name">code</span>&gt;</span></span>position<span class="xml"><span class="tag">&lt;/<span class="name">code</span>&gt;</span></span> parameter while acquiring the related data item inside</span><br><span class="line"><span class="bullet">*</span> this method and should not keep a copy of it. If you need the position of an item later</span><br><span class="line"><span class="bullet">*</span> on (e.g. in a click listener), use &#123;@link ViewHolder#getBindingAdapterPosition()&#125; which</span><br><span class="line"><span class="bullet">*</span> will have the updated adapter position.</span><br></pre></td></tr></table></figure>

<h3 id="getAdapterPosition"><a href="#getAdapterPosition" class="headerlink" title="getAdapterPosition"></a>getAdapterPosition</h3><p>ViewHolder为我们提供了 getAdapterPosition 方法来获取 ViewHolder 的位置。该方法总是返回 ViewHolder 最新的位置，也就意味着使用该方法，即使调用notifyItem*()此类方法来删除/添加/更改 RecyclerView 的数据，该方法返回的位置也能确保获取的Position是正确的。</p>
<p>但getAdapterPosition()被废弃了，原因是在 Adapter 嵌套Adapter 的情况下会带来歧义，推荐使用 getBindingAdapterPosition 或者 getAbsoluteAdapterPosition 这两个方法。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">/<span class="strong">**</span></span><br><span class="line"><span class="strong"> <span class="emphasis">* @return &#123;@link #getBindingAdapterPosition()&#125;</span></span></span><br><span class="line"><span class="emphasis"><span class="strong"> *</span> @deprecated This method is confusing when adapters nest other adapters.</span></span><br><span class="line"><span class="strong"> <span class="emphasis">* If you are calling this in the context of an Adapter, you probably want to call</span></span></span><br><span class="line"><span class="emphasis"><span class="strong"> *</span> &#123;@link #getBindingAdapterPosition()&#125; or if you want the position as &#123;@link RecyclerView&#125;</span></span><br><span class="line"><span class="strong"> <span class="emphasis">* sees it, you should call &#123;@link #getAbsoluteAdapterPosition()&#125;.</span></span></span><br><span class="line"><span class="emphasis"><span class="strong"> *</span>/</span></span><br></pre></td></tr></table></figure>

<p>对于Android来说，复杂的Feed流页面，我们基本都是通过RecyclerView的多样式布局来实现，通过重写Adapter的getItemViewType来区分不同的样式，实现不同的UI逻辑，长久以来一直如此。</p>
<p>这种长久以来的写法，最大的问题就是将不同样式类型的布局耦合在了同一个Adapter中，随着业务的迭代，这个耦合的Adapter很有可能变得异常臃肿，而且这种写法要时刻注意数据的处理要区分ViewType，给日后的维护带来极大的挑战。</p>
<p>谷歌大概是看到了开发者面对这种复杂页面开发和维护时脸上的痛苦面具，所以他们推出了ConcatAdapter这个玩意，简单来说，它就像一个容器，里面可以添加多个Adapter，然后将ConcatAdapter设置为RecyclerView的Adapter，从而轻松实现多样式布局的效果。这就是谷歌官网所写的 Adapter 嵌套 Adapter情况：ConcatAdapter 里可能会包含了多个开发者写的Adapter。</p>
<p>这种情况下，我们如果继续调用getAdapterPosition就会引发歧义了，因为程序可能并不知道你想要的是ViewHolder的<strong>相对位置</strong>，还是<strong>绝对位置</strong>。</p>
<h3 id="相对位置与绝对位置，getBindindAdapterPosition-与-getAbsoluteAdapterPosition"><a href="#相对位置与绝对位置，getBindindAdapterPosition-与-getAbsoluteAdapterPosition" class="headerlink" title="相对位置与绝对位置，getBindindAdapterPosition 与 getAbsoluteAdapterPosition"></a>相对位置与绝对位置，getBindindAdapterPosition 与 getAbsoluteAdapterPosition</h3><img src="/190959e8/2.png" class>

<p>官方提供的两个方法getBindingAdapterPostion与getAbsoluteAdapterPosition就是用来获取ViewHolder的相对位置和绝对位置的。</p>
<p>getBindingAdapterPosition将会返回该ViewHolder相对于它绑定的Adapter中的位置，即相对位置。</p>
<p>getAbsoluteAdapterPosition将会返回该ViewHolder相对于RecyclerView的位置，即绝对位置。</p>
<p>回到开头提到的两种典型的RecyclerView中使用Position的场景：</p>
<p>设置点击事件 &amp; 记录，我们往往使用getBindingAdapterPostion获取ViewHolder对应的数据项，完成点击操作。</p>
<p>操作RecyclerView的滚动状态，我们应该使用getAbsoluteAdapterPosition来操纵RecyclerView的滚动。</p>
<p>不过，如果项目完全没有使用ConcatAdapter，那getBindingAdapterPostion和getAbsoluteAdapterPosition没有任何区别，不过仍推荐按照不同的使用场景选用不同的方法获取适合的位置参数，毕竟以后使用ConcatAdapter 就方便很多了。</p>
<h3 id="getLayoutPosition"><a href="#getLayoutPosition" class="headerlink" title="getLayoutPosition"></a>getLayoutPosition</h3><p>顾名思义，就是获取该ViewHolder在实际布局中的位置。</p>
<p>RecyclerView使用LayoutManager来管理数据集的现实。当开发者调用notifyData*()等方法通知RecyclerView刷新UI时，出于性能的考虑，RecyclerView的UI并不会立刻刷新，和Data保持一致，而是通过LayoutManager惰性更新相关布局——这个过程伴随着时间上的等待，通常情况下，这个等待时间小于16ms。所以，从感官上讲，getLayoutPosition与getAbsoluteAdapterPosition十分相似：getAbsoluteAdapterPosition返回的是该ViewHolder相对于RecyclerView的绝对位置，而getLayoutPosition返回的是该ViewHolder相对于RecyclerView实际布局的绝对位置。</p>
<p>简单来说，就是adapter和layout的位置会有时间差(通常情况下&lt;16ms), 如果你改变了Adapter的数据然后刷新视图, layout需要过一段时间才会更新视图, 在这段时间里面, 这两个方法返回的position会不一样，即在notifyDataSetChanged之后并不能马上获取Adapter中的position，要等布局结束之后才能获取到。</p>
<p>对于Layout的position，在notifyItemInserted之后，Layout不能马上获取到新的position，因为布局还没更新（需要&lt;16ms的时间刷新视图），所以只能获取到旧的，但是Adapter中的position就可以马上获取到最新的position。</p>
<p>所以，对于上面的点击事件的场景，我们在获取用户点击位置的时候，使用getLayoutPosition可能效果更好，这样就能确保用户点击的始终是他看到的那个数据（消除16ms带来的时间差问题）</p>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-音频开发-（一）音频原理</title>
    <url>/77a0fd2b.html</url>
    <content><![CDATA[<h3 id="采样率（samplerate）"><a href="#采样率（samplerate）" class="headerlink" title="采样率（samplerate）"></a>采样率（samplerate）</h3><p><strong>采样</strong>就是把<strong>模拟信号数字化</strong>的过程，<strong>采样频率越高</strong>，记录这一段音频信号所用的<strong>数据量</strong>就<strong>越大</strong>，同时<strong>音频质量</strong>也就<strong>越高</strong>。</p>
<p>数字图像处理课程中，根据奈奎斯特理论，<strong>采样频率</strong>只要<strong>不低于</strong>音频信号<strong>最高频率的两倍</strong>，就可以<strong>无损失地还原</strong>原始的声音。</p>
<p>通常人耳能听到频率范围大约在<strong>20Hz～20kHz</strong>之间的声音，为了保证声音不失真，采样频率<strong>应在40kHz以上</strong>。常用的音频采样频率有：8kHz、11.025kHz、22.05kHz、16kHz、37.8kHz、<strong>44.1kHz</strong>、<strong>48kHz</strong>、96kHz、192kHz等。</p>
<span id="more"></span>

<img src="/77a0fd2b/1.gif" class>

<hr>
<h3 id="比特率（bit-per-second）"><a href="#比特率（bit-per-second）" class="headerlink" title="比特率（bit per second）"></a>比特率（bit per second）</h3><p>表示经过编码（压缩）后的音频数据每秒钟需要用多少个比特来表示，单位常为kbps。</p>
<hr>
<h3 id="量化精度（位宽）"><a href="#量化精度（位宽）" class="headerlink" title="量化精度（位宽）"></a>量化精度（位宽）</h3><p>每一个采样点，都需要用一个数值来表示大小，这个数值的数据类型大小可以是：4bit、8bit、16bit、24bit、32bit等等，位数越多，表示得就越精细，声音质量自然就越好，数据量也会成倍增大。</p>
<p>常见的位宽是：8bit 、 <strong>16bit</strong>（一般测量量化精度，<strong>90dB</strong>动态范围，常见配合<strong>44.1kHz或48kHz</strong>，CD）、<strong>24bit</strong>（精密测量量化精度，<strong>144dB</strong>动态范围，常见配合<strong>48kHz或192kHz</strong>，DVD或蓝光）</p>
<hr>
<h3 id="声道数（channels）"><a href="#声道数（channels）" class="headerlink" title="声道数（channels）"></a>声道数（channels）</h3><p>音频的采集和播放是可以叠加的，因此可以同时从多个音频源采集声音，并分别输出到不同的扬声器，故声道数一般表示声音录制时的音源数量或回放时相应的扬声器数量。</p>
<p>常见：<strong>单声道</strong>（Mono）、<strong>双声道</strong>（Stereo）、<strong>2.1声道</strong>（在双声道基础上加入一个低音声道）、<strong>5.1声道</strong>（正面、左前、右前、左环绕、右环绕、低音，最早应用于早期的电影院）、<strong>7.1声道</strong>（在5.1声道的基础上，把左右环绕拆分为左右环绕以及左右后置，主要应用于BD以及现代的电影院）</p>
<hr>
<h3 id="音频帧（frame）"><a href="#音频帧（frame）" class="headerlink" title="音频帧（frame）"></a>音频帧（frame）</h3><p>视频每一帧就是一张图像，而<strong>音频数据是流式的</strong>，本身没有明确的一帧帧的概念。在实际的应用中，为了音频算法处理/传输的方便，一般约定俗成<strong>取2.5ms~60ms为单位的数据量为一帧音频</strong>，这个时间被称之为“<strong>采样时间</strong>”。</p>
<p>假设某通道的音频信号是采样率为8kHz，位宽为16bit，20ms一帧，双通道，则一帧音频数据的大小为：int size = 8000 x 16bit x 0.02s x 2 = 5120 bit = 640 byte</p>
<hr>
<h3 id="音频编码"><a href="#音频编码" class="headerlink" title="音频编码"></a>音频编码</h3><p>模拟的音频信号转换为数字信号需要经过采样和量化，量化的过程被称之为编码，根据不同的量化策略，产生了许多不同的编码方式，常见的编码方式有：<strong>波形编码</strong>（PCM等）、<strong>参数编码</strong>（LPC）、<strong>混合编码</strong>。</p>
<table>
<thead>
<tr>
<th>编码技术</th>
<th>算法</th>
<th>编码标准</th>
<th>码率（kbps）</th>
<th>应用领域</th>
</tr>
</thead>
<tbody><tr>
<td>波形编码</td>
<td>PCM</td>
<td>G.711</td>
<td>64</td>
<td>PSTN、ISDN</td>
</tr>
<tr>
<td></td>
<td>ADPCM</td>
<td>G.721</td>
<td>32</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>SB-ADPCM</td>
<td>G.721</td>
<td>64/56/48</td>
<td>-</td>
</tr>
<tr>
<td>参数编码</td>
<td>LPC</td>
<td>-</td>
<td>2.4</td>
<td>保密语音</td>
</tr>
<tr>
<td>混合编码</td>
<td>CELPC</td>
<td>-</td>
<td>4.8</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>VSELPC</td>
<td>GIA</td>
<td>8</td>
<td>移动通信、语音信箱</td>
</tr>
<tr>
<td></td>
<td>RPE-LTP</td>
<td>GSM</td>
<td>13.2</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>LD-CELP</td>
<td>G.728</td>
<td>16</td>
<td>ISDN</td>
</tr>
<tr>
<td></td>
<td>MPE</td>
<td>MPE</td>
<td>128</td>
<td>CD</td>
</tr>
</tbody></table>
<hr>
<h3 id="音频压缩"><a href="#音频压缩" class="headerlink" title="音频压缩"></a>音频压缩</h3><p>音频压缩技术指的是<strong>对原始数字音频信号流（PCM编码）</strong>运用适当的数字信号处理技术，在不损失有用信息量，或所引入损失可忽略的条件下，<strong>降低（压缩）其码率</strong>，也称为压缩编码。</p>
<p>音频数据压缩最基本的原理：因为<strong>有冗余信息</strong>，所以可以压缩。</p>
<ol>
<li><p>频谱掩蔽效应：人耳所能察觉的声音信号的频率范围为<strong>20Hz～20KHz</strong>，在这个<strong>频率范围以外</strong>的音频信号属于<strong>冗余信号</strong>。</p>
</li>
<li><p>时域掩蔽效应：当强音信号和弱音信号同时出现时，弱信号会听不到，因此，<strong>弱音信号</strong>也属于<strong>冗余信号</strong>。</p>
</li>
</ol>
<p>个人理解：</p>
<p>压缩比：aac &gt; ogg &gt; mp3(wma) &gt; ape &gt; flac &gt; wav （128kbps WMA = 192kbps MP3）</p>
<p>音质：wav = flac = ape &gt; aac &gt; ogg &gt; mp3 &gt; wma</p>
<p>综合：aac &gt; ogg &gt; flac &gt; ape &gt; mp3 &gt; wav = wma</p>
<p>128kbps以下选AAC，128~192kbps选WMA，192kbps以上选MP3。</p>
<table>
<thead>
<tr>
<th>压缩方式</th>
<th>压缩格式</th>
<th>最高比特率</th>
<th>压缩率</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>有损压缩</td>
<td>AAC</td>
<td>448kbps</td>
<td>1:18</td>
<td>在高比特率下音质仅次于MPC，在高比特率和低比特率下表象都很不错，目前最好的有损格式之一，编码速度慢。有多种编码，faac，nero为常见，比特率最高448kbps。硬件支持方面，高级mp3和现在手机普遍支持。</td>
</tr>
<tr>
<td></td>
<td>MPC</td>
<td>-</td>
<td>-</td>
<td>低比特率下表现一般，不及Mp3Pro编码的MP3和OGG，高比特率下音质最好，编码速度快。</td>
</tr>
<tr>
<td></td>
<td>OGG</td>
<td>500kbps</td>
<td>1:15</td>
<td>低比特率下音质最好，支持多声道，编码速度稍慢。完全免费、开放和没有专利限制。目前最好的有损格式之一，手机装软件部分可以支持。</td>
</tr>
<tr>
<td></td>
<td>MP3</td>
<td>320kbps</td>
<td>1:10~12</td>
<td>分为：固定码率（CBR）、平均码率（ABR）和动态码率（VBR）。在低比特率下音质次于OGG，高频部分一刀切是它的缺点。</td>
</tr>
<tr>
<td></td>
<td>MP3pro</td>
<td>-</td>
<td>1:18~20</td>
<td>保持相同的音质下同样可以把声音文件的文件量压缩到原有MP3格式的一半大小。扩展名仍旧是.mp3，向前向后兼容，但专利费太高导致没有流行。</td>
</tr>
<tr>
<td></td>
<td>WMA</td>
<td>192kbps</td>
<td>1:18</td>
<td>微软力推，减少数据流量但保持音质，可以通过DRM方案加入防止拷贝，或者加入限制播放时间和播放次数，甚至是播放机器的限制，可有力地防止盗版。128kbps为wma最优压缩比，小于128kbps时比mp3好。</td>
</tr>
<tr>
<td></td>
<td>VQF</td>
<td>-</td>
<td>1:18</td>
<td>YAMAHA和NTT共同开发的一种音频压缩技术，减少数据流量但保持音质，相同情况下压缩后VQF的文件体积比MP3小30%～50%，音质极佳，接近CD音质（16位44.1kHz立体声）。但VQF未公开技术标准，宣传不力，这种格式难有用武之地，未能流行。</td>
</tr>
<tr>
<td></td>
<td>ASF</td>
<td>-</td>
<td>-</td>
<td>高级串流格式，Microsoft 为 Windows 98 所开发的串流多媒体文件格式。特别适合在IP网上传输。</td>
</tr>
<tr>
<td></td>
<td>AIF/AIFF</td>
<td>-</td>
<td>-</td>
<td>苹果公司开发的一种声音文件格式，和WAV非常相像，支持MAC平台，支持16位44.1kHz立体声。</td>
</tr>
<tr>
<td></td>
<td>AU</td>
<td>-</td>
<td>-</td>
<td>SUN为UNIX系统开发的AU压缩声音文件格式，和WAV非常相像，只支持8位的声音，是互连网上常用到的声音文件格式，多由SUN工作站创建。</td>
</tr>
<tr>
<td>无损压缩</td>
<td>FLAC</td>
<td>约1000kbps</td>
<td>约58.70%</td>
<td>编码速度快，压缩率在四个中最差，平台支持很好，兼容性好。解码速度快，只需进行整数运算即可完成整个解码过程，对CPU的运算能力要求很低，所以普通的随身听，都可以轻松实现实时解码。</td>
</tr>
<tr>
<td></td>
<td>PAC</td>
<td>-</td>
<td>-</td>
<td>稍慢的编码速度，压缩率排第三，平台支持良好。</td>
</tr>
<tr>
<td></td>
<td>APE</td>
<td>约1000kbps</td>
<td>约55.50%</td>
<td>编码速度最快、最好的压缩率，平台支持一般。版权专用格式。</td>
</tr>
<tr>
<td></td>
<td>WAV</td>
<td>-</td>
<td>-</td>
<td>编码速度很快快，压缩率在四个中排第二，仅支持Windows平台。WAV格式是以RIFF格式为标准的，采用44.1kHz的采样频率，16位量化位数，因此WAV的音质与CD相差无几，体积非常大。</td>
</tr>
<tr>
<td></td>
<td>CDA</td>
<td>1411.2kbps</td>
<td>-</td>
<td>CD音轨文件。标准CD格式为44.1K的采样，速率88K/秒，16位量化位数，可以说是近似无损的。</td>
</tr>
</tbody></table>
<hr>
<h3 id="Android支持的音频格式和版本"><a href="#Android支持的音频格式和版本" class="headerlink" title="Android支持的音频格式和版本"></a>Android支持的音频格式和版本</h3><table>
<thead>
<tr>
<th>格式/编解码器</th>
<th>编码器</th>
<th>解码器</th>
<th>详细信息</th>
<th>支持的文件类型/容器格式</th>
</tr>
</thead>
<tbody><tr>
<td>AAC LC</td>
<td>-</td>
<td>-</td>
<td>支持单声道/立体声/5.0/5.1 内容，标准采样率为 8-48 kHz。</td>
<td>• 3GPP (.3gp) • MPEG-4（.mp4、.m4a） • ADTS 原始 AAC（.aac、在 Android 3.1 及更高版本中解码、在 Android 4.0 及更高版本中编码、不支持 ADIF） • MPEG-TS（.ts、不可查找、Android 3.0 及更高版本）</td>
</tr>
<tr>
<td>HE-AACv1 (AAC+)</td>
<td>Android 4.1 及更高版本</td>
<td>-</td>
<td></td>
<td></td>
</tr>
<tr>
<td>HE-AACv2（增强型 AAC+）</td>
<td>-</td>
<td>-</td>
<td>支持立体声/5.0/5.1 内容，标准采样率为 8-48 kHz。</td>
<td></td>
</tr>
<tr>
<td>AAC ELD（增强型低延迟 AAC）</td>
<td>Android 4.1 及更高版本</td>
<td>Android 4.1 及更高版本</td>
<td>支持单声道/立体声内容，标准采样率为 16-48 kHz</td>
<td></td>
</tr>
<tr>
<td>AMR-NB</td>
<td>-</td>
<td>-</td>
<td>4.75-12.2 kbps，采样率为 8 kHz</td>
<td>3GPP (.3gp)</td>
</tr>
<tr>
<td>AMR-WB</td>
<td>-</td>
<td>-</td>
<td>有 9 个比特率（介于 6.60-23.85 kbit/s 之间）可供选择，采样率为 16 kHz</td>
<td>3GPP (.3gp)</td>
</tr>
<tr>
<td>FLAC</td>
<td>Android 4.1 及更高版本</td>
<td>Android 3.1 及更高版本</td>
<td>单声道/立体声（非多声道）。采样率最高可达 48 kHz（但对于输出为 44.1 kHz 的设备，则建议最高不超过 44.1 kHz，因为 48-44.1 kHz 的降采样器不包含低通滤波器）。建议使用 16 位；对于 24 位，不会应用任何抖动。</td>
<td>仅支持 FLAC (.flac)</td>
</tr>
<tr>
<td>GSM</td>
<td>-</td>
<td>-</td>
<td>Android 支持在电话设备上进行 GSM 解码</td>
<td>GSM (.gsm)</td>
</tr>
<tr>
<td>MIDI</td>
<td>-</td>
<td>-</td>
<td>MIDI 类型 0 和 1。DLS 版本 1 和 2。XMF 和 Mobile XMF。支持铃声格式 RTTTL/RTX、OTA 和 iMelody</td>
<td>• 类型 0 和 1（.mid、.xmf、.mxmf） • RTTTL/RTX（.rtttl、.rtx） • OTA (.ota) • iMelody (.imy)</td>
</tr>
<tr>
<td>MP3</td>
<td>-</td>
<td>-</td>
<td>单声道/立体声 8-320 Kbps 恒定 (CBR) 或可变比特率 (VBR)</td>
<td>MP3 (.mp3)</td>
</tr>
<tr>
<td>Opus</td>
<td>-</td>
<td>Android 5.0 及更高版本</td>
<td>-</td>
<td>Matroska (.mkv)</td>
</tr>
<tr>
<td>PCM/WAVE</td>
<td>Android 4.1 及更高版本</td>
<td>-</td>
<td>8 位和 16 位线性 PCM（比特率最高可达到硬件上限）。以 8000、16000 和 44100 Hz 录制原始 PCM 所需的采样率。</td>
<td>WAVE (.wav)</td>
</tr>
<tr>
<td>Vorbis</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>• Ogg (.ogg) • Matroska（.mkv、Android 4.0 及更高版本）</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-音频开发-（二）音频录制</title>
    <url>/2ac4e08d.html</url>
    <content><![CDATA[<h3 id="AudioRecord（基于字节流录音）"><a href="#AudioRecord（基于字节流录音）" class="headerlink" title="AudioRecord（基于字节流录音）"></a>AudioRecord（基于字节流录音）</h3><p>优点：可以实现语音的实时处理，进行边录边播，对音频的实时处理。</p>
<p>缺点：输出的是PCM的语音数据，如果保存成音频文件是不能被播放器播放的。要用到AudioTrack这个去进行处理。</p>
<span id="more"></span>

<h4 id="实现-AudioRecord-录音的流程"><a href="#实现-AudioRecord-录音的流程" class="headerlink" title="实现 AudioRecord 录音的流程"></a>实现 AudioRecord 录音的流程</h4><ol>
<li><p>构造一个 AudioRecord 对象，其中最小录音缓存 buffer 大小可以通过 getMinBufferSize 方法得到。如果 buffer 容量过小，将导致对象构造的失败。</p>
</li>
<li><p>初始化一个 buffer，该 buffer 大于等于 AudioRecord 对象用于写声音数据的 buffer 大小。</p>
</li>
<li><p>开始录音</p>
</li>
<li><p>创建一个数据流，一边从 AudioRecord 中读取声音数据到初始化的 buffer，一边将 buffer 中数据导入数据流。</p>
</li>
<li><p>关闭数据流</p>
</li>
<li><p>停止录音</p>
</li>
<li><p>释放对象</p>
</li>
</ol>
<h4 id="构造-AudioRecord-对象需要的参数"><a href="#构造-AudioRecord-对象需要的参数" class="headerlink" title="构造 AudioRecord 对象需要的参数"></a>构造 AudioRecord 对象需要的参数</h4><ol>
<li><p>音频源：一般可以使用麦克风作为采集音频的数据源。</p>
</li>
<li><p>采样率：一秒内对声音数据的采样次数，采样率越高，音质越好。</p>
</li>
<li><p>通道：单声道，双声道等。</p>
</li>
<li><p>音频格式：一般选用 PCM 格式，即原始的音频样本。</p>
</li>
<li><p>缓冲区大小：音频数据写入缓冲区的总数，通过 AudioRecord.getMinBufferSize 获取最小的缓冲区。</p>
</li>
</ol>
<p>（最后生成的音频文件是 PCM 格式的，也就是最原始的音频数据，它没有头信息，不能直接播放，必须转换成可识别的格式才行。若转成 WAV 格式，在文件的数据开头加入 WAVE HEAD。）</p>
<h4 id="AudioRecord例子：录制音频"><a href="#AudioRecord例子：录制音频" class="headerlink" title="AudioRecord例子：录制音频"></a>AudioRecord例子：录制音频</h4><p>录音JNI函数不具有线程安全性，因此用单线程，以及设置缓存大小</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mExecutorService = Executors.newSingleThreadExecutor();</span><br><span class="line">mHandler = <span class="keyword">new</span> Handler(Looper.getMainLooper());</span><br><span class="line">mAudioRecordTest = <span class="keyword">new</span> AudioRecordTest.Builder(<span class="keyword">this</span>)</span><br><span class="line">        .setExecutorService(mExecutorService)</span><br><span class="line">        .setHandler(mHandler)</span><br><span class="line">        .setBtStreamRecorder(mBtStreamRecorder)</span><br><span class="line">        .setBufferSize(BUFFER_SIZE)</span><br><span class="line">        .build();</span><br></pre></td></tr></table></figure>

<p>点击button进行录音，再次点击停止录音功能recorderAudio()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">recordAudio</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (mIsRecording) &#123;</span><br><span class="line">        mIsRecording = <span class="keyword">false</span>;</span><br><span class="line">        mBtStreamRecorder.setText(<span class="string">&quot;开始录音&quot;</span>);</span><br><span class="line">        <span class="comment">// 在开始录音中如果这个值没有变false，则一直进行，当再次点击变false时，录音才停止</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        mIsRecording = <span class="keyword">true</span>;</span><br><span class="line">        mBtStreamRecorder.setText(<span class="string">&quot;停止录音&quot;</span>);</span><br><span class="line">        <span class="comment">// 提交后台任务，执行录音逻辑</span></span><br><span class="line">        mExecutorService.submit(<span class="keyword">this</span>::startRecord);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>开始录音startRecorder()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startRecord</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!doStartRecord()) &#123;</span><br><span class="line">        recordFail();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>AudioRecord的配置及录音功能实现doStartRecord()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">doStartRecord</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 记录开始录音时间</span></span><br><span class="line">        startRecorderTime = System.currentTimeMillis();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 创建录音文件</span></span><br><span class="line">        <span class="keyword">if</span> (android.os.Build.VERSION.SDK_INT &gt;= android.os.Build.VERSION_CODES.KITKAT) &#123;</span><br><span class="line">            mAudioRecordFile = <span class="keyword">new</span> File(mContext.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS) +</span><br><span class="line">                    <span class="string">&quot;/AudioRecordDemo/&quot;</span> + startRecorderTime + <span class="string">&quot;.pcm&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (!mAudioRecordFile.getParentFile().exists()) &#123;</span><br><span class="line">                mAudioRecordFile.getParentFile().mkdirs();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        mAudioRecordFile.createNewFile();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 创建文件输出流</span></span><br><span class="line">        FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(mAudioRecordFile);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 配置AudioRecord</span></span><br><span class="line">        <span class="keyword">int</span> audioSource = MediaRecorder.AudioSource.MIC;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 所有android系统都支持</span></span><br><span class="line">        <span class="keyword">int</span> sampleRate = <span class="number">44100</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 单声道输入</span></span><br><span class="line">        <span class="keyword">int</span> channelConfig = AudioFormat.CHANNEL_IN_MONO;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// PCM_16是所有android系统都支持的</span></span><br><span class="line">        <span class="keyword">int</span> audioFormat = AudioFormat.ENCODING_PCM_16BIT;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 计算AudioRecord内部buffer最小</span></span><br><span class="line">        <span class="keyword">int</span> minBufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// buffer不能小于最低要求，也不能小于我们每次我们读取的大小。</span></span><br><span class="line">        mAudioRecord = <span class="keyword">new</span> AudioRecord(audioSource, sampleRate, channelConfig,</span><br><span class="line">                audioFormat, Math.max(minBufferSize, BUFFER_SIZE));</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 开始录音</span></span><br><span class="line">        mAudioRecord.startRecording();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 循环读取数据，写入输出流中</span></span><br><span class="line">        <span class="keyword">while</span> (mIsRecording) &#123;</span><br><span class="line">            <span class="comment">// 只要还在录音就一直读取</span></span><br><span class="line">            <span class="keyword">int</span> read = mAudioRecord.read(mBuffer, <span class="number">0</span>, BUFFER_SIZE);</span><br><span class="line">            <span class="keyword">if</span> (read &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                fos.write(mBuffer, <span class="number">0</span>, read);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 退出循环，停止录音，释放资源</span></span><br><span class="line">        stopRecord();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (mAudioRecord != <span class="keyword">null</span>) &#123;</span><br><span class="line">            mAudioRecord.stop();</span><br><span class="line">            mAudioRecord.release();</span><br><span class="line">            mAudioRecord = <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>停止录音stopRecorder()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">stopRecord</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    mIsRecording = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (!doStopRecord()) &#123;</span><br><span class="line">        recordFail();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再次点击停止录音doStopRecord()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">doStopRecord</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 停止录音，关闭文件输出流</span></span><br><span class="line">    mAudioRecord.stop();</span><br><span class="line">    mAudioRecord.release();</span><br><span class="line">    mAudioRecord = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 记录结束时间，统计录音时长</span></span><br><span class="line">    <span class="keyword">long</span> stopRecorderTime = System.currentTimeMillis();</span><br><span class="line">    <span class="comment">// 大于3秒算成功，在主线程更新UI</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> second = (<span class="keyword">int</span>) (stopRecorderTime - startRecorderTime) / <span class="number">1000</span>;</span><br><span class="line">    <span class="keyword">if</span> (second &gt; <span class="number">3</span>) &#123;</span><br><span class="line">        mHandler.post(() -&gt; &#123;</span><br><span class="line">            Toast.makeText(mContext,</span><br><span class="line">                    <span class="string">&quot;录音成功：&quot;</span> + second + <span class="string">&quot;秒&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;save in &quot;</span> + startRecorderTime + <span class="string">&quot;.pcm&quot;</span>);</span><br><span class="line">            mBtStreamRecorder.setText(<span class="string">&quot;开始录音&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        recordFail();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>录取失败，更新UI操作recorderFail()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">recordFail</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    mHandler.post(() -&gt; &#123;</span><br><span class="line">        Toast.makeText(mContext,</span><br><span class="line">                <span class="string">&quot;录制失败，录音请大于3秒！&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">        mBtStreamRecorder.setText(<span class="string">&quot;开始录音&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (android.os.Build.VERSION.SDK_INT &gt;= android.os.Build.VERSION_CODES.KITKAT) &#123;</span><br><span class="line">            File audioRecordFile = <span class="keyword">new</span> File(mContext.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS) +</span><br><span class="line">                    <span class="string">&quot;/AudioRecordDemo/&quot;</span> + startRecorderTime + <span class="string">&quot;.pcm&quot;</span>);</span><br><span class="line">            audioRecordFile.delete();</span><br><span class="line">        &#125;</span><br><span class="line">        mIsRecording = <span class="keyword">false</span>;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>onDestroy()防止内存泄漏</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">    <span class="keyword">if</span> (mAudioRecordTest.getAudioRecord() != <span class="keyword">null</span>) &#123;</span><br><span class="line">        mAudioRecordTest.getAudioRecord().stop();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mExecutorService != <span class="keyword">null</span>) &#123;</span><br><span class="line">        mExecutorService.shutdownNow();</span><br><span class="line">        mExecutorService = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="MediaRecorder（基于文件录音）"><a href="#MediaRecorder（基于文件录音）" class="headerlink" title="MediaRecorder（基于文件录音）"></a>MediaRecorder（基于文件录音）</h3><p>已集成了录音，编码，压缩等，支持少量的音频格式文件。</p>
<p>优点：封装度很高，操作简单</p>
<p>缺点：无法实现实时处理音频，输出的音频格式少。</p>
<img src="/2ac4e08d/1.jpg" class>

<h4 id="MediaRecorder-类进行音频录制的基本步骤"><a href="#MediaRecorder-类进行音频录制的基本步骤" class="headerlink" title="MediaRecorder 类进行音频录制的基本步骤"></a>MediaRecorder 类进行音频录制的基本步骤</h4><ol>
<li><p>建立 MediaRecorder 类的对象：new MediaRecorder()</p>
</li>
<li><p>设置音频来源：mMediaRecorder.setAudioSource()</p>
</li>
<li><p>设置音频编码方式：mMediaRecorder.setAudioEncoder()</p>
</li>
<li><p>设置音频文件的保存位置及文件名：mMediaRecorder.setOutputFile()</p>
</li>
<li><p>将录音器置于准备状态：mMediaRecorder.prepare()</p>
</li>
<li><p>启动录音器：mMediaRecorder.start()</p>
</li>
<li><p>音频录制完成，停止录音器：mMediaRecorder.stop()</p>
</li>
<li><p>释放录音器对象：mMediaRecorder.release()</p>
</li>
</ol>
<h4 id="MediaRecorder例子：录制音频"><a href="#MediaRecorder例子：录制音频" class="headerlink" title="MediaRecorder例子：录制音频"></a>MediaRecorder例子：录制音频</h4><p>录音JNI函数不具有线程安全性，因此用单线程</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mExecutorService = Executors.newSingleThreadExecutor();</span><br><span class="line">mHandler = <span class="keyword">new</span> Handler(Looper.getMainLooper());</span><br><span class="line">mMediaRecorderTest = <span class="keyword">new</span> MediaRecorderTest.Builder(<span class="keyword">this</span>)</span><br><span class="line">        .setExecutorService(mExecutorService)</span><br><span class="line">        .setHandler(mHandler)</span><br><span class="line">        .setBtMediaRecorder(mBtMediaRecorder)</span><br><span class="line">        .build();</span><br></pre></td></tr></table></figure>

<p>开启一个单线程去实现录音功能按下按钮recordMedia()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">recordMedia</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (mIsRecording) &#123;</span><br><span class="line">        mIsRecording = <span class="keyword">false</span>;</span><br><span class="line">        mBtMediaRecorder.setText(<span class="string">&quot;开始录音&quot;</span>);</span><br><span class="line">        mExecutorService.submit(<span class="keyword">this</span>::stopRecorder);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        mIsRecording = <span class="keyword">true</span>;</span><br><span class="line">        mBtMediaRecorder.setText(<span class="string">&quot;停止录音&quot;</span>);</span><br><span class="line">        <span class="comment">// 提交后台任务，执行录音逻辑</span></span><br><span class="line">        mExecutorService.submit(<span class="keyword">this</span>::startRecorder);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>开始录音startRecorder()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startRecorder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 释放上一次的录音</span></span><br><span class="line">    releaseRecorder();</span><br><span class="line">    <span class="comment">// 开始录音</span></span><br><span class="line">    <span class="keyword">if</span> (!doStart()) &#123;</span><br><span class="line">        recorderFail();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启动录音doStart()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">doStart</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 创建MediaRecorder</span></span><br><span class="line">        mMediaRecorder = <span class="keyword">new</span> MediaRecorder();</span><br><span class="line"> </span><br><span class="line">        startRecorderTime = System.currentTimeMillis();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 创建录音文件</span></span><br><span class="line">        <span class="keyword">if</span> (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.KITKAT) &#123;</span><br><span class="line">            mRecorderFile = <span class="keyword">new</span> File(mContext.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS)</span><br><span class="line">                    + <span class="string">&quot;/MediaRecorderDemo/&quot;</span> + startRecorderTime + <span class="string">&quot;.m4a&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (!mRecorderFile.getParentFile().exists()) &#123;</span><br><span class="line">                mRecorderFile.getParentFile().mkdirs();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        mRecorderFile.createNewFile();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 配置MediaRecorder</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 从麦克风采集</span></span><br><span class="line">        mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 保存文件为MP4格式</span></span><br><span class="line">        mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.MPEG_4);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 所有android系统都支持的适中采样的频率</span></span><br><span class="line">        mMediaRecorder.setAudioSamplingRate(<span class="number">44100</span>);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 通用的AAC编码格式</span></span><br><span class="line">        mMediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 设置音质频率</span></span><br><span class="line">        mMediaRecorder.setAudioEncodingBitRate(<span class="number">96000</span>);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 设置文件录音的位置</span></span><br><span class="line">        mMediaRecorder.setOutputFile(mRecorderFile.getAbsolutePath());</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 开始录音</span></span><br><span class="line">        mMediaRecorder.prepare();</span><br><span class="line">        mMediaRecorder.start();</span><br><span class="line"> </span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        Toast.makeText(mContext, <span class="string">&quot;录音失败，请重试&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 记录开始录音时间</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>停止录音stopRecorder()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">stopRecorder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 提交后台任务，停止录音</span></span><br><span class="line">    <span class="keyword">if</span> (!doStop()) &#123;</span><br><span class="line">        recorderFail();</span><br><span class="line">    &#125;</span><br><span class="line">    releaseRecorder();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>停止录音计算时长doStop()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">doStop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        mMediaRecorder.stop();</span><br><span class="line">        stopRecorderTime = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> second = (<span class="keyword">int</span>) (stopRecorderTime - startRecorderTime) / <span class="number">1000</span>;</span><br><span class="line">        <span class="comment">// 按住时间小于3秒钟，算作录取失败，不进行发送</span></span><br><span class="line">        <span class="keyword">if</span> (second &lt; <span class="number">3</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        mHandler.post(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                Toast.makeText(mContext,</span><br><span class="line">                        <span class="string">&quot;录音成功：&quot;</span> + second + <span class="string">&quot;秒&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">                Log.d(TAG, <span class="string">&quot;save in &quot;</span> + startRecorderTime + <span class="string">&quot;.m4a&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>释放MediaRecorder的releaseRecorder()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">releaseRecorder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (mMediaRecorder != <span class="keyword">null</span>) &#123;</span><br><span class="line">        mMediaRecorder.release();</span><br><span class="line">        mMediaRecorder = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>设置录音失败的逻辑recorderFail()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">recorderFail</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    mRecorderFile = <span class="keyword">null</span>;</span><br><span class="line">    mHandler.post(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            Toast.makeText(mContext,</span><br><span class="line">                    <span class="string">&quot;录制失败，录音请大于3秒！&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">            mBtMediaRecorder.setText(<span class="string">&quot;开始录音&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (android.os.Build.VERSION.SDK_INT &gt;= android.os.Build.VERSION_CODES.KITKAT) &#123;</span><br><span class="line">                File audioRecordFile = <span class="keyword">new</span> File(mContext.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS) +</span><br><span class="line">                        <span class="string">&quot;/MediaRecorderDemo/&quot;</span> + startRecorderTime + <span class="string">&quot;.m4a&quot;</span>);</span><br><span class="line">                audioRecordFile.delete();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>记得在onDestroy()防止内存泄漏</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">    <span class="keyword">if</span> (mMediaRecorderTest.getMediaRecorder() != <span class="keyword">null</span>) &#123;</span><br><span class="line">        mMediaRecorderTest.getMediaRecorder().stop();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mExecutorService != <span class="keyword">null</span>) &#123;</span><br><span class="line">        mExecutorService.shutdownNow();</span><br><span class="line">        mExecutorService = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音频wav转为pcm格式</title>
    <url>/7f2474a.html</url>
    <content><![CDATA[<p>正经方法硬解与软解应该在第三部分mediaCodec中提及，目前测试音频使用第二部分录制的pcm音频以及外部音频，以下是外部音频转pcm的方法：</p>
<ol>
<li><p>将音频导入格式工厂转为wav格式（格式工厂底层利用ffmpeg软解，选择wav是因为wav=44字节wav文件头+pcm）</p>
</li>
<li><p>将wav文件前44个字节去掉并改后缀名为pcm，代码如下（个人用c++实现）</p>
</li>
</ol>
<span id="more"></span>

<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">size_t</span> result;</span><br><span class="line">    <span class="keyword">char</span> *buf;</span><br><span class="line">    FILE *fp1 = <span class="built_in">fopen</span>(<span class="string">&quot;C:\\Users\\ZONGNAN.CHEN\\Music\\test.wav&quot;</span>, <span class="string">&quot;rb&quot;</span>);<span class="comment">//wav文件打开，打开读权限</span></span><br><span class="line">    FILE *fp2 = <span class="built_in">fopen</span>(<span class="string">&quot;C:\\Users\\ZONGNAN.CHEN\\Music\\test.pcm&quot;</span>, <span class="string">&quot;wb&quot;</span>);<span class="comment">//pcm文件创建，给予写权限</span></span><br><span class="line">    <span class="built_in">fseek</span>(fp1, <span class="number">0</span>, SEEK_END);    <span class="comment">// 文件指针从0挪到尾部</span></span><br><span class="line">    <span class="keyword">long</span> filesize;</span><br><span class="line">    filesize = <span class="built_in">ftell</span>(fp1);              <span class="comment">// ftell求文件指针相对于0的便宜字节数，就求出了文件字节数</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (fp1 == <span class="literal">NULL</span> || fp2 == <span class="literal">NULL</span>) &#123;   <span class="comment">// 判断两个文件是否打开</span></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;file open filed!!&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">rewind</span>(fp1);<span class="comment">//还原指针位置</span></span><br><span class="line">    <span class="built_in">fseek</span>(fp1, <span class="number">44</span>, SEEK_SET);   <span class="comment">// wav文件的指针从头向后移动44字节</span></span><br><span class="line">    buf = (<span class="keyword">char</span> *) <span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">char</span>) * filesize);<span class="comment">//开辟空间给缓存数组</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (buf == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;memory  error&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    result = <span class="built_in">fread</span>(buf, <span class="number">1</span>, (filesize - <span class="number">44</span>), fp1);<span class="comment">//每次读一个字节到buf，同时求读的次数</span></span><br><span class="line">    <span class="keyword">if</span> (result != filesize - <span class="number">44</span>) &#123;      <span class="comment">// 判断读的次数和文件大小是否一致</span></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;reing error!!&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">fwrite</span>(buf, <span class="number">1</span>, (filesize - <span class="number">44</span>), fp2);   <span class="comment">// 写到pcm文件中</span></span><br><span class="line">    <span class="built_in">fclose</span>(fp1);    <span class="comment">// 关闭文件指针</span></span><br><span class="line">    <span class="built_in">fclose</span>(fp2);</span><br><span class="line">    <span class="built_in">free</span>(buf);      <span class="comment">// 释放buf</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-音频开发-（三）音频编解码</title>
    <url>/f3f6a8c1.html</url>
    <content><![CDATA[<h3 id="MediaCodec"><a href="#MediaCodec" class="headerlink" title="MediaCodec"></a>MediaCodec</h3><p>Android 官方提供的音频编解码的 API，即 MediaCodec 类，该 API 是在 Andorid 4.1 （API 16） 版本引入的，因此只能工作于 Android 4.1 以上的手机上。</p>
<hr>
<h4 id="MediaCodec-基本介绍"><a href="#MediaCodec-基本介绍" class="headerlink" title="MediaCodec 基本介绍"></a>MediaCodec 基本介绍</h4><ol>
<li><p>提供了一套访问 Android 底层多媒体模块的接口，主要是音视频的编解码接口</p>
</li>
<li><p>Android 底层多媒体模块采用的是 OpenMax 框架，任何 Android 底层编解码模块的实现，都必须遵循 OpenMax 标准。（硬件编解码功能，则需要由芯片厂商依照 OpenMax 框架标准来完成，所以，一般采用不同芯片型号的手机，硬件编解码的实现和性能是不同的）</p>
</li>
</ol>
<span id="more"></span>

<ol start="3">
<li>Android 应用层统一由 MediaCodec API 来提供各种音视频编解码功能，由参数配置来决定采用何种编解码算法、是否采用硬件编解码加速等等</li>
</ol>
<img src="/f3f6a8c1/1.png" class>

<hr>
<h4 id="MediaCodec生命周期和状态"><a href="#MediaCodec生命周期和状态" class="headerlink" title="MediaCodec生命周期和状态"></a>MediaCodec生命周期和状态</h4><p>同步（上）与异步（下）</p>
<img src="/f3f6a8c1/2.png" class>

<img src="/f3f6a8c1/3.png" class>

<ul>
<li><p><strong>Uninitialized</strong>：当通过工厂方法了成功创建编解码器后，此时处于Uninitialized子状态</p>
</li>
<li><p><strong>Configured</strong>：通过configure方法配置编解码器，此时处于Configured子状态，接着，需要调用start方法来启动，让编解码器进入Executing状态的Flushed子状态，才能输入数据给编解码器处理</p>
</li>
<li><p><strong>Flushed</strong>：执行start方法后，此时处于Flushed子状态</p>
</li>
<li><p><strong>Running</strong>：当第一个输入缓冲区被出队，编解码器便进入Running子状态，这意味着大部分时间编解码器都处于此状态</p>
</li>
<li><p><strong>End-of-Stream</strong>：当给编解码器发送一个带有End-of-Stream标记的Buffer后，编解码器就切换为End-of-Stream子状态，此时，编解码器不再接收输入数据，但仍旧会继续输出，直到end-of-stream标记输出</p>
</li>
<li><p><strong>Released</strong>：Stopped和Executing都可切换至此状态，当使用编码器操作完成后，应该调用release方法，使编解码器进入此状态</p>
</li>
</ul>
<p>状态切换：</p>
<ul>
<li><p>**flush()**：Executing → Flushed</p>
</li>
<li><p>**stop()**：Executing → Uninitialized，此时可以调用configure方法来重新配置，进入下一轮循环</p>
</li>
<li><p>**reset()**：any → Uninitialized，reset可以在任何时候被调用。在某些情况下，编解码器会出现异常，此时应该使用reset而不是stop方法</p>
</li>
<li><p>**release()**：不准备重新使用编解码器，那应该调用release进行释放</p>
</li>
</ul>
<hr>
<h4 id="MediaCodec-API-说明"><a href="#MediaCodec-API-说明" class="headerlink" title="MediaCodec API 说明"></a>MediaCodec API 说明</h4><p>getInputBuffers()：获取需要编码数据的输入流队列，返回的是一个ByteBuffer数组</p>
<p>queueInputBuffer()：输入流入队列</p>
<p>dequeueInputBuffer()：从输入流队列中取数据进行编码操作</p>
<p>getOutputBuffers()：获取编解码之后的数据输出流队列，返回的是一个ByteBuffer数组</p>
<p>dequeueOutputBuffer()：从输出队列中取出编码操作之后的数据</p>
<p>releaseOutputBuffer()：处理完成，释放ByteBuffer数据</p>
<hr>
<h4 id="MediaCodec-核心原理"><a href="#MediaCodec-核心原理" class="headerlink" title="MediaCodec 核心原理"></a>MediaCodec 核心原理</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- createEncoderByType/createDecoderByType</span><br><span class="line">- configure</span><br><span class="line">- start</span><br><span class="line">- while(1) &#123;</span><br><span class="line">    - dequeueInputBuffer</span><br><span class="line">    - queueInputBuffer</span><br><span class="line">    - dequeueOutputBuffer</span><br><span class="line">    - releaseOutputBuffer</span><br><span class="line">&#125;</span><br><span class="line">- stop</span><br><span class="line">- release</span><br></pre></td></tr></table></figure>

<p>Buffer 队列的操作是其最核心的部分之一，关于 MediaCodec 的 Buffer 队列 ，示意图如下：</p>
<img src="/f3f6a8c1/4.png" class>

<p>MediaCodec 架构上采用了2个缓冲区队列，异步处理数据：</p>
<ol>
<li><p>Client 从 input 缓冲区队列申请 empty buffer <strong>[dequeueInputBuffer]</strong></p>
</li>
<li><p>Client 把需要编解码的数据拷贝到 empty buffer，然后放入 input 缓冲区队列 <strong>[queueInputBuffer]</strong></p>
</li>
<li><p>MediaCodec 模块从 input 缓冲区队列取一帧数据进行编解码处理</p>
</li>
<li><p>编解码处理结束后，MediaCodec 将原始数据 buffer 置为 empty 后放回 input 缓冲区队列，将编解码后的数据放入到 output 缓冲区队列</p>
</li>
<li><p>Client 从 output 缓冲区队列申请编解码后的 buffer <strong>[dequeueOutputBuffer]</strong></p>
</li>
<li><p>Client 对编解码后的 buffer 进行渲染/播放</p>
</li>
<li><p>渲染/播放完成后，Client 再将该 buffer 放回 output 缓冲区队列 <strong>[releaseOutputBuffer]</strong></p>
</li>
</ol>
<p>MediaCodec 在架构上，其实是采用了一种基于“环形缓冲区”的“生产者-消费者”模式，它设计了 2 个基于 idx 序号的“环形缓冲区”：</p>
<img src="/f3f6a8c1/5.png" class>

<hr>
<h4 id="MediaCodec编码例子（同步）"><a href="#MediaCodec编码例子（同步）" class="headerlink" title="MediaCodec编码例子（同步）"></a>MediaCodec编码例子（同步）</h4><p>使用AudioRecord录制音频，MediaCodec编码为AAC</p>
<p>过程步骤：（基于（二）的doStart()中while循环取得的元数据）</p>
<p>AudioRecorder 基本使用方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 在 Recorder Thread 中创建 Recorder 与相关的 Encoder</span><br><span class="line"><span class="number">2.</span> loop 读取 Recorder 里面的 PCM data，不断地将 PCM 喂入 Encoder中</span><br><span class="line"><span class="number">3.</span> 外部停止录音后，将 run 这个 flag 置为 <span class="keyword">false</span> 跳出循环，并且 close 相关 Encoder 并且保存他们的结果。</span><br><span class="line"><span class="number">4.</span> release 相关资源。</span><br></pre></td></tr></table></figure>

<p>创建一个新的MediaCodec对象然后调用configure()方法对MediaCodec进行配置</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mMediaEncoder = MediaCodec.createEncoderByType(<span class="string">&quot;audio/mp4a-latm&quot;</span>);</span><br><span class="line"> </span><br><span class="line">MediaFormat mediaFormat = <span class="keyword">new</span> MediaFormat();</span><br><span class="line">mediaFormat.setString(MediaFormat.KEY_MIME, <span class="string">&quot;audio/mp4a-latm&quot;</span>);</span><br><span class="line">mediaFormat.setInteger(MediaFormat.KEY_AAC_PROFILE, MediaCodecInfo.CodecProfileLevel.AACObjectLC);</span><br><span class="line">mediaFormat.setInteger(MediaFormat.KEY_BIT_RATE, <span class="number">128000</span>);</span><br><span class="line">mediaFormat.setInteger(MediaFormat.KEY_CHANNEL_COUNT, <span class="number">1</span>);</span><br><span class="line">mediaFormat.setInteger(MediaFormat.KEY_MAX_INPUT_SIZE, <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">mediaFormat.setInteger(MediaFormat.KEY_SAMPLE_RATE, <span class="number">44100</span>);</span><br><span class="line"><span class="comment">// 第四个参数 编码的时候是MediaCodec.CONFIGURE_FLAG_ENCODE 解码的时候是0</span></span><br><span class="line">mMediaEncoder.configure(mediaFormat, <span class="keyword">null</span>, <span class="keyword">null</span>, MediaCodec.CONFIGURE_FLAG_ENCODE);</span><br></pre></td></tr></table></figure>

<p>调用MediaCodec的start()方法，此时MediaCodec处于Executing状态，可以通过getInputBuffers()方法和getOutputBuffers()方法获取缓存队列</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// start()后进入执行状态，才能做后续的操作</span></span><br><span class="line">mMediaEncoder.start();</span><br><span class="line"><span class="comment">// 获取输入缓存，输出缓存</span></span><br><span class="line">mAudioInputBuffers = mMediaEncoder.getInputBuffers();</span><br><span class="line">mAudioOutputBuffers = mMediaEncoder.getOutputBuffers();</span><br><span class="line"><span class="comment">// getInput/OutputBuffers()已经被废弃，应通过dequeueOutputBuffer()获取id然后使用getInput/OutputBuffer(int)来获取缓冲区。(见下文官方例子)</span></span><br></pre></td></tr></table></figure>

<p>返回的整型变量为请求到的输入缓存的index，通过getInputBuffers()得到的是输入缓存数组，通过index和输入缓存数组可以得到当前请求的输入缓存，在使用之前要clear一下，避免之前的缓存数据影响当前数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// dequeueInputBuffer（time）需要传入一个时间值，-1表示一直等待，0表示不等待有可能会丢帧，其他表示等待多少毫秒</span></span><br><span class="line"><span class="keyword">int</span> inputIndex = mMediaEncoder.dequeueInputBuffer(-<span class="number">1</span>);</span><br><span class="line">...</span><br><span class="line"><span class="comment">// 获取输入缓存的index</span></span><br><span class="line">ByteBuffer inputByteBuf = mAudioInputBuffers[inputIndex];</span><br><span class="line">inputByteBuf.clear();</span><br></pre></td></tr></table></figure>

<p>把数据添加到输入缓存中，并调用queueInputBuffer()把缓存数据入队</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 添加数据</span></span><br><span class="line">inputByteBuf.put(data);</span><br><span class="line"><span class="comment">// 限制ByteBuffer的访问长度</span></span><br><span class="line">inputByteBuf.limit(data.length);</span><br><span class="line"><span class="comment">// 把输入缓存塞回去给MediaCodec</span></span><br><span class="line">mMediaEncoder.queueInputBuffer(inputIndex, <span class="number">0</span>, data.length, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// mAudioEncoder.queueInputBuffer(inputBufIndex, 0, data.length, (1000000 * mEncodedSize / AUDIO_BYTE_PER_SAMPLE), 0);</span></span><br><span class="line"><span class="comment">// 有些设备不设置好presentationTimeUs会丢帧</span></span><br><span class="line"><span class="comment">// 这里的1000000是把秒变成微秒，音频输出的时间戳是微秒，输出到surface的视频是纳秒，源码中是这么说的：</span></span><br><span class="line"><span class="comment">// * @param presentationTimeUs The presentation timestamp in microseconds for this</span></span><br><span class="line"><span class="comment">// *                           buffer. This is normally the media time at which this</span></span><br><span class="line"><span class="comment">// *                           buffer should be presented (rendered). When using an output</span></span><br><span class="line"><span class="comment">// *                           surface, this will be propagated as the &#123;@link</span></span><br><span class="line"><span class="comment">// *                           SurfaceTexture#getTimestamp timestamp&#125; for the frame (after</span></span><br><span class="line"><span class="comment">// *                           conversion to nanoseconds).</span></span><br></pre></td></tr></table></figure>

<p>获取输出缓存和获取输入缓存类似，首先通过dequeueOutputBuffer(BufferInfo info, long timeoutUs)来请求一个输出缓存，这里需要传入一个BufferInfo对象，用于存储ByteBuffer的信息</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取输出缓存的index</span></span><br><span class="line"><span class="keyword">int</span> outputIndex = mMediaEncoder.dequeueOutputBuffer(mBufferInfo, <span class="number">0</span>);</span><br></pre></td></tr></table></figure>

<p>通过返回的index得到输出缓存，并通过BufferInfo获取ByteBuffer的信息，注意一定要调用releaseOutputBuffer方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取输出缓存的index</span></span><br><span class="line"><span class="keyword">int</span> outputIndex = mMediaEncoder.dequeueOutputBuffer(mBufferInfo, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">while</span> (outputIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 获取缓存信息的长度</span></span><br><span class="line">    <span class="keyword">int</span> byteBufSize = mBufferInfo.size;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 处理数据</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//释放</span></span><br><span class="line">    mMediaEncoder.releaseOutputBuffer(outputIndex, <span class="keyword">false</span>);</span><br><span class="line">    outputIndex = mMediaEncoder.dequeueOutputBuffer(mBufferInfo, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用完MediaCodec后释放资源</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mAudioEncoder.stop();</span><br><span class="line">mAudioEncoder.release();</span><br></pre></td></tr></table></figure>

<p>上述过程的总结代码如下：PCM数据编码为AAC数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        mMediaEncoder = MediaCodec.createEncoderByType(<span class="string">&quot;audio/mp4a-latm&quot;</span>);</span><br><span class="line"> </span><br><span class="line">        MediaFormat mediaFormat = <span class="keyword">new</span> MediaFormat();</span><br><span class="line">        mediaFormat.setString(MediaFormat.KEY_MIME, <span class="string">&quot;audio/mp4a-latm&quot;</span>);</span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_AAC_PROFILE, MediaCodecInfo.CodecProfileLevel.AACObjectLC);</span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_BIT_RATE, <span class="number">128000</span>);</span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_CHANNEL_COUNT, <span class="number">1</span>);</span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_MAX_INPUT_SIZE, <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_SAMPLE_RATE, <span class="number">44100</span>);</span><br><span class="line">        <span class="comment">// 第四个参数 编码的时候是MediaCodec.CONFIGURE_FLAG_ENCODE 解码的时候是0</span></span><br><span class="line">        mMediaEncoder.configure(mediaFormat, <span class="keyword">null</span>, <span class="keyword">null</span>, MediaCodec.CONFIGURE_FLAG_ENCODE);</span><br><span class="line">        <span class="comment">// start()后进入执行状态，才能做后续的操作</span></span><br><span class="line">        mMediaEncoder.start();</span><br><span class="line">        <span class="comment">// 获取输入缓存，输出缓存</span></span><br><span class="line">        mAudioInputBuffers = mMediaEncoder.getInputBuffers();</span><br><span class="line">        mAudioOutputBuffers = mMediaEncoder.getOutputBuffers();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] encodeData(<span class="keyword">byte</span>[] data) &#123;</span><br><span class="line">    <span class="comment">// dequeueInputBuffer（time）需要传入一个时间值，-1表示一直等待，0表示不等待有可能会丢帧，其他表示等待多少毫秒</span></span><br><span class="line">    <span class="keyword">int</span> inputIndex = mMediaEncoder.dequeueInputBuffer(-<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 获取输入缓存的index</span></span><br><span class="line">    <span class="keyword">if</span> (inputIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        ByteBuffer inputByteBuf = mAudioInputBuffers[inputIndex];</span><br><span class="line">        inputByteBuf.clear();</span><br><span class="line">        <span class="comment">// 添加数据</span></span><br><span class="line">        inputByteBuf.put(data);</span><br><span class="line">        <span class="comment">// 限制ByteBuffer的访问长度</span></span><br><span class="line">        inputByteBuf.limit(data.length);</span><br><span class="line">        <span class="comment">// 把输入缓存塞回去给MediaCodec</span></span><br><span class="line">        mMediaEncoder.queueInputBuffer(inputIndex, <span class="number">0</span>, data.length, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 获取输出缓存的index</span></span><br><span class="line">    <span class="keyword">int</span> outputIndex = mMediaEncoder.dequeueOutputBuffer(mBufferInfo, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">while</span> (outputIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 获取缓存信息的长度</span></span><br><span class="line">        <span class="keyword">int</span> byteBufSize = mBufferInfo.size;</span><br><span class="line">        <span class="comment">// 添加ADTS头部后的长度</span></span><br><span class="line">        <span class="keyword">int</span> bytePacketSize = byteBufSize + <span class="number">7</span>;</span><br><span class="line"> </span><br><span class="line">        ByteBuffer outPutBuf = mAudioOutputBuffers[outputIndex];</span><br><span class="line">        outPutBuf.position(mBufferInfo.offset);</span><br><span class="line">        outPutBuf.limit(mBufferInfo.offset + mBufferInfo.size);</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">byte</span>[] targetByte = <span class="keyword">new</span> <span class="keyword">byte</span>[bytePacketSize];</span><br><span class="line">        <span class="comment">//添加ADTS头部</span></span><br><span class="line">        addADTStoPacket(targetByte, bytePacketSize);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        get（byte[] dst,int offset,int length）:ByteBuffer从position位置开始读，读取length个byte，并写入dst下</span></span><br><span class="line"><span class="comment">        标从offset到offset + length的区域</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        outPutBuf.get(targetByte, <span class="number">7</span>, byteBufSize);</span><br><span class="line"> </span><br><span class="line">        outPutBuf.position(mBufferInfo.offset);</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fileOutputStream.write(targetByte);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//释放</span></span><br><span class="line">        mMediaEncoder.releaseOutputBuffer(outputIndex, <span class="keyword">false</span>);</span><br><span class="line">        outputIndex = mMediaEncoder.dequeueOutputBuffer(mBufferInfo, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> data;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 给编码出的aac裸流添加adts头字段</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> packet    要空出前7个字节，否则会搞乱数据</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> packetLen</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addADTStoPacket</span><span class="params">(<span class="keyword">byte</span>[] packet, <span class="keyword">int</span> packetLen)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> profile = <span class="number">2</span>;  <span class="comment">// AAC LC</span></span><br><span class="line">    <span class="keyword">int</span> freqIdx = <span class="number">4</span>;  <span class="comment">// 44.1KHz</span></span><br><span class="line">    <span class="keyword">int</span> chanCfg = <span class="number">1</span>;  <span class="comment">// SCE</span></span><br><span class="line">    packet[<span class="number">0</span>] = (<span class="keyword">byte</span>) <span class="number">0xFF</span>;</span><br><span class="line">    packet[<span class="number">1</span>] = (<span class="keyword">byte</span>) <span class="number">0xF9</span>;</span><br><span class="line">    packet[<span class="number">2</span>] = (<span class="keyword">byte</span>) (((profile - <span class="number">1</span>) &lt;&lt; <span class="number">6</span>) + (freqIdx &lt;&lt; <span class="number">2</span>) + (chanCfg &gt;&gt; <span class="number">2</span>));</span><br><span class="line">    packet[<span class="number">3</span>] = (<span class="keyword">byte</span>) (((chanCfg &amp; <span class="number">3</span>) &lt;&lt; <span class="number">6</span>) + (packetLen &gt;&gt; <span class="number">11</span>));</span><br><span class="line">    packet[<span class="number">4</span>] = (<span class="keyword">byte</span>) ((packetLen &amp; <span class="number">0x7FF</span>) &gt;&gt; <span class="number">3</span>);</span><br><span class="line">    packet[<span class="number">5</span>] = (<span class="keyword">byte</span>) (((packetLen &amp; <span class="number">7</span>) &lt;&lt; <span class="number">5</span>) + <span class="number">0x1F</span>);</span><br><span class="line">    packet[<span class="number">6</span>] = (<span class="keyword">byte</span>) <span class="number">0xFC</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>附带贴上一段官方提供的代码思路（学习思路）：官方给出的一段同步典型代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MediaCodec codec = MediaCodec.createByCodecName(name);</span><br><span class="line">codec.configure(format, …);</span><br><span class="line">MediaFormat outputFormat = codec.getOutputFormat(); <span class="comment">// option B</span></span><br><span class="line">codec.start();</span><br><span class="line"><span class="keyword">for</span> (;;) &#123;</span><br><span class="line">  <span class="keyword">int</span> inputBufferId = codec.dequeueInputBuffer(timeoutUs);</span><br><span class="line">  <span class="keyword">if</span> (inputBufferId &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    ByteBuffer inputBuffer = codec.getInputBuffer(…);</span><br><span class="line">    <span class="comment">// fill inputBuffer with valid data</span></span><br><span class="line">    …</span><br><span class="line">    codec.queueInputBuffer(inputBufferId, …);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">int</span> outputBufferId = codec.dequeueOutputBuffer(…);</span><br><span class="line">  <span class="keyword">if</span> (outputBufferId &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId);</span><br><span class="line">    MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); <span class="comment">// option A</span></span><br><span class="line">    <span class="comment">// bufferFormat is identical to outputFormat</span></span><br><span class="line">    <span class="comment">// outputBuffer is ready to be processed or rendered.</span></span><br><span class="line">    …</span><br><span class="line">    codec.releaseOutputBuffer(outputBufferId, …);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) &#123;</span><br><span class="line">    <span class="comment">// Subsequent data will conform to new format.</span></span><br><span class="line">    <span class="comment">// Can ignore if using getOutputFormat(outputBufferId)</span></span><br><span class="line">    outputFormat = codec.getOutputFormat(); <span class="comment">// option B</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">codec.stop();</span><br><span class="line">codec.release();</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="MediaCodec编码例子（异步）"><a href="#MediaCodec编码例子（异步）" class="headerlink" title="MediaCodec编码例子（异步）"></a>MediaCodec编码例子（异步）</h4><p>使用AudioRecord录制音频，MediaCodec编码为AAC</p>
<p>设置回调方法必须在MediaCodec创建之后，并且在configure方法之前。</p>
<p>其中index是指向缓冲区的BufferId，利用这个index用户可以获得缓冲区；format是变化后的Mediaformat。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 当inputbuffer可用时回调此方法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">onInputBufferAvailable</span><span class="params">(MediaCodec codec, <span class="keyword">int</span> index)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 当outputbuffer可用时回调此方法</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">onOutputBufferAvailable</span><span class="params">(MediaCodec codec, <span class="keyword">int</span> index, MediaCodec.BufferInfo info)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 当输出格式变化时回调此方法</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">onOutputFormatChanged</span><span class="params">(MediaCodec codec, MediaFormat format)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 发生错误时回调此方法</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">onError</span><span class="params">(MediaCodec codec, MediaCodec.CodecException e)</span></span></span><br></pre></td></tr></table></figure>

<p>基于同步的方法做对应修改，如下给出官方示例：官方给出的一段异步典型代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MediaCodec codec = MediaCodec.createByCodecName(name);</span><br><span class="line">MediaFormat mOutputFormat; <span class="comment">// member variable</span></span><br><span class="line">codec.setCallback(<span class="keyword">new</span> MediaCodec.Callback() &#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">onInputBufferAvailable</span><span class="params">(MediaCodec mc, <span class="keyword">int</span> inputBufferId)</span> </span>&#123;</span><br><span class="line">     ByteBuffer inputBuffer = codec.getInputBuffer(inputBufferId);</span><br><span class="line">     <span class="comment">// fill inputBuffer with valid data</span></span><br><span class="line">     …</span><br><span class="line">     codec.queueInputBuffer(inputBufferId, …);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">onOutputBufferAvailable</span><span class="params">(MediaCodec mc, <span class="keyword">int</span> outputBufferId, …)</span> </span>&#123;</span><br><span class="line">     ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId);</span><br><span class="line">     MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); <span class="comment">// option A</span></span><br><span class="line">     <span class="comment">// bufferFormat is equivalent to mOutputFormat</span></span><br><span class="line">     <span class="comment">// outputBuffer is ready to be processed or rendered.</span></span><br><span class="line">     …</span><br><span class="line">     codec.releaseOutputBuffer(outputBufferId, …);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">onOutputFormatChanged</span><span class="params">(MediaCodec mc, MediaFormat format)</span> </span>&#123;</span><br><span class="line">     <span class="comment">// Subsequent data will conform to new format.</span></span><br><span class="line">     <span class="comment">// Can ignore if using getOutputFormat(outputBufferId)</span></span><br><span class="line">     mOutputFormat = format; <span class="comment">// option B</span></span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">onError</span><span class="params">(…)</span> </span>&#123;</span><br><span class="line">     …</span><br><span class="line">   &#125;</span><br><span class="line">&#125;);</span><br><span class="line">codec.configure(format, …);</span><br><span class="line">mOutputFormat = codec.getOutputFormat(); <span class="comment">// option B</span></span><br><span class="line">codec.start();</span><br><span class="line"><span class="comment">// wait for processing to complete</span></span><br><span class="line">codec.stop();</span><br><span class="line">codec.release();</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="MediaCodec解码例子"><a href="#MediaCodec解码例子" class="headerlink" title="MediaCodec解码例子"></a>MediaCodec解码例子</h4><p>硬解码AAC音频文件并播放</p>
<p>初始化结束后，调用play()传入音频文件即可</p>
<p>配置播放器initAudioTrack()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initAudioTrack</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 配置播放器</span></span><br><span class="line">    <span class="keyword">int</span> streamType = AudioManager.STREAM_MUSIC;</span><br><span class="line">    <span class="keyword">int</span> sampleRate = <span class="number">44100</span>;</span><br><span class="line">    <span class="keyword">int</span> channelConfig = AudioFormat.CHANNEL_OUT_MONO;</span><br><span class="line">    <span class="keyword">int</span> audioFormat = AudioFormat.ENCODING_PCM_16BIT;</span><br><span class="line">    <span class="keyword">int</span> mode = AudioTrack.MODE_STREAM;</span><br><span class="line">    <span class="keyword">int</span> minBufferSize = AudioTrack.getMinBufferSize(sampleRate, channelConfig, audioFormat);</span><br><span class="line">    mAudioTrack = <span class="keyword">new</span> AudioTrack(streamType, sampleRate, channelConfig, audioFormat,</span><br><span class="line">            Math.max(minBufferSize, <span class="number">2048</span>), mode);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>配置解码器initDecoder()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initDecoder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 需要解码数据的类型</span></span><br><span class="line">        String mine = <span class="string">&quot;audio/mp4a-latm&quot;</span>;</span><br><span class="line">        <span class="comment">// 初始化解码器</span></span><br><span class="line">        mDecoder = MediaCodec.createDecoderByType(mine);</span><br><span class="line">        <span class="comment">// MediaFormat用于描述音视频数据的相关参数</span></span><br><span class="line">        MediaFormat mediaFormat = <span class="keyword">new</span> MediaFormat();</span><br><span class="line">        <span class="comment">// 数据类型</span></span><br><span class="line">        mediaFormat.setString(MediaFormat.KEY_MIME, mine);</span><br><span class="line">        <span class="comment">// 声道个数</span></span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_CHANNEL_COUNT, <span class="number">2</span>);</span><br><span class="line">        <span class="comment">// 采样率</span></span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_SAMPLE_RATE, <span class="number">48000</span>);</span><br><span class="line">        <span class="comment">// 比特率</span></span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_BIT_RATE, <span class="number">128000</span>);</span><br><span class="line">        <span class="comment">// 用来标记AAC是否有adts头，1-&gt;有</span></span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_IS_ADTS, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 用来标记aac的类型</span></span><br><span class="line">        mediaFormat.setInteger(MediaFormat.KEY_AAC_PROFILE, MediaCodecInfo.CodecProfileLevel.AACObjectLC);</span><br><span class="line">        <span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[]&#123;(<span class="keyword">byte</span>) <span class="number">0x11</span>, (<span class="keyword">byte</span>) <span class="number">0x90</span>&#125;;</span><br><span class="line">        ByteBuffer csd_0 = ByteBuffer.wrap(data);</span><br><span class="line">        mediaFormat.setByteBuffer(<span class="string">&quot;csd-0&quot;</span>, csd_0);</span><br><span class="line">        <span class="comment">// 解码器配置</span></span><br><span class="line">        mDecoder.configure(mediaFormat, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="number">0</span>);</span><br><span class="line"> </span><br><span class="line">        mDecoder.start();</span><br><span class="line">        <span class="comment">// 输入ByteBuffer</span></span><br><span class="line">        mCodecInputBuffers = mDecoder.getInputBuffers();</span><br><span class="line">        <span class="comment">// 输出ByteBuffer</span></span><br><span class="line">        mCodecOutputBuffers = mDecoder.getOutputBuffers();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>传入文件即可播放aac音频play()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">play</span><span class="params">(File audioRecordFile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 这个值用于找到第一个帧头后，继续寻找第二个帧头，如果解码失败可以尝试缩小这个值</span></span><br><span class="line">    <span class="keyword">int</span> FRAME_MIN_LEN = <span class="number">50</span>;</span><br><span class="line">    <span class="comment">// 一般AAC帧大小不超过200k,如果解码失败可以尝试增大这个值</span></span><br><span class="line">    <span class="keyword">int</span> FRAME_MAX_LEN = <span class="number">100</span> * <span class="number">1024</span>;</span><br><span class="line">    <span class="comment">// 从文件流读数据</span></span><br><span class="line">    FileInputStream fis = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">byte</span>[] mBuffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">2048</span>];</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 循环读数据，写到播放器去播放</span></span><br><span class="line">        fis = <span class="keyword">new</span> FileInputStream(audioRecordFile);</span><br><span class="line">        Log.d(TAG, audioRecordFile.toString());</span><br><span class="line">        <span class="comment">// 保存完整数据帧</span></span><br><span class="line">        <span class="keyword">byte</span>[] frame = <span class="keyword">new</span> <span class="keyword">byte</span>[FRAME_MAX_LEN];</span><br><span class="line">        <span class="comment">// 当前帧长度</span></span><br><span class="line">        <span class="keyword">int</span> frameLen = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 每次从文件读取的数据</span></span><br><span class="line">        <span class="keyword">byte</span>[] readData = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">10</span> * <span class="number">1024</span>];</span><br><span class="line">        <span class="comment">// 循环读数据，写到播放器去播放 只要没读完，循环播放</span></span><br><span class="line">        mAudioTrack.play();</span><br><span class="line">        <span class="keyword">int</span> readLen;</span><br><span class="line">        <span class="keyword">while</span> ((readLen = fis.read(mBuffer)) != -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">// 当前长度小于最大值</span></span><br><span class="line">            <span class="keyword">if</span> (frameLen + readLen &lt; FRAME_MAX_LEN) &#123;</span><br><span class="line">                <span class="comment">// 将readData拷贝到frame</span></span><br><span class="line">                System.arraycopy(readData, <span class="number">0</span>, frame, frameLen, readLen);</span><br><span class="line">                <span class="comment">// 修改frameLen</span></span><br><span class="line">                frameLen += readLen;</span><br><span class="line">                <span class="comment">// 寻找第一个帧头</span></span><br><span class="line">                <span class="keyword">int</span> headFirstIndex = findHead(frame, <span class="number">0</span>, frameLen);</span><br><span class="line">                <span class="keyword">while</span> (headFirstIndex &gt;= <span class="number">0</span> &amp;&amp; isHead(frame, headFirstIndex)) &#123;</span><br><span class="line">                    <span class="comment">// 寻找第二个帧头</span></span><br><span class="line">                    <span class="keyword">int</span> headSecondIndex = findHead(frame, headFirstIndex + FRAME_MIN_LEN, frameLen);</span><br><span class="line">                    <span class="comment">// 如果第二个帧头存在，则两个帧头之间的就是一帧完整的数据</span></span><br><span class="line">                    <span class="keyword">if</span> (headSecondIndex &gt; <span class="number">0</span> &amp;&amp; isHead(frame, headSecondIndex)) &#123;</span><br><span class="line">                        <span class="comment">// 视频解码</span></span><br><span class="line">                        decodeData(frame, headFirstIndex, headSecondIndex - headFirstIndex);</span><br><span class="line">                        <span class="comment">// 截取headSecondIndex之后到frame的有效数据,并放到frame最前面</span></span><br><span class="line">                        <span class="keyword">byte</span>[] temp = Arrays.copyOfRange(frame, headSecondIndex, frameLen);</span><br><span class="line">                        System.arraycopy(temp, <span class="number">0</span>, frame, <span class="number">0</span>, temp.length);</span><br><span class="line">                        <span class="comment">// 修改frameLen的值</span></span><br><span class="line">                        frameLen = temp.length;</span><br><span class="line">                        <span class="comment">// 继续寻找数据帧</span></span><br><span class="line">                        headFirstIndex = findHead(frame, <span class="number">0</span>, frameLen);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 找不到第二个帧头</span></span><br><span class="line">                        headFirstIndex = -<span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//如果长度超过最大值，frameLen置0</span></span><br><span class="line">                frameLen = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        Log.d(TAG, <span class="string">&quot;播放完毕！&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        closeInputStream(fis);</span><br><span class="line">        <span class="comment">// 播放器释放</span></span><br><span class="line">        resetQuietly(mAudioTrack);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>play()中的aac解码+播放函数decodeData()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * aac解码+播放</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">decodeData</span><span class="params">(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> inputIndex = mDecoder.dequeueInputBuffer(-<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (inputIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 获取当前的ByteBuffer</span></span><br><span class="line">        ByteBuffer inputByteBuf = mCodecInputBuffers[inputIndex];</span><br><span class="line">        <span class="comment">// 清空ByteBuffer</span></span><br><span class="line">        inputByteBuf.clear();</span><br><span class="line">        <span class="comment">// 填充数据</span></span><br><span class="line">        inputByteBuf.put(data, offset, length);</span><br><span class="line">        <span class="comment">// 将指定index的input buffer提交给解码器</span></span><br><span class="line">        mDecoder.queueInputBuffer(inputIndex, <span class="number">0</span>, length, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 编解码器缓冲区</span></span><br><span class="line">    MediaCodec.BufferInfo info = <span class="keyword">new</span> MediaCodec.BufferInfo();</span><br><span class="line">    <span class="keyword">int</span> outputBufferIndex = mDecoder.dequeueOutputBuffer(info, -<span class="number">1</span>);</span><br><span class="line">    ByteBuffer outputBuffer;</span><br><span class="line">    <span class="keyword">while</span> (outputBufferIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 获取解码后的ByteBuffer</span></span><br><span class="line">        outputBuffer = mCodecOutputBuffers[outputBufferIndex];</span><br><span class="line">        <span class="comment">// 用来保存解码后的数据</span></span><br><span class="line">        <span class="keyword">byte</span>[] outData = <span class="keyword">new</span> <span class="keyword">byte</span>[info.size];</span><br><span class="line">        outputBuffer.get(outData);</span><br><span class="line">        <span class="comment">// 清空缓存</span></span><br><span class="line">        outputBuffer.clear();</span><br><span class="line">        <span class="comment">// 播放解码后的数据</span></span><br><span class="line">        mAudioTrack.write(outData, <span class="number">0</span>, info.size);</span><br><span class="line">        <span class="comment">// 释放已经解码的buffer</span></span><br><span class="line">        mDecoder.releaseOutputBuffer(outputBufferIndex, <span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">// 解码未解完的数据</span></span><br><span class="line">        outputBufferIndex = mDecoder.dequeueOutputBuffer(info, -<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>play()中的找缓存中aac帧头起始位置findHead()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 寻找指定buffer中AAC帧头的开始位置</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> startIndex 开始的位置</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> data       数据</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> max        需要检测的最大值</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">findHead</span><span class="params">(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> startIndex, <span class="keyword">int</span> max)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = startIndex; i &lt;= max; i++) &#123;</span><br><span class="line">        <span class="comment">// 发现帧头</span></span><br><span class="line">        <span class="keyword">if</span> (isHead(data, i))</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 检测到最大值，未发现帧头</span></span><br><span class="line">    <span class="keyword">if</span> (i == max) &#123;</span><br><span class="line">        i = -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>play()中的判断aac帧头方法isHead()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 判断aac帧头</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isHead</span><span class="params">(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> offset)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> result = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (data[offset] == (<span class="keyword">byte</span>) <span class="number">0xFF</span> &amp;&amp; data[offset + <span class="number">1</span>] == (<span class="keyword">byte</span>) <span class="number">0xF1</span></span><br><span class="line">            &amp;&amp; data[offset + <span class="number">3</span>] == (<span class="keyword">byte</span>) <span class="number">0x80</span>) &#123;</span><br><span class="line">        result = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>生活知识-碳性电池和碱性电池</title>
    <url>/5a98bf54.html</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>在日常生活中，我们都会用到电池无论是电视遥控器还是挂钟，这些都需要电池，这其中还分碳性电池和碱性电池。</p>
<p>碳性电池和碱性电池都是干电池，只是按照材质的不同而分的两种类别。</p>
<p>1、碳性电池的全称应该是碳锌电池，一般正极是碳棒，负极是锌皮，也称为锌锰电池。锌锰电池是目前最普遍的干电池，它有价格低廉和使用安全可靠的特点。</p>
<p>2、碱性电池也称为碱性干电池或碱性锌锰干电池，适用于需放电量大及长时间使用的仪器，碱性电池内阻较低，因此产生的电流较一般锌锰电池大。</p>
<span id="more"></span>

<p>碳性电池（左）和碱性电池（右）</p>
<img src="/5a98bf54/1.png" class>

<hr>
<h3 id="碳性电池"><a href="#碳性电池" class="headerlink" title="碳性电池"></a>碳性电池</h3><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p><strong>碳性电池</strong>，学名是<strong>中性锌-二氧化锰干电池</strong>（zinc-manganese dry battery），最简单的识别方法：电池皮上型号为R6+后缀（五号）/R03+后缀（七号），就是此类电池，后缀S表示普通，P表示高功率，C表示高容量等等。</p>
<p>碳性电池放电功率很低，放电容量也很小，所以只适合用于低耗电电器，如钟表、遥控器等。另外，碳性电池的负极就是电池外壳，放电完毕后常常由于外壳破裂而发生电解液泄露，损坏用电设备。最大的优点是价钱便宜，市面上单价常常低于一元，甚至有低于5角的。</p>
<h4 id="结构原理"><a href="#结构原理" class="headerlink" title="结构原理"></a>结构原理</h4><p>正极材料：MnO₂、石墨棒<br>负极材料：锌片<br>电解质：NH₄Cl、ZnCl₂及淀粉糊状物<br>电池符号可表示为：（-）Zn|ZnCl₂、NH₄Cl（糊状） ‖ MnO₂|C（石墨）（+）<br>负极：Zn - 2e⁻ = Zn²⁺<br>正极：2MnO₂ + 2NH₄⁺ + 2e⁻ = Mn₂O₃ + 2NH₃↑ + H₂O<br>总反应：2Zn + 2MnO₂ + 2NH₄⁺ = 2Zn₂⁺ + Mn₂O₃ + 2NH₃ + H₂O</p>
<p>锌锰碳性电池的电动势为1.5V。因产生的NH₃气被MnO₂吸附，引起电动势下降较快。如果用高导电的糊状KOH代替NH₄Cl，正极材料改用钢筒，MnO₂层紧靠钢筒，就构成碱性锌锰干电池，由于电池反应没有气体产生，内电阻较低，电动势为1.5V，比较稳定。</p>
<p>碳性电池属于化学电源中的原电池，是一种一次性电池，它以二氧化锰为正极，以锌筒为负极，把化学能转变为电能供给外电路。在化学反应中由于锌比锰活泼，锌失去电子被氧化，锰得到电子被还原。</p>
<hr>
<h3 id="碱性电池"><a href="#碱性电池" class="headerlink" title="碱性电池"></a>碱性电池</h3><h4 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h4><p><strong>碱性电池</strong>亦称为碱性干电池、碱性锌锰电池、碱锰电池，是目前商品化的锌锰干电池系列中性能最好的品种。碱性电池的型号是LR6（五号）/LR03（七号），前缀L代表碱性（a”L”kaline）。当然可能在数字后面还有后缀，但是不常见。</p>
<p>碱性电池采用电解二氧化锰制作环形正极，锌粉和添加剂配置的锌膏作为负极。由于电解液导电性强，正负极材料表面积大大优于碳性电池，以及强碱性条件下对锌-锰体系电化学反应的促进作用，使碱性电池的输出功率和容量都远胜于碳性电池。碱性电池相比于碳性电池更适合于较大功率的用电器，不过随着数码技术的发展，很多用电器堪称电老虎，比如高亮度LED手电筒、闪光灯等。这些用电器电流动辄就上1500mA的，一般碱性电池恐怕也难堪大任。</p>
<p>碳性和碱性电池的漏液问题一直是消费者头疼的问题。碳性电池自不必说，用放电过程不断消耗的负极锌兼做外壳，就决定了放电后期外壳很可能破裂漏液，毕竟反应嘛，不一定那么均匀的发生。虽然碱性电池采用了密封的电池结构，但是碱液有个特点，叫做浸润性，对金属表面吸附能力特强。这造成所谓爬碱现象。在家也能做做模拟实验，找个不锈钢筷子之类的，垂直插入较浓的纯碱水溶液。结果纯碱固体会沿着金属筷子一路向上爬。这个现象实际上是由于吸附在金属表面，处于液面以上的纯碱溶液水分蒸发造成浓度梯度，而使下面的纯碱溶液被“吸”上来蒸发掉。这在碱性电池里头也时有发生，也就是我们常说的的电池漏液现象，漏液并不可怕，主要是怕电解液泄漏腐蚀到昂贵的用电器。</p>
<p>此外，碱性电池过度放电下负极产生氢气，电池内压升高，为了避免电池爆炸，位于负极泄压阀会打开，排气同时当然也就漏液了。电池漏液轻则腐蚀电极影响接触，重则腐蚀电路板昂贵用电器报废。所以一直以来，电池的一个重要的改进目标就是没有漏液。</p>
<p>常见的有南孚、金霸王、超霸等。</p>
<h4 id="结构原理-1"><a href="#结构原理-1" class="headerlink" title="结构原理"></a>结构原理</h4><p>正极为阴极反应：<br>MnO₂ + H₂O + e⁻ = MnO(OH) + OH⁻<br>MnO(OH)在碱性溶液中有一定的溶解度<br>MnO(OH) + H₂O + OH⁻ = Mn(OH)₄⁻<br>Mn(OH)₄⁻ + e⁻ = Mn(OH)₄²⁻</p>
<p>负极为阳极反应：<br>Zn + 2OH⁻ = Zn(OH)₂ + 2e⁻<br>Zn(OH)₂ + 2OH⁻ = Zn(OH)₄²⁻</p>
<p>总的电池反应为：<br>Zn + MnO₂ + 2H₂O + 4OH⁻ = Mn(OH)₄²⁻ + Zn(OH)₄²⁻</p>
<hr>
<h3 id="锂铁电池"><a href="#锂铁电池" class="headerlink" title="锂铁电池"></a>锂铁电池</h3><h4 id="介绍-2"><a href="#介绍-2" class="headerlink" title="介绍"></a>介绍</h4><p><strong>锂铁干电池</strong>，全称<strong>锂-二硫化铁干电池</strong>。由于这种电池采用了全新的内部材料，具备多种特性，常常被业界称为第三代干电池。</p>
<p>相较于1949年就有的碱性电池而言，锂铁电池的出现确实十分新颖。正极二硫化铁在放电中发生的反应可逆性较窄，因此这种特殊电池用于开发成为充电电池并不适当，而搭配使用不利于充电但容量较高的锂金属作为负极，便可提高可用容量。这使得这种电池十分适用于一次性电池应用，是碳性电池和碱性电池后的最佳替代方案。由于锂和水会产生剧烈反应的缘故，锂铁电池电解液采用的是含锂盐的有机溶剂而非水溶液，相对于碳性电池和碱性电池而言，这种新型的锂铁电池就从材料上杜绝了漏液的风险。同尺寸锂－二硫化铁电池的重量只有碱性电池一半，而放电总能量却比碱性电池高出25%以上。具有明显放电电压平台（大约1.45V），因此相比碱性电池而言锂铁电池放电电压更稳定。放电功率显著高于碱性电池。特别适合在重负载场合使用，如闪光灯、电动工具、电动牙刷、成人玩具、儿童玩具的使用中。同时相比于碱性电池，其漏液率和自放电都更低，因此用于低功率的用电器同样具有一定的优势，但是制约其普及的最大因素是制作成本较高，电池单价可高出碱性电池100%以上。</p>
<p>锂铁电池除了在内部材料上跟碳性、碱性电池有着本质区别，在生产工艺上也完全不同，耐时锂铁电池的内部也是卷绕式的结构。</p>
<p>这三类电池，可谓各有优势，较第一代碳性和第二代碱性电池而言，第三代锂铁电池优势更为明显。其中最为突出的性能优势：能够完全兼容1.5V用电平台设备；特别适用于大电流放电；电量充足，其实际放电容量超过市面上在售的所有民用一次电池；温度范围比其他一次电池宽广得多，低温性能优异，可用在-40℃至60℃环境下；体积小、重量轻、防漏液；自放电低，可贮存长达10年；不含对环境有害的材料，无汞无铬从原材料上实现真正的零污染。正是基于以上优点，锂铁电池常常被业内称为继碳性电池、碱性电池后的第三代一次电池，是目前一次性电池最理想的替代方案，更成为众多国家地震和战时应急包里的必备品。</p>
<h4 id="结构原理-2"><a href="#结构原理-2" class="headerlink" title="结构原理"></a>结构原理</h4><p>电池一般包括：正极、负极、电解质、隔膜、正极引线、负极引线、中心端子、材料、安全阀、圈密封圈、TC（正温度控制端子）、电池壳等。</p>
<p>锂铁电池工作时，原理如下：<br>负极被氧化：Li = Li⁺ + e⁻<br>正极被还原：FeS₂ + 4e⁻ = Fe + 2S²⁻<br>总放电反应：FeS₂ + 4Li = Fe + 2Li₂S</p>
<h3 id="碳性电池和碱性电池的区别"><a href="#碳性电池和碱性电池的区别" class="headerlink" title="碳性电池和碱性电池的区别"></a>碳性电池和碱性电池的区别</h3><h4 id="用途不同"><a href="#用途不同" class="headerlink" title="用途不同"></a>用途不同</h4><p><strong>碳性电池</strong>一般用在所需电流量比较小的器件，碳性电池很适合在手电筒、半导体收音机、收录机、照相机、电子钟、电子玩具、科研、电信、航海、航空、医学等国民经济中的许多领域。</p>
<p><strong>碱性电池</strong>适用于闪光灯、剃须刀、电动玩具、CD机、大功率遥控器、无线鼠标以及键盘等这类生活用品上。</p>
<h4 id="电量不同"><a href="#电量不同" class="headerlink" title="电量不同"></a>电量不同</h4><p>从最基本的电量上来看，碱性电池比碳性电池性价比要高一些。</p>
<p>碱性电池的容量会因为输出电流的增加而变小。</p>
<p>例如：同样的一枚电池可以在低输出电流时有3000mAh的容量，但用在取1A电流的负载时，容量就只有700mAh，小于原来容量的1/4。</p>
<h4 id="环保程度不同"><a href="#环保程度不同" class="headerlink" title="环保程度不同"></a>环保程度不同</h4><p>碳性电池的全称应该是碳锌电池（因为它一般正级是炭棒，负极是锌皮），也称为锌锰电池，是最普遍之干电池，它有价格低廉和使用安全可靠的特点，基于环保因素的考量，由于仍含有镉之成份，因此必须回收，以免对地球环境造成破坏。</p>
<p>碱性电池还有一个名称是：碱性干电池或碱性锌锰干电池。导电是铜棒，外壳是钢壳，安全可靠，无须回收，碱性电池内阻比碳性电池要低，而环保型碱性电池含汞量只有0.025%，是不需要回收的。因此，碱性电池比碳性电池要环保很多。</p>
<hr>
<h3 id="注意问题"><a href="#注意问题" class="headerlink" title="注意问题"></a>注意问题</h3><p>时钟用碱性电池可能会漏液，因为碱性电池的电流会随电量多少而变化。满电的时候，电流大，对石英钟这种电流敏感的电器会不好；低电的时候，因为石英钟电流低也能跑，电池没电了还剩一点点也还能用，会导致腐蚀外壳内液流出发生漏液。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><table>
<thead>
<tr>
<th>碳性电池</th>
<th>碱性电池</th>
</tr>
</thead>
<tbody><tr>
<td>便宜但电量少，工作电流小，里面有重金属有污染，用完得回收不能乱扔</td>
<td>贵一点但电量多性价比高，电流大一点，没什么污染，可当生活垃圾丢弃</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-基于骨骼的动作识别与近期相关大赛的介绍</title>
    <url>/40623c87.html</url>
    <content><![CDATA[<h3 id="基于骨骼的动作识别方法介绍"><a href="#基于骨骼的动作识别方法介绍" class="headerlink" title="基于骨骼的动作识别方法介绍"></a>基于骨骼的动作识别方法介绍</h3><p>随着视频获取设备和网络的发展，从视频信息中分析和理解人体动作变得越来越重要。人体动作识别应用于视频监控、自动视频标签和人机交互等多个领域，随着家庭服务机器人的发展和普及,对人机交互的实时性提出了越来越高的要求，然而使用机器实时<strong>识别人类动作</strong>仍是一项具有挑战性的任务。</p>
<span id="more"></span>

<p>随着摄像设备的发展，廉价深度摄像头的出现和应用，基于视频的动作识别可以分为基于RGB数据和基于RGB-D数据的动作识别。与传统的RGB数据相比，RGB-D数据提供了额外的体型和结构信息，这些信息已成功应用于从单一深度图中恢复骨骼关节，在深度图中排除了颜色和纹理，使人的检测和分割更加容易。另外，深度传感器对光照变化不敏感，这给黑暗环境下的系统监控带来了很大的好处。根据使用数据的不同，基于深度传感器的动作识别方法又可分为基于深度序列的方法、基于骨骼的方法和基于多模态融合的方法。</p>
<p>其中，<strong>基于骨骼的动作识别方法</strong>是深度数据研究领域中的一个重点方向。该方法基于人体骨骼序列，利用视频帧间人体关节点的变化来描述动作，包括关节点的位置和外观变化。基于骨骼的方法对光线和背景变化具有更强的鲁棒性，并且有足够的特征来表达运动。同时，骨架数据的规模很小，这使得计算资源可以得到充分的利用。此外，随着微软Kinect相机和视频中人体姿态估计算法的发展，骨骼数据的获取变得更加容易。然而，即使研究人员做了很多工作，仍有许多问题需要进一步的解决，如获取数据的观点多样性、人体尺寸的不同、光照条件强弱和动作执行速度的快慢等都会影响算法的性能，因此，需要对基于骨骼的动作识别算法进行进一步的研究。</p>
<p>基于骨骼的动作识别的发展近况，除了可以从各大计算机视觉顶会和顶刊进行了解外，还可从国内外举办的各个动作识别竞赛中了解到当前动作识别，特别是在自然应用场景下的发展水平。下面罗列出近期的几大竞赛。</p>
<hr>
<h3 id="近期举办的基于骨骼的动作识别比赛"><a href="#近期举办的基于骨骼的动作识别比赛" class="headerlink" title="近期举办的基于骨骼的动作识别比赛"></a>近期举办的基于骨骼的动作识别比赛</h3><h4 id="CVPR-2021-International-Challenge-on-Activity-Recognition-（6月，已结束）"><a href="#CVPR-2021-International-Challenge-on-Activity-Recognition-（6月，已结束）" class="headerlink" title="CVPR 2021 International Challenge on Activity Recognition （6月，已结束）"></a>CVPR 2021 International Challenge on Activity Recognition （6月，已结束）</h4><p>2021 年 AVA 挑战赛是 CVPR 2021活动识别国际挑战赛 (ActivityNet)研讨会的一部分。与前一年一样，该挑战赛有两个独立的任务：用于原子动作检测的AVA-Kinetics和用于说话人检测的Active Speaker 。今年的 Active Speaker 获胜者将之前的最佳分数提高了 5.6% 的绝对 mAP，几乎减少了 50% 的相对误差，而 AVA-Kinetics 获胜者在已经很强大的基线上提高了 1.05% 的绝对 mAP。</p>
<p>大赛官网：<br><a href="https://research.google.com/ava/challenge.html">https://research.google.com/ava/challenge.html</a></p>
<img src="/40623c87/1.jpg" class>

<h4 id="ICCV-2021-Multi-Modal-Video-Reasoning-and-Analyzing-Competition-（7月，已结束）"><a href="#ICCV-2021-Multi-Modal-Video-Reasoning-and-Analyzing-Competition-（7月，已结束）" class="headerlink" title="ICCV 2021 Multi-Modal Video Reasoning and Analyzing Competition （7月，已结束）"></a>ICCV 2021 Multi-Modal Video Reasoning and Analyzing Competition （7月，已结束）</h4><p>今年 ICCV 2021 举办的多模态视频分析与推理比赛（Multi-Modal Video Reasoning and Analyzing Competition）其中赛道2用到的数据集是UAV-Human，UAV-Human 在CVPR2021文章提出的数据集，其中包含67,428个多模式视频序列和119个对象用于动作识别，22,476个帧用于姿势估计，41,290个帧和1,144个身份用于人员重新识别以及22,263个用于属性识别的框架。数据集是由多个城市和农村的飞行无人机在三个月的白天和晚上收集的，因此涵盖了主题，背景，光照，天气，遮挡，相机运动和无人机飞行姿态的广泛多样性。这种全面而具有挑战性的基准应该能够促进基于无人机的人类行为理解的研究，包括动作识别，姿势估计，重新识别和属性识别。</p>
<p>比赛结果已经公布，并且该研讨会时间将安排在 2021 年 10 月 11 日进行。</p>
<p>大赛官网：<br><a href="https://sutdcv.github.io/multi-modal-video-reasoning">https://sutdcv.github.io/multi-modal-video-reasoning</a></p>
<p>比赛结果如下：</p>
<img src="/40623c87/2.jpg" class>

<hr>
<h4 id="2021-CCF-BDCI-基于飞桨实现花样滑冰选手骨骼点动作识别-（进行中）"><a href="#2021-CCF-BDCI-基于飞桨实现花样滑冰选手骨骼点动作识别-（进行中）" class="headerlink" title="2021 CCF BDCI 基于飞桨实现花样滑冰选手骨骼点动作识别 （进行中）"></a>2021 CCF BDCI 基于飞桨实现花样滑冰选手骨骼点动作识别 （进行中）</h4><ul>
<li><p>比赛时间<br>2021/9/22 12:00:00 发布比赛训练集数据和A榜测试集数据，开放初赛A榜评测入口<br>2021/11/20 23:59:59 截止比赛报名，关闭初赛A榜评测入口</p>
</li>
<li><p>主办单位<br>中国计算机学会，百度</p>
</li>
<li><p>大赛介绍<br>CCF大数据与计算智能大赛（以下简称CCF BDCI）由中国计算机学会2013年创办。大赛由教育部教学指导委员会、国家自然科学基金委员会指导，是大数据与人工智能领域的算法、应用、系统、行业大型挑战赛事。CCF BDCI 迄今已成功举办八届，参赛规模、影响力逐年增强，累计吸引到了全球1500余所高校、1800家企事业单位及80余所科研机构的13万余人参与。其中，仅2020年第八届大赛，吸引全球25个国家的44858人组成39022支队伍参赛，这些参赛队伍来自谷歌、腾讯等1682家企业、麻省理工、清华大学等1215所高校，提交作品8万余件。2021年，第九届CCF BDCI大赛将继续与百度公司达成独家战略合作，进一步扩大参与规模及影响力，关注技术发展与人才培养，助力推动我国大数据技术及产业生态发展。飞桨PaddlePaddle作为中国首个自主研发、功能丰富、开源开放的产业级深度学习平台，为本次比赛的参赛选手提供了集深度学习核心训练和推理框架、基础模型库、端到端开发套件和丰富的工具组件于一体的一站式服务。百度飞桨AI Studio作为官方指定且唯一的竞赛日常训练平台，为参赛选手提供高效的学习和开发环境，更有亿元GPU Tesla V100 算力免费赠送，助力选手取得优异成绩。</p>
</li>
<li><p>FSD-10数据集介绍<br>所有视频素材均从2017-2018 年的花样滑冰锦标赛中采集得到。源视频素材中视频的帧率被统一标准化至每秒30 帧，并统一图像大小为1080 * 720 ，保证数据集的相对一致性。之后通过2D姿态估计算法Open Pose，对视频进行逐帧骨骼点提取，最后以.npy格式保存数据集。</p>
</li>
</ul>
<p>大赛官网：<br><a href="https://aistudio.baidu.com/aistudio/competition/detail/115">https://aistudio.baidu.com/aistudio/competition/detail/115</a></p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://kns-cnki-net-s.libvpn.scnu.edu.cn/kcms/detail/detail.aspx?dbcode=CMFD&amp;dbname=CMFDTEMP&amp;filename=1021044166.nh&amp;uniplatform=NZKPT&amp;v=jT%25mmd2F6A%25mmd2BPtJT%25mmd2FZomjRDghhdIzbKr1sCwIBlx0QeHBYsR3Rybco3ohlTlHECW2GRQ4v">http://kns-cnki-net-s.libvpn.scnu.edu.cn/kcms/detail/detail.aspx?dbcode=CMFD&amp;dbname=CMFDTEMP&amp;filename=1021044166.nh&amp;uniplatform=NZKPT&amp;v=jT%25mmd2F6A%25mmd2BPtJT%25mmd2FZomjRDghhdIzbKr1sCwIBlx0QeHBYsR3Rybco3ohlTlHECW2GRQ4v</a><br>&lt;Li T, Liu J, Zhang W, 等. UAV-Human: A Large Benchmark for Human Behavior Understanding With Unmanned Aerial Vehicles[A]. 2021: 16266–16275.&gt;<br>&lt;Liu S, Liu X, Huang G, 等. FSD-10: A Dataset for Competitive Sports Content Analysis[J]. arXiv:2002.03312 [cs], 2020.&gt;</p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10488">https://www.scholat.com/teamwork/showPostMessage.html?id=10488</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-音频开发-（四）音频处理</title>
    <url>/555ed0ac.html</url>
    <content><![CDATA[<h3 id="拼接"><a href="#拼接" class="headerlink" title="拼接"></a>拼接</h3><p>下图是pcm数据的储存：</p>
<img src="/555ed0ac/1.jpg" class>

<p>将两个pcm数据进行合并只需将这两个pcm数据直接连续写入到一个文件中就能够获得一个拼接好的数据。要注意的是要控制好写入的buffer大小这样才能保证数据写入的速度（例如1kb）</p>
<span id="more"></span>

<p>音频拼接</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataInputStream ins1 = <span class="keyword">new</span> DataInputStream(<span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(file1.file)));</span><br><span class="line">DataInputStream ins2 = <span class="keyword">new</span> DataInputStream(<span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(file2.file)));</span><br><span class="line">DataOutputStream outputStream  = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(file)));</span><br><span class="line"><span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">byte</span>[] bytes2 = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">boolean</span> isfinish1= <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">boolean</span> isfinish2 = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">while</span>(!isfinish1)&#123;</span><br><span class="line">    <span class="keyword">int</span> temp = ins1.read(bytes);</span><br><span class="line">    <span class="keyword">if</span>(temp &lt;= <span class="number">0</span>)&#123;</span><br><span class="line">        isfinish1 = <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        outputStream.write(bytes);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span>(!isfinish2)&#123;</span><br><span class="line">    <span class="keyword">int</span> temp = ins2.read(bytes2);</span><br><span class="line">    <span class="keyword">if</span>(temp &lt;= <span class="number">0</span>)&#123;</span><br><span class="line">        isfinish2 = <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        outputStream.write(bytes2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">ins1.close();</span><br><span class="line">ins2.close();</span><br><span class="line">outputStream.close();</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="裁剪"><a href="#裁剪" class="headerlink" title="裁剪"></a>裁剪</h3><p>剪pcm和拼接pcm相似，一个是将两个文件写入一个文件，另一个则是将一个文件中的一段写入另外一个新的文件，这里主要的问题是如何确定数据所表明的时间点。</p>
<p>这里要经过计算获得开始写入和结束写入的数据位置，经过采样率、声道数和比特数来获得每秒的数据量。</p>
<p>每秒数据量 = 采样率 ∗ 声道数 ∗ 比特数 / 1000 / 8</p>
<p>音频裁剪</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataInputStream inputStream = <span class="keyword">new</span> DataInputStream(<span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(source.file)));</span><br><span class="line">DataOutputStream outputStream = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(file)));</span><br><span class="line"><span class="keyword">int</span> audioFormat = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span>(source.bit_num == <span class="number">16</span>)&#123;</span><br><span class="line">    audioFormat = AudioFormat.ENCODING_PCM_16BIT;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    audioFormat = AudioFormat.ENCODING_PCM_8BIT;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> bufferSize = AudioRecord.getMinBufferSize(source.sample_rage_hz,source.channel,audioFormat);</span><br><span class="line"><span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[bufferSize * <span class="number">2</span>];</span><br><span class="line"><span class="keyword">int</span> sample = source.getSampleNuit();</span><br><span class="line"><span class="keyword">while</span>(start &lt; end)&#123;</span><br><span class="line">    inputStream.read(buffer,<span class="number">0</span>,buffer.length);</span><br><span class="line">    outputStream.write(buffer, <span class="number">0</span>, buffer.length);</span><br><span class="line">    start = (bufferSize * <span class="number">2</span> + start * sample) / sample;</span><br><span class="line">&#125;</span><br><span class="line">inputStream.close();</span><br><span class="line">outputStream.close();</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="混音"><a href="#混音" class="headerlink" title="混音"></a>混音</h3><h4 id="线性叠加后求平均"><a href="#线性叠加后求平均" class="headerlink" title="线性叠加后求平均"></a>线性叠加后求平均</h4><p>对于pcm的混音原理比较简单，就是数据的加和，可是不一样加和获得的效果是不同的。例如此样例就是用了最简单的线性叠加后求平均。就是两个pcm文件对应的数值向加除以2，固然为了能够调节这两个音频声音大小，能够在每一个数据以前乘以一个系数。</p>
<p>数据结果 = [(pcm数据1 ∗ 系数1) + (pcm数据2 ∗ 系数2)] / 2</p>
<p>优势：不会产生溢出，噪音较小</p>
<p>缺点：衰减过大，影响质量</p>
<p>还有复杂的方法：例如归一化混音和从新采样法等。</p>
<p>音频混音————线性叠加后求平均</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">byte</span> <span class="title">remixAVG</span><span class="params">(<span class="keyword">byte</span> buffer1, <span class="keyword">byte</span> buffer2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> value = (buffer1 + buffer2) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">byte</span>) value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="归一化混音（自适应加权混音算法）"><a href="#归一化混音（自适应加权混音算法）" class="headerlink" title="归一化混音（自适应加权混音算法）"></a>归一化混音（自适应加权混音算法）</h4><p>使用更多的位数（32 bit）来表示音频数据的一个样本，混完音后在想办法下降其振幅，使其仍旧分布在16 bit所能表示的范围以内。</p>
<p>为避免发生溢出，使用一个可变的衰减因子对语音进行衰减。这个衰减因子也就表明语音的权重，衰减因子随着音频数据的变化而变化，因此称为自适应加权混音。当溢出时，衰减因子较小，使得溢出的数据在衰减后可以处于临界值之内，而在没有溢出时，又让衰减因子慢慢增大，使数据较为平缓的变化。</p>
<p>基本公式是：C = A + B - A<em>B / (数据类型的最大值)（byte数据就是：C = A + B - A</em>B / 127; short数据就是：C = A + B - A * B / 32767;）</p>
<p>音频混音——归一化混音（自适应加权混音算法）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">short</span> <span class="title">remixNOR</span><span class="params">(<span class="keyword">short</span> buffer1, <span class="keyword">short</span> buffer2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">    <span class="keyword">if</span> (buffer1 &lt; <span class="number">0</span> &amp;&amp; buffer2 &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        value = (<span class="keyword">int</span>) (buffer1 + buffer2 - buffer1 * buffer2 / (-(Math.pow(<span class="number">2</span>,<span class="number">16</span>-<span class="number">1</span>)-<span class="number">1</span>)));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        value = (<span class="keyword">int</span>) (buffer1 + buffer2 - buffer1 * buffer2 / (Math.pow(<span class="number">2</span>,<span class="number">16</span>-<span class="number">1</span>)-<span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">short</span>) value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="降噪"><a href="#降噪" class="headerlink" title="降噪"></a>降噪</h3><h4 id="常见的开源降噪方案"><a href="#常见的开源降噪方案" class="headerlink" title="常见的开源降噪方案"></a>常见的开源降噪方案</h4><p>Speex：Speex是一套主要针对语音的开源免费，无专利保护的应用集合，它不仅包括编解码器，还包括VAD(语音检测)、DTX(不连续传输)、AEC(回声消除)、NS(去噪)等实用模块。</p>
<p>RNNoise：RNNoise降噪算法是根据纯语音以及噪声通过GRU训练来做。包含特征点提取、预料等核心部分。</p>
<p>WebRTC：WebRTC提供了视频会议的核心技术，包括音视频的采集、编解码、网络传输、显示等功能，并且还支持跨平台：Windows、Linux、Mac、Android。使用的就是WebRTC的音频处理模块audio_processing</p>
<h4 id="RNNoise降噪方案"><a href="#RNNoise降噪方案" class="headerlink" title="RNNoise降噪方案"></a>RNNoise降噪方案</h4><p>传统降噪算法大部分是估计噪声+维纳滤波，噪声估计的准确性是整个算法效果的核心。根据噪声的不同大部分处理是针对平稳噪声以及瞬时噪声来做。</p>
<p>RNNoise的优点主要是一个算法通过训练可以解决所有噪声场景以及可以优化传统噪声估计的时延和收敛问题。</p>
<p>RNNoise的缺点是深度学习算法落地问题。因为相对大部分传统算法，RNNoise训练要得到一个很好的效果，由于特征点个数、隐藏单元的个数以及神经网络层数的增加，导致模型增大，运行效率。</p>
<p>总的来说，RNNoise处理之后的数据更干净些，几乎没有电流音和杂音，但是受限于训练集、特征点问题，在处理一些数据时候会把正常的原声数据一并错误处理掉。</p>
<ul>
<li><p>RNNoise的代码是基于C开源的，集成到Android中需要使用NDK。开源代码中的rnn_data.c和rnn_data.h是通过机器学习训练出来的，不是通用的。</p>
</li>
<li><p>开源项目提供的一个测试方法，但是该方法是针对文件处理的，可以把一个带噪音的PCM文件处理成无噪音文件。直播SDK中的音频数据是分段的byte数组数据，所以中间需要添加一些接口来让RNNoise来支持分段数据的降噪处理。</p>
</li>
<li><p>根据RNNoise的降噪过程和业务接口流程，把接口定义成init、process、free三个接口。</p>
</li>
<li><p>在process数据时发现RNNosie的处理窗口大小是480，所以传入的数据也必须是480的正整数倍。如果不是的话处理之后会有明显的新引入噪音。</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FRAME_SIZE_SHIFT 2</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FRAME_SIZE (120&lt;&lt;FRAME_SIZE_SHIFT)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> WINDOW_SIZE (2*FRAME_SIZE)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 可强制修改FRAME_SIZE大小#define FRAME_SIZE (128&lt;&lt;FRAME_SIZE_SHIFT)</span></span><br></pre></td></tr></table></figure>

<ul>
<li>开源代码中的rnn_data.c和rnn_data.h是通过机器学习训练出来的，不是通用的。在处理一个噪音数据时发现有些数据中的原声也会一并处理掉，这个效果如果不通过新的数据集训练那么降噪之后的数据是不可用的。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*This file is automatically generated from a Keras model*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> RNN_DATA_H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RNN_DATA_H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;rnn.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> INPUT_DENSE_SIZE 24</span></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">const</span> DenseLayer input_dense;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VAD_GRU_SIZE 24</span></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">const</span> GRULayer vad_gru;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NOISE_GRU_SIZE 48</span></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">const</span> GRULayer noise_gru;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DENOISE_GRU_SIZE 96</span></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">const</span> GRULayer denoise_gru;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DENOISE_OUTPUT_SIZE 22</span></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">const</span> DenseLayer denoise_output;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VAD_OUTPUT_SIZE 1</span></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">const</span> DenseLayer vad_output;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">RNNState</span> &#123;</span></span><br><span class="line">    <span class="keyword">float</span> vad_gru_state[VAD_GRU_SIZE];</span><br><span class="line">    <span class="keyword">float</span> noise_gru_state[NOISE_GRU_SIZE];</span><br><span class="line">    <span class="keyword">float</span> denoise_gru_state[DENOISE_GRU_SIZE];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>

<ul>
<li>机器学习和训练是RNNoise的灵魂，需要业务接入方根据自身的使用场景通过大量的数据集来找出最合适的处理集。</li>
</ul>
<h4 id="WebRTC降噪方案"><a href="#WebRTC降噪方案" class="headerlink" title="WebRTC降噪方案"></a>WebRTC降噪方案</h4><ul>
<li><p>WebRTC的代码是基于C++开源的，集成到Android中需要使用NDK。</p>
</li>
<li><p>WebRTC只能处理特定的采样率数据：8000、16000、32000、44100、48000，这个是其代码内部是写死的，需要自己实现音频重采样来满足WebRTC的降噪采样率需求。</p>
</li>
<li><p>根据WebRTC的降噪过程和业务接口流程，把接口定义成init、process、free三个接口。区别RNNoise的是需要在process中做增益处理，WebRTC降噪会降低数据的声音大小，通过增益用来补充声音大小。</p>
</li>
<li><p>在process数据时发现WebRTC的处理窗口大小必须是160或是320个byte，根据采样率不同窗口大小不同。这个和处理RNNoise是一致都只能传正整数倍数据，要不还是会新引入噪音数据。</p>
</li>
<li><p>WebRTC的降噪NS模块和增益AGC模块是独立的，为了一次数据完成两个过程需要组合数据，边降噪边增益，减少处理耗时。</p>
</li>
</ul>
<p>自定义调用WebRTC暴露的接口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  初始化降噪</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initProccesor</span><span class="params">()</span></span>&#123;</span><br><span class="line">    mProcessor = <span class="keyword">new</span> WebrtcProcessor();</span><br><span class="line">    mProcessor.init(frequency);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 处理需要降噪的音频数据</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> data</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processData</span><span class="params">(<span class="keyword">byte</span>[] data)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(mProcessor != <span class="keyword">null</span>)&#123;</span><br><span class="line">        mProcessor.processNoise(data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 处理需要降噪的音频数据</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> data</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processData</span><span class="params">(<span class="keyword">short</span>[] data)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(mProcessor != <span class="keyword">null</span>)&#123;</span><br><span class="line">        mProcessor.processNoise(data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 释放降噪资源</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">releaseProcessor</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(mProcessor != <span class="keyword">null</span>)&#123;</span><br><span class="line">        mProcessor.release();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>自定义降噪类WebrtcProcessor.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.jni;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> android.util.Log;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 音频降噪处理</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WebrtcProcessor</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//加载降噪库</span></span><br><span class="line">            System.loadLibrary(<span class="string">&quot;webrtc&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsatisfiedLinkError e) &#123;</span><br><span class="line">            Log.e(<span class="string">&quot;TAG&quot;</span>, <span class="string">&quot;Couldn&#x27;t load lib:   - &quot;</span> + e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理降噪</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processNoise</span><span class="params">(<span class="keyword">byte</span>[] data)</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span>(data == <span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">int</span> newDataLength = data.length/<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(data.length % <span class="number">2</span> == <span class="number">1</span>)&#123;</span><br><span class="line">            newDataLength += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//此处是将字节数据转换为short数据</span></span><br><span class="line">        <span class="keyword">short</span>[] newData = <span class="keyword">new</span> <span class="keyword">short</span>[newDataLength];</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;newDataLength; i++)&#123;</span><br><span class="line">            <span class="keyword">byte</span> low = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">byte</span> high = <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span>(<span class="number">2</span>*i &lt; data.length)&#123;</span><br><span class="line">                low = data[<span class="number">2</span>*i];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>((<span class="number">2</span>*i+<span class="number">1</span>) &lt; data.length)&#123;</span><br><span class="line">                high = data[<span class="number">2</span>*i+<span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            newData[i] = (<span class="keyword">short</span>) (((high &lt;&lt; <span class="number">8</span>) &amp; <span class="number">0xff00</span>) | (low &amp; <span class="number">0x00ff</span>));</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 交给底层处理</span></span><br><span class="line">        processNoise(newData);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//处理完之后, 又将short数据转换为字节数据</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;newDataLength; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(<span class="number">2</span>*i &lt; data.length)&#123;</span><br><span class="line">                data[<span class="number">2</span>*i] = (<span class="keyword">byte</span>) (newData[i] &amp; <span class="number">0xff</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>((<span class="number">2</span>*i+<span class="number">1</span>) &lt; data.length)&#123;</span><br><span class="line">                data[<span class="number">2</span>*i+<span class="number">1</span>] = (<span class="keyword">byte</span>) ((newData[i] &gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xff</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化降噪设置</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sampleRate 采样率</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 是否初始化成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">init</span><span class="params">(<span class="keyword">int</span> sampleRate)</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理降噪</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">boolean</span> <span class="title">processNoise</span><span class="params">(<span class="keyword">short</span>[] data)</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  释放降噪资源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>只使用的话上述代码已足够，下面稍微看一下源码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;audio_ns.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;noise_suppression.h&quot;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//此处是为了里面的底层方法能被java层识别</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//降噪的实例,句柄</span></span><br><span class="line">    NsHandle* handle = <span class="literal">NULL</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//降噪处理</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">innerProcess</span><span class="params">(<span class="keyword">short</span> in_sample[], <span class="keyword">short</span> out_sample[], <span class="keyword">int</span> length)</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">int</span> curPosition = <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//此处以80为单位, 依次调用audio_ns_process处理数据,因为这个方法一次只能处理80个short音频数据</span></span><br><span class="line">        <span class="keyword">while</span>(curPosition &lt; length)&#123;</span><br><span class="line">            <span class="built_in">audio_ns_process</span>((<span class="keyword">int</span>) handle, in_sample + curPosition, out_sample + curPosition);</span><br><span class="line">            curPosition += <span class="number">80</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function">JNIEXPORT jboolean JNICALL</span></span><br><span class="line"><span class="function">    <span class="title">Java_com_test_jni_WebrtcProcessor_init</span><span class="params">(JNIEnv *env, jobject instance, jint sample_rate)</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//初始化降噪实例</span></span><br><span class="line">        handle = (NsHandle *) <span class="built_in">audio_ns_init</span>(sample_rate);</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function">JNIEXPORT jboolean JNICALL</span></span><br><span class="line"><span class="function">    <span class="title">Java_com_test_jni_WebrtcProcessor_processNoise</span><span class="params">(JNIEnv *env, jobject instance, jshortArray sample)</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span>(!handle)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//获取数据长度</span></span><br><span class="line">        jsize length = env-&gt;<span class="built_in">GetArrayLength</span>(sample);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//转换为jshort数组</span></span><br><span class="line">        jshort *sam = env-&gt;<span class="built_in">GetShortArrayElements</span>(sample, <span class="number">0</span>);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//将sam的数据全部复制给新的in_sample</span></span><br><span class="line">        <span class="keyword">short</span> in_sample[length];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;length; i++)&#123;</span><br><span class="line">            in_sample[i] = sam[i];</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//传入in_sample作为需要处理音频数据, 处理之后的数据返回到sam中</span></span><br><span class="line">        <span class="built_in">innerProcess</span>(in_sample, sam, length);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//将sam中的数据,再转换回sample中</span></span><br><span class="line">        env-&gt;<span class="built_in">ReleaseShortArrayElements</span>(sample, sam, <span class="number">0</span>);</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function">JNIEXPORT <span class="keyword">void</span> JNICALL</span></span><br><span class="line"><span class="function">    <span class="title">Java_com_test_jni_WebrtcProcessor_release</span><span class="params">(JNIEnv *env, jobject instance)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 释放降噪资源</span></span><br><span class="line">        <span class="keyword">if</span>(handle)&#123;</span><br><span class="line">            <span class="built_in">audio_ns_destroy</span>((<span class="keyword">int</span>) handle);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码实际上WebRTC降噪一次性只处理了80个short数据（在8000采样率中是这样的），意思就是说WebRTC每次只能处理10毫秒，0.01秒的数据。那么依次类推，针对44100采样率的数据处理的话，每次能处理的数据长度就应该是441个short数据了。</p>
<p>WebRTC的降噪是如何初始化和处理</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;audio_ns.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;noise_suppression.h&quot;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">audio_ns_init</span><span class="params">(<span class="keyword">int</span> sample_rate)</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">    NsHandle* NS_instance;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line">    <span class="comment">//创建WebRtcNs实例</span></span><br><span class="line">    <span class="keyword">if</span> ((ret = <span class="built_in">WebRtcNs_Create</span>(&amp;NS_instance) )) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;WebRtcNs_Create failed with error code = %d&quot;</span>, ret);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//初始化WebRtcNs实例,此处需要指定采样,告诉它一次可以处理多少个short音频数据,</span></span><br><span class="line">    <span class="comment">//如果是8000, 则一次可以处理80,如果是44100, 则一次可以处理441个</span></span><br><span class="line">    <span class="comment">//也就是说,一次性可以处理10ms时间的数据</span></span><br><span class="line">    <span class="keyword">if</span> ((ret = <span class="built_in">WebRtcNs_Init</span>(NS_instance, sample_rate) )) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;WebRtcNs_Init failed with error code = %d&quot;</span>, ret);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//设置降噪的力度,0,1,2, 0最弱,2最强</span></span><br><span class="line">    <span class="keyword">if</span> (( ret =  <span class="built_in">WebRtcNs_set_policy</span>(NS_instance, <span class="number">2</span>)))&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;WebRtcNs_set_policy failed with error code = %d&quot;</span>, ret);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">int</span>)NS_instance;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">audio_ns_process</span><span class="params">(<span class="keyword">int</span> ns_handle ,  <span class="keyword">short</span> *src_audio_data ,<span class="keyword">short</span> *dest_audio_data)</span></span>&#123;</span><br><span class="line">    <span class="comment">//get handle</span></span><br><span class="line">    NsHandle* NS_instance = (NsHandle* )ns_handle;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//noise suppression</span></span><br><span class="line">    <span class="keyword">if</span>(</span><br><span class="line">        <span class="comment">//此处这么做,是因为,真正的WebRtcNs_Process,一次只能处理80个shorts音频数据</span></span><br><span class="line">        <span class="built_in">WebRtcNs_Process</span>(NS_instance ,src_audio_data ,<span class="literal">NULL</span> ,dest_audio_data , <span class="literal">NULL</span>) ||</span><br><span class="line">        <span class="built_in">WebRtcNs_Process</span>(NS_instance ,&amp;src_audio_data[<span class="number">80</span>] ,<span class="literal">NULL</span> ,&amp;dest_audio_data[<span class="number">80</span>] , <span class="literal">NULL</span>) )&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;WebRtcNs_Process failed with error code = &quot;</span> );</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">audio_ns_destroy</span><span class="params">(<span class="keyword">int</span> ns_handle)</span></span>&#123;</span><br><span class="line">    <span class="comment">//释放WebRtcNs资源</span></span><br><span class="line">    <span class="built_in">WebRtcNs_Free</span>((NsHandle *) ns_handle);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具体的降噪细节在WebRtcNs_Process()函数中，具体算法细节笔者浅尝辄止，下述仅简述思路：</p>
<p>把前50帧的数据拿来构建噪声模型，把前200帧的信号强度用来计算归一化的频谱差值计算。根据这两个模型使用概率目的函数来计算出每帧的信噪比并区分出噪声和声音，然后根据计算出的信噪比在频域使用维纳滤波器对噪声信号进行噪声消除，最后在根据降噪前后的能量比和信号噪声似然比对降噪后的数据进行修复和调整后输出。</p>
<h4 id="两种降噪方案集成优缺点对比"><a href="#两种降噪方案集成优缺点对比" class="headerlink" title="两种降噪方案集成优缺点对比"></a>两种降噪方案集成优缺点对比</h4><p>目前WebRTC最新代码只支持采样率为8000、16000、32000、44100、48000的音频进行降噪，针对其余的采样率需要进行数据重采样到上述采样率之后进行降噪，处理完毕之后需要再次恢复原采样率；RNNoise对采样率没有要求，可以适配常见的采样率。</p>
<p>WebRTC在降噪之后还需要对数据进行增益处理，但是增益会增大电流音，效果会稍差些。</p>
<p>WebRTC处理数据的buffer目前代码是320的整数倍；RNNoise处理数据的buffer目前代码是480的整数倍。输入的buffer需是固定大小的，如果不是正整数倍，需要外部在传入时处理下。</p>
<p>从代码复杂度看，WebRTC的代码是多于RNNoise代码的。RNNoise支持机器学习，通过机器学习生成rnn_data.h和rnn_data.c文件来匹配不同的降噪效果。</p>
<p>降噪耗时对比，RNNoise处理3840字节的buffer数据耗时大概在6ms左右，但在开始时耗时在30ms左右，递减到6ms并稳定；WebRTC处理3840字节的buffer数据耗时大概在2ms左右，但在开始时耗时在10ms左右，递减到2ms并稳定。对比发现WebRTC处理效率更好些。</p>
<p>从处理流程上看都是需要init、process、free操作的，对接入方接入成本是一致的。</p>
<h4 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h4><p>RNN（循环神经网络Recurrent Neural Networks，上）和LSTM（长短期记忆Long Short Term Memory，下）</p>
<img src="/555ed0ac/2.jpg" class>

<img src="/555ed0ac/3.jpg" class>

<hr>
<h3 id="变音"><a href="#变音" class="headerlink" title="变音"></a>变音</h3><p>对于变声的处理一般有以下三种：</p>
<h4 id="变速又变调"><a href="#变速又变调" class="headerlink" title="变速又变调"></a>变速又变调</h4><p>即改变音频的速度（语速），又改变音频的频率（音调）</p>
<p>我们可以对原始音频进行重采样，重采样有上采样和下采样，分别是对原始音频进行插值和抽取，比如P/Q重采样，一般我们的处理是，先对原始音频进行插值，在相邻两点间插入P个采样点，全部插入结束后再每隔Q个采样点进行采样，这样得到的音频语速和音调都是原来的Q/P倍</p>
<p>变调又变速（提高）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 变调又变速（提高）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] up(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> up) &#123;</span><br><span class="line">    <span class="keyword">if</span> (up == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> data;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> length = data.length;</span><br><span class="line">    <span class="keyword">int</span> upLength = length / up;</span><br><span class="line">    <span class="keyword">byte</span>[] upData = <span class="keyword">new</span> <span class="keyword">byte</span>[upLength];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i &lt; length; ) &#123;</span><br><span class="line">        <span class="keyword">if</span> (j &gt;= upLength) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        upData[j] = data[i];</span><br><span class="line">        i += up;</span><br><span class="line">        j++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> upData;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>变调又变速（降低）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] down(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> down) &#123;</span><br><span class="line">    <span class="keyword">if</span> (down == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> data;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> length = data.length;</span><br><span class="line">    <span class="keyword">int</span> downLength = length * down;</span><br><span class="line">    <span class="keyword">byte</span>[] downData = <span class="keyword">new</span> <span class="keyword">byte</span>[downLength];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i &lt; length - <span class="number">1</span>; ) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; down; k++) &#123;</span><br><span class="line">            downData[j] = data[i];</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        i++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> downData;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="变速不变调"><a href="#变速不变调" class="headerlink" title="变速不变调"></a>变速不变调</h4><p>只改变语速，不改变音调</p>
<p>只是改变语速的话，那么就要稍微复杂点，和重采样方法差不多，区别在于我们需要先规定一帧音频的长度，一般我们的采样率设为44.1KHz，也就是一秒钟采样44.1K次，我们可以规定一帧为1024，所有我们可以简单的根据丢帧和重复帧来实现变速不变调，比如对于P/Q变速，我们先对原始音频的每一帧重复P次，最后的结果再进行每隔Q帧取一帧，这样就得到音频音调不变，语速变为Q/P的音频</p>
<p>变速不变调（提高）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] speedUp(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> up) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> FRAME_LENGTH = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">if</span> (up == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> data;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> length = data.length;</span><br><span class="line">    <span class="keyword">int</span> frameShift = FRAME_LENGTH * up;</span><br><span class="line">    <span class="keyword">int</span> upLength = length / up;</span><br><span class="line">    <span class="keyword">byte</span>[] upData = <span class="keyword">new</span> <span class="keyword">byte</span>[upLength];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i &lt; length; ) &#123;</span><br><span class="line">        <span class="keyword">if</span> (i + FRAME_LENGTH &gt;= length) &#123;</span><br><span class="line">            System.arraycopy(data, i, upData, j, length - i);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        System.arraycopy(data, i, upData, j, FRAME_LENGTH);</span><br><span class="line">        i += (FRAME_LENGTH + frameShift);</span><br><span class="line">        j += FRAME_LENGTH;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> upData;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>变速不变调（降低）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] speedDown(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> down) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> FRAME_LENGTH = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">if</span> (down == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> data;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> length = data.length;</span><br><span class="line">    <span class="keyword">int</span> downLength = length * down;</span><br><span class="line">    <span class="keyword">byte</span>[] downData = <span class="keyword">new</span> <span class="keyword">byte</span>[downLength];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i &lt; length; ) &#123;</span><br><span class="line">        <span class="keyword">if</span> (i + FRAME_LENGTH &gt;= length) &#123;</span><br><span class="line">            <span class="keyword">int</span> lastlength = length - i;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; down; k++) &#123;</span><br><span class="line">                System.arraycopy(data, lastlength, downData, j, lastlength);</span><br><span class="line">                j += lastlength;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; down; k++) &#123;</span><br><span class="line">            System.arraycopy(data, i, downData, j, FRAME_LENGTH);</span><br><span class="line">            j += FRAME_LENGTH;</span><br><span class="line">        &#125;</span><br><span class="line">        i += FRAME_LENGTH;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> downData;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="变调不变速"><a href="#变调不变速" class="headerlink" title="变调不变速"></a>变调不变速</h4><p>只改变音调，不改变语速</p>
<p>如果只是变调的话，就要结合重采样和变速不变调来做，我们先对音频信号进行变速不变调处理，再对其进行重采样，比如，我想要让音调变为原来的P/Q倍，那么我们需要先对其进行P/Q变速不变调，语速变为原来的Q/P，接着，在对其进行Q/P重采样，这样，最后就得到了语速不变，而音调变为原来的P/Q倍</p>
<p>设置语速</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] setSpeed(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> up, <span class="keyword">int</span> down) &#123;</span><br><span class="line">    <span class="keyword">byte</span>[] downData = speedDown(data, down);</span><br><span class="line">    <span class="keyword">byte</span>[] upData = speedUp(downData, up);</span><br><span class="line">    <span class="keyword">return</span> upData;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>设置音调</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] setTone(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> up, <span class="keyword">int</span> down) &#123;</span><br><span class="line">    <span class="keyword">byte</span>[] speedData = setSpeed(data, down, up);</span><br><span class="line">    <span class="keyword">byte</span>[] downData = down(speedData, down);</span><br><span class="line">    <span class="keyword">byte</span>[] upData = up(downData, up);</span><br><span class="line">    <span class="keyword">return</span> upData;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>例如，将up设为4，down设为5，声音就变得低沉。</p>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-读论文(PART Theory)</title>
    <url>/13ded1b5.html</url>
    <content><![CDATA[<p>更多论文请见：<a href="https://github.com/mli/paper-reading">https://github.com/mli/paper-reading</a></p>
<hr>
<h3 id="如何读论文-2021-10-6"><a href="#如何读论文-2021-10-6" class="headerlink" title="如何读论文 (2021-10-6)"></a>如何读论文 (2021-10-6)</h3><iframe src="//player.bilibili.com/player.html?aid=975879338&bvid=BV1H44y1t75x&cid=423711758&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<h3 id="如何找研究想法-1-2021-12-10"><a href="#如何找研究想法-1-2021-12-10" class="headerlink" title="如何找研究想法 1 (2021-12-10)"></a>如何找研究想法 1 (2021-12-10)</h3><iframe src="//player.bilibili.com/player.html?aid=592148502&bvid=BV1qq4y1z7F2&cid=457987672&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="如何判断（你自己的）研究工作的价值-2022-01-19"><a href="#如何判断（你自己的）研究工作的价值-2022-01-19" class="headerlink" title="如何判断（你自己的）研究工作的价值 (2022-01-19)"></a>如何判断（你自己的）研究工作的价值 (2022-01-19)</h3><iframe src="//player.bilibili.com/player.html?aid=465786953&bvid=BV1oL411c7Us&cid=487717373&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="你（被）吐槽过论文不够-novel-吗？-2022-02-07"><a href="#你（被）吐槽过论文不够-novel-吗？-2022-02-07" class="headerlink" title="你（被）吐槽过论文不够 novel 吗？ (2022-02-07)"></a>你（被）吐槽过论文不够 novel 吗？ (2022-02-07)</h3><iframe src="//player.bilibili.com/player.html?aid=211258873&bvid=BV1ea41127Bq&cid=502265464&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="跟读者建立联系【研究的艺术·一】-2022-06-24"><a href="#跟读者建立联系【研究的艺术·一】-2022-06-24" class="headerlink" title="跟读者建立联系【研究的艺术·一】 (2022-06-24)"></a>跟读者建立联系【研究的艺术·一】 (2022-06-24)</h3><iframe src="//player.bilibili.com/player.html?aid=257648884&bvid=BV1hY411T7vy&cid=752569504&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="明白问题的重要性【研究的艺术·二】-2022-07-01"><a href="#明白问题的重要性【研究的艺术·二】-2022-07-01" class="headerlink" title="明白问题的重要性【研究的艺术·二】 (2022-07-01)"></a>明白问题的重要性【研究的艺术·二】 (2022-07-01)</h3><iframe src="//player.bilibili.com/player.html?aid=727683126&bvid=BV11S4y1v7S2&cid=753356845&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="讲好故事、论点【研究的艺术·三】-2022-07-15"><a href="#讲好故事、论点【研究的艺术·三】-2022-07-15" class="headerlink" title="讲好故事、论点【研究的艺术·三】 (2022-07-15)"></a>讲好故事、论点【研究的艺术·三】 (2022-07-15)</h3><iframe src="//player.bilibili.com/player.html?aid=598414840&bvid=BV1WB4y1v7ST&cid=773589171&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="理由、论据和担保【研究的艺术·四】-2022-07-22"><a href="#理由、论据和担保【研究的艺术·四】-2022-07-22" class="headerlink" title="理由、论据和担保【研究的艺术·四】 (2022-07-22)"></a>理由、论据和担保【研究的艺术·四】 (2022-07-22)</h3><iframe src="//player.bilibili.com/player.html?aid=601089966&bvid=BV1SB4y1a75c&cid=778243309&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-音频开发-（五）音频播放</title>
    <url>/a580305f.html</url>
    <content><![CDATA[<h3 id="AudioTrack"><a href="#AudioTrack" class="headerlink" title="AudioTrack"></a>AudioTrack</h3><p>AudioTrack属于更偏底层的音频播放，MediaPlayerService的内部就是使用了AudioTrack。</p>
<p>AudioTrack用于单个音频播放和管理，相比于MediaPlayer具有精炼、高效的优点，更适合实时产生播放数据的情况。如加密的音频， MediaPlayer是束手无策的，AudioTrack却可以。</p>
<p>AudioTrack用于播放PCM（PCM无压缩的音频格式）音乐流的回放，如果需要播放其它格式音频，需要响应的解码器，这也是AudioTrack用的比较少的原因，需要自己解码音频。</p>
<span id="more"></span>

<h4 id="AudioTrack实现PCM音频播放"><a href="#AudioTrack实现PCM音频播放" class="headerlink" title="AudioTrack实现PCM音频播放"></a>AudioTrack实现PCM音频播放</h4><ol>
<li><p>配置基本参数</p>
</li>
<li><p>获取最小缓冲区大小</p>
</li>
<li><p>创建AudioTrack对象</p>
</li>
<li><p>获取PCM文件，转成DataInputStream</p>
</li>
<li><p>开启/停止播放</p>
</li>
</ol>
<h4 id="AudioTrack常见参数"><a href="#AudioTrack常见参数" class="headerlink" title="AudioTrack常见参数"></a>AudioTrack常见参数</h4><p>StreamType 音频流类型：区分系统不同功能的音频流。</p>
<p>sampleRateInHz 采样率：播放的音频每秒钟会有多少次采样，MediaRecoder 的采样率通常是8000Hz AAC的通常是44100Hz。 设置采样率为44100为常用的采样率。</p>
<p>channelConfig 声道数（通道数）：一般可选的就两种，单声道CHANNEL_IN_MONO，双声道CHANNEL_IN_STEREO，建议选择单声道。</p>
<p>audioFormat 数据位宽：只支持AudioFormat.ENCODING_PCM_8BIT（8bit）和AudioFormat.ENCODING_PCM_16BIT（16bit）两种，后者支持所有Android手机。</p>
<p>bufferSizeInBytes 音频缓冲区大小：建议使用AudioTrack.getMinBufferSize()这个方法获取。</p>
<p>mode 播放模式：MODE_STATIC，一次性将所有数据都写入播放缓冲区中，简单高效，一般用于铃声，系统提醒音，内存比较小的。MODE_STREAM，需要按照一定的时间间隔，不断的写入音频数据，理论上它可以应用于任何音频播放的场景。</p>
<h4 id="AudioTrack例子：播放录音"><a href="#AudioTrack例子：播放录音" class="headerlink" title="AudioTrack例子：播放录音"></a>AudioTrack例子：播放录音</h4><p>播放录音playAudio()和播放测试音频playAudioTest()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">playAudio</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!mIsPlaying) &#123;</span><br><span class="line">        mExecutorService.submit(() -&gt; &#123;</span><br><span class="line">            mIsPlaying = <span class="keyword">true</span>;</span><br><span class="line">            doStartPlay(getLastFile());</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">playAudioTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (mHasPausing &amp;&amp; !mIsPausing &amp;&amp; mAudioTrack != <span class="keyword">null</span>) &#123;</span><br><span class="line">        mIsPausing = <span class="keyword">true</span>;</span><br><span class="line">        mAudioTrack.stop();</span><br><span class="line">        mBtStreamPlayerTest.setText(<span class="string">&quot;播放测试录音&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mIsPlaying) &#123;</span><br><span class="line">        Toast.makeText(mContext, <span class="string">&quot;正在播放&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        mBtStreamPlayerTest.setText(<span class="string">&quot;暂停测试录音&quot;</span>);</span><br><span class="line">        mExecutorService.submit(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.KITKAT) &#123;</span><br><span class="line">                mHasPausing = <span class="keyword">true</span>;</span><br><span class="line">                mIsPausing = <span class="keyword">false</span>;</span><br><span class="line">                mIsPlaying = <span class="keyword">true</span>;</span><br><span class="line">                doStartPlay(<span class="keyword">new</span> File(mContext.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS) + <span class="string">&quot;/AudioRecordDemo/test.pcm&quot;</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一个算法，获得文件夹里最新更新的文件getLastFile()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> File <span class="title">getLastFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    File realFile = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (android.os.Build.VERSION.SDK_INT &gt;= android.os.Build.VERSION_CODES.KITKAT) &#123;</span><br><span class="line">        realFile = <span class="keyword">new</span> File(mContext.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS) + <span class="string">&quot;/AudioRecordDemo/&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (realFile.isDirectory()) &#123;</span><br><span class="line">        List files = <span class="keyword">new</span> ArrayList();</span><br><span class="line">        File[] subFiles = realFile.listFiles();</span><br><span class="line">        <span class="keyword">for</span> (File file : subFiles) &#123;</span><br><span class="line">            files.add(file);</span><br><span class="line">        &#125;</span><br><span class="line">        Collections.sort(files, (Comparator&lt;File&gt;) (file, newFile) -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (file.lastModified() &lt; newFile.lastModified()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (file.lastModified() == newFile.lastModified()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        Log.d(TAG, <span class="string">&quot;play &quot;</span> + ((File) files.get(<span class="number">0</span>)).toString());</span><br><span class="line">        <span class="keyword">return</span> (File) files.get(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>播放录音具体实现，AudioTrack的使用doStartPlay()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doStartPlay</span><span class="params">(File audioRecordFile)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (audioRecordFile == <span class="keyword">null</span>) &#123;</span><br><span class="line">        Log.d(TAG, <span class="string">&quot;请先录制音频！&quot;</span>);</span><br><span class="line">        mIsPlaying = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 配置播放器</span></span><br><span class="line">    <span class="comment">// 音乐类型，扬声器播放</span></span><br><span class="line">    <span class="keyword">int</span> streamType = AudioManager.STREAM_MUSIC;</span><br><span class="line">    <span class="comment">// 录音时采用的采样频率，所以播放时同样的采样频率</span></span><br><span class="line">    <span class="keyword">int</span> sampleRate = <span class="number">44100</span>;</span><br><span class="line">    <span class="comment">// 单声道，和录音时设置的一样</span></span><br><span class="line">    <span class="keyword">int</span> channelConfig = AudioFormat.CHANNEL_OUT_MONO;</span><br><span class="line">    <span class="comment">// 录音时使用16bit，所以播放时同样采用该方式</span></span><br><span class="line">    <span class="keyword">int</span> audioFormat = AudioFormat.ENCODING_PCM_16BIT;</span><br><span class="line">    <span class="comment">// 流模式</span></span><br><span class="line">    <span class="keyword">int</span> mode = AudioTrack.MODE_STREAM;</span><br><span class="line">    <span class="comment">// 计算最小buffer大小</span></span><br><span class="line">    <span class="keyword">int</span> minBufferSize = AudioTrack.getMinBufferSize(sampleRate, channelConfig, audioFormat);</span><br><span class="line">    <span class="comment">// 构造AudioTrack 不能小于AudioTrack的最低要求，也不能小于我们每次读的大小</span></span><br><span class="line">    mAudioTrack = <span class="keyword">new</span> AudioTrack(streamType, sampleRate, channelConfig, audioFormat,</span><br><span class="line">            Math.max(minBufferSize, BUFFER_SIZE), mode);</span><br><span class="line">    <span class="comment">// 从文件流读数据</span></span><br><span class="line">    FileInputStream fis = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 循环读数据，写到播放器去播放</span></span><br><span class="line">        fis = <span class="keyword">new</span> FileInputStream(audioRecordFile);</span><br><span class="line">        fis.skip(mOffset);</span><br><span class="line">        Log.d(TAG, audioRecordFile.toString());</span><br><span class="line">        <span class="comment">// 循环读数据，写到播放器去播放 只要没读完，循环播放</span></span><br><span class="line">        <span class="keyword">int</span> read;</span><br><span class="line">        mAudioTrack.play();</span><br><span class="line">        Log.d(TAG, String.valueOf(mAudioTrack.getPlayState()));</span><br><span class="line">        <span class="comment">// write 是阻塞的方法</span></span><br><span class="line">        <span class="keyword">while</span> ((read = fis.read(mBuffer)) != -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="comment">// todo: 处理mBuffer实现元数据处理变音等功能</span></span><br><span class="line">            <span class="keyword">int</span> status = mAudioTrack.write(mBuffer, <span class="number">0</span>, read);</span><br><span class="line">            updateOffset(read);</span><br><span class="line">            Log.d(TAG, String.valueOf(mOffset));</span><br><span class="line">            <span class="comment">// 检查write的返回值，处理错误</span></span><br><span class="line">            checkStatus(status);</span><br><span class="line">        &#125;</span><br><span class="line">        Log.d(TAG, <span class="string">&quot;播放完毕！&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">        <span class="comment">// 读取失败</span></span><br><span class="line">        playFail();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mIsPlaying = <span class="keyword">false</span>;</span><br><span class="line">        <span class="comment">// 关闭文件输入流</span></span><br><span class="line">        closeInputStream(fis);</span><br><span class="line">        <span class="comment">// 播放器释放</span></span><br><span class="line">        resetQuietly(mAudioTrack);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateOffset</span><span class="params">(<span class="keyword">int</span> read)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (mAudioTrack.getPlayState() == mAudioTrack.PLAYSTATE_PLAYING) &#123;</span><br><span class="line">        mOffset += read;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>关闭输入流closeInputStream()和resetQuietly()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">closeInputStream</span><span class="params">(InputStream is)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (is != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            is.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">resetQuietly</span><span class="params">(AudioTrack audioTrack)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        audioTrack.stop();</span><br><span class="line">        audioTrack.release();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>播放失败，更新UI操作playFail()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">playFail</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    mHandler.post(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            Toast.makeText(mContext, <span class="string">&quot;pcm播放失败&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>onDestroy()释放资源</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">    <span class="keyword">if</span> (mAudioTrackTest.getAudioTrack() != <span class="keyword">null</span>) &#123;</span><br><span class="line">        mAudioTrackTest.getAudioTrack().stop();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mExecutorService != <span class="keyword">null</span>) &#123;</span><br><span class="line">        mExecutorService.shutdownNow();</span><br><span class="line">        mExecutorService = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="MediaPlayer"><a href="#MediaPlayer" class="headerlink" title="MediaPlayer"></a>MediaPlayer</h3><img src="/a580305f/1.jpg" class>

<p>MediaPlayer支持AAC、AMR、FLAC、MP3、MIDI、OGG、PCM等格式，MediaPlayer可以通过设置元数据和播放源来音频。</p>
<p>播放Raw文件夹下面音频的元数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 直接创建，不需要设置setDataSource</span></span><br><span class="line">MediaPlayer mMediaPlayer;</span><br><span class="line">mMediaPlayer=MediaPlayer.create(<span class="keyword">this</span>, R.raw.audio);</span><br><span class="line">mMediaPlayer.start();</span><br></pre></td></tr></table></figure>

<h4 id="通过设置播放源来播放音频文件的三个方法"><a href="#通过设置播放源来播放音频文件的三个方法" class="headerlink" title="通过设置播放源来播放音频文件的三个方法"></a>通过设置播放源来播放音频文件的三个方法</h4><ul>
<li>setDataSource(String path)</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 如果从sd卡中加载音乐</span></span><br><span class="line"><span class="comment">// &lt;uses-permission android:name=&quot;android.permission.READ_EXTERNAL_STORAGE&quot;/&gt;</span></span><br><span class="line"><span class="comment">// 利用 Environment.getExternalStorageDirectory() 获取SD卡的根目录了，一般为/storage/emulated/0</span></span><br><span class="line"><span class="comment">// 把xxx.wav放到SD的根目录下，就可以获得文件的路径了 String path = Environment.getExternalStorageDirectory()+&quot;/xxx.wav&quot;;</span></span><br><span class="line">mMediaPlayer.setDataSource(path);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 如果从网络加载音乐，如果是从网络中加载那么需要设置网络权限</span></span><br><span class="line"><span class="comment">// &lt;uses-permission android:name=&quot;android.permission.INTERNET&quot;/&gt;</span></span><br><span class="line">mMediaPlayer.setDataSource(<span class="string">&quot;http://..../xxx.mp3&quot;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 需使用异步缓冲</span></span><br><span class="line">mMediaPlayer.prepareAsync();</span><br></pre></td></tr></table></figure>

<ul>
<li>setDataSource(FileDescriptor fd)</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 资源文件放在assets文件夹</span></span><br><span class="line">AssetFileDescriptor fd = getAssets().openFd(<span class="string">&quot;samsara.mp3&quot;</span>);</span><br><span class="line">mMediaPlayer.setDataSource(fd.getFileDescriptor());</span><br><span class="line">mMediaPlayer.prepare();</span><br></pre></td></tr></table></figure>

<ul>
<li>setDataSource(FileDescptor fd,long offset,long length)</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 需将资源文件放在assets文件夹</span></span><br><span class="line">AssetFileDescriptor fd = getAssets().openFd(<span class="string">&quot;samsara.mp3&quot;</span>);</span><br><span class="line">mMediaPlayer.setDataSource(fd.getFileDescriptor(), fd.getStartOffset(), fd.getLength());</span><br><span class="line">mMediaPlayer.prepare();</span><br></pre></td></tr></table></figure>

<p>设置完数据源，不要忘记prepare()，尽量使用异步prepareAync()，这样不会阻塞UI线程。</p>
<h4 id="MediaPlayer例子：播放录音"><a href="#MediaPlayer例子：播放录音" class="headerlink" title="MediaPlayer例子：播放录音"></a>MediaPlayer例子：播放录音</h4><p>播放录音playMedia()和播放测试音频playMediaTest()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">playMedia</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!mIsPlaying) &#123;</span><br><span class="line">        mExecutorService.submit(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                mIsPlaying = <span class="keyword">true</span>;</span><br><span class="line">                doPlay(getLastFile());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Toast.makeText(mContext, <span class="string">&quot;正在播放&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">playMediaTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (mHasPausing &amp;&amp; mMediaPlayer != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (mMediaPlayer.isPlaying()) &#123;</span><br><span class="line">            mMediaPlayer.pause();</span><br><span class="line">            mBtMediaPlayerTest.setText(<span class="string">&quot;播放测试录音&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            mMediaPlayer.start();</span><br><span class="line">            mBtMediaPlayerTest.setText(<span class="string">&quot;暂停测试录音&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mIsPlaying) &#123;</span><br><span class="line">        Toast.makeText(mContext, <span class="string">&quot;正在播放&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        mBtMediaPlayerTest.setText(<span class="string">&quot;暂停测试录音&quot;</span>);</span><br><span class="line">        mExecutorService.submit(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">if</span> (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.KITKAT) &#123;</span><br><span class="line">                    mHasPausing = <span class="keyword">true</span>;</span><br><span class="line">                    mIsPlaying = <span class="keyword">true</span>;</span><br><span class="line">                    doPlay(<span class="keyword">new</span> File(mContext.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS) + <span class="string">&quot;/MediaRecorderDemo/test.m4a&quot;</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具体播放方法doPlay()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doPlay</span><span class="params">(File mediaFile)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 配置播放器 MediaPlayer</span></span><br><span class="line">        mMediaPlayer = <span class="keyword">new</span> MediaPlayer();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 设置声音文件</span></span><br><span class="line">        mMediaPlayer.setDataSource(mediaFile.getAbsolutePath());</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 配置音量,中等音量</span></span><br><span class="line">        mMediaPlayer.setVolume(<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 播放是否循环</span></span><br><span class="line">        mMediaPlayer.setLooping(<span class="keyword">false</span>);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 设置监听回调 播放完毕</span></span><br><span class="line">        mMediaPlayer.setOnCompletionListener(<span class="keyword">new</span> MediaPlayer.OnCompletionListener() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(MediaPlayer mp)</span> </span>&#123;</span><br><span class="line">                Log.d(TAG, <span class="string">&quot;播放完毕！&quot;</span>);</span><br><span class="line">                stopPlayer();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        mMediaPlayer.setOnErrorListener(<span class="keyword">new</span> MediaPlayer.OnErrorListener() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">onError</span><span class="params">(MediaPlayer mp, <span class="keyword">int</span> what, <span class="keyword">int</span> extra)</span> </span>&#123;</span><br><span class="line">                stopPlayer();</span><br><span class="line">                Toast.makeText(mContext, <span class="string">&quot;播放失败&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 设置播放</span></span><br><span class="line">        mMediaPlayer.prepare();</span><br><span class="line">        mMediaPlayer.start();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 异常处理，防止闪退</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">        stopPlayer();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>播放结束关闭播放器stopPlayer()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">stopPlayer</span><span class="params">()</span></span>&#123;</span><br><span class="line">    mIsPlaying = <span class="keyword">false</span>;</span><br><span class="line">    mMediaPlayer.reset();</span><br><span class="line">    mMediaPlayer.release();</span><br><span class="line">    mMediaPlayer = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="SoundPool"><a href="#SoundPool" class="headerlink" title="SoundPool"></a>SoundPool</h3><p>SoundPool支持多个音频文件同时播放（组合音频也是有上限的），延时短，比较适合短促、密集的场景，适合游戏开发中音效播放。</p>
<h4 id="SoundPool实例化方式"><a href="#SoundPool实例化方式" class="headerlink" title="SoundPool实例化方式"></a>SoundPool实例化方式</h4><p>new SoundPool（适用与5.0以下）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> SoundPool(<span class="keyword">int</span> maxStreams, <span class="keyword">int</span> streamType, <span class="keyword">int</span> srcQuality)</span><br><span class="line"><span class="comment">// 从android5.0开始此方法被标记为过时</span></span><br><span class="line"><span class="comment">// maxStreams: 允许同时播放的流的最大值</span></span><br><span class="line"><span class="comment">// streamType: 音频流的类型描述</span></span><br><span class="line"><span class="comment">// srcQuality: 采样率转化质量，默认值为0</span></span><br></pre></td></tr></table></figure>

<p>SoundPool.Builder（从5.0开始支持）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//设置描述音频流信息的属性</span></span><br><span class="line">AudioAttributes abs = <span class="keyword">new</span> AudioAttributes.Builder()</span><br><span class="line">                .setUsage(AudioAttributes.USAGE_MEDIA)</span><br><span class="line">                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)</span><br><span class="line">                .build();</span><br><span class="line">SoundPool mSoundPoll = <span class="keyword">new</span> SoundPool.Builder()</span><br><span class="line">                .setMaxStreams(<span class="number">100</span>)   <span class="comment">//设置允许同时播放的流的最大值</span></span><br><span class="line">                .setAudioAttributes(abs)</span><br><span class="line">                .build();</span><br></pre></td></tr></table></figure>

<h4 id="SoundPool一些重要方法"><a href="#SoundPool一些重要方法" class="headerlink" title="SoundPool一些重要方法"></a>SoundPool一些重要方法</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 几个load方法和上文提到的MediaPlayer基本一致，这里的每个load都会返回一个SoundId值，这个值可以用来播放和卸载音乐。</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">load</span><span class="params">(AssetFileDescriptor afd, <span class="keyword">int</span> priority)</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">load</span><span class="params">(Context context, <span class="keyword">int</span> resId, <span class="keyword">int</span> priority)</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">load</span><span class="params">(String path, <span class="keyword">int</span> priority)</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">load</span><span class="params">(FileDescriptor fd, <span class="keyword">long</span> offset, <span class="keyword">long</span> length, <span class="keyword">int</span> priority)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 通过流id暂停播放</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">pause</span><span class="params">(<span class="keyword">int</span> streamID)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 播放声音，soundID:音频id（这个id来自load的返回值）； left/rightVolume:左右声道(默认1,1)；loop:循环次数(-1无限循环，0代表不循环)；rate:播放速率(1为标准)，该方法会返回一个streamID,如果StreamID为0表示播放失败，否则为播放成功</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">int</span> <span class="title">play</span><span class="params">(<span class="keyword">int</span> soundID, <span class="keyword">float</span> leftVolume, <span class="keyword">float</span> rightVolume, <span class="keyword">int</span> priority, <span class="keyword">int</span> loop, <span class="keyword">float</span> rate)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//释放资源(很重要)</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//恢复播放</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">resume</span><span class="params">(<span class="keyword">int</span> streamID)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//设置指定id的音频循环播放次数</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">setLoop</span><span class="params">(<span class="keyword">int</span> streamID, <span class="keyword">int</span> loop)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//设置加载监听(因为加载是异步的，需要监听加载，完成后再播放)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">setOnLoadCompleteListener</span><span class="params">(SoundPool.OnLoadCompleteListener listener)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//设置优先级(同时播放个数超过最大值时，优先级低的先被移除)</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">setPriority</span><span class="params">(<span class="keyword">int</span> streamID, <span class="keyword">int</span> priority)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//设置指定音频的播放速率，0.5~2.0(rate&gt;1:加快播放，反之慢速播放)</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">setRate</span><span class="params">(<span class="keyword">int</span> streamID, <span class="keyword">float</span> rate)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//停止指定音频播放</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">stop</span><span class="params">(<span class="keyword">int</span> streamID)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//卸载指定音频，soundID来自load()方法的返回值</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">unload</span><span class="params">(<span class="keyword">int</span> soundID)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//暂停所有音频的播放</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">autoPause</span><span class="params">()</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//恢复所有暂停的音频播放</span></span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">autoResume</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Ringtone"><a href="#Ringtone" class="headerlink" title="Ringtone"></a>Ringtone</h3><p>Ringtone为铃声、通知和其他类似声音提供快速播放的方法，Ringtone实例需要从RingtoneManager获取，RingtoneManager提供系统铃声列表检索方法。</p>
<h4 id="获取实例"><a href="#获取实例" class="headerlink" title="获取实例"></a>获取实例</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取实例方法，均为RingtoneManager类提供</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 1.通过铃声uri获取</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> Ringtone <span class="title">getRingtone</span><span class="params">(Context context, Uri ringtoneUri)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 2.通过铃声检索位置获取</span></span></span><br><span class="line"><span class="function">Ringtone <span class="title">getRingtone</span><span class="params">(<span class="keyword">int</span> position)</span></span></span><br></pre></td></tr></table></figure>

<h4 id="RingtoneManager几个重要的方法"><a href="#RingtoneManager几个重要的方法" class="headerlink" title="RingtoneManager几个重要的方法"></a>RingtoneManager几个重要的方法</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 两个构造方法</span></span><br><span class="line">RingtoneManager(Activity activity)</span><br><span class="line">RingtoneManager(Context context)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 获取指定声音类型(铃声、通知、闹铃等)的默认声音的Uri</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> Uri <span class="title">getDefaultUri</span><span class="params">(<span class="keyword">int</span> type)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 获取系统所有Ringtone的cursor</span></span></span><br><span class="line"><span class="function">Cursor <span class="title">getCursor</span><span class="params">()</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 获取cursor指定位置的Ringtone uri</span></span></span><br><span class="line"><span class="function">Uri <span class="title">getRingtoneUri</span><span class="params">(<span class="keyword">int</span> position)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 判断指定Uri是否为默认铃声</span></span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isDefault</span><span class="params">(Uri ringtoneUri)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 获取指定uri的所属类型</span></span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getDefaultType</span><span class="params">(Uri defaultRingtoneUri)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 将指定Uri设置为指定声音类型的默认声音</span></span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setActualDefaultRingtoneUri</span><span class="params">(Context context, <span class="keyword">int</span> type, Uri ringtoneUri)</span></span></span><br></pre></td></tr></table></figure>

<h4 id="Ringtone例子：播放铃声"><a href="#Ringtone例子：播放铃声" class="headerlink" title="Ringtone例子：播放铃声"></a>Ringtone例子：播放铃声</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// &lt;uses-permission android:name=&quot;android.permission.MEDIA_CONTENT_CONTROL&quot;/&gt;</span></span><br><span class="line"><span class="comment">// &lt;uses-permission android:name=&quot;android.permission.READ_EXTERNAL_STORAGE&quot;/&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 播放来电铃声的默认音乐</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">playRingtoneDefault</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Uri uri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_RINGTONE) ;</span><br><span class="line">    Ringtone mRingtone = RingtoneManager.getRingtone(<span class="keyword">this</span>,uri);</span><br><span class="line">    mRingtone.play();</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 随机播放一个Ringtone(有可能是提示音、铃声等)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ShufflePlayback</span><span class="params">()</span></span>&#123;</span><br><span class="line">    RingtoneManager manager = <span class="keyword">new</span> RingtoneManager(<span class="keyword">this</span>) ;</span><br><span class="line">    Cursor cursor = manager.getCursor();</span><br><span class="line">    <span class="keyword">int</span> count = cursor.getCount() ;</span><br><span class="line">    <span class="keyword">int</span> position = (<span class="keyword">int</span>)(Math.random() * count) ;</span><br><span class="line">    Ringtone mRingtone = manager.getRingtone(position) ;</span><br><span class="line">    mRingtone.play();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li>播放大文件音乐，如WAV无损音频和PCM无压缩音频，可使用更底层的播放方式AudioTrack。它支持流式播放，可以读取（可来自本地和网络）音频流，播放延迟较小。</li>
<li>对于延迟度要求不高，并且希望能够更全面的控制音乐的播放，MediaPlayer比较适合。</li>
<li>声音短小，延迟度小，并且需要几种声音同时播放的场景，适合使用SoundPool。</li>
<li>对于系统类声音的播放和操作，Ringtone更适合。</li>
</ol>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-全球首款群体脑机接口系统发布，最多可支持二十人实时脑电交流</title>
    <url>/4cbe97ce.html</url>
    <content><![CDATA[<p>2021年9月10-13日，2021世界机器人大会（World Robot Conference, WRC）在京召开。本次大会以“共享新成果，共注新动能”为主题，围绕世界机器人研究和应用重点领域以及智能社会创新发展，开展高水平的学术交流和最新成果展示，旨在促进国内外的学术交流。在会期间，还将同期举办世界机器人博览会、世界机器人大赛等活动，同时打造一系列创新型“配套活动”，形成以会为媒、以展促产、以赛引才的机器人产业全要素综合服务体系。丰富机器人、自动化与人工智能领域的学生、学者、企业家及行业专家的知识与经验的同时，通过展示创新技术、培育创新人才，提升学者、企业家和行业专家的国际参与度，从而推动机器人技术与产业的发展，使其成为国际社会真正的创业、创新驱动力。</p>
<span id="more"></span>

<img src="/4cbe97ce/1.jpg" class>

<p>本次大会上，清华大学医学院生物医学工程系高小榕教授，重点关注了BCI脑控机器人大赛。</p>
<p>在谈到脑机接口的市场应用时，高小榕教授表示，教育和工业还不是脑机接口的刚需，真正的刚需在于医疗行业，必须平衡脑机接口研究的目标、实际能力和手段，不能让它发展过快。大家一窝蜂投入研究后，会忽视伦理问题的重要性。而脑机接口的发展是一项综合性的工程，涉及到各个学科的协同发展，没有其它学科的进步也是局限的。</p>
<img src="/4cbe97ce/2.png" class>

<p>谈及脑机接口主要应用，高教授认为主要分为三大块：</p>
<p><strong>第一块是医疗，主要解决病人的问题——不能用鼠标键盘也不能说话的人群应该怎么应用。</strong>原来的医用主要是存在障碍的人群，比如运动受限以及事故损伤、老龄化带来的各种运动障碍。我们的方式是外周控制，通过大脑直接控制一些外设，比如轮椅不需要自己手动遥控，直接通过大脑的指令发送，可以控制轮椅能够直接行动，同时也可以控制一些外骨骼进行行走，进而融入社会。情感脑机接口方面，我们也是在尽量解码大脑的情绪。通过脑机接口的手段，我们可以在人心情不好的时候播放相应的音乐，对病人的精神状况进行调控，形成一个环路。目前我们更多的还是辅助运动控制方面做得比较多，未来的话应该是进一步在精神环节也有相应的应用。临床应用的时候也会发现，实际上很多病人的行动和语言表达都会受限，需要清楚这个人的认知状态是不是受影响。但是原先的测量方式对很多病人来说很难适用，比如很多量表都是通过看人的反应，单位时间内能够写对多少字，根据正确率作判断。因为传统的很多量表都是基于健康人群，通过大量样本得到数据，运动障碍的人群手颤抖到根本无法书写，所以我们通过脑部绕过外周神经直接进行评估。目前临床上可以用脑机接口手段评估病人的认知状态，认知状态具体达到什么程度，然后做状态的调节。</p>
<p><strong>第二块是教育。</strong>学生在学习的时候注意力和认知功能有缺陷的话，可以用脑机接口弥补。根据学生上课的注意力做一个反馈，或者从家属的反馈中知道学生是因为不听讲没学会，还是因为不理解没学会。这是两个很大的问题，如果不理解没学会就是逻辑的问题，如果是不听讲没学会就是另外一个问题。</p>
<p><strong>第三块跟工业相关，实际上涉及到的核心问题是安全。</strong>最容易理解的例子就是自动驾驶，你的车可以有自动驾驶，也可以人来驾驶，什么时候人驾驶、什么时候自动驾驶，出现一个协调的问题。如果有了脑机接口就可以很容易地做出来，比如注意力不集中、困倦、喝酒等等，车辆检测不适合人驾驶，那么就车辆自动驾驶，或者自动停在路边也可以防止出事。比如打电话的时候，车辆发现不能继续驾驶就可以停下来；人突然心脏不好了，车辆也可以自动切换。</p>
<p>在被问到以后可能将脑机接口接入正常人，进入“超人时代”，对待记忆写入，记忆增强时，是否还坚持谨慎态度。</p>
<p>高教授表示，我现在还是持有这种观点，因为脑机接口确实是影响面非常广的东西。它的危害在于，芯片进入人脑的时候你并不知道可能得到什么东西，但你知道失去了什么东西。设想脑组织的运动就像海浪，你拿一个尖的东西晃几次，对不同的人有没有伤害，或者这个伤害是人能够接受吗。所以，<strong>脑机接入一定要伦理先行。</strong></p>
<p>关于脑机接口研究方向上亟需解决的技术难题，高教授解释道，脑机接口研究的途径包括几种：一种是有创，就是要把电极搁到大脑里，还有一种是无创，就是把电极放在头皮上。有创的方法信息更大，但人不一定能够接收，好好地往大脑里插一根电极，人很难接受。那么就用无创的办法，头皮上植入电极。就像把麦克风放到屋内和屋外的差距，搁到屋外，信号就弱得多，在屋外能够听到里面大声说话，或者有人大笑，但在屋内能够知道在笑什么。马斯克的研究都是有创的方法，把电极放入脑神经其实是很难的，因为脑组织是人类最软的组织，除了体液就是脑组织。我们监测的硅这些东西反而是最硬的，一个最软的东西和一个最硬的东西放在一起，工作环境一定会有问题。而且人还要活动，跳一下蹦一下，心脏血液会有波动，所以软的和硬的损失有多大？难度还是很大的，这是<strong>物理上的难度</strong>。</p>
<p><strong>第二个难度就是生物上的难度</strong>，放进去的东西即使是软的，但对人体是有毒性的。</p>
<p><strong>第三个难度是信息。</strong>人脑有一千亿个神经元，每个神经元都在工作，按照通讯速率的比特率来说，这是按照每秒1TB的速度。如果把我的语言采样，一百比特就可以把我的语言传递到你那里，你耳朵里听到一百比特又会重新解读成1TB，所以这个就是基于语言的压缩能力。但是一百比特和计算机相比还是显得不够，所以这是非常难的东西。</p>
<p>谈及高教授所说技术应用情况，高教授说，我们在天坛医院控制机械手这类应用都有，“挑战不可能”有一个渐冻症的中国病人，我们做临床的时候发现这个病人可以用脑机接口打字，后来还参加了董卿的“挑战不可能”节目，和董卿一块朗诵了一首诗。这个人已经说不出话了，呼吸机插着管呢，但脑子好使。</p>
<p>脑机接口技术的最终目标是让失能者不必惜字如金，不必追求意义，可以真正地“随便聊聊”。正如高小榕教授所说：“如果表达是人类最基本的权利，脑机接口就是守护这一权利底线的技术。”</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://baijiahao.baidu.com/s?id=1712233110156743981">https://baijiahao.baidu.com/s?id=1712233110156743981</a><br><a href="https://www.aconf.cn/conf_180259.html">https://www.aconf.cn/conf_180259.html</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10559">https://www.scholat.com/teamwork/showPostMessage.html?id=10559</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>JavaScript-异步编程：一次性搞懂Callback、Promise、async、await</title>
    <url>/8ad76204.html</url>
    <content><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>异步编程允许我们在执行一个长时间任务时，程序不需要进行等待，而是继续执行之后的代码，直到这些任务完成之后再回来通知你，通常是以回调函数（callback）的形式。</p>
<img src="/8ad76204/1.png" class>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">getUserPost(<span class="function"><span class="keyword">function</span>(<span class="params">userPost</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(userPost);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<p>这种编程模式避免了程序的阻塞，大大提高了CPU的执行效率，尤其适用于IO密集的操作，例如需要经常进行网络操作、数据库访问的应用。</p>
<img src="/8ad76204/2.png" class>

<p>本文将以JavaScript为例介绍异步编程的概念，Promise以及新标准中更优雅的async、await语法糖。</p>
<p>本文中讲到的所有概念也同样适用于其它的编程语言，比如Python、Golang、Rust、Java、C#等等，它们也全都提供异步编程的支持。</p>
<p>如果还不是特别清楚并发、并行、异步、同步的概念，请看之后的blog（可能会写）。</p>
<img src="/8ad76204/3.png" class>

<hr>
<h3 id="Callback-与-Promise"><a href="#Callback-与-Promise" class="headerlink" title="Callback 与 Promise"></a>Callback 与 Promise</h3><h4 id="Callback"><a href="#Callback" class="headerlink" title="Callback"></a>Callback</h4><p>我们知道在JavaScript中有两种实现异步的方式，首先第一种是传统的回调函数（Callback Function），比如我们可以使用setTimeout()让一个函数在指定的时间后执行。</p>
<p>这个函数本身会立刻返回，程序会紧接着执行之后的代码，而我们传入的回调函数则会等到预定的时间才会执行。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// () =&gt; &#123;&#125; 是箭头表达式，相当于函数定义的简化写法</span></span><br><span class="line"><span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;三秒后才看见这句话！&#x27;</span>);</span><br><span class="line">&#125;, <span class="number">3000</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;你会马上看见这句话！&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>需要注意的是JavaScript从设计之初就是一个单线程的编程语言，即便看上去这里的回调函数和主程序在并发执行，但它们都运行在同一个主线程中。实际上主线程中还运行了我们写的其它代码，包括界面逻辑、网络请求、数据处理等等。</p>
<img src="/8ad76204/4.png" class>

<p>虽然只有单个线程在执行，但这种单线程的异步编程方式其实有诸多优点，由于所有操作都运行在同一个线程中，因此我们无需考虑线程同步或者资源竞争的问题。</p>
<img src="/8ad76204/5.png" class>

<p>并且从源头上避免了线程之间的频繁切换，从而降低了线程自身的开销。</p>
<img src="/8ad76204/6.png" class>

<p>回调函数虽然简单好理解，但它有一个明显的缺点，如果我们需要依次执行多个异步操作，我们的程序可能会写成这样：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;先等三秒&#x27;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">&#x27;再等三秒&#x27;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">&#x27;最后等三秒&#x27;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// ...</span></span><br><span class="line">        &#125;, <span class="number">3000</span>);</span><br><span class="line">    &#125;, <span class="number">3000</span>);</span><br><span class="line">&#125;, <span class="number">3000</span>);</span><br></pre></td></tr></table></figure>

<p>一层一层的嵌套，可读性会变得非常差，这种情况也被叫做函数的“回调地狱”（Callback Hell）。</p>
<h4 id="Promise"><a href="#Promise" class="headerlink" title="Promise"></a>Promise</h4><p>为了解决这个问题，Promise应运而生。而JavaScript中使用Promise的API：fetch()就是一个很好的例子。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">fetch(<span class="string">&#x27;http://...&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>它用来发起一个请求来获取服务器数据，我们可以用它动态更新页面的内容，也就是我们平时说的Ajax技术（Asynchronous JavaScript and XML）</p>
<img src="/8ad76204/7.png" class>

<p>例如我们调用fetch()去获取一个测试地址的数据，可以看到fetch()立刻返回了一个Promise对象，这里的promise几乎就是它的字面意思，promise-&gt;承诺，“承诺”这个请求会在未来某个时刻返回数据。</p>
<img src="/8ad76204/8.png" class>

<img src="/8ad76204/9.png" class>

<p>我们随后可以调用它的then方法并传递一个回调函数，如果这个请求在未来成功完成，那么回调函数会被调起，请求的结果也会以参数的形式传递进来。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">fetch(<span class="string">&#x27;https://jsonplaceholder.typicode.com/posts/1&#x27;</span>)</span><br><span class="line">    .then(<span class="function">(<span class="params">response</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure>

<p>当然如果光是这样，Promise和回调函数就没有什么区别了。其实Promise的优点在于它可以用一种链式结构将多个异步操作串联起来（Chaining，链式调用）。</p>
<p>比如下文的response.json()方法也会返回一个Promise，它代表在未来的某个时刻，将返回的数据转换成JSON格式。</p>
<p>如果我们想要等到它完成之后再执行其它的操作，我们可以在后面追加一个then，然后执行接下来的代码，比如将结果打印出来：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">fetch(<span class="string">&#x27;https://jsonplaceholder.typicode.com/posts/1&#x27;</span>)</span><br><span class="line">    .then(<span class="function">(<span class="params">response</span>) =&gt;</span> response.json())</span><br><span class="line">    .then(<span class="function">(<span class="params">json</span>) =&gt;</span> <span class="built_in">console</span>.log(json));</span><br></pre></td></tr></table></figure>

<img src="/8ad76204/10.png" class>

<p>Promise的链式调用避免了代码的层层嵌套，即便是我们有一个很长的链，代码也不过是向下方增长而并非向右，因此可读性会提升很多。</p>
<img src="/8ad76204/11.png" class>

<p>在使用异步操作的时候，我们也可能遇到错误，比如各种网络问题或者返回的数据格式不正确。</p>
<img src="/8ad76204/12.png" class>

<p>如果我们想要捕获这些错误，最简单的方法是附加一个catch在链式结构的末尾，如果之前任意一个阶段发生了错误，那么catch将会被触发，而之后的then()将不会执行。这和同步编程中用到的try/catch块很类似。</p>
<p>类似的Promise还提供finally方法，它会在Promise链结束之后调用，无论前面失败与否。我们可以在这里做一些清理工作，比如如果我们用到了加载动画，则可以在finally中关闭它。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">fetch(<span class="string">&#x27;https://jsonplaceholder.typicode.com/posts/1&#x27;</span>)</span><br><span class="line">    .then(<span class="function">(<span class="params">response</span>) =&gt;</span> response.json())</span><br><span class="line">    .then(<span class="function">(<span class="params">json</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(json)</span><br><span class="line">    &#125;)</span><br><span class="line">    .catch(<span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="built_in">console</span>.error(error)</span><br><span class="line">    &#125;)</span><br><span class="line">    .finally(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">        stopLoadingAnimation();</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="async、await"><a href="#async、await" class="headerlink" title="async、await"></a>async、await</h3><p>新标准ECMA17中加入的两个关键字async、await，简单来说它们是基于Promise之上的一个语法糖，可以让异步操作更加的简洁明了。</p>
<p>首先我们需要使用async关键字将函数标记为异步函数，异步函数就是指返回值为Promise对象的函数，比如之前用到的fetch()就是一个异步函数。</p>
<p>在异步函数中我们可以调用其它的异步函数，不过我们不再需要使用then()，而是使用一个更加简洁的await语法。await会等待Promise完成之后直接返回最终的结果，所以这里的response已经是服务器返回的响应数据了。</p>
<p>await虽然看上去会暂停函数的执行，但在等待的过程中JavaScript同样可以处理其它的任务，比如更新界面、运行其它程序代码等等。这是因为await底层是基于Promise和事件循环机制实现的。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> response = <span class="keyword">await</span> fetch(<span class="string">&#x27;http://...&#x27;</span>);</span><br><span class="line">    <span class="keyword">const</span> json = <span class="keyword">await</span> response.json();</span><br><span class="line">    <span class="built_in">console</span>.log(json);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f();    <span class="comment">// 这个函数返回值永远都是Promise对象</span></span><br></pre></td></tr></table></figure>

<p>最后我们在使用await的时候，需要留意以下的这几个陷阱：</p>
<ul>
<li>陷阱1</li>
</ul>
<p>如果我们分别去await这两个异步操作，虽然不存在逻辑错误，但这样写会打破这两个fetch()操作的并行，因为我们会等到第一个任务执行完成之后才开始执行第二个任务。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> a = <span class="keyword">await</span> fetch(<span class="string">&#x27;http://.../post/1&#x27;</span>);</span><br><span class="line">    <span class="keyword">const</span> b = <span class="keyword">await</span> fetch(<span class="string">&#x27;http://.../post/2&#x27;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里更高效的做法是将所有Promise用Promise.all结合起来，然后再去await。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> promiseA = fetch(<span class="string">&#x27;http://.../post/1&#x27;</span>);</span><br><span class="line">    <span class="keyword">const</span> promiseB = fetch(<span class="string">&#x27;http://.../post/2&#x27;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">const</span> [a, b] = <span class="keyword">await</span> <span class="built_in">Promise</span>.all([promiseA, promiseB]);</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>陷阱2</li>
</ul>
<p>如果我们需要在循环中执行异步操作，是不能够直接调用forEach或者map这一类方法的。尽管我们在回调函数中写了await，但这里的forEach会立刻返回，它并不会暂停等到所有异步操作都执行完毕。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].forEach(<span class="keyword">async</span> (i) =&gt; &#123;</span><br><span class="line">        <span class="keyword">await</span> someAsyncOperation();</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;done&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果我们希望等待循环中的异步操作都一一完成之后才继续执行，那我们还是应当使用传统的for循环。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i <span class="keyword">of</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) &#123;</span><br><span class="line">        <span class="keyword">await</span> someAsyncOperation();</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;done&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>更进一步，如果我们想要循环中的所有操作都并发执行，一种更炫酷的写法是使用for await，这里的for循环依然会等到所有的异步操作都完成之后才继续向后执行。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> promises = [</span><br><span class="line">        someAsyncOperation(),</span><br><span class="line">        someAsyncOperation(),</span><br><span class="line">        someAsyncOperation(),</span><br><span class="line">    ];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">await</span> (<span class="keyword">let</span> result <span class="keyword">of</span> promises) &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;done&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>陷阱3</li>
</ul>
<p>我们不能在全局或者普通函数中直接使用await关键字，await只能被用在异步函数（async function）中。如果我们想在最外层中使用await，那么需要先定义一个异步函数，然后在函数体中使用它。（听说ES2022可以直接用了）</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">await</span> someAsyncOperation();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 更简洁的写法</span></span><br><span class="line">(<span class="keyword">async</span> () =&gt; &#123;</span><br><span class="line">    <span class="keyword">await</span> someAsyncOperation();</span><br><span class="line">&#125;)();</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>使用async和await可以让我们写出更清晰、更容易理解的异步代码，有了它们之后，我们几乎不再需要使用底层的Promise对象，包括调用它的then()、catch()函数等等。</p>
<p>即便是对于某些旧版本的浏览器，它们不支持async语法，我们还是可以使用转译器（Transpiler）将它们编译成旧版本也兼容的等效代码。</p>
<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1WP4y187Tu">https://www.bilibili.com/video/BV1WP4y187Tu</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐JavaScript</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-视频开发-（一）视频原理</title>
    <url>/ae862ca2.html</url>
    <content><![CDATA[<h3 id="图像"><a href="#图像" class="headerlink" title="图像"></a>图像</h3><h4 id="颜色的相关概念"><a href="#颜色的相关概念" class="headerlink" title="颜色的相关概念"></a>颜色的相关概念</h4><p>颜色是创建图像的基础，它通过光被人们感知。不同物体受光线照射后，一部分光线被吸收，其余的被反射后被人的眼睛接受并被大脑感知，称为我们所见的色彩。</p>
<p>表示一颜色光的度量采用三个物理量：<strong>色调</strong>（颜色：如红、黄等）、<strong>饱和度</strong>（深浅程度：如粉红、深蓝等）和<strong>亮度</strong>（明暗程度）。</p>
<p>从理论上讲，任何一种颜色都可以用三种基本颜色按照不同的比例混合得到，也就是三原色原理（红R、绿G、蓝B）。</p>
<span id="more"></span>

<h4 id="彩色模型"><a href="#彩色模型" class="headerlink" title="彩色模型"></a>彩色模型</h4><p>彩色模型是用来精确标定和生成各种颜色的一套规则和定义：<strong>RGB</strong>颜色模型、<strong>CMY（CMYK）</strong>颜色模型和<strong>YUV</strong>彩色模型。</p>
<p><strong>RGB彩色模型</strong>：是工业界的一种颜色标准，是通过对红R、绿G、蓝B三个颜色通道的变化及他们相互之间的叠加来得到各式各样的颜色的，如彩色荧光屏通过发射三种不同强度的电子束，使屏幕内侧覆盖的红、绿、蓝光粉受激发光而产生各种不同的颜色。</p>
<img src="/ae862ca2/1.jpg" class>

<p><strong>YUV彩色模型</strong>：是被欧洲电视系统所采用的一种颜色编码方法，在现代彩色电视系统中，通常采用三管彩色摄像机或彩色CCD摄像机进行取像，然后取得的彩色图像信号经分色、分别放大矫正后得到RGB，在经过矩阵变换得到亮度信号Y和两个色差信号B-Y（即U）、R-Y（即V），最后发送端将亮度和色差三个信号分别进行编码，用同一个信道发送出去。这种色彩的表示方法就是YUV色彩空间表示，其重要性是它的亮度信号Y和色度信号UV是分离的。</p>
<p>RGB和YUV的换算：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Y = <span class="number">0.</span>299R + <span class="number">0.</span>587G + <span class="number">0.</span>114B</span><br><span class="line">U = -<span class="number">0.</span>147R - <span class="number">0.</span>289G + <span class="number">0.</span>436B</span><br><span class="line">V = <span class="number">0.</span>615R - <span class="number">0.</span>515G - <span class="number">0.</span>100B</span><br><span class="line">R = Y + <span class="number">1.</span>14V</span><br><span class="line">G = Y - <span class="number">0.</span>39U - <span class="number">0.</span>58V</span><br><span class="line">B = Y + <span class="number">2.</span>03U</span><br></pre></td></tr></table></figure>

<p>ITU-R BT.601-7 标准中拿到推荐的相关系数，就可以得到 YCbCr 与 RGB 相互转换的公式:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Y = <span class="number">0.</span>299R + <span class="number">0.</span>587G + <span class="number">0.</span>114B</span><br><span class="line">Cb = <span class="number">0.564</span>(B - Y)</span><br><span class="line">Cr = <span class="number">0.713</span>(R - Y)</span><br><span class="line">R = Y + <span class="number">1.</span>402Cr</span><br><span class="line">G = Y - <span class="number">0.</span>344Cb - <span class="number">0.</span>714Cr</span><br><span class="line">B = Y + <span class="number">1.</span>772Cb</span><br></pre></td></tr></table></figure>

<h4 id="图形和图像"><a href="#图形和图像" class="headerlink" title="图形和图像"></a>图形和图像</h4><p>图形：用矢量表示的图形，一般是工程作图等。</p>
<p>图像：用像素点描述的图，一般是摄像机和扫描仪等输入设备捕捉的实际场景。其属性一般包含分辨率、像素深度、图像表示法和种类等。</p>
<p>像素深度：是指存储每个像素所用的二进制位数。如一幅图像的图像深度是n位，则该图像的最多颜色数或灰度级为2的n次幂种。</p>
<p>分辨率：分为显示分辨率和图像分辨率。显示分辨率是指显示屏上能够显示出的像素数目（如手机屏幕是1080p，意思是手机屏幕上的像素点数目是1920X1080），图像分辨率是指组成一幅图像的像素密度，即每英寸多少个像素点（DPI，200dpi的设备扫描2x2.5英寸的彩色图片，得到图片的像素个数是400x500）。</p>
<h4 id="图像的获取"><a href="#图像的获取" class="headerlink" title="图像的获取"></a>图像的获取</h4><p>将现实世界的景物通过物理设备输入到计算机的过程可以成为图像的获取：如用数码相机或数码摄像机进行拍照和录像。</p>
<p>一幅彩色图像可以看做二维连续函数f(x, y)，将其变换为离散的矩阵表示，同样包含采样、量化和编码的数字化过程。</p>
<p>采样：分别在x和y轴上根据图像分辨率进行周期性采样，获得色彩值（亮度和色彩信息，会量化为像素点），假如DPI是200，获取2x2.5英寸的彩色图像，则采用后的像素矩阵大小是400x450，矩阵中的每个值代表一个像素点。</p>
<p>量化：对扫描得到的离散的像素点对应的连续色彩值进行A/D转换，每个采样点用N位的二进制表示；图像的数据量=总像素数x图像深度，如一幅400x450的256色图像大小是400x450x8b。</p>
<p>编码：把离散的像素矩阵按一定方式编成二进制码组，最后把得到的图像数据按某个图像格式记录在图像文件中；编码技术主要包括有损压缩和无损压缩，目前使用最广泛的压缩编码标准是JPEG标准；常用的图像文件格式有.jpeg、.png、.bmp、.gif等。</p>
<hr>
<h3 id="视频"><a href="#视频" class="headerlink" title="视频"></a>视频</h3><h4 id="帧-帧数（Frame-Frames）"><a href="#帧-帧数（Frame-Frames）" class="headerlink" title="帧/帧数（Frame/Frames）"></a>帧/帧数（Frame/Frames）</h4><p>简单的理解帧就是为视频或者动画中的每一张画面，而视频和动画特效就是由无数张画面组合而成，每一张画面都是一帧。帧数其实就是为帧生成数量的简称，可以解释为静止画面的数量。</p>
<p>一个帧（Frame）可能包含多个采样（Sample）：一般每个视频帧中只包含一个视频采样，而音频帧中包含多个音频采样。</p>
<p>常见的视频帧有I、P、B帧。</p>
<p>I帧：关键帧，采用帧内压缩技术</p>
<p>P帧：向前参考帧，表示这一帧与上一帧的差别，属于帧间压缩技术</p>
<p>B帧：表示双向参考帧，压缩时既参考前一帧也参考后一帧，帧间压缩技术</p>
<p>一个 I 帧可以不依赖其他帧就解码出一幅完整的图像，而 P 帧、B 帧不行。P 帧需要依赖视频流中排在它前面的帧才能解码出图像。B 帧则需要依赖视频流中排在它前面或后面的帧才能解码出图像。</p>
<h4 id="帧率（Frame-Rate）"><a href="#帧率（Frame-Rate）" class="headerlink" title="帧率（Frame Rate）"></a>帧率（Frame Rate）</h4><p>帧率（Frame rate） = 帧数（Frames）/时间（Time），单位为帧每秒（f/s, frames per second, fps）</p>
<p>帧率是用于测量显示帧数的量度，测量单位为“每秒显示帧数”（Frame per Second, fps）或“赫兹”（Hz），一般来说 FPS 用于描述视频、电子绘图或游戏每秒播放多少帧。</p>
<p>帧率的一般以下几个典型值：</p>
<p>24/25 fps：1 秒 24/25 帧，一般的电影帧率；</p>
<p>30/60 fps：1 秒 30/60 帧，游戏的帧率，30 帧可以接受，60 帧会感觉更加流畅逼真。</p>
<p>85 fps 以上人眼基本无法察觉出来了，所以更高的帧率在视频里没有太大意义。</p>
<h4 id="分辨率"><a href="#分辨率" class="headerlink" title="分辨率"></a>分辨率</h4><p>指视频成像产品所形成的图像大小或尺寸。</p>
<table>
<thead>
<tr>
<th>标准</th>
<th>分辨率</th>
</tr>
</thead>
<tbody><tr>
<td>QCIF</td>
<td>176x144</td>
</tr>
<tr>
<td>CIF</td>
<td>352x288</td>
</tr>
<tr>
<td>DV（NTSC）</td>
<td>704x576</td>
</tr>
<tr>
<td>DV（PAL）</td>
<td>720x576</td>
</tr>
<tr>
<td>HD（720p）</td>
<td>1280x720</td>
</tr>
<tr>
<td>1080p</td>
<td>1920x1080</td>
</tr>
<tr>
<td>4K</td>
<td>3840x2160</td>
</tr>
</tbody></table>
<h4 id="码率（比特率-bps）"><a href="#码率（比特率-bps）" class="headerlink" title="码率（比特率/bps）"></a>码率（比特率/bps）</h4><p>也就是比特率，比特率是单位时间播放连续的媒体（如压缩的音频和视频）的比特数量。比特率越高，带宽消耗得越多。</p>
<h4 id="封装格式"><a href="#封装格式" class="headerlink" title="封装格式"></a>封装格式</h4><p>视频封装格式，简称视频格式，相当于一种储存视频信息的容器，它里面包含了封装视频文件所需要的视频信息、音频信息和相关的配置信息（比如：视频和音频的关联信息、如何解码等等）。一种视频封装格式的直接反映就是对应着相应的视频文件格式。</p>
<img src="/ae862ca2/2.jpg" class>

<h4 id="编码格式"><a href="#编码格式" class="headerlink" title="编码格式"></a>编码格式</h4><p>通过压缩技术，将原始视频格式的文件转换成另一种视频格式文件。编码的目的是压缩数据量，采用编码算法压缩冗余数据。</p>
<p>无损压缩：RGB → YUV（色域转换）</p>
<p>有损压缩：MPEG（MPEG-2、MPEG-4）、H.26X（H.264/AVC、H.265/HEVC）</p>
<p>（几乎所有压缩都是有损压缩，损失了原始图像信息）</p>
<h4 id="压缩编码"><a href="#压缩编码" class="headerlink" title="压缩编码"></a>压缩编码</h4><p>数字视频信息的数据量很大，如每帧1280x720像素点，图像深度为16位，每秒30帧，则每秒的数量量高达1280x720x16x30/（8x1024x1024）=52.7MB。为了解决此问题，必须对数字视频信息进行压缩编码：帧内压缩和帧间压缩。</p>
<p>帧内压缩：也称为空间压缩，近考虑本帧的数据，即把单独的图像帧当做一个静态图像进行压缩，如M-JPEG编码；</p>
<p>帧间压缩：视频具有时间上的连续特征，可以利用帧内信息冗余，即视频数据的连续前后两帧具有很大的相关性，或者说前后两帧信息变化很小的特点实现高效的数据压缩，通常采用基于运动补偿的帧间预测编码技术。</p>
<p>帧的种类分为I帧、P帧和B帧，I帧是关键帧只采用帧内压缩技术，在视频快进时只能寻找I帧；P帧是基于上一个I帧或者P帧的差异采用帧间压缩获得的帧；B帧是双向两个帧采用帧间压缩获得的帧。编码时选定一个I帧，基于此I帧生成一个P帧，然后在此IP帧中间插入若干个B帧，其存储顺序为IPBBB，在播放时正常的顺序是IBBBP。</p>
<h4 id="GOP"><a href="#GOP" class="headerlink" title="GOP"></a>GOP</h4><p>GOP即Group of picture（图像组），指两个I帧之间的距离。参考周期（Reference）指两个P帧之间的距离。一个I帧所占用的字节数大于一个P帧，一个P帧所占用的字节数大于一个B帧。所以在码率不变的前提下，GOP值越大，P、B帧的数量会越多，平均每个I、P、B帧所占用的字节数就越多，也就更容易获取较好的图像质量；Reference越大，B帧的数量越多，同理也更容易获得较好的图像质量。</p>
<img src="/ae862ca2/3.jpg" class>

<h4 id="DTS和PTS"><a href="#DTS和PTS" class="headerlink" title="DTS和PTS"></a>DTS和PTS</h4><p>DTS：Decode Time Stamp，主要用于标示读入内存的比特流在什么时候开始送入解码器中进行解码。</p>
<p>PTS：Presentation Time Stamp，主要用于度量解码后的视频帧什么时候被显示出来。</p>
<p>由于B帧需要前后的帧才能解出图像，所以可能一个视频中帧的显示顺序是I B B P，但我们在解码B帧时需要P帧的信息，所以在传输的视频流中的顺序是I P B B。这时候就体现出每帧都有 DTS 和 PTS 的作用了。DTS 告诉我们该按什么顺序解码这几帧图像，PTS 告诉我们该按什么顺序显示这几帧图像。</p>
<p>例如:</p>
<p>Stream: I P B B</p>
<p>PTS: 1 4 2 3</p>
<p>DTS: 1 2 3 4</p>
<h4 id="数字视频信息"><a href="#数字视频信息" class="headerlink" title="数字视频信息"></a>数字视频信息</h4><p>是指活动、连续的图像序列，一幅图像称为一帧，帧是构成视频信息的基本单元。数字视频使用的彩色模型是YCbCr，此模型接近YUV模型，Cb代表蓝色差，Cr代表红色差信号，由于人眼对色度信号的敏感程度远不如对亮度信号敏感，所以色度信号的采样频率可以比亮度信号的取样频率低一些，以减少数字视频的数据量，这种方式称为色度子采样。目前常用的色度子样模式是：</p>
<p>4：4：4，指每条扫描线上每4个连续的采样点取4个亮点样本Y、4个色度样本Cr和4个色度样本Cb，这就相当于每个像素都用3个分量样本表示；</p>
<p>4：2：2，指每条扫描线上每4个连续的采样点取4个亮点样本Y、2个色度样本Cr和2个色度样本Cb；</p>
<p>4：1：1，指每条扫描线上每4个连续的采样点取4个亮点样本Y、1个色度样本Cr和1个色度样本Cb；</p>
<p>4：2：0，指在水平和垂直方向上每2个连续的取样点上取2个亮度样本Y、1个色度样本Cr和1个色度样本Cb，即对2X2点阵的4个采样点采样4个亮度样本和各1个色度样本；H.261、H.263和MPEG-1视频标准均使用这种取样格式。</p>
<img src="/ae862ca2/4.png" class>

<hr>
<h3 id="字幕"><a href="#字幕" class="headerlink" title="字幕"></a>字幕</h3><p>根据字幕的存放方式可以把内嵌字幕（硬字幕）和外挂字幕（软字幕）。</p>
<h4 id="内嵌字幕（硬字幕）"><a href="#内嵌字幕（硬字幕）" class="headerlink" title="内嵌字幕（硬字幕）"></a>内嵌字幕（硬字幕）</h4><p>把字幕文件和视频流压制在同一组数据里，像水印一样，无法分离。特点是兼容性好，对一些播放器无需字幕插件需求；缺点是，修正难度大，一旦出错必须整个视频文件重新制作，因为无法分离，限制了用户对字体风格个人喜好的修改。</p>
<h4 id="外挂字幕（软字幕）"><a href="#外挂字幕（软字幕）" class="headerlink" title="外挂字幕（软字幕）"></a>外挂字幕（软字幕）</h4><p>把字幕文件单独保存为srt、ASS、SSA或SUB格式，只需与视频文件名相同，播放时自动调用，也可用MKV进行封装；缺点是，需要字幕插件支持，一些播放器在某些配置下无法渲染；优点是，修正便捷，可以随意修改字体风格等。</p>
<hr>
<h3 id="详细拓展"><a href="#详细拓展" class="headerlink" title="详细拓展"></a>详细拓展</h3><h4 id="编码格式详解"><a href="#编码格式详解" class="headerlink" title="编码格式详解"></a>编码格式详解</h4><h5 id="H-26X-系列"><a href="#H-26X-系列" class="headerlink" title="H.26X 系列"></a>H.26X 系列</h5><p>由国际电传视讯联盟远程通信标准化组织(ITU-T)主导，包括 H.261、H.262、H.263、H.264、H.265。</p>
<p><strong>H.261</strong></p>
<p>H.261产生的时候，由于各国的电视制式并不统一，因此在H.261中规定了一种中间格式CIF，在编码时首先需要将需要编码的格式转换为CIF格式，然后进行传输，接收端进行解码后在转化为各自的格式。H.261规定的CIF格式视频的亮度分辨率为352×288，QCIF格式的亮度分辨率为176×144。</p>
<p>H.261编码所采用的技术：<br>帧内编码/帧间编码判定：根据帧与帧之间的相关性判定——相关性高使用帧间编码，相关性低使用帧内编码。<br>帧内编码：对于帧内编码帧，直接使用DCT编码8×8的像素块。<br>帧间编码/运动估计：使用以宏块为基础的运动补偿预测编码；当前宏块从参考帧中查找最佳匹配宏块，并计算其相对偏移量(Vx, Vy)作为运动矢量；编码器使用DCT、量化编码当前宏块和预测宏块的残差信号；<br>环路滤波器：实际上是一个数字低通滤波器，滤除不必要的高频信息，以消除方块效应。</p>
<p>H.261的码流采用了分层结构：</p>
<img src="/ae862ca2/5.jpg" class>

<p><strong>H.262</strong></p>
<p>等同于 MPEG-2 第二部分，使用在 DVD、SVCD 和大多数数字视频广播系统和有线分布系统中。</p>
<p><strong>H.263</strong></p>
<p>H.263是在H.261的基础上做了改进和增强，相对于H.261有着更好的压缩比，并且在H.261的CIF和QCIF的格式基础上增加了Sub-QCIF、4CIF和16CIF。</p>
<table>
<thead>
<tr>
<th>格式</th>
<th>分辨率</th>
</tr>
</thead>
<tbody><tr>
<td>CIF</td>
<td>352x288</td>
</tr>
<tr>
<td>QCIF</td>
<td>176x144</td>
</tr>
<tr>
<td>Sub-QCIF</td>
<td>128x96</td>
</tr>
<tr>
<td>4CIF</td>
<td>704x576</td>
</tr>
<tr>
<td>16CIF</td>
<td>1480x1152</td>
</tr>
</tbody></table>
<p>在视频信源编码上，相比H.261，从每个宏块一个运动矢量扩展为对每一个8*8的像素块分配一个运动矢量，并且开始支持1/2像素精度的运动矢量。同时增加了算数编码和双向预测来进一步提升压缩比。</p>
<table>
<thead>
<tr>
<th></th>
<th>H.261</th>
<th>H.263</th>
<th>H.264</th>
</tr>
</thead>
<tbody><tr>
<td>运动矢量</td>
<td>每个宏块分配一个运动矢量</td>
<td>每个8*8的像素块分配一个运动矢量</td>
<td>可针对4<em>4和16</em>16的像素块分配运动矢量</td>
</tr>
<tr>
<td>像素精度</td>
<td>整像素</td>
<td>1/2像素</td>
<td>1/4像素、1/8像素</td>
</tr>
<tr>
<td>预测模式</td>
<td>I帧、P帧</td>
<td>I帧、P帧、B帧，增加了双向预测</td>
<td>帧内预测提供4<em>4和16</em>16两种分块方式；帧内预测预测了所有的变化系数</td>
</tr>
<tr>
<td>熵编码</td>
<td>变长编码</td>
<td>变长编码、算术编码</td>
<td></td>
</tr>
</tbody></table>
<p><strong>H.264</strong></p>
<p>H.264，等同于 MPEG-4 第十部分，也被称为高级视频编码（Advanced Video Coding，简称 AVC），是一种视频压缩标准，一种被广泛使用的高精度视频的录制、压缩和发布格式。该标准引入了一系列新的能够大大提高压缩性能的技术，并能够同时在高码率端和低码率端大大超越以前的诸标准。</p>
<p>H.264在最初制定时，仅支持8bit采用，色度采样使用4:2:0，仅考虑了大部分通用的视频处理和传输场合，没有考虑特殊的处理，如源视频采样精度超过了8bit，色度采样使用了4:2:2或4:4:4，这些视频处理能力都超出了H.264的处理范围，后来又推出了H.264 FRExt。</p>
<p>H.264整体的编码框架上，依旧采用了块结构的混合编码框架；整个结构包括两个部分，网络抽象层（NAL）和视频编码层（VCL）。视频的每一帧被分为一个或多个slice进行编码，每一个slice包含多了宏块（Macroblock），其中宏块是H.264基本的编码单元，这种宏块包含一个16<em>16亮度块+两个8</em>8的色度块+其他一些宏块头信息。整个编码的框架如下图：</p>
<img src="/ae862ca2/6.jpg" class>

<p>H.264相比原来的编码标准有着更多的改进，在编码中，H.264的每一个宏块会被分割为多种不同大小的子块进行预测编码，帧内预测采用的块的大小可能为16<em>16，也可能为4</em>4，帧间预测采用的块有着7种不同的大小，分别是16<em>16、16</em>8、8<em>16、8</em>8、8<em>4、4</em>8和4<em>4，针对预测残差数据进行的变换编码采用了4</em>4或8*8的变换块。在熵编码中提供了CAVLC（Context Adaptive VariableLength Coding）和CABAC（ContextAdaptive Binary Arithmatic Coding）</p>
<p><strong>帧内预测</strong></p>
<p>预测编码的思路简单来说就是指编码的实际值和预测值之间的差异，对于帧内预测来说是利用空间冗余，即利用帧内像素的相似性，来获得残差，如果对残差进行编码要比对实际值进行编码的码流小的多。例如在一个88的亮度分量的实际像素值中，左侧是实际值，中间是预测值，右侧是残差。在H.264中，使用空间域的左方与上方的相邻像素预测当前编码的像素值，如果一个宏块是Intra宏块，即宏块采用帧内预测，其亮度分量有两种分割模式，一个16<em>16像素块或者16个4</em>4像素块，其中对于每个4<em>4像素块有9中预测模式，对于16</em>16的像素块有4种预测模式。由于H.264的一个宏块包含了2个88的色度分量，对于色度分量的预测方式与16*16的亮度分量相同。</p>
<p>4*4像素块的预测方式</p>
<img src="/ae862ca2/7.jpg" class>

<p>16*16像素块的预测方式</p>
<img src="/ae862ca2/8.jpg" class>

<p><strong>帧间预测</strong></p>
<p>H.264的帧间预测方法类似于H.263等前期标准的方法，在具体的算法上进行了一定的改进，相比H.263增加了更多的宏块划分模式，从16<em>16到4</em>4，并且使用了非整像素来增加运动矢量精度。</p>
<p>帧间预测的宏块分割方式</p>
<img src="/ae862ca2/9.jpg" class>

<p><strong>H.265</strong></p>
<p>H.265，被称为高效率视频编码(High Efficiency Video Coding，简称 HEVC)是一种视频压缩标准，是 H.264 的继任者。HEVC 被认为不仅提升图像质量，同时也能达到 H.264 两倍的压缩率（等同于同样画面质量下比特率减少了 50%），可支持 4K 分辨率甚至到超高画质电视，最高分辨率可达到 8192×4320（8K 分辨率），这是目前发展的趋势。</p>
<h5 id="MPEG-系列"><a href="#MPEG-系列" class="headerlink" title="MPEG 系列"></a>MPEG 系列</h5><p>由国际标准组织机构（ISO）下属的运动图象专家组（MPEG）开发。</p>
<p>MPEG-1 第二部分：主要使用在 VCD 上，有些在线视频也使用这种格式。该编解码器的质量大致上和原有的 VHS 录像带相当。</p>
<p>MPEG-2 第二部分：等同于 H.262，使用在 DVD、SVCD 和大多数数字视频广播系统和有线分布系统中。</p>
<p>MPEG-4 第二部分：可以使用在网络传输、广播和媒体存储上。比起 MPEG-2 第二部分和第一版的 H.263，它的压缩性能有所提高。</p>
<p>MPEG-4 第十部分：等同于 H.264，是这两个编码组织合作诞生的标准。</p>
<p>其他，AMV、AVS、Bink、CineForm 等等，这里就不做多的介绍了。</p>
<h4 id="封装格式详解"><a href="#封装格式详解" class="headerlink" title="封装格式详解"></a>封装格式详解</h4><p><strong>AVI 格式</strong>，对应的文件格式为 <strong>.avi</strong>，英文全称 Audio Video Interleaved</p>
<p>是由 Microsoft 公司于 1992 年推出。这种视频格式的优点是图像质量好，无损 AVI 可以保存 alpha 通道。缺点是体积过于庞大，并且压缩标准不统一，存在较多的高低版本兼容问题。</p>
<p><strong>DV-AVI 格式</strong>，对应的文件格式为 <strong>.avi</strong>，英文全称 Digital Video Format</p>
<p>是由索尼、松下、JVC 等多家厂商联合提出的一种家用数字视频格式。常见的数码摄像机就是使用这种格式记录视频数据的。它可以通过电脑的 IEEE 1394 端口传输视频数据到电脑，也可以将电脑中编辑好的的视频数据回录到数码摄像机中。</p>
<p><strong>WMV 格式</strong>，对应的文件格式是 <strong>.wmv、.asf</strong>，英文全称 Windows Media Video</p>
<p>是微软推出的一种采用独立编码方式并且可以直接在网上实时观看视频节目的文件压缩格式。在同等视频质量下，WMV 格式的文件可以边下载边播放，因此很适合在网上播放和传输。</p>
<p><strong>MPEG 格式</strong>，对应的文件格式有 <strong>.mpg、.mpeg、.mpe、.dat、.vob、.asf、.3gp、.mp4</strong> 等等，英文全称 Moving Picture Experts Group</p>
<p>是由运动图像专家组制定的视频格式，该专家组于 1988 年组建，专门负责视频和音频标准制定，其成员都是视频、音频以及系统领域的技术专家。MPEG 格式目前有三个压缩标准，分别是 MPEG-1、MPEG-2、和 MPEG-4。MPEG-4 是现在用的比较多的视频封装格式，它为了播放流式媒体的高质量视频而专门设计的，以求使用最少的数据获得最佳的图像质量。</p>
<p><strong>Matroska 格式</strong>，对应的文件格式是 <strong>.mkv</strong></p>
<p>Matroska 是一种新的视频封装格式，它可将多种不同编码的视频及 16 条以上不同格式的音频和不同语言的字幕流封装到一个 Matroska Media 文件当中。</p>
<p><strong>Real Video 格式</strong>，对应的文件格式是 <strong>.rm、.rmvb</strong></p>
<p>是 Real Networks 公司所制定的音频视频压缩规范称为 Real Media。用户可以使用 RealPlayer 根据不同的网络传输速率制定出不同的压缩比率，从而实现在低速率的网络上进行影像数据实时传送和播放。</p>
<p><strong>QuickTime File Format 格式</strong>，对应的文件格式是 <strong>.mov</strong></p>
<p>是 Apple 公司开发的一种视频格式，默认的播放器是苹果的 QuickTime。这种封装格式具有较高的压缩比率和较完美的视频清晰度等特点，并可以保存 alpha 通道。</p>
<p><strong>Flash Video 格式</strong>，对应的文件格式是 <strong>.flv</strong></p>
<p>是由 Adobe Flash 延伸出来的一种网络视频封装格式。这种格式被很多视频网站所采用。</p>
<h4 id="编码格式和封装格式的关系"><a href="#编码格式和封装格式的关系" class="headerlink" title="编码格式和封装格式的关系"></a>编码格式和封装格式的关系</h4><p>可以把「封装格式」看做是一个装着视频、音频、「编码方式」等信息的容器。一种「封装格式」可以支持多种「编码方式」，比如：QuickTime File Format（.MOV）支持几乎所有的「编码方式」，MPEG（.MP4）也支持相当广的「视频编解码方式」。当我们看到一个视频文件名为 test.mov时，我们可以知道它的「视频文件格式」是 .mov，也可以知道它的视频封装格式是 QuickTime File Format，但是无法知道它的「视频编解码方式」。那比较专业的说法可能是以 A/B 这种方式，A 是「视频编解码方式」，B 是「视频封装格式」。比如：一个 H.264/MOV 的视频文件，它的封装方式就是 QuickTime File Format，编码方式是 H.264。</p>
<h4 id="IPB帧详解"><a href="#IPB帧详解" class="headerlink" title="IPB帧详解"></a>IPB帧详解</h4><p><strong>I 帧（Intra coded frames）</strong>：I 帧图像采用帧内编码方式，即只利用了单帧图像内的空间相关性，而没有利用时间相关性。I 帧使用帧内压缩，不使用运动补偿，由于 I 帧不依赖其它帧，所以是随机存取的入点，同时是解码的基准帧。I 帧主要用于接收机的初始化和信道的获取，以及节目的切换和插入，I 帧图像的压缩倍数相对较低。I 帧图像是周期性出现在图像序列中的，出现频率可由编码器选择。</p>
<p><strong>P 帧（Predicted frames）</strong>：P 帧和 B 帧图像采用帧间编码方式，即同时利用了空间和时间上的相关性。P 帧图像只采用前向时间预测，可以提高压缩效率和图像质量。P 帧图像中可以包含帧内编码的部分，即 P 帧中的每一个宏块可以是前向预测，也可以是帧内编码。<br><strong>B 帧（Bi-directional predicted frames）</strong>：B 帧图像采用双向时间预测，可以大大提高压缩倍数。值得注意的是，由于 B 帧图像采用了未来帧作为参考，因此 MPEG-2 编码码流中图像帧的传输顺序和显示顺序是不同的。</p>
<p>也就是说，一个 I 帧可以不依赖其他帧就解码出一幅完整的图像，而 P 帧、B 帧不行。P 帧需要依赖视频流中排在它前面的帧才能解码出图像。B 帧则需要依赖视频流中排在它前面或后面的帧才能解码出图像。</p>
<p>这就带来一个问题：在视频流中，先到来的 B 帧无法立即解码，需要等待它依赖的后面的 I、P 帧先解码完成，这样一来播放时间与解码时间不一致了，顺序打乱了，那这些帧就需要DTS 和 PTS来播放。</p>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-脑机接口技术创新与产业发展（2021）报告解读</title>
    <url>/4695146.html</url>
    <content><![CDATA[<p>2021年9月26日，由中国信息通信研究院主办的“2021首届数字化社会论坛”在北京唯实国际文化交流中心举行。论坛旨在号召全社会共同关注数字化转型中的开源生态建设与知识产权保护、生物与信息前沿技术发展等议题，加强相互间的交流与借鉴，共同助力产业发展。</p>
<span id="more"></span>

<p>本次论坛紧紧围绕“开源创新与人工智能”、“脑机接口技术创新与产业发展”等议题，从产业生态建设、技术创新趋势、知识产权态势等方面展开深入研讨，旨在促进技术思想碰撞，探索产业创新方向。</p>
<p>“脑机接口技术创新与产业发展” 专题论坛上，中国信通院高级工程师周洁对《脑机接口技术创新与产业发展报告》进行了解读。周洁指出，当前脑机接口的学术研究较热，多国科研高校和实验室积极探索技术并取得成绩，我国清华大学、浙江大学、天津大学等科研高校在芯片设计、算法研究、医疗实践、赛事会议等多方面取得进展，且创新成果伴随涌现大量专利申请。脑刺激技术手段趋于多样，人工智能技术逐渐融入。非侵入式脑机接口产品有望领先于侵入式打开消费市场，未来产业合作和收并购将成巨头切入脑机领域的商业模式，随创新者的不断增多，脑机接口产业生态将更加完善。</p>
<img src="/4695146/1.jpg" class>

<img src="/4695146/2.jpg" class>

<p>在脑机接口产业生态不断完善的同时，中国也在积极地推进脑机接口标准化的进程，8月30日、9月13日，ISO/IEC JTC1 AG16脑机接口咨询组第19、20次视频工作会议召开，来自中美等国专家及科研机构、重点企业代表参会。与会专家继续就基于用例的技术报告编制工作展开探讨。我们团队潘家辉老师、王斐老师也受邀其中。</p>
<img src="/4695146/3.jpg" class>

<p>目前，《信息技术脑机接口用例》技术报告已形成初步汇总稿。该技术报告分为用例介绍、数据分析以及标准需求分析等五部分。用例介绍部分，分别对收集的20个国际用例进行概述，并附图片；数据分析部分，对用例的关键技术、应用领域和场景等进行统计分析；标准需求部分是该技术报告的创新点所在，基于目前的应用场景，梳理各场景中的标准需求，并按照优先级排序，为脑机接口标准化工作的持续性开展提供有效支撑。</p>
<p>脑机术语国际标准提案的新工作项目投票已接近尾声，若投票通过，该技术报告将作为国家成员体贡献物提交JTC 1，以支持在JTC 1建立脑机接口标准化工作实体。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.163.com/dy/article/GKS56ENQ0552DNFX.html">https://www.163.com/dy/article/GKS56ENQ0552DNFX.html</a><br><a href="https://mp.weixin.qq.com/s/30TIatcgUihvckfsXHRHlg">https://mp.weixin.qq.com/s/30TIatcgUihvckfsXHRHlg</a><br><a href="https://mp.weixin.qq.com/s/WxIU7VwwfXxBp-Dl4BkFWw">https://mp.weixin.qq.com/s/WxIU7VwwfXxBp-Dl4BkFWw</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10576">https://www.scholat.com/teamwork/showPostMessage.html?id=10576</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-视频开发-（二）视频录制</title>
    <url>/f3e23104.html</url>
    <content><![CDATA[<h3 id="相机"><a href="#相机" class="headerlink" title="相机"></a>相机</h3><p>Android框架包含了各种相机和相机功能的支持，使你可以在你的应用中捕获图像和视频。本文讨论一个简单快速的获取图像和视频的方法，并概述一个创建自定义用户相机体验的方法。</p>
<p>录制视频有两种方法：</p>
<ol>
<li><p>系统相机的录制视频功能</p>
</li>
<li><p>通过安卓自带的MediaRecorder来录制视频</p>
</li>
</ol>
<span id="more"></span>

<hr>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>Android框架支持通过CameraAPI或Cemera intent来抓取图像和视频。下面就是相关的类：</p>
<p><strong>Camera</strong>：此类是控制设备相机的主要API．此类用于在创建相机应用时获取图片和视频．</p>
<p><strong>SurfaceView</strong>：此类为用户提供camera的实时图像预览．</p>
<p><strong>MediaRecorder</strong>：此类用于从camera录制视频．</p>
<p><strong>Intent</strong>：一个MediaStore.ACTION_IMAGE_CAPTURE或MediaStore.ACTION_VIDEO_CAPTURE型的intent，可以使用它来抓取图像或视频，而不用操作Camera对象。</p>
<hr>
<h3 id="Manifest中的声明"><a href="#Manifest中的声明" class="headerlink" title="Manifest中的声明"></a>Manifest中的声明</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;uses-feature android:name=<span class="string">&quot;android.hardware.camera&quot;</span>/&gt;</span><br><span class="line">&lt;uses-feature android:name=<span class="string">&quot;android.hardware.camera.autofocus&quot;</span> /&gt;</span><br><span class="line">&lt;uses-permission android:name=<span class="string">&quot;android.permission.READ_EXTERNAL_STORAGE&quot;</span> /&gt;</span><br><span class="line">&lt;uses-permission android:name=<span class="string">&quot;android.permission.WRITE_EXTERNAL_STORAGE&quot;</span> /&gt;</span><br><span class="line">&lt;uses-permission android:name=<span class="string">&quot;android.permission.RECORD_AUDIO&quot;</span>/&gt;</span><br><span class="line">&lt;uses-permission android:name=<span class="string">&quot;android.permission.CAMERA&quot;</span> /&gt;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Camera（Android-5-0-API-21已弃用）"><a href="#Camera（Android-5-0-API-21已弃用）" class="headerlink" title="Camera（Android 5.0 API 21已弃用）"></a>Camera（Android 5.0 API 21已弃用）</h3><h4 id="拍摄图片"><a href="#拍摄图片" class="headerlink" title="拍摄图片"></a>拍摄图片</h4><p>利用Camera想要拍照，需要如下使用步骤:</p>
<ol>
<li><p>利用open(int)获取Camera实例。</p>
</li>
<li><p>利用getParameters()获取默认设置，如果需要利用setParameters(Camera.Parameters)进行参数设置。</p>
</li>
<li><p>利用setDisplayOrientation(int)函数设置正确的预览方向。</p>
</li>
<li><p>想要预览，需要配合SurfaceView，利用setPreviewDisplay(SurfaceHolder)设置SurfaceView的SurfaceHolder用于预览。</p>
</li>
<li><p>调用startPreview()开始预览，拍照之前必须已经开始预览。</p>
</li>
<li><p>takePicture 拍摄照片<br> 调用takePicture后预览会停止，需用重新调用startPreview才能再次开始预览。预览开始后，就可以通过Camera.takePicture()方法拍摄一张照片，返回的照片数据通过Callback接口获取。<br> takePicture()接口可以获取三个类型的照片：<br> 第一个，ShutterCallback接口，在拍摄瞬间瞬间被回调，通常用于播放“咔嚓”这样的音效<br> 第二个，PictureCallback接口，返回未经压缩的RAW类型照片<br> 第三个，PictureCallback接口，返回经过压缩的JPEG类型照片</p>
</li>
<li><p>调用takePickture后预览会停止，想要继续预览需要调用startPreview()函数</p>
</li>
<li><p>调用stopPreview()停止预览</p>
</li>
<li><p>调用release()释放资源，为了节省资源在Activity.onPause是调用停止预览，在onResume是开始预览。</p>
</li>
</ol>
<h4 id="录制视频"><a href="#录制视频" class="headerlink" title="录制视频"></a>录制视频</h4><p>跳转使用Intent</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Intent intent = <span class="keyword">new</span> Intent(MediaStore.ACTION_VIDEO_CAPTURE);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 1. 设置视频录制的最长时间（单位：s），录制到达时间，系统会自动保存视频，停止录制</span></span><br><span class="line">intent.putExtra (MediaStore.EXTRA_DURATION_LIMIT, <span class="number">30</span>);</span><br><span class="line"><span class="comment">// 2. 限制视频的大小，这里是100兆。当大小到达的时候，系统会自动停止录制</span></span><br><span class="line">intent.putExtra(MediaStore.EXTRA_SIZE_LIMIT, <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">100</span>);</span><br><span class="line"><span class="comment">// 3. 设置视频录制的画质（0~1之间，0和1是所有相机都有的设置：0较差，一分钟约5m；默认1较好，一分钟约40m）</span></span><br><span class="line">intent.putExtra(MediaStore.EXTRA_VIDEO_QUALITY, <span class="number">1</span>);</span><br><span class="line"><span class="comment">// 4. 表示录制完后保存的录制，如果不写，则会保存到默认的路径，在onActivityResult()的回调，通过intent.getData中返回保存的路径</span></span><br><span class="line">String filePath = getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS) + <span class="string">&quot;/msc/&quot;</span> + <span class="string">&quot;test.mp4&quot;</span>;</span><br><span class="line">Uri uri = Uri.fromFile(<span class="keyword">new</span> File(filePath));</span><br><span class="line">intent.putExtra(MediaStore.EXTRA_OUTPUT, uri);</span><br><span class="line"> </span><br><span class="line">startActivityForResult (intent, VIDEO_WITH_CAMERA);</span><br></pre></td></tr></table></figure>

<p>录制完回调获取</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onActivityResult</span><span class="params">(<span class="keyword">int</span> requestCode, <span class="keyword">int</span> resultCode, Intent data)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onActivityResult(requestCode, resultCode, data);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (resultCode == Activity.RESULT_OK &amp;&amp; requestCode == VIDEO_WITH_CAMERA) &#123;</span><br><span class="line">            Uri uri = data.getData();</span><br><span class="line">            Log.e(TAG, <span class="string">&quot;onActivityResult: &quot;</span> + uri.toString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>获取视频时长</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mediaPlayer.setDataSource(<span class="keyword">this</span>, uri);</span><br><span class="line">mediaPlayer.prepare();</span><br><span class="line"><span class="keyword">int</span> duration = mediaPlayer.getDuration() / <span class="number">1000</span>;   <span class="comment">// 获取到的是毫秒值</span></span><br></pre></td></tr></table></figure>

<p>获取视频的第一帧的图片</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MediaMetadataRetriever media = <span class="keyword">new</span> MediaMetadataRetriever();</span><br><span class="line">String videoPath = uri.getPath();            <span class="comment">// 通过Uri获取绝对路径</span></span><br><span class="line">media.setDataSource(videoPath);</span><br><span class="line">Bitmap bitmap = media.getFrameAtTime();      <span class="comment">// 视频的第一帧图片</span></span><br></pre></td></tr></table></figure>

<h4 id="选择本地视频"><a href="#选择本地视频" class="headerlink" title="选择本地视频"></a>选择本地视频</h4><p>这里有个坑，不同品牌机子间获取本地相册有兼容性问题，需要查阅对应手册针对性调用，有一篇博客记录到：</p>
<p>“使用<strong>ACTION_PICK</strong>的方式打开相册在<strong>oppo、vivo、华为、小米</strong>使用均没问题，但是在<strong>魅族</strong>和<strong>一加</strong>都不可以（跳转后的界面无法选择视频）。而<strong>魅族</strong>手机使用<strong>ACTION_OPEN_DOCUMENT</strong>方式可以选择视频文件，但是在<strong>华为</strong>手机（测试用的华为）上则会出现闪退（无法获取到被选中的视频文件的路径）。”</p>
<p>使用系统的选择本地视频的方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Intent intent = <span class="keyword">new</span> Intent();</span><br><span class="line"><span class="keyword">if</span> (<span class="string">&quot;Meizu&quot;</span>.equalsIgnoreCase(android.os.Build.MANUFACTURER)) &#123;  <span class="comment">// 判断用户手机是否是“魅族”。忽略大小写的比较</span></span><br><span class="line">    intent.setAction(Intent.ACTION_OPEN_DOCUMENT);</span><br><span class="line">    intent.addCategory(Intent.CATEGORY_OPENABLE);</span><br><span class="line">    intent.setType(<span class="string">&quot;video/*&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    intent.setAction(Intent.ACTION_PICK);</span><br><span class="line">    intent.setData(android.provider.MediaStore.Video.Media.EXTERNAL_CONTENT_URI);</span><br><span class="line">&#125;</span><br><span class="line">context.startActivityForResult(intent, REQUEST_CODE_CHOOSE_VIDEO);</span><br></pre></td></tr></table></figure>

<p>选择视频后回调</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleVideoResult</span><span class="params">(<span class="keyword">int</span> requestCode, <span class="keyword">int</span> resultCode, Intent data)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (resultCode == Activity.RESULT_OK &amp;&amp; <span class="keyword">null</span> != data)</span><br><span class="line">        <span class="keyword">if</span> (requestCode == REQUEST_CODE_CHOOSE_VIDEO) &#123;</span><br><span class="line">             <span class="keyword">try</span> &#123;</span><br><span class="line">                Uri selectedVideo = data.getData();      <span class="comment">// 获取视频的Uri</span></span><br><span class="line">                String[] filePathColumn = &#123;MediaStore.Video.Media.DATA&#125;;</span><br><span class="line">                cursor = context.getContentResolver().query(selectedVideo,</span><br><span class="line">                        filePathColumn, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">                cursor.moveToFirst();</span><br><span class="line">                <span class="keyword">int</span> columnIndex = cursor.getColumnIndex(filePathColumn[<span class="number">0</span>]);</span><br><span class="line">                String path = cursor.getString(columnIndex);          <span class="comment">// 视频路径</span></span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (cursor != <span class="keyword">null</span>) cursor.close();                   <span class="comment">// 关闭cursor</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>选中后，可以获取到视频的各种信息</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 视频ID:MediaStore.Audio.Media._ID</span></span><br><span class="line"><span class="keyword">int</span> videoId = cursor.getInt(cursor.getColumnIndexOrThrow(MediaStore.Video.Media._ID));</span><br><span class="line"><span class="comment">// 视频名称：MediaStore.Audio.Media.TITLE</span></span><br><span class="line">String title = cursor.getString(cursor.getColumnIndexOrThrow(MediaStore.Video.Media.TITLE));</span><br><span class="line"><span class="comment">// 视频路径：MediaStore.Audio.Media.DATA</span></span><br><span class="line">String videoPath = cursor.getString(cursor.getColumnIndexOrThrow(MediaStore.Video.Media.DATA));</span><br><span class="line"><span class="comment">// 视频时长：MediaStore.Audio.Media.DURATION</span></span><br><span class="line"><span class="keyword">int</span> duration = cursor.getInt(cursor.getColumnIndexOrThrow(MediaStore.Video.Media.DURATION));</span><br><span class="line"><span class="comment">// 视频大小：MediaStore.Audio.Media.SIZE</span></span><br><span class="line"><span class="keyword">long</span> size = cursor.getLong(cursor.getColumnIndexOrThrow(MediaStore.Video.Media.SIZE));</span><br><span class="line"><span class="comment">// 视频缩略图路径：MediaStore.Images.Media.DATA</span></span><br><span class="line">String imagePath = cursor.getString(cursor.getColumnIndexOrThrow(MediaStore.Images.Media.DATA));</span><br><span class="line"><span class="comment">// 缩略图ID:MediaStore.Audio.Media._ID</span></span><br><span class="line"><span class="keyword">int</span> imageId = cursor.getInt(cursor.getColumnIndexOrThrow(MediaStore.Images.Media._ID));</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="MediaRecorder基于Camera-API实现自定义相机"><a href="#MediaRecorder基于Camera-API实现自定义相机" class="headerlink" title="MediaRecorder基于Camera API实现自定义相机"></a>MediaRecorder基于Camera API实现自定义相机</h3><p>视频录制也可以通过 MediaRecorder 类完成，其步骤与音频录制基本相同，只是添加了一些对视频进行处理的操作。</p>
<p>视频录制的基本步骤如下：</p>
<p><strong>1. 调用Camera.open()方法打开摄像头。</strong></p>
<p><strong>2. 调用 Camera.setPreviewDisplay() 连接预览窗口。</strong></p>
<p>以便将从摄像头获取的图像放置到预览窗口中显示出来。</p>
<p><strong>3. 调用 Camera.startPreview()启动预览。</strong></p>
<p>显示摄像头拍摄到的图像。</p>
<p>打开摄像机openCamera()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">openCamera</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Log.d(TAG, <span class="string">&quot;openCamera.&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        camera = Camera.open(Camera.CameraInfo.CAMERA_FACING_BACK);</span><br><span class="line">        <span class="comment">// 旋转成竖屏</span></span><br><span class="line">        camera.setDisplayOrientation(<span class="number">90</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        Log.e(TAG, <span class="string">&quot;open camera error!&quot;</span>);</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        camera.setPreviewDisplay(mSurfaceHolder);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        Log.e(TAG, <span class="string">&quot;preview failed.&quot;</span>);</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    camera.startPreview();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>4. 使用 MediaRecorder 进行视频录制。</strong></p>
<p>1）使用 Camera.unlock() 方法解锁摄像头，以使 MediaRecorder 获得对摄像头的使用权。</p>
<p>unlock的作用是：Camera属于硬件设备，通常情况下Camera被一个使用Camera的进程锁定，是不允许其他进程使用的。unLock必须在你调用MediaRecorder.setCamera之前调用。</p>
<p>从api14 开始，录制视频时MediaRecorder调用start函数时Camera 会自动的调用Lock，所以再开始录制视频之前或者录制视频结束之后不需要手动的调用lock函数。</p>
<p>【注意：lock和unLock 都是只有在录制视频时才会使用，其他情况用不到这两个函数。如果你不是要录制视频，只是简单地预览不需要调用这个函数。】</p>
<p>unlock()解锁摄像机</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Camera.Parameters params = camera.getParameters();</span><br><span class="line"><span class="keyword">int</span> height = params.getSupportedVideoSizes().get(<span class="number">3</span>).height;</span><br><span class="line"><span class="keyword">int</span> width = params.getSupportedVideoSizes().get(<span class="number">3</span>).width;</span><br><span class="line"><span class="comment">// 给摄像头解锁</span></span><br><span class="line">camera.unlock();</span><br><span class="line"><span class="comment">// MediaRecorder获取到摄像头的访问权</span></span><br><span class="line">mVideoRecorder.setCamera(camera);</span><br></pre></td></tr></table></figure>

<p>2）配置 MediaRecorder。</p>
<p>音频源和视频源中包括</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">AudioSource类中包括：（一般使用默认或者主麦克风或者摄像头旁边的麦克风。）</span><br><span class="line">    MediaRecorder.AudioSource.DEFAULT： 默认音频源</span><br><span class="line">    MediaRecorder.AudioSource.MIC：主麦克风。</span><br><span class="line">    MediaRecorder.AudioSource.VOICE_CALL：来源为语音拨出的语音与对方说话的声音</span><br><span class="line">    MediaRecorder.AudioSource.VOICE_COMMUNICATION：摄像头旁边的麦克风</span><br><span class="line">    MediaRecorder.AudioSource.VOICE_DOWNLINK：下行声音</span><br><span class="line">    MediaRecorder.AudioSource.VOICE_RECOGNITION：语音识别</span><br><span class="line">    MediaRecorder.AudioSource.VOICE_UPLINK：上行声音</span><br><span class="line"> </span><br><span class="line">VideoSource类中包括：</span><br><span class="line">    VideoSource.DEFAULT:默认</span><br><span class="line">    VideoSource.CAMERA:摄像头</span><br><span class="line">    VideoSource.SURFACE：Surface作为来源</span><br><span class="line"> </span><br><span class="line">在录制视频的步骤中有一步是调用setCamera设置Camera，这一步相当于设置来源是摄像头，下面就需要使用VideoSource.CAMERA作为视频源，还可以使用MediaRecorder的getSurface播放视频，代替setCamera，这时的视频来源就是Surface。</span><br></pre></td></tr></table></figure>

<p>建立 MediaRecorder 类的对象，并设置音频源和视频源</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MediaRecorder mVideoRecorder = <span class="keyword">new</span> MediaRecorder();</span><br><span class="line"><span class="comment">// 设置视频录制过程中所录制的音频来自手机的麦克风</span></span><br><span class="line">mVideoRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);</span><br><span class="line"><span class="comment">// mVideoRecorder.setAudioSource(MediaRecorder.AudioSource.CAMCORDER);系统内部声音</span></span><br><span class="line"><span class="comment">// 设置视频源为摄像头</span></span><br><span class="line">mVideoRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA);</span><br></pre></td></tr></table></figure>

<p>设置视频的输出和编码格式</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 设置视频录制的输出文件为mp4文件</span></span><br><span class="line">mVideoRecorder.setOutputFormat(MediaRecorder.OutputFormat.MPEG_4);</span><br><span class="line"><span class="comment">// 设置音频编码方式为AAC</span></span><br><span class="line">mVideoRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC);</span><br><span class="line"><span class="comment">// 设置录制的视频编码为H.264</span></span><br><span class="line">mVideoRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.H264);</span><br><span class="line"><span class="comment">// 设置视频录制的分辨率，必须放在设置编码和格式的后面，否则报错</span></span><br><span class="line">mVideoRecorder.setVideoSize(width, height);</span><br><span class="line"><span class="comment">// 设置录制的视频的视频帧率，必须放在设置编码和格式的后面，否则报错</span></span><br><span class="line">mVideoRecorder.setVideoFrameRate(<span class="number">30</span>);</span><br><span class="line">mVideoRecorder.setVideoEncodingBitRate(<span class="number">8</span>*<span class="number">1024</span>*<span class="number">1024</span>);</span><br></pre></td></tr></table></figure>

<p>也可以通过 CamcorderProfile 对象可用于对 MediaRecorder 进行相关设置。</p>
<p>CamcorderProfile 为预先定义好的一组视频录制相关配置信息。</p>
<p>Android SDK 共定义了10+种 CamcorderProfile 配置，如 CamcorderProfile. QUALITY_HIGH、CamcorderProfile. QUALITY_LOW、CamcorderProfile. QUALITY_TIME_LAPSE_1080P 等。其中，QUALITY_LOW 和 QUALITY_HIGH 两种配置是所有的摄像头都支持的，其他配置则根据硬件性能决定。</p>
<p>每一种配置都涉及文件输出格式、视频编码格式、视频比特率、视频帧率、视频的高和宽、音频编码格式、音频的比特率、音频采样率和音频录制的通道数几个方面。通过使用这些预定义配置能够降低代码复杂度，提高编码效率。</p>
<p>CamcorderProfile和参数设置</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">CamcorderProfile <span class="title">get</span><span class="params">(<span class="keyword">int</span> cameraId, <span class="keyword">int</span> quality)</span></span></span><br><span class="line"><span class="function">CamcorderProfile <span class="title">get</span><span class="params">(<span class="keyword">int</span> quality)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 参数说明</span></span></span><br><span class="line"><span class="function"><span class="comment">// cameraId：摄像头id，分为前置摄像头或者后置摄像头。</span></span></span><br><span class="line"><span class="function"><span class="comment">// quality：质量情况</span></span></span><br><span class="line"><span class="function"><span class="comment">// 第一种例如QUALITY_HIGH：需要手动设置码率比特率采样率等</span></span></span><br><span class="line"><span class="function"><span class="comment">// QUALITY_TIME_LAPSE_HIGH：时间流逝质量（比特率）</span></span></span><br><span class="line"><span class="function"><span class="comment">// QUALITY_HIGH_SPEED_HIGH：高速（高帧率）质量</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function">CamcorderProfile mCamcorderProfile </span>= CamcorderProfile.get(Camera.CameraInfo.CAMERA_FACING_BACK, CamcorderProfile.QUALITY_HIGH);</span><br><span class="line">mMediaRecorder.setProfile(mCamcorderProfile);</span><br><span class="line"><span class="comment">// 利用setProfile设置参数必须在设置了video和audio Source之后调用，在setOutputFile之前设置。如果时间流逝的CamcorderProfile被使用，audio相关的源或者参数设置将被忽略。</span></span><br><span class="line"><span class="comment">// 注意：如果调用了setProfile函数，setOutputFormat，setAudioEncoder，setVideoEncoder，不能再调用设置。</span></span><br></pre></td></tr></table></figure>

<p>设置录制的视频文件的保存位置及文件名</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mVideoRecorder.setOutputFile(PATH_NAME);</span><br></pre></td></tr></table></figure>

<p>使用 MediaRecorder.setPreviewDisplay() 方法指定 MediaRecorder 的视频预览窗口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mVideoRecorder.setPreviewDisplay(mSurfaceHolder.getSurface());</span><br></pre></td></tr></table></figure>

<p>3）将录像器置于准备状态，然后启动录像器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mVideoRecorder.prepare();</span><br><span class="line">mVideoRecorder.start();</span><br></pre></td></tr></table></figure>

<p><strong>5. 视频录制完成后，可使用以下方法停止视频录制。</strong></p>
<p>停止录像器，重置录像器的相关配置，释放录像器对象</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mMediaRecorder.stop();</span><br><span class="line">mMediaRecorder.reset();</span><br><span class="line">mMediaRecorder.release();</span><br></pre></td></tr></table></figure>

<p>【调用 Camera.lock() 方法锁定摄像头。从 Android N（7.x） 开始，该调用也不再必需，除非 MediaRecorder.prepare() 方法失败】</p>
<p><strong>6. 调用Camera.stopPreview()方法停止预览。</strong></p>
<p><strong>7. 调用Camera.release()方法释放摄像头。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">releaseCamera</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (camera != <span class="keyword">null</span>) &#123;</span><br><span class="line">        camera.release();</span><br><span class="line">        camera = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>#. 其它一些关于MediaRecorder的方法。</strong></p>
<p>Android 4.0.3 引入可以使图像稳定化（通过修改参数）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Camera.Parameters parameters = camera.getParameters();</span><br><span class="line"><span class="comment">// 不是所有的照相机设备都支持图像稳定化，所以需要先检查下</span></span><br><span class="line"><span class="keyword">if</span> (parameters.isVideoStabilizationSupported()) &#123;</span><br><span class="line">    parameters.setVideoStabilization(<span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line">camera.setParameters(parameters);</span><br></pre></td></tr></table></figure>

<p>创建一个延时的视频</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Capture an image every 30 seconds.</span></span><br><span class="line"><span class="comment">// 参数是Double fps，即每秒的帧数</span></span><br><span class="line">mediaRecorder.setCaptureRate(<span class="number">0.03</span>);</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Camera2"><a href="#Camera2" class="headerlink" title="Camera2"></a>Camera2</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>Android 5.0（API 21）开始出现了新的相机Camera 2 API，弃用以前的Camera API，这是因为Camera1 那寥寥无几的 API 和极差的灵活性早已不能满足日益复杂的相机功能开发。Camera2 的出现给相机应用程序带来了巨大的变革，因为它的目的是为了给应用层提供更多的相机控制权限，从而构建出更高质量的相机应用程序。</p>
<p>Camera2 API不仅提高了android系统的拍照性能，还支持RAW照片输出，还可以设置相机的对焦模式，曝光模式，快门等等。</p>
<img src="/f3e23104/1.png" class>

<p>这里引用了管道的概念将安卓设备和摄像头之间联通起来，系统向摄像头发送 Capture 请求，而摄像头会返回 CameraMetadata。这一切建立在一个叫作 CameraCaptureSession 的会话中。</p>
<p>整个拍摄流程如下：</p>
<ol>
<li><p>创建一个用于从 Pipeline 获取图片的 CaptureRequest。</p>
</li>
<li><p>修改 CaptureRequest 的闪光灯配置，让闪光灯在拍照过程中亮起来。</p>
</li>
<li><p>创建两个不同尺寸的 Surface 用于接收图片数据，并且将它们添加到 CaptureRequest 中。</p>
</li>
<li><p>发送配置好的 CaptureRequest 到 Pipeline 中等待它返回拍照结果。</p>
</li>
</ol>
<img src="/f3e23104/2.jpg" class>

<p>一个新的 CaptureRequest 会被放入一个被称作 Pending Request Queue 的队列中等待被执行，当 In-Flight Capture Queue 队列空闲的时候就会从 Pending Request Queue 获取若干个待处理的 CaptureRequest，并且根据每一个 CaptureRequest 的配置进行 Capture 操作。最后我们从不同尺寸的 Surface 中获取图片数据并且还会得到一个包含了很多与本次拍照相关的信息的 CaptureResult，流程结束。</p>
<h4 id="Camera2-中主要的API类"><a href="#Camera2-中主要的API类" class="headerlink" title="Camera2 中主要的API类"></a>Camera2 中主要的API类</h4><img src="/f3e23104/3.png" class>

<p>CameraManager类：摄像头管理类，用于检测、打开系统摄像头，通过getCameraCharacteristics(cameraId)可以获取摄像头特征。</p>
<p>CameraCharacteristics类：相机特性类，例如，是否支持自动调焦，是否支持zoom，是否支持闪光灯一系列特征。</p>
<p>CameraDevice类： 相机设备，类似早期的camera类。</p>
<p>CameraCaptureSession类：用于创建预览、拍照的Session类。通过它的setRepeatingRequest()方法控制预览界面，通过它的capture()方法控制拍照动作或者录像动作。</p>
<p>CameraRequest类：一次捕获的请求，可以设置一些列的参数，用于控制预览和拍照参数，例如：对焦模式，曝光模式，zoom参数等等。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// CameraManager类</span></span><br><span class="line"></span><br><span class="line">通过以下代码可以获取摄像头的特征对象，例如：前后摄像头，分辨率等。</span><br><span class="line">CameraCharacteristics cameraCharacteristics = manager.getCameraCharacteristics(cameraId);</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// CameraCharacteristics类</span></span><br><span class="line"></span><br><span class="line">相机特性类</span><br><span class="line">CameraCharacteristics是一个包含相机参数的对象，可以通过一些key获取对应的values。</span><br><span class="line"> </span><br><span class="line">以下几种常用的参数：</span><br><span class="line">LENS_FACING：获取摄像头方向。LENS_FACING_FRONT是前摄像头，LENS_FACING_BACK是后摄像头。</span><br><span class="line">SENSOR_ORIENTATION：获取摄像头拍照的方向。</span><br><span class="line">FLASH_INFO_AVAILABLE：获取是否支持闪光灯。</span><br><span class="line">SCALER_AVAILABLE_MAX_DIGITAL_ZOOM：获取最大的数字调焦值，也就是zoom最大值。</span><br><span class="line">LENS_INFO_MINIMUM_FOCUS_DISTANCE：获取最小的调焦距离，某些手机上获取到的该values为<span class="keyword">null</span>或者<span class="number">0.0</span>。前摄像头大部分有固定焦距，无法调节。</span><br><span class="line">INFO_SUPPORTED_HARDWARE_LEVEL：获取摄像头支持某些特性的程度。</span><br><span class="line"> </span><br><span class="line">以下手机中支持的若干种程度：</span><br><span class="line">INFO_SUPPORTED_HARDWARE_LEVEL_FULL：全方位的硬件支持，允许手动控制全高清的摄像、支持连拍模式以及其他新特性。</span><br><span class="line">INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED：有限支持，这个需要单独查询。</span><br><span class="line">INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY：所有设备都会支持，也就是和过时的Camera API支持的特性是一致的。</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// CameraDevice类</span></span><br><span class="line"></span><br><span class="line">CameraDevice的reateCaptureRequest(<span class="keyword">int</span> templateType)方法创建CaptureRequest.Builder。</span><br><span class="line"> </span><br><span class="line">templateType参数有以下几种：</span><br><span class="line">TEMPLATE_PREVIEW：预览</span><br><span class="line">TEMPLATE_RECORD：拍摄视频</span><br><span class="line">TEMPLATE_STILL_CAPTURE：拍照</span><br><span class="line">TEMPLATE_VIDEO_SNAPSHOT：创建视视频录制时截屏的请求</span><br><span class="line">TEMPLATE_ZERO_SHUTTER_LAG：创建一个适用于零快门延迟的请求。在不影响预览帧率的情况下最大化图像质量。</span><br><span class="line">TEMPLATE_MANUAL：创建一个基本捕获请求，这种请求中所有的自动控制都是禁用的(自动曝光，自动白平衡、自动焦点)。</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// CameraDevice.StateCallback抽象类</span></span><br><span class="line"></span><br><span class="line">该抽象类用于CemeraDevice相机设备状态的回调。</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 当相机设备的状态发生改变的时候，将会回调。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> CameraDevice.StateCallback stateCallback = <span class="keyword">new</span> CameraDevice.StateCallback() &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当相机打开的时候，调用</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cameraDevice</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onOpened</span><span class="params">(<span class="meta">@NonNull</span> CameraDevice cameraDevice)</span> </span>&#123;</span><br><span class="line">        mCameraDevice = cameraDevice;</span><br><span class="line">        startPreView();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDisconnected</span><span class="params">(<span class="meta">@NonNull</span> CameraDevice cameraDevice)</span> </span>&#123;</span><br><span class="line">        cameraDevice.close();</span><br><span class="line">        mCameraDevice = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 发生异常的时候调用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 这里释放资源，然后关闭界面</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cameraDevice</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> error</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onError</span><span class="params">(<span class="meta">@NonNull</span> CameraDevice cameraDevice, <span class="keyword">int</span> error)</span> </span>&#123;</span><br><span class="line">        cameraDevice.close();</span><br><span class="line">        mCameraDevice = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *当相机被关闭的时候</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClosed</span><span class="params">(<span class="meta">@NonNull</span> CameraDevice camera)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.onClosed(camera);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// CameraCaptureSession.StateCallback抽象类</span></span><br><span class="line"></span><br><span class="line">该抽象类用于Session过程中状态的回调。</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">StateCallback</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//摄像头完成配置，可以处理Capture请求了。</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">onConfigured</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession session)</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//摄像头配置失败</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">onConfigureFailed</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession session)</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//摄像头处于就绪状态，当前没有请求需要处理</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onReady</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession session)</span> </span>&#123;&#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//摄像头正在处理请求</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onActive</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession session)</span> </span>&#123;&#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//请求队列中为空，准备着接受下一个请求。</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCaptureQueueEmpty</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession session)</span> </span>&#123;&#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//会话被关闭</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClosed</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession session)</span> </span>&#123;&#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//Surface准备就绪</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSurfacePrepared</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession session,<span class="meta">@NonNull</span> Surface surface)</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>CameraManager 是那个站在高处统管所有摄像投设备（CameraDevice）的管理者，而每个 CameraDevice 自己会负责建立 CameraCaptureSession 以及建立 CaptureRequest。</p>
<p>CameraCharacteristics 是 CameraDevice 的属性描述类，非要做个对比的话，那么它与原来的 CameraInfo 有相似性。</p>
<p>类图中有着三个重要的 callback，其中 CameraCaptureSession.CaptureCallback 将处理预览和拍照图片的工作，需要重点对待。</p>
<p>这些类是如何相互配合的？下面是简单的流程图。</p>
<img src="/f3e23104/4.png" class>

<h4 id="Camera2-拍照和录像流程例子"><a href="#Camera2-拍照和录像流程例子" class="headerlink" title="Camera2 拍照和录像流程例子"></a>Camera2 拍照和录像流程例子</h4><p><strong>1. 打开指定的方向的相机。</strong></p>
<p>最先获取CameraManager对象，通过该对象的getCameraIdList()获取到一些列的摄像头参数。</p>
<p>通过循环匹配，获取到指定方向的摄像头，例如后摄像头等</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CameraManager manager = (CameraManager)getSystemService(Context.CAMERA_SERVICE);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 获取到可用的相机</span></span><br><span class="line"><span class="keyword">for</span> (String cameraId : manager.getCameraIdList()) &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 获取到每个相机的参数对象，包含前后摄像头，分辨率等</span></span><br><span class="line">    CameraCharacteristics  cameraCharacteristics = manager.getCameraCharacteristics(cameraId);</span><br><span class="line">    <span class="comment">// 摄像头的方向</span></span><br><span class="line">    Integer facing = cameraCharacteristics.get(CameraCharacteristics.LENS_FACING);</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (facing == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 匹配方向,指定打开后摄像头</span></span><br><span class="line">    <span class="keyword">if</span> (facing != CameraCharacteristics.LENS_FACING_BACK) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 打开指定的摄像头</span></span><br><span class="line">    manager.openCamera(mCameraId, stateCallback, workThreadManager.getBackgroundHandler());</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当然，实际开发中，还需要获取相机支持的特性（闪光灯、zoom调焦、手动调焦等)，和设置摄像头的参数（例如：预览的Size）。</p>
<p><strong>2. 创建预览界面。</strong></p>
<p>CameraDevice.StateCallback 对象传入CameraManager中openCamera(mCameraId, stateCallback, workThreadManager.getBackgroundHandler())的第二个参数，用于监听摄像头的状态。</p>
<p>创建 CameraDevice.StateCallback 对象，且开启一个相机。当相机开启后，将出现相机预览界面。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 相机设备</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> CameraDevice mCameraDevice;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 当相机设备的状态发生改变的时候，将会回调。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> CameraDevice.StateCallback stateCallback = <span class="keyword">new</span> CameraDevice.StateCallback() &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当相机打开的时候，调用</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cameraDevice</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onOpened</span><span class="params">(<span class="meta">@NonNull</span> CameraDevice cameraDevice)</span> </span>&#123;</span><br><span class="line">        mCameraDevice = cameraDevice;</span><br><span class="line">        createCameraPreviewSession();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 省略该状态接口的部分方法</span></span><br><span class="line">    ...............</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 预览请求的Builder</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> CaptureRequest.Builder mPreviewRequestBuilder;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 相机开始预览，创建一个CameraCaptureSession对象</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">createCameraPreviewSession</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 将CaptureRequest的构建器与Surface对象绑定在一起   </span></span><br><span class="line">    mPreviewRequestBuilder = mCameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 为相机预览，创建一个CameraCaptureSession对象</span></span><br><span class="line">    mCameraDevice.createCaptureSession(Arrays.asList(surface, imageReader.getSurface()), stateCallback, <span class="keyword">null</span>);       </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>3. 在预览界面过程中，需要间隔刷新界面。</strong></p>
<p>相机预览使用TextureView来实现。</p>
<p>创建一个CameraCaptureSession ，通过一个用于预览界面的CaptureRequest，间隔复用给CameraCaptureSession。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> CameraCaptureSession mCaptureSession;</span><br><span class="line"> </span><br><span class="line">CameraCaptureSession.StateCallback stateCallback=<span class="keyword">new</span> CameraCaptureSession.StateCallback() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onConfigured</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession cameraCaptureSession)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//当cameraCaptureSession已经准备完成，开始显示预览界面</span></span><br><span class="line">        mCaptureSession = cameraCaptureSession;</span><br><span class="line">        setCameraCaptureSession();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 省略该接口的部分方法</span></span><br><span class="line">    .......</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 设置CameraCaptureSession的特征:</span></span><br><span class="line"><span class="comment"> * 自动对焦，闪光灯</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setCameraCaptureSession</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 设置预览界面的特征，通过mPreviewRequestBuilder.set()方法,例如，闪光灯，zoom调焦等</span></span><br><span class="line">    ..........</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 为CameraCaptureSession设置间隔的CaptureRequest，用间隔刷新预览界面。</span></span><br><span class="line">    mCaptureSession.setRepeatingRequest(mPreviewRequestBuilder.build(), mCaptureCallback, workThreadManager.getBackgroundHandler());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>只要未开始拍照动作或者录像动作，该复用的CaptureRequest会重复的刷新预览界面。</p>
<p>接下来，等待用户点击拍照按钮或者录像按钮，进行拍照动作，或者录像动作。</p>
<p><strong>4. 拍照动作。</strong></p>
<p>首先锁住焦点，通过在相机预览界面CaptureRequest，然后以类似方式运行一个预捕获序列。接下来，已经准备好捕捉图片。</p>
<p>创建一个新的CaptureRequest，且拍照。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 拍照一个静态的图片</span></span><br><span class="line"><span class="comment"> * 当在CaptureCallback监听器响应的时候调用该方法。</span></span><br><span class="line"><span class="comment"> * 当数字调焦缩放的时候，在写入图片数中也要设置。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">captureStillPicture</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 创建一个拍照的CaptureRequest.Builder</span></span><br><span class="line">        <span class="keyword">final</span> CaptureRequest.Builder captureBuilder = mCameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);</span><br><span class="line"> </span><br><span class="line">        captureBuilder.addTarget(imageReader.getSurface());</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 设置一系列的拍照参数，这里省略</span></span><br><span class="line">        ...........</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 先停止以前的预览状态</span></span><br><span class="line">        mCaptureSession.stopRepeating();</span><br><span class="line">        mCaptureSession.abortCaptures();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 执行拍照动作</span></span><br><span class="line">        mCaptureSession.capture(captureBuilder.build(), captureCallback, <span class="keyword">null</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (CameraAccessException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>拍照界面产生的数据只是在手机内存中，图片是一个磁盘文件，还需要一个将拍照产生数据写入文件中的操作类ImageReader。</p>
<p>先是创建ImageReader对象，和设置监听器等一系列参数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 处理静态图片的输出</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> ImageReader imageReader;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 对于静态图片，使用可用的最大值来拍摄。</span></span><br><span class="line">Size largest = Collections.max(Arrays.asList(map.getOutputSizes(ImageFormat.JPEG)), <span class="keyword">new</span> CompareSizeByArea());</span><br><span class="line"><span class="comment">// 设置ImageReader,将大小，图片格式</span></span><br><span class="line">imageReader = ImageReader.newInstance(largest.getWidth(), largest.getHeight(), ImageFormat.JPEG, <span class="comment">/*maxImages*/</span><span class="number">2</span>);</span><br><span class="line">imageReader.setOnImageAvailableListener(onImageAvailableListener, workThreadManager.getBackgroundHandler());</span><br></pre></td></tr></table></figure>

<p>将ImageReader的surface配置到captureBuilder对象中captureBuilder.addTarget(imageReader.getSurface());（captureStillPicture()中）</p>
<p>当拍照完成后，会在该监听状态中回调</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这里采用RxJava+RxAndroid异步通讯，避免太多回调接口</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ImageReader的回调监听器</span></span><br><span class="line"><span class="comment"> * onImageAvailable被调用的时候，已经拍照完，准备保存的操作</span></span><br><span class="line"><span class="comment"> * 通常写入磁盘文件中。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> ImageReader.OnImageAvailableListener onImageAvailableListener = (ImageReader reader)</span><br><span class="line">        -&gt; writePictureData(reader.acquireNextImage());</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writePictureData</span><span class="params">(Image image)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (camera2ResultCallBack != <span class="keyword">null</span>) &#123;</span><br><span class="line">        camera2ResultCallBack.callBack(ObservableBuilder.createWriteCaptureImage(appContext, image));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;       </span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将JPEG图片的数据，写入磁盘中</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> mImage</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Observable&lt;String&gt; <span class="title">createWriteCaptureImage</span><span class="params">(<span class="keyword">final</span> Context context, <span class="keyword">final</span> Image mImage)</span> </span>&#123;</span><br><span class="line">    Observable&lt;String&gt; observable = Observable.create(subscriber -&gt; &#123;</span><br><span class="line">        File file = FileUtils.createPictureDiskFile(context, FileUtils.createBitmapFileName());</span><br><span class="line">        ByteBuffer buffer = mImage.getPlanes()[<span class="number">0</span>].getBuffer();</span><br><span class="line">        <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[buffer.remaining()];</span><br><span class="line">        buffer.get(bytes);</span><br><span class="line">        FileOutputStream output = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            output = <span class="keyword">new</span> FileOutputStream(file);</span><br><span class="line">            output.write(bytes);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            mImage.close();</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">null</span> != output) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    output.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        subscriber.onNext(file.getAbsolutePath());</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> observable;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>5. 录像动作。</strong></p>
<p>录像是长时间的动作，录像过程中需要重复性的刷新录制界面。其余的步骤和拍照动作基本类似。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 开始视频录制。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startRecordingVideo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 创建录制的session会话中的请求</span></span><br><span class="line">        mPreviewBuilder = mCameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_RECORD);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 设置录制参数，这里省略</span></span><br><span class="line">        .........</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// Start a capture session</span></span><br><span class="line">        <span class="comment">// Once the session starts, we can update the UI and start recording</span></span><br><span class="line">        mCameraDevice.createCaptureSession(surfaces, <span class="keyword">new</span> CameraCaptureSession.StateCallback() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onConfigured</span><span class="params">(<span class="meta">@NonNull</span> CameraCaptureSession cameraCaptureSession)</span> </span>&#123;</span><br><span class="line">                mPreviewSession = cameraCaptureSession;</span><br><span class="line">                Log.i(TAG, <span class="string">&quot; startRecordingVideo 正式开始录制 &quot;</span>);</span><br><span class="line">                updatePreview();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 该接口的方法，部分省略</span></span><br><span class="line">            .............</span><br><span class="line">        &#125;, workThreadManager.getBackgroundHandler());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (CameraAccessException | IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 录制过程中，不断刷新录制界面</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updatePreview</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        mPreviewSession.setRepeatingRequest(mPreviewBuilder.build(), <span class="keyword">null</span>, workThreadManager.getBackgroundHandler());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (CameraAccessException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>和拍照类似，将视频数据写入磁盘文件中，也是需要一个操作类MediaRecorder来实现的。</p>
<p>创建该操作类对象，设置一些参数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// MediaRecorder</span></span><br><span class="line"><span class="keyword">private</span> MediaRecorder mMediaRecorder;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 设置媒体录制器的配置参数</span></span><br><span class="line"><span class="comment"> * 音频，视频格式，文件路径，频率，编码格式等等</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setUpMediaRecorder</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);</span><br><span class="line">    mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.SURFACE);</span><br><span class="line">    mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.MPEG_4);</span><br><span class="line">    mNextVideoAbsolutePath = FileUtils.createVideoDiskFile(appContext, FileUtils.createVideoFileName()).getAbsolutePath();</span><br><span class="line">    mMediaRecorder.setOutputFile(mNextVideoAbsolutePath);</span><br><span class="line">    mMediaRecorder.setVideoEncodingBitRate(<span class="number">10000000</span>);</span><br><span class="line">    <span class="comment">// 每秒30帧</span></span><br><span class="line">    mMediaRecorder.setVideoFrameRate(<span class="number">30</span>);</span><br><span class="line">    mMediaRecorder.setVideoSize(mVideoSize.getWidth(), mVideoSize.getHeight());</span><br><span class="line">    mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.H264);</span><br><span class="line">    mMediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC);</span><br><span class="line">    <span class="keyword">int</span> rotation = activity.getWindowManager().getDefaultDisplay().getRotation();</span><br><span class="line">    <span class="keyword">switch</span> (mSensorOrientation) &#123;</span><br><span class="line">        <span class="keyword">case</span> SENSOR_ORIENTATION_DEFAULT_DEGREES:</span><br><span class="line">            mMediaRecorder.setOrientationHint(DEFAULT_ORIENTATIONS.get(rotation));</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> SENSOR_ORIENTATION_INVERSE_DEGREES:</span><br><span class="line">            mMediaRecorder.setOrientationHint(ORIENTATIONS.get(rotation));</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    mMediaRecorder.prepare();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>间隔性的随着视频录制而输出数据到文件中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 为 MediaRecorder设置Surface</span></span><br><span class="line">Surface recorderSurface = mMediaRecorder.getSurface();</span><br><span class="line">surfaces.add(recorderSurface);</span><br><span class="line">mPreviewBuilder.addTarget(recorderSurface);</span><br></pre></td></tr></table></figure>

<p>最后，当录制视频结束后，停止输出</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 停止录制</span></span><br><span class="line">mMediaRecorder.stop();</span><br><span class="line">mMediaRecorder.reset();</span><br></pre></td></tr></table></figure>

<p><strong>6. 恢复到预览界面。</strong></p>
<p>完成一些列拍照或录像动作后,重新恢复到预览界面</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 完成一些列拍照或录像动作后，释放焦点。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">unlockFocus</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//向session重新发送，预览的间隔性请求，出现预览界面。</span></span><br><span class="line">        mCaptureSession.setRepeatingRequest(mPreviewRequest, mCaptureCallback, workThreadManager.getBackgroundHandler());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (CameraAccessException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当然，还有关闭相机操作，和与Activity生命周期绑定的操作，这里不再做介绍了。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li><p>Camera Intent方便快捷，不需要太多的代码量；MediaRecorder代码量稍大</p>
</li>
<li><p>Camera Intent视频清晰度只有两种，一个是最不清楚，一个是最清楚；MediaRecorder视频清晰度可根据数值自动往上调</p>
</li>
<li><p>Camera Intent在录制过程中，操作方便，有自己的暂停、录制、播放按钮；MediaRecorder需要自己去写暂停、录制或播放按钮</p>
</li>
<li><p>Camera1 严格区分了预览和拍照两个流程，而 Camera2 则把这两个流程都抽象成了 Capture 行为，只不过一个是一次性的 Capture，一个是不断重复的 Capture 而已</p>
</li>
<li><p>如同 Camera1 一样，Camera2 的一些 API 调用也会耗时，所以建议使用独立的线程执行所有的相机操作，尽量避免直接在主线程调用 Camera2 的 API，可使用 HandlerThread</p>
</li>
<li><p>Camera2 所有的相机操作都可以注册相关的回调接口，然后在不同的回调方法里写业务逻辑，这可能会让代码因为不够线性而错综复杂，建议可以尝试使用子线程的阻塞方式来尽可能地保证代码的线性执行。例如在子线程阻塞等待 CaptureResult，然后继续执行后续的操作，而不是将代码拆分到到 CaptureCallback.onCaptureCompleted() 方法里</p>
</li>
<li><p>可以认为 Camera1 是 Camera2 的一个子集，也就是说 Camera1 能做的事情 Camera2 一定能做</p>
</li>
</ol>
<p><strong>一些其它地方别人的总结：</strong></p>
<ol>
<li><p>如果应用程序需要同时兼容 Camera1 和 Camera2，建议分开维护，因为 Camera1 蹩脚的 API 设计很可能让 Camera2 灵活的 API 无法得到充分的发挥，另外将两个设计上完全不兼容的东西搅和在一起带来的痛苦可能远大于其带来便利性，多写一些冗余的代码也许还更开心</p>
</li>
<li><p>官方说 Camera2 的性能会更好，但起码在较早期的一些机器上运行 Camera2 的性能并没有比 Camera1 好</p>
</li>
<li><p>当设备的 Supported Hardware Level 低于 FULL 的时候，建议还是使用 Camera1，因为 FULL 级别以下的 Camera2 能提供的功能几乎和 Camera1 一样，所以倒不如选择更加稳定的 Camera1</p>
</li>
</ol>
<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.jianshu.com/p/9a2e66916fcb">https://www.jianshu.com/p/9a2e66916fcb</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-读论文(PART I)</title>
    <url>/8a9d1ce5.html</url>
    <content><![CDATA[<p>更多论文请见：<a href="https://github.com/mli/paper-reading">https://github.com/mli/paper-reading</a></p>
<hr>
<h3 id="AlexNet：深度学习奠基作之一-2021-10-14"><a href="#AlexNet：深度学习奠基作之一-2021-10-14" class="headerlink" title="AlexNet：深度学习奠基作之一 (2021-10-14)"></a>AlexNet：深度学习奠基作之一 (2021-10-14)</h3><iframe src="//player.bilibili.com/player.html?aid=208532381&bvid=BV1ih411J7Kz&cid=424903662&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<h3 id="AlexNet-论文逐段精读-2021-10-15"><a href="#AlexNet-论文逐段精读-2021-10-15" class="headerlink" title="AlexNet 论文逐段精读 (2021-10-15)"></a>AlexNet 论文逐段精读 (2021-10-15)</h3><iframe src="//player.bilibili.com/player.html?aid=548615305&bvid=BV1hq4y157t1&cid=425249408&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="ResNet：撑起计算机视觉半边天-2021-10-21"><a href="#ResNet：撑起计算机视觉半边天-2021-10-21" class="headerlink" title="ResNet：撑起计算机视觉半边天 (2021-10-21)"></a>ResNet：撑起计算机视觉半边天 (2021-10-21)</h3><iframe src="//player.bilibili.com/player.html?aid=633628859&bvid=BV1Fb4y1h73E&cid=428373981&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="ResNet-论文逐段精读-2021-10-22"><a href="#ResNet-论文逐段精读-2021-10-22" class="headerlink" title="ResNet 论文逐段精读 (2021-10-22)"></a>ResNet 论文逐段精读 (2021-10-22)</h3><iframe src="//player.bilibili.com/player.html?aid=421169743&bvid=BV1P3411y7nn&cid=428820831&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Transformer-论文逐段精读-2021-10-28"><a href="#Transformer-论文逐段精读-2021-10-28" class="headerlink" title="Transformer 论文逐段精读 (2021-10-28)"></a>Transformer 论文逐段精读 (2021-10-28)</h3><iframe src="//player.bilibili.com/player.html?aid=506354287&bvid=BV1pu411o7BE&cid=432055065&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="GNN-GCN：图神经网络多图详解-2021-11-4"><a href="#GNN-GCN：图神经网络多图详解-2021-11-4" class="headerlink" title="GNN/GCN：图神经网络多图详解 (2021-11-4)"></a>GNN/GCN：图神经网络多图详解 (2021-11-4)</h3><iframe src="//player.bilibili.com/player.html?aid=933985047&bvid=BV1iT4y1d7zP&cid=435975594&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="GAN-论文逐段精读-2021-11-10"><a href="#GAN-论文逐段精读-2021-11-10" class="headerlink" title="GAN 论文逐段精读 (2021-11-10)"></a>GAN 论文逐段精读 (2021-11-10)</h3><iframe src="//player.bilibili.com/player.html?aid=634089974&bvid=BV1rb4y187vD&cid=439574005&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="BERT-论文逐段精读-2021-11-19"><a href="#BERT-论文逐段精读-2021-11-19" class="headerlink" title="BERT 论文逐段精读 (2021-11-19)"></a>BERT 论文逐段精读 (2021-11-19)</h3><iframe src="//player.bilibili.com/player.html?aid=464324279&bvid=BV1PL411M7eQ&cid=444844922&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="ViT-论文逐段精读-2021-11-30"><a href="#ViT-论文逐段精读-2021-11-30" class="headerlink" title="ViT 论文逐段精读 (2021-11-30)"></a>ViT 论文逐段精读 (2021-11-30)</h3><iframe src="//player.bilibili.com/player.html?aid=892100567&bvid=BV15P4y137jb&cid=451711833&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="MAE-论文逐段精读-2021-12-09"><a href="#MAE-论文逐段精读-2021-12-09" class="headerlink" title="MAE 论文逐段精读 (2021-12-09)"></a>MAE 论文逐段精读 (2021-12-09)</h3><iframe src="//player.bilibili.com/player.html?aid=592243278&bvid=BV1sq4y1q77t&cid=457423264&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="MoCo-论文逐段精读-2021-12-16"><a href="#MoCo-论文逐段精读-2021-12-16" class="headerlink" title="MoCo 论文逐段精读 (2021-12-16)"></a>MoCo 论文逐段精读 (2021-12-16)</h3><iframe src="//player.bilibili.com/player.html?aid=422340209&bvid=BV1C3411s7t9&cid=461830701&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="对比学习论文综述-2021-12-31"><a href="#对比学习论文综述-2021-12-31" class="headerlink" title="对比学习论文综述 (2021-12-31)"></a>对比学习论文综述 (2021-12-31)</h3><iframe src="//player.bilibili.com/player.html?aid=680170801&bvid=BV19S4y1M7hm&cid=472587940&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Deepmind-用机器学习指导数学直觉论文精读-2022-01-08"><a href="#Deepmind-用机器学习指导数学直觉论文精读-2022-01-08" class="headerlink" title="Deepmind 用机器学习指导数学直觉论文精读 (2022-01-08)"></a>Deepmind 用机器学习指导数学直觉论文精读 (2022-01-08)</h3><iframe src="//player.bilibili.com/player.html?aid=380508665&bvid=BV1YZ4y1S72j&cid=479659575&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Swin-Transformer-论文精读-2022-01-15"><a href="#Swin-Transformer-论文精读-2022-01-15" class="headerlink" title="Swin Transformer 论文精读 (2022-01-15)"></a>Swin Transformer 论文精读 (2022-01-15)</h3><iframe src="//player.bilibili.com/player.html?aid=850677660&bvid=BV13L4y1475U&cid=483320545&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-浅显易懂的PyTorch深度学习入门</title>
    <url>/d1d6413c.html</url>
    <content><![CDATA[<p>本文将通过实现一个简单的歌词生成AI，快速了解深度学习的基本流程以及PyTorch这款必备的深度学习框架。</p>
<hr>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>首先我们要知道，深度学习或者说神经网络的本质其实是一个数学问题。我们可以通过“训练”让一个神经网络学习“输入”到“输出”之间的数据映射关系。</p>
<img src="/d1d6413c/1.png" class>

<span id="more"></span>

<p>例如当神经网络看到这张图片时，它应该知道输出是一只狗。</p>
<img src="/d1d6413c/2.png" class>

<p>在PyTorch中，构建神经网络的核心数据结构是一个叫做张量（Tensor）的东西。</p>
<img src="/d1d6413c/3.png" class>

<p>它和numpy数组非常类似，不过Tensor的运算可以被放在GPU上执行，利用GPU的并行运算来加速整个计算过程。在Tensor之上，我们可以构建各种复杂的数学模型。</p>
<img src="/d1d6413c/4.png" class>

<p>PyTorch同时提供了梯度（Gradient）的自动计算，梯度你可以简单理解为导数在高维度上的推广。</p>
<img src="/d1d6413c/5.png" class>

<p>这是因为对于神经网络的“训练”，或者说一般的最优化问题，大家会用到一个核心算法————梯度下降（gradient descent）。</p>
<img src="/d1d6413c/6.png" class>

<p>而PyTorch将偏导数的计算、链式法则这些细节全都隐藏在了框架中，因此我们可以关注于解决实际问题，而不是这些繁琐的计算细节。</p>
<img src="/d1d6413c/7.png" class>

<p>除了这些基本的计算功能以外，PyTorch对神经网络还有各种模块化的封装，比如常见的卷积层（conv layer）、线性层（linear layer）、池化层（pooling layer）、padding layer、各种激活函数、CNN、RNN、Transformer模型等等。</p>
<hr>
<h3 id="安装PyTorch"><a href="#安装PyTorch" class="headerlink" title="安装PyTorch"></a>安装PyTorch</h3><p>PyTorch的安装还是非常容易的，我们可以在<a href="https://pytorch.org/">PyTorch官网</a>选择对应的操作系统、CUDA版本，Anaconda其实不是必须的，只是可以更好地进行包管理。最后复制下面的命令到控制台安装即可。</p>
<img src="/d1d6413c/8.png" class>

<hr>
<h3 id="数据集（Dataset）"><a href="#数据集（Dataset）" class="headerlink" title="数据集（Dataset）"></a>数据集（Dataset）</h3><p>训练的第一步是准备我们需要的原始数据，数据集（Dataset）通常很容易被我们忽视，但又是深度学习中相当重要的一环。有时候即使你的模型再好，但是训练的数据很差，最后也很难得到一个好的结果。</p>
<p>这里使用的是这个<a href="https://www.heywhale.com/mw/dataset/5e6382164b7a30002c98c62c">中文歌词语料库</a>。</p>
<img src="/d1d6413c/9.png" class>

<p>在下载的原始数据集中我们可以看到很多非中文歌曲，以及有些歌词中的格式不工整，有些歌词的前面包含了不需要的信息。</p>
<img src="/d1d6413c/10.png" class>

<p>因此我们需要对这些原始数据做一些预处理（Data Preprocessing），并将数据转换成我们需要的格式。需要写一个处理脚本data_preprocess.py，过滤掉不需要的歌词，去除多余的文件，并以斜杠来分隔歌词的每一句，每一行是一首歌的歌词，最后存放在一个纯文本中（data/lyrics.txt）。</p>
<p>接下来可以利用PyTorch提供的DataSet和DataLoader来读取这个歌词文件。这两个类封装了基本的数据操作，比如切分训练数据、随机打乱数据、或者对数据进行简单变换等等，这样我们就不用自己去造轮子了。</p>
<img src="/d1d6413c/11.png" class>

<p>我们可以通过继承DataSet类来定义我们的歌词数据集，接下来我们在init函数中加载之前的这个歌词文件，并将所有的文字转换成一个个索引。【PyTorch神经网络不支持“字符”类型的输入，我们需要将文字转换成不重复的整型值才能传递给网络】</p>
<img src="/d1d6413c/12.png" class>

<p>这里我们定义两个dict用来保存索引到文字以及文字到索引的映射。</p>
<img src="/d1d6413c/13.png" class>

<p>接下来我们需要实现两个函数，第一个函数len，我们需要返回样本的总数。这里我们将所有歌词文本拆分成一个个长度为48的序列，所以样本总数（seq_len）等于文字的总数/序列长度（48），这里为什么减1，后文会提及。</p>
<img src="/d1d6413c/14.png" class>

<p>第二个函数getitem，我们可以根据指定的下标返回对应的文字序列。</p>
<img src="/d1d6413c/15.png" class>

<p>这里返回的数据可以分为两部分，一部分代表网络的输入，另一部分代表网络的输出，输入和输出刚好相差一个字，因为输出的文字刚好是对下一个字的预测。</p>
<img src="/d1d6413c/16.png" class>

<p>定义完毕之后，我们对刚刚的代码进行一下简单测试。这里我们可以创建一个数据集对象，然后根据下标随便获取其中一个样本，可以看到返回了一个整数序列，长度为48，其中的每个数字代表一个文字的索引。</p>
<img src="/d1d6413c/17.png" class>

<p>我们当然可以根据之前创建的映射将它们再还原成一个个字符。</p>
<img src="/d1d6413c/18.png" class>

<p>这一步检查其实是很有必要的，不然一步错步步错。</p>
<p>在定义了Dataset之后，我们需要再创建一个DataLoader来访问其中的数据，主要是DataLoader允许我们随机打乱数据，或者按批次（batch）读取数据。</p>
<img src="/d1d6413c/19.png" class>

<p>当然这里还进一步将数据随机分成了两部分，一部分用来做训练，另一部分用来做测试（验证），原因在之后训练的时候会讲到。</p>
<img src="/d1d6413c/20.png" class>

<hr>
<h3 id="创建模型（Build-Model）"><a href="#创建模型（Build-Model）" class="headerlink" title="创建模型（Build Model）"></a>创建模型（Build Model）</h3><p>接下来，我们来定义我们用到的这个神经网络结构。</p>
<p>在PyTorch中，我们可以通过继承nn中的Module类来定义一个神经网络。这里最关键的是forward函数，它定义了我们网络从输入到输出的整个计算过程，比如数据会经过哪些层、层与层之间应当如何连接等等。</p>
<img src="/d1d6413c/21.png" class>

<p>在定义模型时，有一点非常重要，不管我们要解决的问题有多么复杂，最好都先从构建一个最基本的模型开始，这样会大大降低训练和调试的难度，并且我们在增加模型复杂度之后，可以以这个简单的模型做参照，确保复杂的模型是否能真的表现的更好。</p>
<p>其实对于文本生成问题，使用当下最流行的Transformer架构应该是更好的选择。</p>
<img src="/d1d6413c/22.png" class>

<p>不过这里我们先用一个更加简单、基本的RNN（Recurrent Neural Network，循环神经网络：特指将当前的状态信息循环传递给自身的网络模型）模型来做演示。</p>
<p>首先我们会将这里输入的文字经过一个embedding层转换成一个向量，因为高维向量能够很好地表示不同文字间的语义关联。</p>
<p>接着我们将这个向量传入一个LSTM单元，最后通过一个线性层转换成输出的文字。</p>
<img src="/d1d6413c/23.png" class>

<p>和所有的分类问题（categorization）一样，这里的文字是使用one-hot向量来编码的。</p>
<p>另外LSTM单元同时有一个隐藏状态的输入和一个隐藏状态的输出，正是因为有这个隐藏状态，才使得我们的神经网络具有记忆的能力，因为我们不希望生成的歌词前言不搭后语，我们需要让模型记住文字前后的关系。</p>
<hr>
<h3 id="训练（Training）"><a href="#训练（Training）" class="headerlink" title="训练（Training）"></a>训练（Training）</h3><p>在训练的过程中，每次会从数据中抽取一小部分（称之为一个batch），然后我们会一个batch接着一个batch训练。</p>
<p>当所有的数据都被训练过一遍之后（称之为一个epoch），通过我们会对模型训练若干个epoch，让它更好地去拟合训练数据。</p>
<p>我们可以在循环中实现整个训练的过程，对于每个epoch，我们会一个batch接着一个batch地训练。</p>
<img src="/d1d6413c/24.png" class>

<p>标记代码单纯代表将训练数据上传至GPU，如果使用GPU来加速训练过程的话是有必要的。</p>
<p>接下来我们将数据传入之前创建的模型，让模型预测一个输出，然后我们会去计算这个输出与标准答案（ground truth）之间的“差异”，这里我们会用到损失函数（Loss Function）。</p>
<p>对于不同的问题，我们会用到不同的损失函数，比如对于纯数值类型的输出（Scalar Output），像温度、房价、身高…，这个loss可以简单是输出与标准答案的绝对值或者是平方差。</p>
<img src="/d1d6413c/25.png" class>

<p>而对于我们这种情况，由于我们的输出是ont-hot编码的文字，因此我们会用到交叉熵（Cross Entropy），可以简单将这个loss理解为输出与标准答案之间的差距，通常我们希望这个loss越小越好，这样代表预测的结果与标准答案更接近。</p>
<img src="/d1d6413c/26.png" class>

<p>我们训练神经网络的目标，就是通过缓慢调节网络中的各种权重（Weight）来降低这个loss，用到的算法就是之前提到的梯度下降。关于梯度的计算，我们可以轻松地通过调用一句backward()完成，然后我们可以调用optimizer的step()，通过计算得到的梯度自动修改网络的权重。</p>
<p>其中optimizer.zero_grad()也非常重要，它会在计算之前先将梯度清零，避免我们得到一个累加的梯度值。</p>
<img src="/d1d6413c/27.png" class>

<p>刚刚我们提到的optimizer是优化器，它可以通过计算得到的梯度自动更新网络的权重。</p>
<img src="/d1d6413c/28.png" class>

<p>Adam和SGD是两个非常常用的优化器。</p>
<img src="/d1d6413c/29.png" class>

<p>另外优化器有一个额外的参数————学习速率（Learning Rate），它会影响每次权重变化的大小。</p>
<p>学习率越大，神经网络权重的变化量就越大，但学习率绝不是越大越好，过大的学习率会让loss无法收敛，甚至可能出现随着训练增大的情况。</p>
<img src="/d1d6413c/30.png" class>

<p>学习率设置的过小会降低训练的速度，甚至可能让你的神经网络学不到任何东西。</p>
<img src="/d1d6413c/31.png" class>

<p>当然也有人尝试使用动态的学习率，比如随着训练的推进逐渐降低学习率。关于学习率和优化器的选择又是一个很宽泛的话题，这里就不展开讨论了。</p>
<p>另外在训练的过程中，我们可以将loss打印出来以方便我们跟踪模型的训练进度。这里我们还可以用到Tensorboard这个库，然后可以调用add_scalar()来绘制像loss、精确度这样标量的数据，命令行调用tensorboard –logdir=runs可查看。</p>
<img src="/d1d6413c/32.png" class>

<p>这一步不是必要的，但是图表呈现的信息往往比数字要直观很多。</p>
<img src="/d1d6413c/33.png" class>

<hr>
<h3 id="模型评估（Model-Evaluation）"><a href="#模型评估（Model-Evaluation）" class="headerlink" title="模型评估（Model Evaluation）"></a>模型评估（Model Evaluation）</h3><p>我们将数据分成了训练和测试两部分，通过我们会预留少量的数据做评估，这一部分数据并不会拿来做训练。</p>
<img src="/d1d6413c/34.png" class>

<p>评估的代码和训练非常相似，除了我们不会计算梯度来更新网络的权重。我们同样会输出一个loss，然后观察这个loss下降的情况，因为单纯训练loss的降低并不能代表模型表现得很好，模型也有可能过度拟合（Overfit）我们的训练数据，也就是说我们的模型对于训练数据表现得很好，但是对于从没有见过的数据却表现得很差。</p>
<img src="/d1d6413c/35.png" class>

<p>为了避免这种情况，我们会同时关注训练和评估时候的loss以及精确度这些指标。</p>
<img src="/d1d6413c/36.png" class>

<hr>
<h3 id="最基本的验证（Sanity-Check）"><a href="#最基本的验证（Sanity-Check）" class="headerlink" title="最基本的验证（Sanity Check）"></a>最基本的验证（Sanity Check）</h3><p>在真正训练之前，我们最好对之前的代码做一个最最基本的验证，因为训练一个模型通常会花很多时间，有时候一两天都有可能，如果等你训练完了才发现模型根本不工作，那一定让人气到原地升天。</p>
<p>so how to do?</p>
<p>比如我们可以修改这里的dataloader，让我们暂时只用第一个batch的数据，并且我们只用batch中的前两个样本来做训练。</p>
<img src="/d1d6413c/37.png" class>

<img src="/d1d6413c/38.png" class>

<p>如果在这种情况下loss都不会降低，也就是说我们的模型都不能过拟合，那么我们的代码肯定哪里有问题，需要进行调试。</p>
<hr>
<h3 id="真正的模型训练（Model-Training）"><a href="#真正的模型训练（Model-Training）" class="headerlink" title="真正的模型训练（Model Training）"></a>真正的模型训练（Model Training）</h3><p>在训练的过程中，我们还可以每隔一段时间，让目前的模型生成一段输出，这一步主要是为了实时观测模型的预测结果，may大be可以看到我们模型的输出随着训练有显著的提升。</p>
<p>我们还可以做一些改进，比如使用两层的lstm单元，并在输出之前额外增加了一个线性层。与之前的模型相比较，新的模型进一步降低了loss并提高了预测的准确度。</p>
<p>虽然不是每一个修改都能保证模型效果的提升，不过模型优化确实需要我们不断地进行尝试，通常我们在loss不再降低的时候就可以停止训练了（需要同时观察validation loss而不单单是training loss）。</p>
<hr>
<h3 id="推断（Inference）"><a href="#推断（Inference）" class="headerlink" title="推断（Inference）"></a>推断（Inference）</h3><p>生成歌词的generate()函数稍微有点长，不过总体来说，它会将我们规定的首字符先传递给神经网络，然后让神经网络自由创作，直到这一句结束（遇到“/”分隔符为止）。</p>
<img src="/d1d6413c/39.png" class>

<p>这里的next_word函数会将当前字符传入神经网络然后返回预测的下一个字，中间也会维护一个隐藏状态hidden</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文也只不过提到了深度学习的冰山一角，像图像、声音、语言处理等等，每一个子领域都有太多东西值得去推敲，每年也会看到很多新的突破。</p>
<p>要训练一个好的模型绝对不是一件轻松的事情，有时候对模型结构的一点点修改，甚至是对（超）参数（hyper parameter）的一点点调整，都有可能带来很大的性能提升。</p>
<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1oq4y1E7Vd">https://www.bilibili.com/video/BV1oq4y1E7Vd</a><br><a href="https://github.com/rossning92/ai-lyrics-writing">https://github.com/rossning92/ai-lyrics-writing</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-视频开发-（三）视频播放</title>
    <url>/47f70dd6.html</url>
    <content><![CDATA[<h3 id="视频播放器的原理"><a href="#视频播放器的原理" class="headerlink" title="视频播放器的原理"></a>视频播放器的原理</h3><p>音视频技术主要包含以下几点：封装技术、视频压缩编码技术、音频压缩编码技术、流媒体协议技术（如果考虑到网络传输的话）。</p>
<p>视频播放器播放一个<strong>互联网上的视频文件</strong>，需要经过以下几个步骤：<strong>解协议，解封装，解码音视频，音视频同步</strong>。</p>
<p>播放<strong>本地文件</strong>则不需要解协议，为以下几个步骤：<strong>解封装，解码音视频，音视频同步</strong>。</p>
<img src="/47f70dd6/1.png" class>

<span id="more"></span>

<p><strong>解协议</strong>：将流媒体协议的数据，解析为标准的相应的封装格式数据。音视频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP、RTMP、MMS等等。这些协议在传输音视频数据的同时，也会传输一些信令数据。这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留音视频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。</p>
<p><strong>解封装</strong>：将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4、MKV、RMVB、TS、FLV、AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。</p>
<p><strong>解码</strong>：将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含AAC、MP3、AC-3等等，视频的压缩编码标准则包含H.264、MPEG2、VC-1等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P、RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。</p>
<p><strong>音视频同步</strong>：根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来。</p>
<hr>
<h3 id="MediaPlayer"><a href="#MediaPlayer" class="headerlink" title="MediaPlayer"></a>MediaPlayer</h3><img src="/47f70dd6/2.jpg" class>

<h4 id="MediaPlayer生命周期"><a href="#MediaPlayer生命周期" class="headerlink" title="MediaPlayer生命周期"></a>MediaPlayer生命周期</h4><ol>
<li><p><strong>Idle（闲置）状态与End（结束）状态</strong></p>
<p> MediaPlayer 对象声明周期 : 从 Idle 到 End 状态就是 MediaPlayer 整个生命周期<br> 生命周期<strong>开始</strong>: 进入 Idle (闲置) 状态<br> 生命周期<strong>结束</strong>: 进入 End (结束) 状态</p>
<p> <strong>Idle 和 End 状态转换：</strong><br> 进入 Idle 状态：new MediaPlayer() 或者 任何状态调用了 reset() 方法之后，进入 Idle (闲置) 状态<br> 进入 End 状态：在 Idle 状态调用 release() 方法后，会进入 End (结束) 状态（涉及到资源的释放），不能转换为其他状态<br> <strong>注意：create()初始化的MediaPlayer直接进入Prepared状态</strong></p>
</li>
<li><p><strong>Error（错误）状态</strong></p>
<p> <strong>Error状态转换：</strong><br> 进入Error状态：检测到异常，系统回调onError()进入Error状态<br> 离开Error状态：可以使用reset()回到Idle状态<br> 注册监听：注册一个 OnErrorListener 监听器重写OnError(), 用于获取播放器引擎内部发生的错误<br> 注册方法：调用 MediaPlayer.setOnErrorListener(OnErrorListener) 方法，注册 OnErrorListener</p>
</li>
<li><p><strong>Initialized(初始化)状态</strong></p>
<p> <strong>Initialized 状态转换：</strong><br> 在 Idle 状态调用 setDataSource() 方法，MediaPlayer 会迁移到 Initialized 状态<br> 注意：只能在 Idle 状态调用该方法，如果在其它状态调用该方法，会报出 IllegalStateException 异常</p>
</li>
<li><p><strong>Prepared(就绪)和Preparing(准备中)状态</strong></p>
<p> <strong>Prepared状态转移(两种方式)</strong><br> Initialized状态调用 prepared() 进入Prepared状态（同步操作，若数据量较大则容易造成主线程阻塞甚至ANR）<br> Initialized状态调用 prepareAsync() 进入Preparing状态，注册OnPreparedListener.OnPrepared()，在将准备就绪后的操作放置OnPrepared()中（异步操作，便于操纵数据量大的情况，避免主线程阻塞）</p>
</li>
<li><p><strong>Started（开始）状态</strong></p>
<p> <strong>Started状态转移：</strong><br> Prepared状态调用start()进入Started状态<br> 判断MediaPlayer是否在Started状态：isPlaying():boolean<br> 跟踪缓冲状态：在 Started 状态，调用 OnBufferingUpdateListener.onBufferingUpdate() 方法，可以获取视频音频流的缓冲状态</p>
</li>
<li><p><strong>Paused（暂停）状态</strong></p>
<p> <strong>Paused状态转移：</strong><br> Started状态调用paused()进入Paused状态<br> Paused状态调用start()进入Started状态</p>
</li>
<li><p><strong>Stop状态</strong></p>
<p> <strong>Stop状态转移：</strong><br> 在 Prepared、Started、Paused、PlaybackCompleted 状态下 调用 stop() 方法，MediaPlayer 会迁移到 Stopped 状态<br> <strong>注意Stop状态不能直接start()，要回到prepared状态（prepare()或prepareAsyn()），才能start</strong></p>
</li>
<li><p><strong>播放位置调整seekTo()</strong></p>
<p> 该方法异步，调用后播放器引擎还需要进行其它操作，跳转才能完成<br> 进行的操作：播放器引擎会回调 OnSeekComplete.onSeekComplete()方法，该方法通过 setOnSeekCompleteListener() 方法注册<br> 获取播放位置：调用 getCurrentPosition() 方法，可以获取当前播放的位置，可以帮助播放器更新进度条</p>
</li>
<li><p><strong>PlaybackCompleted (播放完毕) 状态</strong></p>
<p> <strong>PlaybackCompleted 状态转移：</strong><br> 如果设置了循环模式SetLooping()，那么播放完毕之后会重新进入Started状态；若没设置循环，则调用 OnCompletion.onCompletion() 回调方法，MediaPlayer 会进入 PlaybackCompleted 状态<br> 也可以在该状态直接调用start()进入Started状态</p>
</li>
</ol>
<h4 id="MediaPlayer实现步骤时序图"><a href="#MediaPlayer实现步骤时序图" class="headerlink" title="MediaPlayer实现步骤时序图"></a>MediaPlayer实现步骤时序图</h4><img src="/47f70dd6/3.png" class>

<h4 id="播放视频"><a href="#播放视频" class="headerlink" title="播放视频"></a>播放视频</h4><ol>
<li><p>系统自带的播放器</p>
<p> 通过intent的方式，调用系统自带的播放器</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Uri uri = Uri.parse(<span class="string">&quot;/storage/emulated/0/DCIM/Camera/test.mp4&quot;</span>); </span><br><span class="line"><span class="comment">// 调用系统自带的播放器</span></span><br><span class="line">Intent intent = <span class="keyword">new</span> Intent(Intent.ACTION_VIEW);</span><br><span class="line">intent.setDataAndType(uri, <span class="string">&quot;video/mp4&quot;</span>);</span><br><span class="line">startActivity(intent);</span><br></pre></td></tr></table></figure>
</li>
<li><p>VideoView+MediaController</p>
<p> VideoView继承了SurfaceView同时实现了MediaPlayerControl接口，MediaController则是安卓封装的辅助控制器，带有暂停，播放，停止，进度条等控件。通过VideoView+MediaController可以很轻松的实现视频播放、停止、快进、快退等功能。</p>
<p> VideoView是包装过的MediaPlayer，所以使用起来很相似<br> 1)调用setVideoPath()去设置视频文件路径（非setDataSource）<br> 2)new一个MediaController<br> 3)videoView.setMediaController(mediaController)设置媒体控制器<br> 4)videoView.requestFocus()请求焦点后start()</p>
<p> 还可以设置videoView.setOnCompletionListener、videoView.setOnBufferingUpdateListener等回调函数</p>
</li>
<li><p>SurfaceView+MediaPlayer+MediaController/自定义控制器</p>
<p> 1)在界面布局文件中定义SurfaceView组件，并为SurfaceView的SurfaceHolder添加Callback监听器<br> 2)创建MediaPlayer对象，并setDataSource()让它加载指定的视频文件<br> 3)调用MediaPlayer对象的setDisplay(SurfaceHolder sh)将所播放的视频图像输出到指定的SurfaceView组件<br> 4)调用MediaPlayer对象的prepareAsync()或prepare()方法装载流媒体文件<br> 5)调用MediaPlayer对象的start()、stop()和pause()方法来控制视频的播放</p>
<p> SurfaceView例子</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyPlayer</span> <span class="keyword">implements</span> <span class="title">MediaPlayer</span>.<span class="title">OnPreparedListener</span>, <span class="title">MediaPlayer</span>.<span class="title">OnErrorListener</span>, <span class="title">MediaPlayer</span>.<span class="title">OnCompletionListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> MediaPlayer mPlayer;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> hasPrepared;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initIfNecessary</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> == mPlayer) &#123;</span><br><span class="line">            mPlayer = <span class="keyword">new</span> MediaPlayer();</span><br><span class="line">            mPlayer.setOnErrorListener(<span class="keyword">this</span>);</span><br><span class="line">            mPlayer.setOnCompletionListener(<span class="keyword">this</span>);</span><br><span class="line">            mPlayer.setOnPreparedListener(<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">play</span><span class="params">(Context context, Uri dataSource)</span> </span>&#123;</span><br><span class="line">        hasPrepared = <span class="keyword">false</span>; <span class="comment">// 开始播放前讲Flag置为不可操作</span></span><br><span class="line">        initIfNecessary(); <span class="comment">// 如果是第一次播放/player已经释放了，就会重新创建、初始化</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mPlayer.reset();</span><br><span class="line">            mPlayer.setDataSource(context, dataSource); <span class="comment">// 设置曲目资源</span></span><br><span class="line">            mPlayer.prepareAsync(); <span class="comment">// 异步的准备方法</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// release()会释放player、将player置空，所以这里需要判断一下</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != mPlayer &amp;&amp; hasPrepared) &#123;</span><br><span class="line">            mPlayer.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pause</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != mPlayer &amp;&amp; hasPrepared) &#123;</span><br><span class="line">            mPlayer.pause();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">seekTo</span><span class="params">(<span class="keyword">int</span> position)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != mPlayer &amp;&amp; hasPrepared) &#123;</span><br><span class="line">            mPlayer.seekTo(position);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 对于播放视频来说，通过设置SurfaceHolder来设置显示Surface。这个方法不需要判断状态、也不会改变player状态</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDisplay</span><span class="params">(SurfaceHolder holder)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != mPlayer) &#123;</span><br><span class="line">            mPlayer.setDisplay(holder);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        hasPrepared = <span class="keyword">false</span>;</span><br><span class="line">        mPlayer.stop();</span><br><span class="line">        mPlayer.release();</span><br><span class="line">        mPlayer = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPrepared</span><span class="params">(MediaPlayer mp)</span> </span>&#123;</span><br><span class="line">        hasPrepared = <span class="keyword">true</span>; <span class="comment">// 准备完成后回调到这里</span></span><br><span class="line">        start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(MediaPlayer mp)</span> </span>&#123;</span><br><span class="line">        hasPrepared = <span class="keyword">false</span>;</span><br><span class="line">        <span class="comment">// 通知调用处，调用play()方法进行下一个曲目的播放</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">onError</span><span class="params">(MediaPlayer mp, <span class="keyword">int</span> what, <span class="keyword">int</span> extra)</span> </span>&#123;</span><br><span class="line">        hasPrepared = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>TextureView+MediaPlayer+MediaController/自定义控制器</p>
<p> 因为SurfaceView的内容不在应用窗口上，所以不能使用变换（平移、缩放、旋转等）。也难以放在ListView或者ScrollView中，不能使用UI控件的一些特性比如View.setAlpha()。</p>
<p> 为了解决这个问题 Android 4.0中引入了TextureView。</p>
<p> 1)在界面布局文件中定义TextureView组件，并为TextureView的添加回调mTextureView.setSurfaceTextureListener<br> 2)在onSurfaceTextureAvailable回调里取出SurfaceTexture：mSurface = new Surface(surface);<br> 3)创建MediaPlayer对象，并setDataSource()让它加载指定的视频文件<br> 4)调用MediaPlayer对象的setSurface(mSurface)将所播放的视频图像输出指定<br> 5)调用MediaPlayer对象的prepareAsync()或prepare()方法装载流媒体文件<br> 6)调用MediaPlayer对象的start()、stop()和pause()方法来控制视频的播放</p>
<p> 补充：mMediaPlayer.setOnPreparedListener、mMediaPlayer.setOnCompletionListener等回调可自定义添加</p>
</li>
</ol>
<hr>
<h3 id="ExoPlayer（专注于Android）"><a href="#ExoPlayer（专注于Android）" class="headerlink" title="ExoPlayer（专注于Android）"></a>ExoPlayer（专注于Android）</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>ExoPlayer是一个开源的应用级媒体播放器项目，构建在Android的低级媒体API之上，它提供了Android的MediaPlayer API的替代方法，用于在本地和通过Internet播放音频和视频。</p>
<p>ExoPlayer支持Android的MediaPlayer API目前不支持的功能，包括DASH和SmoothStreaming自适应播放。 与MediaPlayer API不同，ExoPlayer易于自定义和扩展。</p>
<p>ExoPlayer库的核心是Exoplayer接口，Exoplayer公开了传统的高级媒体播放器功能，例如缓冲媒体、播放、暂停和seek等功能，ExoPlayer通过组件实现其它高级功能。</p>
<p>MediaSource：定义多媒体数据源，从Uri中读取数据，传入ExoPlayer<br>TrackSelector：轨道提取器，从MediaSource中提取各个轨道的二进制数据，交给Render渲染<br>LoadControl：可以控制MediaSource，比如什么时候开始缓冲，缓冲多少之后暂停缓冲</p>
<h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p>与Android内置的MediaPlayer相比，ExoPlayer具有许多优点：</p>
<ol>
<li><p>支持通过HTTP（DASH）和SmoothStreaming进行动态自适应流，这两种都不受MediaPlayer的支持</p>
</li>
<li><p>能够自定义和扩展播放器，大部分组件都可以自己替换以适应各种不同需求，还可以接入ffmpeg组件</p>
</li>
<li><p>与IJKPlayer和Vitamio相比，ExoPlayer导入项目之后APK体积增加小</p>
</li>
</ol>
<p>缺点：</p>
<ol>
<li><p>最低支持版本4.4且实现比较复杂</p>
</li>
<li><p>约增加APP包体几百KB的大小</p>
</li>
<li><p>相比于Android原生的MediaPlayer，ExoPlayer将显著的消耗更多的电量</p>
</li>
</ol>
<h4 id="支持的格式"><a href="#支持的格式" class="headerlink" title="支持的格式"></a>支持的格式</h4><img src="/47f70dd6/4.jpg" class>

<h4 id="支持设备情况"><a href="#支持设备情况" class="headerlink" title="支持设备情况"></a>支持设备情况</h4><p>ExoPlayer支持大部分流媒体格式，并且对DRM的支持也比较友好，比如下方就是官方提供的支持的设备情况：</p>
<img src="/47f70dd6/5.jpg" class>

<h4 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h4><p>通过ExoPlayer的架构图，可以看到其组件模块化的设计，这个架构设计值得学习，也是好的组件/SDK的一个重要要求。在日常项目开发中，开发一个组件从易用性和以扩展性方面考虑，既要保证使用者很容易上手使用（提供一套默认实现），又要有方便使用者根据自己的场景进行方便的扩展的能力。</p>
<img src="/47f70dd6/6.png" class>

<h4 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h4><img src="/47f70dd6/7.svg" class>

<h4 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h4><p>我们只要按照下面的步骤就能简单的将ExoPlayer使用起来了：</p>
<p>1、添加对ExoPlayer库的依赖<br>2、创建一个SimpleExoPlayer实例<br>3、将播放器关联到播放渲染的View上<br>4、将播放资源包装类MediaSource的对象准备好，通过ExoPlayer的prepare()方法设置进去<br>5、当我们不需要播放的时候记得通过release方法进行释放</p>
<ol>
<li><p><strong>添加ExoPlayer模块</strong></p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// implementation &#x27;com.google.android.exoplayer:exoplayer:2.x.x&#x27;</span></span><br><span class="line">implementation <span class="string">&#x27;com.google.android.exoplayer:exoplayer:2.15.0&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>添加Java 8支持</strong></p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">compileOptions &#123;</span><br><span class="line">        targetCompatibility JavaVersion.VERSION_1_8</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>创建播放器</strong></p>
<p> ExoPlayer可以使用SimpleExoPlayer.Builder或创建实例ExoPlayer.Builder，这些构建器提供了一系列用于创建ExoPlayer实例的定制选项。</p>
<p> 对于绝大多数用例， SimpleExoPlayer.Builder都可以使用。</p>
<p> 此构建器返回 SimpleExoPlayer，它扩展ExoPlayer为添加其他高级播放器功能。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 2.12版本以后推荐</span></span><br><span class="line">SimpleExoPlayer player = <span class="keyword">new</span> SimpleExoPlayer.Builder(context).build();</span><br></pre></td></tr></table></figure>

<p> 也可以这么创建：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建带宽</span></span><br><span class="line">BandwidthMeter bandwidthMeter = <span class="keyword">new</span> DefaultBandwidthMeter();</span><br><span class="line"><span class="comment">// 创建轨道选择工厂 视频每一这的画面如何渲染,实现默认的实现类</span></span><br><span class="line">TrackSelection.Factory videoTrackSelectionFactory = <span class="keyword">new</span> DefaultRenderersFactory(application)</span><br><span class="line"><span class="comment">// 创建轨道选择实例 视频的音视频轨道如何加载 使用默认的轨道选择器</span></span><br><span class="line">TrackSelector trackSelector = <span class="keyword">new</span> DefaultTrackSelector(videoTrackSelectionFactory);</span><br><span class="line"><span class="comment">// 创建播放器实例</span></span><br><span class="line">SimpleExoPlayer player = ExoPlayerFactory.newSimpleInstance(<span class="keyword">this</span>, trackSelector);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>将播放器附加到视图</strong></p>
<p> ExoPlayer库为媒体播放提供了一系列预构建的UI组件。其中包括StyledPlayerView，它封装了 StyledPlayerControlView、SubtitleView和渲染视频的Surface。</p>
<p> 将播放器绑定到视图</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Bind the player to the view.</span></span><br><span class="line">playerView.setPlayer(player);</span><br></pre></td></tr></table></figure>

<p> 对于实现自己的UI视频的应用，可以分别使用SimpleExoPlayer的setVideoSurfaceView()，setVideoTextureView()，setVideoSurfaceHolder()和setVideoSurface()的方法设置自己的SurfaceView，TextureView， SurfaceHolder或者Surface。</p>
<p> SimpleExoPlayer的addTextOutput()可用于接收在播放过程中应呈现的字幕。</p>
</li>
<li><p><strong>填充播放列表并准备播放器</strong></p>
<p> 在ExoPlayer中，每种媒体都由表示MediaItem。播放列表可以在播放期间进行更新，而无需再次准备播放器。</p>
<p> 要播放媒体，需要构建相应的媒体MediaItem，将其添加到播放器中，准备播放器，然后调用play以开始播放：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建mediaItem</span></span><br><span class="line">MediaItem mediaItem = MediaItem.fromUri(videoUri);</span><br><span class="line"><span class="comment">// 设置mediaItem</span></span><br><span class="line">player.setMediaItem(mediaItem);</span><br><span class="line"><span class="comment">// 准备播放</span></span><br><span class="line">player.prepare();</span><br><span class="line"><span class="comment">// 开始播放</span></span><br><span class="line">player.play();</span><br></pre></td></tr></table></figure>

<p> ExoPlayer直接支持播放列表，因此可以为播放器准备多个要依次播放的媒体项目：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建mediaItem</span></span><br><span class="line">MediaItem firstItem = MediaItem.fromUri(firstVideoUri);</span><br><span class="line">MediaItem secondItem = MediaItem.fromUri(secondVideoUri);</span><br><span class="line"><span class="comment">// 添加要播放的媒体项目。</span></span><br><span class="line">player.addMediaItem(firstItem);</span><br><span class="line">player.addMediaItem(secondItem);</span><br><span class="line"><span class="comment">// 准备播放</span></span><br><span class="line">player.prepare();</span><br><span class="line"><span class="comment">// 开始播放</span></span><br><span class="line">player.play();</span><br></pre></td></tr></table></figure>

<p> 在ExoPlayer 2.12之前，player需要的是一个MediaSource而不是MediaItem。从2.12开始，player内部会将MediaItem转换为需要的 MediaSource实例，但仍可以使用ExoPlayer.setMediaSource()和ExoPlayer.addMediaSource()将MediaSource实例直接提供给播放器。</p>
<p> 2.12之前是这样创建的</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建加载数据的工厂 (生成加载媒体数据的数据源实例)</span></span><br><span class="line">DataSource.Factory dataSourceFactory = <span class="keyword">new</span> DefaultDataSourceFactory(context, Util.getUserAgent(context, <span class="string">&quot;yourApplicationName&quot;</span>));</span><br><span class="line"></span><br><span class="line">Uri uri = Uri.parse(url);</span><br><span class="line"><span class="comment">// 创建资源</span></span><br><span class="line">ExtractorMediaSource mediaSource = <span class="keyword">new</span> ExtractorMediaSource.Factory(dataSourceFactory).createMediaSource(uri);</span><br><span class="line"><span class="comment">// 或者MediaSource mediaSource= new ProgressiveMediaSource.Factory(dataSourceFactory).createMediaSource(uri);</span></span><br><span class="line"><span class="comment">// 准备播放</span></span><br><span class="line">player.prepare(mediaSource);</span><br><span class="line"><span class="comment">// 开始播放</span></span><br><span class="line">player.setPlayWhenReady(<span class="keyword">true</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>控制播放器</strong></p>
<p> 准备好播放器后，可以通过调用播放器上的方法来控制播放。下面列出了一些最常用的方法：<br> play()、pause()，开始和暂停播放<br> seekTo()，允许在media内搜寻。<br> hasPrevious()、hasNext()、previous()、next()，允许通过播放列表进行浏览。<br> setRepeatMode()，控制media是否循环以及如何循环。<br> setShuffleModeEnabled()，控制播放列表移动。<br> setPlaybackParameters()，调整播放速度和音频音高。</p>
<p> 如果player绑定到PlayerView或PlayerControlView，则用户与这些组件的交互将导致调用player上的相应方法。</p>
</li>
<li><p><strong>释放播放器</strong></p>
<p> 在不再需要播放器时将其释放，以释放有限的资源（例如视频解码器）供其他应用程序使用。</p>
<p> 可以通过调用来完成ExoPlayer.release</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.onDestroy();</span><br><span class="line">    <span class="keyword">if</span> (player != <span class="keyword">null</span>) &#123;</span><br><span class="line">        player.release();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="拓展使用"><a href="#拓展使用" class="headerlink" title="拓展使用"></a>拓展使用</h4><ol>
<li><p>添加回调函数与其它监听器</p>
<p> Events 如状态更改和播放错误等事件将报告给已注册Player.EventListener实例。</p>
<p> 注册一个监听器来接收这样的事件：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 添加一个监听器来接收来自播放器的事件.</span></span><br><span class="line">player.addListener(eventListener);</span><br></pre></td></tr></table></figure>

<p> 通用回调：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>onEvents(Player player, Events events)</td>
<td>回调</td>
</tr>
</tbody></table>
<p> 个别回调：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>onPlaybackStateChanged(@State int state)</td>
<td>播放状态变更</td>
</tr>
<tr>
<td>onIsPlayingChanged(boolean isPlaying)</td>
<td>单独检查是否播放，不用每次都isPlaying()</td>
</tr>
<tr>
<td>onPlayerError(ExoPlaybackException error)</td>
<td>接收到导致播放失败的错误信息，发生错误时将在播放状态转换为Player.STATE_IDLE之前立即调用此方法。可以通过调用ExoPlayer.retry重试或停止的播放</td>
</tr>
<tr>
<td>onMediaItemTransition(MediaItem mediaItem, @MediaItemTransitionReason int reason)</td>
<td>播放器更改播放列表中的新媒体项目时，就会在注册Player.EventListeners上调用到 。表明原因是自动过渡、seek（例如在调用之后player.next()）、重复相同项目还是由于播放列表更改（例如，如果当前正在播放的项目被删除）引起的</td>
</tr>
<tr>
<td>onPositionDiscontinuity()与reason=DISCONTINUITY_REASON_SEEK</td>
<td>是调用Player.seekTo的直接结果</td>
</tr>
</tbody></table>
<p> 两者的区别：</p>
<table>
<thead>
<tr>
<th>通用回调</th>
<th>个别回调</th>
</tr>
</thead>
<tbody><tr>
<td>希望针对多个事件触发相同的逻辑（例如更新用于两者的UIonPlaybackStateChanged和 onPlayWhenReadyChanged）</td>
<td>对更改的原因感兴趣。例如，为onPlayWhenReadyChanged或提供的原因onMediaItemTransition</td>
</tr>
<tr>
<td>需要访问该Player对象以触发其他事件，例如在媒体项转换后进行搜索</td>
<td>仅对通过回调参数提供的新值起作用，或触发不依赖于回调参数的其他事件</td>
</tr>
<tr>
<td>对事件是否在逻辑上一起发生感兴趣。例如onPlaybackStateChanged，以STATE_BUFFERING因媒体项目过渡。</td>
<td>更喜欢在方法名称中以清晰可读的方式指示触发事件的原因</td>
</tr>
</tbody></table>
<p> 添加其它SimpleExoPlayer监听器：<br> addAnalyticsListener：收听详细的事件，这些事件可能对分析和日志记录有用。请参阅分析页面以获取更多详细信息。<br> addTextOutput：收听字幕或字幕提示中的更改。<br> addMetadataOutput：收听定时的元数据事件，例如定时的ID3和EMSG数据。<br> addVideoListener：收听与视频渲染有关的事件，这些事件可能对调整UI有用（例如，Surface正在渲染视频的长宽比）。<br> addAudioListener：收听与音频有关的事件，例如音频会话ID更改以及播放器音量更改时。<br> addDeviceListener：收听与设备状态有关的事件。</p>
<p> ExoPlayer的UI组件（例如StyledPlayerView）将自己注册为相应的事件的监听器。因此，使用上述方法进行手动注册仅对实现自己的播放器UI或需要出于其他目的监听事件的应用程序有用。</p>
</li>
<li><p>在指定的播放位置触发事件</p>
<p> 如果需要在指定的播放位置触发事件，支持使用ExoPlayer.createMessage()来创建PlayerMessage。它可以使用来设置应执行播放的位置PlayerMessage.setPosition()。默认情况下，消息是在播放线程上执行的，但这可以使用进行自定义 PlayerMessage.setLooper()。PlayerMessage.setDeleteAfterDelivery()可用于控制是在每次遇到指定的播放位置时（是由于搜寻和重复模式而发生多次）还是仅在第一次时执行消息。一旦PlayerMessage配置了，就可以使用进行安排PlayerMessage.send()。</p>
<p> 在指定的播放位置触发事件</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">player.createMessage((messageType, payload) -&gt; &#123;</span><br><span class="line">    <span class="comment">// Do something at the specified playback position.</span></span><br><span class="line">&#125;)</span><br><span class="line">.setLooper(Looper.getMainLooper())</span><br><span class="line">.setPosition(<span class="comment">/* windowIndex= */</span> <span class="number">0</span>, <span class="comment">/* positionMs= */</span> <span class="number">120000</span>)</span><br><span class="line">.setPayload(customPayloadData)</span><br><span class="line">.setDeleteAfterDelivery(<span class="keyword">false</span>)</span><br><span class="line">.send();</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询/修改播放列表</p>
<p> 可以使用Player.getMediaItemCount和Player.getMediaItemAt()来查询播放列表。</p>
<p> 可以通过Player.getCurrentMediaItem()查询当前播放的媒体项目。</p>
<p> 可以通过添加、移动和删除媒体项来动态修改播放列表。</p>
<p> 可以在播放之前和播放过程中通过调用相应的播放列表API方法来完成此操作：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在playlist的position添加一个MediaItem</span></span><br><span class="line">player.addMediaItem(<span class="comment">/* index= */</span> <span class="number">1</span>, MediaItem.fromUri(thirdUri));</span><br><span class="line"><span class="comment">//将第三个MediaItem从位置2移动到playlist的开始</span></span><br><span class="line">player.moveMediaItem(<span class="comment">/* currentIndex= */</span> <span class="number">2</span>, <span class="comment">/* newIndex= */</span> <span class="number">0</span>);</span><br><span class="line"><span class="comment">// 从playlist中移除第一项</span></span><br><span class="line">player.removeMediaItem(<span class="comment">/* index= */</span> <span class="number">0</span>);</span><br></pre></td></tr></table></figure>

<p> 还支持替换和清除整个播放列表：</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Replaces the playlist with a new one.</span></span><br><span class="line">List&lt;MediaItem&gt; newItems = ImmutableList.of(</span><br><span class="line">    MediaItem.fromUri(fourthUri),</span><br><span class="line">    MediaItem.fromUri(fifthUri)</span><br><span class="line">);</span><br><span class="line">player.setMediaItems(newItems, <span class="comment">/* resetPosition= */</span> <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// Clears the playlist. If prepared, the player transitions to the ended state.</span></span><br><span class="line">player.clearMediaItems();</span><br></pre></td></tr></table></figure>

<p> 播放器会在播放过程中以正确的方式自动处理修改。例如，如果当前播放的媒体项目已移动，则播放不会中断，并且新的后继对象将在完成后播放。如果MediaItem删除了当前正在播放的列表项，则播放器将自动移动到播放剩余的第一个后继列表项，如果不存在该后继播放器，则播放器将过渡到结束状态。</p>
</li>
</ol>
<hr>
<h3 id="ijkPlayer（专注于跨平台）"><a href="#ijkPlayer（专注于跨平台）" class="headerlink" title="ijkPlayer（专注于跨平台）"></a>ijkPlayer（专注于跨平台）</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>ijkplayer是由b站开源的播放器项目，最底层的是<strong>ijkffmpeg</strong>模块是由著名的开源流媒体开源项目ffmpeg改写而来，负责视频的解协议、解封装的一些业务。</p>
<p>yuv格式一开始是为了广播电视信号兼容黑白电视而生，而在网络时代由于yuv420、yuv420sp需要的带宽相对较小所以依然得到了沿用。但是由于硬件设备支持的都是rgba格式的像素信息，所以解封装之后拿到的像素信息需要进行转化之后才可以显示出来，ijkplayer中负责这方面功能的模块是<strong>ijkyuv</strong>。</p>
<p>像素信息解析之后需要展示到用户的面前，ijkplayer选择了使用著名的可移植框架SDL，但是ijkplayer针对移动平台的进行了优化并将名称改为<strong>ijkSDL</strong>。</p>
<p>既然有像素信息的处理那就必然也存在对音频信息的处理，比较常见的一个场景就是变速播放，但是OpenSL ES在倍速播放音频的时候存在变调的问题，所以引入了<strong>ijksoundtouch</strong>来解决倍速变调的问题。</p>
<p>android平台原生就支持多种格式，并且如果使用硬件解码的话可以降低cpu的载荷，将这些任务交给gpu进行。但是比较尴尬的是ndk在android 21之后才添加相关的接口。所以为了适配低配置低版本Android手机 ijkplayer 采用了 ndk 调用 java 方法的方式来进行硬件解码。同时如果选择AudioTrack进行播放的话也是通过这种方式进行的，负责这一方面工作的就是<strong>ijkj4a</strong>。</p>
<h4 id="系统架构图"><a href="#系统架构图" class="headerlink" title="系统架构图"></a>系统架构图</h4><p>Android上的系统架构图如下：</p>
<img src="/47f70dd6/8.png" class>

<p><strong>ijkplayer-example：</strong>是ui逻辑的实现，包括activity的实现、ui控件的组织、窗口的定制、数据的存储。通过调用ijkmediaplayer、android mediaplayer、 google exoplayer这三种mediaplayer来实现媒体播放。</p>
<p><strong>ijkplayer-java：</strong>是对底层实现的ijkmediaplayer和android mediaplayer的java封装，对ijkmediaplayer的封装是通过调用底层jni对应的java接口，对android mediaplayer的封装是调用android系统实现的默认mediaplayer接口。</p>
<p><strong>ijkplayer-exo：</strong>是对google exoplayer的封装。</p>
<p><strong>libijkplayer：</strong>提供了ijkmediaplayer的jni实现ijkplayer_jni.c，然后调用封装过的ffplayer.c，再调用底层实现的解码库libijkffmpeg和显示库libijksdl，实现了媒体文件的demux、decode等功能。</p>
<p><strong>libijksdl：</strong>实现对解码后的数据进行显示。</p>
<h4 id="Java层关键模块分析"><a href="#Java层关键模块分析" class="headerlink" title="Java层关键模块分析"></a>Java层关键模块分析</h4><ol>
<li><p>三种不同的mediaplayer实现</p>
 <img src="/47f70dd6/9.png" class>

<p> AndroidMediaPlayer是对Andoid默认播放器的封装。<br> IjkMediaPlayer是基于ffmpeg的播放器实现。<br> IjkExoMediaPlayer是基于Goodle开源的ExoPlayer的封装。</p>
</li>
<li><p>设置不同的Render</p>
 <img src="/47f70dd6/10.png" class>

<p> SurfaceRenderView是基于SurfaceView的显示实现。<br> TextureRenderView是基于TextureView的显示实现。<br> 上述两种显示实现方式都实现了接口IRenderView。</p>
</li>
</ol>
<h4 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h4><ol>
<li><p>设置surface</p>
 <img src="/47f70dd6/11.png" class>

<p> 通过接口_setVideoSurface()，把UI层的Surface对象（可以理解为显示窗口）设置给SDL显示对象，作为其显示窗口（native_window），这样SDL有需要显示的内容可以直接在这个显示窗口上显示输出即可。</p>
</li>
<li><p>显示流程</p>
 

<p> 解码线程ffp_video_thread()解码完成以后，调用接口queue_picture()把需要显示的buffer往SDL模块发送。<br> 然后调用func_fill_frame()填充显示buffer, 这个时候需要判断是通过ffmpeg还是mediacodec实现的解码。<br> 如果是ffmpeg实现的话则调用ijksdl_vout_overlay_ffmpeg.c中的函数func_fill_frame()。<br> 否则调用ijksdl_vout_overlay_android_mediacodec.c中的func_fill_frame()。<br> 然后显示线程video_refresh_thread就可以开始显示了。如果是GPU支持的格式则调用GPU进行输出，这个时候调用的是IJK_EGL_display，否则调用ANativeWindow_lock和ANativeWindow_unlockAndPost进行输出。</p>
</li>
</ol>
<h4 id="基本使用-1"><a href="#基本使用-1" class="headerlink" title="基本使用"></a>基本使用</h4><p>ijkPlayer的使用与mediaPlayer的过程基本相似，即将MediaPlayer对象换为IjkMediaPlayer对象。不同的是IjkMediaPlayer在不同平台下针对性的底层解码。</p>
<hr>
<h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>DKPlayer、GSYVideoPlayer 基于ijkPlayer的播放器；<br>JiaoZiVideoPlayer 专注于多播放内核切换，方便接入者使用不同的播放内核；<br>PLDroidPlayer 专注于完整 SDK 的开发，但它目前应该还是闭源的，用户难以定制。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>MediaPlayer：</strong>在Android系统中对于视频播放器有原生的实现MediaPlayer，以及将MediaPlayer、SurfaceView封装在一起的VideoView，两者都只是使用硬解播放，基本上只支持本地和HTTP协议的视频播放，扩展性都很差，只适合最简单的视频播放需求。</p>
<p><strong>ExoPlayer：</strong>提供了更好的扩展性和定制能力，并加入了对DASH和HLS等直播协议的支持，但也只支持硬码，如果项目中只需要支持对H264格式的视频播放，以及流媒体协议比较常规（比如HTTP，HLS），基于ExoPlayer定制也是不错的选择。</p>
<p><strong>IjkPlayer：</strong>整合了FFMpeg、ExoPlayer、MediaPlayer等多种实现，提供了类似于MediaPlayer的API，可以实现软硬解码自由切换，自定义TextureView实现，同时得益于FFMpeg的能力，也能支持多种流媒体协议（RTSP、RTMP、HLS等），多种视频编码格式（h264，mpeg4，mjpeg)，具有很高的灵活性，可以定制实现自己特色的播放器（比如支持视频缩放、视频翻转等）。</p>
<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://blog.csdn.net/weixin_43846184/article/details/96132895">https://blog.csdn.net/weixin_43846184/article/details/96132895</a><br><a href="https://www.jianshu.com/p/3f2f8bf1d581">https://www.jianshu.com/p/3f2f8bf1d581</a><br><a href="https://blog.csdn.net/u014606081/article/details/79927057">https://blog.csdn.net/u014606081/article/details/79927057</a><br><a href="https://blog.csdn.net/qq_35864421/article/details/115345091">https://blog.csdn.net/qq_35864421/article/details/115345091</a><br><a href="https://blog.csdn.net/dengpeng_/article/details/54910840">https://blog.csdn.net/dengpeng_/article/details/54910840</a><br><a href="https://blog.csdn.net/codeyanbao/article/details/92842939">https://blog.csdn.net/codeyanbao/article/details/92842939</a><br><a href="https://cloud.tencent.com/developer/article/1824644">https://cloud.tencent.com/developer/article/1824644</a><br><a href="https://blog.51cto.com/u_15127656/2803056">https://blog.51cto.com/u_15127656/2803056</a><br><a href="https://exoplayer.dev/doc/reference/com/google/android/exoplayer2/ExoPlayer.html">https://exoplayer.dev/doc/reference/com/google/android/exoplayer2/ExoPlayer.html</a><br><a href="https://exoplayer.dev/doc/reference/com/google/android/exoplayer2/Player.EventListener.html">https://exoplayer.dev/doc/reference/com/google/android/exoplayer2/Player.EventListener.html</a><br><a href="https://exoplayer.dev/listening-to-player-events.html#individual-callbacks-vs-onevents">https://exoplayer.dev/listening-to-player-events.html#individual-callbacks-vs-onevents</a><br><a href="https://wenxiaoming.github.io/2018/03/19/analysis-of-ijkplayer/">https://wenxiaoming.github.io/2018/03/19/analysis-of-ijkplayer/</a><br><a href="https://zhuanlan.zhihu.com/p/256402336">https://zhuanlan.zhihu.com/p/256402336</a><br><a href="https://blog.csdn.net/qq_34895720/article/details/101511876">https://blog.csdn.net/qq_34895720/article/details/101511876</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-唤起触觉的双向BCI控制的机械臂</title>
    <url>/56c2e2c4.html</url>
    <content><![CDATA[<p>2021年5月21日，美国匹兹堡复中心神经工程实验室（University of Pittsburgh Rehab Neural Engineering Labs）在《Science》的杂志中发表了论文《A brain-computer interface that evokes tactile sensations improves robotic arm control》，其中描述了一位瘫痪的患者可以由大脑来控制机械臂，并且机械臂可向这个人的大脑提供一个触觉反馈。在提供触觉反馈之后，操作者进行抓取物体等实验的时间减少了51.2%，从20.9秒的中位数减少到了10.2秒。论文提出，使用植入电极测量运动相关神经活动的脑机接口 (BCI) 可以恢复部分失去的手臂和手部功能 ，因为皮层仍然能够产生控制手臂和手部运动的神经活动。因此，脑机接口可以绕过受伤的脊髓来控制假肢 、功能性电刺激系统或其他设备。</p>
<img src="/56c2e2c4/1.png" class>

<span id="more"></span>

<p>在之前开发的BCI控制的机械臂中，完成伸手和抓取等动作仅仅依赖于视觉，缺乏关键的感官维度，再进一步是使用微小的电脉冲来刺激大脑的感觉区域。而在这项研究当中使用了双向BCI——一种通过皮层刺激唤起触觉的系统，而尝试运动期间的神经记录被解码以控制机器人假肢。该团队开发了一个“双向”接口——这意味着它不仅可以“读取”大脑的指令并将它们发送到假肢，还可以“写入”设备的感觉并将它们传输回来。</p>
<img src="/56c2e2c4/2.png" class>

<p>2004 年，一场车祸中，Copeland 手臂受损，于是他加入了一项用以测试触觉运动微电机的脑-机接口（brain-computer interface，BCI）的临床实验，并植入了美国 Blackrock Microsystems 公司的四块微电机阵列，通常也称作 Utah 阵列。“我是世界上第一个在感觉皮层中植入可以直接刺激我的大脑的人，”34 岁的内森科普兰说道。“然后我觉得好像有一种感觉来自我的手。”他自愿参加科学研究，并在六年前进行了一次大手术，将微型电极植入了他的大脑。两组 88 个电极，一根头发那么宽，排列成“阵列”，类似于小发刷，深入大脑的运动皮层，指导运动。研究的共同主要作者、匹兹堡大学物理医学与康复系助理教授 Rob Gaunt 说，世界上只有不到 30 人拥有这种植入物。</p>
<img src="/56c2e2c4/3.png" class>

<p>在Copeland的大脑中，有一组特殊的电极，他们连接到身体的感觉皮层，用于接收和处理感觉。Copenlan说，触觉反馈对于充当义肢的机械臂来说非常重要，没有触觉反馈你很难去抓取一个东西，因为你感觉不到它。对于正常人来说很简单的一件事情，比如用手去握住一个苹果，是非常依赖于手上的触觉反馈的。“当我们抓取物体的时候，我们很自然的去使用触觉来提高控制物品的能力，但这对残疾人来说是非常困难的”纲特解释说道。</p>
<p>约翰·霍普金斯大学机械工程系约翰·c·马龙的助理教授杰里米·d·布朗表示，研究结果的意义远远超出了机器人手臂。“高科技义肢在模拟触觉时也能更好地工作，有些是通过振动或提供其他形式的触觉反馈来实现的，这与许多智能手机上帮助用户在屏幕上打字的方法相同。”</p>
<p>布朗说，随着假肢或机械臂提供更多的感官反馈，它们将变得更有用。“触觉不仅仅是为了增加灵活性。这不仅仅是把手伸进口袋里拿钥匙的能力。它还可以牵着爱人的手，感受那种情感联系。”</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10652">https://www.scholat.com/teamwork/showPostMessage.html?id=10652</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-AAC编码</title>
    <url>/18fff05b.html</url>
    <content><![CDATA[<h3 id="什么是AAC"><a href="#什么是AAC" class="headerlink" title="什么是AAC"></a>什么是AAC</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>AAC是高级音频编码（Advanced Audio Coding）的缩写，出现于1997年，最初是基于MPEG-2的音频编码技术。由Fraunhofer IIS、Dolby Laboratories、AT&amp;T、Sony等公司共同开发，目的是取代MP3格式。2000年，MPEG-4标准出台，AAC重新集成了其它技术（PS,SBR），为区别于传统的MPEG-2 AAC，故含有SBR或PS特性的AAC又称为MPEG-4 AAC。</p>
<p>AAC通常压缩比为18：1，也有资料说为20：1，远胜mp3。</p>
<span id="more"></span>

<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ol>
<li><p>AAC是一种高压缩比的音频压缩算法，但它的压缩比要远超过较老的音频压缩算法，如AC-3、MP3等。并且其质量可以同未压缩的CD音质相媲美。</p>
</li>
<li><p>同其他类似的音频编码算法一样，AAC也是采用了变换编码算法，但AAC使用了分辨率更高的滤波器组，因此它可以达到更高的压缩比。</p>
</li>
<li><p>AAC使用了临时噪声重整、后向自适应线性预测、联合立体声技术和量化哈夫曼编码等最新技术，这些新技术的使用都使压缩比得到进一步的提高。</p>
</li>
<li><p>AAC支持更多种采样率和比特率、支持1个到48个音轨、支持多达15个低频音轨、具有多种语言的兼容能力、还有多达15个内嵌数据流。</p>
</li>
<li><p>AAC支持更宽的声音频率范围，最高可达到96kHz，最低可达8KHz，远宽于MP3的16KHz-48kHz的范围。</p>
</li>
<li><p>不同于MP3及WMA，AAC几乎不损失声音频率中的甚高、甚低频率成分，并且比WMA在频谱结构上更接近于原始音频，因而声音的保真度更好。专业评测中表明，AAC比WMA声音更清晰，而且更接近原音。</p>
</li>
<li><p>AAC采用优化的算法达到了更高的解码效率，解码时只需较少的处理能力。</p>
</li>
</ol>
<h4 id="编码方式"><a href="#编码方式" class="headerlink" title="编码方式"></a>编码方式</h4><p>AAC音频格式有ADIF和ADTS：</p>
<p><strong>ADIF：</strong>Audio Data Interchange Format 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不需进行在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。故这种格式常用在磁盘文件中。</p>
<p><strong>ADTS：</strong>Audio Data Transport Stream 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。它的特征类似于mp3数据流格式。</p>
<p>简单说，ADTS可以在任意帧解码，也就是说它每一帧都有头信息。ADIF只有一个统一的头，所以必须得到所有的数据后解码。且这两种的header的格式也是不同的，目前一般编码后的和抽取出的都是ADTS格式的音频流。</p>
<p>ADTS是帧序列，本身具备流特征，在音频流的传输与处理方面更加合适。</p>
<hr>
<h3 id="ADIF编码"><a href="#ADIF编码" class="headerlink" title="ADIF编码"></a>ADIF编码</h3><p><strong>ADIF：</strong>Audio Data Interchange Format 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不需进行在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。故这种格式常用在磁盘文件中。</p>
<img src="/18fff05b/3.webp" class>

<p>ADIF只有一个文件头。</p>
<h4 id="ADIF头信息"><a href="#ADIF头信息" class="headerlink" title="ADIF头信息"></a>ADIF头信息</h4><img src="/18fff05b/4.webp" class>

<hr>
<h3 id="ADTS编码"><a href="#ADTS编码" class="headerlink" title="ADTS编码"></a>ADTS编码</h3><p><strong>ADTS：</strong>Audio Data Transport Stream 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。它的特征类似于mp3数据流格式。这种格式可以用于广播电视。</p>
<img src="/18fff05b/1.webp" class>

<p>可以看到ADTS的每一帧都有头信息，即ADTS_header，ADTS头中相对有用的信息是采样率、声道数、帧长度。一般ADTS头信息都是7字节，如果有CRC则为9字节。</p>
<p>ADTS每个包前面有一个文件头。</p>
<h4 id="ADTS头信息"><a href="#ADTS头信息" class="headerlink" title="ADTS头信息"></a>ADTS头信息</h4><img src="/18fff05b/5.webp" class>

<h4 id="ADTS帧首部结构"><a href="#ADTS帧首部结构" class="headerlink" title="ADTS帧首部结构"></a>ADTS帧首部结构</h4><table>
<thead>
<tr>
<th>序号</th>
<th>域</th>
<th>长度（bits）</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Syncword</td>
<td>12</td>
<td>all bits must be 1</td>
</tr>
<tr>
<td>2</td>
<td>MPEG version</td>
<td>1</td>
<td>0 for MPEG-4, 1 for MPEG-2</td>
</tr>
<tr>
<td>3</td>
<td>Layer</td>
<td>2</td>
<td>always 0</td>
</tr>
<tr>
<td>4</td>
<td>Protection Absent</td>
<td>1</td>
<td>et to 1 if there is no CRC and 0 if there is CRC</td>
</tr>
<tr>
<td>5</td>
<td>Profile</td>
<td>2</td>
<td>the MPEG-4 Audio Object Type minus 1</td>
</tr>
<tr>
<td>6</td>
<td>MPEG-4 Sampling Frequency Index</td>
<td>4</td>
<td>MPEG-4 Sampling Frequency Index (15 is forbidden)</td>
</tr>
<tr>
<td>7</td>
<td>Private Stream</td>
<td>1</td>
<td>set to 0 when encoding, ignore when decoding</td>
</tr>
<tr>
<td>8</td>
<td>MPEG-4 Channel Configuration</td>
<td>3</td>
<td>MPEG-4 Channel Configuration (in the case of 0, the channel configuration is sent via an inband PCE)</td>
</tr>
<tr>
<td>9</td>
<td>Originality</td>
<td>1</td>
<td>set to 0 when encoding, ignore when decoding</td>
</tr>
<tr>
<td>10</td>
<td>Home</td>
<td>1</td>
<td>set to 0 when encoding, ignore when decoding</td>
</tr>
<tr>
<td>11</td>
<td>Copyrighted Stream</td>
<td>1</td>
<td>set to 0 when encoding, ignore when decoding</td>
</tr>
<tr>
<td>12</td>
<td>Copyrighted Start</td>
<td>1</td>
<td>set to 0 when encoding, ignore when decoding</td>
</tr>
<tr>
<td>13</td>
<td>Frame Length</td>
<td>13</td>
<td>this value must include 7 or 9 bytes of header length: FrameLength = (ProtectionAbsent == 1 ? 7 : 9) + size(AACFrame)</td>
</tr>
<tr>
<td>14</td>
<td>Buffer Fullness</td>
<td>11</td>
<td>buffer fullness</td>
</tr>
<tr>
<td>15</td>
<td>Number of AAC Frames</td>
<td>2</td>
<td>number of AAC frames (RDBs) in ADTS frame minus 1, for maximum compatibility always use 1 AAC frame per ADTS frame</td>
</tr>
<tr>
<td>16</td>
<td>CRC</td>
<td>16</td>
<td>CRC if protection absent is 0</td>
</tr>
</tbody></table>
<h4 id="ADTS头部的生成"><a href="#ADTS头部的生成" class="headerlink" title="ADTS头部的生成"></a>ADTS头部的生成</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 添加ADTS头部</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> packet    ADTS header 的 byte[]，长度为7</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> packetLen 该帧的长度，包括header的长度</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addADTStoPacket</span><span class="params">(<span class="keyword">byte</span>[] packet, <span class="keyword">int</span> packetLen)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> profile = <span class="number">2</span>; <span class="comment">// AAC LC</span></span><br><span class="line">    <span class="keyword">int</span> freqIdx = <span class="number">3</span>; <span class="comment">// 48000Hz</span></span><br><span class="line">    <span class="keyword">int</span> chanCfg = <span class="number">2</span>; <span class="comment">// 2 Channel</span></span><br><span class="line"></span><br><span class="line">    packet[<span class="number">0</span>] = (<span class="keyword">byte</span>) <span class="number">0xFF</span>;</span><br><span class="line">    packet[<span class="number">1</span>] = (<span class="keyword">byte</span>) <span class="number">0xF9</span>;</span><br><span class="line">    packet[<span class="number">2</span>] = (<span class="keyword">byte</span>) (((profile - <span class="number">1</span>) &lt;&lt; <span class="number">6</span>) + (freqIdx &lt;&lt; <span class="number">2</span>) + (chanCfg &gt;&gt; <span class="number">2</span>));</span><br><span class="line">    packet[<span class="number">3</span>] = (<span class="keyword">byte</span>) (((chanCfg &amp; <span class="number">3</span>) &lt;&lt; <span class="number">6</span>) + (packetLen &gt;&gt; <span class="number">11</span>));</span><br><span class="line">    packet[<span class="number">4</span>] = (<span class="keyword">byte</span>) ((packetLen &amp; <span class="number">0x7FF</span>) &gt;&gt; <span class="number">3</span>);</span><br><span class="line">    packet[<span class="number">5</span>] = (<span class="keyword">byte</span>) (((packetLen &amp; <span class="number">7</span>) &lt;&lt; <span class="number">5</span>) + <span class="number">0x1F</span>);</span><br><span class="line">    packet[<span class="number">6</span>] = (<span class="keyword">byte</span>) <span class="number">0xFC</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中profile表示使用哪个级别的AAC，在MPEG-2 AAC中定义了3种：</p>
<img src="/18fff05b/2.webp" class>

<p>freqIdx表示使用的采样率下标，通过这个下标在 Sampling Frequencies[ ]数组中查找得知采样率的值：</p>
<table>
<thead>
<tr>
<th>freqIdx</th>
<th>采样率（Hz）</th>
<th>freqIdx</th>
<th>采样率（Hz）</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>96000Hz</td>
<td>1</td>
<td>88200Hz</td>
</tr>
<tr>
<td>2</td>
<td>64000Hz</td>
<td>3</td>
<td>48000Hz</td>
</tr>
<tr>
<td>4</td>
<td>44100Hz</td>
<td>5</td>
<td>32000Hz</td>
</tr>
<tr>
<td>6</td>
<td>24000Hz</td>
<td>7</td>
<td>22050Hz</td>
</tr>
<tr>
<td>8</td>
<td>16000Hz</td>
<td>9</td>
<td>12000Hz</td>
</tr>
<tr>
<td>10</td>
<td>11025Hz</td>
<td>11</td>
<td>8000Hz</td>
</tr>
<tr>
<td>12</td>
<td>7350Hz</td>
<td>13</td>
<td>Reserved</td>
</tr>
<tr>
<td>14</td>
<td>Reserved</td>
<td>15</td>
<td>frequency is written explictly</td>
</tr>
</tbody></table>
<p>chanCfg表示声道数：</p>
<table>
<thead>
<tr>
<th>chanCfg</th>
<th>声道数</th>
<th>chanCfg</th>
<th>声道数</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>Defined in AOT Specifc Config</td>
<td>1</td>
<td>1 channel: front-center</td>
</tr>
<tr>
<td>2</td>
<td>2 channels: front-left, front-right</td>
<td>3</td>
<td>3 channels: front-center, front-left, front-right</td>
</tr>
<tr>
<td>4</td>
<td>4 channels: front-center, front-left, front-right, back-center</td>
<td>5</td>
<td>5 channels: front-center, front-left, front-right, back-left, back-right</td>
</tr>
<tr>
<td>6</td>
<td>6 channels: front-center, front-left, front-right, back-left, back-right, LFE-channel</td>
<td>7</td>
<td>8 channels: front-center, front-left, front-right, side-left, side-right, back-left, back-right, LFE-channel</td>
</tr>
<tr>
<td>8-15</td>
<td>Reserved</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<hr>
<h4 id="AAC的解析"><a href="#AAC的解析" class="headerlink" title="AAC的解析"></a>AAC的解析</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AACHelper</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 采样频率对照表</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Map&lt;Integer, Integer&gt; samplingFrequencyIndexMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">96000</span>, <span class="number">0</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">88200</span>, <span class="number">1</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">64000</span>, <span class="number">2</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">48000</span>, <span class="number">3</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">44100</span>, <span class="number">4</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">32000</span>, <span class="number">5</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">24000</span>, <span class="number">6</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">22050</span>, <span class="number">7</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">16000</span>, <span class="number">8</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">12000</span>, <span class="number">9</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">11025</span>, <span class="number">10</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">8000</span>, <span class="number">11</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x0</span>, <span class="number">96000</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x1</span>, <span class="number">88200</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x2</span>, <span class="number">64000</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x3</span>, <span class="number">48000</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x4</span>, <span class="number">44100</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x5</span>, <span class="number">32000</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x6</span>, <span class="number">24000</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x7</span>, <span class="number">22050</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x8</span>, <span class="number">16000</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0x9</span>, <span class="number">12000</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0xa</span>, <span class="number">11025</span>);</span><br><span class="line">        samplingFrequencyIndexMap.put(<span class="number">0xb</span>, <span class="number">8000</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> AdtsHeader mAdtsHeader = <span class="keyword">new</span> AdtsHeader();</span><br><span class="line">    <span class="keyword">private</span> BitReader mHeaderBitReader = <span class="keyword">new</span> BitReader(<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">7</span>]);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">byte</span>[] mSkipTwoBytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">private</span> FileInputStream mFileInputStream;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">byte</span>[] mBytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 构造函数，通过传递进来的文件路径创建输入流</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> aacFilePath AAC文件路径</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> FileNotFoundException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">AACHelper</span><span class="params">(String aacFilePath)</span> <span class="keyword">throws</span> FileNotFoundException </span>&#123;</span><br><span class="line">        mFileInputStream = <span class="keyword">new</span> FileInputStream(aacFilePath);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取下一Sample数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> byteBuffer 存放Sample数据的ByteBuffer</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 当前Sample的byte[]大小，如果为空返回-1</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSample</span><span class="params">(ByteBuffer byteBuffer)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (readADTSHeader(mAdtsHeader, mFileInputStream)) &#123;</span><br><span class="line">            <span class="keyword">int</span> length = mFileInputStream.read(mBytes, <span class="number">0</span>, mAdtsHeader.frameLength - mAdtsHeader.getSize());</span><br><span class="line">            byteBuffer.clear();</span><br><span class="line">            byteBuffer.put(mBytes, <span class="number">0</span>, length);</span><br><span class="line">            byteBuffer.position(<span class="number">0</span>);</span><br><span class="line">            byteBuffer.limit(length);</span><br><span class="line">            <span class="keyword">return</span> length;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从AAC文件流中读取ADTS头部</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> adtsHeader      ADTS头部</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileInputStream AAC文件流</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 是否读取成功</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">readADTSHeader</span><span class="params">(AdtsHeader adtsHeader, FileInputStream fileInputStream)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (fileInputStream.read(mHeaderBitReader.buffer) &lt; <span class="number">7</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        mHeaderBitReader.position = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> syncWord = mHeaderBitReader.readBits(<span class="number">12</span>); <span class="comment">// A</span></span><br><span class="line">        <span class="keyword">if</span> (syncWord != <span class="number">0xfff</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;Expected Start Word 0xfff&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        adtsHeader.mpegVersion = mHeaderBitReader.readBits(<span class="number">1</span>); <span class="comment">// B</span></span><br><span class="line">        adtsHeader.layer = mHeaderBitReader.readBits(<span class="number">2</span>); <span class="comment">// C</span></span><br><span class="line">        adtsHeader.protectionAbsent = mHeaderBitReader.readBits(<span class="number">1</span>); <span class="comment">// D</span></span><br><span class="line">        adtsHeader.profile = mHeaderBitReader.readBits(<span class="number">2</span>) + <span class="number">1</span>;  <span class="comment">// E</span></span><br><span class="line">        adtsHeader.sampleFrequencyIndex = mHeaderBitReader.readBits(<span class="number">4</span>);</span><br><span class="line">        adtsHeader.sampleRate = samplingFrequencyIndexMap.get(adtsHeader.sampleFrequencyIndex); <span class="comment">// F</span></span><br><span class="line">        mHeaderBitReader.readBits(<span class="number">1</span>); <span class="comment">// G</span></span><br><span class="line">        adtsHeader.channelconfig = mHeaderBitReader.readBits(<span class="number">3</span>); <span class="comment">// H</span></span><br><span class="line">        adtsHeader.original = mHeaderBitReader.readBits(<span class="number">1</span>); <span class="comment">// I</span></span><br><span class="line">        adtsHeader.home = mHeaderBitReader.readBits(<span class="number">1</span>); <span class="comment">// J</span></span><br><span class="line">        adtsHeader.copyrightedStream = mHeaderBitReader.readBits(<span class="number">1</span>); <span class="comment">// K</span></span><br><span class="line">        adtsHeader.copyrightStart = mHeaderBitReader.readBits(<span class="number">1</span>); <span class="comment">// L</span></span><br><span class="line">        adtsHeader.frameLength = mHeaderBitReader.readBits(<span class="number">13</span>); <span class="comment">// M</span></span><br><span class="line">        adtsHeader.bufferFullness = mHeaderBitReader.readBits(<span class="number">11</span>); <span class="comment">// 54</span></span><br><span class="line">        adtsHeader.numAacFramesPerAdtsFrame = mHeaderBitReader.readBits(<span class="number">2</span>) + <span class="number">1</span>; <span class="comment">// 56</span></span><br><span class="line">        <span class="keyword">if</span> (adtsHeader.numAacFramesPerAdtsFrame != <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;This muxer can only work with 1 AAC frame per ADTS frame&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (adtsHeader.protectionAbsent == <span class="number">0</span>) &#123;</span><br><span class="line">            fileInputStream.read(mSkipTwoBytes);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 释放资源</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        mFileInputStream.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * ADTS头部</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">AdtsHeader</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">int</span> <span class="title">getSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">7</span> + (protectionAbsent == <span class="number">0</span> ? <span class="number">2</span> : <span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> sampleFrequencyIndex;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> mpegVersion;</span><br><span class="line">        <span class="keyword">int</span> layer;</span><br><span class="line">        <span class="keyword">int</span> protectionAbsent;</span><br><span class="line">        <span class="keyword">int</span> profile;</span><br><span class="line">        <span class="keyword">int</span> sampleRate;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> channelconfig;</span><br><span class="line">        <span class="keyword">int</span> original;</span><br><span class="line">        <span class="keyword">int</span> home;</span><br><span class="line">        <span class="keyword">int</span> copyrightedStream;</span><br><span class="line">        <span class="keyword">int</span> copyrightStart;</span><br><span class="line">        <span class="keyword">int</span> frameLength;</span><br><span class="line">        <span class="keyword">int</span> bufferFullness;</span><br><span class="line">        <span class="keyword">int</span> numAacFramesPerAdtsFrame;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.jianshu.com/p/839b11e0638b">https://www.jianshu.com/p/839b11e0638b</a><br><a href="https://www.jianshu.com/p/b5ca697535bd">https://www.jianshu.com/p/b5ca697535bd</a><br><a href="https://blog.csdn.net/leixiaohua1020/article/details/11822537">https://blog.csdn.net/leixiaohua1020/article/details/11822537</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-脑机接口助力儿童教育与医疗</title>
    <url>/5b4fe1dd.html</url>
    <content><![CDATA[<p>2021年10月21日，国内首个聚焦儿童脑成像研究机构-华东师范大学儿童脑成像中心正式揭牌，同时揭牌的还有“上海脑科学与类脑研究中心华东师范大学脑智发育平台”和“华东师范大学上海纽约大学脑成像中心”。2021年4月7日，由国家儿童医学中心-上海交通大学附属儿童医学中心与强脑科技（BrainCo）脑机接口便携式神经反馈系统训练联合研究项目启动仪式在上海举行。</p>
<span id="more"></span>

<p>根据中国教育协会公布的最新“多动症儿童调查”显示，中国约有3000万儿童存在多动、注意力不集中、学习障碍等问题行为，其中1461万至1979万个孩子患有注意缺陷多动障碍。此外，自闭症、语言障碍、睡眠障碍等神经发育障碍的发病率也居高不下，严重影响了中国儿童的脑智健康。</p>
<p>上海儿童医学中心发育行为科主任章依文指出：“针对神经发育障碍疾病，目前最常见的治疗方法是在病症出现的早期，对孩子进行干预治疗，但目前在临床上的技术有很大的局限性。而强脑科技在脑机接口神经反馈系统训练技术上的提升，使得这类疾病的诊疗无论是在便携性，精准性还是及时性方面都得到了优化。</p>
<p>强脑科技创始人兼CEO韩璧丞表示：“本次与国家医学中心-上海交通大学医学院附属上海儿童医学中心合作的项目，将采用强脑科技自主研发的便携式脑机接口设备建立儿童行为发育的评估和诊疗干预新体系。”同年七月健康中国2021 思南峰会上，强脑科技发布startkids开星果社交与注意力康复系统，是一款采用了脑神经反馈训练技术的自闭症干预产品。目前此技术已经在与中国康复研究中心、国家孤独症康复研究中心和多家医院机构进行了联合研发和临床测试，已积累了一些早期干预的成功案例。</p>
<img src="/5b4fe1dd/1.jpg" class>

<p>据悉，华东师范大学儿童脑成像中心将运用多模态神经影像技术探索儿童脑发育，认知发展及其个体差异，并与国内外顶级科研机构合作，探索理论与方法层面的创新。</p>
<img src="/5b4fe1dd/2.png" class>

<img src="/5b4fe1dd/3.png" class>

<p>“因材施教”的教育理念，或将因为脑科学研究的进步真正成为现实。华东师大脑科学与教育创新研究院常务副院长林龙年表示，通过长期对儿童脑成像的观察和分析可见，后天教育导致他们的大脑发生了结构性的变化，其实这就是重新塑造大脑的过程。孩子在发育过程中的可塑性相当强，除了先天遗传基因的影响，教育和环境起着非常重要的作用。未来，如果以脑科学的发展规律创新教育方式，将更大程度上实现个性化教育。不过，这方面的研究应用于教育实践仍然有很长的路要走。林龙年直言，目前科学家对人类大脑发展的基本规律仍不清楚，儿童脑智发育和教育间的科学规律也需要更长时间的研究来证实。多位与会专家指出，研究过程中，大数据收集非常必要。但脑科学研究的目的不只是收集数据，更重要的是数据的质量及怎样分析利用。因此，数据收集应该是问题导向，比如儿童脑智研究中发现的一些现象，可能推动脑科学与教育、人工智能等领域的融合发展。</p>
<p>少年强则国强，在脑机接口领域，从小关注少年，幼儿的发展。从病理方向上如多动症，自闭症等心理疾病上给出相应的解决方案，在儿童教育方向上也是做出巨大的努力，成立脑成像中心等手段，从而更好的分析儿童的心理状况。使得儿童能够选择自己合适的道路，通过各种手段，做到真正的英才施教，北大心理学博士说过，如果是花，就不能按树的方式去培养，如果是树，就不能按着花一样来呵护。如何确定孩子是花还是树，脑机接口从心理和脑成像等技术手段可以辅助分析儿童的心理状况，给出儿童的兴趣，从而培养各种人才，做到真正的因材施教。</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10655">https://www.scholat.com/teamwork/showPostMessage.html?id=10655</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-视频开发-（四）视频编解码</title>
    <url>/1a455a10.html</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>在学习了Android 音视频的基本的相关知识，并整理了相关的API之后，应该对基本的音视频有一定的轮廓了。</p>
<p>下面是一个Android音视频中相当重要的几个API：<strong>MediaCodec</strong>（音视频编解码）、<strong>MediaExtractor</strong>（音视频解封装）、<strong>MediaMuxer</strong>（音视频封装）。</p>
<p>学习这个API的时候，主要的方向为：</p>
<ul>
<li>学习 MediaCodec API，完成音频 AAC 硬编、硬解</li>
<li>学习 MediaCodec API，完成视频 H.264 的硬编、硬解</li>
</ul>
<hr>
<span id="more"></span>

<h3 id="MediaCodec"><a href="#MediaCodec" class="headerlink" title="MediaCodec"></a>MediaCodec</h3><h4 id="MediaCodec-介绍"><a href="#MediaCodec-介绍" class="headerlink" title="MediaCodec 介绍"></a>MediaCodec 介绍</h4><p>MediaCodec类可以用于使用一些基本的多媒体编解码器（音视频编解码组件），它是Android基本的多媒体支持基础架构的一部分通常和<strong>MediaExtractor</strong>（解封装音视频）, <strong>MediaSync</strong>（音视频同步）, <strong>MediaMuxer</strong>（封装音视频）, <strong>MediaCrypto</strong>（解码加密的媒体数据）, <strong>MediaDrm</strong>（解密DRM）, Image, Surface, AudioTrack 一起使用。</p>
<p>一个<strong>编解码器</strong>可以<strong>处理输入</strong>的数据来<strong>产生输出</strong>的数据，编解码器使用<strong>一组输入和输出缓冲器</strong>来<strong>异步</strong>处理数据。你可以<strong>创建</strong>一个空的输入缓冲区，<strong>填充</strong>数据后<strong>发送</strong>到编解码器进行处理。编解码器使用输入的数据进行<strong>转换</strong>，然后<strong>输出</strong>到一个空的输出缓冲区。最后你<strong>获取</strong>到输出缓冲区的数据，消耗掉里面的数据，<strong>释放</strong>回编解码器。如果后续还有数据需要继续处理，编解码器就会重复这些操作。输出流程如下：</p>
<img src="/1a455a10/1.png" class>

<p>编解码器的生命周期：</p>
<p>主要的生命周期为：Stopped、Executing、Released。</p>
<ul>
<li>Stopped的状态下也分为三种子状态：Uninitialized、Configured、Error。</li>
<li>Executing的状态下也分为三种子状态：Flushed, Running、End-of-Stream。</li>
</ul>
<p>生命周期图：同步（左）与异步（右）</p>
<img src="/1a455a10/2.png" class>

<img src="/1a455a10/3.png" class>

<h4 id="MediaCodec-API-说明"><a href="#MediaCodec-API-说明" class="headerlink" title="MediaCodec API 说明"></a>MediaCodec API 说明</h4><p>MediaCodec可以处理具体的视频流，主要有这几个方法：</p>
<ul>
<li>getInputBuffers：获取需要编码数据的输入流队列，返回的是一个ByteBuffer数组</li>
<li>queueInputBuffer：输入流入队列</li>
<li>dequeueInputBuffer：从输入流队列中取数据进行编码操作</li>
<li>getOutputBuffers：获取编解码之后的数据输出流队列，返回的是一个ByteBuffer数组</li>
<li>dequeueOutputBuffer：从输出队列中取出编码操作之后的数据</li>
<li>releaseOutputBuffer：处理完成，释放ByteBuffer数据</li>
</ul>
<h4 id="MediaCodec-流控"><a href="#MediaCodec-流控" class="headerlink" title="MediaCodec 流控"></a>MediaCodec 流控</h4><p><strong>流控基本概念：</strong></p>
<p>流控就是流量控制。涉及到了 TCP 和视频编码：对 TCP 来说就是控制单位时间内发送数据包的数据量，对编码来说就是控制单位时间内输出数据的数据量。</p>
<ul>
<li>TCP 的限制条件是网络带宽，流控就是在避免造成或者加剧网络拥塞的前提下，尽可能利用网络带宽。带宽够、网络好，我们就加快速度发送数据包，出现了延迟增大、丢包之后，就放慢发包的速度（因为继续高速发包，可能会加剧网络拥塞，反而发得更慢）。<br>视频编码的限制条件最初是解码器的能力，码率太高就会无法解码，后来随着 codec 的发展，解码能力不再是瓶颈，限制条件变成了传输带宽/文件大小，我们希望在控制数据量的前提下，画面质量尽可能高。</li>
<li>无论是要发送的 TCP 数据包，还是要编码的图像，都可能出现“尖峰”，也就是短时间内出现较大的数据量。TCP 面对尖峰，可以选择不为所动（尤其是网络已经拥塞的时候），这没有太大的问题，但如果视频编码也对尖峰不为所动，那图像质量就会大打折扣了。如果有几帧数据量特别大，但仍要把码率控制在原来的水平，那势必要损失更多的信息，因此图像失真就会更严重。</li>
</ul>
<p><strong>Android 硬编码流控：</strong></p>
<p>MediaCodec 流控相关的接口并不多，一是配置时设置目标码率和码率控制模式，二是动态调整目标码率(Android 19 版本以上)。</p>
<p>配置时指定目标码率和码率控制模式</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mediaFormat.setInteger(MediaFormat.KEY_BIT_RATE, bitRate);</span><br><span class="line">mediaFormat.setInteger(MediaFormat.KEY_BITRATE_MODE, MediaCodecInfo.EncoderCapabilities.BITRATE_MODE_VBR);</span><br><span class="line">mVideoCodec.configure(mediaFormat, <span class="keyword">null</span>, <span class="keyword">null</span>, MediaCodec.CONFIGURE_FLAG_ENCODE);</span><br></pre></td></tr></table></figure>

<p>码率控制模式有三种：</p>
<ul>
<li>CQ  表示完全不控制码率，尽最大可能保证图像质量；</li>
<li>CBR 表示编码器会尽量把输出码率控制为设定值，即我们前面提到的“不为所动”；</li>
<li>VBR 表示编码器会根据图像内容的复杂度（实际上是帧间变化量的大小）来动态调整输出码率，图像复杂则码率高，图像简单则码率低；</li>
</ul>
<p><strong>Android 流控策略选择：</strong></p>
<ul>
<li>质量要求高、不在乎带宽、解码器支持码率剧烈波动的情况下，可以选择 CQ 码率控制策略。</li>
<li>VBR 输出码率会在一定范围内波动，对于小幅晃动，方块效应会有所改善，但对剧烈晃动仍无能为力；连续调低码率则会导致码率急剧下降，如果无法接受这个问题，那 VBR 就不是好的选择。</li>
<li>CBR 的优点是稳定可控，这样对实时性的保证有帮助。所以 WebRTC 开发中一般使用的是CBR。</li>
</ul>
<h4 id="MediaCodec-使用"><a href="#MediaCodec-使用" class="headerlink" title="MediaCodec 使用"></a>MediaCodec 使用</h4><p>MediaCodec常用方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">createEncoderByType（<span class="meta">@NonNul</span> String type）：静态构造方法，type为指定的音视频格式，创建指定格式的编码器</span><br><span class="line">createDecoderByType(<span class="meta">@NonNull</span> String type)：静态构造方法，type为指定的音视频格式，创建指定格式的解码器</span><br><span class="line">  </span><br><span class="line"><span class="comment">// MediaCodec的设置</span></span><br><span class="line">configure(</span><br><span class="line">       <span class="meta">@Nullable</span> MediaFormat format,    <span class="comment">// 绑定编解码的媒体格式</span></span><br><span class="line">       <span class="meta">@Nullable</span> Surface surface,       <span class="comment">// 绑定surface，可以直接完成数据的渲染</span></span><br><span class="line">       <span class="meta">@Nullable</span> MediaCrypto crypto,    <span class="comment">// 加密算法</span></span><br><span class="line">       <span class="meta">@ConfigureFlag</span> <span class="keyword">int</span> flags)        <span class="comment">// 加密的格式，如果不需要直接设置0即可</span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">dequeueInputBuffer</span><span class="params">(<span class="keyword">long</span> timeoutUs)</span></span></span><br><span class="line"><span class="function"><span class="comment">// timeoutUs等待时间，返回可以使用的输入buffer的索引</span></span></span><br><span class="line"><span class="function">  </span></span><br><span class="line"><span class="function"><span class="comment">// 设置指定索引位置的buffer的信息</span></span></span><br><span class="line"><span class="function"><span class="title">queueInputBuffer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="keyword">int</span> index,          // 数组的索引值</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="keyword">int</span> offset,         // 写入buffer的起始位置</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="keyword">int</span> size,           // 写入的输出的长度</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="keyword">long</span> presentationTimeUs,    // 该数据显示的时间戳</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="keyword">int</span> flags           // 该数据的标记位，例如关键帧，结束帧等等</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br><span class="line"><span class="function">  </span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">dequeueOutputBuffer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="meta">@NonNull</span> BufferInfo info,  // 这个BufferInfo需要自己手动创建，调用后，会把该索引的数据的信息写在里面</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="keyword">long</span> timeoutUs             // 等待时间</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br><span class="line"><span class="function"><span class="comment">// timeoutUs等待时间，返回可以读取的buffer的索引</span></span></span><br><span class="line"><span class="function">  </span></span><br><span class="line"><span class="function"><span class="title">releaseOutputBuffer</span><span class="params">(<span class="keyword">int</span> index, <span class="keyword">boolean</span> render)</span>：释放指定索引位置的buffer</span></span><br><span class="line"><span class="function"><span class="comment">// index：索引</span></span></span><br><span class="line"><span class="function"><span class="comment">// render：如果绑定了surface，该数据是否要渲染到画布上</span></span></span><br></pre></td></tr></table></figure>

<p>MediaCodec是系统级别的编解码库，底层还是调用native方法，使用MediaCodec的基本流程是：</p>
<p><strong>创建与文件相匹配的MediaCodec</strong> -&gt; <strong>MediaCodec写入数据，进行编码/解码</strong> -&gt; <strong>读取MediaCodec编/解码结果</strong></p>
<p>【音频MediaCodec的具体使用详见音频篇编解码】</p>
<hr>
<h3 id="MediaExtractor"><a href="#MediaExtractor" class="headerlink" title="MediaExtractor"></a>MediaExtractor</h3><h4 id="MediaExtractor-介绍"><a href="#MediaExtractor-介绍" class="headerlink" title="MediaExtractor 介绍"></a>MediaExtractor 介绍</h4><p>MediaExtractor字面意思是多媒体提取器，它在Android的音视频开发里主要负责提取视频或者音频中的信息和数据流（例如将视频文件，解析头信息，剥离出音频与视频）。</p>
<h4 id="MediaExtractor-API-说明"><a href="#MediaExtractor-API-说明" class="headerlink" title="MediaExtractor API 说明"></a>MediaExtractor API 说明</h4><ul>
<li>setDataSource(String path)：即可以设置本地文件又可以设置网络文件</li>
<li>getTrackCount()：得到源文件通道数</li>
<li>getTrackFormat(int index)：获取指定（index）的通道格式</li>
<li>getSampleTime()：返回当前的时间戳</li>
<li>readSampleData(ByteBuffer byteBuf, int offset)：把指定通道中的数据按偏移量读取到ByteBuffer中；</li>
<li>advance()：读取下一帧数据</li>
<li>release(): 读取结束后释放资源</li>
</ul>
<h4 id="MediaExtractor-使用"><a href="#MediaExtractor-使用" class="headerlink" title="MediaExtractor 使用"></a>MediaExtractor 使用</h4><ol>
<li><p>通过setDataSource()设置数据源，数据源可以是本地文件地址，也可以是网络地址</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MediaExtractor mVideoExtractor = <span class="keyword">new</span> MediaExtractor();</span><br><span class="line">mVideoExtractor.setDataSource(mVideoPath);</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以通过getTrackFormat(int index)来获取各个track的MediaFormat，通过MediaFormat来获取track的详细信息，如：MimeType、分辨率、采样频率、帧率等等</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; mVideoExtractor.getTrackCount(); i++) &#123;</span><br><span class="line">    MediaFormat format = mVideoExtractor.getTrackFormat(i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MediaFormat: 封装描述媒体数据格式的信息，无论是音频还是视频。媒体数据的格式被指定为字符串/值对。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 【肯定可以获取到的】</span></span><br><span class="line"><span class="comment">// 获取MIME信息</span></span><br><span class="line">MediaFormat mediaFormat = extractor.getTrackFormat(<span class="number">0</span>);<span class="comment">//获取多媒体格式,因为是demo已经确定自己的视频文件没问题,所以直接获取0位轨道</span></span><br><span class="line">String mimeFormat = mediaFormat.getString(MediaFormat.KEY_MIME);<span class="comment">//获取MIME格式内容</span></span><br><span class="line">Log.e(TAG, <span class="string">&quot;mediaExtractor: 获取MIME格式内容=&quot;</span>+mimeFormat);</span><br><span class="line"><span class="comment">// 获取语言格式(大多数情况是获取到空的字符串,但是至少不会报null)</span></span><br><span class="line">MediaFormat mediaFormat = extractor.getTrackFormat(<span class="number">0</span>);</span><br><span class="line">String language = mediaFormat.getString(MediaFormat.KEY_LANGUAGE);<span class="comment">//获取语言格式内容</span></span><br><span class="line">Log.e(TAG, <span class="string">&quot;mediaExtractor: 获取语言格式内容=&quot;</span>+language);</span><br><span class="line"><span class="comment">// 视频的高度与宽度</span></span><br><span class="line">MediaFormat mediaFormat = extractor.getTrackFormat(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">int</span> width = mediaFormat.getInteger(MediaFormat.KEY_WIDTH);<span class="comment">//获取高度</span></span><br><span class="line"><span class="keyword">int</span> height = mediaFormat.getInteger(MediaFormat.KEY_HEIGHT);<span class="comment">//获取高度</span></span><br><span class="line"><span class="comment">// 播放总时长</span></span><br><span class="line"><span class="keyword">long</span> durationTime = mediaFormat.getLong(MediaFormat.KEY_DURATION);<span class="comment">//总时间</span></span><br><span class="line"><span class="comment">// 获取MediaFormat描述的数据缓冲区的最大字节数</span></span><br><span class="line"><span class="keyword">int</span> maxByteCount = mediaFormat.getInteger(MediaFormat.KEY_MAX_INPUT_SIZE);<span class="comment">//获取视频缓存输出的最大大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 【不一定能获取到，没有则会空指针】</span></span><br><span class="line"><span class="comment">// 获取采样率</span></span><br><span class="line"><span class="keyword">int</span> sampleRate = mediaFormat.getInteger(MediaFormat.KEY_SAMPLE_RATE);<span class="comment">//获取采样率</span></span><br><span class="line"><span class="comment">// 获取比特率</span></span><br><span class="line"><span class="keyword">int</span> bitRate = mediaFormat.getInteger(MediaFormat.KEY_BIT_RATE);<span class="comment">//获取比特</span></span><br><span class="line"><span class="comment">// 获取声道数量</span></span><br><span class="line"><span class="keyword">int</span> channelCount = mediaFormat.getInteger(MediaFormat.KEY_CHANNEL_COUNT);<span class="comment">//获取声道数量</span></span><br><span class="line"><span class="comment">// 获取最大高度与最大宽度</span></span><br><span class="line"><span class="keyword">int</span> maxWidth = mediaFormat.getInteger(MediaFormat.KEY_MAX_WIDTH);<span class="comment">//最大宽度</span></span><br><span class="line"><span class="keyword">int</span> maxHeight = mediaFormat.getInteger(MediaFormat.KEY_MAX_HEIGHT);<span class="comment">//最大高度</span></span><br><span class="line"><span class="comment">// 获取颜色格式</span></span><br><span class="line"><span class="keyword">int</span> colorFormat = mediaFormat.getInteger(MediaFormat.KEY_COLOR_FORMAT);<span class="comment">//颜色格式</span></span><br><span class="line"><span class="comment">// 获取帧率</span></span><br><span class="line"><span class="keyword">int</span> frameRate = mediaFormat.getInteger(MediaFormat.KEY_FRAME_RATE);<span class="comment">//帧率</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>获取到track的详细信息后，通过selectTrack(int index)选择指定的通道</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (format.getString(MediaFormat.KEY_MIME).startsWith(<span class="string">&quot;video/&quot;</span>)) &#123;</span><br><span class="line">    mVideoExtractor.selectTrack(i);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>指定通道之后就可以从MediaExtractor中读取数据了</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> sampleSize = mVideoExtractor.readSampleData(buffer, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (sampleSize &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// do something</span></span><br><span class="line">    mVideoExtractor.advance(); <span class="comment">// 移动到下一帧</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在读取结束之后，记得释放资源</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mVideoExtractor.release();</span><br></pre></td></tr></table></figure>

</li>
</ol>
<hr>
<h3 id="MediaMuxer"><a href="#MediaMuxer" class="headerlink" title="MediaMuxer"></a>MediaMuxer</h3><h4 id="MediaMuxer-介绍"><a href="#MediaMuxer-介绍" class="headerlink" title="MediaMuxer 介绍"></a>MediaMuxer 介绍</h4><p>利用MediaExtractor提取的aac和.h264文件不经过处理没办法播放，需要MediaMuxer合并生成可以播放的文件（aac文件和.h264需要首先利用MediaMuxer生成MP4文件，才能进行合并）。</p>
<p>MediaMuxer从api18开始提供，可以封装编码后的视频流和音频流到视频文件中。目前MediaMuxer支持的文件输出格式包括MP4，webm和3gp。</p>
<img src="/1a455a10/4.png" class>

<h4 id="MediaMuxer-API-说明"><a href="#MediaMuxer-API-说明" class="headerlink" title="MediaMuxer API 说明"></a>MediaMuxer API 说明</h4><ul>
<li>MediaMuxer(String path, int format)</li>
<li>addTrack(MediaFormat format)：利用MediaFormat添加音频或视频轨道</li>
<li>release()：释放MediaMuxer的资源</li>
<li>setLocation(float latitude,float longitude)：设置并存储地理位置信息到生成文件中</li>
<li>setOrientationHint(int degrees)：设置输出视频回放的方向提示</li>
<li>start()：开始muxer，等待数据的输入</li>
<li>stop()：停止muxer，调用这个函数后将生成合成的文件</li>
<li>writeSampleData(int trackIndex, ByteBuffer byteBuf, MediaCodec.BufferInfo bufferInfo)：往muxer中写入编码的数据。</li>
</ul>
<h4 id="MediaMuxer-使用"><a href="#MediaMuxer-使用" class="headerlink" title="MediaMuxer 使用"></a>MediaMuxer 使用</h4><ol>
<li><p>生成MediaMuxer对象：</p>
<p> 通过new MediaMuxer(String path, int format)指定视频文件输出路径和文件格式：<br> MediaMuxer mMediaMuxer = new MediaMuxer(mOutputVideoPath, MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4);</p>
</li>
<li><p>addTrack</p>
<p> addTrack(MediaFormat format)，添加媒体通道，传入MediaFormat对象，通常从MediaExtractor或者MediaCodec中获取，也可以自己创建<br> addTrack会返回trackindex</p>
</li>
<li><p>调用start函数</p>
<p> MediaMuxer.start();</p>
</li>
<li><p>写入数据</p>
<p> 调用MediaMuxer.writeSampleData()向mp4文件中写入数据了。每次只能添加一帧视频数据或者单个Sample的音频数据，需要BufferInfo对象作为参数。<br> BufferInfo info = new BufferInfo();<br> info.offset = 0;<br> info.size = sampleSize;<br> info.flags = MediaCodec.BUFFER_FLAG_SYNC_FRAME;<br> info.presentationTimeUs = mVideoExtractor.getSampleTime();<br> mMediaMuxer.writeSampleData(videoTrackIndex, buffer, info);<br> info.size 必须填入数据的大小<br> info.flags 需要给出是否为同步帧/关键帧<br> info.presentationTimeUs 必须给出正确的时间戳，注意单位是 us，第二次getSampleTime()和首次getSampleTime()的时间差。</p>
</li>
<li><p>释放关闭资源</p>
<p> 结束写入后关闭以及释放资源：<br> MediaMuxer.stop();<br> MediaMuxer.release();</p>
</li>
</ol>
<p>官网say that it is generally used like this:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MediaMuxer muxer = <span class="keyword">new</span> MediaMuxer(<span class="string">&quot;temp.mp4&quot;</span>, OutputFormat.MUXER_OUTPUT_MPEG_4);</span><br><span class="line"><span class="comment">// More often, the MediaFormat will be retrieved from MediaCodec.getOutputFormat()</span></span><br><span class="line"><span class="comment">// or MediaExtractor.getTrackFormat().</span></span><br><span class="line">MediaFormat audioFormat = <span class="keyword">new</span> MediaFormat(...);</span><br><span class="line">MediaFormat videoFormat = <span class="keyword">new</span> MediaFormat(...);</span><br><span class="line"><span class="keyword">int</span> audioTrackIndex = muxer.addTrack(audioFormat);</span><br><span class="line"><span class="keyword">int</span> videoTrackIndex = muxer.addTrack(videoFormat);</span><br><span class="line">ByteBuffer inputBuffer = ByteBuffer.allocate(bufferSize);</span><br><span class="line"><span class="keyword">boolean</span> finished = <span class="keyword">false</span>;</span><br><span class="line">BufferInfo bufferInfo = <span class="keyword">new</span> BufferInfo();</span><br><span class="line"> </span><br><span class="line">muxer.start();</span><br><span class="line"><span class="keyword">while</span>(!finished) &#123;</span><br><span class="line">  <span class="comment">// getInputBuffer() will fill the inputBuffer with one frame of encoded</span></span><br><span class="line">  <span class="comment">// sample from either MediaCodec or MediaExtractor, set isAudioSample to</span></span><br><span class="line">  <span class="comment">// true when the sample is audio data, set up all the fields of bufferInfo,</span></span><br><span class="line">  <span class="comment">// and return true if there are no more samples.</span></span><br><span class="line">  finished = getInputBuffer(inputBuffer, isAudioSample, bufferInfo);</span><br><span class="line">  <span class="keyword">if</span> (!finished) &#123;</span><br><span class="line">    <span class="keyword">int</span> currentTrackIndex = isAudioSample ? audioTrackIndex : videoTrackIndex;</span><br><span class="line">    muxer.writeSampleData(currentTrackIndex, inputBuffer, bufferInfo);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">muxer.stop();</span><br><span class="line">muxer.release();</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="综合例子"><a href="#综合例子" class="headerlink" title="综合例子"></a>综合例子</h3><h4 id="视频换音"><a href="#视频换音" class="headerlink" title="视频换音"></a>视频换音</h4><p>使用MediaExtractor和MediaMuxer来实现视频的换音</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">muxingAudioAndVideo</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    MediaMuxer mMediaMuxer = <span class="keyword">new</span> MediaMuxer(mOutputVideoPath,</span><br><span class="line">                MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 视频的MediaExtractor</span></span><br><span class="line">    MediaExtractor mVideoExtractor = <span class="keyword">new</span> MediaExtractor();</span><br><span class="line">    mVideoExtractor.setDataSource(mVideoPath);</span><br><span class="line">    <span class="keyword">int</span> videoTrackIndex = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; mVideoExtractor.getTrackCount(); i++) &#123;</span><br><span class="line">        MediaFormat format = mVideoExtractor.getTrackFormat(i);</span><br><span class="line">        <span class="keyword">if</span> (format.getString(MediaFormat.KEY_MIME).startsWith(<span class="string">&quot;video/&quot;</span>)) &#123;</span><br><span class="line">            mVideoExtractor.selectTrack(i);</span><br><span class="line">            videoTrackIndex = mMediaMuxer.addTrack(format);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 音频的MediaExtractor</span></span><br><span class="line">    MediaExtractor mAudioExtractor = <span class="keyword">new</span> MediaExtractor();</span><br><span class="line">    mAudioExtractor.setDataSource(mAudioPath);</span><br><span class="line">    <span class="keyword">int</span> audioTrackIndex = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; mAudioExtractor.getTrackCount(); i++) &#123;</span><br><span class="line">        MediaFormat format = mAudioExtractor.getTrackFormat(i);</span><br><span class="line">        <span class="keyword">if</span> (format.getString(MediaFormat.KEY_MIME).startsWith(<span class="string">&quot;audio/&quot;</span>)) &#123;</span><br><span class="line">            mAudioExtractor.selectTrack(i);</span><br><span class="line">            audioTrackIndex = mMediaMuxer.addTrack(format);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 添加完所有轨道后start</span></span><br><span class="line">    mMediaMuxer.start();</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 封装视频track</span></span><br><span class="line">    <span class="keyword">if</span> (-<span class="number">1</span> != videoTrackIndex) &#123;</span><br><span class="line">        MediaCodec.BufferInfo info = <span class="keyword">new</span> MediaCodec.BufferInfo();</span><br><span class="line">        info.presentationTimeUs = <span class="number">0</span>;</span><br><span class="line">        ByteBuffer buffer = ByteBuffer.allocate(<span class="number">100</span> * <span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> sampleSize = mVideoExtractor.readSampleData(buffer, <span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span> (sampleSize &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            info.offset = <span class="number">0</span>;</span><br><span class="line">            info.size = sampleSize;</span><br><span class="line">            info.flags = MediaCodec.BUFFER_FLAG_SYNC_FRAME;</span><br><span class="line">            info.presentationTimeUs = mVideoExtractor.getSampleTime();</span><br><span class="line">            mMediaMuxer.writeSampleData(videoTrackIndex, buffer, info);</span><br><span class="line"> </span><br><span class="line">            mVideoExtractor.advance();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 封装音频track</span></span><br><span class="line">    <span class="keyword">if</span> (-<span class="number">1</span> != audioTrackIndex) &#123;</span><br><span class="line">        MediaCodec.BufferInfo info = <span class="keyword">new</span> MediaCodec.BufferInfo();</span><br><span class="line">        info.presentationTimeUs = <span class="number">0</span>;</span><br><span class="line">        ByteBuffer buffer = ByteBuffer.allocate(<span class="number">100</span> * <span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> sampleSize = mAudioExtractor.readSampleData(buffer, <span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span> (sampleSize &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            info.offset = <span class="number">0</span>;</span><br><span class="line">            info.size = sampleSize;</span><br><span class="line">            info.flags = MediaCodec.BUFFER_FLAG_SYNC_FRAME;</span><br><span class="line">            info.presentationTimeUs = mAudioExtractor.getSampleTime();</span><br><span class="line">            mMediaMuxer.writeSampleData(audioTrackIndex, buffer, info);</span><br><span class="line"> </span><br><span class="line">            mAudioExtractor.advance();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 释放MediaExtractor</span></span><br><span class="line">    mVideoExtractor.release();</span><br><span class="line">    mAudioExtractor.release();</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 释放MediaMuxer</span></span><br><span class="line">    mMediaMuxer.stop();</span><br><span class="line">    mMediaMuxer.release();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="硬解码h-265视频及音频进行播放"><a href="#硬解码h-265视频及音频进行播放" class="headerlink" title="硬解码h.265视频及音频进行播放"></a>硬解码h.265视频及音频进行播放</h4><p>视频解码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 【设置数据源】</span></span><br><span class="line">MediaExtractor mediaExtractor = <span class="keyword">new</span> MediaExtractor();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    mediaExtractor.setDataSource(path); <span class="comment">// 设置数据源</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">    e1.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 【根据视频的编码信息来初始化MediaCodec: 视频的mimeType是video类型。】</span></span><br><span class="line">String mimeType = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; mediaExtractor.getTrackCount(); i++) &#123; <span class="comment">// 信道总数</span></span><br><span class="line">    MediaFormat format = mediaExtractor.getTrackFormat(i); <span class="comment">// 音频文件信息</span></span><br><span class="line">    mimeType = format.getString(MediaFormat.KEY_MIME);</span><br><span class="line">    <span class="keyword">if</span> (mimeType.startsWith(<span class="string">&quot;video/&quot;</span>)) &#123; <span class="comment">// 视频信道</span></span><br><span class="line">        mediaExtractor.selectTrack(i); <span class="comment">// 切换到视频信道</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mediaCodec = MediaCodec.createDecoderByType(mimeType); <span class="comment">// 创建解码器,提供数据输出</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        mediaCodec.configure(format, surface, <span class="keyword">null</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">mediaCodec.start(); <span class="comment">// 启动MediaCodec ，等待传入数据</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 【获取缓存器】</span></span><br><span class="line"><span class="comment">// 输入</span></span><br><span class="line">ByteBuffer[] inputBuffers = mediaCodec.getInputBuffers(); <span class="comment">// 用来存放目标文件的数据</span></span><br><span class="line"><span class="comment">// 输出</span></span><br><span class="line">ByteBuffer[] outputBuffers = mediaCodec.getOutputBuffers(); <span class="comment">// 解码后的数据</span></span><br><span class="line">MediaCodec.BufferInfo info = <span class="keyword">new</span> MediaCodec.BufferInfo(); <span class="comment">// 用于描述解码得到的byte[]数据的相关信息</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 【开始解码】</span></span><br><span class="line"><span class="keyword">while</span> (!Thread.interrupted()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!bIsEos) &#123;</span><br><span class="line">        <span class="keyword">int</span> inIndex = mediaCodec.dequeueInputBuffer(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (inIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            ByteBuffer buffer = inputBuffers[inIndex];</span><br><span class="line">            <span class="keyword">int</span> nSampleSize = mediaExtractor.readSampleData(buffer, <span class="number">0</span>); <span class="comment">// 读取一帧数据至buffer中</span></span><br><span class="line">            <span class="keyword">if</span> (nSampleSize &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                Log.d(TAG, <span class="string">&quot;InputBuffer BUFFER_FLAG_END_OF_STREAM&quot;</span>);</span><br><span class="line">                mediaCodec.queueInputBuffer(inIndex, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, MediaCodec.BUFFER_FLAG_END_OF_STREAM);</span><br><span class="line">                bIsEos = <span class="keyword">true</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 填数据</span></span><br><span class="line">                mediaCodec.queueInputBuffer(inIndex, <span class="number">0</span>, nSampleSize, mediaExtractor.getSampleTime(), <span class="number">0</span>); <span class="comment">// 通知MediaDecode解码刚刚传入的数据</span></span><br><span class="line">                mediaExtractor.advance(); <span class="comment">// 继续下一取样</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> outIndex = mediaCodec.dequeueOutputBuffer(info, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">switch</span> (outIndex) &#123;</span><br><span class="line">        <span class="keyword">case</span> MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED:</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;INFO_OUTPUT_BUFFERS_CHANGED&quot;</span>);</span><br><span class="line">            outputBuffers = mediaCodec.getOutputBuffers();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> MediaCodec.INFO_OUTPUT_FORMAT_CHANGED:</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;New format &quot;</span> + mediaCodec.getOutputFormat());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> MediaCodec.INFO_TRY_AGAIN_LATER:</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;dequeueOutputBuffer timed out!&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            ByteBuffer buffer = outputBuffers[outIndex];</span><br><span class="line">            Log.v(TAG, <span class="string">&quot;We can&#x27;t use this buffer but render it due to the API limit, &quot;</span> + buffer);</span><br><span class="line"> </span><br><span class="line">            mediaCodec.releaseOutputBuffer(outIndex, <span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> ((info.flags &amp; MediaCodec.BUFFER_FLAG_END_OF_STREAM) != <span class="number">0</span>) &#123;</span><br><span class="line">        Log.d(<span class="string">&quot;DecodeActivity&quot;</span>, <span class="string">&quot;OutputBuffer BUFFER_FLAG_END_OF_STREAM&quot;</span>);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 【解码完成后释放资源】</span></span><br><span class="line">mediaCodec.stop();</span><br><span class="line">mediaCodec.release();</span><br><span class="line">mediaExtractor.release();</span><br></pre></td></tr></table></figure>

<p>这样视频的解码就已经完成了，此时surfaceView已经可以播放视频了，接下来是音频解码。</p>
<p>音频解码的过程和上面大同小异，主要区别在于，视频是用surfaceView播放显示的，而音频我们需要使用AudioTrack来播放。</p>
<p>音频解码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 【创建一个AudioPlayer类用于播放音频】</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AudioPlayer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> mFrequency;<span class="comment">// 采样率</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> mChannel;<span class="comment">// 声道</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> mSampBit;<span class="comment">// 采样精度</span></span><br><span class="line">    <span class="keyword">private</span> AudioTrack mAudioTrack;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">AudioPlayer</span><span class="params">(<span class="keyword">int</span> frequency, <span class="keyword">int</span> channel, <span class="keyword">int</span> sampbit)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.mFrequency = frequency;</span><br><span class="line">        <span class="keyword">this</span>.mChannel = channel;</span><br><span class="line">        <span class="keyword">this</span>.mSampBit = sampbit;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mAudioTrack != <span class="keyword">null</span>) &#123;</span><br><span class="line">            release();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 获得构建对象的最小缓冲区大小</span></span><br><span class="line">        <span class="keyword">int</span> minBufSize = AudioTrack.getMinBufferSize(mFrequency, mChannel, mSampBit);</span><br><span class="line">        mAudioTrack = <span class="keyword">new</span> AudioTrack(AudioManager.STREAM_MUSIC,</span><br><span class="line">                mFrequency, mChannel, mSampBit, minBufSize, AudioTrack.MODE_STREAM);</span><br><span class="line">        mAudioTrack.play();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 释放资源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mAudioTrack != <span class="keyword">null</span>) &#123;</span><br><span class="line">            mAudioTrack.stop();</span><br><span class="line">            mAudioTrack.release();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将解码后的pcm数据写入audioTrack播放</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data   数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> offset 偏移</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> length 需要播放的长度</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">play</span><span class="params">(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (data == <span class="keyword">null</span> || data.length == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mAudioTrack.write(data, offset, length);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 【初始化音频解码器：音频的mineType是audio类型，我们根据这个来去音频信息即可。】</span></span><br><span class="line">String mimeType;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; mediaExtractor.getTrackCount(); i++) &#123; <span class="comment">// 信道总数</span></span><br><span class="line">    MediaFormat format = mediaExtractor.getTrackFormat(i); <span class="comment">// 音频文件信息</span></span><br><span class="line">    mimeType = format.getString(MediaFormat.KEY_MIME);</span><br><span class="line">    <span class="keyword">if</span> (mimeType.startsWith(<span class="string">&quot;audio/&quot;</span>)) &#123; <span class="comment">// 音频信道</span></span><br><span class="line">        mediaExtractor.selectTrack(i); <span class="comment">// 切换到 音频信道</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mediaCodec = MediaCodec.createDecoderByType(mimeType); <span class="comment">// 创建解码器,提供数据输出</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        mediaCodec.configure(format, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="number">0</span>);</span><br><span class="line">        mPlayer = <span class="keyword">new</span> AudioPlayer(format.getInteger(MediaFormat.KEY_SAMPLE_RATE), AudioFormat</span><br><span class="line">                .CHANNEL_OUT_STEREO, AudioFormat.ENCODING_PCM_16BIT);</span><br><span class="line">        mPlayer.init();</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (mediaCodec == <span class="keyword">null</span>) &#123;</span><br><span class="line">    Log.e(TAG, <span class="string">&quot;Can&#x27;t find video info!&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">mediaCodec.start(); <span class="comment">// 启动MediaCodec ，等待传入数据</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 【音频解码：音频解码过程与视频解码大同小异，只需要额外调用一下我们创建的AudioPlayer来播放音频即可。】</span></span><br><span class="line"><span class="keyword">while</span> (!Thread.interrupted()) &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (!bIsEos) &#123;</span><br><span class="line">        <span class="keyword">int</span> inIndex = mediaCodec.dequeueInputBuffer(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (inIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            ByteBuffer buffer = inputBuffers[inIndex];</span><br><span class="line">            <span class="keyword">int</span> nSampleSize = mediaExtractor.readSampleData(buffer, <span class="number">0</span>); <span class="comment">// 读取一帧数据至buffer中</span></span><br><span class="line">            <span class="keyword">if</span> (nSampleSize &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                Log.d(TAG, <span class="string">&quot;InputBuffer BUFFER_FLAG_END_OF_STREAM&quot;</span>);</span><br><span class="line">                mediaCodec.queueInputBuffer(inIndex, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, MediaCodec.BUFFER_FLAG_END_OF_STREAM);</span><br><span class="line">                bIsEos = <span class="keyword">true</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 填数据</span></span><br><span class="line">                mediaCodec.queueInputBuffer(inIndex, <span class="number">0</span>, nSampleSize, mediaExtractor.getSampleTime(), <span class="number">0</span>); <span class="comment">// 通知MediaDecode解码刚刚传入的数据</span></span><br><span class="line">                mediaExtractor.advance(); <span class="comment">// 继续下一取样</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">int</span> outIndex = mediaCodec.dequeueOutputBuffer(info, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">switch</span> (outIndex) &#123;</span><br><span class="line">        <span class="keyword">case</span> MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED:</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;INFO_OUTPUT_BUFFERS_CHANGED&quot;</span>);</span><br><span class="line">            outputBuffers = mediaCodec.getOutputBuffers();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> MediaCodec.INFO_OUTPUT_FORMAT_CHANGED:</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;New format &quot;</span> + mediaCodec.getOutputFormat());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> MediaCodec.INFO_TRY_AGAIN_LATER:</span><br><span class="line">            Log.d(TAG, <span class="string">&quot;dequeueOutputBuffer timed out!&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            ByteBuffer buffer = outputBuffers[outIndex];</span><br><span class="line">            Log.v(TAG, <span class="string">&quot;We can&#x27;t use this buffer but render it due to the API limit, &quot;</span> + buffer);</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">while</span> (info.presentationTimeUs / <span class="number">1000</span> &gt; System.currentTimeMillis() - startMs) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    sleep(<span class="number">10</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//用来保存解码后的数据</span></span><br><span class="line">            <span class="keyword">byte</span>[] outData = <span class="keyword">new</span> <span class="keyword">byte</span>[info.size];</span><br><span class="line">            buffer.get(outData);</span><br><span class="line">            <span class="comment">//清空缓存</span></span><br><span class="line">            buffer.clear();</span><br><span class="line">            <span class="comment">//播放解码后的数据</span></span><br><span class="line">            mPlayer.play(outData, <span class="number">0</span>, info.size);</span><br><span class="line">            mediaCodec.releaseOutputBuffer(outIndex, <span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// All decoded frames have been rendered, we can stop playing</span></span><br><span class="line">    <span class="comment">// now</span></span><br><span class="line">    <span class="keyword">if</span> ((info.flags &amp; MediaCodec.BUFFER_FLAG_END_OF_STREAM) != <span class="number">0</span>) &#123;</span><br><span class="line">        Log.d(<span class="string">&quot;DecodeActivity&quot;</span>, <span class="string">&quot;OutputBuffer BUFFER_FLAG_END_OF_STREAM&quot;</span>);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.cnblogs.com/renhui/p/7478527.html">https://www.cnblogs.com/renhui/p/7478527.html</a><br><a href="https://www.jianshu.com/p/e7eae2541e01">https://www.jianshu.com/p/e7eae2541e01</a><br><a href="https://www.cnblogs.com/guanxinjing/p/11378133.html">https://www.cnblogs.com/guanxinjing/p/11378133.html</a><br><a href="https://www.jianshu.com/p/66acab100e4b">https://www.jianshu.com/p/66acab100e4b</a><br><a href="https://blog.csdn.net/qq_25412055/article/details/78990538">https://blog.csdn.net/qq_25412055/article/details/78990538</a><br><a href="https://blog.csdn.net/u010126792/article/details/86510903">https://blog.csdn.net/u010126792/article/details/86510903</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Java-为什么Integer的1000==1000为false，100==100为true</title>
    <url>/9e3298ff.html</url>
    <content><![CDATA[<h3 id="问题引入"><a href="#问题引入" class="headerlink" title="问题引入"></a>问题引入</h3><p>这是一个很简单的问题，也是一个不简单的问题，总之挺有趣的，可以讨论讨论、动手实操一下。</p>
<p><strong>为什么Integer的1000==1000为false，100==100为true？</strong>如果你运行了下面的代码，确实会得到这个结果。</p>
<img src="/9e3298ff/1.png" class>

<hr>
<span id="more"></span>

<h3 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h3><h4 id="和-equals"><a href="#和-equals" class="headerlink" title="==和.equals()"></a>==和.equals()</h4><table>
<thead>
<tr>
<th>==</th>
<th>.equals()</th>
</tr>
</thead>
<tbody><tr>
<td>比较的是地址</td>
<td>比较的是值</td>
</tr>
</tbody></table>
<p>即如果两个引用指向同一个对象，用 == 表示它们是相等的；如果两个引用指向不同的对象，用 == 表示它们是不相等的，即使它们的内容相同。</p>
<h4 id="Integer和int"><a href="#Integer和int" class="headerlink" title="Integer和int"></a>Integer和int</h4><p>Java是面向对象的编程语言，一切都是对象，但是为了编程的方便还是引入了基本数据类型，为了能够将这些基本数据类型当成对象操作，Java为每一个基本数据类型都引入了对应的包装类型（wrapper class），int的包装类就是Integer，从Java 5开始引入了自动装箱/拆箱机制，使得二者可以相互转换。</p>
<p><strong>区别：</strong></p>
<ul>
<li>Integer是int的包装类，int则是java的一种基本数据类型</li>
<li>Integer变量必须实例化后才能使用，而int变量不需要</li>
<li>Integer实际是对象的引用，当new一个Integer时，实际上是生成一个指针指向此对象；而int则是直接存储数据值</li>
<li>Integer的默认值是null，int的默认值是0</li>
</ul>
<hr>
<h3 id="源码探析"><a href="#源码探析" class="headerlink" title="源码探析"></a>源码探析</h3><p>那么照这么理解，应该是两个false。但深入源码Integer.java第769行</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Cache to support the object identity semantics of autoboxing for values between</span></span><br><span class="line"><span class="comment"> * -128 and 127 (inclusive) as required by JLS.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The cache is initialized on first usage.  The size of the cache</span></span><br><span class="line"><span class="comment"> * may be controlled by the &#123;<span class="doctag">@code</span> -XX:AutoBoxCacheMax=&lt;size&gt;&#125; option.</span></span><br><span class="line"><span class="comment"> * During VM initialization, java.lang.Integer.IntegerCache.high property</span></span><br><span class="line"><span class="comment"> * may be set and saved in the private system properties in the</span></span><br><span class="line"><span class="comment"> * sun.misc.VM class.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntegerCache</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> low = -<span class="number">128</span>;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> high;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> Integer cache[];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="comment">// high value may be configured by property</span></span><br><span class="line">        <span class="keyword">int</span> h = <span class="number">127</span>;</span><br><span class="line">        String integerCacheHighPropValue =</span><br><span class="line">            sun.misc.VM.getSavedProperty(<span class="string">&quot;java.lang.Integer.IntegerCache.high&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (integerCacheHighPropValue != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">int</span> i = parseInt(integerCacheHighPropValue);</span><br><span class="line">                i = Math.max(i, <span class="number">127</span>);</span><br><span class="line">                <span class="comment">// Maximum array size is Integer.MAX_VALUE</span></span><br><span class="line">                h = Math.min(i, Integer.MAX_VALUE - (-low) -<span class="number">1</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span>( NumberFormatException nfe) &#123;</span><br><span class="line">                <span class="comment">// If the property cannot be parsed into an int, ignore it.</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        high = h;</span><br><span class="line"></span><br><span class="line">        cache = <span class="keyword">new</span> Integer[(high - low) + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span> j = low;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; cache.length; k++)</span><br><span class="line">            cache[k] = <span class="keyword">new</span> Integer(j++);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// range [-128, 127] must be interned (JLS7 5.1.7)</span></span><br><span class="line">        <span class="keyword">assert</span> IntegerCache.high &gt;= <span class="number">127</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">IntegerCache</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个内部私有类缓存了-128~127之间的所有整数对象，所以当我们类似于声明</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer a = <span class="number">100</span>;</span><br></pre></td></tr></table></figure>

<p>实际上内部做的是</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer a = Integer.valueof(<span class="number">100</span>);</span><br></pre></td></tr></table></figure>

<p>接着再去看看valueof方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Returns an &#123;<span class="doctag">@code</span> Integer&#125; instance representing the specified</span></span><br><span class="line"><span class="comment"> * &#123;<span class="doctag">@code</span> int&#125; value.  If a new &#123;<span class="doctag">@code</span> Integer&#125; instance is not</span></span><br><span class="line"><span class="comment"> * required, this method should generally be used in preference to</span></span><br><span class="line"><span class="comment"> * the constructor &#123;<span class="doctag">@link</span> #Integer(int)&#125;, as this method is likely</span></span><br><span class="line"><span class="comment"> * to yield significantly better space and time performance by</span></span><br><span class="line"><span class="comment"> * caching frequently requested values.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This method will always cache values in the range -128 to 127,</span></span><br><span class="line"><span class="comment"> * inclusive, and may cache other values outside of this range.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span>  i an &#123;<span class="doctag">@code</span> int&#125; value.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> an &#123;<span class="doctag">@code</span> Integer&#125; instance representing &#123;<span class="doctag">@code</span> i&#125;.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span>  1.5</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Integer <span class="title">valueOf</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)</span><br><span class="line">        <span class="keyword">return</span> IntegerCache.cache[i + (-IntegerCache.low)];</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Integer(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果值的范围在-128~127之间，它就从高速缓存中返回实例，所以a、b指向的是同个对象。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer a = <span class="number">100</span>, b = <span class="number">100</span>;</span><br></pre></td></tr></table></figure>

<p>你可能会问，为什么这里需要缓存？</p>
<p>合理的理由是，在此范围内的“小”整数使用率比大整数高很多，重复创建与销毁对象是有一定代价的，因此使用相同的底层对象是有价值的，可以减少潜在的内存占用与抖动。</p>
<hr>
<h3 id="拓展解析"><a href="#拓展解析" class="headerlink" title="拓展解析"></a>拓展解析</h3><ol>
<li><p>由于Integer变量实际上是对一个Integer对象的引用，所以两个通过new生成的Integer变量永远是不相等的（因为new生成的是两个对象，其内存地址不同）。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i = <span class="keyword">new</span> Integer(<span class="number">100</span>);</span><br><span class="line">Integer j = <span class="keyword">new</span> Integer(<span class="number">100</span>);</span><br><span class="line">System.out.print(i == j); <span class="comment">//false</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Integer变量和int变量比较时，只要两个变量的值是向等的，则结果为true（因为包装类Integer和基本数据类型int比较时，java会自动拆包装为int，然后进行比较，实际上就变为两个int变量的比较）</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i = <span class="keyword">new</span> Integer(<span class="number">100</span>);</span><br><span class="line"><span class="keyword">int</span> j = <span class="number">100</span>；</span><br><span class="line">System.out.print(i == j); <span class="comment">//true</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>非new生成的Integer变量和new Integer()生成的变量比较时，结果为false。（因为非new生成的Integer变量指向的是java常量池中的对象，而new Integer()生成的变量指向堆中新建的对象，两者在内存中的地址不同）</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i = <span class="keyword">new</span> Integer(<span class="number">100</span>);</span><br><span class="line">Integer j = <span class="number">100</span>;</span><br><span class="line">System.out.print(i == j); <span class="comment">//false</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>对于两个非new生成的Integer对象，进行比较时，如果两个变量的值在区间-128到127之间，则比较结果为true，如果两个变量的值不在此区间，则比较结果为false</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i = <span class="number">100</span>;</span><br><span class="line">Integer j = <span class="number">100</span>;</span><br><span class="line">System.out.print(i == j); <span class="comment">//true</span></span><br><span class="line">Integer i = <span class="number">128</span>;</span><br><span class="line">Integer j = <span class="number">128</span>;</span><br><span class="line">System.out.print(i == j); <span class="comment">//false</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="理解自动装箱、拆箱"><a href="#理解自动装箱、拆箱" class="headerlink" title="理解自动装箱、拆箱"></a>理解自动装箱、拆箱</h4><p>自动装箱与拆箱实际上算是一种“语法糖”。所谓语法糖，可简单理解为Java平台为我们自动进行了一些转换，保证不同的写法在运行时等价。因此它们是发生在编译阶段的，也就是说生成的字节码是一致的。</p>
<p>对于整数，javac替我们自动把装箱转换为Integer.valueOf()，把拆箱替换为Integer.intValue()。可以通过将代码编译后，再反编译加以证实。</p>
<p>原则上，建议避免无意中的装箱、拆箱行为，尤其是在性能敏感的场合，创建10万个Java对象和10万个整数的开销可不是一个数量级的。当然请注意，只有确定你现在所处的场合是性能敏感的，才需要考虑上述问题。毕竟大多数的代码还是以开发效率为优先的。</p>
<p>顺带说一下，在32位环境下，Integer对象占用内存16字节；在64位环境下则更大。</p>
<h4 id="值缓存"><a href="#值缓存" class="headerlink" title="值缓存"></a>值缓存</h4><p>就像String，Java也为Integer提供了值缓存。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer i1 = <span class="number">1</span>;</span><br><span class="line">Integer i2 = Integer.valueOf(<span class="number">2</span>);</span><br><span class="line">Integer i3 = <span class="keyword">new</span> Integer(<span class="number">3</span>);</span><br></pre></td></tr></table></figure>

<p>上述代码中第一行与第二行的写法取值使用了值缓存，而第三行的写法则没有利用值缓存。结合刚刚讲到的自动装箱、拆箱的知识，第一行代码用到的自动装箱，等价于调用了Integer.valueOf()。</p>
<p>不仅仅是Integer，Java也为其它包装类提供了值缓存机制，包括Boolean、Byte、Short和Character等。但与String不同的是，默认都只会将绝对值较小的值放入缓存。以Integer为例，默认情况下只会缓存-128到127之间的值。当然如果你愿意也可以通过以下JVM参数进行设置：</p>
<p>-XX:AutoBoxCacheMax=N</p>
<h4 id="原始类型操作线程安全吗？"><a href="#原始类型操作线程安全吗？" class="headerlink" title="原始类型操作线程安全吗？"></a>原始类型操作线程安全吗？</h4><p>线程不安全！！</p>
<p>原始数据类型的变量，需要使用并发相关手段才能保证线程安全。特别的是，部分比较宽的数据类型，比如long、float、double，甚至不能保证更新操作的原子性，可能出现程序读取到只更新了一半数据位的数值！</p>
<p>如果有线程安全的计算需要，建议考虑使用类似AtomicInteger、AtomicLong这样线程安全的类。</p>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Java</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-视频开发-（五）视频处理</title>
    <url>/44c52947.html</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>一般来说视频处理有两种方式，一种是软编解码（软解，FFmpeg），一种是硬编解码（硬解，MediaCodec）。</p>
<p>两者的优缺点如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>FFmpeg</th>
<th>MediaCodec</th>
</tr>
</thead>
<tbody><tr>
<td>优点</td>
<td>（1）封装了很多的格式，使用起来比较灵活、简单、兼容性好，功能强大；（2）命令行的方式很方便，比如视频裁剪的步骤：ffmpeg -ss 10 -t 20 -i INPUT -acodec copy -vcodec copy OUTPUT，相对来说写个函数去实现就太麻烦。</td>
<td>功耗低，速度快</td>
</tr>
<tr>
<td>缺点</td>
<td>软编解码功耗大</td>
<td>扩展性不强，不同芯片厂商提供的支持方案不同，导致程序移植性差</td>
</tr>
</tbody></table>
<hr>
<span id="more"></span>

<h3 id="软编解码"><a href="#软编解码" class="headerlink" title="软编解码"></a>软编解码</h3><h4 id="FFmpeg库的引入"><a href="#FFmpeg库的引入" class="headerlink" title="FFmpeg库的引入"></a>FFmpeg库的引入</h4><p>引入库的方式有两种：aar或者源码依赖</p>
<p>aar依赖</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">    compile <span class="string">&#x27;com.writingminds:FFmpegAndroid:0.3.2&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>源码依赖</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 用git将ffmpeg-android-java clone到本地，然后把项目中FFmpegAndroid库的源码加入到项目与app同级的目录中。</span></span><br><span class="line"><span class="comment">// https://github.com/WritingMinds/ffmpeg-android-java</span></span><br></pre></td></tr></table></figure>

<h4 id="库的初始化"><a href="#库的初始化" class="headerlink" title="库的初始化"></a>库的初始化</h4><p>初始化的目的是根据Android手机的cpu架构，load对应架构的ffmpeg库。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZApplication</span> <span class="keyword">extends</span> <span class="title">Application</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.onCreate();</span><br><span class="line">        initFFmpegBinary(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initFFmpegBinary</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FFmpeg.getInstance(context).loadBinary(<span class="keyword">new</span> LoadBinaryResponseHandler() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FFmpegNotSupportedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="执行ffmpeg的commend命令"><a href="#执行ffmpeg的commend命令" class="headerlink" title="执行ffmpeg的commend命令"></a>执行ffmpeg的commend命令</h4><p>这个库是对ffmpeg的在Linux系统中命令行的一个封装，在FFmpegInterface.java类中找到了如下的API：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Executes a command</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> environvenmentVars Environment variables</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> cmd command to execute</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> ffmpegExecuteResponseHandler &#123;<span class="doctag">@link</span> FFmpegExecuteResponseHandler&#125;</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> FFmpegCommandAlreadyRunningException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Map&lt;String, String&gt; environvenmentVars, String[] cmd, FFmpegExecuteResponseHandler ffmpegExecuteResponseHandler)</span> <span class="keyword">throws</span> FFmpegCommandAlreadyRunningException</span>;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Executes a command</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> cmd command to execute</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> ffmpegExecuteResponseHandler &#123;<span class="doctag">@link</span> FFmpegExecuteResponseHandler&#125;</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> FFmpegCommandAlreadyRunningException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(String[] cmd, FFmpegExecuteResponseHandler ffmpegExecuteResponseHandler)</span> <span class="keyword">throws</span> FFmpegCommandAlreadyRunningException</span>;</span><br></pre></td></tr></table></figure>

<h4 id="视频裁剪"><a href="#视频裁剪" class="headerlink" title="视频裁剪"></a>视频裁剪</h4><p>视频裁剪：ffmpeg -ss START -t DURATION -i INPUT -vcodec copy -acodec copy OUTPUT</p>
<h4 id="视频合并"><a href="#视频合并" class="headerlink" title="视频合并"></a>视频合并</h4><p>方法一：FFmpeg concat 协议</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">对于 MPEG 格式的视频，可以直接连接：</span><br><span class="line">ffmpeg -i <span class="string">&quot;concat:input1.mpg|input2.mpg|input3.mpg&quot;</span> -c copy output.mpg</span><br><span class="line"> </span><br><span class="line">对于非 MPEG 格式容器，但是是 MPEG 编码器（H<span class="number">.264</span>、DivX、XviD、MPEG4、MPEG2、AAC、MP2、MP3 等），可以包装进 TS 格式的容器再合并。在新浪视频，有很多视频使用 H<span class="number">.264</span> 编码器，可以采用这个方法</span><br><span class="line">ffmpeg -i input1.flv -c copy -bsf:v h264_mp4toannexb -f mpegts input1.ts</span><br><span class="line">ffmpeg -i input2.flv -c copy -bsf:v h264_mp4toannexb -f mpegts input2.ts</span><br><span class="line">ffmpeg -i input3.flv -c copy -bsf:v h264_mp4toannexb -f mpegts input3.ts</span><br><span class="line">ffmpeg -i <span class="string">&quot;concat:input1.ts|input2.ts|input3.ts&quot;</span> -c copy -bsf:a aac_adtstoasc -movflags +faststart output.mp4</span><br><span class="line">保存 QuickTime/MP4 格式容器的时候，建议加上 -movflags +faststart。这样分享文件给别人的时候可以边下边看。</span><br></pre></td></tr></table></figure>

<p>方法二：FFmpeg concat 分离器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">先创建一个文本文件filelist.txt：</span><br><span class="line">file <span class="string">&#x27;input1.mkv&#x27;</span></span><br><span class="line">file <span class="string">&#x27;input2.mkv&#x27;</span></span><br><span class="line">file <span class="string">&#x27;input3.mkv&#x27;</span></span><br><span class="line"> </span><br><span class="line">然后：</span><br><span class="line">ffmpeg -f concat -i filelist.txt -c copy output.mkv</span><br><span class="line">注意：使用 FFmpeg concat 分离器时，如果文件名有奇怪的字符，要在 filelist.txt 中转义。</span><br></pre></td></tr></table></figure>

<p>方法三：Mencoder 连接文件并重建索引</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">对于没有使用 MPEG 编码器的视频（如 FLV1 编码器），可以尝试这种方法。</span><br><span class="line">mencoder -forceidx -of lavf -oac copy -ovc copy -o output.flv input1.flv input2.flv input3.flv</span><br></pre></td></tr></table></figure>

<p>方法四：使用 FFmpeg concat 过滤器重新编码（有损）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">这个方法可以合并不同编码器的视频片段，也可以作为其他方法失效的后备措施。</span><br><span class="line">ffmpeg -i input1.mp4 -i input2.webm -i input3.avi -filter_complex <span class="string">&#x27;[0:0] [0:1] [1:0] [1:1] [2:0] [2:1] concat=n=3:v=1:a=1 [v] [a]&#x27;</span> -map <span class="string">&#x27;[v]&#x27;</span> -map <span class="string">&#x27;[a]&#x27;</span> &lt;编码器选项&gt; output.mkv</span><br><span class="line">如你所见，上面的命令合并了三种不同格式的文件，FFmpeg concat 过滤器会重新编码它们。注意这是有损压缩。</span><br><span class="line">[<span class="number">0</span>:<span class="number">0</span>] [<span class="number">0</span>:<span class="number">1</span>] [<span class="number">1</span>:<span class="number">0</span>] [<span class="number">1</span>:<span class="number">1</span>] [<span class="number">2</span>:<span class="number">0</span>] [<span class="number">2</span>:<span class="number">1</span>] 分别表示第一个输入文件的视频、音频、第二个输入文件的视频、音频、第三个输入文件的视频、音频。concat=n=<span class="number">3</span>:v=<span class="number">1</span>:a=<span class="number">1</span> 表示有三个输入文件，输出一条视频流和一条音频流。[v] [a] 就是得到的视频流和音频流的名字，注意在 bash 等 shell 中需要用引号，防止通配符扩展。</span><br></pre></td></tr></table></figure>

<h4 id="其它常用命令"><a href="#其它常用命令" class="headerlink" title="其它常用命令"></a>其它常用命令</h4><p>FFmpeg常用基本命令</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span>分离视频音频流</span><br><span class="line">ffmpeg -i input_file -vcodec copy -an output_file_video　　<span class="comment">//分离视频流</span></span><br><span class="line">ffmpeg -i input_file -acodec copy -vn output_file_audio　　<span class="comment">//分离音频流</span></span><br><span class="line"> </span><br><span class="line"><span class="number">2.</span>视频解复用</span><br><span class="line">ffmpeg –i test.mp4 –vcodec copy –an –f m4v test<span class="number">.264</span></span><br><span class="line">ffmpeg –i test.avi –vcodec copy –an –f m4v test<span class="number">.264</span></span><br><span class="line"> </span><br><span class="line"><span class="number">3.</span>视频转码</span><br><span class="line">ffmpeg –i test.mp4 –vcodec h264 –s <span class="number">352</span>*<span class="number">278</span> –an –f m4v test<span class="number">.264</span> <span class="comment">//转码为码流原始文件</span></span><br><span class="line">ffmpeg –i test.mp4 –vcodec h264 –bf <span class="number">0</span> –g <span class="number">25</span> –s <span class="number">352</span>*<span class="number">278</span> –an –f m4v test<span class="number">.264</span> <span class="comment">//转码为码流原始文件</span></span><br><span class="line">ffmpeg –i test.avi -vcodec mpeg4 –vtag xvid –qsame test_xvid.avi <span class="comment">//转码为封装文件</span></span><br><span class="line"><span class="comment">//-bf B帧数目控制，-g 关键帧间隔控制，-s 分辨率控制</span></span><br><span class="line"> </span><br><span class="line"><span class="number">4.</span>视频封装</span><br><span class="line">ffmpeg –i video_file –i audio_file –vcodec copy –acodec copy output_file</span><br><span class="line"> </span><br><span class="line"><span class="number">5.</span>视频剪切</span><br><span class="line">ffmpeg –i test.avi –r <span class="number">1</span> –f image2 image-%<span class="number">3d</span>.jpeg <span class="comment">//提取图片</span></span><br><span class="line">ffmpeg -ss <span class="number">0</span>:<span class="number">1</span>:<span class="number">30</span> -t <span class="number">0</span>:<span class="number">0</span>:<span class="number">20</span> -i input.avi -vcodec copy -acodec copy output.avi <span class="comment">//剪切视频</span></span><br><span class="line"><span class="comment">//-r 提取图像的频率，-ss 开始时间，-t 持续时间</span></span><br><span class="line"> </span><br><span class="line"><span class="number">6.</span>视频录制</span><br><span class="line">ffmpeg –i rtsp:<span class="comment">//192.168.3.205:5555/test –vcodec copy out.avi</span></span><br><span class="line"> </span><br><span class="line"><span class="number">7.</span>YUV序列播放</span><br><span class="line">ffplay -f rawvideo -video_size 1920x1080 input.yuv</span><br><span class="line"> </span><br><span class="line"><span class="number">8.</span>YUV序列转AVI</span><br><span class="line">ffmpeg –s w*h –pix_fmt yuv420p –i input.yuv –vcodec mpeg4 output.avi</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">【常用参数说明】</span><br><span class="line">主要参数：</span><br><span class="line">-i 设定输入流</span><br><span class="line">-f 设定输出格式</span><br><span class="line">-ss 开始时间</span><br><span class="line">视频参数：</span><br><span class="line">-b 设定视频流量，默认为200Kbit/s</span><br><span class="line">-r 设定帧速率，默认为<span class="number">25</span></span><br><span class="line">-s 设定画面的宽与高</span><br><span class="line">-aspect 设定画面的比例</span><br><span class="line">-vn 不处理视频</span><br><span class="line">-vcodec 设定视频编解码器，未设定时则使用与输入流相同的编解码器</span><br><span class="line">音频参数：</span><br><span class="line">-ar 设定采样率</span><br><span class="line">-ac 设定声音的Channel数</span><br><span class="line">-acodec 设定声音编解码器，未设定时则使用与输入流相同的编解码器</span><br><span class="line">-an 不处理音频</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="硬编解码"><a href="#硬编解码" class="headerlink" title="硬编解码"></a>硬编解码</h3><h4 id="exoplayer"><a href="#exoplayer" class="headerlink" title="exoplayer"></a>exoplayer</h4><p>如果播放器部分是用exoplayer，也是硬解，这样就可以减少很多体积，且内置了一些功能可以直接调用。</p>
<p>使用exoplayer的原因：</p>
<ul>
<li>谷歌官方出品的开源库，易于自定义和扩展，exoplayer专门为此做了设计，准许很多组件可以被自定义的实现类替换</li>
<li>java编写，相比于native code，开发更容易，更清楚的获得一些异常源和进行部分代码调试</li>
<li>较少的设备兼容问题</li>
</ul>
<table>
<thead>
<tr>
<th>功能</th>
<th>exoplayer是否已有api支持</th>
<th>拓展使用的基类和接口</th>
</tr>
</thead>
<tbody><tr>
<td>视频裁剪</td>
<td>已有支持</td>
<td>ClippingMediaSource</td>
</tr>
<tr>
<td>素材拼接</td>
<td>已有支持</td>
<td>ConcatenatingMediaSource</td>
</tr>
<tr>
<td>视频变速</td>
<td>已有支持</td>
<td>SimpleExoPlayer.setPlaybackParameters</td>
</tr>
</tbody></table>
<p><strong>视频裁剪：</strong></p>
<p>视频裁剪播放使用ClippingMediaSource设置裁剪素材，按api文档传入起始时间和结束时间。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates a new clipping source that wraps the specified source and provides samples between the</span></span><br><span class="line"><span class="comment"> * specified start and end position.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> mediaSource The single-period source to wrap.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> startPositionUs The start position within &#123;<span class="doctag">@code</span> mediaSource&#125;&#x27;s window at which to start</span></span><br><span class="line"><span class="comment"> *     providing samples, in microseconds.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> endPositionUs The end position within &#123;<span class="doctag">@code</span> mediaSource&#125;&#x27;s window at which to stop</span></span><br><span class="line"><span class="comment"> *     providing samples, in microseconds. Specify &#123;<span class="doctag">@link</span> C#TIME_END_OF_SOURCE&#125; to provide samples</span></span><br><span class="line"><span class="comment"> *     from the specified start point up to the end of the source. Specifying a position that</span></span><br><span class="line"><span class="comment"> *     exceeds the &#123;<span class="doctag">@code</span> mediaSource&#125;&#x27;s duration will also result in the end of the source not</span></span><br><span class="line"><span class="comment"> *     being clipped.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ClippingMediaSource</span><span class="params">(MediaSource mediaSource, <span class="keyword">long</span> startPositionUs, <span class="keyword">long</span> endPositionUs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(</span><br><span class="line">        mediaSource,</span><br><span class="line">        startPositionUs,</span><br><span class="line">        endPositionUs,</span><br><span class="line">        <span class="comment">/* enableInitialDiscontinuity= */</span> <span class="keyword">true</span>,</span><br><span class="line">        <span class="comment">/* allowDynamicClippingUpdates= */</span> <span class="keyword">false</span>,</span><br><span class="line">        <span class="comment">/* relativeToDefaultPosition= */</span> <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>素材拼接:</strong></p>
<p>多个视频拼接播放，使用ConcatenatingMediaSource可以用来无缝地合并播放多个素材。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> mediaSources The &#123;<span class="doctag">@link</span> MediaSource&#125;s to concatenate. It is valid for the same &#123;<span class="doctag">@link</span></span></span><br><span class="line"><span class="comment"> *     MediaSource&#125; instance to be present more than once in the array.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcatenatingMediaSource</span><span class="params">(MediaSource... mediaSources)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(<span class="comment">/* isAtomic= */</span> <span class="keyword">false</span>, mediaSources);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>视频变速：</strong></p>
<p>变速使用setPlaybackParameters设置速度参数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SimpleExoPlayer simpleExoPlayer = player.getExoPlayer();</span><br><span class="line"><span class="keyword">if</span> (simpleExoPlayer != <span class="keyword">null</span>) &#123;</span><br><span class="line">    simpleExoPlayer.setPlaybackParameters(<span class="keyword">new</span> PlaybackParameters(speed));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="MediaCodec-MediaExtractor-MediaMuxer"><a href="#MediaCodec-MediaExtractor-MediaMuxer" class="headerlink" title="MediaCodec+MediaExtractor+MediaMuxer"></a>MediaCodec+MediaExtractor+MediaMuxer</h4><p>音视频编辑中，对多段媒体素材进行截取和拼接是非常常见的操作，截取和拼接实际上是对媒体文件数据重新进行组合的过程。</p>
<p>要实现这些功能，就需要对媒体文件进行编解码操作，即先解码要处理的媒体文件数据，然后再按照某种规则对这些数据进行编码，以生成我们所需的目标。</p>
<img src="/44c52947/1.png" class>

<p>注意：当要向文件中同时写入视频和音频数据时，必需先writeSampleData所有视频数据，再写音频数据，或者反之，即二者必需连续调用writeSampleData，不能交叉调用，否则写出的文件会有问题。</p>
<p><strong>具体操作过程：</strong></p>
<p>先初始化MediaExtractor并分离音视频轨道、MediaMuxer初始化，再把分离后的数据送到MediaCodec中进行解码处理操作元数据，最后用MediaMuxer对文件进行封装。</p>
<p>视频裁剪</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@TargetApi(Build.VERSION_CODES.LOLLIPOP)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">genVideoUsingMuxer</span><span class="params">(Context context, String srcPath, String dstPath, <span class="keyword">int</span> startMs, <span class="keyword">int</span> endMs, <span class="keyword">boolean</span> useAudio, <span class="keyword">boolean</span> useVideo)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> success = <span class="keyword">true</span>;</span><br><span class="line">    <span class="comment">// Set up MediaExtractor to read from the source.</span></span><br><span class="line">    MediaExtractor extractor = <span class="keyword">new</span> MediaExtractor();</span><br><span class="line">    extractor.setDataSource(srcPath);</span><br><span class="line">    <span class="keyword">int</span> trackCount = extractor.getTrackCount();</span><br><span class="line">    <span class="comment">// Set up MediaMuxer for the destination.</span></span><br><span class="line">    MediaMuxer muxer;</span><br><span class="line">    muxer = <span class="keyword">new</span> MediaMuxer(dstPath, MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4);</span><br><span class="line">    <span class="comment">// Set up the tracks and retrieve the max buffer size for selected tracks.</span></span><br><span class="line">    HashMap&lt;Integer, Integer&gt; indexMap = <span class="keyword">new</span> HashMap&lt;&gt;(trackCount);</span><br><span class="line">    <span class="keyword">int</span> bufferSize = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; trackCount; i++) &#123;</span><br><span class="line">        MediaFormat format = extractor.getTrackFormat(i);</span><br><span class="line">        String mime = format.getString(MediaFormat.KEY_MIME);</span><br><span class="line">        <span class="keyword">boolean</span> selectCurrentTrack = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (mime.startsWith(<span class="string">&quot;audio/&quot;</span>) &amp;&amp; useAudio) &#123;</span><br><span class="line">            selectCurrentTrack = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (mime.startsWith(<span class="string">&quot;video/&quot;</span>) &amp;&amp; useVideo) &#123;</span><br><span class="line">            selectCurrentTrack = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (selectCurrentTrack) &#123;</span><br><span class="line">            extractor.selectTrack(i);</span><br><span class="line">            <span class="keyword">int</span> dstIndex = muxer.addTrack(format);</span><br><span class="line">            indexMap.put(i, dstIndex);</span><br><span class="line">            <span class="keyword">if</span> (format.containsKey(MediaFormat.KEY_MAX_INPUT_SIZE)) &#123;</span><br><span class="line">                <span class="keyword">int</span> newSize = format.getInteger(MediaFormat.KEY_MAX_INPUT_SIZE);</span><br><span class="line">                bufferSize = newSize &gt; bufferSize ? newSize : bufferSize;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (bufferSize &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        bufferSize = <span class="number">1080</span>*<span class="number">1920</span>*<span class="number">30</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// Set up the orientation and starting time for extractor.</span></span><br><span class="line">    MediaMetadataRetriever retrieverSrc = <span class="keyword">new</span> MediaMetadataRetriever();</span><br><span class="line">    retrieverSrc.setDataSource(srcPath);</span><br><span class="line">    String degreesString = retrieverSrc.extractMetadata(</span><br><span class="line">            MediaMetadataRetriever.METADATA_KEY_VIDEO_ROTATION);</span><br><span class="line">    <span class="keyword">if</span> (degreesString != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> degrees = Integer.parseInt(degreesString);</span><br><span class="line">        <span class="keyword">if</span> (degrees &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            muxer.setOrientationHint(degrees);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (startMs &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        extractor.seekTo(startMs * <span class="number">1000</span>, MediaExtractor.SEEK_TO_PREVIOUS_SYNC);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Copy the samples from MediaExtractor to MediaMuxer. We will loop</span></span><br><span class="line">    <span class="comment">// for copying each sample and stop when we get to the end of the source</span></span><br><span class="line">    <span class="comment">// file or exceed the end time of the trimming.</span></span><br><span class="line">    <span class="keyword">int</span> offset = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> trackIndex = -<span class="number">1</span>;</span><br><span class="line">    ByteBuffer dstBuf = ByteBuffer.allocate(bufferSize);</span><br><span class="line">    MediaCodec.BufferInfo bufferInfo = <span class="keyword">new</span> MediaCodec.BufferInfo();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        muxer.start();</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            bufferInfo.offset = offset;</span><br><span class="line">            bufferInfo.size = extractor.readSampleData(dstBuf, offset);</span><br><span class="line">            <span class="keyword">if</span> (bufferInfo.size &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                Log.d(TAG, <span class="string">&quot;Saw input EOS.&quot;</span>);</span><br><span class="line">                bufferInfo.size = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                bufferInfo.presentationTimeUs = extractor.getSampleTime();</span><br><span class="line">                <span class="keyword">if</span> (endMs &gt; <span class="number">0</span> &amp;&amp; bufferInfo.presentationTimeUs &gt; (endMs * <span class="number">1000</span>)) &#123;</span><br><span class="line">                    Log.d(TAG, <span class="string">&quot;The current sample is over the trim end time.&quot;</span>);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    bufferInfo.flags = extractor.getSampleFlags();</span><br><span class="line">                    trackIndex = extractor.getSampleTrackIndex();</span><br><span class="line">                    muxer.writeSampleData(indexMap.get(trackIndex), dstBuf, bufferInfo);</span><br><span class="line">                    extractor.advance();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        muxer.stop();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// Swallow the exception due to malformed source.</span></span><br><span class="line">        Log.w(TAG, <span class="string">&quot;The source video file is malformed&quot;</span>);</span><br><span class="line">        success = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        muxer.release();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> success;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="其他处理：OpenGL-MediaCodec"><a href="#其他处理：OpenGL-MediaCodec" class="headerlink" title="其他处理：OpenGL+MediaCodec"></a>其他处理：OpenGL+MediaCodec</h4><p>众多视频编辑sdk封装ffmpeg对视频进行转码、裁剪、合并、压缩。在音视频领域，一般大型成熟的商用sdk是跨平台的，各终端sdk公用一套由c++开发的底层引擎，针对各端硬件的不同做不同处理，例如分别对pc、android、ios（已有AVFoundation框架）提供硬编硬解的功能。（七牛云短视频SDK 12w/年、腾讯云短视频SDK 50w/年、阿里云短视频SDK 15w/年、VE视频编辑SDK 60w/年）</p>
<img src="/44c52947/2.jpg" class>

<p><strong>硬解用到的技术：</strong></p>
<p>先用MediaExtractor读出视频数据，再用MediaCodec进行解码，将解码的画面通过OpenGL渲染到SurfaceTexture上，由SurfaceTexture生成Surface把画面重新编码进MediaCodec，最后通过MediaMuxer合成视频，视频长度由MediaCodec控制，而画面大小由opengl来裁剪。</p>
<p><strong>OpenGL处理：</strong></p>
<p>OpenGL视频处理流程即使用OpenGL对原始视频帧进行二次处理。创建OpenGL渲染环境，通过SurfaceTexture的updateTexImage接口，可将视频流中最新的帧数据更新到对应的GL纹理，再操作GL纹理可对数据进行处理。</p>
<p>（OpenGL还不熟悉，待补充）</p>
<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.jianshu.com/p/41957301f4a3">https://www.jianshu.com/p/41957301f4a3</a><br><a href="https://www.jianshu.com/p/2cf527f2129f">https://www.jianshu.com/p/2cf527f2129f</a><br><a href="https://www.cnblogs.com/duanxiaojun/articles/6904878.html">https://www.cnblogs.com/duanxiaojun/articles/6904878.html</a><br><a href="https://www.cnblogs.com/dwdxdy/p/3240167.html">https://www.cnblogs.com/dwdxdy/p/3240167.html</a><br><a href="https://blog.csdn.net/u010302327/article/details/81363402">https://blog.csdn.net/u010302327/article/details/81363402</a><br><a href="https://www.jianshu.com/p/a56505bfc15a">https://www.jianshu.com/p/a56505bfc15a</a><br><a href="https://www.jianshu.com/p/eb8615fe9f7a">https://www.jianshu.com/p/eb8615fe9f7a</a><br><a href="https://blog.csdn.net/yangxi_pekin/article/details/48374827">https://blog.csdn.net/yangxi_pekin/article/details/48374827</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-音视频-视频开发-（六）基础组件</title>
    <url>/7c3e1c07.html</url>
    <content><![CDATA[<h3 id="SurfaceView"><a href="#SurfaceView" class="headerlink" title="SurfaceView"></a>SurfaceView</h3><h4 id="Surface"><a href="#Surface" class="headerlink" title="Surface"></a>Surface</h4><p>Surface 就是“表面”的意思，可以<strong>简单理解为内存中的一段绘图缓冲区</strong>。在SDK的文档中，对Surface的描述是这样的：“Handle onto a raw buffer that is being managed by the screen compositor”，翻译成中文就是“由屏幕显示内容合成器(screen compositor)所管理的原生缓冲器的句柄”， 这句话包括下面两个意思：</p>
<ul>
<li>通过Surface（因为Surface是句柄）就可以获得原生缓冲器以及其中的内容。就像在C语言中，可以通过一个文件的句柄，就可以获得文件的内容一样；</li>
<li>原生缓冲器（rawbuffer）是用于保存当前窗口的像素数据的。</li>
</ul>
<p>简单的说 <strong>Surface 对应了一块屏幕缓冲区，每个Window对应一个Surface，任何View都是画在Surface上的</strong>，传统的view共享一块屏幕缓冲区，所有的绘制必须在UI线程中进行我们不能直接操作Surface实例，要通过SurfaceHolder，在SurfaceView中可以通过getHolder()方法获取到SurfaceHolder实例。</p>
<p><strong>Surface 是一个用来画图形的地方，但是我们知道画图都是在一个Canvas对象上面进行的</strong>，Surface 中的 Canvas 成员，是专门用于提供画图的地方，就像黑板一样，其中的原始缓冲区是用来保存数据的地方。</p>
<p>Surface本身的作用类似一个句柄，得到了这个句柄就可以得到其中的Canvas、原始缓冲区以及其他方面的内容，所以简单的说Surface是用来管理数据的(句柄)。</p>
<span id="more"></span>

<h4 id="SurfaceView简介"><a href="#SurfaceView简介" class="headerlink" title="SurfaceView简介"></a>SurfaceView简介</h4><p>简单的说SurfaceView就是一个<strong>有Surface的View里面内嵌了一个专门用于绘制的Surface</strong>，SurfaceView 控制这个 Surface 的格式和尺寸以及绘制位置。</p>
<p><strong>SurfaceView 就是在 Window 上挖一个洞，它就是显示在这个洞里，其他的View是显示在Window上，所以View可以显式在 SurfaceView之上，你也可以添加一些层在SurfaceView之上。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (mWindow == <span class="keyword">null</span>) &#123;  </span><br><span class="line">    mWindow = <span class="keyword">new</span> MyWindow(<span class="keyword">this</span>);  </span><br><span class="line">    mLayout.type = mWindowType;  </span><br><span class="line">    mLayout.gravity = Gravity.LEFT|Gravity.TOP;  </span><br><span class="line">    mSession.addWithoutInputChannel(mWindow, mWindow.mSeq, mLayout,  </span><br><span class="line">    mVisible ? VISIBLE : GONE, mContentInsets);  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>很明显，<strong>每个SurfaceView创建的时候都会创建一个MyWindow，new MyWindow(this)中的this正是SurfaceView自身</strong>，因此将SurfaceView和window绑定在一起，而前面提到过每个window对应一个Surface。</p>
<p><strong>所以SurfaceView也就内嵌了一个自己的Surface，可以认为SurfaceView是来控制Surface的位置和尺寸。</strong>传统View及其派生类的更新只能在UI线程，然而UI线程还同时处理其他交互逻辑，这就无法保证view更新的速度和帧率了，而SurfaceView可以用独立的线程来进行绘制。</p>
<p>因此可以提供更高的帧率，例如游戏，摄像头取景等场景就比较适合用SurfaceView来实现。</p>
<p>Surface是纵深排序(Z-ordered)的，这表明它总在自己所在窗口的后面。</p>
<p>Surfaceview提供了一个可见区域，只有在这个可见区域内的Surface部分内容才可见，可见区域外的部分不可见，所以可以认为SurfaceView就是展示Surface中数据的地方，Surface就是管理数据的地方，SurfaceView就是展示数据的地方，只有通过SurfaceView才能展现Surface中的数据。</p>
<img src="/7c3e1c07/1.png" class>

<p><strong>Surface的排版显示受到视图层级关系的影响，它的兄弟视图结点会在顶端显示。</strong>这意味者Surface的内容会被它的兄弟视图遮挡，这一特性可以用来放置遮盖物(overlays)(例如，文本和按钮等控件)。</p>
<p>如果Surface上面有透明控件，那么它的每次变化都会引起框架重新计算它和顶层控件的透明效果，这会影响性能。surfaceview变得可见时，surface被创建；surfaceview隐藏前，surface被销毁，这样能节省资源。</p>
<p>如果你要查看surface被创建和销毁的时机，可以重载surfaceCreated(SurfaceHolder)和surfaceDestroyed(SurfaceHolder)。</p>
<p><strong>SurfaceView的核心在于提供了两个线程：UI线程和渲染线程,两个线程通过“双缓冲”机制来达到高效的界面适时更新。</strong>而这个双缓冲可以理解为，SurfaceView在更新视图时用到了两张Canvas，一张frontCanvas和一张backCanvas。</p>
<p>每次实际显示的是frontCanvas，backCanvas存储的是上一次更改前的视图，当使用lockCanvas()获取画布时，得到的实际上是backCanvas而不是正在显示的frontCanvas，之后你在获取到的backCanvas上绘制新视图，再unlockCanvasAndPost(canvas)此视图，那么上传的这张canvas将替换原来的frontCanvas作为新的frontCanvas，原来的frontCanvas将切换到后台作为backCanvas。</p>
<p>例如，如果你已经先后两次绘制了视图A和B，那么你再调用lockCanvas()获取视图，获得的将是A而不是正在显示的B，之后你将重绘的C视图上传，那么C将取代B作为新的frontCanvas显示在SurfaceView上，原来的B则转换为backCanvas。</p>
<p>不用画布，直接在窗口上进行绘图叫做无缓冲绘图。用了一个画布，将所有内容都先画到画布上，在整体绘制到窗口上，就该叫做单缓冲绘图，那个画布就是一个缓冲区。用了两个画布，一个进行临时的绘图，一个进行最终的绘图，这样就叫做双缓冲。</p>
<h4 id="SurfaceHolder-简介"><a href="#SurfaceHolder-简介" class="headerlink" title="SurfaceHolder 简介"></a>SurfaceHolder 简介</h4><p><strong>显示一个 Surface 的抽象接口，使你可以控制 Surface 的大小和格式以及在Surface上编辑像素，和监视 Surace 的改变。</strong>这个接口通常通过SurfaceView类实现。</p>
<p>简单的说就是<strong>我们无法直接操作Surface只能通过SurfaceHolder这个接口来获取和操作Surface。</strong></p>
<p>SurfaceHolder中提供了一些lockCanvas()：获取一个Canvas对象，并锁定。</p>
<p>所得到的Canvas对象，其实就是 Surface 中一个成员。加锁的目的其实就是为了在绘制的过程中，Surface 中的数据不会被改变。lockCanvas 是为了防止同一时刻多个线程对同一 canvas写入。</p>
<p>从设计模式的角度来看，**Surface、SurfaceView、SurfaceHolder实质上就是MVC(Model-View-Controller)**。Model就是模型或者说是数据模型，更简单的可以理解成数据，在这里也就是Surface；View就是视图，代表用户交互界面，这里就是 SurfaceView；SurfaceHolder 就是 Controller。</p>
<hr>
<h3 id="TextureView"><a href="#TextureView" class="headerlink" title="TextureView"></a>TextureView</h3><h4 id="SurfaceTexture简介"><a href="#SurfaceTexture简介" class="headerlink" title="SurfaceTexture简介"></a>SurfaceTexture简介</h4><p><strong>SurfaceTexture 是 Surface 和 OpenGL ES(GLES) 纹理的组合。SurfaceTexture 用于提供输出到 GLES 纹理的 Surface 。</strong></p>
<p>SurfaceTexture 是从Android 3.0开始加入，与SurfaceView不同的是，<strong>它对图像流的处理并不直接显示，而是转为GL外部纹理，因此用于图像流数据的二次处理。</strong></p>
<p>比如 Camera 的预览数据，变成纹理后可以交给 GLSurfaceView 直接显示，也可以通过SurfaceTexture 交给TextureView 作为 View heirachy 中的一个硬件加速层来显示。</p>
<p>首先，SurfaceTexture从图像流 (来自Camera预览、视频解码、GL绘制场景等) 中获得帧数据，当调用updateTexImage()时，根据内容流中最近的图像更新 SurfaceTexture 对应的GL纹理对象。</p>
<p>SurfaceTexture 包含一个应用是其使用方的BufferQueue。当生产方将新的缓冲区排入队列时，onFrameAvailable() 回调会通知应用。然后，应用调用updateTexImage()，这会释放先前占有的缓冲区，从队列中获取新缓冲区并执行EGL调用，从而使GLES可将此缓冲区作为外部纹理使用。</p>
<h4 id="TextureView简介"><a href="#TextureView简介" class="headerlink" title="TextureView简介"></a>TextureView简介</h4><p>因为上面所说的SurfaceView不在主窗口中，它没法做动画没法使用一些View的特性方法，所以<strong>在Android 4.0中引入了TextureView，它是一个结合了View和SurfaceTexture的View对象。</strong></p>
<p>它不会在WMS中单独创建窗口，而是作为View hierachy中的一个普通view，<strong>因此它可以和其他普通View一样进行平移、旋转等动画</strong>。但是TextureView必须在硬件加速的窗口中，它显示的内容流数据可以来自App进程或者远程进程。</p>
<p>TextureView 重载了 draw() 方法，其中<strong>主要 SurfaceTexture 中收到的图像数据作为纹理更新到对应的 HardwareLayer 中</strong>。</p>
<p>SurfaceTexture.OnFrameAvailableListener用于通知TextureView内容流有新图像到来。SurfaceTextureListener接口用于让TextureView的使用者知道SurfaceTexture已准备好，这样就可以把SurfaceTexture交给相应的内容源。</p>
<p>Surface为BufferQueue的Producer接口实现类，使生产者可以通过它的软件或硬件渲染接口为SurfaceTexture内部的BufferQueue提供graphic buffer。</p>
<p>SurfaceTexture 可以用作非直接输出的内容流，这样就提供二次处理的机会。与SurfaceView直接输出相比，这样会有若干帧的延迟。同时，由于它本身管理BufferQueue，因此内存消耗也会稍微大一些。</p>
<p>TextureView <strong>是一个可以把内容流作为外部纹理输出在上面的 View</strong>，它本身需要是一个硬件加速层。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>SurfaceView 是一个有自己Surface的View。</strong>它的渲染可以放在单独线程而不是主线程中。其<strong>缺点是不能做变形和动画</strong>。</p>
<p><strong>SurfaceTexture</strong>可以用作非直接输出的内容流，这样就提供二次处理的机会。与SurfaceView直接输出相比，这样会有若干帧的延迟。同时，由于它本身管理BufferQueue，因此内存消耗也会稍微大一些。</p>
<p><strong>TextureView是一个可以把内容流作为外部纹理输出在上面的View。它本身需要是一个硬件加速层。事实上TextureView本身也包含了SurfaceTexture。</strong>它与SurfaceView+SurfaceTexture组合相比可以完成类似的功能（即把内容流上的图像转成纹理，然后输出）。<strong>区别在于TextureView是在View hierachy中做绘制，因此一般它是在主线程上做的（在Android 5.0引入渲染线程后，它是在渲染线程中做的）。</strong>而SurfaceView+SurfaceTexture在单独的Surface上做绘制，可以是用户提供的线程，而不是系统的主线程或是渲染线程。与 SurfaceView 相比，<strong>TextureView 具有更出色的 Alpha 版和旋转处理能力</strong>，但在视频上以分层方式合成界面元素时，SurfaceView 具有性能方面的优势。</p>
<p>当客户端使用 SurfaceView 呈现内容时，SurfaceView 会为客户端提供单独的合成层。如果设备支持，SurfaceFlinger 会将单独的层合成为硬件叠加层。</p>
<p>当客户端使用 TextureView 呈现内容时，界面工具包会使用 GPU 将 TextureView 的内容合成到 View 层次结构中。</p>
<p>对内容进行的更新可能会导致其他 View 元素重绘，例如，如果其他 View 位于 TextureView 上方。View 呈现完成后，SurfaceFlinger 会合成应用界面层和所有其他层，以便每个可见像素合成两次。</p>
<p><strong>注意：受 DRM 保护的视频只能在叠加平面上呈现。支持受保护内容的视频播放器必须使用 SurfaceView 进行实现。</strong></p>
<table>
<thead>
<tr>
<th>项目</th>
<th>SurfaceView</th>
<th>TextureView</th>
</tr>
</thead>
<tbody><tr>
<td>内存</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>耗电</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>绘制</td>
<td>及时</td>
<td>1~3帧延迟</td>
</tr>
<tr>
<td>动画和截图</td>
<td>不支持</td>
<td>支持</td>
</tr>
</tbody></table>
<ul>
<li><strong>在Android 7.0上系统 Surfaceview 的性能比 TextureView 更有优势</strong>，支持对象的内容位置和包含的应用内容同步更新，平移、缩放不会产生黑边。<strong>在7.0以下系统如果使用场景有动画效果，可以选择性使用TextureView。</strong></li>
<li>由于失效(invalidation)和缓冲的特性，<strong>TextureView增加了额外1~3帧的延迟显示画面更新。</strong></li>
<li>TextureView总是使用GL合成，而SurfaceView可以使用硬件overlay后端，可以占用更少的内存。</li>
<li><strong>TextureView的内部缓冲队列导致比SurfaceView使用更多的内存。</strong></li>
<li>SurfaceView：内部自己持有surface，surface 创建、销毁、大小改变时系统来处理的，通过surfaceHolder的callback回调通知。</li>
<li>当画布创建好时，可以将Surface绑定到MediaPlayer中。SurfaceView如果为用户可见的时候，创建SurfaceView的SurfaceHolder用于显示视频流解析的帧图片，如果发现SurfaceView变为用户不可见的时候，则立即销毁SurfaceView的SurfaceHolder，以达到节约系统资源的目的。</li>
</ul>
<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://cloud.tencent.com/developer/article/1771629">https://cloud.tencent.com/developer/article/1771629</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>JavaScript-并发、并行、异步、同步的区别</title>
    <url>/6a74f0a0.html</url>
    <content><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>并发、并行、异步、同步，这些属于之间到底有什么区别和联系，本文来解开这个谜题~</p>
<img src="/6a74f0a0/1.png" class>

<hr>
<span id="more"></span>

<h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><p><strong>并发</strong>是一个比较宽泛的概念，它单纯代表计算机能够同时执行多项任务</p>
<img src="/6a74f0a0/2.png" class>

<p>至于计算机怎么做到“并发”则有许多不同的形式</p>
<img src="/6a74f0a0/3.png" class>

<p>比如对于一个单核处理器，计算机可以通过分配时间片的方式，让一个任务执行一段时间，然后切换到另外一个任务再运行一段时间。</p>
<p>不同的任务会这样交替往复的一直执行下去，这个过程也被称作是进程或者线程的上下文切换（context switching）</p>
<hr>
<h3 id="并行"><a href="#并行" class="headerlink" title="并行"></a>并行</h3><p>当然对于多核处理器，情况就有所不同了</p>
<img src="/6a74f0a0/4.png" class>

<p>我们可以在不同的核心上真正并行地执行任务，而不用通过分配时间片的方式运行，这种情况也就是我们所说的并行（parallelism）</p>
<hr>
<h3 id="同步-amp-异步"><a href="#同步-amp-异步" class="headerlink" title="同步&amp;异步"></a>同步&amp;异步</h3><p>至于同步和异步则是两种不同的编程模型。</p>
<p><strong>同步（Synchronous）</strong>代表需要等到必须前一个任务执行完毕之后，才能进行下一个任务</p>
<img src="/6a74f0a0/5.png" class>

<p>因此在同步中并没有并发或者并行的概念。</p>
<p>而<strong>异步（Asynchronous）</strong>则代表不同的任务之间并不会相互等待</p>
<img src="/6a74f0a0/6.png" class>

<p>也就是说，你在执行任务A的时候，也可以同时运行任务B</p>
<p>一个典型实现异步的方式则是通过多线程编程，你可以创建多个线程并且启动它们</p>
<img src="/6a74f0a0/7.png" class>

<p>在多核的环境下，每个线程就会被分配到独立的核心上运行，实现真正的“并行”</p>
<p>当然如果你使用的是多核心处理器，或者设置亲和力（Affinity）强制将线程绑定到某个核心上</p>
<img src="/6a74f0a0/8.png" class>

<p>操作系统则会通过分配时间片的方式来执行这些线程</p>
<img src="/6a74f0a0/9.png" class>

<p>不过这些线程依然是在“并发”地执行</p>
<p>当然像某些编程语言，比如JavaScript本身是没有多线程的概念。不过通过它的函数回调（function callback）机制，我们依然能够做到单线程的“并发”</p>
<img src="/6a74f0a0/10.png" class>

<p>比如你可以通过fetch()同时访问多个网络资源。我们在调用fetch()函数的时候，程序并不会等待，而会直接继续执行下去。当获取到网络资源后，回调函数才会被调起。</p>
<img src="/6a74f0a0/11.png" class>

<p>虽然主程序和回调函数看起来是同时进行的，但它们依然是运行在同一个线程中。因此通过这种异步编程方式，我们完全能够做到单线程的“并发”，而且这不是JavaScript的专利，很多语言也都提供了原生的异步编程方式，比如C#的async Task和await、Rust的async、C++20中的co_await、Python中的asyncio等等</p>
<hr>
<h3 id="多线程编程-amp-（单线程）异步编程"><a href="#多线程编程-amp-（单线程）异步编程" class="headerlink" title="多线程编程&amp;（单线程）异步编程"></a>多线程编程&amp;（单线程）异步编程</h3><p>那么多线程编程和这种单线程的异步编程，我们应当如何选择呢？</p>
<img src="/6a74f0a0/12.png" class>

<img src="/6a74f0a0/13.png" class>

<p>简而言之，对于I/O密集的应用程序，比如Web应用就会经常执行网络操作、数据库访问，这类应用就非常适合使用异步编程的方式。反之如果我们使用多线程的方式，则会浪费不少的系统资源，因为每个线程的绝大多数时间都是在等待这些I/O操作，而线程自身会占用额外的内存，线程的切换也会有额外的开销，更不用说线程之间的资源竞争问题。</p>
<img src="/6a74f0a0/14.png" class>

<p>而多线程编程则非常适合于计算量密集的应用，比如视频图像处理，科学计算等等，它能让每一个CPU核心发挥最大的功效，而不是消耗在空闲的等待上</p>
<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV17V411e7Ua">https://www.bilibili.com/video/BV17V411e7Ua</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐JavaScript</category>
      </categories>
  </entry>
  <entry>
    <title>加密算法-公钥加密算法RSA</title>
    <url>/837d52c.html</url>
    <content><![CDATA[<h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>一直到上个世纪的70年代，人们都还在使用对称加密算法，也就是说信息的收发方会通过事先商定好的密钥，对数据进行加密和解密。</p>
<img src="/837d52c/1.png" class>

<p>然而这种加密方式有诸多缺陷，随着网络规模的不断增大，每多一个用户就需要保存许多额外的密钥，密钥的管理也将逐渐成为所有人的负担。</p>
<img src="/837d52c/2.png" class>

<span id="more"></span>

<p>更加致命的是，密钥必须通过见面协商，而没有办法直接通过网络进行交换。因为密钥的传输过程需要进行加密，而没有密钥则不能进行加密。</p>
<img src="/837d52c/3.png" class>

<p>那有没有一种可能性，我们用不同的密钥对数据进行加密和解密。其中对数据加密的密钥是对所有人公开的，而对数据解密的密钥却仅为接收者持有呢？</p>
<img src="/837d52c/4.png" class>

<hr>
<h3 id="RSA简介"><a href="#RSA简介" class="headerlink" title="RSA简介"></a>RSA简介</h3><p>RSA公钥加密算法是1977年由Ron Rivest、Adi Shamirh和Len Adleman在美国麻省理工学院发现的。RSA取名来自开发他们三者的名字。</p>
<p>RSA是目前最有影响力的公钥加密算法，它能够抵抗到目前为止已知的所有密码攻击，已被ISO推荐为公钥数据加密标准。RSA算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但那时想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥。</p>
<img src="/837d52c/35.jpg" class>

<p>正是基于这种理论，1978年出现了著名的RSA算法，它通常是先生成一对RSA密钥，其中之一是保密密钥，由用户保存；另一个为公开密钥，可对外公开，甚至可在网络服务器中注册。为提高保密强度，RSA密钥至少为500位长，一般推荐使用1024位。这就使加密的计算量很大。为减少计算量，在传送信息时，常采用传统加密方法与公开密钥加密方法相结合的方式，即信息采用改进的DES或IDEA对话密钥加密，然后使用RSA密钥加密对话密钥和信息摘要。对方收到信息后，用不同的密钥解密并可核对信息摘要。</p>
<p>RSA算法是第一个能同时用于加密和数字签名的算法，也易于理解和操作。RSA是被研究得最广泛的公钥算法，从提出到现今的三十多年里，经历了各种攻击的考验，逐渐为人们接受，普遍认为是目前最优秀的公钥方案之一。</p>
<hr>
<h3 id="RSA原理"><a href="#RSA原理" class="headerlink" title="RSA原理"></a>RSA原理</h3><h4 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h4><p>RSA公开密钥密码体制的原理是：根据数论，寻求两个大素数比较简单，而将它们的乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥。</p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><p>RSA算法的具体描述如下：</p>
<ol>
<li><p>任意选取两个不同的大素数p和q计算乘积n = pq，φ(n) = (p-1)(q-1)</p>
</li>
<li><p>任意选取一个大整数e，满足gcd(e, φ(n)) = 1，整数e用做加密钥（注意：e的选取是很容易的，例如，所有大于p和q的素数都可用）</p>
</li>
<li><p>确定的解密钥d，满足(de) mod φ(n) = 1，即de = kφ(n) + 1, k &gt;= 1是一个任意的整数；所以，若知道e和φ(n)，则很容易计算出d</p>
</li>
<li><p>公开整数n和e，秘密保存d</p>
</li>
<li><p>将明文m（m&lt;n是一个整数）加密成密文c，加密算法为：c = E(m) = mᵉ mod n</p>
</li>
<li><p>将密文c解密为明文m，解密算法为：m = D(c) = cᵈ mod n</p>
</li>
</ol>
<p>然而只根据n和e（注意：不是p和q）要计算出d是不可能的。因此，任何人都可对明文进行加密，但只有授权用户（知道d）才可对密文解密。</p>
<hr>
<h4 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h4><p>RSA的安全性依赖于大数分解，但是否等同于大数分解一直未能得到理论上的证明，也并没有从理论上证明破译。RSA的难度与大数分解难度等价。因为没有证明破解RSA就一定需要做大数分解。假设存在一种无须分解大数的算法，那它肯定可以修改成为大数分解算法，即RSA的重大缺陷是无法从理论上把握它的保密性能如何，而且密码学界多数人士倾向于因子分解不是NPC问题。</p>
<p>目前，RSA的一些变种算法已被证明等价于大数分解。不管怎样，分解n是最显然的攻击方法。现在，人们已能分解140多个十进制位的大素数。因此，模数n必须选大些，视具体适用情况而定。</p>
<p>RSA算法的保密强度随其密钥的长度增加而增强。但是，密钥越长，其加解密所耗用的时间也越长。因此，要根据所保护信息的敏感程度与攻击者破解所要花费的代价值不值得以及系统所要求的反应时间来综合考虑，尤其对于商业信息领域更是如此。</p>
<hr>
<h4 id="运算速度"><a href="#运算速度" class="headerlink" title="运算速度"></a>运算速度</h4><p>由于进行的都是大数计算，使得RSA最快的情况也比DES慢上好几倍，无论是软件还是硬件实现。速度一直是RSA的缺陷。一般来说只用于少量数据加密。RSA的速度比对应同样安全级别的对称密码算法要慢1000倍左右。</p>
<hr>
<h4 id="算法攻击"><a href="#算法攻击" class="headerlink" title="算法攻击"></a>算法攻击</h4><p>迄今为止，对RSA的攻击已经很多，但都没有对它构成真正的威胁。在这里，我们讨论一些典型的攻击方法：</p>
<h5 id="RSA的选择密码攻击"><a href="#RSA的选择密码攻击" class="headerlink" title="RSA的选择密码攻击"></a>RSA的选择密码攻击</h5><p>RSA在选择密码攻击面前显得很脆弱。一般攻击者是将某一信息进行下伪装，让拥有私钥的实体签名；然后，经过计算就可得到它所想要的信息。实际上，攻击利用的都是同一个弱点，即存在这样一个事实：乘幂保留了输入的乘法结构。前面已经提到，这个固有的问题来自于公钥密码系统的最基本的特征，即每个人都能使用公钥加密信息。从算法上无法解决这一问题，改进措施有两条：是采用好的公钥协议保证工作过程中实体不对其他实体任意产生的信息解密，不对自己一无所知的信息签名；二是决不对陌生人送来的随机文档签名，或签名时首先对文档作Hash处理，或同时使用不同的签名算法。</p>
<h5 id="RSA的小指数攻击"><a href="#RSA的小指数攻击" class="headerlink" title="RSA的小指数攻击"></a>RSA的小指数攻击</h5><p>当公钥e取较小的值，虽然会使加密变得易于实现，速度有所提高，但这样做也是不安全的。最简单的办法就是e和d都取较大的值。</p>
<p>因为密钥的产生受素数产生技术的限制，所以也有它的局限性。<br>（1）密钥的产生受素数产生技术的限制，因而难以做到一次一密；<br>（2）分组长度太大，为保证安全性，n至少也要600比特以上，使运算代价很高，尤其是速度较慢，比对称密码算法慢几个数量级；随着大整数素因数分解算法的改进和计算机计算能力的提高，对n的长度在不断增加，不利于实现数据格式的标准化。</p>
<hr>
<h3 id="RSA详细解析"><a href="#RSA详细解析" class="headerlink" title="RSA详细解析"></a>RSA详细解析</h3><h4 id="单向函数：模运算"><a href="#单向函数：模运算" class="headerlink" title="单向函数：模运算"></a>单向函数：模运算</h4><p>在公钥加密算法中，由于公钥是对所有人公开的信息，我们需要保证数据被“公钥”加密之后，不能够被轻易地反推出来。</p>
<img src="/837d52c/5.png" class>

<p>那什么样的算法单向计算容易，而逆向反推却非常难呢？（这种关系被称为限门单向函数）</p>
<img src="/837d52c/6.png" class>

<p>其中一个答案是模运算。模运算又被叫作求余运算，像计算机中伪随机数、散列（hash）算法都是它的典型应用。</p>
<p>试想一下这个例子：3³ mod 7</p>
<p>要计算3的3次方对7取余数很容易，答案是6。</p>
<p>3ⁿ mod 7 = 6</p>
<p>但已知答案是6的情况下，我们又应当如何去寻找这里的n值呢？由于求余运算并不可逆，我们只能一个数一个数地代进去尝试，从0开始直到得到答案3。</p>
<p>但如果这里出现的是很大很大的数字，再去一一尝试就很不现实了：3ⁿ mod 98859834576182328468765894361723649832 = 6</p>
<img src="/837d52c/7.png" class>

<p>这也是为什么模运算被称作是单向函数，因为对于大数来说，对模运算求逆是根本不现实的。而公钥加密正是利用了模运算的这个特性。</p>
<hr>
<h4 id="模运算加密原理"><a href="#模运算加密原理" class="headerlink" title="模运算加密原理"></a>模运算加密原理</h4><p>假设我们将原始数据表示成一个数m（message）</p>
<img src="/837d52c/8.png" class>

<p>然后我们对它求e次幂，这里的e（encrypt）可以看作是我们加密时用的密钥</p>
<img src="/837d52c/9.png" class>

<p>然后我们将结果除以N并取余数，最后得到密文c（cipher）</p>
<img src="/837d52c/10.png" class>

<p>并且根据之前我们讲到的正向计算出这里的密文c很简单，但反向推出这里的原始数据却很难</p>
<img src="/837d52c/11.png" class>

<p>解密的过程与之非常类似，我们需要对密文c求d次幂，这里的d（decrypt）代表另外一个用于解密的密钥，最后得到的结果是解密后的原始数据m</p>
<img src="/837d52c/12.png" class>

<p>为了接下来理解的方便，我们将两个公式做一些变换</p>
<img src="/837d52c/13.png" class>

<p>再变换一下</p>
<img src="/837d52c/14.png" class>

<p>合并为一个更为简洁的形式：m的e*d次幂除以N取余数，将会得到原始数据m本身。</p>
<p>可以发现，如何选取这里的e和d便成了公钥加密中最关键的问题</p>
<p>为此我们就不得不提到欧拉在1763年的一个重要发现————欧拉定理（Euler’s Theorem）</p>
<hr>
<h4 id="欧拉定理"><a href="#欧拉定理" class="headerlink" title="欧拉定理"></a>欧拉定理</h4><img src="/837d52c/15.png" class>

<p>欧拉定理表示，对于任何一个与n互质的正整数m，取它φ(n)次方并除以n取余数，结果都永远等于1。</p>
<p>这里的φ(n)是欧拉函数，它代表在小于或等于n的正整数中，有多少个与n互质的数</p>
<img src="/837d52c/16.png" class>

<p>这样说可能有些抽象，我们来看一个例子：φ(6)</p>
<img src="/837d52c/17.png" class>

<p>我们会发现在小于等于6的正整数中，只有1、5和数字6除了1以外并不存在其它的公约数，所以φ(6)=2</p>
<p>在了解φ函数之后，我们回到欧拉定理，尝试对公式进行一些简单的变换，首先我们可以在等式两端同时取k次幂</p>
<img src="/837d52c/18.png" class>

<p>k在这里代表任意的正整数</p>
<img src="/837d52c/19.png" class>

<p>接着我们可以在两端同时乘以m</p>
<img src="/837d52c/20.png" class>

<p>化简后式子如下：</p>
<img src="/837d52c/21.png" class>

<p>最后我们将模运算写在等式的左边，如果我们将这个公式和之前讲到的加密解密公式对应起来</p>
<img src="/837d52c/22.png" class>

<p>我们会发现这里公式的指数部分是相同的，于是我们可以将d与e的关系表示成这种形式</p>
<img src="/837d52c/23.png" class>

<p>也就是说我们可以通过选取这里的k、n、e，来计算出解密的密钥d</p>
<p>这个公式看起来非常简单，但其实这里φ(n)的计算并没有想象中的那么容易，而φ(n)的计算也恰恰正是公钥加密中最关键的部分</p>
<p>实际上，要计算出φ(n)的唯一办法是对这个数n做质因数分解，而大数的质因数分解本身是非常困难的事情</p>
<img src="/837d52c/24.png" class>

<p>截至目前为止，用最前沿的分布式算法，花了大约2700个“CPU年”，才成功分解了一个829位的数字。因此对于大数来说，φ(n)的求解可以看作是计算上不可行的（computational infeasible）</p>
<p>但是，如果n本身就是一个质数，情况就有所不同了，比如对于质数7来说，小于等于7并与7互质的数有1~6，除了7本身，因此φ(7)=6</p>
<img src="/837d52c/25.png" class>

<p>同理对于质数13来说，与13互质的数除了13本身其它全部都是，因此φ(13)=12</p>
<img src="/837d52c/26.png" class>

<p>其实对于任何的质数p，我们可以推广到φ(p)等于这个质数p减去1：</p>
<img src="/837d52c/27.png" class>

<p>除此之外，φ函数还有一个重要的特性，对于任意两个互质的整数p和q，φ(p*q)可以直接拆分为φ(p)和φ(q)它们单独的乘积（欧拉函数是积性函数）</p>
<img src="/837d52c/28.png" class>

<p>例如，我们可以选取两个质数17和23，因此我们可以轻易求得φ(391)=352</p>
<img src="/837d52c/29.png" class>

<hr>
<h4 id="RSA加密解密"><a href="#RSA加密解密" class="headerlink" title="RSA加密解密"></a>RSA加密解密</h4><p>我们代入之前推导出的公式，然后选取一个较小的数e=3，这里我们需要保证它与φ(n)互质</p>
<img src="/837d52c/30.png" class>

<p>于是在k=5的情况下，求得用于解密的密钥d等于587</p>
<p>在求出了私钥d以后，我们将不再需要这里的p和q了，算法会将e和n公布，作为加密时用的公钥（public key），而d将保存下来作为解密时用的私钥（private key），其他人由于不知道p和q这两个关键的质因数，没有办法计算出这里的φ(n)，因而无从破译这里的私钥d</p>
<p>公钥加密正是利用了这个信息不对等，让加密者能够快速构造出一个φ(n)，而其他人却无法在有限的时间内求解它</p>
<p>接着我们用求得的e、d、n来模拟一段信息的加密解密过程，我们要加密的字符是“a”，它所对应的ascII编码是97，于是97的三次方除以391并取余数等于79，79是我们加密后的密文，为了解密，我们计算79的587次方除以391取余数，得到原始数据97，因此成功还原了字符“a”</p>
<img src="/837d52c/31.png" class>

<hr>
<h3 id="RSA的应用"><a href="#RSA的应用" class="headerlink" title="RSA的应用"></a>RSA的应用</h3><p>RSA是当今应用最为广泛的公钥加密算法，像数字签名、数字证书、SSH、HTTPS的加密连接，全部是它的典型应用</p>
<img src="/837d52c/32.png" class>

<p>在实际使用中，由于公钥加密的计算量大、速度慢，通常它会和对称加密算法一同使用</p>
<img src="/837d52c/33.png" class>

<p>公钥加密算法常被用作最初连接的建立，而真正数据传输的过程会交由对称加密算法来处理</p>
<img src="/837d52c/34.png" class>

<hr>
<h3 id="参考与鸣谢"><a href="#参考与鸣谢" class="headerlink" title="参考与鸣谢"></a>参考与鸣谢</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV14y4y1272w">https://www.bilibili.com/video/BV14y4y1272w</a><br><a href="https://baike.baidu.com/item/RSA%E7%AE%97%E6%B3%95/263310">https://baike.baidu.com/item/RSA%E7%AE%97%E6%B3%95/263310</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>学习报告-博睿康脑电设备的试用报告</title>
    <url>/8c7d5916.html</url>
    <content><![CDATA[<p>本篇学习报告主要介绍博睿康脑电设备的基本信息、使用方法、SSVEP范式和P300范式实验及相关注意事项。</p>
<span id="more"></span>

<h3 id="硬件设备介绍"><a href="#硬件设备介绍" class="headerlink" title="硬件设备介绍"></a>硬件设备介绍</h3><h4 id="智能同步中心"><a href="#智能同步中心" class="headerlink" title="智能同步中心"></a>智能同步中心</h4><img src="/8c7d5916/1.jpg" class>

<p>智能同步中心通过WI-FI将无线脑电放大器与电脑无线相连。首先连接智能同步中心的电源，待路由器的蓝灯亮起即代表路由器正常工作，之后再把Trigger Box分别连接电源和电脑，在电脑上连接名为NeusenW2-5G的WI-FI。</p>
<p>安放注意事项：</p>
<ul>
<li>尽量摆放在高处（远离地面）</li>
<li>不贴墙放置</li>
<li>不靠近大量金属物</li>
<li>不远离放大器</li>
</ul>
<h4 id="多参数同步器（Trigger-Box）"><a href="#多参数同步器（Trigger-Box）" class="headerlink" title="多参数同步器（Trigger Box）"></a>多参数同步器（Trigger Box）</h4><img src="/8c7d5916/2.jpg" class>

<p>连接示意图：</p>
<img src="/8c7d5916/3.png" class>

<img src="/8c7d5916/4.png" class>

<h4 id="无线脑电放大器"><a href="#无线脑电放大器" class="headerlink" title="无线脑电放大器"></a>无线脑电放大器</h4><img src="/8c7d5916/5.jpg" class>

<hr>
<h3 id="SSVEP程序说明"><a href="#SSVEP程序说明" class="headerlink" title="SSVEP程序说明"></a>SSVEP程序说明</h3><h4 id="连接设备"><a href="#连接设备" class="headerlink" title="连接设备"></a>连接设备</h4><ol>
<li>组装智能同步中心并连接好电源。</li>
<li>选择相应的WIFI，连接电脑与智能同步中心。</li>
</ol>
<table>
<thead>
<tr>
<th>WiFi</th>
<th>账号</th>
<th>密码</th>
</tr>
</thead>
<tbody><tr>
<td>2.4G</td>
<td>Dolphin001</td>
<td>Neuracle0519</td>
</tr>
<tr>
<td>5G(推荐)</td>
<td>NeusenW2-5G</td>
<td>neuracle0519</td>
</tr>
</tbody></table>
<ol start="3">
<li>连接多参数同步器（Trigger Box）并打开电源，静待网络指示灯长亮，连接相应的trigger线。</li>
<li>放大器装载电池，固定至脑电帽，长按至设备震动、电源指示灯亮起，静待网络指示灯亮起。</li>
<li>将脑电帽正确佩戴在受试者头部。</li>
</ol>
<h4 id="启动Recorder界面"><a href="#启动Recorder界面" class="headerlink" title="启动Recorder界面"></a>启动Recorder界面</h4><ol>
<li><p>搜索设备</p>
 <img src="/8c7d5916/6.jpg" class>


</li>
</ol>
<ol start="2">
<li><p>同步设备</p>
 <img src="/8c7d5916/7.jpg" class>
</li>
<li><p>设置转发通道</p>
 <img src="/8c7d5916/8.jpg" class>

<p> 将新建的导联组从左侧移入右侧中并保存</p>
 <img src="/8c7d5916/26.png" class>
</li>
<li><p>设置受试者</p>
 <img src="/8c7d5916/27.png" class>
</li>
<li><p>选择受试者，进入Recorder界面</p>
 <img src="/8c7d5916/28.png" class>

 <img src="/8c7d5916/29.png" class>

 <img src="/8c7d5916/30.png" class>

<p> 完成后则会直接进入Recorder界面</p>
 <img src="/8c7d5916/31.png" class>
</li>
<li><p>数据转发</p>
 <img src="/8c7d5916/9.jpg" class>

</li>
</ol>
<h4 id="启动SSVEP程序"><a href="#启动SSVEP程序" class="headerlink" title="启动SSVEP程序"></a>启动SSVEP程序</h4><p>SSVEP由刺激器（Stimulator）和处理器（Onlineprocessor）两部分组成，启动顺序为：</p>
<img src="/8c7d5916/10.png" class>

<ol>
<li><p>点击LoadConfig准备接收处理器的参数</p>
</li>
<li><p>点击SetParams发送在OnlineProcessor处理器已经设置好的参数，触发Connection</p>
</li>
<li><p>连接 DataServer 数据接收、Stimulator刺激反馈和Output外部设备(按需勾选）</p>
</li>
<li><p>点击 Start 开始运行：算法右边会显示F（目标对应的频率）、T（目标）和R（阈值）的结果并实时刷新</p>
</li>
<li><p>点击Run运行刺激器，按空格键启动SSVEP刺激界面（空格键可以控制刺激开始和暂停）</p>
 <img src="/8c7d5916/11.jpg" class>

</li>
</ol>
<hr>
<h3 id="P300程序说明"><a href="#P300程序说明" class="headerlink" title="P300程序说明"></a>P300程序说明</h3><p>P300程序配合脑电信号采集系统使用，可以达到脑电数据的在线分析处理。同时程序拥有训练模式构造被试的训练模型，很大程度上排除了个体差异，具有针对性。且P300程序必须进行训练，加载训练数据。程序主要分为两部分，一个是刺激器，一个是处理器。包含两种模式：<strong>训练模式</strong>和<strong>实验模式</strong>。</p>
<h4 id="训练模式"><a href="#训练模式" class="headerlink" title="训练模式"></a>训练模式</h4><ol>
<li><p>启动脑电信号采集软件，脑电帽和放大器吸合完好，多参同步盒连接正确，搜索设备并添加；</p>
</li>
<li><p>开启脑电采集软件的数据转发端口，选择转发P300的Montage，并记录数据；</p>
</li>
<li><p>启动P300程序的刺激器和处理器；</p>
</li>
</ol>
<p>刺激界面：</p>
<img src="/8c7d5916/12.png" class>

<p>处理器界面：</p>
<img src="/8c7d5916/13.png" class>

<ol start="4">
<li><p>在处理器界面配置刺激参数，主要是设置刺激的模式，FD为整行整列的刺激闪烁，SD为单个刺激闪烁。Trigge是选择打trigger的模式；</p>
</li>
<li><p>勾选训练模式Training，点击刺激器界面的加载配置按钮LoadConfig，在3s内快速点击处理器界面的设置参数按钮Set Params，出现一个提示框，点击OK即可；</p>
</li>
<li><p>点击加载训练数据按钮Load TrainData，在跳出的窗口选择录制好的训练数据，等待数据加载完成；</p>
</li>
<li><p>点击DataServer的Connect按钮，连接脑电信号采集软件的数据。点击Stimulator的Connect按钮，连接刺激器；</p>
</li>
<li><p>点击处理器界面的Start按钮，之后点击刺激器界面的Run按钮，刺激界面出现，实验模式开始。</p>
</li>
</ol>
<hr>
<h3 id="打标代码说明"><a href="#打标代码说明" class="headerlink" title="打标代码说明"></a>打标代码说明</h3><h4 id="打标连接"><a href="#打标连接" class="headerlink" title="打标连接"></a>打标连接</h4><p>安装串口软件</p>
<img src="/8c7d5916/33.png" class>

<p>需要使用电脑USB-A口与同步器的micro-USB相连。</p>
<img src="/8c7d5916/32.jpg" class>

<p>（前提，需要把设备连接好，不连接，是不会有的）<br>查看电脑与同步器相连的串口号：此电脑（右键）-&gt;属性-&gt;设备管理器-&gt;端口，一般为COM3、COM4等COM加上一个数字</p>
<img src="/8c7d5916/34.png" class>

<p>导入打标的py库，填写好打标的串口号，运行该行代码即可在采集脑电过程中插入打标信息（脑电信息与打标信息各自单独文件）</p>
<img src="/8c7d5916/35.png" class>

<hr>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li>电刺激的保存方法：电刺激的电极不能接触其他任何金属，正确的保存方式是：用水清洗、擦干、晾干、单独放入塑料包装袋、放入设备箱保存。注意 triggerbox、充电器插头，线缆接头等设备部分的金属也不能接触。</li>
<li>屏幕分辨率只能设为 60Hz，144Hz 则会屏幕报错。</li>
<li>程序中 triggerbox 为 false，但 triggerbox 的 USB 线需要接好。</li>
<li>处理器中，刺激模式选择默认的 FD 模式，程序中写的 SD 模式。</li>
</ul>
<hr>
<h3 id="完整实验流程演示（以P300为例）"><a href="#完整实验流程演示（以P300为例）" class="headerlink" title="完整实验流程演示（以P300为例）"></a>完整实验流程演示（以P300为例）</h3><h4 id="按上述二、三的要求连接好设备"><a href="#按上述二、三的要求连接好设备" class="headerlink" title="按上述二、三的要求连接好设备"></a>按上述二、三的要求连接好设备</h4><h4 id="受试者正确佩戴脑电帽并打入医用导电膏降低阻抗"><a href="#受试者正确佩戴脑电帽并打入医用导电膏降低阻抗" class="headerlink" title="受试者正确佩戴脑电帽并打入医用导电膏降低阻抗"></a>受试者正确佩戴脑电帽并打入医用导电膏降低阻抗</h4><p>受试者佩戴好脑电帽，在相应的电极上（在界面左侧有标记出<strong>P300</strong>需要的电极）打入适量的医用导电膏（稍稍溢出即可），打开<strong>Impedance</strong>界面可以查看阻抗的大小，对着此界面调整导电膏的量，以减小阻抗。</p>
<img src="/8c7d5916/14.jpg" class>

<h4 id="记录数据并设置数据转发"><a href="#记录数据并设置数据转发" class="headerlink" title="记录数据并设置数据转发"></a>记录数据并设置数据转发</h4><ol>
<li><p>开始记录数据：</p>
 <img src="/8c7d5916/15.jpg" class>
</li>
<li><p>设置数据转发：</p>
 <img src="/8c7d5916/16.jpg" class>

</li>
</ol>
<h4 id="运行Matlab程序"><a href="#运行Matlab程序" class="headerlink" title="运行Matlab程序"></a>运行Matlab程序</h4><ol>
<li><p>打开并运行P300Stimulator.m：</p>
 <img src="/8c7d5916/17.jpg" class>
</li>
<li><p>打开并运行OnlinProcessor.m：</p>
 <img src="/8c7d5916/18.jpg" class>

</li>
</ol>
<h4 id="训练模式-1"><a href="#训练模式-1" class="headerlink" title="训练模式"></a>训练模式</h4><p>按照下图设置好后即可开始训练模式：</p>
<img src="/8c7d5916/19.jpg" class>

<h4 id="实验模式"><a href="#实验模式" class="headerlink" title="实验模式"></a>实验模式</h4><p>按照下图设置好后即可开始实验模式：</p>
<img src="/8c7d5916/20.jpg" class>

<h4 id="“Load-TrainData”的特别说明"><a href="#“Load-TrainData”的特别说明" class="headerlink" title="“Load TrainData”的特别说明"></a>“Load TrainData”的特别说明</h4><ul>
<li><p>查找脑电数据记录存放路径</p>
  <img src="/8c7d5916/21.jpg" class>
  <img src="/8c7d5916/22.jpg" class>
  <img src="/8c7d5916/23.jpg" class>
</li>
<li><p>点击“Load TrainData”按钮后，选中两个BDF文件</p>
  <img src="/8c7d5916/24.jpg" class>

<p>  设置完成后，进入实验模式：</p>
  <img src="/8c7d5916/25.jpg" class>

</li>
</ul>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10730&amp;teamId=1158">https://www.scholat.com/teamwork/showPostMessage.html?id=10730&amp;teamId=1158</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫知识分享</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-如何读论文①</title>
    <url>/31ec5d1c.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=975879338&bvid=BV1H44y1t75x&cid=423711758&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<h3 id="论文的结构"><a href="#论文的结构" class="headerlink" title="论文的结构"></a>论文的结构</h3><ol>
<li><p>title（标题，然后还有作者）</p>
</li>
<li><p>abstract（摘要）</p>
</li>
<li><p>introduction（导言）</p>
</li>
<li><p>method（提出的算法）</p>
</li>
<li><p>experience（实验）</p>
</li>
<li><p>conclusion（结论）</p>
</li>
</ol>
<hr>
<h3 id="读论文三部曲"><a href="#读论文三部曲" class="headerlink" title="读论文三部曲"></a>读论文三部曲</h3><h4 id="pass-1（粗读）"><a href="#pass-1（粗读）" class="headerlink" title="pass 1（粗读）"></a>pass 1（粗读）</h4><ul>
<li><p>关注标题和摘要</p>
<p>  看一下title是否跟我研究领域相关，看摘要知晓文章在做什么</p>
</li>
<li><p>直接跳到结论</p>
<p>  结论通常跟摘要是一样的，但是摘要里可能提出了一两个问题，会在此处用一些实际的数字与结论证明一下</p>
</li>
</ul>
<p>读完这三个部分，通常这一次用十几分钟的时间，大概就知道这篇论文是在讲什么东西（可以瞄一眼图和表，以及看看用了什么方法）</p>
<p><strong>pass 1</strong> 目的：文章讲什么、质量怎么样、结果怎么样、方法怎么样、是不是适合自己的，决定说要不要再继续深读下去</p>
<hr>
<h4 id="pass-2（细读）"><a href="#pass-2（细读）" class="headerlink" title="pass 2（细读）"></a>pass 2（细读）</h4><ul>
<li>对文章每个模块过一遍<ul>
<li>沿着标题一直往下读到最后，知道每一块到底在干什么。也不用太注意很多细节，比如一些公式、证明、很细节的部分等等。</li>
<li>重要的是，要搞清楚重要的图和表，知道它每一个字在干什么事情，比如方法里面的流程图、算法里的图、实验里每张图的x轴y轴每一个点的含义、作者的方法和别人的方法是怎么对比的和差距有多大。</li>
<li>通读后可能还没完全搞懂，可以把细节留到最后精读。</li>
<li>觉得太难了也可以读一读相关文献里之前引用的研究工作。</li>
</ul>
</li>
</ul>
<p><strong>pass 2</strong> 目的：对文章的各个部分有大概了解、可以把引用的相关文献圈出来，决定说要不要往下精读</p>
<hr>
<h4 id="pass-3（精读与拓展）"><a href="#pass-3（精读与拓展）" class="headerlink" title="pass 3（精读与拓展）"></a>pass 3（精读与拓展）</h4><ul>
<li><p>了解每一句话干什么</p>
<p>  可以想象在读这篇文章的时候，脑子里不断地重复实现这篇文章，或者说如果是我来做的话会用什么方法</p>
</li>
</ul>
<p><strong>pass 3</strong> 目的：知道每一句在干什么、脑补一下整个过程使得好像是自己做了一遍、也可以进行实验复刻</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1H44y1t75x">https://www.bilibili.com/video/BV1H44y1t75x</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫方法技巧</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-AlexNet论文精读-《ImageNet Classification with Deep Convolutional Neural Networks》</title>
    <url>/de804d7a.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2012-ImageNet-Classification-with-Deep-Convolutional.pdf" data-height="500px"></div>

<hr>
<span id="more"></span>

<h3 id="深度学习奠基作之一：AlexNet"><a href="#深度学习奠基作之一：AlexNet" class="headerlink" title="深度学习奠基作之一：AlexNet"></a>深度学习奠基作之一：AlexNet</h3><h4 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h4><p><strong>标题：</strong>ImageNet Classification with Deep Convolutional Neural Networks<br><strong>时间：</strong>2012<br><strong>出版源：</strong>Neural Information Processing Systems (NIPS)<br><strong>论文领域：</strong>深度学习，计算机视觉<br><strong>论文链接：</strong><a href="https://dl.acm.org/doi/10.1145/3065386">https://dl.acm.org/doi/10.1145/3065386</a><br><strong>引用格式：</strong>Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.</p>
<h4 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h4><ul>
<li><strong>数据集：</strong>出现imageNet这样的大数据集，可以用来训练更复杂的模型 。</li>
<li><strong>CNN：</strong>而CNNs它们的能力可以通过改变深度和广度来控制，它们还对图像的本质（即统计的平稳性和像素依赖性的局部性）做出了强有力且基本正确的假设。与具有类似大小层的标准前馈神经网络相比，CNNs具有更少的连接和参数，因此更容易训练，而其理论上最好的性能可能只会稍微差一些。</li>
<li><strong>GPU：</strong>GPU和卷积操作结合，使得训练大型CNN网络成为可能</li>
</ul>
<h4 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h4><h5 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h5><ul>
<li>对ImageNet的子集进行了迄今为止最大的卷积神经网络训练，并取得了最好效果</li>
<li>高度优化GPU实现2D卷积方法，后面提到网络在2块GPU并行</li>
<li>网络包含很多新的不寻常特征</li>
<li>防止过拟合</li>
</ul>
<h5 id="ReLU激活函数"><a href="#ReLU激活函数" class="headerlink" title="ReLU激活函数"></a>ReLU激活函数</h5><p>使用ReLUs的四层卷积神经网络在CIFAR-10上达到25%的训练错误率，比使用tanh神经元的同等网络快六倍。每个网络的学习率都是独立选择的，以使训练尽可能快。没有任何形式的正规化。这里演示的效果的大小随网络结构的不同而不同，但是使用ReLUs的网络始终比使用饱和神经元的网络学习速度快几倍。</p>
<h5 id="Local-Response-Normalization-局部响应归一化（没啥用）"><a href="#Local-Response-Normalization-局部响应归一化（没啥用）" class="headerlink" title="Local Response Normalization 局部响应归一化（没啥用）"></a>Local Response Normalization 局部响应归一化（没啥用）</h5><img src="/de804d7a/28.png" class>

<p>此方案有助于泛化，CNN在未归一化的情况下，测试错误率为13%;在归一化的情况下，测试错误率为11%。</p>
<p>大致意思就是当今kernel的map的(x, y)像素位置在周围邻居相同kernel的map的(x, y)像素。然后把这些邻居pixel的值平方再加和。乘以一个系数 α 再加上一个常数k, 然后 β 次幂就是分母，分子就是kernel对应的map的(x, y)位置的pixel值。关键是参数 α, β, k如何确定, 论文中说在验证集中确定, 最终确定的结果为: k = 2, n = 5, α = 0.0001, β = 0.75</p>
<h5 id="Overlapping-Pooling-重叠池化"><a href="#Overlapping-Pooling-重叠池化" class="headerlink" title="Overlapping Pooling 重叠池化"></a>Overlapping Pooling 重叠池化</h5><p>初步理解：假如池化单元为zxz</p>
<ul>
<li>步长s = z，就是传统的池化</li>
<li>步长s &lt; z，就是重叠池化</li>
</ul>
<p>作者提到当s = 2, z = 3时，对比s = z = 2，错误率减少了0.4%(top-1) 和 0.3%(top-5)<strong>（使用重叠池化可以减少过拟合）</strong></p>
<h5 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h5><img src="/de804d7a/29.png" class>

<p>一共8层，前5层是卷积层，后3层是全连接层：</p>
<ul>
<li>卷积层除了第3层，其余卷积层直接连接在同GPU上。第3层会连接第2层所有输出。</li>
<li>局部响应规范化（Local Response Normalization）层在第1层和第2层卷积层后。</li>
<li>最大池化层在响应规范化层（第1层和第2层卷积）和第5层卷积后。</li>
<li>ReLU非线性激活函数应用在每个卷积和全连接层。</li>
</ul>
<img src="/de804d7a/30.png" class>

<hr>
<h3 id="pass-1"><a href="#pass-1" class="headerlink" title="pass 1"></a>pass 1</h3><h4 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h4><p>首先是论文标题，论文标题：ImageNet Classification with Deep Convolutional Neural Networks，中文意思是：使用深度卷积神经网络对ImageNet数据集进行分类。</p>
<p>第一次读论文标题时要注意下面几个关键词：</p>
<ul>
<li>ImageNet：论文使用的数据集是ImageNet，ImageNet数据集具体内容是什么样的？</li>
<li>Neural Networks ：神经网络，这篇文章使用了神经网络技术。</li>
<li>Deep Convolutional：卷积神经网络工作原理是什么? 同时作者为什么要使用深度的卷积神经网络。</li>
</ul>
<p>下面是论文的作者，论文一作是Alex，这也是本篇论文提出的网络被称为AlexNet的原因。可能对论文前两个作者不是很熟悉，但是论文通信作者是Hinton，长期研究神经网络和深度学习。</p>
<img src="/de804d7a/31.png" class>

<h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>首先我们先读一读摘要：</p>
<img src="/de804d7a/1.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>摘要</strong></p>
<p><strong>我们训练了一个大型深度卷积神经网络来将ImageNet LSVRC-2010竞赛的120万高分辨率的图像分到1000不同的类别中。在测试数据上，我们得到了top-1 37.5%和top-5 17.0%的错误率，这个结果比目前的最好结果好很多。这个神经网络有6000万参数和65万个神经元，包含5个卷积层（某些卷积层后面带有池化层）和3个全连接层，最后是一个1000维的softmax。为了训练的更快，我们使用了非饱和神经元，并在进行卷积操作时使用了非常有效的GPU。为了减少全连接层的过拟合，我们采用了一个最近开发的名为dropout的正则化方法，结果证明是非常有效的。我们也使用这个模型的一个变种参加了ILSVRC-2012竞赛，赢得了冠军并且与第二名top-5 26.2%的错误率相比，我们取得了top-5 15.3%的错误率。</strong></p>
<ul>
<li>前2句话介绍了自己做的工作，训练了一个很大很深的卷积神经网络在LSVRC-2010 contest取得了很好的结果。</li>
<li>第3句话介绍了网络的模型，有6000万个参数和65万个神经元，模型包含5个卷积层，以及最大池化层和3个全连接层。</li>
<li>第4句和第5句介绍了如何训练网络，使用了不饱和的神经元和GPU实现，为了减少全连接层的过拟合，使用了dropout技术。</li>
<li>最后一句， 介绍在ILSVRC-2012比赛取得了第一名，错误率比第二名低了10.9%，可以看到本文设计的网络模型效果很好。</li>
</ul>
<p>很少有人会在第一句话写我做了什么、第二句话写我做得很好，这种写法十分少见。然后他说这个神经网络有6千万个参数和65万个神经元，在当时可能还不知道什么是神经元，但对比起SVM、线性模型等参数量还是很大的。接着他说神经网络有五层，一层max-pooling、三层全连接层、最后一层softmax，在当时第一次读应该也不清楚在干什么事情。之后他说为了加快训练使用了GPU，从2007年出了CUDA库之后，在2012年GPU的使用已经比较常见了，那时候机器学习用的大部分都是matlab的gpu加速包。另外，为了减少过拟合，也用了一个dropout的方法。最后说这个模型在刷榜比赛上比第二名领先很多。这里最后说的15.3%和前面的17.0%第一眼看起来有点奇怪，但我们最后再来看看这是怎么回事。</p>
<p>这个不算是一个很好的摘要，更像是一个技术报告，但结果在这里比别人好很多，有一定吸引力。</p>
<hr>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><img src="/de804d7a/2.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>我们的结果表明一个大型深度卷积神经网络在一个具有高度挑战性的数据集上使用纯有监督学习可以取得破纪录的结果。值得注意的是，如果移除任何一个卷积层，我们的网络性能会降低。例如，移除任何中间层都会引起网络损失大约2%的top-1性能。因此深度对于实现我们的结果非常重要。</strong></p>
<p><strong>为了简化我们的实验，我们没有使用任何无监督的预训练，尽管我们希望它会有所帮助，特别是在如果我们能获得足够的计算能力来显著增加网络的大小而标注的数据量没有对应增加的情况下。到目前为止，我们的结果已经提高了，因为我们的网络更大、训练时间更长，但为了匹配人类视觉系统的下颞线（视觉专业术语）我们仍然有许多数量级要达到。最后我们想在视频序列上使用非常大的深度卷积网络，视频序列的时序结构会提供非常有帮助的信息，这些信息在静态图像上是缺失的或远不那么明显。</strong></p>
<p>这篇文章是没有结论的，而是一个讨论。讨论更多是吐吐槽、看看未来要干什么事情，结论很多时候是跟摘要的一一对应，所以说没有结论通常是比较少见的。</p>
<p>虽然第一段的结论说“深度是重要的”，并没有错，但不能因为移除一层网络就下降2个点就说明是深度影响了，也有可能是参数没设好、参数变少了等原因。但在现在的观点看来确实没什么问题，深度固然很重要，但宽度也很重要。不能说特别深特别窄，也不能说特别扁特别宽，就像拍照一样高宽比是很重要的。</p>
<p>训练神经网络的时候，可以先预训练一下，把参数大致调整一下再进行精细训练，因为深度神经网络在当时训练是很不容易的，所以很多时候会先用一些未标号的预热。但本文说我们没有先预训练，是针对与标注数据进行专一训练（监督学习），而不是说通过一个大网络得到一个万能通用的对未标注数据的解法（无监督学习）。所以说AlexNet也是引领了监督学习的一个浪潮，不过从GAN开始大家的目光又慢慢回到无监督学习。</p>
<p>论文讨论有两段，第一段说我们在有监督学习上取得了很好的效果，证明了网络的深度很重要。第二段说我们没有使用任何的无监督预训练，这直接导致了后面的深度学习研究都集中在有监督学习上；同时作者提出未来会研究视频数据（当前研究的一个很火方向），因为视频数据会提供时序信息，这是静态图像数据所缺失的。</p>
<p>文章也是说了如果模型、计算量更大的情况下还能更好，虽然跟人类比还是有差距，但在现在看来，深度学习已经比人类好很多了，开开车大概也不是问题了。最后也提出了说如果算力更好的话也想对视频这种时序性强的数据进行训练，但在现在看来，过去了这么多年训练video数据仍是很难的事情。虽然我们在图片上做了很多事情、在自然语言上做了很多事情，但视频数据走的路还是比较慢，因为数据量增加的不是一点点，而且大部分还是有版权的。</p>
<hr>
<h4 id="图和表"><a href="#图和表" class="headerlink" title="图和表"></a>图和表</h4><img src="/de804d7a/3.png" class>

<p>左边的图我们看到分类还是很准确的，而且比如第4个leopard豹子的第二预测jaguar美洲豹也是很接近的一个类别。但第7个dalmatian斑点狗和cherry樱桃同时在图里还是容易出错。第8个madagascar cat一般人也认不出来，也看得出深度学习中监督学习的优点。</p>
<p>右边的图比较有意思，他是把神经网络倒数第二层的图片拿出来，得到一个长的向量，根据余弦相似度得到相近的图片组，发现都很像。虽然论文没有讨论到这个东西有多重要，但实际上可能这才是最重要的结果。就是说深度神经网络最后训练出来的向量在语义空间里的表示特别好，相似的图片会把它放在一起，是一个非常好的特征，非常适合用之后机器学习的简单的分类器来分类，这也是深度学习的一大强项。</p>
<hr>
<img src="/de804d7a/4.png" class>

<p>这个表是本文的结果和别人的结果进行对比。前两个是那时候最好的在Top-1和Top-5上的结果，但可以看到本文的结果好很多。</p>
<hr>
<h4 id="pass-1-总结"><a href="#pass-1-总结" class="headerlink" title="pass 1 总结"></a>pass 1 总结</h4><p>第一遍读完大概知道这篇文章用深度学习的方法，效果特别好。具体为什么好、怎么做的还不清楚，之后再细读。</p>
<hr>
<h3 id="pass-2"><a href="#pass-2" class="headerlink" title="pass 2"></a>pass 2</h3><p>第二遍开始细读，对文章正文内容开始阅读。</p>
<h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><img src="/de804d7a/5.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>1 引言</strong></p>
<p><strong>当前的目标识别方法基本上都使用了机器学习方法。为了提高目标识别的性能，我们必须收集更大的数据集，学习更强大的模型，使用更好的技术来防止过拟合。直到最近，标注图像的数据集都相对较小——都在几万张图像的数量级上（例如，NORB[16]，Caltech-101/256 [8, 9]和CIFAR-10/100 [12]）。简单的识别任务在这样大小的数据集上可以被解决的相当好，尤其是如果通过标签保留变换进行数据增强的情况下。例如，目前在MNIST数字识别任务上（&lt;0.3%）的最好准确率已经接近了人类水平[4]。但真实环境中的对象表现出了相当大的可变性，因此为了学习识别它们，有必要使用更大的训练数据集。实际上，小图像数据集的缺点已经被广泛认识到（例如，Pinto et al. [21]），但收集上百万图像的标注数据仅在最近才变得的可能。新的更大的数据集包括LabelMe [23]，它包含了数十万张完全分割的图像，以及包含了22000个类别上的超过1500万张标注的高分辨率的图像ImageNet[6]。</strong></p>
<p>大数据集、大模型、更好的技术来防止过拟合，这基本是机器学习正常的途径。当时深度学习界认为，大模型+正则来防止过拟合，并且在之后几年内大家也是这么做的。但现在观点来看，好像正则又不是很重要，关键是整个神经网络的设计，使得很大的神经网络在没有很好的正则情况下也能训练的很好。这部分的理论和实践工作还在推进，坐等以后新的结论。后面吹了一下它这个ImageNet特别好，毕竟题目就说了本文用的是ImageNet，吹一下它数据量大、类别多。</p>
<hr>
<img src="/de804d7a/6.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>为了从数百万张图像中学习几千个对象，我们需要一个有很强学习能力的模型。然而对象识别任务的巨大复杂性意味着这个问题不能被特定化，即使通过像ImageNet这样足够大的数据集，因此我们的模型应该也有许多先验知识来补偿我们所没有的数据。卷积神经网络(CNNs)构成了一类这样的模型[16, 11, 13, 18, 15, 22, 26]。它们的容量可以通过改变它们的深度和广度来控制，它们也可以对图像的本质进行强大且通常正确的假设（也就是说，统计的稳定性和像素依赖的局部性）。因此，与具有层次大小相似的标准前馈神经网络相比，CNNs有更少的连接和参数，因此它们更容易训练，而它们理论上的最佳性能可能仅比标准前馈神经网络稍微差一点。</strong></p>
<p>说完需要很大的模型，然后就直接讲CNN了，讲怎么把CNN做的特别大，所以这段的意思是大家应该用CNN来做，因为CNN是一个很好的模型。但是CNN做大不容易，因为做大很容易overfitting或者训练不动，但当时主流不用CNN，文章却没有提及其它模型和别人的算法，只提到CNN会显得视角比较狭窄，这个不能学。不能只提到自己的小领域，也要跟他人作对比。</p>
<hr>
<img src="/de804d7a/7.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>尽管CNN具有引人注目的质量，尽管它们的局部架构相对有效，但是将它们应用到大规模的高分辨率图像中仍然是极其昂贵的。幸运的是，目前的GPU，搭配了高度优化的2D卷积实现，强大到足够促进有趣大量CNN的训练，以及最近的数据集例如ImageNet包含足够多的标注样本来训练这样的模型而没有严重的过拟合。</strong></p>
<p>第三段讲用GPU训练CNN，并且数据集ImageNet够大没有过拟合。所以前三段大概就是讲了个故事，讲做了什么东西。</p>
<hr>
<img src="/de804d7a/8.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>本文具体的贡献如下：我们在ILSVRC-2010和ILSVRC-2012[2]的ImageNet子集上训练了到目前为止最大的神经网络之一，并取得了迄今为止在这些数据集上报道过的最好结果。我们编写了高度优化的2D卷积GPU实现以及训练卷积神经网络固有的所有其它操作，我们把它公开了。我们的网络包含许多新的不寻常的特性，这些特性提高了神经网络的性能并减少了训练时间，详见第三节。即使使用了120万标注的训练样本，我们的网络尺寸仍然使过拟合成为一个明显的问题，因此我们使用了一些有效的技术来防止过拟合，详见第四节。我们最终的网络包含5个卷积层和3个全连接层，深度似乎是非常重要的：我们发现移除任何卷积层（每个卷积层包含的参数不超过模型参数的1%）都会导致更差的性能。</strong></p>
<p>第四段讲的是作者这个paper的贡献。作者训练了当时为止最大的神经网络并且取得了特别好的成果，然后在GPU上实现了一个2D的卷积，网络也有新的特性，能够提升性能和降低训练时间，然后说第三节细说。第四节细说怎么防止这个大网络过拟合。最后说网络有5个卷积层、3个全连接层，发现深度好像很重要。</p>
<p>如果说在Imagenet上取得了特别好的结果，但只是把100个模型融合起来拿了个第一名，这就没什么意思了。就是说，在模型上没有太多创新，更多的是一些工程上、技术上的创新，这种论文大家就不太爱看。但本文说用了一些unusual features、新的技术来防止过拟合，新的技术是比较有意思的，如果用新技术又取得了较好的成果，大家更愿意往下去做、去钻研这个方向，更有启发性一点。</p>
<p>太大、太复杂、不容易复现，这样的模型对以后的研究工作不是很有用，作为研究工作者更希望看到新的思路、新的能够取得好效果的方向。（或许内涵GPT-3 or yolov4的叠buff操作）</p>
<p>反过来讲，本文如果只是取得了好的成果，没有什么新东西，也就不会成为奠基作了。</p>
<hr>
<img src="/de804d7a/9.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>最后，网络尺寸主要受限于目前GPU的内存容量和我们能忍受的训练时间。我们的网络在两个GTX 580 3GB GPU上训练五六天。我们的所有实验表明我们的结果可以简单地通过等待更快的GPU和更大的可用数据集来提高。</strong></p>
<p>这一段介绍了一下设备。存下来的很多都是一些研究型的东西，少是工程性的细节，后面大家各种文章去更好的实现也没有这篇奠基石的开创性更重要。工程工作的本质还是脑力层面的体力劳动。</p>
<hr>
<h4 id="The-Dataset"><a href="#The-Dataset" class="headerlink" title="The Dataset"></a>The Dataset</h4><img src="/de804d7a/10.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>2 数据集</strong></p>
<p><strong>ImageNet数据集有超过1500万的标注高分辨率图像，这些图像属于大约22000个类别。这些图像是从网上收集的，使用了亚马逊（Amazon）的Mechanical Turk的众包工具通过人工标注的。从2010年起，作为Pascal视觉对象挑战赛的一部分，每年都会举办ImageNet大规模视觉识别挑战赛（ILSVRC）。ILSVRC使用ImageNet的一个子集，1000个类别每个类别大约1000张图像。总计，大约120万训练图像，50000张验证图像和15万测试图像。</strong></p>
<p><strong>ILSVRC-2010是ILSVRC竞赛中唯一可以获得测试集标签的版本，因此我们大多数实验都是在这个版本上运行的。由于我们也使用我们的模型参加了ILSVRC-2012竞赛，因此在第六节我们也报告了模型在这个版本的数据集上的结果，这个版本的测试标签是不可获得的。在ImageNet上，按照惯例报告两个错误率：top-1和top-5，top-5错误率是指测试图像的正确标签不在模型认为的五个最可能的便签之中的分数。</strong></p>
<p>这两段话介绍了一下数据集，ImageNet很大、类别很多有22000类。这个模型参加过几次比赛，ILSVRC-2010有测试集所以看得出错误率，ILSVRC-2012就没有提供数据集，简单讲了一下摘要里那些错误率怎么来的。</p>
<hr>
<img src="/de804d7a/11.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>ImageNet包含各种分辨率的图像，而我们的系统要求固定的输入维度。因此，我们将图像进行下采样到固定的256×256分辨率。给定一个矩形图像，我们首先缩放图像短边长度为256，然后从结果图像中裁剪中心的256×256大小的图像块。除了在训练集上对像素减去平均活跃度外，我们不对图像做任何其它的预处理。因此我们在原始的RGB像素值（中心化的）上训练我们的网络。</strong></p>
<p>这段讲ImageNet的预处理，保证短边为256然后中心裁剪，不做其它预处理。因为ImageNet图片的大小不一，要先处理一下。</p>
<p>当时的工作大部分都是把图片抽取特征，然后再进行训练，但这个是直接对原始像素上做的，虽然文章没有把这个作为卖点，但这个端对端的观点（end to end）在之后也得到了证实，模型会帮我们提取出特征，不用我们先提取。</p>
<p>SIFT在之前也是一个很流行的图像特征抽取算法，但从这开始，或许你不知道SIFT是怎么抽的，但你知道AlexNet是怎么做的，了解从原始图片到目标结果，不再需要了解那么多的专业知识，不再需要了解CV过去30年做特征是怎么做的。所以说，简单有效的东西是能够持久的。</p>
<hr>
<h4 id="The-Architecture"><a href="#The-Architecture" class="headerlink" title="The Architecture"></a>The Architecture</h4><img src="/de804d7a/12.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>3 架构</strong></p>
<p><strong>我们的网络架构概括为图2。它包含八个学习层——5个卷积层和3个全连接层。下面，我们将描述我们网络结构中的一些新奇的或者不寻常的特性。3.1-3.4小节按照我们对它们评估的重要性进行排序，最重要的排在最前面。</strong></p>
<p>第三章是讲网络的架构，这也是文章的主要贡献之一，另外一个主要贡献是怎样避免过拟合在第四章。</p>
<hr>
<img src="/de804d7a/13.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>3.1 ReLU非线性</strong></p>
<p><strong>将神经元输出f建模为输入x的函数的标准方式是用f(x) = tanh(x)或f(x) = (1 + e−x)−1。考虑到梯度下降的训练时间，这些饱和的非线性比非饱和非线性f(x) = max(0,x)更慢。根据Nair和Hinton[20]的说法，我们将这种非线性神经元称为修正线性单元(ReLU)。采用ReLU的深度卷积神经网络训练时间比等价的tanh单元要快好几倍。在图1中，对于一个特定的四层卷积网络，在CIFAR-10数据集上达到25%的训练误差所需要的迭代次数可以证实这一点。这幅图表明，如果我们采用传统的饱和神经元模型，我们将不能在如此大的神经网络上实验该工作。</strong></p>
<p><strong>图1：使用ReLU的四层卷积神经网络在CIFAR-10数据集上达到25%的训练误差比使用tanh神经元的等价网络（虚线）快六倍。为了使训练尽可能快，每个网络的学习率是单独选择的。没有采用任何类型的正则化。影响的大小随着网络结构的变化而变化，这一点已得到证实，但使用ReLU的网络一直比等价的饱和神经元快几倍。</strong></p>
<p><strong>我们不是第一个考虑替代CNN中传统神经元模型的人。例如，Jarrett等人[11]声称非线性函数f(x) = |tanh(x)|与对比归一化以及局部均值池化在Caltech-101数据集上表现甚好。然而，在这个数据集上主要的关注点是防止过拟合，因此他们观测到的影响（预防过拟合）不同于我们使用ReLU拟合数据集时的反映的加速能力。更快的学习速率对大型模型在大型数据集上的性能有很大的影响。</strong></p>
<p>本小节标题是ReLU非线性激活函数，它说正常都是用tanh和sigmoid，但这些饱和的非线性激活函数会比非饱和的非线性激活函数慢（比如ReLU：max(0, x)）。可能有些人饱和和非饱和这些 saturating nonlinearities 、 non-saturating nonlinearity 没懂，但我们第二遍就不死挖到底了。</p>
<p>文章说用了ReLU特别好、特别快，图1也就表示出了它好的效果，随着epoch训练轮数的增加下降得更快。为什么非饱和更快，文章没有详细说明，有个引用标注，之后可以再看[20]的引用论文。</p>
<p>也分析了其他人的激活函数比如|tanh(x)|也不错，但还是不如ReLU快，毕竟数据集很大。在那时训练个ImageNet代价还是比较大的，快一点当然比较喜欢。不过在现在看来ReLU也没有说快多少，而且当时觉得ReLU快的原因在现在看来也不是那么正确，现在换个激活函数问题也不大。但大家还是用ReLU是单纯因为它简单。</p>
<hr>
<img src="/de804d7a/14.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>3.2 在多GPU上训练</strong></p>
<p><strong>单个GTX580 GPU只有3G内存，这限制了可以在GTX580上进行训练的网络最大尺寸。事实证明120万图像用来进行网络训练是足够的，但网络太大不能在单个GPU上进行训练。因此我们将网络分布在两个GPU上。目前的GPU非常适合跨GPU并行，因为它们可以直接互相读写内存，而不需要通过主机内存。我们采用的并行方案基本上每个GPU放置一半的核（或神经元），还有一个额外的技巧：只在某些特定的层上进行GPU通信。这意味着，例如，第3层的核会将第2层的所有核映射作为输入。然而，第4层的核只将位于相同GPU上的第3层的核映射作为输入。这种连接模式的选择有一个关于交叉验证的问题，但这可以让我们准确地调整通信数量，直到它的计算量在可接受的范围内。</strong></p>
<p><strong>除了我们的列不是独立的之外（看图2），最终的架构有点类似于Ciresan等人[5]采用的“柱状”CNN。与每个卷积层中只有一半的核在单GPU上训练的网络相比，这个方案分别降低了我们的top-1 1.7%，top-5 1.2%的错误率。双GPU网络比单GPU网络稍微减少了训练时间2。</strong></p>
<p><strong>图2：我们CNN架构图解，明确描述了两个GPU之间的职责。一个GPU运行图中上面部分的层，而另一个GPU运行图下面部分的层。两个GPU只在特定的层进行通信。网络的输入是150,528维，网络剩下层的神经元数目分别是253,440-186,624-64,896-64,896-43,264-4096-4096-1000。</strong></p>
<p>这几段主要是讲怎么用多个GPU并行训练，其实这些比较工程性细节的东西第二遍可以不看，除非是系统方向的论文，深度学习的可以等之后要复现再来细看。</p>
<hr>
<img src="/de804d7a/15.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>3.3 局部响应归一化（译者注：后来的研究表明，LRN几乎没有用处，因此读者可以跳过此部分）</strong></p>
<p><strong>ReLU具有让人满意的特性，即它不需要通过输入归一化来防止饱和。如果至少一些训练样本对ReLU产生了正输入，那么那个神经元上将发生学习。然而，我们仍然发现接下来的局部归一化有助于泛化。 表示神经元激活，通过在(x,y)位置应用核i，然后应用ReLU非线性来计算，响应归一化激活 通过下式给定：</strong></p>
<p><strong>求和运算在n个“毗邻的”核映射的同一位置上执行，N是本层的卷积核数目。核映射的顺序当然是任意的，在训练开始前确定。响应归一化的顺序实现了一种侧抑制形式，灵感来自于真实神经元中发现的类型，为使用不同核进行神经元输出计算的较大活动创造了竞争。常量k，n，α，β是超参数，它们的值通过验证集确定；我们设k=2，n=5，α=0.0001，β=0.75。我们在特定的层使用的ReLU非线性之后应用了这种归一化（请看3.5小节）。</strong></p>
<p><strong>这个方案与Jarrett等人[11]的局部对比度归一化方案有一定的相似性，但我们更恰当的称其为“亮度归一化”，因为我们没有减去均值。响应归一化分别减少了top-1 1.4%，top-5 1.2%的错误率。我们也在CIFAR-10数据集上验证了这个方案的有效性：没有归一化的四层CNN取得了13%的错误率，而使用归一化取得了11%的错误率。</strong></p>
<p>“不需要通过输入归一化来防止饱和”，看不太懂，可以圈出来第三遍再看。它只讲了怎么定义怎么用这些细节，但没说为什么一定要用它以及它的效果。第二遍看不太懂，可以忽略一下，知道它是个normalization就可以。</p>
<p>如果以现在的眼光来看，这个东西已经不重要了，在之后的研究几乎没有人用到它。现在我们也有更好的normalization的技术。</p>
<hr>
<img src="/de804d7a/16.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>3.4 重叠池化</strong></p>
<p><strong>CNN中的池化层使用相同的核映射归纳了神经元相邻组的输出。习惯上，相邻池化单元归纳的区域是不重叠的（例如[17, 11, 4]）。更确切的说，池化层可看作由池化单元网格组成，网格间距为s个像素，每个网格归纳池化单元中心位置z × z大小的邻居。如果设置s = z，我们会得到通常在CNN中采用的传统局部池化。如果设置s &lt; z，我们会得到重叠池化。这就是我们网络中使用的方法，设置s = 2，z = 3。这个方案与非重叠方案s = 2, z = 2相比，分别降低了top-1 0.4%，top-5 0.3%的错误率，两者的输出维度是相等的。我们在训练过程发现，采用重叠池化的模型更难以过拟合。</strong></p>
<p>一般来说pooling是不会overlapping的，但这说要重叠一下。也有可能不了解什么是pooling是干什么的，都第三遍之前先看一下。本文在传统池化方法上做了一点改动，虽然说改动不大，但文章说效果很好。</p>
<hr>
<img src="/de804d7a/17.png" class>

<img src="/de804d7a/18.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>3.5 整体架构</strong></p>
<p><strong>现在我们准备描述我们的CNN的整体架构。如图2所示，我们的网络包含8个带权重的层；前5层是卷积层，剩下的3层是全连接层。最后一层全连接层的输出喂给1000维的softmax层，softmax会产生1000类标签的分布。我们的网络最大化多项逻辑回归的目标，这等价于最大化预测分布下训练样本正确标签的对数概率的均值。</strong></p>
<p><strong>第2，4，5卷积层的神经元只与位于同一GPU上的前一层的核映射相连接（见图2）。第3卷积层的核与第2层的所有核映射相连。全连接层的神经元与前一层的所有神经元相连。第1，2卷积层之后是响应归一化层。第3.4节描述的这种最大池化层加在了响应归一化层和第5卷积层之后。ReLU非线性应用在每个卷积层和全连接层的输出上。</strong></p>
<p><strong>第1卷积层使用96个核对224 × 224 × 3的输入图像进行滤波操作，核大小为11 × 11 × 3，步长是4个像素（核映射中相邻神经元感受野中心之间的距离）。第2卷积层使用第1卷积层的输出（响应归一化和池化）作为输入，并使用256个大小为5 × 5 × 48核进行滤波。第3，4，5卷积层依次连接，中间没有接入任何池化层或归一化层。第3卷积层有384个大小为3 × 3 × 256的核，与第2卷积层的输出（归一化的，池化的）相连。第4卷积层有384个大小为3 × 3 × 192的核，第5卷积层有256个核大小为3 × 3 × 192的核。每个全连接层有4096个神经元。</strong></p>
<p>最后这一部分是整体的架构，讲了整体的8个层，因为用了两个GPU所以整个架构是比较麻烦的，第一个层的大小是224 × 224 × 3（为什么不是256之后会说）……</p>
<p>这篇文章看起来更像一篇技术报告，只讲作者做了什么，也不跟其他人做对比。</p>
<p>接下来看看图里的网络结构，不过这个图过于抠细节，有些繁琐，第一次看不一定理解。</p>
<p>框框是指每一层输入输出的数据的大小，进来的时候是一个224 × 224 × 3的图片。第一次卷积是11 × 11，stride跳4格，输出是55 × 55 × 48。在两个GPU上都有各自的5层卷积层，从第1层到第2层，是对当前GPU的层进行卷积；第2层到第3层，会到另一个GPU拿来卷积结果看一眼，在输出通道维度合并；第3到第4，第4到第5都是各搞各的，各自卷积；从卷积层到第1个全连接层又进行了一次通讯，后面的全连接层也是，其实就是表示成一个4096的向量，最后用一个线性分类器变成1000分类。</p>
<p>也就是说一张图片最后会表示成一个4096的维度，这个向量能很好的抓住语义信息，如果两个图片向量特别相近，那么很有可能是类似的图片。所以就是一张人能看得懂的像素图片，进行神经网络的特征提取，最后变成一个4096的机器能懂的向量，这个向量能够表示中间的语义信息。其实网络就是在压缩，这个向量机器可以拿来做搜索也好、分类也好。</p>
<p>但分成了两个GPU训练，导致模型较为复杂，其实在现在来看，其中的一块卡可能用caffe已经可以训练这个AlexNet了，没必要双卡，但Alex应该是花了很多时间搞这个双卡的模型，觉得是一个贡献点。如果三个卡、四个卡呢，网络岂不是更为复杂，所以模型其实也不用切。在六七年里，大家也都没有把模型进行切分，但在最近比如要训练GPT这种超级大的网络，可能训练不动了，又觉得模型切分好用了。（硬件再发展可能又不用切分了，所以这是一个机器算力和模型大小的矛盾）</p>
<hr>
<h4 id="Reducing-Overfitting"><a href="#Reducing-Overfitting" class="headerlink" title="Reducing Overfitting"></a>Reducing Overfitting</h4><img src="/de804d7a/19.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>4 减少过拟合</strong></p>
<p><strong>我们的神经网络架构有6000万参数。尽管ILSVRC的1000类使每个训练样本从图像到标签的映射上强加了10比特的约束，但这不足以学习这么多的参数而没有相当大的过拟合。下面，我们会描述我们用来克服过拟合的两种主要方式。</strong></p>
<p>第四节讲的是如何降低过拟合，因为训练了一个较大的网络，现在要防止过拟合。</p>
<hr>
<img src="/de804d7a/20.png" class>

<img src="/de804d7a/21.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>4.1 数据增强</strong></p>
<p><strong>图像数据上最简单常用的用来减少过拟合的方法是使用标签保留变换（例如[25, 4, 5]）来人工增大数据集。我们使用了两种不同的数据增强方式，这两种方式都是从原始图像通过非常少的计算量产生变换的图像，因此变换图像不需要存储在硬盘上。在我们的实现中，变换图像通过CPU的Python代码生成，而此时GPU正在训练前一批图像。因此，实际上这些数据增强方案没有消耗计算量。</strong></p>
<p><strong>第一种数据增强方式包括产生图像平移和水平翻转。我们从256 × 256图像上通过随机提取224 × 224的图像块（以及这些图像块的水平翻转）实现了这种方式，然后在这些提取的图像块上进行训练。这通过一个2048因子增大了我们的训练集，尽管最终的训练样本是高度相关的。没有这个方案，我们的网络会有大量的过拟合，这会迫使我们使用更小的网络。在测试时，网络会提取5个224 × 224的图像块（四个角上的图像块和中心的图像块）和它们的水平翻转（因此总共10个图像块）进行预测，然后对网络在10个图像块上的softmax层的预测结果进行平均。</strong></p>
<p><strong>第二种数据增强方式包括改变训练图像的RGB通道的强度。具体地，我们在整个ImageNet训练集上对RGB像素值集合执行主成分分析（PCA）。对于每幅训练图像，我们加上多倍找到的主成分，大小成正比的对应特征值乘以一个随机变量，随机变量通过均值为0，标准差为0.1的高斯分布得到。因此对于每幅RGB图像像素 ，我们加上下面的数量：</strong></p>
<p><strong>pi，λi分别是RGB像素值3 × 3协方差矩阵的第i个特征向量和特征值，αi是前面提到的随机变量。对于某个训练图像的所有像素，每个αi只获取一次，直到图像进行下一次训练时才重新获取。这个方案近似抓住了自然图像的一个重要特性，即光照的强度和颜色发生变化时，物体本身没有发生变化。这个方案减少了top 1错误率1%以上。</strong></p>
<p>用了两种数据增强方式，当然也不是首创，也是前人的方法了。</p>
<p>第一种是尺寸上修改，通过平移与翻转进行抠图，从256 × 256变成224 × 224；第二种是颜色上修改，比如PCA改变一下图片的颜色，这个PCA不明白也可以留到后面细看。</p>
<hr>
<img src="/de804d7a/22.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>将许多不同模型的预测结果结合起来是降低测试误差[1, 3]的一个非常成功的方法，但对于需要花费几天来训练的大型神经网络来说，这似乎将花费太长时间以至于无法训练。然而，有一个非常有效的模型结合版本，它只花费两倍的训练成本。这种最近推出的技术，叫做“dropout”[10]，它会以0.5的概率对每个隐层神经元的输出设为0。那些用这种方式“丢弃”的神经元不再进行前向传播并且不参与反向传播。因此每次输入时，神经网络会采样一个不同的架构，但所有架构共享权重。这个技术减少了复杂的神经元互适应，因为一个神经元不能依赖特定的其它神经元的存在。因此，神经元被强迫学习更鲁棒的特征，它在与许多不同的其它神经元的随机子集结合时是有用的。在测试时，我们使用所有的神经元但它们的输出乘以0.5，对指数级的许多失活网络的预测分布进行几何平均，这是一种合理的近似。</strong></p>
<p><strong>我们在图2中的前两个全连接层使用失活。如果没有失活，我们的网络表现出大量的过拟合。失活大致上使要求收敛的迭代次数翻了一倍。</strong></p>
<p>虽然说模型融合很好用，但太久了不好用。所以Alex用了Hinton老爷子在其论文《Improving neural networks by preventing co-adaptation of feature detectors》中提出Dropout，设置每次0.5的概率忽略神经元来防止过拟合，其实现在的眼光来看，dropout也不是模型融合，应该说是正则项。几年后他们也写了篇文章说dropout在线性模型中等价于一个L2的正则项，更复杂来说应该说是带来了一个正则的效果。</p>
<p>文章说把dropout放在了全连接层前，如果不放那么过拟合就很严重，但放了后训练时间大概会翻倍。所以AlexNet用了3个全连接，最后一个肯定是有的毕竟要输出，中间的两个很大的4096全连接是模型的一大瓶颈，这是该模型当时设计的一大缺陷，所以说导致整个模型特别大，放不进一个GPU里。因为用的是4096的全连接，dropout能防止过拟合，但现在CNN的设计通常不会使用那么大的全连接层，所以导致dropout也不那么重要，GPU的内存也没那么吃紧了。</p>
<p>反过来讲，dropout在全连接上还是很有用的，在RNN上、在Attention上dropout用得很多。</p>
<hr>
<h4 id="Details-of-learning"><a href="#Details-of-learning" class="headerlink" title="Details of learning"></a>Details of learning</h4><img src="/de804d7a/23.png" class>

<img src="/de804d7a/24.png" class>

<p><strong>中文翻译：</strong></p>
<p><strong>我们使用随机梯度下降来训练我们的模型，样本的batch size为128，动量为0.9，权重衰减率为0.0005。我们发现少量的权重衰减对于模型的学习是重要的。换句话说，权重衰减不仅仅是一个正则项：而且它减少了模型的训练误差。权重ww的更新规则是：</strong></p>
<p><strong>i是迭代索引，v是动量变量，ϵ是学习率， 是目标函数对w，在wi上的第i批微分Di的平均。</strong></p>
<p><strong>我们使用均值为0，标准差为0.01的高斯分布对每一层的权重进行初始化。我们在第2，4，5卷积层和全连接隐层将神经元偏置初始化为常量1。这个初始化通过为ReLU提供正输入加速了早期阶段的学习。我们对剩下的层的神经元偏置初始化为0。</strong></p>
<p><strong>我们对所有的层使用相等的学习率，这个是在整个训练过程中我们手动调整得到的。当验证误差在当前的学习率下停止改善时，我们遵循启发式的方法将学习率除以10。学习率初始化为0.01，在训练停止之前降低三次。我们在120万图像的训练数据集上训练神经网络大约90个循环，在两个NVIDIA GTX 580 3GB GPU上花费了五到六天。</strong></p>
<p>第五章讲的是模型是怎么样训练的，他说用SGD这个优化算法来训练，现在来看SGD当然是深度学习最常用的算法，但当年大家并不是这么觉得，因为SGD调参相对来说比较难调，那时候常用更稳定的算法比如L-BFGS、Coordinate Descent。后来大家发现SGD里面的噪音对模型其实是有好处的，所以现在深度学习大家都用这个了。</p>
<p>batch size是128，momentum是0.9，weight decay是0.0005。weight decay当时在机器学习界主流上应该叫作L2 regularization（L2正则项），但是这篇文章以及神经网络里面喜欢叫作weight decay，所以这个东西不是加在模型上，而是加在优化算法上，虽然说这两者其实是等价的关系，但深度学习的崛起大家也都叫做weight decay了。momentum也是防止在一段非极值较陡的区域上陷入局部最低点，而是保有一个冲量，冲过这一段，更好地找到最值。</p>
<p>函数里也可以看到新的momentum项等于0.9 × 旧momentum - 0.0005 × weight decay × 另外一个东西（这个东西其实就是学习率），最后再减去梯度。</p>
<p>然后他说权重是用一个均值为0、方差为0.01的高斯随机变量来初始化的。0.01这个值也是经验值，这个不大也不小，比较好用。当然了网络比较深需要更多的优化，对于这些简单的网络已经很ok了，现在那些大的网络有些也用0.02。</p>
<p>还说了在第2、4、5层卷积层和全连接层神经元的偏移量设置为1，其它设置为0，其实一般都是初始化为0，这个调参比较玄学，后来大家也没有跟进研究这个细节。毕竟全部为0效果也不差，就不整这个玄学了。（或许多训练一次结果又不一样了）</p>
<p>每个层都用的一样的学习率0.01，然后人工盯着不太动了就变为当前的十分之一，当时计算资源比较贵以及一段时间内大家都是这么干的（手动炼丹），但现在看来也没那么复杂，比如ResNet总共训练120轮每30轮就乘以0.1（动态学习率），也可以比如先训练60轮、100轮后面再下降。现在来说用一些更平滑的方法更常见，比如用cos之类的曲线。当然了学习率一开始也不能太大，太大了容易炸，太小了学不会训练不动，所以也有像yolo一样从0开始，先线性上升在cos下降。</p>
<p>训练了90个epochs，每一遍都是扫了训练集的120w张图片，用2张580训练了五六天。这个还是挺久的，调个参得五六天才出结果。（这也让N卡股价暴涨，要买好卡赶紧出结果）现在图像很快了，但即使用几千块的卡训练文本也要很多天，看看下次迭代是啥时候，让文本领域也发光发热。</p>
<hr>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><img src="/de804d7a/25.png" class>

<img src="/de804d7a/26.png" class>

<img src="/de804d7a/27.png" class>

<p><strong>6 结果</strong></p>
<p><strong>我们在ILSVRC-2010上的结果概括为表1。我们的神经网络取得了top-1 37.5%，top-5 17.0%的错误率5。在ILSVRC-2010竞赛中最佳结果是top-1错误率47.1%和top-5错误率28.2%，使用的方法是对6个在不同特征上训练的稀疏编码模型生成的预测进行平均，之后公布的最好结果是top-1错误率45.7%和top-5错误率25.7%，使用的方法是在Fisher向量（FV）上训练的两个分类器的预测结果取平均，Fisher向量是通过两种密集采样特征计算得到的[24]。</strong></p>
<p><strong>表1：ILSVRC-2010测试集上的结果对比。斜体表示的是其它人取得的最好结果。</strong></p>
<p><strong>我们也用我们的模型参加了ILSVRC-2012竞赛并在表2中报告了我们的结果。由于ILSVRC-2012的测试集标签没有公开，因此我们不能报告我们尝试的所有模型的测试错误率。在这段的其余部分，我们会将验证误差率和测试误差率互换，因为在我们的实验中它们的差别不会超过0.1%（看图2）。本文中描述的CNN取得了top-5 18.2%的错误率。五个类似的CNN预测的平均误差率为16.4%。为了对ImageNet 2011秋季发布的整个数据集（1500万图像，22000个类别）进行分类，我们在最后的池化层之后有一个额外的第6卷积层，训练了一个CNN，然后在它上面进行“微调”，在ILSVRC-2012取得了16.6%的错误率。对在ImageNet 2011秋季发布的整个数据集上预训练的两个CNN和前面提到的五个CNN的预测进行平均得到了15.3%的错误率。第二名的最好竞赛团队取得了26.2%的错误率，他的方法是对FV上训练的一些分类器的预测结果进行平均，FV在不同类型密集采样特征计算得到的。</strong></p>
<p><strong>表2：ILSVRC-2012验证集和测试集的误差对比。斜线部分是其它人取得的最好的结果。带星号的是“预训练的”对ImageNet 2011秋季数据集进行分类的模型。更多细节请看第六节。</strong></p>
<p><strong>最后，我们也报告了我们在ImageNet 2009秋季数据集上的错误率，ImageNet 2009秋季数据集有10,184个类，890万图像。在这个数据集上我们按照文献中的惯例，用一半的图像来训练，一半的图像来测试。由于数据集上没有建立好的测试集，我们对数据集分割必然不同于以前作者的数据集分割，但这对结果没有明显的影响。我们在这个数据集上的的top-1和top-5错误率是67.4%和40.9%，使用的是上面描述的在最后的池化层之后有一个额外的第6卷积层网络。这个数据集上公开可获得的top-1和top-5错误率最好结果是78.1%和60.9%[19]。</strong></p>
<p><strong>6.1 定性评估</strong></p>
<p><strong>图3显示了网络的两个数据连接层学习到的卷积核。网络学习到了大量的频率核、方向选择核，也学到了各种颜色点。注意两个GPU表现出的专业化，3.5小节中描述的受限连接的结果。GPU 1上的核主要是没有颜色的，而GPU 2上的核主要是针对颜色的。这种专业化在每次运行时都会发生，并且是与任何特别的随机权重初始化（以GPU的重新编号为模）无关的。</strong></p>
<p><strong>图3：第一卷积层在224×224×3的输入图像上学习到的大小为11×11×3的96个卷积核。上面的48个核是在GPU 1上学习到的而下面的48个卷积核是在GPU 2上学习到的。更多细节请看6.1小节。</strong></p>
<p><strong>在图4的左边部分，我们通过在8张测试图像上计算它的top-5预测定性地评估了网络学习到的东西。注意即使不在图像中心的目标也能被网络识别，例如左上角的小虫。大多数的top-5标签似乎是合理的。例如，对于美洲豹来说，只有其它类型的猫被认为是看似合理的标签。在某些案例（格栅，樱桃）中，照片的预期焦点确实存在的模糊性。</strong></p>
<p><strong>图4：（左）8张ILSVRC-2010测试图像和我们的模型认为最可能的5个标签。每张图像的下面是它的正确标签，正确标签的概率用红色柱形表示（如果正确标签在top 5中）。（右）第一列是5张ILSVRC-2010测试图像。剩下的列展示了6张训练图像，这些图像在最后的隐藏层的特征向量与测试图像的特征向量有最小的欧氏距离。</strong></p>
<p><strong>探索网络可视化知识的另一种方式是思考最后的4096维隐藏层在图像上得到的特征激活。如果两幅图像生成的特征激活向量之间有较小的欧式距离，我们可以认为神经网络的更高层特征认为它们是相似的。图4表明根据这个度量标准，测试集的5张图像和训练集的6张图像中的每一张都是最相似的。注意在像素级别，检索到的训练图像与第一列的查询图像在L2上通常是不接近的。例如，检索的狗和大象似乎有不同的姿态。我们在补充材料中对更多的测试图像呈现了这种结果。</strong></p>
<p><strong>通过两个4096维实值向量间的欧氏距离来计算相似性是效率低下的，但通过训练一个自动编码器将这些向量压缩为短二值编码可以使其变得高效。这应该会产生一种比将自动编码器应用到原始像素上[14]更好的图像检索方法，自动编码器应用到原始像素上的方法没有使用图像标签，因此会趋向于检索与要检索的图像具有相似边缘模式的图像，无论它们是否是语义上相似。</strong></p>
<p>这部分也就是说模型的效果有多好，中间的过程也是现在深度学习的标准流程了。</p>
<p>我们读论文的很多时候，实验部分相对来说是不那么重要的，我们关心的是实验的一个效果，但是具体实验是怎么做的，很多时候除非我们是这个领域的专家，但专家一眼就大概知道了，如果是初入领域的新手也看不懂，除非你要重复这个实验、或者审论文等专家行为的时候才会大概去看他的实验。</p>
<p>最后文章也汇报了模型在完整的ImageNet上训练10184个种类的890w张图，但大家一般对ImageNet的印象也就是那1000类的120w张图，之后训练大家也不跑完整的890w，比较不解。</p>
<p>6.1也说了在两块GPU上的一个是无颜色的一个是颜色相关的，很奇怪，炼丹多次也是一样的结果。这里也是留下了一个疑惑，不过后来大家也都不拆分模型，所以也没有得到重视，毕竟是炼丹，过程奇怪也正常（？）。鄙人拙见可能是跟卷积核或者图片切块的方式有关。</p>
<p>有一些神经元还是很有对应性的，比如底层的神经元学到的是一些局部的信息，比如纹理、方向，上层的神经元学到的一些比如头、胳膊、动物等轮廓。也有人受启发去研究神经网络到底学什么，学形状呢还是学纹理，所以说这篇奠基石是很有启发性的。</p>
<p>相对于比较简单的机器学习模型来讲，现在大家还是不知道神经网络到底在学什么，它的可解释性还是比较低的。但这几年大家也开始慢慢研究它的公平性、神经网络的偏移等也是热议的重点，因为如果想用神经网络做决策，那么公平是很重要的。</p>
<hr>
<h3 id="他人总结"><a href="#他人总结" class="headerlink" title="他人总结"></a>他人总结</h3><blockquote>
<p><a href="https://blog.csdn.net/cg129054036/article/details/120794416">https://blog.csdn.net/cg129054036/article/details/120794416</a></p>
</blockquote>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1ih411J7Kz">https://www.bilibili.com/video/BV1ih411J7Kz</a><br><a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf</a><br><a href="https://blog.csdn.net/Jwenxue/article/details/89317880">https://blog.csdn.net/Jwenxue/article/details/89317880</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-Krishna V. Shenoy：脑机接口与意念手写｜2021腾讯科学WE大会视频回顾</title>
    <url>/e5610da1.html</url>
    <content><![CDATA[<h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>11月6日，2021腾讯科学WE大会正式举行。<strong>斯坦福大学教授Krishna V. Shenoy</strong>分享了脑机接口与意念手写相关的最新思考与研究。传统方法实现用“意念”打字是通过脑机接口技术，让瘫痪患者在脑中想象移动光标，从屏幕上的键盘选取字母，组成单词。Shenoy教授和团队另辟蹊径，让患者在脑中想象手写字母，收集神经数据对人工智能算法进行训练，让人工智能可以识别并提前预测患者想要打出的字母，这种方法比传统方法的打字速度快了一倍。演讲中，Shenoy教授分享了人脑与机脑交互的背景、现状和未来。</p>
<p>Shenoy教授表示，过去20年可植入治疗设备在全球得到了更好的普及，其他研究团队的成果也表明人工膝盖、人工关节甚至人工起搏器已经得到了广泛的应用，相信未来几十年与人脑的对接会是重点领域之一。人脑大约3磅重（约1.36kg），是神经科学的研究对象，而通过连接大脑去帮助瘫痪或有其它疾病或损伤的病人，有可能彻底改变整个医学体系。</p>
<span id="more"></span>

<hr>
<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>目前有一些治疗系统可以向大脑输入信息：</p>
<ol>
<li><strong>人工视网膜：</strong>把一个微小的芯片，就像手机或电脑芯片一样，植入眼中。它会像镜头一样采集光线，然后将光信息转化为电刺激信号，输入人脑中负责视觉的部分并重建视力。</li>
<li><strong>人工耳蜗：</strong>人工耳蜗可能是截至目前最成功且应用最广泛的神经假体技术，可以让先天性失聪患者学习说话。它的工作原理是通过刺激耳蜗周边不同的区域来重建听力。</li>
<li><strong>深部脑刺激器：</strong>通过神经外科手术将这些几英寸长的电极植入大脑深层的一个叫做“苍白球”（the globus pallidus）的区域。这个像起搏器一样的装置会输出电流，电流会阻断该区域的异常神经活动，从而让帕金森病患者停止颤抖。</li>
</ol>
<p>这些治疗装置都是通过向大脑传递信号电子能量光能量甚至电磁能量，来帮助病人。反向研究在癫痫的治疗上有所体现，不仅是向大脑输入信号，同时也读取大脑发出的信号。原理是将癫痫控制装置植入人脑，感知即将发生的高强度癫痫脑电波，然后做出决策去刺激大脑的另一个部分，从而阻止和避免癫痫的突然发作。</p>
<img src="/e5610da1/1.png" class>

<hr>
<h3 id="研究重点"><a href="#研究重点" class="headerlink" title="研究重点"></a>研究重点</h3><p><strong>必须搞懂的一个神经科学问题是，不同的信号是在人脑的什么部位被编码的以及如何被编码的。</strong>这涉及了人类精神生命的核心。</p>
<p>当前Shenoy教授团队的研究重点就是<strong>读取大脑信号</strong>，比如大脑如何让肢体移动或者让人能够看到或听到。还有其它各个相关的领域，比如精神疾病和精神障碍等。</p>
<p>全世界的瘫痪病人不计其数，Shenoy教授认为可以通过植入皮质内脑机接口来帮助他们。“皮质内”的意思就是在大脑皮层的内侧。大脑皮层是大脑外部的组织，人类的大脑皮层要远多于低等动物。<strong>而脑机接口的原理是，在某种程度上让脑信号与计算机信号互动。</strong></p>
<img src="/e5610da1/3.png" class>

<p>这是一张皮质内脑机接口侧视图，脑机接口可以用于控制义肢瘫痪的手臂以及计算机接口。正常人的控制流程如下：视网膜首先传递视觉信息到大脑后部，然后向前传送到运动皮质区，在此通过脊髓传递详细指令信号给手臂的肌肉。从而伸手去拿起那杯咖啡。</p>
<img src="/e5610da1/4.png" class>

<p>一种方法是芯片可以读取并使用这些信号，继续传递信号并刺激瘫痪手臂的不同肌肉，让手臂恢复活动功能。如图展示，手臂可以拿起咖啡并送到嘴边饮用，也就是通过刺激瘫痪的手臂让其恢复活动功能。</p>
<img src="/e5610da1/5.png" class>

<p>另一种方式是让机械手臂或义肢具有活动功能。使用者只需要想着去移动右臂，芯片读取这些信号并让机械手臂做出相应的动作。</p>
<img src="/e5610da1/6.png" class>

<p>第三种是<strong>一种与电脑直接沟通的解决方案</strong>。该电极阵列中的每个电极4毫米见方，共有100个微型电极，每个长度1.5毫米。这组电极阵列就是该研究领域的核心，叫做<strong>犹他电极阵列</strong>（Utah Electrode Array），它可以植入人脑收集有用的信号，工作时间长达几年。该芯片通过手术植入到大脑表皮以下1.5-2毫米处，这些电极的末梢紧挨着个体细胞和神经元。观察其中一个电极，可以看到电压和时间脉冲。对此可以对义肢或电脑屏幕上的光标进行精确的控制。</p>
<img src="/e5610da1/7.png" class>

<hr>
<h3 id="意念手写"><a href="#意念手写" class="headerlink" title="意念手写"></a>意念手写</h3><p>Shenoy教授认为许多基础研究都来自于非灵长类动物，但一旦面对真实患者的诉求，想法就会转变。例如帮助丧失沟通能力的患者实现表达与交流。</p>
<img src="/e5610da1/8.png" class>

<p>图中展示的是通过使用现有的治疗装置，丧失沟通能力的患者每分钟可以表达出的单词数，比如吹吸气接口等，沿着轴线的许多点表示打字速度。例如使用者凭空想象去移动电脑屏幕上的光标并完成这个动作，最快打字速度可以达到每分钟8个单词；使用者尝试写字，解码这些字母并呈现出来，使用者的书写速度达到每分钟17-18个单词。</p>
<p>而对于语言交流而言，目前的治疗系统可以收集来自大脑表层的信号，并从字典中成千上万的单词中按照顺序进行选择。Shenoy教授团队的目标是，<strong>了解个体神经元与说话之间存在怎样的关联，如何让人能够说出想说的任何单词，也就是所谓的“开放词汇”</strong>。</p>
<img src="/e5610da1/9.png" class>

<p>信号从电极装置发出，然后过滤一些噪音，对信号和绿色部分的解码模块的含义进行解读，然后这些信号用于控制这位T5志愿者面前的电脑的白色光标。最终测试得患者的打字速度约为每分钟32个正确的字母。</p>
<img src="/e5610da1/10.gif" class>

<hr>
<h3 id="近期成果"><a href="#近期成果" class="headerlink" title="近期成果"></a>近期成果</h3><p>Shenoy教授的团队中Frank Willard博士最近关于手写有一些研究成果。目的并不是要将笔迹完全重建，而是读取信号得到目标字母实现短语拼写。做法是将两组电极阵列放入皮质运动区中负责手和手指的区域，首先让患者写出字母“a”，然后依次写出其它一些字母。这期间收集神经数据，使用机器学习和人工智能算法对神经网络进行训练。这实际上是对大脑表达区域的解码。</p>
<img src="/e5610da1/11.png" class>

<p>这是一个神经状态空间，可以通过分辨不同的集群解读信息。例如你想写“paper”这个字，会记录来自约200个神经元的每一个动作电位和电脉冲，就像这个小长方形展示的那样。在短短20毫秒内，可以读取信息，通过经过训练的神经网络和机器学习算法来解读这些信息。而结果就是判断出使用者想要打出哪个字母，是a、b还是c。</p>
<img src="/e5610da1/12.png" class>

<p>通过<strong>机器学习</strong>甚至可以对拼写进行修正，将这些信息与大脑发出的神经信息相结合，在词汇搜索过程中将两者相互比对，然后更正错误，就像是电脑一样中使用的拼写和语法检查功能一样。该模型使用者每分钟可以写出约90个字母，这比之前用屏幕光标打字的速度快了一倍多（当时每分钟可以打出约40个字母）。错误率在5%左右，正确率95%。当加入了语言模型之后，错误率从5%降低至0.5%，说明未来还有巨大的提升空间。</p>
<img src="/e5610da1/13.png" class>

<p><strong>Shenoy教授相信能够解码大脑活动的皮质内脑机接口正在快速进步，它带来了全新的与人脑对接的神经接口或沟通桥梁。</strong>得益于神经科学和相关的机器学习与解码算法的进步，新的脑机接口可以很好地控制2D光标，可以将使用者的打字速度提高一倍以上。这些信号也可以用来控制机械手臂和瘫痪手臂的肌肉组织，最后这些全新的皮质内脑机接口可以将打字速度提高一倍多，而未来还有更多提升。</p>
<hr>
<h3 id="展望未来"><a href="#展望未来" class="headerlink" title="展望未来"></a>展望未来</h3><p>人脑中约有<strong>860亿</strong>个神经元，目前只能记录其中的<strong>几百或几千个</strong>。但随着纳米科学和其它工程材料学的发展，在未来有能力对几百万个神经元进行记录。对此，可以通过新的方法刺激几千甚至几百万个神经元，不只是电流刺激，还可以通过“光遗传学”的光学方式进行刺激，最终研制出可植入人脑的超低功率治疗系统，治疗多种神经损伤和疾病。这些系统无需有形的电线，它们是微型的，植入大脑浅皮层，可以通过微电子和集成电路芯片产业的革命加以实现。</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/SsGs-UDQ1hpGOQIupFMNzw">https://mp.weixin.qq.com/s/SsGs-UDQ1hpGOQIupFMNzw</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>第九艺术-微软Xbox科普指南（2021版）</title>
    <url>/b2f3cb6a.html</url>
    <content><![CDATA[<hr>
<p><strong>注意：不看参数，只想知道买什么的直接看第四部分</strong></p>
<hr>
<h3 id="Xbox家族介绍"><a href="#Xbox家族介绍" class="headerlink" title="Xbox家族介绍"></a>Xbox家族介绍</h3><p>Xbox是<strong>美国微软公司</strong>创建的<strong>电子游戏品牌</strong>，随2001年11月第一代<strong>Xbox游戏机发布而首次推出。其产品和服务包括</strong>家用游戏机<strong>、游戏制作与发行、线上游戏服务和内容订阅服务。Xbox已发售的四代家用游戏机有</strong>Xbox<strong>、</strong>Xbox360<strong>、</strong>Xbox One<strong>、</strong>Xbox Series**。</p>
<table>
<thead>
<tr>
<th>信息</th>
<th>内容</th>
<th>信息</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>外文名</strong></td>
<td>Xbox</td>
<td><strong>所属公司</strong></td>
<td>微软</td>
</tr>
<tr>
<td><strong>所属行业</strong></td>
<td>电子游戏</td>
<td><strong>初代产品</strong></td>
<td>Xbox</td>
</tr>
<tr>
<td><strong>创立时间</strong></td>
<td>2001年11月15日</td>
<td><strong>所属国家</strong></td>
<td>美国</td>
</tr>
</tbody></table>
<hr>
<span id="more"></span>

<h4 id="第一代Xbox"><a href="#第一代Xbox" class="headerlink" title="第一代Xbox"></a>第一代Xbox</h4><h5 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h5><p>Xbox游戏机是Xbox旗下的第一代家用游戏机产品。Xbox的研发代号是“中途岛”（Midway），二战期间美国太平洋舰队在中途岛一战重创日本海军，代号不知是否是一种巧合，暗示了微软与强大的日本游戏主机产业对抗的决心。</p>
<p>2000年3月10日，比尔·盖茨在GDC2000上正式公布Xbox，当时的Xbox尚未完成造型设计，比尔·盖茨掀开的盖头下是一台打造成X型的概念机。</p>
<img src="/b2f3cb6a/1.jpg" class>

<p>本世纪伊始，时任NOA（任天堂美国分社）社长荒川实获悉微软即将全面进军TV游戏产业，深知微软底细的他立即飞回京都面见岳父山内溥（注1：NOA在西雅图的办公楼和微软总部仅一墙之隔）。荒川的意愿是希望山内家族能够顺势将股份转让给微软全身而退，他的想法无疑触动了山内溥的逆鳞，翁婿二人自此彻底破脸。山内溥不惜投入超过十三亿美元巨额预算，联合松下公司开发NGC主机，并积极联络第三方厂商意图再次君临天下。其以往诸如世嘉、NEC和索尼等竞争对手的身量实际都相差有限（注2：在索尼进入传统游戏产业的22年间，任天堂有16年的纯利润都要高于索尼集团），山内没有意识到和微软的巨大实力差距。</p>
<p>微软为了推出Xbox，亏损超过四十亿美元，Xbox不惜血本的硬件规格令NGC失色，在争夺第三方资源方面，微软不惜采用补贴开发资金和包揽广告费等非常规手段。</p>
<p>时任纽约市长，经历了9/11的鲁道夫·朱利安尼则请求微软不要取消预定在时代广场举办的Xbox首发仪式，纽约需要这场盛大的典礼来向世界证明自己的坚韧，证明自己仍是世界的贸易中心。</p>
<p>2001年11月14日深夜，比尔·盖茨亲自来到时代广场，在午夜时分将第一台Xbox交给了来自新泽西的20岁年轻人爱德华·格拉克曼，后者在回忆中说：“比尔·盖茨就是上帝。”性能超越顶级PC的Xbox让他们趋之若鹜。</p>
<img src="/b2f3cb6a/2.jpg" class>

<p>2000年3月10日，微软宣布将推出游戏机Xbox。Xbox发布后一年，微软以3.75亿美元收购了为任天堂制作了诸如《007黄金眼》（GoldenEye 007）、《完美黑暗》（Perfect Dark）等游戏的公司Rare。</p>
<p>Xbox和SONY的PlayStation 2，以及任天堂公司的NGC形成了三足鼎立的局面。</p>
<p>内装英特尔公司制造的Pentium III基本中央处理器、内建8GB容量的硬盘与DVD-ROM光驱、以太网路连接埠，支援网络的能力，与个人电脑架构相似。</p>
<hr>
<h5 id="硬件规格"><a href="#硬件规格" class="headerlink" title="硬件规格"></a>硬件规格</h5><table>
<thead>
<tr>
<th>项目</th>
<th>参数</th>
</tr>
</thead>
<tbody><tr>
<td><strong>中央处理器CPU</strong></td>
<td>英特尔PentiumIII 733MHz</td>
</tr>
<tr>
<td><strong>图型处理器GPU</strong></td>
<td>由微软与NVIDIA公司共同研发的特制绘图芯片” X-Chip” 233MHz (GeForce3的改良版)</td>
</tr>
<tr>
<td><strong>多边形处理能力</strong></td>
<td>1.165亿/秒</td>
</tr>
<tr>
<td><strong>同步贴图材质数目</strong></td>
<td>4</td>
</tr>
<tr>
<td><strong>内建硬盘容量</strong></td>
<td>8GB</td>
</tr>
<tr>
<td><strong>内存</strong></td>
<td>DDR 64MB</td>
</tr>
<tr>
<td><strong>内存带宽</strong></td>
<td>6.4GB/秒</td>
</tr>
<tr>
<td><strong>记忆装置</strong></td>
<td>5倍速DVD光驱、8GB内建硬盘；支援8MB记忆卡</td>
</tr>
<tr>
<td><strong>输出入埠</strong></td>
<td>游戏控制器连接埠x4、10/100Mbps以太网路连接埠</td>
</tr>
<tr>
<td><strong>音轨数量</strong></td>
<td>256</td>
</tr>
<tr>
<td><strong>音频输出</strong></td>
<td>支援MIDI+DLS与Dolby®Digital 5.1环绕音效</td>
</tr>
<tr>
<td><strong>视频输出</strong></td>
<td>支援色差分量端子输出；支援HDTV规格</td>
</tr>
<tr>
<td><strong>最大分辨率</strong></td>
<td>1920×1080</td>
</tr>
<tr>
<td><strong>重量</strong></td>
<td>3.86kg</td>
</tr>
<tr>
<td><strong>外型大小</strong></td>
<td>324×265×90mm</td>
</tr>
<tr>
<td><strong>售价</strong></td>
<td>199美元</td>
</tr>
<tr>
<td><strong>系统带宽</strong></td>
<td>22.4 GB/s 记忆体总线界面（基于128 bit位宽总线，每时钟周期700 MHz × 2次访问（每波峰一次）<br>32 GB/s GPU到eDRAM带宽（基于64bit DDR总线，每时钟周期2 GHz × 2次访问）<br>21.6 GB/s 前端总线（上下行各10.8 GB/s）<br>1 GB/s 南桥带宽（上下行各500 MB/s）</td>
</tr>
</tbody></table>
<hr>
<h4 id="第二代Xbox-360"><a href="#第二代Xbox-360" class="headerlink" title="第二代Xbox 360"></a>第二代Xbox 360</h4><h5 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h5><p>Xbox 360游戏机是Xbox旗下的第二代游戏机产品。2005年11月，先于Wii问世。2008年5月，Xbox 360成为三大平台中最早突破1000万销量的主机，然而仅2个月后，Wii后来居上反超了它。</p>
<img src="/b2f3cb6a/3.jpg" class>

<p>主打体感操作的Wii完全打乱了索尼和微软的经营战略，一度完全主导市场。微软对此采取策略就是“走别人的路，让别人无路可走”，一掷数十亿重金倾力打造了具有颠覆性效果的Kinect系统。成功地分散了市场对于Wii平台的聚焦。Kinect的问世至少缩短了Wii两年以上的生命周期，最终导致任天堂不得不仓促推出WiiU这个先天不足的早产儿。根据微软一贯的作风，我们丝毫不怀疑在2017年即将接踵推出的三款主机中，天蝎的硬件性能会独树一帜，这对于NX来说将陷入尴尬的境地。即便NX搭载了什么标新立异的创意设计，微软也会不惜血本地第一时间据为已有。</p>
<p>2016年4月21日，在问世10年后，微软Xbox 360游戏主机停产。</p>
<p>微软Xbox业务主管菲尔·斯宾塞(Phil Spencer)在博文中宣布，将继续为现有Xbox 360提供硬件和软件支持。Xbox Live服务器将继续供Xbox 360使用，用户依旧可以通过该主机在线对战。微软公司也将继续销售现有的Xbox 360。</p>
<table>
<thead>
<tr>
<th>信息</th>
<th>内容</th>
<th>信息</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>外文名</strong></td>
<td>Xbox 360</td>
<td><strong>画面分辨率</strong></td>
<td>720P</td>
</tr>
<tr>
<td><strong>媒介</strong></td>
<td>DVD/后推出外接的HD DVD播放器</td>
<td><strong>颜色</strong></td>
<td>黑色/白色（另有定制颜色）</td>
</tr>
<tr>
<td><strong>上市日期</strong></td>
<td>2005年11月22日</td>
<td><strong>停产时间</strong></td>
<td>2016年4月21日</td>
</tr>
</tbody></table>
<hr>
<h5 id="硬件规格-1"><a href="#硬件规格-1" class="headerlink" title="硬件规格"></a>硬件规格</h5><table>
<thead>
<tr>
<th>项目</th>
<th>参数</th>
</tr>
</thead>
<tbody><tr>
<td><strong>中央处理器CPU</strong></td>
<td>CPU 是 3.2 GHz 名为 Xenon，是一个基于IBM的PowerPC的三核设计<br>65纳米制程，1.65亿个晶体管<br>拥有三个对称核心，每个核心都支持SMT，运行频率为3.2 GHz<br>每核心都拥有一个VMX-128 单指令流多数据流(SIMD)单元<br>每个VMX单元拥有128×128位的寄存器（Register）<br>1 MB 二级缓存 (可以由GPU锁定)</td>
</tr>
<tr>
<td><strong>视频处理芯片GPU</strong></td>
<td>Xbox360*GPU是基于ATI R500修改而成的”Xenos”<br>500 MHz运行频率GPU (90纳米制程，2.32亿个晶体管)</td>
</tr>
<tr>
<td><strong>着色性能</strong></td>
<td>每秒处理480亿个着色命令，每个时钟周期处理16个已过滤和16个未过滤的贴图</td>
</tr>
<tr>
<td>多边形最大处理性能</td>
<td>每秒5亿个三角形</td>
</tr>
<tr>
<td><strong>像素填充</strong></td>
<td>在4倍多次采样抗锯齿(MSAA)情况下每秒160亿个</td>
</tr>
<tr>
<td><strong>粒子能力</strong></td>
<td>最大理论值每秒0.96亿，与CPU协作时最大理论值为3.36亿</td>
</tr>
<tr>
<td></td>
<td>500 MHz 10MB 内嵌DRAM缓存 (90纳米制程，1.05亿个晶体管) (现主要为65纳米制程)</td>
</tr>
<tr>
<td></td>
<td>NEC设计的eDRAM有处理彩色、阿尔法混合(Alpha Blending)、Z轴/模板缓存(Zbuffer)、抗锯齿(Anti-alias)的逻辑功能</td>
</tr>
<tr>
<td></td>
<td>48路并联浮点动态着色管线，由于是统一著色结构，所以顶点及像素命令皆可处理</td>
</tr>
<tr>
<td></td>
<td>每条管线拥有4个逻辑运算单元用以处理顶点或像素着色命令</td>
</tr>
<tr>
<td></td>
<td>统一着色运算架构（这代表每条管线都能够运算像素或顶点着色命令）</td>
</tr>
<tr>
<td></td>
<td>支持DirectX 9.0的3.0着色模式，对有DirectX 10着色模式实现有限度支持</td>
</tr>
<tr>
<td></td>
<td>每个时钟周期可以处理两个着色命令</td>
</tr>
<tr>
<td></td>
<td>通过所有着色管线并联每个时钟周期一共可以处理96个着色命令</td>
</tr>
<tr>
<td><strong>记忆体</strong></td>
<td>512MB GDDR3RAM内存<br>700 MHz DDR<br>共享内存架构（UMA）</td>
</tr>
<tr>
<td><strong>系统带宽</strong></td>
<td>22.4 GB/s 记忆体总线界面 (基于128 bit位宽总线，每时钟周期700 MHz × 2次访问 (每波峰一次))<br>256 GB/s eDRAM逻辑内部到eDRAM内部记忆体带宽<br>32 GB/s GPU到eDRAM带宽(基于64bit DDR总线，每时钟周期2 GHz × 2次访问)<br>21.6 GB/s 前端总线(上下行各10.8 GB/s)<br>1 GB/s 南桥带宽(上下行各500 MB/s)</td>
</tr>
</tbody></table>
<hr>
<h5 id="型号"><a href="#型号" class="headerlink" title="型号"></a>型号</h5><p>2005-11-22<br>发售精简版 (Core)：白色 / 无硬盘 / 主板代号 Xenon（现已停产）</p>
<p>2005-11-22<br>发售豪华版 (Premium)：白色 / 20 GB 硬盘 / 主板代号 Xenon （现已停产）</p>
<p>2007-03-27<br>公布精英版 (Elite)：黑色 / 120GB 硬盘 / HDMI 接口 / 主板代号 Zephyr，2007-4-29 上市（现已停产）</p>
<p>2007-07-11<br>公布 Halo 3 限定版：军绿色 / 20GB 硬盘 / HDMI 接口 / 主板代号 Zephyr，2007-9-25 上市（现已停产）</p>
<p>2007-07-04<br>生产 HDMI 豪华版 (Premium)：白色 / 20GB 硬盘 / HDMI 接口 / 主板代号 Zephyr（现已停产）</p>
<p>2008-10-23<br>发布 Xbox 360 （Arcade)：CPU及GPU均采用65纳米制程.用以代替Xbox 360 Core版 白色 / 包括主机 / 手柄 / 256MB内置储存 / 标准AV连接线 / Xbox LIVE银卡服务会员（现已停产）</p>
<p>2010-06-14<br>发布纤体版 Xbox 360 (Xbox 360 Slim)：黑色/ 250G内置硬盘/ HDMI接口（现已停产）</p>
<p>2013-03-01<br>发布 Xbox 360 E：黑色/250G内置硬盘/HDMI接口 外观改变，更轻、更薄，配置与 Xbox360 Slim 相同，2013-06-11 上市（现已停产）</p>
<hr>
<h4 id="第三代Xbox-One"><a href="#第三代Xbox-One" class="headerlink" title="第三代Xbox One"></a>第三代Xbox One</h4><h5 id="Xbox-One"><a href="#Xbox-One" class="headerlink" title="Xbox One"></a>Xbox One</h5><h6 id="介绍-2"><a href="#介绍-2" class="headerlink" title="介绍"></a>介绍</h6><p>Xbox One游戏机是Xbox旗下的第三代游戏机产品。于2013年11月22日在美国、欧洲等13个国家发售。2014年9月4日在日本发售。初代机型已停产，有Xbox One S和Xbox One X两款机型。</p>
<p>2018年9月，微软在Xbox官网正式宣布，对Xbox One连接键鼠外设的支持会向部分Insider会员率先开放</p>
<table>
<thead>
<tr>
<th>信息</th>
<th>内容</th>
<th>信息</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>外文名</strong></td>
<td>Xbox One</td>
<td><strong>美国发售日</strong></td>
<td>2013年11月22日</td>
</tr>
<tr>
<td><strong>颜色</strong></td>
<td>白色、黑色、特别版颜色</td>
<td><strong>国行发售日</strong></td>
<td>2014年9月29日</td>
</tr>
<tr>
<td><strong>媒介</strong></td>
<td>蓝光DVD、数字</td>
<td><strong>网络</strong></td>
<td>Xbox Live</td>
</tr>
<tr>
<td><strong>视频输出</strong></td>
<td>HDMI</td>
<td><strong>更多机型</strong></td>
<td>Xbox One S / Xbox One X</td>
</tr>
<tr>
<td><strong>处理器</strong></td>
<td>AMD APU</td>
<td><strong>硬盘</strong></td>
<td>500GB / 1TB</td>
</tr>
</tbody></table>
<img src="/b2f3cb6a/4.jpg" class>

<hr>
<h6 id="硬件规格-2"><a href="#硬件规格-2" class="headerlink" title="硬件规格"></a>硬件规格</h6><table>
<thead>
<tr>
<th>项目</th>
<th>参数</th>
</tr>
</thead>
<tbody><tr>
<td><strong>CPU</strong></td>
<td>AMD APU处理器 8核X86~0.1T/s 浮点运算能力</td>
</tr>
<tr>
<td><strong>GPU</strong></td>
<td>1.31T/s 浮点运算能力 32MB ESRAM 支持DX12</td>
</tr>
<tr>
<td><strong>共享内存</strong></td>
<td>DDR3 8GB</td>
</tr>
<tr>
<td><strong>硬盘容量</strong></td>
<td>500GB /1000GB</td>
</tr>
<tr>
<td><strong>网络功能</strong></td>
<td>10/100/1000Mbps Ethernet，3x 802.11n radios w/Wi-Fi 支持手柄直接连接</td>
</tr>
<tr>
<td><strong>音频特性</strong></td>
<td>杜比5.1ch 杜比7.1ch</td>
</tr>
<tr>
<td><strong>体感控制</strong></td>
<td>Kinect2.0：内置新麦克风，嘈杂的房间也能经过噪声隔离出用户的声音<br>支持 30FPS 的 1080P 影片录制<br>手势控制也比之前更精确、更灵敏、更直观<br>Kinect：主机内置，包括一个250万像素的红外线深度感应器和720p摄像头</td>
</tr>
<tr>
<td><strong>手柄</strong></td>
<td>新方向键<br>新摇杆<br>新的振动模块<br>Xbox 键的位置挪到了手柄的上方<br>START 和 SELECT 按键标符做了改变<br>精度和控制灵敏度大大增加<br>后期支持编程，玩家支持自定义输入</td>
</tr>
<tr>
<td><strong>接口</strong></td>
<td>HDMI输入接口，HDMI输出接口，3×USB3.0接口，IR额外端口</td>
</tr>
<tr>
<td><strong>屏幕</strong></td>
<td>HDMI输入输出支持4K视频</td>
</tr>
<tr>
<td><strong>产品尺寸</strong></td>
<td>雾面和亮面的设计结合，形状宽高比为 16:9</td>
</tr>
</tbody></table>
<img src="/b2f3cb6a/8.jpg" class>

<hr>
<h5 id="Xbox-One-S"><a href="#Xbox-One-S" class="headerlink" title="Xbox One S"></a>Xbox One S</h5><p>2016年6月13日，微软举行E3游戏大展的新闻发布会，发布一款更小、更轻薄的Xbox One。</p>
<p>2016年7月，微软公布了500GB和1TB两个版本的 Xbox One S 于8月23日发售，并开始接受预购，与之一同的还有两个同捆套装。</p>
<p>Xbox One S游戏机作为Xbox One游戏机的升级版于2016年8月2日发售。Xbox One S在包括美国在内的部分地区发售，并在随后扩展到包括中国大陆的更多区域。</p>
<p>Xbox One S 它比初版 Xbox One 更小、更薄，体积缩小了40%，并采用了电源内置设计，在内部集成了电源供应模块。此外，Xbox One S 的游戏与 Xbox One 完全兼容。除了尺寸更小外，对应的配置清单还显示，这款新游戏机将支持4K视频、HDR和2TB存储内存——比现有的最高配Xbox One多出一倍。</p>
<p>Xbox One S 支持4k蓝光碟，同时首次支持4K视频播放，支持HDR游戏特性。同时Xbox One S还配套了全新的蓝牙手柄，连接范围更广。能使得支持的视频以及游戏呈现更丰富的明暗和色彩细节，首批支持 HDR 的 Xbox One 游戏包括《战争机器4》、《极限竞速：地平线3》等。</p>
<p>2TB版Xbox One S售价399美元（约合人民币2626元），500GB版本售价299美元（约合人民币1968元），1TB版本售价349美元（约合人民币2297元）。</p>
<table>
<thead>
<tr>
<th>信息</th>
<th>内容</th>
<th>信息</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>中文名</strong></td>
<td>微软游戏盒子</td>
<td><strong>曝光时间</strong></td>
<td>2016年6月13日</td>
</tr>
<tr>
<td><strong>外文名</strong></td>
<td>Xbox One S</td>
<td><strong>特点</strong></td>
<td>比第一代Xbox One更小、更轻薄</td>
</tr>
<tr>
<td><strong>发布</strong></td>
<td>Microsoft（微软）</td>
<td><strong>首发时间</strong></td>
<td>2016年8月2日</td>
</tr>
</tbody></table>
<img src="/b2f3cb6a/5.jpg" class>

<hr>
<h5 id="Xbox-One-S-青春版"><a href="#Xbox-One-S-青春版" class="headerlink" title="Xbox One S 青春版"></a>Xbox One S 青春版</h5><p>2019年，Xbox One S青春版发售。与Xbox One S不同的是，Xbox One S青春版没有光驱，价格更低廉。</p>
<img src="/b2f3cb6a/9.jpg" class>

<p>2020年7月20日停产。</p>
<hr>
<h5 id="Xbox-One-X"><a href="#Xbox-One-X" class="headerlink" title="Xbox One X"></a>Xbox One X</h5><p>Xbox One X 天蝎限量版于10月19日零点正式在微软官方商城开启预售，售价3999元。</p>
<p>Xbox One X 主机于2017年11月7日全球同步上市，国行版售价3999元。</p>
<p>“Project Scorpio”是一个改进版的、高性能Xbox One控制台，旨在为用户带来更华丽、更流畅的游戏体验。同时，“Project Scorpio”还会支持更多视觉上的改进，例如原生4K和60帧每秒的性能，使得游戏看起来更加真实。</p>
<p>Xbox one X兼容Xbox原机所有的游戏，并在游戏画面表现方面呈现出更真实的效果。为了配合Xbox one X的发售，微软重置部分Xbox 1代游戏。</p>
<p>2020年7月20日，微软宣布 XBOX ONE X 和 XBOX ONE S 数字版停产，XBOX ONE S会继续生产销售。</p>
<img src="/b2f3cb6a/6.jpg" class>

<h6 id="硬件规格-3"><a href="#硬件规格-3" class="headerlink" title="硬件规格"></a>硬件规格</h6><p>Xbox one x拥有6T/s浮点运算能力，12GB共享显存，326GB/s显存带宽，并支持原生4K游戏。此外，Xbox One X还是第一个配备水冷系统的主机，蒸发舱可以确保运行期间的清凉恒温。</p>
<hr>
<h4 id="第四代Xbox-Series"><a href="#第四代Xbox-Series" class="headerlink" title="第四代Xbox Series"></a>第四代Xbox Series</h4><p>Xbox Series X/S游戏机是Xbox旗下的第四代游戏机产品，首次于2019年12月13日在The Game Awards上公布，并宣布在2020年假日期间发售。</p>
<p>微软国行版Xbox Series X/S新世代主机于2021年6月10日零点正式开售。国行版 Xbox Series X 的售价为 3899 元。</p>
<h5 id="Xbox-Series-S"><a href="#Xbox-Series-S" class="headerlink" title="Xbox Series S"></a>Xbox Series S</h5><h6 id="介绍-3"><a href="#介绍-3" class="headerlink" title="介绍"></a>介绍</h6><p>Xbox Series S定价为299美元，体积比Xbox Series X小60%，是迄今为止最小的Xbox主机。游戏机采用定制512GB NVMe SSD，1440P下可达120 FPS，并支持光线追踪、可变速率着色和可变刷新频率。</p>
<p>2021年9月微软宣布，Xbox Series S 主机已正式支持杜比视界游戏，玩家将获得全面提升的视觉体验。</p>
<img src="/b2f3cb6a/10.jpg" class>

<h6 id="硬件规格-4"><a href="#硬件规格-4" class="headerlink" title="硬件规格"></a>硬件规格</h6><table>
<thead>
<tr>
<th>项目</th>
<th>参数</th>
</tr>
</thead>
<tbody><tr>
<td><strong>CPU</strong></td>
<td>定制版AMD Zen 2微架构<br>8核心<br>时钟频率3.6 GHz（当使用同时多线程时3.4 GHz）</td>
</tr>
<tr>
<td><strong>GPU</strong></td>
<td>20计算单元<br>时钟频率1.565 GHz<br>单精度浮点数运算速度4 TFLOPS</td>
</tr>
<tr>
<td><strong>制程</strong></td>
<td>台积电7 nm Enhanced</td>
</tr>
<tr>
<td><strong>裸片面积</strong></td>
<td>197.05mm2</td>
</tr>
<tr>
<td><strong>内存</strong></td>
<td>10 GB GDDR6<br>内存总线宽度128位</td>
</tr>
<tr>
<td><strong>内存带宽</strong></td>
<td>8GB @ 224 GB/s<br>2GB @ 56 GB/s</td>
</tr>
<tr>
<td><strong>存储</strong></td>
<td>定制版512GB NVMe固态硬盘</td>
</tr>
<tr>
<td><strong>I/O吞吐量</strong></td>
<td>2.4 GB/s (原始数据)<br>4.8 GB/s (压缩数据，使用定制硬件解压缩)</td>
</tr>
<tr>
<td><strong>可扩展存储</strong></td>
<td>支持1 TB希捷扩展卡（与内部存储容量一致）<br>支持USB 3.1外接硬盘驱动器</td>
</tr>
<tr>
<td><strong>性能目标</strong></td>
<td>1440p 120fps</td>
</tr>
<tr>
<td><strong>尺寸</strong></td>
<td>6.5 cm x 15.1 cm x 27.5 cm</td>
</tr>
<tr>
<td><strong>重量</strong></td>
<td>4.25磅</td>
</tr>
</tbody></table>
<hr>
<h5 id="Xbox-Series-X"><a href="#Xbox-Series-X" class="headerlink" title="Xbox Series X"></a>Xbox Series X</h5><h6 id="介绍-4"><a href="#介绍-4" class="headerlink" title="介绍"></a>介绍</h6><p>Xbox Series X是一款由微软研发并推出的家用电子游戏机。产品接替Xbox One，属于Xbox系列游戏机的第四代。其最初于2019年E3游戏展上以研发代号Project Scarlett公开，后于2019年The Game Awards颁奖典礼上公布正式名称，并计划于2020年11月10日发售。</p>
<p>产品外观设计采用黑色长方体造型，内部搭载了拥有12 TFLOPS单精度浮点数运算速度的定制版AMD处理器、GDDR6内存和NVMe固态硬盘。</p>
<p>2021年9月微软宣布，Xbox Series X主机已正式支持杜比视界游戏，玩家将获得全面提升的视觉体验。</p>
<table>
<thead>
<tr>
<th>信息</th>
<th>内容</th>
<th>信息</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>外文名</strong></td>
<td>Xbox Series X</td>
<td><strong>前一代产品</strong></td>
<td>Xbox One（包括Xbox One X和Xbox One S）</td>
</tr>
<tr>
<td><strong>上市时间</strong></td>
<td>2020年11月10日</td>
<td><strong>同代产品</strong></td>
<td>Xbox Series S</td>
</tr>
<tr>
<td><strong>研发代号</strong></td>
<td>Project Scarlett</td>
<td><strong>简称</strong></td>
<td>XSX</td>
</tr>
</tbody></table>
<img src="/b2f3cb6a/7.jpg" class>

<h6 id="新功能特性"><a href="#新功能特性" class="headerlink" title="新功能特性"></a>新功能特性</h6><ul>
<li><p>可变速率着色（VRS）</p>
<p>Xbox Series X正在使用“VRS的专利形式，使开发人员能够更有效地利用Xbox Series X的全部功能”。与其将GPU周期均匀地花费在屏幕上每个像素上，不如将GPU对特定游戏角色或重要环境对象的各个效果进行优先排序。此技术可实现更稳定的帧速率和更高的分辨率，而不会影响最终图像质量。<br>VRS是一项新技术，已被证明可以渲染出更清晰的图像，而对硬件的性能影响较小。</p>
</li>
<li><p>硬件加速的DirectX光线跟踪</p>
<p>你可以期待由硬件加速的DirectX光线追踪支持的更动态、更逼真的环境，这是主机游戏的第一次尝试。这意味着你在探索游戏世界时会实时获得逼真的照明、准确的反射和逼真的声音。<br>微软在使光线追踪与Direct X 12兼容方面的工作对于PC游戏玩家来说至关重要，但是主机游戏玩家将可以从中受益。</p>
</li>
<li><p>快速恢复</p>
<p>新的“快速恢复”功能使你几乎可以在暂停状态下继续进行多个游戏，而无需等待很长的加载屏幕时间，就可以将自己返回到原处和所从事的状态。</p>
</li>
<li><p>动态延迟输入（DLI）</p>
<p>Xbox正在从Xbox无线控制手柄开始优化玩家到控制主机管道中的延迟，Xbox无线控制器在连接到控制主机时会利用高带宽专有无线通信协议。动态延迟输入（DLI）是一项新功能，可将输入立即与显示的内容同步，控件更加精确和响应迅速。</p>
</li>
<li><p>HDMI 2.1创新</p>
<p>Xbox已与HDMI论坛和电视制造商合作，通过自动低延迟模式（ALLM）和可变刷新率（VRR）等功能实现最佳游戏体验。ALLM允许Xbox One和Xbox Series X自动将连接的显示器设置为最低延迟模式。VRR将显示器的刷新率与游戏的帧率同步，从而保持流畅的视觉效果而不会撕裂。确保最小的延迟和最及时的游戏体验。</p>
</li>
<li><p>120 fps支持</p>
<p>Xbox Series X支持高达120 fps帧率，使开发人员可以超过标准的60 fps输出，从而支持增强的真实感或快节奏的动作。</p>
</li>
<li><p>智能分配</p>
<p>这项技术使你能够一次购买一款游戏，并且明白无论你是在Xbox One还是Xbox Series X上玩游戏-不论你使用哪种Xbox，都可以得到该游戏的正确版本。Xbox承诺在所有独家Xbox Game Studios游戏作品（包括Halo Infinite）上使用Smart Delivery，以确保你只需要购买一次，即可为他们选择在任何Xbox主机畅玩最佳的可用版本。这项技术适用于所有开发人员和发行商，他们可以选择将其先用于Xbox One上发行，然后再在Xbox Series X上发行推广。</p>
</li>
</ul>
<h6 id="硬件规格-5"><a href="#硬件规格-5" class="headerlink" title="硬件规格"></a>硬件规格</h6><p>2020年3月16日，微软公布了Xbox Series X的详细规格参数。对比前一代产品Xbox One X，产品的CPU和GPU分别提供了4倍和2倍的性能，并在Xbox系列中首次搭载了NVMe固态硬盘。接口上，产品取消了HDMI输入端口和S/PDIF音频端口。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>参数</th>
</tr>
</thead>
<tbody><tr>
<td>CPU**</td>
<td>定制版AMD Zen 2微架构<br>AMD64指令集<br>8核心<br>时钟频率3.8 GHz （当使用同时多线程时3.6 GHz）</td>
</tr>
<tr>
<td>GPU**</td>
<td>定制版AMD RDNA 2微架构<br>52计算单元<br>时钟频率1.825 GHz<br>单精度浮点数运算速度12.155 TFLOPS</td>
</tr>
<tr>
<td><strong>晶体管数</strong></td>
<td>153亿（SoC包括CPU和GPU）</td>
</tr>
<tr>
<td><strong>裸片面积</strong></td>
<td>360.45 mm2</td>
</tr>
<tr>
<td><strong>制程</strong></td>
<td>台积电7 nm Enhanced（N7P）</td>
</tr>
<tr>
<td><strong>内存</strong></td>
<td>16 GB GDDR6 SDRAM<br>内存总线宽度320位</td>
</tr>
<tr>
<td><strong>内存带宽</strong></td>
<td>10 GB @ 560 GB/s<br>6 GB @ 336 GB/s</td>
</tr>
<tr>
<td><strong>存储</strong></td>
<td>定制版希捷1 TB PCIe 4.0 NVMe固态硬盘</td>
</tr>
<tr>
<td><strong>可扩展存储</strong></td>
<td>1 TB扩展卡</td>
</tr>
<tr>
<td><strong>I/O吞吐量</strong></td>
<td>2.4 GB/s（原始数据）<br>4.8 GB/s（用定制硬件压缩块压缩数据）</td>
</tr>
<tr>
<td><strong>外接存储</strong></td>
<td>支持USB 3.2外接硬盘</td>
</tr>
<tr>
<td><strong>光驱</strong></td>
<td>4K UHD蓝光光驱</td>
</tr>
<tr>
<td><strong>性能目标</strong></td>
<td>4K @ 60 FPS（最高120 FPS）</td>
</tr>
<tr>
<td><strong>电源供应</strong></td>
<td>315 W</td>
</tr>
<tr>
<td><strong>尺寸</strong></td>
<td>15.1 cm x 15.1 cm x 30.1 cm</td>
</tr>
<tr>
<td><strong>重量</strong></td>
<td>4.45 kg</td>
</tr>
<tr>
<td><strong>接口</strong></td>
<td>1个HDMI 2.1视频输出接口<br>3个USB 3.2 Type-A接口<br>1个RJ-45网络接口<br>1个扩展卡槽接口<br>1个IEC 60320 C7电源输入接口<br>1个Kensington锁槽</td>
</tr>
</tbody></table>
<hr>
<h3 id="软件与服务"><a href="#软件与服务" class="headerlink" title="软件与服务"></a>软件与服务</h3><h4 id="线上服务"><a href="#线上服务" class="headerlink" title="线上服务"></a>线上服务</h4><p>Xbox Live是游戏线上服务，于2002年启动。是原版Xbox主机的配套网络服务，并为后来的Xbox 360, Xbox One，PC和移动平台的微软游戏服务。Xbox Live总体分为两部分，第一部分为“银会员(Xbox Live Silver)”。玩家只要注册Xbox Live就可免费享有。现阶段，银会员可让玩家查看游戏成就、分数、好友在线状态和云存档等功能。在银会员的基础上，如果玩家每月订阅金会员（Xbox Live Gold），则可进行多人对战或联机合作战役。</p>
<h4 id="内容订阅服务"><a href="#内容订阅服务" class="headerlink" title="内容订阅服务"></a>内容订阅服务</h4><p>Xbox Game Pass是内容订阅服务，玩家每月需支付一定月费，可无限游玩Xbox平台上超过100款不同类型的游戏，每个月都会新增新游戏。Xbox Game Pass高级会员（Xbox Game Pass Ultimate）服务同时包含Xbox Game Pass和Xbox Live会员服务。</p>
<h4 id="游戏制作与发行"><a href="#游戏制作与发行" class="headerlink" title="游戏制作与发行"></a>游戏制作与发行</h4><p>Xbox Game Studios是负责游戏发行与制作的工作室，原名Microsoft Studios，包含13个创作团队。</p>
<h4 id="游戏串流服务"><a href="#游戏串流服务" class="headerlink" title="游戏串流服务"></a>游戏串流服务</h4><p>Xbox Game Streaming是游戏串流服务，并提供两种串流方式。Project xCloud可以从云端服务器进行串流。Xbox Console Streaming可以从用户的主机串流。</p>
<hr>
<h3 id="Xbox各代性能"><a href="#Xbox各代性能" class="headerlink" title="Xbox各代性能"></a>Xbox各代性能</h3><p>近期IGN专门做了Xbox家族的性能进化史，为大家展现了Xbox主机在性能方面的变化。从给出的进化史来看，Xbox Series X的性能相当于2061.7台初代Xbox，性能可谓突飞猛进。</p>
<p>提升最明显的莫过于第二代。Xbox 360的性能相当于41.3个第一代Xbox，如此强大的性能提升在后来再也没有发生过，或许是因为微软在开发第一代时并没有太多经验。</p>
<img src="/b2f3cb6a/11.jpg" class>

<p>Xbox 360的性能相当于41.3个第一代Xbox</p>
<img src="/b2f3cb6a/12.jpg" class>

<p>Xbox One相当于5.45台Xbox 360</p>
<img src="/b2f3cb6a/13.jpg" class>

<p>Xbox One X相当于4.58台Xbox One</p>
<img src="/b2f3cb6a/14.jpg" class>

<p>Xbox Series X相当于2台Xbox One X</p>
<p>此后性能提升越来越缓慢，Xbox One相当于5.45台Xbox 360，Xbox One X相当于4.58台Xbox One，Xbox Series X相当于2台Xbox One X。虽然性能提升放缓，但Xbox Series X的性能已经足够强悍，已经可以提供4K 90帧游戏体验。</p>
<hr>
<h3 id="2021年购买指南"><a href="#2021年购买指南" class="headerlink" title="2021年购买指南"></a>2021年购买指南</h3><p><strong>Q：考虑Play Station系列和Xbox系列</strong></p>
<ol>
<li><p>是否需要玩该平台的独占游戏（PS各种日式rpg，Xbox主玩车枪球）</p>
</li>
<li><p>是否是以前玩过觉得好玩，值得买并下定了决心（不冲动购物）</p>
</li>
<li><p>有时间往游戏上砸，并且会玩好久（游戏花钱占大头，替代电脑游戏娱乐）</p>
</li>
</ol>
<p><strong>Q：Xbox不知道买哪个型号</strong></p>
<ol>
<li><p><strong>Xbox One 系列</strong></p>
<p>前世代主机Xbox One系列分为Xbox One、<strong>Xbox One S</strong>（简称为X1S，对比机型为PS4 Slim）、<strong>Xbox One X</strong>（简称X1X，对比机型为PS4 Pro）</p>
</li>
</ol>
<ul>
<li><p><strong>Xbox One S</strong>的目标受众为对画质没有强烈需求，或对价格比较敏感的玩家。<br><strong>优势：</strong>价格实惠，是市面上超值的4K蓝光播放器之一。体积小巧，有国行。<br><strong>劣势：</strong>性能较差，与初代的Xbox One性能相差无几。画面表现在现在看来非常粗糙。<br><strong>指导价：闲鱼1k</strong></p>
</li>
<li><p><strong>Xbox One X</strong>的定位为上世代的最强性能主机，主打4K游戏。<br><strong>优势：</strong>能游玩真4K HDR的主机游戏，大多数游戏的帧数为30帧左右，部分游戏支持到60帧；支持杜比视界，杜比音效。有国行。<br><strong>劣势：</strong>作为上世代主机来说，没有特别明显的短板。体积对比X1S稍大，发热量也会稍大一些。<br>喜欢玩体感游戏的玩家注意，Xbox One为最后一代支持Kinect体感摄像头的系列。<br><strong>指导价：闲鱼1.5k</strong><br>（注：该机型上市时提供了天蝎座限定版,后面大家习惯性的都把这个机型叫做“天蝎座”或者“Xbox天蝎座”）</p>
</li>
</ul>
<ol start="2">
<li><p><strong>Xbox Series 系列</strong></p>
<p>然后是本世代主机Xbox Series系列，分为Xbox Series S（下面简称为XSS），以及Xbox Series X（下面简称为XSX）。<br>本世代开始微软取消了体感摄像头的支持，Xbox One系列上的大多数体感游戏也无法在本世代运行。</p>
</li>
</ol>
<ul>
<li><p><strong>Xbox Series S</strong>的定位适合非电视玩家、学生党以及对于画面没有极致要求的玩家。也非常适合用在卧室电视或者书房显示器作为家里的第二台主机。主打功能为2K\120帧。<br><strong>优势：</strong>价格实惠，外观体积非常美观轻巧。适合没有电视或者用游戏显示器玩游戏的玩家。该机型同样支持4K游戏，但帧数与上世代的X1X相比没有本质的提升。<br><strong>劣势：</strong>XSS为纯数字主机 所有游戏只能通过下载安装运行，不支持光碟游戏，所以也不能作为4K蓝光播放器使用。<br><strong>指导价：闲鱼1.8k~2k，全新2.5k+</strong></p>
</li>
<li><p><strong>Xbox Series X</strong>成为本世代最强性能主机。<br>最高支持到8K分辨率、4KHDR 120帧（经过测试目前应该只有微软自家的游戏《Ori》支持到最高6K 60帧/4K 120帧）。8K游戏目前应该是还没有推出，毕竟是本世代的开端，大家还可以继续期待。<br><strong>优势：</strong>进一步改善散热功能，而且硬盘由原来的机械硬盘也提升到了固态硬盘，系统的响应速度，开机速度，以及游戏的读取速度对比上一代的X1X有数倍的提升。同时支持了快速恢复功能，在支持的游戏安装在内部硬盘的情况下，可以供两个游戏之间的快速切换，无需重启游戏——甚至关闭主机后开机也能迅速恢复。<br><strong>劣势：</strong>在现在大作经常上到100G左右的世代下，XSX依然配备一块1TB的硬盘。除去系统占用后，安装几个大作后基本就捉襟见肘了。（不过微软提供了扩展卡功能，现在只有1Tb版本，某电商平台上价格从1600-1800不等，有条件的可以考虑官方扩展，想经济实惠一点的话外置固态硬盘是个不错的选择。但是装在外置硬盘里面的游戏会失去前面提到的快速恢复功能，并且读取速度和内置硬盘还是有些差距的。）<br><strong>指导价：闲鱼4.3k~4.5k，全新5k+</strong></p>
</li>
</ul>
<hr>
<h3 id="额外阅读补充"><a href="#额外阅读补充" class="headerlink" title="额外阅读补充"></a>额外阅读补充</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/113894827">https://zhuanlan.zhihu.com/p/113894827</a><br><a href="https://zhuanlan.zhihu.com/p/368121388">https://zhuanlan.zhihu.com/p/368121388</a></p>
</blockquote>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://baike.baidu.com/item/Xbox/19680933">https://baike.baidu.com/item/Xbox/19680933</a><br><a href="https://baike.baidu.com/item/Xbox/277794">https://baike.baidu.com/item/Xbox/277794</a><br><a href="https://baike.baidu.com/item/Xbox%20360">https://baike.baidu.com/item/Xbox%20360</a><br><a href="https://baike.baidu.com/item/Xbox%20One">https://baike.baidu.com/item/Xbox%20One</a><br><a href="https://baike.baidu.com/item/Xbox%20One%20X">https://baike.baidu.com/item/Xbox%20One%20X</a><br><a href="https://baike.baidu.com/item/Xbox%20Series%20S">https://baike.baidu.com/item/Xbox%20Series%20S</a><br><a href="https://baike.baidu.com/item/Xbox%20Series%20X">https://baike.baidu.com/item/Xbox%20Series%20X</a><br><a href="https://baijiahao.baidu.com/s?id=1659547749133897297">https://baijiahao.baidu.com/s?id=1659547749133897297</a><br><a href="https://www.zhihu.com/question/397265098/answer/1526470427">https://www.zhihu.com/question/397265098/answer/1526470427</a><br><a href="https://www.bilibili.com/read/cv10705828">https://www.bilibili.com/read/cv10705828</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-脑机接口技术发展新趋势—基于2019—2020年研究进展</title>
    <url>/91549d43.html</url>
    <content><![CDATA[<p>脑机接口（BCI）技术通过直接从大脑信号中实时解码用户意图来为辅助设备提供丰富、强大的命令信号。近年来，脑机接口技术的理论和实际应用的研究进展迅速，技术日趋成熟，其应用领域在不断扩大，发展趋势呈良好态。</p>
<span id="more"></span>

<hr>
<h3 id="应用系统实现"><a href="#应用系统实现" class="headerlink" title="应用系统实现"></a>应用系统实现</h3><h4 id="沟通交流"><a href="#沟通交流" class="headerlink" title="沟通交流"></a>沟通交流</h4><p>语音解码类脑机接口技术能够将神经活动直接转换为语音信号，对由于神经功能障碍而无法正常交流的群体具有革命性的意义。2019年4月， 加州大学旧金山分校的研究团队基于脑机接口技术设计了一种新型的神经解码器，该解码器能够通过提取大脑皮层活动对发声器官的运动情况来实现语音的合成。即使受试者不发出声音读句子，解码器也能实现语音合成。同年7月，该研究团队展示了基于高密度ECoG信号的模拟自然问答对话系统。利用在对话中记录下的脑信号，能够确定受试者何时在听、说，且能够预测所听、说的是什么，这一技术对于无法交流的患者具有重要意义。</p>
<img src="/91549d43/1.jpg" class>

<p>除上述提及的侵入式脑机接口实现语言交流功能外，非侵入式脑机接口在此方面也展现出较大潜力。2019年4月，在《挑战不可能》节目中，清华大学研究团队展示了一套脑机接口打字输入系统，该系统展示了帮助渐冻症群体重拾交流能力的潜力。</p>
<h4 id="触觉和运动恢复"><a href="#触觉和运动恢复" class="headerlink" title="触觉和运动恢复"></a>触觉和运动恢复</h4><p>美国巴特尔纪念研究所及合作研究团队从初级运动皮层活动反映的运动意图中提取出患者残余的、无法被患者知觉感知的手部触觉信号，并将该信号进行增强后反馈给患者，从而实现皮层内控制的闭环感觉反馈，并可通过触摸信号调节握力，以实现触觉和运动功能的同时恢复。这项研究表明，脑机接口可以从大脑皮层采集低于知觉反应范围的神经号，并将其转换为有意识的知觉，从而显著增强功能。</p>
<h4 id="运动控制"><a href="#运动控制" class="headerlink" title="运动控制"></a>运动控制</h4><p>卡耐基梅隆大学和明尼苏达大学的研究人员提出了非入侵式脑机接口的机械臂控制。基于头皮脑电，通过连续的追踪任务和相关的训练范式增加用户的参与度，显著改善了基于脑电的神经解码效率，且允许用户对机械臂实现高分辨率控制，实现对连续随机运动目标的实时跟踪。这种高质量的神经解码能力与非侵入式机械臂控制的实际应用相结合，将对利用非侵入式脑机接口开发和实现神经机器人技术产生重大影响。</p>
<img src="/91549d43/2.png" class>

<p>2020年1月，浙江大学研究团队也实现了国内第一例植入式脑机接口临床研究。植入电极后，患者可以利用大脑运动皮层信号精准控制外部机械臂与机械手实现三维空间的运动，首次证明高龄患者利用植入式脑机接口进行复杂而有效的运动控制的可行性。</p>
<hr>
<h3 id="关键技术进展"><a href="#关键技术进展" class="headerlink" title="关键技术进展"></a>关键技术进展</h3><h4 id="新硬件"><a href="#新硬件" class="headerlink" title="新硬件"></a>新硬件</h4><p>脑机接口的硬件主要涉及电极和信号采集系统。对于侵入式脑机接口而言，需要具有生物相容性、安全性和长期植入的材料特性的电极；非侵入式脑机接口则倾向于舒适、便携的信号获取方式。</p>
<p>2019年，Elon Musk的Neuralink 公司发布了一款可扩展的高带宽脑机接口系统。该系统包含小而灵活的电极“线”阵列，每个阵列共分布3072个电极。该系统还包含一个神经外科手术机器人，该机器人每分钟可以插入6根线。电极阵列被封装在一个小的可植入设备中，3072个通道封装所占面积小于23mm × 18.5mm × 2mm。一根USB-C电缆可提供设备的全带宽数据流传输，并记录所有数据。相较于传统的样机往往较为简陋，未实现工程上的充分优化，Neuralink提出的这一套高度集成化、自动化的脑机接口系统展示了工业界的关注对脑机接口实用化进程的重大意义。</p>
<img src="/91549d43/3.png" class>

<p>英国诺丁汉大学及合作研究团队开发了一种基于自行车头盔改造且完全符合生命周期的可穿戴脑磁系统，该系统能够为所有年龄段的受试者提供高保真数据，且无需限制受试者的活动。因此可以使用单一系统测量儿童、成人在外部环境中大脑如何做出反应并适应自然事件的能力。</p>
<img src="/91549d43/4.png" class>

<p>佐治亚理工学院及合作研究团队报道了一个完全便携式、无线、灵活的头皮电子系统，其中包括一组干电极和一个柔性膜电路。相比于商用系统，柔性电子产品因显著降低噪声和电磁干扰能够提高诱发电位检测性能。两通道的头皮电子系统获得了122.1 bit/min的信息传输率，允许对电动轮椅、电动汽车和无键盘演示进行无线、实时和通用的脑电控制。</p>
<img src="/91549d43/5.png" class>

<p>除此之外，丹麦奥尔胡斯大学及合作研究团队开发的一种基于干式接触电极的外耳道脑电采集系统，其性能与靠近耳朵的头皮脑电图性能相当。清华大学及合作研究团队开发的一种高成本效率、易于制造、灵活、鲁棒且无凝胶的银纳米线/聚乙稀醇缩丁醛/三聚氰胺海绵的脑电电极，具有具有高电导率，重量低及卓越的机械稳定性和绕过头发的能力的特性。这一成果显示出该新型电极有望替代脑电采集的常规电极。</p>
<h4 id="新算法"><a href="#新算法" class="headerlink" title="新算法"></a>新算法</h4><p>对侵入式脑机接口而言，脑机接口技术临床应用的关键障碍是植入皮层电极所记录的神经活动会随时间变化。卡内基梅隆大学及合作研究团队利用低维神经流形的对齐，开发了一种基于流形的神经信号稳定器，实现脑机接口信号的稳输入，以解决神经记录的不稳定而导致临床脑机接口无法控制的问题。斯坦福大学及合作研究团队提出一种时间约束的稀疏组空间模式，通过同时优化共空间模式中滤波器频带和时间窗长，实现进一步提高想象运动脑机接口的性能。华中科技大学的研究团队提出了一种新颖的流形嵌入知识迁移方法（MEKT）。该方法可以处理一个或多个源域，并且可以高效地进行计算。针对于大量源域的情况，该团队还提出了域迁移性估计方法（DTE），以识别最有利的源域。实验表明，MEKT优于几种最先进的转移学习方法，并且当源受试者的数量很大时，DTE可以减少一半以上的计算成本，且几乎不会牺牲分类精度。法国Aramis project-team 及合作研究团队提出的一种融合方法，能够整合来自同步脑电和脑磁信号的信息，提高基于运动想象脑机接口的分类性能。</p>
<h4 id="新范式"><a href="#新范式" class="headerlink" title="新范式"></a>新范式</h4><p>斯坦福大学及合作研究团队研究发现面部、头部、手臂和腿部运动在运动皮层“手结区”均具有较好的表征，并存在着将四肢联系起来的神经编码。该研究团队设计了一个脑机接口系统，能够利用“手结区”的信号精确地解码四肢的运动。这一研究成果展示只在一个区域放置植入电极，就可能实现全身的运动控制，大大拓宽颅内脑机接口的应用空间。</p>
<p>多伦多大学及合作研究团队利用近红外光谱成像技术实现了在线三分类想象言语脑机接口。用户可以通过隐式默念短语“是”或“否”来直接回答是或否问题，该接口还能识别无限制休息状态。</p>
<p>匹兹堡大学的研究团队提出了一种基于运动想象的混合脑机接口，它利用脑电图记录脑电活动以及利用功能性经颅多普勒超声测量脑血流速度。与现有的基于EEG和fNIRS的混合脑机接口相比，所构建的系统能够以较短的任务持续时间实现相似或更高的准确率。</p>
<h4 id="新应用"><a href="#新应用" class="headerlink" title="新应用"></a>新应用</h4><p>脑机接口技术已经开始在其他领域发挥价值。</p>
<p>哥伦比亚大学的研究团队展示了一个闭环的脑机接口，该系统基于脑电信号解码器输出的听觉反馈信号，动态地调整个体在执行 bound⁃ ary-avoidance 任务时的唤醒程度，并根据 YerkesDodson 定律（唤醒程度与任务执行是倒U形曲线关系）提高任务执行效率。该方法有望应用于不同的任务或用于将自我调节作为目标治疗的临床应用。</p>
<p>俄罗斯 Neurobotics 和莫斯科物理技术学院的研究团队研究了另一种新颖的闭环脑机接口系统。该系统可利用受试者的脑电特征实时重建受试者观察到的或想象的刺激图像， 并将重建的图像作为视觉反馈呈现给受试者。从而有望用于训练脑机接口的新用户。</p>
<p>中国科学院半导体研究所的研究团队利用编码调制的视觉诱发电位，实现了一套个体身份识别系统。该系统具有高识别性能，有望为个体身份识别提供基于脑电的解决方案。此外，该团队还和清华大学的研究团队利用 room-scale 虚拟现实头盔开发一个便携式稳态视觉诱发电位脑机接口。验证了脑机接口在移动虚拟现实环境中的应用潜力，并为利用移动虚拟现实系统开发实用脑机接口提供了实验和方法的指导。</p>
<hr>
<h3 id="发展趋势与展望"><a href="#发展趋势与展望" class="headerlink" title="发展趋势与展望"></a>发展趋势与展望</h3><h4 id="高性能脑机接口"><a href="#高性能脑机接口" class="headerlink" title="高性能脑机接口"></a>高性能脑机接口</h4><p>尽管近年来脑机接口在性能上获得了较大的提高，但相比于自然的人机交互，目前脑机接口的通信速率仍较低，是限制脑机接口应用的最大障碍。通过脑信号解码技术大幅提高通信速率，在大脑与机器之间建立高效的信息交流通道，是实现高性能脑机接口的关键。目前，如何使用先进算法与大脑进行交互已引起脑机接口研究者的广泛关注。清华大学研究团队发布了基于稳态视觉诱发电位的脑机接口的BETA数据集。该研究具有领域内迄今为止规模最大、测试基准算法最全等特色，为今后研究开发提供了测试平台与数据支撑。同时，世界机器人大赛-BCI脑控机器人大赛也推动了国内脑机接口的算法水平。脑机接口技术的发展离不开领域内学者的共同努力，期待着后续更多跨研究组、跨高校的通力合作。</p>
<img src="/91549d43/6.png" class>

<h4 id="双向脑机接口"><a href="#双向脑机接口" class="headerlink" title="双向脑机接口"></a>双向脑机接口</h4><p>在脑机交互中，信息可以在两个方向上传播： “从脑到机”或“从机到脑”。 目前脑机接口领域的研究仍以 “从脑到机”为主。但近年来，神经调控技术的发展为“从机到脑”提供了可能。调节神经活动将是下一代脑机接口的重要组成部分。匹兹堡大学及合作研究团队展示了通过体感皮层的皮层内微电刺激来恢复触觉感知反馈，使得具有双向脑机接口的受试者能够改善其在由神经控制的假肢完成的功能性物体运输任务中的性能。</p>
<img src="/91549d43/7.png" class>

<h4 id="信息安全"><a href="#信息安全" class="headerlink" title="信息安全"></a>信息安全</h4><p>近年来，与健康相关的物联网设备越来越流行。一方面，用户可以方便了解自身的健康状况信息；另一方面，这些信息也面临新的安全风险。乔治·华盛顿大学及合作研究团队研究了家用脑电系统的安全性，发现NeuroSky App store 中的 156 个脑机接口应用程序都容易受到近程攻击，而且 31 个免费应用程序都容易受到至少一种远程攻击的攻击。考虑到脑活动的高度私密性和重要性，在实现脑机接口应用的过程中，如何对脑活动数据进行有效安全的管理并制定相关标准规范是当下科研界和产业界都必须深入思考的关键一环。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>2019—2020年，脑机接口技术在理论分析、硬件实现、算法改进、场景应用等方面均取得了阶段性的研究进展，对推动脑机接口技术的发展起到了重要的作用。但目前脑机接口仍主要局限于复杂的实验室环境。对于侵入式脑机接口而言，目前仍面临着人体排异反应及颅骨向外传输信息会减损这两大问题；非侵入式脑机接口技术则朝小型化、便携化、可穿戴化及简单易用化方向发展。随着各国对这项技术越来越重视，相信脑机接口技术的爆发未来可期。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.researchgate.net/publication/356375024_naojijiekoujishufazhanxinqushi--jiyu_2019-2020_nianyanjiujinzhan">https://www.researchgate.net/publication/356375024_naojijiekoujishufazhanxinqushi--jiyu_2019-2020_nianyanjiujinzhan</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10828">https://www.scholat.com/teamwork/showPostMessage.html?id=10828</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-GauGAN再升级！只需一句话即可得到逼真画作</title>
    <url>/67450ff6.html</url>
    <content><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>GauGAN是英伟达研发的一款交互型应用，首次亮相于2019年举办的GTC大会上。最初的GauGAN可以实现勾勒简单的线条，然后输出一副细腻的画作。2021年11月，英伟达推出GauGAN2。GauGAN2继承了GauGAN的原有功能，并且结合了分割映射、修复和文本到图像生成等技术。GauGAN2是一个通过输入文字和简单的绘画即可创建高质量图像的应用。</p>
<p>目前，GauGAN2仍在完善阶段，英伟达为感兴趣的用户提供了一个demo地址：<a href="https://www.nvidia.com/en-us/research/ai-demos/">https://www.nvidia.com/en-us/research/ai-demos/</a></p>
<span id="more"></span>

<hr>
<h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p>GauGAN2现有三种主要的生成模式：</p>
<ol>
<li><p>在简笔画的基础上生成</p>
 <img src="/67450ff6/1.png" class>

<p> 只需勾勒出山脉的线条，AI就会生成完整的山脉，并且补充天空、云彩和江河等元素。</p>
</li>
<li><p>在文本的基础上生成</p>
 <img src="/67450ff6/2.png" class>

<p> 这个生成模式是GauGAN2的重大创新，在文本框添加的每一个单词信息，都会在AI创建的图像中得到呈现。例如在下图中，从sunshine，到a tall tree 最后再到sunshine in a tall tree forest，生成的图像一直在随着文本的丰富而发生变化。</p>
 <img src="/67450ff6/3.gif" class>
</li>
<li><p>在原有图像的基础上编辑部分内容生成</p>
 <img src="/67450ff6/4.png" class>

<p> AI会根据保留下来的部分中的元素智能填充到被涂抹的部分。</p>
</li>
</ol>
<hr>
<h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><p>GauGAN2建立在生成对抗网络(GAN)的基础上，由生成器和鉴别器组成。生成器的目标是生成逼真的图像。例如获取与文本匹配的图像，并预测可能与图片中元素对应的数据（例如图2中的山脉、雨天），使得鉴别器不能将合成图像与真实图像区分开。GAN的转换质量会随着鉴别器的反馈而不断提高。</p>
<p>此外，GauGAN2背后的AI模型借助了NVIDIA Selene超级计算机（全球最强的10台超级计算机之一），在1000万张高质量风景图像上训练而成。GauGAN2在单个模型中结合了分割映射、修复和文本到图像的生成，还借助神经网络学习词汇与其对应的视觉效果之间的连接。</p>
<img src="/67450ff6/5.png" class>

<p>编码器(Encoder)利用真实图像计算产生随机向量z；生成器(Generator)接收随机向量z，产生图像x，在产生过程中不断使用语义图增强语义信息；鉴别器(Discriminator)经过处理输出判断结果，如果与语义图与真实图像相连接则判断为真，如果与生成器生成的图像相连接则为假。</p>
<p>在生成器中构建了一个模块SPADE ResBlk，SPADE可以更好地保护语义信息不受常见归一化层的影响。使用SPADE不需要将分割图提供给生成器的第一层，因为学习的调制参数已经编码了关于标签布局的足够信息。</p>
<img src="/67450ff6/6.jpg" class>

<hr>
<h3 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h3><p>目前来看，如果GauGAN2的技术最终成熟，并达到英伟达宣称的水准。那么一定会降低画作艺术创作的门槛。理论上来说可以在电影、软件、视频游戏、产品、时尚设计等领域得到应用，英伟达官方称GauGAN第一代产品已经被用于电影和游戏中创建概念艺术，但是GauGAN2的模型虽然又超过1亿个参数，但是训练时间还不到一个月，训练图像仅来自于专有的风景图像数据集。GauGAN2仍在不断完善，可以期待未来GauGAN2提供开源并在更多领域投入使用。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/GvZqFLoE3EtJoRAXuaSbbA">https://mp.weixin.qq.com/s/GvZqFLoE3EtJoRAXuaSbbA</a><br><a href="https://blogs.nvidia.com/blog/2021/11/22/gaugan2-ai-art-demo/">https://blogs.nvidia.com/blog/2021/11/22/gaugan2-ai-art-demo/</a><br><a href="https://arxiv.org/abs/1903.07291">https://arxiv.org/abs/1903.07291</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10852">https://www.scholat.com/teamwork/showPostMessage.html?id=10852</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-ResNet论文精读-《Deep Residual Learning for Image Recognition》</title>
    <url>/da444d02.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2015-Deep-Residual-Learning-for-Image-Recognition.pdf" data-height="500px"></div>

<hr>
<span id="more"></span>

<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><h4 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h4><p><strong>标题：</strong>Deep Residual Learning for Image Recognition<br><strong>时间：</strong>2015<br><strong>论文领域：</strong>深度学习，计算机视觉<br><strong>论文链接：</strong><a href="https://arxiv.org/abs/1512.03385">https://arxiv.org/abs/1512.03385</a></p>
<hr>
<h3 id="pass-1"><a href="#pass-1" class="headerlink" title="pass 1"></a>pass 1</h3><p>论文标题中文意思是：深度残差学习的图像识别。论文标题指出了关键词：<strong>Residual Learning</strong>，残差是数理统计中常用到的一个词。</p>
<p>本篇论文作者全部为中国学者，这四个人现在都很有名了。一作也是 <strong>CVPR 2009</strong> 的最佳论文获得者，目前在Facebook AI Research任研究科学家；二作、三作当时是微软亚洲研究院的实习生，目前二作在旷视工作，三作在蔚来工作，通信作者目前是旷视研究院院长。</p>
<img src="/da444d02/1.png" class>

<p>下面是论文摘要，摘要总共11句话：</p>
<ul>
<li>第1句话就提出了论文要解决的问题，<strong>更深的神经网络很难训练</strong>。</li>
<li>第2、3句介绍了论文使用的方法，提出了一个<strong>残差学习框架</strong>使深的神经网络更容易训练，网络中的层对层输入的残差函数进行学习。</li>
<li>4-7句为在<strong>ImageNet</strong>上的比赛结果，论文设计的152层网络取得了3.57%的错误率，获得了比赛第一名。</li>
<li>第8句，作者在<strong>CIFAR-10</strong>数据集上进行了100层和1000层网络的实验分析。</li>
<li>9-11句，其它比赛结果，在<strong>ILSVRC</strong>和<strong>COCO 2015</strong>比赛上获得了<strong>ImageNet</strong>检测任务，定位任务，<strong>COCO</strong>检测和分割任务的第一名。</li>
</ul>
<img src="/da444d02/2.png" class>

<p>由于<strong>CVPR2016</strong>要求提交论文正文在8页以内，从摘要可以看出，作者做的实验是比较多的，因此本篇论文没有结论部分。</p>
<hr>
<h3 id="pass-2"><a href="#pass-2" class="headerlink" title="pass 2"></a>pass 2</h3><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>总共9段。第一段介绍故事背景，第二段引出第一个问题：堆叠更多的层数以后网络是否学习效果更好？但是堆叠更多的层后往往会遇到<strong>梯度爆炸、梯度消失</strong>问题，会从一开始就阻止收敛。好在这个问题可以通过归一化初始化或中间层归一化来解决。第三段介绍了另一个问题：当网络开始收敛时，往往会出现<strong>退化现象</strong>。随着网络深度的增加，准确率趋近饱和，然后迅速下降。意外的是，这不是由于过拟合造成的，更深的模型反而会有更高的训练误差。</p>
<img src="/da444d02/3.png" class>

<p>第4-6段，为了解决深度学习的退化问题，作者提出了<strong>深度残差学习框架</strong>，让网络层去<strong>拟合残差映射</strong>。如果我们想要得到的映射为 H(x)，则我们让添加的非线性网络层去拟合<strong>残差映射</strong> F(x) = H(x) − x，则原始的映射就可以写成 F(x) + x。残差映射的实现可以通过图2所示的连接块实现，<strong>跳跃连接</strong>是一个恒等映射，没有引入额外的参数和计算复杂度，整个网络很容易实现（最初<strong>ResNet</strong>是使用<strong>Caffe</strong>库实现的）。</p>
<p>后面三段是本文设计的网络在<strong>ImageNet</strong>、<strong>CIFAR-10</strong>、<strong>COCO</strong>数据集上的实验结果，大量的实验结果表明作者设计的<strong>残差学习框架</strong>的通用性，一方面不仅使得网络更容易优化，另一方面随着网络深度的增加，网络复杂度并没有明显增加，准确率却会提高很多。</p>
<img src="/da444d02/4.png" class>

<hr>
<h4 id="Deep-Residual-Learning"><a href="#Deep-Residual-Learning" class="headerlink" title="Deep Residual Learning"></a>Deep Residual Learning</h4><p>这里要理解各种<strong>ResNet</strong>是如何形成的。网络设计原则为：（1）对于相同的输出特征图尺寸，卷积层具有相同数量的卷积核；（2）如果特征图尺寸减半，则卷积核数量加倍，以便保持每层的时间复杂度。通过步长为2的卷积层直接执行下采样。下面以<strong>ResNet-34</strong>为例进行介绍：</p>
<ul>
<li>首先是<strong>第一个卷积层</strong>，卷积核大小为 7 × 7，卷积核个数为64，步长为2</li>
<li>然后是<strong>第二个卷积层</strong>，卷积核大小为 3 × 3，卷积核个数为64，步长为2</li>
<li>接着是<strong>三个残差连接块</strong>，每一个连接块由两层卷积网络组成，卷积核大小为 3 × 3，卷积核个数为64</li>
<li>然后是<strong>四个残差连接块</strong>，每一个连接块由两层卷积网络组成，卷积核大小为 3 × 3，卷积核个数为128</li>
<li>接着是<strong>六个残差连接块</strong>，每一个连接块由两层卷积网络组成，卷积核大小为 3 × 3，卷积核个数为256</li>
<li>然后是<strong>三个残差连接块</strong>，每一个连接块由两层卷积网络组成，卷积核大小为 3 × 3，卷积核个数为512</li>
</ul>
<p>最后是全局平均池化层和具有softmax的1000维度的全连接层，这样整个网络包含 1 + 1 + (3 + 4 + 6 + 3) × 2 = 34 个卷积层。尽管网络深度相比<strong>VGG-19</strong>要深了许多，但是<strong>FLOPs</strong>只是<strong>VGG-19</strong>的18%左右。</p>
<img src="/da444d02/5.png" class>

<p>从表1可以看到，<strong>ResNet-18</strong>和<strong>ResNet-34</strong>具有相同的残差连接块，每个连接块包含两个卷积层。而<strong>ResNet-50/101/152</strong>的每个连接块包含3个卷积层。作者把这种连接块称为<strong>bottleneck</strong>，这里主要使用了1 × 1的卷积核，主要是用于匹配特征图维度以及从实践出发能够承担的起训练时间。（之前听过论文通信作者的一个报告，据说这个网络训练时间为一个月，具体一个月是指纯训练还是指训练+测试+调参就不太清楚了）。</p>
<img src="/da444d02/6.png" class>

<hr>
<h4 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h4><p>作者是参考<strong>AlexNet</strong>和<strong>VGG</strong>来进行训练。首先对图像的短边进行尺度扩大，扩大到[256, 480]，然后和<strong>AlexNet</strong>一样，随机选择 224 × 224 大小的图案。作者在这里使用到了<strong>batch normalization</strong>(BN)技术；然后作者按照自己的另一篇文章来进行<strong>初始化</strong>并从零开始训练（如果对作者之前工作不了解的话还要再去看作者的文章了解如何对网络初始化，对第一次看到这篇文章的读者来说增加了阅读难度，不过作者可能也是因为受到篇幅影响，不想再过多介绍）。梯度下降使用了<strong>SGD</strong>，<strong>mini-batch</strong>大小为256，总共进行了 60 × 10^4 次迭代（目前很少有这样的写法了，都是介绍训练了多少个epochs）。为了得到最好的实验结果，作者在多个尺度上进行评估，然后取平均分。</p>
<img src="/da444d02/7.png" class>

<hr>
<h4 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h4><p>从论文中可以看到作者做了大量实验。首先是<strong>ImageNet Classification</strong>，首先评估了<strong>plain-18/34</strong>两个网络，从表2可以看到，<strong>plain-34</strong>网络比<strong>plain-18</strong>有更高的错误率，从图4左图也可以看到，在训练过程中，出现了<strong>退化现象</strong>，随着网络深度的增加，训练误差反而变大。作者在论文中解释到：退化现象应该不是<strong>梯度消失</strong>引起的，因为整个训练使用了<strong>BN</strong>来训练，也查验了反向传播时梯度幅值也是正常的，作者怀疑<strong>可能是因为更深的网络有着更低的收敛速度，影响着训练误差的减小，这个问题未来会进一步研究</strong>。</p>
<p>接着是<strong>ResNet-18/34</strong>两个网络的评估，从表2和图4右图可以观察到三个现象：</p>
<ul>
<li>网络越深，训练误差反而越小，<strong>退化问题可以通过残差学习得到解决</strong></li>
<li>与<strong>plain-34</strong>网络相比，训练误差下降了3.5%，随着网络深度的不断增加，网络性能进一步提高</li>
<li>与<strong>palin-18/34</strong>网络相比，残差网络收敛速度更快</li>
</ul>
<img src="/da444d02/8.png" class>

<p>然后是<strong>恒等跳跃连接和投影跳跃连接</strong>的对比，可以看到三种连接都有助于提高网络性能，但是为了不增加网络结构的复杂度，作者这里主要选择恒等跳跃连接进行后续的实验。</p>
<img src="/da444d02/9.png" class>

<p>下面是<strong>ResNet-50/101/152</strong>网络的评估，首先可以看到，尽管网络深度不断增加，但是复杂度依然低于<strong>VGG-16/19</strong>。随着网络深度的不断增加，错误率不断下降，同时在训练过程中也没有出现退化现象，在单个模型上取得了4.49%的错误率，在<strong>ImageNet2015</strong>比赛上，通过集成6个不同的模型，取得了3.57%的错误率（这是一个很了不起的结果，因为ImageNet数据集在人工标注时，可能就会有1%的错误率。）</p>
<img src="/da444d02/10.png" class>

<p>最后总结一下，<strong>ResNet</strong>解决了网络训练退化的问题，找到了可以训练更深网络的办法，目前已经成为了深度学习中最重要的一种模型。</p>
<hr>
<h4 id="从梯度的角度对残差学习理论进行阐述"><a href="#从梯度的角度对残差学习理论进行阐述" class="headerlink" title="从梯度的角度对残差学习理论进行阐述"></a>从梯度的角度对残差学习理论进行阐述</h4><p>这里使用吴恩达老师的讲义来进一步补充。</p>
<img src="/da444d02/11.png" class>

<p>假设有一个很大的神经网络，其输入为X，输出为a[l]。为这个神经网络再添加残差块，输出为a[l+2]。假设整个网络中都选用 ReLU 作为激活函数，因此输出的<strong>所有激活值都大于等于0</strong>。a[l]与a[l+2]之间的函数关系为：</p>
<img src="/da444d02/12.png" class>

<p>当发生梯度消失时，即残差块网络没有学到有用信息，W[l+2] ≈ 0，b[l+2] ≈ 0，则有：</p>
<img src="/da444d02/13.png" class>

<p>因此，<strong>残差块的使用不会降低网络性能</strong>。而如果没有发生梯度消失时，训练得到的非线性关系会使得网络性能进一步提高。（关于残差网络的理论更深解释，也有很多相关的研究，感兴趣可以查阅对应文献。）</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1P3411y7nn">https://www.bilibili.com/video/BV1P3411y7nn</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-Transformer论文精读-《Attention Is All You Need》</title>
    <url>/98fdeece.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2017-Attention-Is-All-You-Need.pdf" data-height="500px"></div>

<hr>
<span id="more"></span>

<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><h4 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h4><p><strong>标题：</strong>Attention Is All You Need<br><strong>时间：</strong>2017<br><strong>论文领域：</strong>Computer Science - Computation and Language<br><strong>论文链接：</strong><a href="https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p>
<hr>
<h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>自从Attention机制在提出之后，加入Attention的Seq2Seq模型在各个任务上都有了提升，所以现在的Seq2Seq模型指的都是结合RNN和Attention的模型。传统的基于RNN的Seq2Seq模型难以处理长序列的句子，无法实现并行，并且面临对齐的问题。</p>
<p>所以之后这类模型的发展大多数从三个方面入手：</p>
<ol>
<li>Input的方向性从单向到多向；</li>
<li>深度从单层到多层；</li>
<li>类型从RNN到LSTM GRU。</li>
</ol>
<p>但是依旧收到一些潜在问题的制约，神经网络需要能够将源语句的所有必要信息压缩成固定长度的向量。这可能使得神经网络难以应付长时间的句子，特别是那些比训练语料库中的句子更长的句子；每个时间步的输出需要依赖于前面时间步的输出，这使得模型没有办法并行，效率低；仍然面临对齐问题。</p>
<p>再然后CNN由计算机视觉也被引入到Deep NLP中，CNN不能直接用于处理变长的序列样本但可以实现并行计算。完全基于CNN的Seq2Seq模型虽然可以并行实现，但非常占内存，很多的trick，大数据量上参数调整并不容易。</p>
<p>本篇文章创新点在于抛弃了之前传统的Encoder-Decoder模型必须结合CNN或者RNN的固有模式，只用Attention机制。文章的主要目的在于减少计算量和提高并行效率的同时不损害最终的实验结果。</p>
<hr>
<h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><ul>
<li>靠attention机制，不使用rnn和cnn，并行度高</li>
<li>通过attention，抓长距离依赖关系比rnn强</li>
</ul>
<hr>
<h4 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h4><ul>
<li>通过self-attention，自己和自己做attention，使得每个词都有全局的语义信息（长依赖）</li>
<li>由于 Self-Attention 是每个词和所有词都要计算 Attention，所以不管他们中间有多长距离，最大的路径长度也都只是1。可以捕获长距离依赖关系</li>
<li>提出multi-head attention，可以看成attention的ensemble版本，不同head学习不同的子空间语义。</li>
</ul>
<hr>
<h3 id="详读"><a href="#详读" class="headerlink" title="详读"></a>详读</h3><h4 id="标题-作者"><a href="#标题-作者" class="headerlink" title="标题+作者"></a>标题+作者</h4><p>Transformer 开创了继 MLP 、CNN和 RN 之后的第四大类模型。200页综述（<a href="https://arxiv.org/pdf/2108.07258.pdf">https://arxiv.org/pdf/2108.07258.pdf</a>）建议将Transformer作为基础模型。</p>
<p><strong>标题：</strong>XXX is all you need. 头条标题。Attention is all you need. 英文语法正确，集中注意力。</p>
<p><strong>作者：</strong>8个共同一作 *，排序随机、贡献相等，推荐在论文中阐述作者的具体贡献。</p>
<hr>
<h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>sequence transduction: 序列转录，序列到序列的生成。input一个序列，output一个序列。e.g. 机器翻译：输入一句中文，输出一句英文。</p>
<p><strong>第1句：主流的序列转录模型</strong><br>包括一个 encoder 和 一个 decoder的 RNN 或者 CNN 架构。</p>
<p><strong>第2句：表现好的序列转录模型：用了attention</strong><br>表现好的sequence transduction模型在 encoder 和 docoder 之间使用了attention。</p>
<p><strong>第3句：本文提出基于attention的Transformer</strong><br>Transformer的贡献：简单 simple (褒义词)，跟之前的（表现好的）循环 or 卷积架构不一样。</p>
<p><strong>第4句：实验总结 - 并行化、更少时间训练</strong></p>
<p><strong>第5-6句：实验BLEU 提分介绍</strong><br>2 个机器翻译任务的实验结果</p>
<ul>
<li>英 -&gt; 德：提高 2 BLEU</li>
<li>英 -&gt; 法：SOTA，41.8 BLEU，只需8GPUs的3.5天的训练</li>
</ul>
<p><strong>第7句：能很好的泛化到其他任务</strong><br>本文是从机器翻译的角度写的，后续图片、视频transformer出圈了。</p>
<hr>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p><strong>第1句：</strong>介绍了Transformer模型，第一个仅仅使用注意力、做序列转录的模型，把之前在 encoder - decoder 的结构换成了 multi-headed self-attention。</p>
<p><strong>第2句：机器翻译任务</strong><br>SOTA，比其他结构训练快</p>
<p><strong>第3句：纯注意力的模型其他任务的应用</strong><br>图片、音频、视频；使生成不那么时序化 less sequential</p>
<p>代码：本文在结论部分，目前推荐放在摘要最后，方便了解论文详细内容和复现。</p>
<hr>
<h4 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h4><p>是摘要（1-3句）的扩充。</p>
<p>sequence model and transduction问题：language modeling, machine translation。2017年常用方法是 RNN, LSTM, GRU。语言模型、编码器-解码器架构</p>
<p>RNN 特点（缺点）：从左往右一步一步计算，对第 t 个状态 ht，由 ht-1（历史信息）和 当前词 t 计算。</p>
<ul>
<li>难以并行。e.g. 100个词要算100步</li>
<li>过早的历史信息可能被丢掉。时序信息是一步一步往后传递的，e.g. 时序长的时候</li>
<li>一个大的 ht 存历史信息。每一个 计算步都需要存储，内存开销大</li>
</ul>
<p>最近的工作通过 fatorization 分解 tricks 和 conditional computation 并行化来提升计算效率，但sequential computation的问题本质依然存在。</p>
<p>attention 在 RNN 上的应用: attention用在怎么把 encoder 的信息有效的传给 decoder，允许建模 input or output sequence 与距离无关的 dependencies</p>
<p>本文 Transformer 网络不再使用循环结构、<strong>纯attention</strong>、并行度高、较短时间达到很好的效果(8 P100 GPU 12 hours)。</p>
<p>导言较短，8页内容尽可能涵盖提出的新内容。</p>
<hr>
<h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><p><strong>3个联系：CNN</strong>（局部像素 -&gt; 全部像素；多通道 -&gt; multi-head），<strong>Self-attention</strong> 他人提出和应用，<strong>Memory network</strong> 使用 recurrent attention mechanism 而不是 sequence-aligned recurrence.</p>
<p><strong>1个区别：</strong>Transformer <strong>仅依赖 self-attention</strong> 计算输入输出的表征，没有使用 sequence-aligned RNNs or convolution.</p>
<p><strong>CNN：</strong><br>(cons) CNN 替换 RNN 来减少时序的计算，但 CNN 对较长的序列难以建模。因为卷积计算的时候看一个比较小的窗口，i.e., 3 * 3 窗口，如果 2 个像素隔得比较远，需要用很多 3 * 3 的卷积层、一层一层的叠加上去，才能把隔得很远的 2个像素联系起来。</p>
<p>Transformer 的 attention mechanism 每一次看到所有的像素，一层能够看到整个序列。</p>
<p>(pros) 多个输出通道，每个通道可以识别不同的模式。<br>Transformer 的 multi-head self-attention 模拟 CNNs  多通道输出的效果。</p>
<p><strong>Self-attention 别人提出， 17年memory network</strong>也是一个研究热点，不知道可跳过。</p>
<p>区别：<strong>first transduction model relying entirely on self-attention</strong> to compute representations of its input and output without using sequencealigned RNNs or convolution.</p>
<p>background章节：跟你论文<strong>相关的是谁</strong>？跟你的<strong>联系与区别</strong></p>
<hr>
<h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><h5 id="第一段：-encoder-decoder-架构-autogressive-in-decoder"><a href="#第一段：-encoder-decoder-架构-autogressive-in-decoder" class="headerlink" title="第一段： encoder-decoder 架构 + autogressive in decoder"></a>第一段： encoder-decoder 架构 + autogressive in decoder</h5><p>sequence transduction models 比较好的结构是 encoder-decoder</p>
<p>encoder 将 （x1, x2, … , xn）（原始输入） 映射成 （z1, z2, …, zn）（机器学习可以理解的向量）。i.e., 一个句子有 n 个词，xt 是第 t 个词，zt 是第 t 个词的向量表示。</p>
<p>decoder 拿到 encoder 的输出，会生成一个长为 m 的序列（y1, y2, … , ym）</p>
<p>n 和 m 可以一样长、可以不一样长。i.e., 中英互译：Hello World 你好世界</p>
<p>encoder 和 decoder 的区别：decoder 的输出词是一个一个生成的，auto-regressive 的模型</p>
<p>encoder 一次性很可能看全整个句子。i.e., 翻译的时候，看到整句英语：Hello World</p>
<p>decoder 在解码的时候，只能一个一个的生成。auto-regressive，输入又是你的输出。i.e., 给定 z 向量 (z1, …, zn) 生成 y1，在得到 y1 之后可以生成 y2。在生成 yt 的时候，要把之前的 y1 到 yt-1 都拿到。在翻译的时候，一个词一个词往外蹦。</p>
<p>过去时刻的输出会作为你当前时刻的输入，自回归 auto-regressive。</p>
<hr>
<h5 id="第二段：Transformer-使用了-encoder-decoder架构"><a href="#第二段：Transformer-使用了-encoder-decoder架构" class="headerlink" title="第二段：Transformer 使用了 encoder-decoder架构"></a>第二段：Transformer 使用了 encoder-decoder架构</h5><p>堆叠的 stacked self-attention and point-wise, fully-connected layers，展示在 figure 1</p>
<p>写论文：全局图、一张图解释所有</p>
<img src="/98fdeece/1.png" class>

<p>i.e., 中 译 英<br>Inputs: 中文句子<br>Outputs: decoder在做预测的时候 是没有输入的。<strong>Shifted right</strong> 指的是 decoder 在之前时刻的一些输出，作为此时的输入。一个一个往右移。</p>
<p><strong>Inputs —- Input Embedding</strong><br>输入经过一个 Embedding层， i.e., 一个词进来之后表示成一个向量。得到的向量值和 Positional Encoding （3.5）相加。</p>
<p><strong>Encoder 的核心架构</strong><br>Nx：N个 Transformer 的 block 叠在一起。<br>i.e., ResNet 中 N 个残差块 的叠加。</p>
<p><strong>Transformer 的block</strong><br>Multi-Head attention<br>Add &amp; Norm: 残差连接 + Layernorm<br>Feed Forward: 前馈神经网络 MLP</p>
<p>encoder 的输出 作为 decoder 的输入</p>
<img src="/98fdeece/2.png" class>

<p>decoder 和 encoder有一点像</p>
<img src="/98fdeece/3.png" class>

<p>decoder 多了一个 Masked Multi-Head Attention</p>
<img src="/98fdeece/4.png" class>

<p>decoder 是 encoder 相同部分 和 Masked Multi-Head Attention 组成一个块，重复 Nx 次</p>
<img src="/98fdeece/5.png" class>

<p>decoder的输出进入一个 Linear 层，做一个 softmax，得到输出。<br>Linear + softmax: 一个标准的神经网络的做法</p>
<img src="/98fdeece/6.png" class>

<p>总结：Transformer 是一个比较标准的 encoder - decoder 架构。区别：encoder、decoder 内部结构不同，encoder 的输出 如何作为 decoder 的输入有一些不一样。</p>
<img src="/98fdeece/7.png" class>

<hr>
<h5 id="3-1-Encoder-and-Decoder-Stacks"><a href="#3-1-Encoder-and-Decoder-Stacks" class="headerlink" title="3.1 Encoder and Decoder Stacks"></a>3.1 Encoder and Decoder Stacks</h5><p>Encoder 结构：重复 6 个图中红色的 layer</p>
<img src="/98fdeece/8.png" class>

<p>每个 layer 有 2 个 sub-layers。</p>
<ul>
<li>第一个 sub-layer 是 multi-head self-attention</li>
<li>第二个 sub-layer 是 simple, position-wise fully connected feed-forward network, 简称 MLP</li>
</ul>
<p>每个 sub-layer 的输出做 残差连接 和 LayerNorm<br>公式：LayerNorm( x + Sublayer(x) )<br>Sublayer(x) 指 self-attention 或者 MLP</p>
<p>residual connections 需要输入输出维度一致，不一致需要做投影。简单起见，固定 每一层的输出维度dmodel = 512</p>
<p>简单设计：只需调 2 个参数 dmodel 每层维度有多大 和 N 多少层，影响后续一系列网络的设计，BERT、GPT。</p>
<p>Remark：和 CNN、MLP 不一样。MLP 通常空间维度往下减；CNN 空间维度往下减，channel 维度往上拉。</p>
<p>LayerNorm<br>写作：不要假设读者都知道所有的细节。可以的话，花几句话讲清楚内容</p>
<p><strong>LayerNorm 和 BatchNorm 的画图对比</strong></p>
<p>BatchNorm 简单的 2 维 情况<br>每一行是一个样本 X，每一列是 一个 feature<br>BatchNorm：每次把一列（1 个 feature）放在一个 mini-batch 里，均值变成 0， 方差变成 1 的标准化。</p>
<img src="/98fdeece/9.png" class>

<p>How：（该列向量 - mini-batch 该列向量的均值）/（mini - batch 该列向量的方差）<br>训练时：mini-batch 计算均值；<br>测试时：使用 全局 均值、方差。</p>
<p>BatchNorm 还会学 lambda1 beta，BatchNorm 可以通过学习将向量 放缩成 任意均值、任意方差 的一个向量。</p>
<p><strong>Layernorm 画图示例</strong></p>
<p>LayerNorm 跟 BatchNorm 在很多时候几乎是一样的，除了实现的方法有点不一样之外。</p>
<p>二维输入：<br>LayerNorm：对每个样本做 Normalization（把每一行变成 均值为 0、方差为 1），不是对每个特征做 normalization。</p>
<img src="/98fdeece/10.png" class>

<p><strong>LayerNorm 在操作上 和 BatchNorm (二维输入) 的关系</strong><br>LayerNorm 整个把数据转置一次，放到 BatchNorm 里面出来的结果，再转置回去，基本上可以得到LayerNorm的结果。</p>
<p><strong>三维输入</strong></p>
<p>Transformer 和 RNN 里面：3 维输入。<br>输入的是一个序列的样本，每个样本中有很多元素，是一个序列。<br>一个句子里面有 n 个词，每个词对应一个向量，+ 一个 batch –&gt; 3 维</p>
<p><strong>3维输入示意图</strong><br>列 是 seq 序列长度 n；第 3 维 feature 是每个词额外的向量，d = 512 in transformer</p>
<img src="/98fdeece/11.png" class>

<p>BatchNorm<br>每次取一个特征，切一块（蓝色线），拉成一个向量，均值为 0 、方差为 1 的标准化。</p>
<img src="/98fdeece/12.png" class>

<p>LayerNorm (橙色) 横着切</p>
<img src="/98fdeece/13.png" class>

<p><strong>LayerNorm 为什么用的多？</strong><br>时序数据中 样本长度可能不一样。</p>
<p>举例分析：4个长度不一样的样本，0 填充到 max_len</p>
<img src="/98fdeece/14.png" class>

<p>BatchNorm 切出来的结果</p>
<img src="/98fdeece/15.png" class>

<p>BatchNorm 计算均值和方差，有效的是阴影部分，其余是 0</p>
<img src="/98fdeece/16.png" class>

<p>Mini-batch 的均值和方差：如果样本长度变化比较大的时候，每次计算小批量的均值和方差，均值和方差的抖动大。</p>
<p>全局的均值和方差：测试时遇到一个特别长的全新样本（最上方蓝色阴影块），训练时未见过，训练时计算的均值和方差可能不好用。</p>
<img src="/98fdeece/17.png" class>

<p>LayerNorm 切出来的结果</p>
<img src="/98fdeece/18.png" class>

<p>LayerNorm 每个样本自己算均值和方差，不需要存全局的均值和方差。</p>
<img src="/98fdeece/19.png" class>

<p>LayerNorm 更稳定，不管样本长还是短，均值和方差是在每个样本内计算。</p>
<p><strong>Decoder 架构</strong></p>
<p>decoder 和 encoder 很像，6 个 相同 layer 的堆叠、每个 sub-layer 的 residual connections、layer normalization。</p>
<p>每个 layer 里有 2个 encoder 中的 sub-layers, decoder 有第 3 个 sub-layer，对 encoder 的输出做 multi-head attention。</p>
<p>decoder 是 auto-regressive 自回归。当前时刻的输入集 是 之前一些时刻的输出。做预测时，decoder 不能看到 之后时刻的输出。</p>
<p>attention mechanism 每一次能看完完整的输入，要避免这个情况的发生。</p>
<p>在 decoder 训练的时候，在预测第 t 个时刻的输出的时候，decoder不应该看到 t 时刻以后的那些输入。它的做法是通过一个带掩码 masked 的注意力机制。–&gt; 保证 训练和预测时 行为一致。</p>
<hr>
<h5 id="3-2-Attention"><a href="#3-2-Attention" class="headerlink" title="3.2 Attention"></a>3.2 Attention</h5><p>注意力函数是 一个将一个 query 和一些 key - value 对 映射成一个输出的函数，其中所有的 query、key、value 和 output 都是一些向量。</p>
<p>具体来说，output 是 value 的一个加权和 –&gt; 输出的维度 ==  value 的维度。</p>
<p>output 中 value 的权重 = 查询 query 和对应的 key 的相似度 or compatibility function</p>
<p>权重等价于 query 和对应的 key 的相似度</p>
<p>虽然 key-value 并没有变，但是随着 query 的改变，因为权重的分配不一样，导致输出会有不一样，这就是注意力机制。</p>
<hr>
<h5 id="3-2-1-Scaled-Dot-Product-Attention"><a href="#3-2-1-Scaled-Dot-Product-Attention" class="headerlink" title="3.2.1 Scaled Dot-Product Attention"></a>3.2.1 Scaled Dot-Product Attention</h5><p>不同的相似度函数 导致 不同的注意力机制<br>Scaled Dot-Product Attention，最简单的注意力机制。</p>
<p>query 和 key 的长度是等长的，都等于 dk。value 的维度是 dv，输出也是 dv。<br>因为 query 和 key 可以不等长，不等长是有别的办法算的。</p>
<p>注意力的具体计算是：对每一个 query 和 key 做内积，然后把它作为相似度。</p>
<p>两个向量做内积：如果这两个向量的 norm 是一样d的话，那么内积的值越大，它的余弦值越大，这两个向量的相似度就越高。如果你的内积的值为 0 ，这两个向量正交了，没有相似度。</p>
<p>attention = softmax( 两个向量的内积值 / sqrt(dk)) * V ，dk 是向量的长度</p>
<p>使用 softmax ：一个 query 给 n 个 key - value pair ，这个 query 会跟每个 key - value pair 做内积，会产生 n 个相似度值。传入 softmax 得到 n 个非负、求和为 1 的权重值。把 softmax 得到的权重值 与 value 矩阵 V 相乘 得到 attention 输出。</p>
<p>实际计算：不会一个 query 一个 query 的计算，因为运算比较慢。把多个 query 写成 一个矩阵，并行化运算。<br>Q：n * dk<br>K:  m * dk<br>Q * K T：(n * dk) * (m * dk)T = (n * m)<br>每一行蓝色的线：一个 query 对所有 key 的内积值，然后再除以sqrt(dk)， 再做 softmax。 softmax 是对每一行的值做 softmax，然后每一行之间是独立的，会得到权重。</p>
<img src="/98fdeece/20.png" class>

<p>权重 softmax( Q * K T / sqrt(dk) ) (n * m) 再乘以  V （m * dv）= (n * dv) 矩阵。</p>
<img src="/98fdeece/21.png" class>

<p>绿色的每一行它就是 attention。</p>
<p>attention 的计算：2次矩阵乘法、并行计算</p>
<hr>
<h5 id="Scaled-Dot-Product-Attention-和-别的注意力机制的区别"><a href="#Scaled-Dot-Product-Attention-和-别的注意力机制的区别" class="headerlink" title="Scaled Dot-Product Attention 和 别的注意力机制的区别"></a>Scaled Dot-Product Attention 和 别的注意力机制的区别</h5><p>2 种常见的注意力机制：加性的注意力机制（它可以处理你的 query 和 key 不等长的情况，点积 dot-product 的注意力机制 （本文采用 scaled，➗ sqrt(dk) ），所以你可以看到它的名字它叫做 scale 的。</p>
<p>选用 dot-product 原因：两种注意力机制其实都差不多， 点乘实现 简单、高效，两次矩阵乘法计算。</p>
<p><strong>scale</strong> dot-product 原因 ➗ sqrt(dk) ：防止softmax函数的梯度消失。</p>
<p>dk不是很大的时候，➗ 不➗ 都 ok。dk 比较大时 （2 个向量的长度比较长的时候），点积的值会比较大，or 会比较小。</p>
<p>当你的值比较大的时候，相对的差距会变大，导致最大值 softmax会更加靠近于1，剩下那些值就会更加靠近于0。值就会更加向两端靠拢，算梯度的时候，梯度比较小。<br>softmax会让大的数据更大，小的更小</p>
<p>因为 softmax 最后的结果是希望 softmax 的预测值，置信的地方尽量靠近，不置信的地方尽量靠近零，以保证收敛差不多了。这时候梯度就会变得比较小，那就会跑不动。</p>
<p>在 trasformer 里面一般用的 dk 比较大 (本文 512)，所以➗ sqrt(dk) 是一个不错的选择。</p>
<img src="/98fdeece/22.png" class>

<hr>
<h5 id="怎么做-mask-？"><a href="#怎么做-mask-？" class="headerlink" title="怎么做 mask ？"></a>怎么做 mask ？</h5><p>避免在 t 时刻，看到 t 时刻以后的输入。<br>在计算权重的时候，t 时刻只用了 v1, …, vt-1 的结果，不要用到 t 时刻以后的内容。</p>
<p>把 t 时刻以后 Qt 和 Kt 的值换成一个很大的负数，如 1 ^ (-10)，进入 softmax 后，权重为0。 –&gt; 和 V 矩阵做矩阵乘法时，没看到 t 时刻以后的内容，只看 t 时刻之前的 key - value pair。</p>
<p>理解：mask是个 0 1矩阵，和attention（scale QK）size一样，t 时刻以后 mask 为 0。</p>
<hr>
<h5 id="3-3-2-Multi-head-attention"><a href="#3-3-2-Multi-head-attention" class="headerlink" title="3.3.2 Multi-head attention"></a>3.3.2 Multi-head attention</h5><p>与其做一个单个的注意力函数，不如说把整个 query、key、value 整个投影 project 到 1个低维，投影 h 次。然后再做 h 次的注意力函数，把每一个函数的输出 拼接在一起，然后 again projected，会得到最终的输出。</p>
<img src="/98fdeece/23.png" class>

<p>输入是：原始的 value、key、query<br>进入一个线形层，线形层把 value、key、query 投影到比较低的维度。然后再做一个 scaled dot product （图 2 左图）。</p>
<p>执行 h 次会得到 h 个输出，再把 h 个 输出向量全部合并 concat 在一起，最后做一次线性的投影 Linear，会回到我们的 multi-head attention。</p>
<p>为什么要做多头注意力机制呢？一个 dot product 的注意力里面，没有什么可以学的参数。具体函数就是内积，为了识别不一样的模式，希望有不一样的计算相似度的办法。</p>
<p>加性 attention 有一个权重可学，也许能学到一些内容。</p>
<p>本文的 dot-product attention，先投影到低维，投影的 w 是可以学习的。</p>
<p>multi-head attention 给 h 次机会去学习 不一样的投影的方法，使得在投影进去的度量空间里面能够去匹配不同模式需要的一些相似函数，然后把 h 个 heads 拼接起来，最后再做一次投影。</p>
<p>有点像 CNN 多个输出通道的感觉。</p>
<hr>
<h5 id="multi-head-attention-具体公式"><a href="#multi-head-attention-具体公式" class="headerlink" title="multi-head attention 具体公式"></a>multi-head attention 具体公式</h5><p>Multi-head 的输入还是Q,K,V</p>
<p>但是输出是 不同的头的输出的 concat 起来，再投影到一个 WO 里面。</p>
<p>每一个头 hi 是把 Q,K,V 通过 可以学习的 Wq, Wk, Wv 投影到 dv 上，再通过注意力函数，得到 headi。 </p>
<p>本文采用 8 个 heads。因为有残差连接的存在使得输入和输出的维度至少是一样的。</p>
<p>投影维度 dv = dmodel / h = 512 / 8 = 64，每个 head 得到 64 维度，concat，再投影回 dmodel。</p>
<hr>
<h5 id="3-2-3-Applications-of-attentions-in-our-model"><a href="#3-2-3-Applications-of-attentions-in-our-model" class="headerlink" title="3.2.3 Applications of attentions in our model"></a>3.2.3 Applications of attentions in our model</h5><p>3 种 不一样的注意力层</p>
<img src="/98fdeece/24.png" class>

<p><strong>encoder 的注意力层：</strong></p>
<p>i.e., 句子长度是 n，encoder 的输入是一个 n 个长为 d 的向量。<br>假设  pn 大小设成 1 了，每一个输入词对应的是一个长为 d 的向量。</p>
<img src="/98fdeece/25.png" class>

<p>encoder 的注意力层，有三个输入，它分别表示的是key、value 和 query。</p>
<img src="/98fdeece/26.png" class>

<p>一根线过来，它复制成了三下：同样一个东西，既 key 也作为 value 也作为 query，所以叫做<strong>自注意力机制</strong>。<strong>key、value 和 query 其实就是一个东西</strong>，就是自己本身。</p>
<img src="/98fdeece/27.png" class>

<p>输入了 n 个 query，每个 query 会得到一个输出，那么会有 n 个输出。<br>输出  是 value 加权和（权重是 query 和 key 的相似度），输出的维度 == d  – &gt; 输入维度 == 输出维度</p>
<img src="/98fdeece/28.png" class>

<p>绿色线代表权重，和自己的相似度最大、权重线最粗。</p>
<p>假设和最右侧向量 相似度比较高，权重也会高一些、绿色线会粗一些。</p>
<p>不考虑 multi-head 和 有投影的情况：<br>输出是 输入的加权和，其权重来自 每个向量与其它向量的相似度。</p>
<p>multi-head 和 有投影的情况：<br>学习 h 个不一样的距离空间，使得输出变化。</p>
<p><strong>decoder 的 masked multi-head attention</strong></p>
<img src="/98fdeece/29.png" class>

<p>输入复制 3 份。</p>
<img src="/98fdeece/30.png" class>

<img src="/98fdeece/31.png" class>

<p>masked 体现在，看不到 t 时刻以后的输入，黄圈内的绿色权重为 0</p>
<p><strong>decoder 的 multi-head attention</strong></p>
<p>不再是 self-attention。<br>key - value 来自 encoder 的输出。</p>
<img src="/98fdeece/32.png" class>

<p>query 是来自 decoder 里 masked multi-head attention 的输出。</p>
<img src="/98fdeece/33.png" class>

<p>图中红色方块：encoder 的输出  value 和 key 。<br>encoder 最后一层的输出： n 个 长为 d 的向量。</p>
<p>图中绿色方块：<br>decoder 的 masked multi-head attention + Add &amp; Norm 的输出是 m 个 长为 d 的向量。</p>
<p>图中蓝色方块：decoder 的输出<br>根据 query 算输出： value 的加权和 （权重 取决于 红色方块 和 绿色方块 的相似度）</p>
<p>第 3 个 attention 层，根据 query 去有效的提取 encoder 层输出</p>
<img src="/98fdeece/34.png" class>

<p>i.e.， Hello World –&gt; 你好世界</p>
<p>计算 “好” 的时候，“好”作为 query ，会跟 “hello” 向量更相近一点，给 “hello” 向量一个比较大的权重。</p>
<p>但是 “world” 跟后面的词相关， “world” 跟 当前的query （“好” ）相关度没那么高。</p>
<p>在算 “好” 的时候，我会给“hello” 向量一个比较大的权重。</p>
<p>在算 query “世” 的时候，会给第二个 “world” 向量，一个比较大的权重。</p>
<p>根据解码器的输入的不一样，会根据当前的 query 向量，去在编码器的输出里面去挑我（当前 query）感兴趣的东西。</p>
<p>attention：query 注意到 当前的 query 感兴趣的东西，对当前的 query的不感兴趣的内容，可以忽略掉。 –&gt; attention 作用：在 encoder 和 decoder 之间传递信息</p>
<hr>
<h5 id="3-3-Position-wise-Feed-Forward-Networks"><a href="#3-3-Position-wise-Feed-Forward-Networks" class="headerlink" title="3.3 Position-wise Feed-Forward Networks"></a>3.3 Position-wise Feed-Forward Networks</h5><p>作用在最后一个维度的 MLP</p>
<p>MLP: applied to each position separtely and identically.<br><strong>Point-wise：</strong>把一个 MLP 对每一个词 （position）作用一次，对每个词作用的是同样的 MLP </p>
<p>FFN： Linear + ReLU + Linear</p>
<p>单隐藏层的 MLP，中间 W1 扩维到4倍 2048，最后 W2 投影回到 512 维度大小，便于残差连接。<br>pytorch实现：2个线性层。pytorch在输入是3d的时候，默认在最后一个维度做计算。</p>
<p>最简单情况：没有残差连接、没有 layernorm、 attention 单头、没有投影。看和 RNN 区别</p>
<p>attention 对输入做一个加权和，加权和 进入 point-wise MLP。（画了多个红色方块 MLP， 是一个权重相同的 MLP）</p>
<p>point-wise MLP 对 每个输入的点 做计算，得到输出。</p>
<p>attention 作用：把整个序列里面的信息抓取出来，做一次汇聚 aggregation</p>
<img src="/98fdeece/35.png" class>

<p>图中红色填充块，已经就有了，序列中感兴趣的东西<br>以至于我在做投影，在做 MLP 的时候映射成我更想要的那个语义空间的时候，因为这个东西已经含有了我的序列信息，所以每个 MLP 只要在对每个点独立做就行了。</p>
<p>历史信息，因为这个地方序列信息已经被汇聚完成，所以 MLP 是可以分开做的，也就整这个 transformer 是如何抽取序列信息，然后把这些信息加工成我最后要的语义空间，向量的过程</p>
<p>对比 RNN 怎么做的。<br>图中 绿色 表示之前的信息</p>
<img src="/98fdeece/36.png" class>

<p>RNN 跟 transformer <strong>异：如何传递序列的信息</strong><br>RNN 是把上一个时刻的信息输出传入下一个时候做输入。Transformer 通过一个 attention 层，去全局的拿到整个序列里面信息，再用 MLP 做语义的转换。</p>
<p>RNN 跟 transformer <strong>同：语义空间的转换 + 关注点</strong><br>用一个线性层 or 一个 MLP 来做语义空间的转换。<br><strong>关注点：</strong>怎么有效的去使用序列的信息。</p>
<hr>
<h5 id="3-4-Embeddings-and-Softmax"><a href="#3-4-Embeddings-and-Softmax" class="headerlink" title="3.4 Embeddings and Softmax"></a>3.4 Embeddings and Softmax</h5><p>embedding：将输入的一个词、词语 token 映射成 为一个长为 d 的向量。学习到的长为 d 的向量 来表示整个词、词语 token。</p>
<p>本文 d = 512<br>编码器、解码器、最后 softmax 之前的 3 个 embedding 共享权重。–&gt; 训练更简单。</p>
<p>Note：权重 *  sqrt(dmodel = 512) ，学 embedding 的时候，会把每一个向量的 L2 Norm 学的比较小。</p>
<p>i.e., 学成 1， 不论维度多大，最后的值都会 = 1。<br>维度大的化，学到的一些权重值就会变小，但之后还需要加上 positional encoding（不会随着维度的增加而变化）。 </p>
<p>multiply weights by sqrt(dmodel) 使得 embedding 和  positional encosing 的 scale 差不多，可以做加法。</p>
<hr>
<h5 id="3-5-Positional-Encoding"><a href="#3-5-Positional-Encoding" class="headerlink" title="3.5 Positional Encoding"></a>3.5 Positional Encoding</h5><p>Why? attention 不会有时序信息。<br>output 是 value 的 加权和（权重是 query 和 key 之间的距离，和 序列信息 无关）。<br>根本不看 key - value 对在序列哪些地方。一句话把顺序任意打乱之后，attention 出来，结果都是一样的。<br><strong>顺序会变，但是值不会变，有问题！</strong><br>在处理时序数据的时候，一句话里面的词完全打乱，那么语义肯定会发生变化，但是 attention 不会处理这个情况。 –&gt; 加入时序信息。</p>
<p><strong>How：</strong>RNN 把上一时刻的输出 作为下一个时刻的输入，来传递时序信息。<br><strong>How：</strong>attention 在输入里面加入时序信息 –&gt; positional encoding<br>一个在位置 i 的词，会把 i 位置信息加入到输入里面。如位置12345，12345。</p>
<p>计算机表示一个 32 位的整数：32个 bit，每个 bit 上有不同的值来表示。</p>
<p>一个词在嵌入层表示成一个 512 维的向量，用另一个 512 维的向量来表示一个数字，位置信息 1 2 3 4 5 6 7 8……。</p>
<p>表示一个位置数字信息的值，怎么计算？<br>周期不一样的 sin 和 cos 函数计算 –&gt; 任何一个值可以用一个长为 512 的向量来表示。</p>
<p>这个长为 512 、记录了时序信息的一个positional encoding，+ 嵌入层相加 –&gt; 完成 把时序信息加进数据。</p>
<p><strong>详细看图解释：</strong>输入进来进入 embedding 层之后，那么对每个词都会拿到那个向量长为 512 的一个向量。positional encodding （这个词在句子中的位置），返回一个长为 512 的向量，表示这个位置，然后把 embeding 和 positional encodding 加起来就行了。</p>
<p>positional encodding 是 cos 和 sin 的一个函数，在 [-1, +1] 之间抖动的。所以 input embedding * sqrt(d) ，使得乘积后的每个数字也是在差不多的 [-1, +1] 数值区间。相加完成 –&gt; 在输入里面添加时序信息。 </p>
<p>完成 与 positional encoding 相加 之后的部分是顺序不变的。</p>
<p>不管怎么打乱输入序列的顺序，进入 layer 之后，输出那些值是不变的，最多是顺序发生了相应的变化。所以就直接把顺序信息直接加在数据值里。</p>
<hr>
<h5 id="模型架构总结"><a href="#模型架构总结" class="headerlink" title="模型架构总结"></a>模型架构总结</h5><p>内容不长、但弄清楚细节比较花时间。</p>
<hr>
<h5 id="Why-Self-attention"><a href="#Why-Self-attention" class="headerlink" title="Why Self-attention"></a>Why Self-attention</h5><p>模型长什么样，为什么要这样做？设计理念<br>解释 Table 1</p>
<img src="/98fdeece/37.png" class>

<p>第一个当然是他们关注的自注意力，然后是循环层、卷积层。另外一个是他构造出来一个受限的自注意力，它的有三列作比较。第一列是说我的计算复杂度当然是越低越好。第二个是说我的顺序的计算越少越好。顺序的计算就是说你下一步计算必须要等前面多少步计算完成，再算一个 layer 的时候。你越标的，那么你的并行度就越高啊。</p>
<p>Complexity per Layer 越少越好<br>n 序列长度，d 向量长度； </p>
<p>self-attention: O(n^2 * d) 主要是矩阵乘法，并行度高<br>Q（n * d） K（m * d）–&gt; Q * KT (n * m)<br>self-attention 自注意力，query、key 相同 –&gt; m = n, 复杂度为O(n^2 * d)  【其它的矩阵运算复杂度是一样的 O()省略了常数项 k 】</p>
<p>recurrent: 序列长度为 n ，一个 dense layer * 一个长为 d 的输入</p>
<p>循环层是要我们知道，如果你的序列是长的 N 话，它就一个一个做运算，每个里面它的主要的计算就是一个 N 乘以 N 的矩阵，一个你就是一个 dance layer 然后再乘以你一个长为 D 的一个输入，所以它是一个 N 平方，然后要做 N 次，所以是 N 乘 D 平方。</p>
<p>然后你对比一下这两个东西是有一定区别的，真的取决你是 N 大还是 D 大。如果你 N 大的话，当然它贵点。你第一大的话是下面一个贵一点。实际上来说，你的第一这个地方是52，你的 N 也差不多是几百的样子。现在当然是说比较大的模型话，第一可以做到 22048 甚至更大，你的 N 相对来说也会做得比较，也是几千的样子。所以你其实现在看起来这两个东西都差不多， N 和 D 的其实在差不多的数据上面。所以这两个都差不多。</p>
<p>convolutional: k 比较小 3 5；CNN 和 RNN 复杂度差不多；<br>self-attention(restricted): query 只跟 最近的 r 个邻居计算</p>
<p>Sequential Operations （下一步计算，必须要等前面多少步 计算完成） 越少，并行度越高<br>self-attention: O(1)，矩阵乘法的并行度高<br>recurrent: 一步一步做运算，当前时刻的词 需要等待前面所有时刻 计算完成，–&gt; 一个成为 N 的一个序列化的操作，在并行上是比较吃亏的。我们之前提到过。另外一个是说你最初点的那个历史信息，需要到最后那一个点的话需要走过 N 步才能过去，所以它这个地方的最长是 on 所以大家会批评。<br>convolutional:<br>self-attention(restricted):</p>
<p>Maximum Path Length（一个信息从一个数据点走到另外一个数据点要走多少步）越短越好<br>任何两个 走多少步<br>self-attention: O(1)，一个 query 和所有的 key 做运算。输出是所有 value 的加权和。任何 query 和任意一个很远的 key-value pair，只要一次就能过来。<br>recurrent:<br>convolutional:<br>self-attention(restricted):</p>
<p><strong>总结：</strong>实际使用 self-attention ，前 3 个算法的时间复杂度差不多，attention 需要更多的数据。</p>
<hr>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><h5 id="Training-Data-and-Benchmarking"><a href="#Training-Data-and-Benchmarking" class="headerlink" title="Training Data and Benchmarking"></a>Training Data and Benchmarking</h5><p>WMT 2014 数据集<br>byte-pair encoding, BPE 提取词根 –&gt; 处理一个词的多种变化 -ing -ed、37000 tokens（英语德语共享字典 –&gt; encoder 和 decoder 用一个东西、模型更简单、Embedding 共享权重）</p>
<p>英语法语用了一个更大的数据集</p>
<hr>
<h5 id="Hardware-and-Schedule"><a href="#Hardware-and-Schedule" class="headerlink" title="Hardware and Schedule"></a>Hardware and Schedule</h5><p>8 P100 GPUs, 现在 Google 推荐用 TPUs (适合大的矩阵乘法)<br>0.4 seconds / batch, 100, 000 steps or 12 hours<br>big models: 1s / step, 300, 000 steps, 3.5 days</p>
<hr>
<h5 id="Optimizer：没有可以调的Adam"><a href="#Optimizer：没有可以调的Adam" class="headerlink" title="Optimizer：没有可以调的Adam"></a>Optimizer：没有可以调的Adam</h5><p>Adam 训练器； beta2 常见为 0.99 or 0.999<br>学习率通过公式计算</p>
<p>dmodel ^ (-0.5) == 1 / sqrt(dmodel)  –&gt; <strong>模型要学习的宽度越宽，学习率越低</strong></p>
<p>warm-up, 从一个小的值慢慢爬到一个高的值，到一定值之后，根据 step_num ^ 0.5衰减<br>warmup-steps 4000步</p>
<img src="/98fdeece/38.png" class>

<p>学习率不用调，Adam 对学习率不那么敏感，dmodel已经考虑在公式里， step_num 也是不错的 schedule。</p>
<hr>
<h5 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h5><p><strong>Residual Dropout</strong></p>
<p>each sub-layer: 多头注意力 和 之后的 MLP，每一层的输出上，在进入残差连接之前和进入 layernorm 之前，使用 dropout，P drop = 0.1<br>10% 的元素 重置为 0， 剩下的值 * 1.1</p>
<p><strong>总结：</strong>带权重的层，输出都使用了 dropout</p>
<p><strong>Label Smoothing</strong><br><strong>Inception V3</strong><br>0 - 1 标签，softmax很难趋近为1。很soft，输出值很大，才会激活为1。<br>正确的词，softmax的输出为 0.1 即可，剩下的值是 0.9 / 字典大小</p>
<p>损失 perplexity，模型的困惑度（不确信度）、log（loss）做指数。因为正确的标签只需要给到 10 %。<br>模型不那么精确，可以提高 accuracy and BLEU score</p>
<p><strong>超参数的对比：只调 N层数、dmodel模型的宽、注意力的head数 h</strong></p>
<img src="/98fdeece/39.png" class>

<p>N 是 堆多少层<br>dmodel 模型的宽度：是 一个 token 进来之后表示成 多长的向量<br>dff 是 MLP 中间隐藏层输出的大小<br>h 是 注意力层 head 的个数<br>dk, dv 分别是 key 和 value 的维度<br>Pdrop 是 dropout 的概率<br>Els 是 label smoothing 要学的正确的 label 值为多少</p>
<p>dmodel = h * dk</p>
<p>big model：模型宽度 * 2,  dff * 2，<br>h * 2 –&gt; dk 和 dv 不用变维度<br>模型更复杂 –&gt; Pdrop = 0.3, train steps 300 K</p>
<p>模型可调的参数：多少层 N，多宽 dmodel, 模型的 head数 h，剩下的参数按比例计算，便于后人的工作。</p>
<p>Table 4: 除了 MT，其它的任务也表现不错。</p>
<hr>
<h4 id="评论：写作、Transformer-模型、-attention标题、未来"><a href="#评论：写作、Transformer-模型、-attention标题、未来" class="headerlink" title="评论：写作、Transformer 模型、 attention标题、未来"></a>评论：写作、Transformer 模型、 attention标题、未来</h4><p><strong>写作：</strong>非常简洁、每句话在讲一件事情；没有太多的写作技巧、提出了 Transformer 模型、和 CNN、 RNN 的对比</p>
<p><strong>建议：</strong>写作技巧 – 将一个故事，有代入感，设计理念是什么、对整篇文章的思考是什么，不那么重要的放 appendix</p>
<p><strong>Transformer 模型出圈 –&gt; 多模态</strong>：像 CNN 对 CV 的作用，不仅仅应用在NLP，在 CV、Video上也有很好的应用。</p>
<p><strong>启示：</strong>一个新的模型可以在 DL 上 通用。人的感知是多模态的、使得 Transformer 在文本、语音、视频抽取多维特征。</p>
<p><strong>对 Transformer 中 attention 的理解：</strong>attention只是起到 把整个序列的信息聚合起来 的作用，后面的 MLP 和 残差连接 是缺一不可的。去掉 MLP 和 残差连接，只有 attention，也什么都训练不出来。</p>
<p><strong>呼应标题 attention is all you need：</strong>不是只有 attention 就行了。</p>
<p>attention 没有对数据的顺序建模，为什么 ko RNN 呢？<br>RNN 显示的建模了序列信息，理论应该比 attention 效果更好。</p>
<p>attention 用了更广泛的 inductive bias 归置偏置，使得 attention 没有用空间上的假设，取得和 CNN 一样、 甚至更好的结果。</p>
<p>代价：假设更加一般、对数据的抓取能力差，需要使用更多的数据、更大的模型 才能训练出一样的效果</p>
<p>注：<a href="https://www.zhihu.com/question/264264203">inductive bias</a></p>
<img src="/98fdeece/40.png" class>

<p>CNN的inductive bias应该是locality和spatial invariance，即空间相近的grid elements有联系而远的没有，和空间不变性（kernel权重共享）</p>
<p>RNN的inductive bias是sequentiality和time invariance，即序列顺序上的timesteps有联系，和时间变换的不变性（rnn权重共享）</p>
<p><strong>attention 给研究者的鼓励：</strong>在 CNN 和 RNN 之外，也有新的模型能够打败它们。有研究者在尝试就用 MLP or 更简单的架构，在图片、文本上去的很好的效果。</p>
<p>未来 DL 领域会有更多的模型出现，更有意思~</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1pu411o7BE">https://www.bilibili.com/video/BV1pu411o7BE</a><br><a href="https://www.cnblogs.com/baobaotql/p/11662720.html">https://www.cnblogs.com/baobaotql/p/11662720.html</a><br><a href="https://zhuanlan.zhihu.com/p/34781297">https://zhuanlan.zhihu.com/p/34781297</a><br><a href="https://www.bilibili.com/read/cv13759416">https://www.bilibili.com/read/cv13759416</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>一个非常快速的LaTeX入门教程</title>
    <url>/2458f8d8.html</url>
    <content><![CDATA[<h3 id="LaTeX"><a href="#LaTeX" class="headerlink" title="LaTeX"></a>LaTeX</h3><img src="/2458f8d8/1.png" class>

<p>LaTeX是一款开源免费并且应用相当广泛的排版工具，它不仅能对文字、公式、图片进行精确而复杂的排版，并且还能保证全文各个章节格式的一致性。</p>
<span id="more"></span>

<img src="/2458f8d8/2.png" class>

<img src="/2458f8d8/3.png" class>

<p>像平时看到的论文、书籍，几乎无一例外都是使用LaTeX生成的</p>
<img src="/2458f8d8/4.png" class>

<p>LaTeX同时提供相当数量的宏包，作为对基础排版功能的扩充</p>
<img src="/2458f8d8/5.png" class>

<p>像乐谱、原理图，甚至简单的动画也都可以用它完成</p>
<img src="/2458f8d8/6.png" class>

<p>求职也可以用LaTeX来做一份专业的简历</p>
<img src="/2458f8d8/7.png" class>

<p>本篇博客将消除大家对LaTeX复杂难用的刻板印象，并让你快速上手这款文字排版的必备神器。</p>
<hr>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>LaTeX的主要优势是它会将文档的内容和排版区分开来，这就好像是html和css的关系</p>
<img src="/2458f8d8/8.png" class>

<p>同时也正如Markdown，它也是一种将内容和排版分开的标记语言，并且Markdown的语法非常轻量，非常适合于简单文字的创作</p>
<img src="/2458f8d8/9.png" class>

<p>像很多wiki，比如GitHub的文档，都是使用Markdown语法生成的。</p>
<p>和Markdown类似，LaTeX的格式和排版也可以随后轻易地替换，通常也就是一两行代码的事，例如你可以轻易的将一篇普通文档切换为科学期刊，甚至是幻灯片</p>
<img src="/2458f8d8/10.png" class>

<p>当然每个工具都有适用的地方，我也不会鼓吹在所有的情况下都去用LaTeX，如果你只是记记笔记，不怎么需要大篇幅排版的情况下，使用word这类所见即所得的工具自然也会方便很多。</p>
<hr>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>常用的Tex发行版一般有两个：TeX Live 和 MiKTeX</p>
<img src="/2458f8d8/11.png" class>

<p>TeX Live提供的包很全，但占用空间大；MiKTeX占用空间小，安装速度快，但如果遇到本地缺少的包则需要联网下载。大家可以根据实际情况考虑，如果你的网络连接不太稳定，则可以选择下载TeX Live一劳永逸，如果大家不希望本地配置环境，只是想快速尝试的话，也可以使用<a href="https://www.overleaf.com/">Overleaf</a>这款可以免费在线使用的TeX编辑器。</p>
<img src="/2458f8d8/12.png" class>

<p>我使用的是TeX Live，可以在<a href="https://www.tug.org/texlive/acquire-iso.html">这个页面</a>下载离线的安装包</p>
<p>不过TeX Live的安装速度有些慢，大家可能需要耐心等待。安装完毕后，我们可以打开TeX Live自带的编辑器TeXworks</p>
<img src="/2458f8d8/13.png" class>

<p>当然大家完全可以使用自己喜欢的任意文本编辑器，我个人比较喜欢的是vscode，关于vscode和LaTeX的环境配置我会放在末尾给大家讲解</p>
<img src="/2458f8d8/14.png" class>

<hr>
<h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><p>LaTeX中所有的命令都以\（反斜杠）开头，后面可以跟一个花括号，代表这个命令的参数，比如这里的documentclass指定了文档的类型</p>
<img src="/2458f8d8/15.png" class>

<p>最广泛使用的文档类型有article，代表普通的文章，其它常用的还有book、report等等。如果你希望创建一个幻灯片格式的文档，则可以在这里使用beamer。由于我们需要在文档中显示中文，这里需要使用一个叫作ctexart的文档类型，它支持简体中文和英文的混排</p>
<p>另外千万不要忘记在这里指定文档的编码格式，UTF8是TeXworks编辑器默认使用的编码类型，如果不去正确设置它的话，文档中的中文可能会变成一堆乱码</p>
<p>要注意的是，所有位于\begin{document}之前的内容都被称作是前言（preamble），它就像是html中的head标签，你可以在这里设置文档的格式、页面的尺寸，也可以指定文档中需要导入的宏包等等</p>
<p>下面介于\begin{document}和\end{document}之间的内容称为文档的正文（body），我们在这片区域输入的所有内容，将会被排版到最终生成的文档中</p>
<img src="/2458f8d8/16.png" class>

<p>在前言区块内，我们可以通过\title{}命令给文档设置一个标题，\author命令可以用来指定作者的名字，\date命令可以用来指定文档的修改日期（可以配合使用\today命令自动生成当天的日期）。要显示这些信息，我们还需要在文档的正文区添加一个\maketitle命令，这个命令会在当前位置生成文档的标题，标题的内容就是之前在前言区（preamble）设定的信息</p>
<img src="/2458f8d8/17.png" class>

<p>接下来我们来了解一下LaTeX中最基础的格式化命令</p>
<p>如果要加粗文字，我们可以使用\textbf{}命令，需要加粗的内容可以直接写在花括号中（bf，bold font）</p>
<p>如果要设置斜体字，我们可以使用\textit{}命令（it，italic）</p>
<p>如果是设置下划线标记的文字，我们可以使用\underline{}命令</p>
<p>如果要在文章中添加一个新的段落，可以通过输入两个换行符来完成。需要注意的是单独的一个换行符只会生成一个空格，并不会开启新的段落</p>
<img src="/2458f8d8/18.png" class>

<hr>
<h4 id="章和节"><a href="#章和节" class="headerlink" title="章和节"></a>章和节</h4><p>和其它的排版工具一样，我们可以将文章按结构分成多个章节。要开启一个新的章节，我们可以使用\section{}命令，花括号中的内容代表章节的名字。如果要在章节下创建一个子章节或者二级章节，则可以使用\subsection{}命令。同理要创建三级章节，可以使用\subsubsection{}命令</p>
<img src="/2458f8d8/19.png" class>

<p>如果是对书籍排版的话，比如文档类型是ctexbook，还可以加入比section更大的chapter，通常用来表示书籍中的第几章</p>
<img src="/2458f8d8/20.png" class>

<p>比chapter还要大的还有part，通常用来表示书籍中的第几部</p>
<img src="/2458f8d8/21.png" class>

<hr>
<h4 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h4><p>如果要在文档中添加图片，则需要在前言中引用graphicx这个包，这个包里面包含若干个绘制图片的指令</p>
<p>随后在正文中，我们可以使用\includegraphics{}命令在当前位置添加一张图片，后面花括号中的head是图片文件的名字。在名字中，我们可以直接省略掉后面png的扩展名部分</p>
<img src="/2458f8d8/22.png" class>

<p>我们可以给\includegraphics{}命令添加一个可选的参数，在方括号中写入width=0.5\textwidth，这里的\textwidth代表当前文本区域的宽度</p>
<img src="/2458f8d8/23.png" class>

<p>如果希望给图片添加标题，可以先将图片嵌套在一个figure环境中，随后我们可以通过\caption{}命令指定图片的标题，同时我们也可以通过\centering命令将图片居中显示</p>
<img src="/2458f8d8/24.png" class>

<hr>
<h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><p>要在LaTeX中显示列表，我们需要先切换到列表的“环境”。环境（environment）是LaTeX中的一个专用术语，它就像是编程语言里面的作用域，任何介于\begin{}和\end{}之间的内容都属于同一个环境，位于同一个环境中的内容将会共享相同的文字格式。</p>
<p>对于无序列表的创建，可以使用itemize环境。列表中的每一个元素都需要以\item开头</p>
<img src="/2458f8d8/25.png" class>

<p>对于有序列表，可以使用enumerate环境，与无序列表相同，列表中的元素同样需要以\item开头</p>
<img src="/2458f8d8/26.png" class>

<hr>
<h4 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h4><p>在熟练掌握语法之后，你可以非常快速地生成任意复杂的公式。LaTeX允许你在段落内直接添加公式，它们被称作行内公式（inline equation），行内公式需要写在两个美元符号之间，比如这段代码将生成爱因斯坦的质能守恒方程 E=mc^2</p>
<img src="/2458f8d8/27.png" class>

<p>如果我们希望将公式显示在单独一行，则可以使用equation这个“环境”。同时你也可以将displaymath环境简写为\[…\]的形式。（equation会在公式右边打印编号，displaymath则不会）</p>
<img src="/2458f8d8/28.png" class>

<img src="/2458f8d8/29.png" class>

<p>对于复杂的公式，则需要熟记公式中经常用到的一些指令，比如RSA公式为例：\over代表几分之几，分子在前分母在后，由于这里的分子是另一个表达式，所以需要用花括号括起来，但这里的花括号并不会直接显示在最终的公式中，\varghi在这里代表小写的符号φ，\phi则表示大写的Φ</p>
<img src="/2458f8d8/30.png" class>

<img src="/2458f8d8/31.png" class>

<p>另外对于LaTeX公式语法的测试，推荐这个<a href="https://latex.codecogs.com/eqneditor/editor.php">在线的公式编辑器</a>。可以在这里快速测试想要排版的公式，也可以通过这里的按钮快速查阅公式的语法</p>
<hr>
<h4 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h4><p>可以使用tabular环境在当前位置创建一个表格，tabular环境要求我们传入一个参数，用来指定表格的尺寸，这里的{ c c c }代表表格一共有三列，其中每一列的内容都居中对齐（centering），可以替换c为l表示左对齐、r表示右对齐</p>
<p>下面的区域定义了表格中需要显示的内容，其中每列的数据需要以 &amp; 符号隔开，表格每一行的数据需要以\\分割</p>
<img src="/2458f8d8/32.png" class>

<img src="/2458f8d8/34.png" class>

<p>可以在上面加入竖线为表格添加竖直的边框，水平方向的边框则需要通过\hline命令添加，甚至可以输入两次\hline来添加双横线的效果</p>
<img src="/2458f8d8/33.png" class>

<img src="/2458f8d8/35.png" class>

<p>如果我们需要单独指定每一列的宽度，可以将c改成p，并在后面的花括号里输入列宽，这里的p代表paragraph，是一种允许设置列宽的列格式</p>
<img src="/2458f8d8/36.png" class>

<p>和图表类似，如果希望给表格添加标题，可以先将整个表格放在一个table环境里，随后我们可以通过\caption{}命令指定表格的标题，并通过\center命令将表格居中显示</p>
<img src="/2458f8d8/37.png" class>

<img src="/2458f8d8/38.png" class>

<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上内容可以说是LaTeX排版中最最基础的用法，另外作为经典的入门资料，我十分推荐这本<a href="https://github.com/CTeX-org/lshort-zh-cn">《一份（不太）简短的LaTeX介绍》</a>。这篇文档展示了LaTeX中，各个功能的详尽示例和用法，例如可以查阅到之前讲到的公式用法</p>
<img src="/2458f8d8/39.png" class>

<p>可以把它当作一本使用手册，遇到特定的排版问题也都可以在其中搜索查阅。另外这本文档本身也是用LaTeX编写的，你可以在其中找到这篇文档的源码，顺便学习一下这篇100多页的手册是如何编排的</p>
<hr>
<h3 id="vscode配置LaTeX"><a href="#vscode配置LaTeX" class="headerlink" title="vscode配置LaTeX"></a>vscode配置LaTeX</h3><p>系统中先安装TeX Live，然后下载一个名为LaTeX Workshop的插件即可</p>
<img src="/2458f8d8/40.png" class>

<p>安装完毕后，你可以通过view latex这个命令打开文档的预览窗口，快捷键是 Ctrl+Alt+V</p>
<p>当你保存文档的时候，这个插件会自动编译文档，并更新右边的预览窗口</p>
<img src="/2458f8d8/41.png" class>

<p>你也可以在同目录下找到生成的pdf文件</p>
<img src="/2458f8d8/42.png" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV11h41127FD">https://www.bilibili.com/video/BV11h41127FD</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>Anaconda使用教程</title>
    <url>/5ead0eb4.html</url>
    <content><![CDATA[<p>Python是一种面向对象的解释型计算机程序设计语言，其使用，具有跨平台的特点，可以在Linux、macOS以及Windows系统中搭建环境并使用，其编写的代码在不同平台上运行时，几乎不需要做较大的改动，使用者无不受益于它的便捷性。</p>
<p>此外，Python的强大之处在于它的应用领域范围之广，遍及人工智能、科学计算、Web开发、系统运维、大数据及云计算、金融、游戏开发等。实现其强大功能的前提，就是Python具有数量庞大且功能相对完善的标准库和第三方库。通过对库的引用，能够实现对不同领域业务的开发。然而，正是由于库的数量庞大，对于管理这些库以及对库作及时的维护成为既重要但复杂度又高的事情。</p>
<span id="more"></span>

<hr>
<h3 id="什么是Anaconda？"><a href="#什么是Anaconda？" class="headerlink" title="什么是Anaconda？"></a>什么是Anaconda？</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p><a href="https://www.anaconda.com/">Anaconda</a>就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。</p>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>Anaconda具有如下特点：</p>
<ul>
<li>开源</li>
<li>安装过程简单</li>
<li>高性能使用Python和R语言</li>
<li>免费的社区支持</li>
</ul>
<p>其特点的实现主要基于Anaconda拥有的：</p>
<ul>
<li>conda包</li>
<li>环境管理器</li>
<li>1000+开源库</li>
</ul>
<p>如果日常工作或学习并不必要使用1,000多个库，那么可以考虑安装<a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda</a>，这里不过多介绍Miniconda的安装及使用。</p>
<h4 id="Anaconda、conda、pip、virtualenv的区别"><a href="#Anaconda、conda、pip、virtualenv的区别" class="headerlink" title="Anaconda、conda、pip、virtualenv的区别"></a>Anaconda、conda、pip、virtualenv的区别</h4><h5 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h5><p>Anaconda是一个包含180+的科学包及其依赖项的发行版本。其包含的科学包包括：conda, numpy, scipy, ipython notebook等。</p>
<h5 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h5><p>conda是包及其依赖项和环境的管理工具。</p>
<p>适用语言：Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN。<br>适用平台：Windows, macOS, Linux</p>
<p>用途：</p>
<ul>
<li>快速安装、运行和升级包及其依赖项。</li>
<li>在计算机中便捷地创建、保存、加载和切换环境。</li>
</ul>
<p>“如果你需要的包要求不同版本的Python，你无需切换到不同的环境，因为conda同样是一个环境管理器。仅需要几条命令，你可以创建一个完全独立的环境来运行不同的Python版本，同时继续在你常规的环境中使用你常用的Python版本。”————conda官方网站</p>
<p>conda为Python项目而创造，但可适用于上述的多种语言。</p>
<p>conda包和环境管理器包含于Anaconda的所有版本当中。</p>
<h5 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h5><p>pip是用于安装和管理软件包的包管理器。</p>
<p>pip编写语言：Python。</p>
<p>Python中默认安装的版本：</p>
<ul>
<li>Python 2.7.9及后续版本：默认安装，命令为pip</li>
<li>Python 3.4及后续版本：默认安装，命令为pip3</li>
</ul>
<p>pip名称的由来：pip采用的是递归缩写进行命名的。其名字被普遍认为来源于2处：</p>
<ul>
<li>“Pip installs Packages”（“pip安装包”）</li>
<li>“Pip installs Python”（“pip安装Python”）</li>
</ul>
<h5 id="virtualenv"><a href="#virtualenv" class="headerlink" title="virtualenv"></a>virtualenv</h5><p>virtualenv：用于创建一个独立的Python环境的工具。</p>
<p>解决问题：</p>
<ol>
<li>当一个程序需要使用Python 2.7版本，而另一个程序需要使用Python 3.6版本，如何同时使用这两个程序？</li>
<li>如果将所有程序都安装在系统下的默认路径，如：/usr/lib/python2.7/site-packages，当不小心升级了本不该升级的程序时，将会对其他的程序造成影响。</li>
<li>如果想要安装程序并在程序运行时对其库或库的版本进行修改，都会导致程序的中断。</li>
<li>在共享主机时，无法在全局site-packages目录中安装包。</li>
</ol>
<p>virtualenv将会为它自己的安装目录创建一个环境，这并不与其他virtualenv环境共享库；同时也可以选择性地不连接已安装的全局库。</p>
<h5 id="pip-与-conda-比较"><a href="#pip-与-conda-比较" class="headerlink" title="pip 与 conda 比较"></a>pip 与 conda 比较</h5><p><strong>依赖项检查</strong></p>
<p>pip：</p>
<ul>
<li>不一定会展示所需其他依赖包。</li>
<li>安装包时或许会直接忽略依赖项而安装，仅在结果中提示错误。</li>
</ul>
<p>conda：</p>
<ul>
<li>列出所需其他依赖包。</li>
<li>安装包时自动安装其依赖项。</li>
<li>可以便捷地在包的不同版本中自由切换。</li>
</ul>
<p><strong>环境管理</strong></p>
<p>pip：维护多个环境难度较大。<br>conda：比较方便地在不同环境之间进行切换，环境管理较为简单。</p>
<p><strong>对系统自带Python的影响</strong></p>
<p>pip：在系统自带Python中包的**更新/回退版本/卸载将影响其他程序。<br>conda：不会影响系统自带Python。</p>
<p><strong>适用语言</strong></p>
<p>pip：仅适用于Python。<br>conda：适用于Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN。</p>
<h5 id="conda与pip、virtualenv的关系"><a href="#conda与pip、virtualenv的关系" class="headerlink" title="conda与pip、virtualenv的关系"></a>conda与pip、virtualenv的关系</h5><p>conda结合了pip和virtualenv的功能。</p>
<hr>
<h3 id="管理conda"><a href="#管理conda" class="headerlink" title="管理conda"></a>管理conda</h3><p>接下来均是以命令行模式进行介绍，Windows用户请打开“Anaconda Prompt”；macOS和Linux用户请打开“Terminal”（“终端”）进行操作。</p>
<h4 id="验证conda已被安装"><a href="#验证conda已被安装" class="headerlink" title="验证conda已被安装"></a>验证conda已被安装</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda --version</span><br></pre></td></tr></table></figure>

<p>终端上将会以conda 版本号的形式显示当前安装conda的版本号。如：conda 3.11.0</p>
<p>注意：如果出现错误信息，则需核实是否出现以下情况：</p>
<ul>
<li>使用的用户是否是安装Anaconda时的账户。</li>
<li>是否在安装Anaconda之后重启了终端。</li>
</ul>
<h4 id="更新conda至最新版本"><a href="#更新conda至最新版本" class="headerlink" title="更新conda至最新版本"></a>更新conda至最新版本</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda update conda</span><br></pre></td></tr></table></figure>

<p>执行命令后，conda将会对版本进行比较并列出可以升级的版本。同时，也会告知用户其他相关包也会升级到相应版本。</p>
<p>当较新的版本可以用于升级时，终端会显示Proceed ([y]/n)?，此时输入y即可进行升级。</p>
<h4 id="查看conda帮助信息"><a href="#查看conda帮助信息" class="headerlink" title="查看conda帮助信息"></a>查看conda帮助信息</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda --<span class="built_in">help</span></span><br><span class="line">// or</span><br><span class="line">conda -h</span><br></pre></td></tr></table></figure>

<h4 id="卸载conda"><a href="#卸载conda" class="headerlink" title="卸载conda"></a>卸载conda</h4><h5 id="Linux-或-macOS"><a href="#Linux-或-macOS" class="headerlink" title="Linux 或 macOS"></a>Linux 或 macOS</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">rm -rf ~/anaconda3</span><br></pre></td></tr></table></figure>

<p>即删除Anaconda的安装目录。根据安装的Anaconda版本选择相应的卸载命令。</p>
<h5 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">控制面板 → 添加或删除程序</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="管理环境"><a href="#管理环境" class="headerlink" title="管理环境"></a>管理环境</h3><p>接下来均是以命令行模式进行介绍，Windows用户请打开“Anaconda Prompt”；macOS和Linux用户请打开“Terminal”（“终端”）进行操作。</p>
<h4 id="创建新环境"><a href="#创建新环境" class="headerlink" title="创建新环境"></a>创建新环境</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda create --name &lt;env_name&gt; &lt;package_names&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>env_name即创建的环境名。建议以英文命名，且不加空格，名称两边不加尖括号“&lt;&gt;”。</li>
<li>package_names即安装在环境中的包名。名称两边不加尖括号“&lt;&gt;”。<ul>
<li>如果要安装指定的版本号，则只需要在包名后面以=和版本号的形式执行。如：conda create –name python2 python=2.7，即创建一个名为“python2”的环境，环境中安装版本为2.7的python。</li>
<li>如果要在新创建的环境中创建多个包，则直接在package_names后以空格隔开，添加多个包名即可。如：conda create -n python3 python=3.5 numpy pandas，即创建一个名为“python3”的环境，环境中安装版本为3.5的python，同时也安装了numpy和pandas。</li>
</ul>
</li>
<li>–name同样可以替换为-n。</li>
</ul>
<p>提示：默认情况下，新创建的环境将会被保存在/Users/user_name/anaconda3/env目录下，其中，user_name为当前用户的用户名。</p>
<h4 id="切换环境"><a href="#切换环境" class="headerlink" title="切换环境"></a>切换环境</h4><h5 id="Linux-或-macOS-1"><a href="#Linux-或-macOS-1" class="headerlink" title="Linux 或 macOS"></a>Linux 或 macOS</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">source activate &lt;env_name&gt;</span><br></pre></td></tr></table></figure>

<h5 id="Windows-1"><a href="#Windows-1" class="headerlink" title="Windows"></a>Windows</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">activate &lt;env_name&gt;</span><br></pre></td></tr></table></figure>

<h5 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h5><ol>
<li><p>如果创建环境后安装Python时没有指定Python的版本，那么将会安装与Anaconda版本相同的Python版本，即如果安装Anaconda第2版，则会自动安装Python 2.x；如果安装Anaconda第3版，则会自动安装Python 3.x。</p>
</li>
<li><p>当成功切换环境之后，在该行行首将以“env_name”开头，“env_name”为切换到的环境名。如：在macOS系统中执行source active python2，即切换至名为“python2”的环境，则行首将会以(python2)开头。</p>
</li>
</ol>
<h4 id="退出环境至root"><a href="#退出环境至root" class="headerlink" title="退出环境至root"></a>退出环境至root</h4><h5 id="Linux-或-macOS-2"><a href="#Linux-或-macOS-2" class="headerlink" title="Linux 或 macOS"></a>Linux 或 macOS</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">source deactivate</span><br></pre></td></tr></table></figure>

<h5 id="Windows-2"><a href="#Windows-2" class="headerlink" title="Windows"></a>Windows</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure>

<p>当执行退出当前环境，回到root环境命令后，原本行首以“env_name”开头的字符将不再显示。</p>
<h4 id="显示已创建环境"><a href="#显示已创建环境" class="headerlink" title="显示已创建环境"></a>显示已创建环境</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda info --envs</span><br><span class="line">// or</span><br><span class="line">conda info -e</span><br><span class="line">// or</span><br><span class="line">conda env list</span><br></pre></td></tr></table></figure>

<p>结果中星号“*”所在行即为当前所在环境。macOS系统中默认创建的环境名为“base”。</p>
<h4 id="复制环境"><a href="#复制环境" class="headerlink" title="复制环境"></a>复制环境</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda create --name &lt;new_env_name&gt; --clone &lt;copied_env_name&gt;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li>copied_env_name即为被复制/克隆环境名。环境名两边不加尖括号“&lt;&gt;”。</li>
<li>new_env_name即为复制之后新环境的名称。环境名两边不加尖括号“&lt;&gt;”。</li>
<li>如：conda create –name py2 –clone python2，即为克隆名为“python2”的环境，克隆后的新环境名为“py2”。此时，环境中将同时存在“python2”和“py2”环境，且两个环境的配置相同。</li>
</ol>
<h4 id="删除环境"><a href="#删除环境" class="headerlink" title="删除环境"></a>删除环境</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda remove --name &lt;env_name&gt; --all</span><br></pre></td></tr></table></figure>

<p>注意：env_name为被删除环境的名称。环境名两边不加尖括号“&lt;&gt;”。</p>
<hr>
<h3 id="管理包"><a href="#管理包" class="headerlink" title="管理包"></a>管理包</h3><h4 id="查找可供安装的包版本"><a href="#查找可供安装的包版本" class="headerlink" title="查找可供安装的包版本"></a>查找可供安装的包版本</h4><h5 id="精确查找"><a href="#精确查找" class="headerlink" title="精确查找"></a>精确查找</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda search --full-name &lt;package_full_name&gt;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li>–full-name为精确查找的参数。</li>
<li>package_full_name是被查找包的全名。包名两边不加尖括号“&lt;&gt;”。</li>
</ol>
<p>例如：conda search –full-name python即查找全名为“python”的包有哪些版本可供安装。</p>
<h5 id="模糊查找"><a href="#模糊查找" class="headerlink" title="模糊查找"></a>模糊查找</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda search &lt;text&gt;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li>text是查找含有此字段的包名。此字段两边不加尖括号“&lt;&gt;”。</li>
</ol>
<p>例如：conda search py即查找含有“py”字段的包，有哪些版本可供安装。</p>
<h4 id="获取当前环境中已安装的包信息"><a href="#获取当前环境中已安装的包信息" class="headerlink" title="获取当前环境中已安装的包信息"></a>获取当前环境中已安装的包信息</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda list</span><br></pre></td></tr></table></figure>

<p>执行上述命令后将在终端显示当前环境已安装包的包名及其版本号。</p>
<h4 id="安装包"><a href="#安装包" class="headerlink" title="安装包"></a>安装包</h4><h5 id="在指定环境中安装包"><a href="#在指定环境中安装包" class="headerlink" title="在指定环境中安装包"></a>在指定环境中安装包</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda install --name &lt;env_name&gt; &lt;package_name&gt;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li>env_name即将包安装的指定环境名。环境名两边不加尖括号“&lt;&gt;”。</li>
<li>package_name即要安装的包名。包名两边不加尖括号“&lt;&gt;”。</li>
</ol>
<p>例如：conda install –name python2 pandas即在名为“python2”的环境中安装pandas包。</p>
<h5 id="在当前环境中安装包"><a href="#在当前环境中安装包" class="headerlink" title="在当前环境中安装包"></a>在当前环境中安装包</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda install &lt;package_name&gt;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li>package_name即要安装的包名。包名两边不加尖括号“&lt;&gt;”。</li>
<li>执行命令后在当前环境中安装包。</li>
</ol>
<p>例如：conda install pandas即在当前环境中安装pandas包。</p>
<h5 id="使用pip安装包"><a href="#使用pip安装包" class="headerlink" title="使用pip安装包"></a>使用pip安装包</h5><p>当使用conda install无法进行安装时，可以使用pip进行安装。例如：see包。</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">pip install &lt;package_name&gt;</span><br></pre></td></tr></table></figure>

<p>注意：package_name为指定安装包的名称。包名两边不加尖括号“&lt;&gt;”。</p>
<p>如：pip install see即安装see包。</p>
<ol>
<li>pip只是包管理器，无法对环境进行管理。因此如果想在指定环境中使用pip进行安装包，则需要先切换到指定环境中，再使用pip命令安装包。</li>
<li>pip无法更新python，因为pip并不将python视为包。</li>
<li>pip可以安装一些conda无法安装的包；conda也可以安装一些pip无法安装的包。因此当使用一种命令无法安装包时，可以尝试用另一种命令。</li>
</ol>
<h5 id="从Anaconda-org安装包"><a href="#从Anaconda-org安装包" class="headerlink" title="从Anaconda.org安装包"></a>从Anaconda.org安装包</h5><p>当使用conda install无法进行安装时，可以考虑从Anaconda.org中获取安装包的命令，并进行安装。</p>
<p>在当前环境中安装来自于Anaconda.org的包时，需要通过输入要安装的包在Anaconda.org中的路径作为获取途径。查询路径的方式如下：</p>
<ol>
<li>在浏览器中输入：<a href="https://anaconda.org/">https://anaconda.org/</a></li>
<li>在新页面“Anaconda Cloud”的上方搜索框中输入要安装的包名，然后点击右边“放大镜”标志。<img src="/5ead0eb4/1.webp" class></li>
<li>搜索结果中有数以千计的包可供选择，此时点击“Downloads”可根据下载量进行排序，最上面的为下载最多的包。</li>
<li>选择满足需求的包或下载量最多的包，点击包名。</li>
<li>复制“To install this package with conda run:”下方的命令，并粘贴在终端中执行。<img src="/5ead0eb4/2.webp" class>

</li>
</ol>
<h4 id="卸载包"><a href="#卸载包" class="headerlink" title="卸载包"></a>卸载包</h4><h5 id="卸载指定环境中的包"><a href="#卸载指定环境中的包" class="headerlink" title="卸载指定环境中的包"></a>卸载指定环境中的包</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda remove --name &lt;env_name&gt; &lt;package_name&gt;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li>env_name即卸载包所在指定环境的名称。环境名两边不加尖括号“&lt;&gt;”。</li>
<li>package_name即要卸载包的名称。包名两边不加尖括号“&lt;&gt;”。</li>
</ul>
<p>例如：conda remove –name python2 pandas即卸载名为“python2”中的pandas包。</p>
<h5 id="卸载当前环境中的包"><a href="#卸载当前环境中的包" class="headerlink" title="卸载当前环境中的包"></a>卸载当前环境中的包</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda remove &lt;package_name&gt;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li>package_name即要卸载包的名称。包名两边不加尖括号“&lt;&gt;”。</li>
<li>执行命令后即在当前环境中卸载指定包。</li>
</ul>
<p>例如：conda remove pandas即在当前环境中卸载pandas包。</p>
<h4 id="更新包"><a href="#更新包" class="headerlink" title="更新包"></a>更新包</h4><h5 id="更新所有包"><a href="#更新所有包" class="headerlink" title="更新所有包"></a>更新所有包</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda update --all</span><br><span class="line">// or</span><br><span class="line">conda upgrade --all</span><br></pre></td></tr></table></figure>

<p>建议：在安装Anaconda之后执行上述命令更新Anaconda中的所有包至最新版本，便于使用。</p>
<h5 id="更新指定包"><a href="#更新指定包" class="headerlink" title="更新指定包"></a>更新指定包</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda update &lt;package_name&gt;</span><br><span class="line">// or</span><br><span class="line">conda upgrade &lt;package_name&gt;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li>package_name为指定更新的包名。包名两边不加尖括号“&lt;&gt;”。</li>
<li>更新多个指定包，则包名以空格隔开，向后排列。如：conda update pandas numpy matplotlib即更新pandas、numpy、matplotlib包。</li>
</ul>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.jianshu.com/p/62f155eb6ac5">https://www.jianshu.com/p/62f155eb6ac5</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Python</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-Batch Norm和Layer Norm</title>
    <url>/5a7353d9.html</url>
    <content><![CDATA[<img src="/5a7353d9/4.png" class>

<p>前阵子读了Transformer的论文，发现自己对BN和LN并不是很清楚，故博众家所长作此文。</p>
<span id="more"></span>

<hr>
<h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><p>由于 ICS 问题的存在，x 的分布可能相差很大。要解决独立同分布的问题，“理论正确”的方法就是对每一层的数据都进行<strong>白化操作</strong>。然而标准的白化操作代价高昂，且不可微不利于反向传播更新梯度。因此，以 BN 为代表的 Normalization 方法退而求其次，进行了简化的白化操作。</p>
<p>（白化是一个比PCA稍微高级一点的算法，目的是降低输入的冗余性，输入数据集X，经过白化处理后，新的数据X’满足两个性质：特征之间相关性较低，所有特征具有相同的方差）</p>
<p>基本思想是：在将 x 送给神经元之前，先对其做平移和伸缩变换， 将 x 的分布规范化成在固定区间范围的标准分布。</p>
<hr>
<h3 id="深度学习中的ICS问题"><a href="#深度学习中的ICS问题" class="headerlink" title="深度学习中的ICS问题"></a>深度学习中的ICS问题</h3><p>covariate shift 是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同。</p>
<p>而统计机器学习中的一个经典假设是 “源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。</p>
<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>在一个网络中, 如果训练数据的分布同测试数据时, <strong>训练最有效率</strong>, 因为此时根据训练数据计算出的梯度最接近真实的梯度, 因此使用此梯度对参数进行优化最高效。</p>
<h4 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h4><p>神经网络的目的就是输入一批数据, 根据这批数据的分布, 预测真实数据的分布, 我们一般将这里的数据数据称之为训练数据。</p>
<p>如果把第一层, 也就是最底层网络去掉, 剩下的网络称之为<strong>子网络</strong>, 那么<strong>子网络</strong>的目的与原网络相同, 同样是输入一批数据, 根据这批数据的分布, 预测真实数据的分布, <strong>而这里的输入数据就是训练数据经过第一层网络后的输出数据</strong>, 此时目的不变, 那么同样适用上面那个原则, 即输入数据的分布于测试数据的分布越接近, 那么该网络的优化越高效. 依此类推, 这个结论适用于任何层次的子网络。</p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>因此, 我们就应当考虑这样一个问题, 要尽量保证数据在经过每一层网络时, 其分布保持不变, 也就是数据在输入每一层网络之前, <strong>其分布都与测试数据接近</strong>, 那么可以使得整个网络的训练是高效的。</p>
<p>ICS问题(internal covariate shift), 就是说如果训练数据在经过网络的每一层后其分布都<strong>发生了变化</strong>, 通过上述论证可知, 此时就不能保证整个网络的优化过程是高效的, 甚至说会极大地降低网络的优化效率。</p>
<h4 id="ICS导致的问题"><a href="#ICS导致的问题" class="headerlink" title="ICS导致的问题"></a>ICS导致的问题</h4><p>每个神经元的输入数据不再是 “独立同分布”。</p>
<ol>
<li>上层参数需要不断适应新的输入数据分布，降低学习速度。</li>
<li>下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止。</li>
<li>每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。</li>
</ol>
<hr>
<h3 id="通用变换框架"><a href="#通用变换框架" class="headerlink" title="通用变换框架"></a>通用变换框架</h3><img src="/5a7353d9/1.webp" class>

<p>最终得到的数据符合均值为 b 、方差为 g^2 的分布。</p>
<h4 id="为什么要再平移再缩放"><a href="#为什么要再平移再缩放" class="headerlink" title="为什么要再平移再缩放"></a>为什么要再平移再缩放</h4><p>为了保证模型的表达能力不因为规范化而下降。</p>
<p>第一步的规范化会将几乎所有数据映射到激活函数的非饱和区（线性区），仅利用到了线性变化能力，从而降低了神经网络的表达能力。而进行再变换，则可以将数据从线性区变换到非线性区，恢复模型的表达能力。</p>
<h4 id="平移参数和再平移参数的区别"><a href="#平移参数和再平移参数的区别" class="headerlink" title="平移参数和再平移参数的区别"></a>平移参数和再平移参数的区别</h4><p>平移参数，x 的均值取决于下层神经网络的复杂关联。</p>
<p>但再平移参数中，去除了与下层计算的密切耦合。新参数很容易通过梯度下降来学习，简化了神经网络的训练。</p>
<hr>
<h3 id="Batch-Norm"><a href="#Batch-Norm" class="headerlink" title="Batch Norm"></a>Batch Norm</h3><p><strong>每一batch的样本具有相同的均值和方差</strong></p>
<p>BN在batch维度的归一化，也就是对于每个batch，该层相应的output位置归一化所使用的mean和variance都是一样的。</p>
<p>BN的学习参数包含rescale和shift两个参数。</p>
<ol>
<li>BN在单独的层级之间使用比较方便，比如CNN。得像RNN这样层数不定，直接用BN不太方便，需要对每一层（每个time step）做BN，并保留每一层的mean和variance。不过由于RNN输入不定长（time step长度不定），可能会有validation或test的time step比train set里面的任何数据都长，因此会造成mean和variance不存在的情况。</li>
<li>BN会引入噪声（因为是mini batch而不是整个training set），所以对于噪声敏感的方法（如RL）不太适用。</li>
</ol>
<p>我们在对数据训练之前会对数据集进行归一化，归一化的目的归一化的目的就是使得预处理的数据被限定在一定的范围内（比如[0, 1]或者[-1, 1]），从而消除奇异样本数据导致的不良影响。<strong>虽然输入层的数据，已经归一化，后面网络每一层的输入数据的分布一直在发生变化，前面层训练参数的更新将导致后面层输入数据分布的变化，必然会引起后面每一层输入数据分布的改变。而且，网络前面几层微小的改变，后面几层就会逐步把这种改变累积放大。</strong>训练过程中网络中间层数据分布的改变称之为：“Internal Covariate Shift”（ICS）。</p>
<p><strong>BN</strong>的提出，就是要<strong>解决在训练过程中，中间层数据分布发生改变的情况</strong>。所以就引入了BN的概念，来消除这种影响。所以在每次传入网络的数据每一层的网络都进行一次BN，将数据拉回正态分布，这样做使得数据分布一致且避免了梯度消失。</p>
<p>此外，internal corvariate shift和covariate shift是两回事，前者是网络内部，后者是针对输入数据，比如我们在训练数据前做归一化等预处理操作。</p>
<p>需要注意的是<strong>在使用小batch-size时BN会破坏性能</strong>，当具有分布极不平衡二分类任务时也会出现不好的结果。因为如果小的batch-size归一化的原因，使得原本的数据的均值和方差偏离原始数据，均值和方差不足以代替整个数据分布。分布不均的分类任务也会出现这种情况！</p>
<p>BN实际使用时需要计算并且保存某一层神经网络batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其他sequence长很多，这样training时，计算很麻烦。</p>
<img src="/5a7353d9/5.png" class>

<img src="/5a7353d9/6.png" class>

<img src="/5a7353d9/7.png" class>

<hr>
<h3 id="Layer-Norm"><a href="#Layer-Norm" class="headerlink" title="Layer Norm"></a>Layer Norm</h3><p><strong>每一个神经元有相同的均值和方差，每个样本的均值和方差不同</strong></p>
<p>LayerNorm实际就是对隐含层做层归一化，即对某一层的所有神经元的输入进行归一化。（每hidden_size个数求平均/方差）</p>
<ol>
<li>它在training和inference时没有区别，只需要对当前隐藏层计算mean and variance就行。不需要保存每层的moving average mean and variance。</li>
<li>不受batch size的限制，可以通过online learning的方式一条一条的输入训练数据。</li>
<li>LN可以方便的在RNN中使用。</li>
<li>LN增加了gain和bias作为学习的参数。</li>
</ol>
<p>与BN不同的是，LN对每一层的所有神经元进行归一化，与BN不同的是：</p>
<ol>
<li>LN 中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；</li>
<li>BN 中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。</li>
<li>LN不依赖于batch的大小和输入sequence的深度，因此可以用于batchsize为1和RNN中对边长的输入sequence的normalize操作。</li>
</ol>
<p>一般情况，LN常常用于RNN网络！把一个 batch 的 feature 类比为一摞书，LN 求均值时，相当于把每一本书的所有字加起来，再除以这本书的字符总数：C×H×W，即求整本书的“平均字”，求标准差时也是同理。</p>
<p>Layer Norm</p>
<img src="/5a7353d9/2.webp" class>

<p>Layer Norm求均值方差</p>
<img src="/5a7353d9/3.webp" class>

<p>Bert layer norm实现代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerNorm</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;Construct a layernorm module (See citation for details).&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, features, eps=<span class="number">1e-6</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LayerNorm, self).__init__()</span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(features))</span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(features))</span><br><span class="line">        self.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># mean(-1) 表示 mean(len(x)), 这里的-1就是最后一个维度，也就是hidden_size维</span></span><br><span class="line">        mean = x.mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Batch Normalization 的处理对象是对一批样本， Layer Normalization 的处理对象是单个样本。Batch Normalization 是对这批样本的同一维度特征做归一化， Layer Normalization 是对这单个样本的所有维度特征做归一化。</p>
<img src="/5a7353d9/8.jpg" class>

<p>BN、LN可以看作横向和纵向的区别。</p>
<p>经过归一化再输入激活函数，得到的值大部分会落入非线性函数的线性区，导数远离导数饱和区，避免了梯度消失，这样来加速训练收敛过程。BatchNorm这类归一化技术，目的就是让每一层的分布稳定下来，让后面的层可以在前面层的基础上安心学习知识。</p>
<p>BatchNorm就是通过对batch size这个维度归一化来让分布稳定下来。LayerNorm则是通过对Hidden size这个维度归一。</p>
<p><strong>（CV领域）</strong>，如果你的特征依赖于不同样本间的统计参数，那BN更有效。因为它抹杀了不同特征之间的大小关系，但是保留了不同样本间的大小关系。<br><strong>（NLP领域）</strong>，LN就更加合适。因为它抹杀了不同样本间的大小关系，但是保留了一个样本内不同特征之间的大小关系。对于NLP或者序列任务来说，一条样本的不同特征，其实就是时序上字符取值的变化，样本内的特征关系是非常紧密的。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.jianshu.com/p/cb8769fd0c41">https://www.jianshu.com/p/cb8769fd0c41</a><br><a href="https://www.jianshu.com/p/91b54246b51c">https://www.jianshu.com/p/91b54246b51c</a><br><a href="https://blog.csdn.net/MissingDi/article/details/106155394">https://blog.csdn.net/MissingDi/article/details/106155394</a><br><a href="https://zhuanlan.zhihu.com/p/113233908">https://zhuanlan.zhihu.com/p/113233908</a><br><a href="https://zhuanlan.zhihu.com/p/428620330">https://zhuanlan.zhihu.com/p/428620330</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-三星电子与哈佛联手将大脑神经元“复制粘贴”到芯片上</title>
    <url>/f47c3812.html</url>
    <content><![CDATA[<p>2021年9月23日，韩国三星电子和哈佛大学联手在科学期刊《自然·电子学》（Nature Electronics）发表了一篇题为 ”Neuromorphic electronics based on copying and pasting the brain”（基于拷贝和粘贴大脑的神经形态电子）的论文。论文的主题可以笼统地概括为“复制”与“粘贴”。</p>
<img src="/f47c3812/1.jpg" class>

<span id="more"></span>

<p>论文中，他们提出了一种能够将人类大脑的神经元“复制粘贴”到芯片上，使得其特征接近大脑独特的信息计算特征：低功耗、便捷的学习能力、对环境的适应，甚至是自主和认知。这是前所未有的技术创新。</p>
<p>研究中，他们基于当前的神经形态工程方法，并提供了一种愿景，使神经形态电子学回归其对大脑进行逆向工程的最初目标。纳米电极数组可以有效进入大量的神经元，灵敏地记录它们的电信号。这些大规模并行的细胞记录可以为神经元的网络连接图提供信息，可以描绘出神经元相互连接的位置以及这些连接的强度。从这些记录中，可以提取或复制神经元的网络连结图。</p>
<img src="/f47c3812/2.png" class>

<p>论文还进一步提出了一种将神经元布线图快速粘贴到记忆内存网络上的方法策略。当由细胞内记录的信号直接驱动时，一个专门设计的非挥发性内存网络可以学习和表达神经元网络连接图。这是一个直接将大脑的神经元网络连接图下载到记忆内存芯片上的方案。</p>
<img src="/f47c3812/3.png" class>

<p>此研究为神经元连接研究提供了新的方向，势必会吸引更多的研究人员参与相关领域研究，为打破神经形态工程界限提供更多助力。虽然这个技术方法的提出非常具有创新性，但这仍处于开始阶段。这项研究还没有真正应用，或许它距离商业化还有几年的时间。但是，三星表示仍将探索这些概念以将它们应用到当前的解决方案中。例如，该公司将研究神经形态工程，并利用其部分资源开发下一代人工智能半导体。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://xw.qq.com/cmsid/20211007A059QN00">https://xw.qq.com/cmsid/20211007A059QN00</a><br><a href="https://baijiahao.baidu.com/s?id=1712053940913750214">https://baijiahao.baidu.com/s?id=1712053940913750214</a><br><a href="https://www.zhongguojinrongtouziwang.com/keji/202109/78900.html">https://www.zhongguojinrongtouziwang.com/keji/202109/78900.html</a><br><a href="https://baijiahao.baidu.com/s?id=1712225322557726758">https://baijiahao.baidu.com/s?id=1712225322557726758</a></p>
</blockquote>
<hr>
<h3 id="论文完整链接"><a href="#论文完整链接" class="headerlink" title="论文完整链接"></a>论文完整链接</h3><blockquote>
<p><a href="https://www.nature.com/articles/s41928-021-00646-1">https://www.nature.com/articles/s41928-021-00646-1</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10950">https://www.scholat.com/teamwork/showPostMessage.html?id=10950</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-华为公布三维人脸重建专利，可用于驾驶员监测系统</title>
    <url>/e2b6d25a.html</url>
    <content><![CDATA[<p>日前，华为技术有限公司公布一项涉及智能汽车的专利：“人脸图像处理方法、装置和车辆”[1]。根据专利摘要显示，提出的方法首先获取人脸图像中的局部人脸形状特征，在数据库中获取与所述局部特征匹配的人脸样本，进一步获取人脸形状参数。然后基于参数化人脸模型生成三维人脸，并进行优化拟合以完成三维人脸重建。由于该专利基于局部人脸形状特征，能够实现在人脸被遮挡或被剪裁的情况下进行三维人脸重建，并且<strong>该方法可以用于智能汽车领域，例如驾驶员监测系统。</strong></p>
<img src="/e2b6d25a/1.jpg" class>

<span id="more"></span>

<p>三维人脸重建一直是计算机视觉和计算机图形学的研究热点。三维人脸的重建是虚拟现实/增强显示、自动驾驶、机器人等领域的核心技术之一，并且在智能汽车领域驾驶员状态监测系统中具有极大的应用价值。<strong>三维人脸重建技术可以用于监测驾驶员的头部姿态、视线方向等等，从而实时监控驾驶员注意力状态。</strong></p>
<p>对车辆驾驶员进行状态监测时，经常会出现人手、方向盘、手机、食物等导致的图像中人脸面部区域被遮挡的情况。遮挡会使得人脸图像的固有特征呈现为各种局部特征的缺失，从而导致三维人脸重建失真甚至失败，严重影响三维人脸重建的性能，限制了三维人脸重建的应用场景。因此，<strong>华为提出了一种在遮挡条件下具有良好鲁棒性的三维人脸重建方法应用于人脸图像处理中。</strong></p>
<img src="/e2b6d25a/2.jpg" class>

<p>华为提出的人脸图像处理方法如图所示。该方法的具体步骤如下：</p>
<ol>
<li>通过双目摄像头或RGB-D摄像头获取包含局部人脸区域的图像及其相应的深度信息。</li>
<li>利用MobileNet-V2（或其他网络）获取图像中的目标人脸区域。采用YOLOv2网络（或其他网络）进行局部人脸区域的提取。局部人脸稀疏特征的提取采用ResNet-50（或其他特征提取网络）实现。</li>
<li>将提取的局部特征与人脸数据库中的各个三维人脸样本的特征进行相似度匹配，获得匹配的三维人脸样本对应的形状参数。</li>
<li>根据形状参数构建对应的参数化人头模型。此处采用的参数化人头模型是FLAME模型，人头网格由5023个顶点和9976个三角面组成，并采用主成分分析法得到形状、表情和姿态的主成分，由此确定一个完整的参数化三维人头模型。</li>
<li>另一方面，利用局部人脸区域的各个关键点的三维坐标信息与所建立的三维人头模型采用点云匹配算法（如ICP）进行刚体变换，实现三维人头模型与相机坐标系中局部人脸区域点云的初步对齐，然后利用参数拟合算法（如拟牛顿算法）进行拟合优化，完成三维重建。</li>
</ol>
<p>由于该方法是根据人脸局部特征进行三维重建，因此该方法针对人脸发生部分遮挡或大角度姿态发生自遮挡的情况能够重建出具有较好效果的三维人脸模型。下表展示了用离散随机事件模型仿真的方法估算人脸发生不同比例的遮挡时，传统三维人脸重建与使用该方法进行三维人脸重建的失败的比例。可见，提出的方法实现三维人脸重建具有更好的鲁棒性，相比传统的三维人脸重建，在不同的人脸遮挡比例下，重建失败比例都偏低，尤其是当人脸遮挡较大情况下重建失败的比例仍然较低。</p>
<img src="/e2b6d25a/3.jpg" class>

<p>该方法可以应用于对车辆、飞机等交通工具内的人员，如对驾驶员的面部进行三维重建，从而可以根据重建后的三维人脸，判断驾驶员的头部姿态、视线方向等，以对驾驶员的状态进行识别。同样的，可以应用于教学授课场景中，根据学生的头部姿态、视线方向等信息确定学生的注意力方向、注意力程度等。还可以应用于移动终端，如手机、平板电脑、便携式电脑所采集的人员的脸部图像进行三维人脸重建。甚至可以应用在人脸图像修复等技术领域，对关键信息缺失的人脸图像进行修复。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://cprs.patentstar.com.cn/Search/Detail?ANE=7DCA9CIB2AAA9HBADHFA9EFA9IHG7GBA5CBA0AAA6DBA6EBA">https://cprs.patentstar.com.cn/Search/Detail?ANE=7DCA9CIB2AAA9HBADHFA9EFA9IHG7GBA5CBA0AAA6DBA6EBA</a><br><a href="https://zhuanlan.zhihu.com/p/432139253">https://zhuanlan.zhihu.com/p/432139253</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=10963">https://www.scholat.com/teamwork/showPostMessage.html?id=10963</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-什么是范数</title>
    <url>/da6b54c.html</url>
    <content><![CDATA[<h3 id="什么是范数"><a href="#什么是范数" class="headerlink" title="什么是范数"></a>什么是范数</h3><p>我们知道距离的定义是一个宽泛的概念，只要满足<strong>非负、自反、三角不等式</strong>就可以称之为距离。范数是一种强化了的距离概念，它在定义上比距离多了一条数乘的运算法则。有时候为了便于理解，我们可以把范数当作距离来理解。</p>
<p>在数学上，范数包括<strong>向量范数</strong>和<strong>矩阵范数</strong>，向量范数表征向量空间中向量的大小，矩阵范数表征矩阵引起变化的大小。一种非严密的解释就是，对应向量范数，向量空间中的向量都是有大小的，这个大小如何度量，就是用范数来度量的，不同的范数都可以来度量这个大小，就好比米和尺都可以来度量远近一样；对于矩阵范数，学过线性代数，我们知道，通过运算AX=B，可以将向量X变化为B，矩阵范数就是来度量这个变化大小的。</p>
<p>向量的范数表示这个原有集合的大小。</p>
<p>矩阵的范数表示这个变化过程的大小的一个度量。</p>
<p>简单说：L0范数表示向量中非零元素的个数（即为其稀疏度），L1范数表示为绝对值之和，而L2范数则指模。</p>
<span id="more"></span>

<hr>
<h3 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h3><h4 id="L-P范数"><a href="#L-P范数" class="headerlink" title="L-P范数"></a>L-P范数</h4><p>x 的 n 范数：x 到零点的 n 阶闵氏距离。即向量元素绝对值的p次方和的1/p次幂</p>
<img src="/da6b54c/1.svg" class>

<p>根据P的变化，范数也有着不同的变化，一个经典的有关P范数的变化图如下：</p>
<img src="/da6b54c/11.png" class>

<p>实际上，在0时，Lp并不满足三角不等式的性质，也就不是严格意义下的范数。</p>
<hr>
<h4 id="0-范数"><a href="#0-范数" class="headerlink" title="0-范数"></a>0-范数</h4><p>x 的 0 范数：x 到零点的汉明距离。表示向量 x 中非零元素的个数。</p>
<p>当P = 0时，也就是L0范数，L0范数并不是一个真正的范数，它主要被用来度量向量中非零元素的个数。</p>
<img src="/da6b54c/12.svg" class>

<p>对于L0范数，其优化问题为：</p>
<img src="/da6b54c/13.svg" class>

<p>在实际应用中，由于L0范数本身不容易有一个好的数学表示形式，给出上面问题的形式化表示是一个很难的问题，故被人认为是一个NP难问题。所以在实际情况中，L0的最优问题会被放宽到L1或L2下的最优化。</p>
<hr>
<h4 id="1-范数"><a href="#1-范数" class="headerlink" title="1-范数"></a>1-范数</h4><p>x 的 0 范数：x 到零点的汉明距离。表示向量 x 中非零元素的绝对值之和。</p>
<img src="/da6b54c/2.svg" class>

<p>L1范数有很多的名字，例如我们熟悉的曼哈顿距离、最小绝对误差等。使用L1范数可以度量两个向量间的差异，如绝对误差和（Sum of Absolute Difference）： </p>
<img src="/da6b54c/14.png" class>

<p>对于L1范数，它的优化问题如下： </p>
<img src="/da6b54c/15.png" class>

<img src="/da6b54c/16.png" class>

<p>由于L1范数的天然性质，对L1优化的解是一个稀疏解，因此L1范数也被叫做稀疏规则算子。通过L1可以实现特征的稀疏，去掉一些没有信息的特征，例如在对用户的电影爱好做分类的时候，用户有100个特征，可能只有十几个特征是对分类有用的，大部分特征如身高体重等可能都是无用的，利用L1范数就可以过滤掉。</p>
<hr>
<h4 id="2-范数"><a href="#2-范数" class="headerlink" title="2-范数"></a>2-范数</h4><p>x 的 2 范数：x 到零点的欧氏距离。Euclid范数（欧几里得范数，常用计算向量长度），表示向量元素的平方和再开平方。 </p>
<img src="/da6b54c/3.svg" class>

<p>L2范数是我们最常见最常用的范数了，像L1范数一样，L2也可以度量两个向量间的差异，如平方差和（Sum of Squared Difference）: </p>
<img src="/da6b54c/17.png" class>

<p>对于L2范数，它的优化问题如下： </p>
<img src="/da6b54c/18.png" class>

<img src="/da6b54c/19.png" class>

<p>L2范数通常会被用来做优化目标函数的正则化项，防止模型为了迎合训练集而过于复杂造成过拟合的情况，从而提高模型的泛化能力。</p>
<hr>
<h4 id="∞-范数"><a href="#∞-范数" class="headerlink" title="∞-范数"></a>∞-范数</h4><p>x 的无穷范数：x 到零点的切比雪夫距离。即所有向量元素绝对值中的最大值/最小值</p>
<img src="/da6b54c/4.svg" class>

<img src="/da6b54c/5.svg" class>

<hr>
<h3 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h3><h4 id="1-范数-1"><a href="#1-范数-1" class="headerlink" title="1-范数"></a>1-范数</h4><p>列和范数，即所有矩阵列向量绝对值之和的最大值</p>
<img src="/da6b54c/6.svg" class>

<h4 id="2-范数-1"><a href="#2-范数-1" class="headerlink" title="2-范数"></a>2-范数</h4><p>谱范数，即AᵀA矩阵的最大特征值的开平方（λ为AᵀA的最大特征值）</p>
<img src="/da6b54c/7.svg" class>

<h4 id="∞-范数-1"><a href="#∞-范数-1" class="headerlink" title="∞-范数"></a>∞-范数</h4><p>行和范数，即所有矩阵行向量绝对值之和的最大值</p>
<img src="/da6b54c/8.svg" class>

<h4 id="F-范数"><a href="#F-范数" class="headerlink" title="F-范数"></a>F-范数</h4><p>Frobenius范数，即矩阵元素绝对值的平方和再开平方</p>
<img src="/da6b54c/9.svg" class>

<h4 id="核范数"><a href="#核范数" class="headerlink" title="核范数"></a>核范数</h4><p>即奇异值之和（λᵢ是A的奇异值）</p>
<img src="/da6b54c/10.svg" class>

<hr>
<h3 id="机器学习中的范数"><a href="#机器学习中的范数" class="headerlink" title="机器学习中的范数"></a>机器学习中的范数</h3><p>在很多机器学习相关的著作和教材中，我们经常看到各式各样的距离及范数，如：∥𝓍∥、∥𝑿∥，其中，𝓍 和 𝑿 分别表示向量和矩阵。</p>
<hr>
<h4 id="与L0范数相关"><a href="#与L0范数相关" class="headerlink" title="与L0范数相关"></a>与L0范数相关</h4><p>在诸多机器学习模型中，比如压缩感知（compressive sensing），我们很多时候希望最小化向量的L0范数。然而，由于L0范数仅仅表示向量中非0元素的个数，因此这个优化模型在数学上被认为是一个NP-hard问题，即直接求解它很复杂、也不可能找到解。需要注意的是，正是由于该类优化问题难以求解，因此压缩感知模型是将L0范数最小化问题转换成L1范数最小化问题。</p>
<hr>
<h4 id="与L1范数相关"><a href="#与L1范数相关" class="headerlink" title="与L1范数相关"></a>与L1范数相关</h4><p>L1范数优化问题比L0范数优化问题更容易求解，借助现有凸优化算法（线性规划或是非线性规划），就能够找到我们想要的可行解。鉴于此，依赖于L1范数优化问题的机器学习模型如压缩感知就能够进行求解了。</p>
<hr>
<h4 id="正则项与稀疏解"><a href="#正则项与稀疏解" class="headerlink" title="正则项与稀疏解"></a>正则项与稀疏解</h4><p>在机器学习的诸多方法中，假设给定了一个比较小的数据集让我们来做训练，我们常常遇到的问题可能就是<strong>过拟合</strong> (over-fitting) 了，即训练出来的模型可能将数据中隐含的噪声和毫无关系的特征也表征出来。</p>
<p>为了避免类似的过拟合问题，一种解决方法是在 (机器学习模型的) 损失函数中加入正则项，比如用<strong>L1范数</strong>表示的正则项，只要使得<strong>L1范数</strong>的数值尽可能变小，就能够让我们期望的解变成一个<strong>稀疏解</strong> (即解的很多元素为0)。</p>
<p>如果我们想解决的优化问题是损失函数 f(𝓍) 最小化，那么，考虑由L1范数构成的正则项后，优化目标就变成：</p>
<img src="/da6b54c/20.svg" class>

<p>尽管类似的优化模型看起来很“简练”，在很多著作和教材中也会加上这样一句说明：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">只要优化模型的解 𝓍 的 L1范数比较小，那么这个解就是稀疏解，并且稀疏解可以避免过拟合。其中，“稀疏”一词可以理解为 𝓍 中的大多数元素都是0，只有少量的元素是非0的。</span><br></pre></td></tr></table></figure>

<p>可能比较难理解，接下来做简要说明，为了理解L1范数的正则项和稀疏性之间的关系，我们可以想想下面三个问题：</p>
<ul>
<li>为什么L1范数就能使得我们得到一个稀疏解呢？</li>
<li>为什么稀疏解能够避免过拟合？</li>
<li>正则项在模型中扮演者何种角色？</li>
</ul>
<hr>
<h5 id="什么是过拟合问题？"><a href="#什么是过拟合问题？" class="headerlink" title="什么是过拟合问题？"></a>什么是过拟合问题？</h5><p>假设我们现在买了一个机器人，想让它学会区分汉字，例如：</p>
<img src="/da6b54c/21.png" class>

<p>认定前5个字属于第一类，后5个字属于第二类。在这里，10个字是所有的训练“数据”。如果机器人很聪明，它能够把所有的字都“记住”，看过这10个字以后，机器人学会了一种<strong>分类</strong>的方式：它把前5个字的一笔一划都准确地记在心里。只要我们给任何一个字，如“揪”（不在10个字里面），它就会很自信地告诉你，非此即彼，这个字属于第二类。机器人没见过这个字，它将这个字归为第二类，这可能就错了。</p>
<p>因为我们可以明显看到，前5个字都带提手旁。所以，“揪”属于第一类。机器人的失败在于它太聪明，而训练数据又太少，不允许它那么聪明，这就是过拟合问题。</p>
<hr>
<h5 id="正则项是什么？为什么稀疏可以避免过拟合？"><a href="#正则项是什么？为什么稀疏可以避免过拟合？" class="headerlink" title="正则项是什么？为什么稀疏可以避免过拟合？"></a>正则项是什么？为什么稀疏可以避免过拟合？</h5><p>其实可以让机器人变笨一点，希望它不要记那么多东西。</p>
<p>还是给它前面测试过的那10个字，但现在机器人已经没办法记住前5个字的一笔一划了（存储有限），它此时只能记住一些简单的模式，于是，第一类字都带有提手旁就被它成功地发现了。</p>
<p>实际上，这就是L1范数正则项的作用。L1范数会让你的模型变傻一点，相比于记住事物本身，此时机器人更倾向于从数据中找到一些简单的模式。</p>
<p>机器人原来的解：[把, 打, 扒, 捕, 拉]<br>机器人变傻以后的解：[扌, 0, 0, 0, 0]</p>
<p>比较正式的解释如下：</p>
<p>假设我们有一个待训练的机器学习模型：A𝓍 = b</p>
<p>其中， A 是一个训练数据构成的矩阵， b 是一个带有标签的向量，这里的 𝓍 是我们希望求解出来的解。</p>
<p>当训练样本很少 (training data is not enough)、向量 𝓍 长度很长时，这个模型的解就很多了。</p>
<img src="/da6b54c/22.png" class>

<p>如图，矩阵 A 的行数远少于向量 𝓍 的长度。</p>
<p>我们希望的是找到一个比较合理的解，即向量 𝓍 能够发现有用的特征 (useful features)。使用L1范数作为正则项，向量 𝓍 会变得稀疏，非零元素就是有用的特征了。</p>
<p>当然这里也有一个比较生动的例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Suppose you are the king of a kingdom that has a large population and an OK overall GDP, but the per capita is very low. Each one of your citizens is lazy and unproductive and you are mad. Therefore you command “be productive, strong and hard working, or you die!” And you enforce the same GDP as before. As a result, many people died due to your harshness, those who survived your tyranny became really capable and productive. [example]</span><br></pre></td></tr></table></figure>

<p>如果把总人口总量视作向量 𝓍 的长度，那么<strong>优胜劣汰其实相当于增加了一个正则项</strong>。在稀疏的结果中，我们能够保证向量 𝓍 的每个元素都是有用的！</p>
<p>到这里，我们知道了为什么稀疏可以避免过拟合。</p>
<hr>
<h5 id="为什么增加L1范数能够保证稀疏？"><a href="#为什么增加L1范数能够保证稀疏？" class="headerlink" title="为什么增加L1范数能够保证稀疏？"></a>为什么增加L1范数能够保证稀疏？</h5><p>根据L1范数的定义，向量的L1范数是所有元素的绝对值之和，以向量 [x, y]ᵀ 为例，其L1范数为 |x| + |y|</p>
<p>选取两个向量：x1 = [0.1, 0.1]ᵀ 、 x2 = [1000, 0]ᵀ</p>
<p>其中，x1很明显不是一个稀疏向量，但其L1范数∥x1∥ = |0.1| + |0.1| = 0.2 却远小于稀疏向量x2的L1范数∥x2∥ = |1000| + |0| = 1000</p>
<p>仅仅是看L1范数的数值大小，我们可能很难比较向量的稀疏程度，因此，需要结合损失函数。</p>
<p>再回到前面的问题：A𝓍 = b，在平面直角坐标系上，假设一次函数 y = ax + b 经过点(10, 5) ，则</p>
<img src="/da6b54c/23.png" class>

<p>由于 b = 5 - 10a ，所以参数a, b的解有无数组 (在蓝线上的点都是解)。</p>
<img src="/da6b54c/24.png" class>

<p>怎样通过L1范数找到一个稀疏解呢？</p>
<p>我们不妨先假设向量的L1范数是一个常数c ，如下图：</p>
<img src="/da6b54c/25.png" class>

<p>它的形状是一个正方形 (红色线)，不过在这些边上只有<strong>很少的点是稀疏</strong>的，即<strong>与坐标轴相交的4个顶点</strong>。</p>
<img src="/da6b54c/26.png" class>

<p>把红色的正方形（L1范数为常数）与蓝色的线 (解) 放在同一个坐标系，于是，我们发现蓝线与横轴的交点恰好是满足稀疏性要求的解。同时，这个交点使得L1范数取得最小值。</p>
<hr>
<h4 id="最简单的最小二乘线性模型"><a href="#最简单的最小二乘线性模型" class="headerlink" title="最简单的最小二乘线性模型"></a>最简单的最小二乘线性模型</h4><p>最开始，最小二乘的loss（需优化的目标函数）如下：</p>
<img src="/da6b54c/27.png" class>

<p>式中，tn是目标变量，xn是观测量（自变量），Φ是基函数（后期推导与核化相关），是w是参数。此式有闭式解，解为：</p>
<img src="/da6b54c/28.png" class>

<p>但是我们都知道，矩阵求逆是一个病态问题，即矩阵并不是在所有情况下都有逆矩阵。所以上述式子在实际使用时会遇到问题。为了解决这个问题，可以求其近似解。可以用SGD(梯度下降法)求一个近似解，或者加入正则项（L2范数）。加入正则项是我们这里要说的。加入L2范数的正则项可以解决这个病态问题，并且也可以得到闭式解，在实际使用时要比用SGD快，并且加入正则化后的好处并不仅仅是这些。加入正则项（L2范数）的loss如下：</p>
<img src="/da6b54c/29.png" class>

<p>其闭式解为：</p>
<img src="/da6b54c/30.png" class>

<p>此式在 λ 不为零时，总是有解的，所以是一个非病态的问题，这在实际使用时很好。除了这一点，2范数的正则项还有其他好处，比如控制方差和偏差的关系，得到一个好的拟合，这里就不赘述了，毕竟这里讲的是范数，有兴趣可以参阅相关资料。</p>
<p>加入正则项后一般情况下的loss为：</p>
<img src="/da6b54c/31.png" class>

<p>好了，我们终于可以专注于范数了。不同范数对应的曲线如下图：</p>
<img src="/da6b54c/32.jpg" class>

<p>上图中，可以明显看到一个趋势，即q越小，曲线越贴近坐标轴，q越大，曲线越远离坐标轴，并且棱角越明显。q = 0 和 q = ∞ 时极限情况如下：</p>
<img src="/da6b54c/33.png" class>

<p>除了图形上的直观形象，在数学公式的推导中，q = 0 和 q = ∞ 时两种极限的行为可以简记为非零元的个数和最大项。即L0范数对应向量或矩阵中非零元的个数，无穷范数对应向量或矩阵中最大的元素。</p>
<img src="/da6b54c/34.jpg" class>

<p>上图中，蓝色的圆圈表示原问题可能的解范围，橘色的表示正则项可能的解范围。而整个目标函数（原问题+正则项）有解当且仅当两个解范围相切。从上图可以很容易地看出，由于L2范数解范围是圆，所以相切的点有很大可能不在坐标轴上，而由于L1范数是菱形（顶点是凸出来的），其相切的点更可能在坐标轴上，而坐标轴上的点有一个特点，其只有一个坐标分量不为零，其他坐标分量为零，即是稀疏的。</p>
<p>所以有如下结论，L1范数可以导致稀疏解，L2范数导致稠密解。那么为什么不用L0范数呢，理论上它是求稀疏解最好的规范项了。然而在机器学习中，特征的维度往往很大，解L0范数又是NP-hard问题，所以在实际中不可行。但是用L1范数解是可行的，并且也可以得到稀疏解，所以实际稀疏模型中用L1范数约束。</p>
<p>至此，我们总结一下，在机器学习中，以L0范数和L1范数作为正则项，可以求得稀疏解，但是L0范数的求解是NP-hard问题; 以L2范数作为正则项可以得到稠密解，并且由于其良好的性质，其解的定义很好，往往可以得到闭式解，所以用的很多。</p>
<p>另外，从距离的角度说一下范数。1范数对应街区距离，2范数对应大家熟知的欧式距离，无穷范数对应棋盘距离（切比雪夫距离）。</p>
<img src="/da6b54c/35.png" class>

<img src="/da6b54c/36.png" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/a493823882/article/details/80569888">https://blog.csdn.net/a493823882/article/details/80569888</a><br><a href="https://www.zhihu.com/question/20473040">https://www.zhihu.com/question/20473040</a><br><a href="https://zhuanlan.zhihu.com/p/26884695">https://zhuanlan.zhihu.com/p/26884695</a><br><a href="https://blog.csdn.net/susanzhang1231/article/details/52127011">https://blog.csdn.net/susanzhang1231/article/details/52127011</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-关于BN和LN的一些补充</title>
    <url>/2b3c20c7.html</url>
    <content><![CDATA[<h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><h4 id="独立同分布与白化"><a href="#独立同分布与白化" class="headerlink" title="独立同分布与白化"></a>独立同分布与白化</h4><h5 id="独立同分布"><a href="#独立同分布" class="headerlink" title="独立同分布"></a>独立同分布</h5><p>独立同分布：independent and identically distributed</p>
<ul>
<li>强相关：Naive Bayes 模型就建立在特征彼此独立的基础</li>
<li>弱相关：Logistic Regression 和 神经网络 则在非独立的特征数据上依然可以训练出很好的模型</li>
</ul>
<p>独立同分布的数据可以简化常规机器学习模型的训练、提升机器学习模型的预测能力</p>
<h5 id="白化"><a href="#白化" class="headerlink" title="白化"></a>白化</h5><p>【数据预处理步骤】</p>
<p>去除特征间的相关性 -&gt; 独立<br>使所有特征具有相同的均值和方差 -&gt; 同分布</p>
<span id="more"></span>

<hr>
<h4 id="ICS"><a href="#ICS" class="headerlink" title="ICS"></a>ICS</h4><p>什么叫做“Internal Covariate Shift”呢？ 看一下下图所示的sigmoid函数图：</p>
<img src="/2b3c20c7/6.png" class>

<p>可以看出当<strong>x</strong>值在<strong>0</strong>附近时，其<strong>导数较大</strong>，<strong>靠近两边</strong>时<strong>导数很小</strong>。而在深度神经网络中，如果不加以约束，则<strong>激活函数的输入值很容易向两边偏移，导致导数变小</strong>，这样会使得网络训练<strong>变慢</strong>，而且逐层累乘后还会产生<strong>梯度消失</strong>现象。所以normalization的作用相当于<strong>数据在经过每层时都将它拉回为一个统一分布</strong>。</p>
<p>深度神经网络涉及到很多层的叠加，而每一层的参数更新会导致上层的输入数据分布发生变化，通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。</p>
<p>模型训练对于数据的一个假设：“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如 transfer learning / domain adaptation 等。而 covariate shift 就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同</p>
<p>ICS（每个神经元的输入数据不再是“独立同分布”）导致的后果：</p>
<ul>
<li>上层参数需要不断适应新的输入数据分布，降低学习速度</li>
<li>下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止</li>
<li>每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎</li>
</ul>
<hr>
<h4 id="ICS带来的后果"><a href="#ICS带来的后果" class="headerlink" title="ICS带来的后果"></a>ICS带来的后果</h4><ol>
<li>上层参数需要不断适应新的输入数据分布，导致学习速度下降</li>
<li>下层输入的变化可能趋于变大或变小，导致上层落入饱和区，从而学习过早停止</li>
<li>每层的更新都会影响到其他层，因此每层参数更新策略需要尽可能谨慎</li>
</ol>
<hr>
<h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><h4 id="通用框架与基本思想"><a href="#通用框架与基本思想" class="headerlink" title="通用框架与基本思想"></a>通用框架与基本思想</h4><p>假设神经元的输入：</p>
<img src="/2b3c20c7/1.png" class>

<p>输出的结果：</p>
<img src="/2b3c20c7/2.png" class>

<p>ICS 问题：X 的分布可能相差很大</p>
<p>解决方法：</p>
<ul>
<li>方法：对每一层的数据做白化操作</li>
<li>存在问题：成本高，因为要保证白化操作是可微的</li>
</ul>
<p>基本思想：在将 x 送给神经元之前，先对其做平移和伸缩变换，将 x 的分布规范化成在固定区间范围的标准分布</p>
<p>变换框架：（μ：平移参数，δ：缩放参数）</p>
<img src="/2b3c20c7/3.png" class>

<p>步骤：</p>
<ol>
<li>对 x 进行 shift 和 scale 变换，得到的数据符合均值为 0、方差为 1 的标准分布</li>
</ol>
<img src="/2b3c20c7/4.png" class>

<ol start="2">
<li>b 是再平移参数（re-shift parameter），g 是再缩放参数（re-scale parameter），再进一步变换，得到的数据符合均值为 b 、方差为 g² 的分布</li>
</ol>
<img src="/2b3c20c7/5.png" class>

<hr>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><h4 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h4><p>Batch Normalization（纵向规范化）</p>
<p>论文：<a href="https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p>
<p>从论文名字就可以看出，BatchNorm技术是用来加速网络训练的，手段就是通过“Reducing Internal Covariate Shift（减小内部协变量偏移）”</p>
<p>BatchNorm的缺点：</p>
<ol>
<li>需要较大的batch以体现整体数据分布</li>
<li>训练阶段需要保存每个batch的均值和方差，以求出整体均值和方差在infrence阶段使用</li>
<li>不适用于可变长序列的训练，如RNN</li>
</ol>
<img src="/2b3c20c7/8.png" class>

<p>方式：针对单个神经元进行，利用网络训练时一个 mini-batch 的数据来计算该神经元 𝓍ᵢ 的均值和方差，因而称为 Batch Normalization，其中 M 是 mini-batch 的大小。</p>
<img src="/2b3c20c7/9.png" class>

<p>batch normalization过程如下：</p>
<img src="/2b3c20c7/7.png" class>

<p>其中 𝓍ᵢ 是线性激活值。首先求出均值和方差，之后再减去均值、除以方差。参数 ε 应该是为了防止因为方差接近0而使得除以0无限大的问题，所以在pytorch中 ε 是一个比较小的值：1e-5。为了防止网络表达性下降，又在normalization之后添加一个逆变换，即将 𝓍 乘以一个缩放值 γ 并加上一个偏移量 β，其中 γ 和 β 都是可学习参数。</p>
<p>因此，normalization其实更像是另一个神经网络层，因为有可学习参数存在，但是参数量相对来说是极少的，与线性变换中 y = wx + b 的 b 参数量一致，为神经元个数。</p>
<hr>
<h4 id="适用的场景"><a href="#适用的场景" class="headerlink" title="适用的场景"></a>适用的场景</h4><p>每个 mini-batch 比较大，数据分布比较接近。在进行训练之前，要做好充分的 shuffle，否则效果会差很多。</p>
<hr>
<h4 id="存在什么问题"><a href="#存在什么问题" class="headerlink" title="存在什么问题"></a>存在什么问题</h4><p>BN 独立地规范化每一个输入维度 𝓍ᵢ，但规范化的参数是一个 mini-batch 的一阶统计量和二阶统计量。这就要求每一个 mini-batch 的统计量是整体统计量的近似估计，或者说每一个 mini-batch 彼此之间，以及和整体数据，都应该是近似同分布的。</p>
<p>分布差距较小的 mini-batch 可以看做是为规范化操作和模型训练引入了噪声，可以增加模型的鲁棒性；但如果每个 mini-batch 的原始分布差别很大，那么不同 mini-batch 的数据将会进行不一样的数据变换，这就增加了模型训练的难度。</p>
<p>由于 BN 需要在运行过程中统计每个 mini-batch 的一阶统计量和二阶统计量，因此不适用于<strong>动态的网络结构</strong>和<strong>RNN网络</strong>。</p>
<ol>
<li>BN 特别依赖 Batch Size。当 Batch size 很小的时候，BN 的效果就非常不理想了。在很多情况下，Batch size 大不了是因为你GPU的显存不够。所以通常会有其他比较麻烦的手段去解决这个问题，比如 MegDet 的 CGBN 等</li>
<li>BN对处理序列化数据的网络比如 RNN 是不太适用的</li>
<li>BN只在训练的时候用，inference的时候不会用到，因为inference的输入不是批量输入</li>
</ol>
<hr>
<h3 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h3><h4 id="是什么-1"><a href="#是什么-1" class="headerlink" title="是什么"></a>是什么</h4><p>Layer Normalization（横向规范化）</p>
<img src="/2b3c20c7/10.png" class>

<p>方式：综合考虑一层所有维度的输入，计算该层的平均输入值和输入方差，然后用同一个规范化操作来转换各个维度的输入。</p>
<img src="/2b3c20c7/11.png" class>

<p>其中 i 枚举了该层所有的输入神经元。对应到标准公式中，四大参数 μ, δ, g, b 均为标量（BN中是向量），所有输入共享一个规范化变换。</p>
<hr>
<h4 id="有什么用"><a href="#有什么用" class="headerlink" title="有什么用"></a>有什么用</h4><p>LN 针对单个训练样本进行，不依赖于其他数据，因此可以避免 BN 中受 mini-batch 数据分布影响的问题，可以用于 小mini-batch场景、动态网络场景和 RNN，特别是自然语言处理领域。此外，LN 不需要保存 mini-batch 的均值和方差，节省了额外的存储空间。</p>
<p>LayerNorm 克服了 BatchNorm 的缺点，在特征维度进行归一化，对每个 Batch 有一个均值和方差，因此不依赖于 batch 大小，即使 batch 为 1 也能使用。</p>
<p>LayerNorm 只是归一化的维度与 BatchNorm 有所区别，但是其他区别不大。LayerNorm 中也存在 γ 和 β 可学习参数，并且 γ 和 β 是在特征维度进行，而不是在 Batch 维度。</p>
<p>例如 input 是 batch × seq_len × hidden，则 Layer 首先在 hidden 维度求出 batch × seq_len 个标准差和均值，再使用它们进行归一化，但 γ 和 β 只有 hidden 个，因此 LayerNorm 归一化之后的缩放是在特征维度上进行。</p>
<hr>
<h4 id="具体使用"><a href="#具体使用" class="headerlink" title="具体使用"></a>具体使用</h4><h5 id="使用numpy实现LayerNorm"><a href="#使用numpy实现LayerNorm" class="headerlink" title="使用numpy实现LayerNorm"></a>使用numpy实现LayerNorm</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=array([[[-<span class="number">0.66676328</span>, -<span class="number">0.95822262</span>,  <span class="number">1.2951657</span> ,  <span class="number">0.67924618</span>],</span><br><span class="line">        [-<span class="number">0.46616455</span>, -<span class="number">0.39398589</span>,  <span class="number">1.95926177</span>,  <span class="number">2.36355916</span>],</span><br><span class="line">        [-<span class="number">0.39897415</span>,  <span class="number">0.80353481</span>, -<span class="number">1.46488175</span>,  <span class="number">0.55339737</span>]],</span><br><span class="line"> </span><br><span class="line">       [[-<span class="number">0.66223895</span>, -<span class="number">0.16435625</span>, -<span class="number">1.96494932</span>, -<span class="number">1.07376919</span>],</span><br><span class="line">        [ <span class="number">1.30338369</span>, -<span class="number">0.19603094</span>, -<span class="number">1.43136723</span>, -<span class="number">1.0207508</span> ],</span><br><span class="line">        [ <span class="number">0.8452505</span> , -<span class="number">0.08878595</span>, -<span class="number">0.5211611</span> ,  <span class="number">0.10511936</span>]]])</span><br><span class="line">u=np.mean(a, axis=(<span class="number">2</span>,))</span><br><span class="line">s = np.std(a, axis=(<span class="number">2</span>,))</span><br><span class="line"> </span><br><span class="line">y = a-u[...,<span class="literal">None</span>]</span><br><span class="line">y = y/s[...,<span class="literal">None</span>]</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">########################输出###################################</span></span><br><span class="line">array([[[-<span class="number">0.80954074</span>, -<span class="number">1.12241971</span>,  <span class="number">1.29657224</span>,  <span class="number">0.63538821</span>],</span><br><span class="line">        [-<span class="number">1.0214588</span> , -<span class="number">0.96610083</span>,  <span class="number">0.83874033</span>,  <span class="number">1.14881929</span>],</span><br><span class="line">        [-<span class="number">0.30472338</span>,  <span class="number">1.04125172</span>, -<span class="number">1.49779981</span>,  <span class="number">0.76127147</span>]],</span><br><span class="line"> </span><br><span class="line">       [[ <span class="number">0.46047519</span>,  <span class="number">1.21440667</span>, -<span class="number">1.51218696</span>, -<span class="number">0.16269489</span>],</span><br><span class="line">        [ <span class="number">1.56757537</span>,  <span class="number">0.13400543</span>, -<span class="number">1.04708279</span>, -<span class="number">0.65449801</span>],</span><br><span class="line">        [ <span class="number">1.53885365</span>, -<span class="number">0.35203004</span>, -<span class="number">1.2273397</span> ,  <span class="number">0.04051609</span>]]])</span><br></pre></td></tr></table></figure>

<h5 id="Pytorch的LayerNorm"><a href="#Pytorch的LayerNorm" class="headerlink" title="Pytorch的LayerNorm"></a>Pytorch的LayerNorm</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"> </span><br><span class="line"><span class="built_in">input</span> = torch.tensor(a)</span><br><span class="line">y = F.layer_norm(<span class="built_in">input</span>,(<span class="number">4</span>,))</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#####################输出################</span></span><br><span class="line">tensor([[[-<span class="number">0.8095</span>, -<span class="number">1.1224</span>,  <span class="number">1.2966</span>,  <span class="number">0.6354</span>],</span><br><span class="line">         [-<span class="number">1.0215</span>, -<span class="number">0.9661</span>,  <span class="number">0.8387</span>,  <span class="number">1.1488</span>],</span><br><span class="line">         [-<span class="number">0.3047</span>,  <span class="number">1.0412</span>, -<span class="number">1.4978</span>,  <span class="number">0.7613</span>]],</span><br><span class="line"> </span><br><span class="line">        [[ <span class="number">0.4605</span>,  <span class="number">1.2144</span>, -<span class="number">1.5122</span>, -<span class="number">0.1627</span>],</span><br><span class="line">         [ <span class="number">1.5676</span>,  <span class="number">0.1340</span>, -<span class="number">1.0471</span>, -<span class="number">0.6545</span>],</span><br><span class="line">         [ <span class="number">1.5388</span>, -<span class="number">0.3520</span>, -<span class="number">1.2273</span>,  <span class="number">0.0405</span>]]])</span><br></pre></td></tr></table></figure>

<h5 id="Pytorch-LayerNorm添加缩放"><a href="#Pytorch-LayerNorm添加缩放" class="headerlink" title="Pytorch LayerNorm添加缩放"></a>Pytorch LayerNorm添加缩放</h5><p>的确是只在特征维度进行缩放</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">w = torch.tensor([<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">b = torch.tensor([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">y = F.layer_norm(<span class="built_in">input</span>,(<span class="number">4</span>,),w,b)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#########################输出######################</span></span><br><span class="line">tensor([[[ <span class="number">0.1905</span>, -<span class="number">0.1224</span>,  <span class="number">3.5931</span>,  <span class="number">2.2708</span>],</span><br><span class="line">         [-<span class="number">0.0215</span>,  <span class="number">0.0339</span>,  <span class="number">2.6775</span>,  <span class="number">3.2976</span>],</span><br><span class="line">         [ <span class="number">0.6953</span>,  <span class="number">2.0412</span>, -<span class="number">1.9956</span>,  <span class="number">2.5225</span>]],</span><br><span class="line"> </span><br><span class="line">        [[ <span class="number">1.4605</span>,  <span class="number">2.2144</span>, -<span class="number">2.0243</span>,  <span class="number">0.6746</span>],</span><br><span class="line">         [ <span class="number">2.5676</span>,  <span class="number">1.1340</span>, -<span class="number">1.0942</span>, -<span class="number">0.3090</span>],</span><br><span class="line">         [ <span class="number">2.5388</span>,  <span class="number">0.6480</span>, -<span class="number">1.4546</span>,  <span class="number">1.0810</span>]]])</span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<hr>
<h3 id="BN-vs-LN"><a href="#BN-vs-LN" class="headerlink" title="BN vs LN"></a>BN vs LN</h3><p>BN 的转换是针对单个神经元可训练的————不同神经元的输入经过再平移和再缩放后分布在不同的区间，而 LN 对于一整层的神经元训练得到同一个转换————所有的输入都在同一个区间范围内。如果不同输入特征不属于相似的类别（比如颜色和大小），那么 LN 的处理可能会降低模型的表达能力。</p>
<hr>
<h3 id="Normalization-为何有效"><a href="#Normalization-为何有效" class="headerlink" title="Normalization 为何有效"></a>Normalization 为何有效</h3><img src="/2b3c20c7/12.png" class>

<h4 id="权重伸缩不变性"><a href="#权重伸缩不变性" class="headerlink" title="权重伸缩不变性"></a>权重伸缩不变性</h4><p>介绍：权重 W 按照常量 λ 进行伸缩时，得到的规范化后的值保持不变（其中：W’ = λW）</p>
<img src="/2b3c20c7/13.png" class>

<p>原因：当权重 W 伸缩时，对应的均值和标准差均等比例伸缩，分子分母相抵。</p>
<img src="/2b3c20c7/14.png" class>

<p>优点：权重伸缩不变性可以有效地提高反向传播的效率</p>
<img src="/2b3c20c7/15.png" class>

<p>注：因此，权重的伸缩变化不会影响反向梯度的 Jacobian 矩阵，因此也就对反向传播没有影响，避免了反向传播时因为权重过大或过小导致的梯度消失或梯度爆炸问题，从而加速了神经网络的训练。</p>
<p>权重伸缩不变性还具有参数正则化的效果，可以使用更高的学习率。</p>
<img src="/2b3c20c7/16.png" class>

<p>因此，下层的权重值越大，其梯度就越小。这样，参数的变化就越稳定，相当于实现了参数正则化的效果，避免参数的大幅震荡，提高网络的泛化性能。</p>
<hr>
<h4 id="数据伸缩不变性"><a href="#数据伸缩不变性" class="headerlink" title="数据伸缩不变性"></a>数据伸缩不变性</h4><p>介绍：当数据 x 按照常量 λ 进行伸缩时，得到的规范化后的值保持不变（注：x’= λx）</p>
<img src="/2b3c20c7/17.png" class>

<p>优点：数据伸缩不变性可以有效地减少梯度消失，简化对学习率的选择</p>
<p>对于某一层神经元：</p>
<img src="/2b3c20c7/18.png" class>

<p>可得：</p>
<img src="/2b3c20c7/19.png" class>

<p>每一层神经元的输出依赖于底下各层的计算结果。如果没有正则化，当下层输入发生伸缩变化时，经过层层传递，可能会导致数据发生剧烈的膨胀或者弥散，从而也导致了反向计算时的梯度爆炸或梯度消失。</p>
<p>加入 Normalization 之后，不论底层的数据如何变化，对于某一层神经元而言，其输入 𝓍ᵢ 永远保持标准的分布，这就使得高层的训练更加简单。从梯度的计算公式来看：</p>
<img src="/2b3c20c7/20.png" class>

<p>数据的伸缩变化也不会影响到对该层的权重参数更新，使得训练过程更加鲁棒，简化了对学习率的选择。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/qq_34467412/article/details/104656266">https://blog.csdn.net/qq_34467412/article/details/104656266</a><br><a href="https://jishuin.proginn.com/p/763bfbd5641b">https://jishuin.proginn.com/p/763bfbd5641b</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-归一化层BN、LN、IN、GN、SN</title>
    <url>/928002b2.html</url>
    <content><![CDATA[<h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><p>归一化层，目前主要有这几个方法，<strong>Batch Normalization</strong>（2015年）、<strong>Layer Normalization</strong>（2016年）、<strong>Instance Normalization</strong>（2017年）、<strong>Group Normalization</strong>（2018年）、<strong>Switchable Normalization</strong>（2018年）</p>
<p>将输入的图像 shape 记为 [N, C, H, W]，这几个方法主要的区别就是在：</p>
<ul>
<li><strong>BatchNorm</strong>是在 batch 上，对 NHW 做归一化，就是对每个单一通道输入进行归一化，这样做对小 batchsize 效果不好</li>
<li><strong>LayerNorm</strong>在通道方向上，对 CHW 归一化，就是对每个深度上的输入进行归一化，主要对 RNN 作用明显</li>
<li><strong>InstanceNorm</strong>在图像像素上，对 HW 做归一化，对一个图像的长宽即对一个像素进行归一化，用在风格化迁移</li>
<li><strong>GroupNorm</strong>将 channel 分组，有点类似于 LN，只是 GN 把 channel 也进行了划分，细化，然后再做归一化</li>
<li><strong>SwitchableNorm</strong>是将 BN、LN、IN 结合，赋予权重，让网络自己去学习归一化层应该使用什么方法</li>
</ul>
<img src="/928002b2/1.png" class>

<span id="more"></span>

<img src="/928002b2/6.jpg" class>

<ul>
<li>图中每一个正方体块表示一个数据（比如说这里一个正方体就是一个图像）</li>
<li>每一个正方体中的<strong>C</strong>, <strong>H</strong>, <strong>W</strong>分别表示<strong>channel</strong>(通道个数), <strong>height</strong>(图像的高), <strong>weight</strong>(图像的宽)</li>
<li>Norm 的方式，如Layer Norm中<strong>NHWC-&gt;N111</strong>表示是将<strong>后面的三个进行标准化</strong>，不与 batch 有关</li>
<li>我们可以看到，后面的<strong>LayerNorm</strong>, <strong>InstanceNorm</strong>和<strong>GroupNorm</strong>这三种方式都是和 batch 是没有关系的</li>
</ul>
<hr>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p><strong>论文：</strong><a href="https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization</a></p>
<p>首先，在进行训练之前，一般要对数据做<strong>归一化</strong>，使其分布一致，但是在深度神经网络训练过程中，通常以送入网络的每一个 batch 训练，这样每个 batch 具有不同的分布；此外，为了解决 internal covarivate shift 问题，这个问题定义是随着 batch normalizaiton 这篇论文提出的，在训练过程中，数据分布会发生变化，对下一层网络的学习带来困难。</p>
<p>所以 batch normalization 就是强行将数据拉回到<strong>均值为 0</strong>，<strong>方差为 1</strong> 的正态分布上，这样不仅<strong>数据分布一致</strong>，而且<strong>避免发生梯度消失</strong>。</p>
<p>此外，internal corvariate shift和covariate shift是两回事，前者是网络内部，后者是针对输入数据，比如我们在训练数据前做归一化等预处理操作。</p>
<img src="/928002b2/7.png" class>

<p><strong>算法过程：</strong></p>
<ol>
<li>沿着通道计算每个 batch 的均值 u</li>
<li>沿着通道计算每个 batch 的方差 σ^2</li>
<li>对 x 做归一化，x’ = (x - u) / √(σ^2 + ε)</li>
<li>加入缩放和平移变量 γ 和 β ，归一化后的值，y = γx’ + β</li>
</ol>
<p>加入缩放平移变量的原因是：保证每一次数据经过归一化后还保留原有学习来的特征，同时又能完成归一化操作，加速训练。这两个参数是用来学习的参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Batchnorm</span>(<span class="params">x, gamma, beta, bn_param</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># x_shape:[B, C, H, W]</span></span><br><span class="line">    running_mean = bn_param[<span class="string">&#x27;running_mean&#x27;</span>]</span><br><span class="line">    running_var = bn_param[<span class="string">&#x27;running_var&#x27;</span>]</span><br><span class="line">    results = <span class="number">0.</span></span><br><span class="line">    eps = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">    x_mean = np.mean(x, axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    x_var = np.var(x, axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=True0)</span><br><span class="line">    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)</span><br><span class="line">    results = gamma * x_normalized + beta</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因为在测试时是单个图片测试，这里保留训练时的均值和方差，用在后面测试时用</span></span><br><span class="line">    running_mean = momentum * running_mean + (<span class="number">1</span> - momentum) * x_mean</span><br><span class="line">    running_var = momentum * running_var + (<span class="number">1</span> - momentum) * x_var</span><br><span class="line"></span><br><span class="line">    bn_param[<span class="string">&#x27;running_mean&#x27;</span>] = running_mean</span><br><span class="line">    bn_param[<span class="string">&#x27;running_var&#x27;</span>] = running_var</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> results, bn_param</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Layer-Normalizaiton"><a href="#Layer-Normalizaiton" class="headerlink" title="Layer Normalizaiton"></a>Layer Normalizaiton</h3><p><strong>论文：</strong><a href="https://arxiv.org/pdf/1607.06450v1.pdf">Layer Normalizaiton</a></p>
<p>Batch Normalization 存在以下缺点：</p>
<ul>
<li>对 batchsize 的大小比较敏感，由于每次计算均值和方差是在一个 batch 上，所以如果 batchsize 太小，则计算的均值、方差不足以代表整个数据分布</li>
<li>BN 实际使用时需要计算并且保存某一层神经网络 batch 的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用 BN，很方便；但对于 RNN 来说，sequence 的长度是不一致的，换句话说 RNN 的深度不是固定的，不同的 time-step 需要保存不同的 statics 特征，可能存在一个特殊 sequence 比其他 sequence 长很多，这样 training 时，计算很麻烦。</li>
</ul>
<p>与 BN 不同，<strong>LN</strong> 是针对深度网络的<strong>某一层的所有神经元的输入</strong>按以下公式进行 normalize 操作。</p>
<img src="/928002b2/8.png" class>

<p>BN与LN的区别在于：</p>
<ul>
<li>LN 中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；</li>
<li>BN 中则针对不同神经元输入计算均值和方差，同一个 batch 中的输入拥有相同的均值和方差。</li>
</ul>
<p>所以，LN <strong>不依赖</strong>于 <strong>batch 的大小</strong>和输入 <strong>sequence 的深度</strong>，因此可以用于 batchsize 为 1 和 RNN 中对边长的输入 sequence 的 normalize 操作。</p>
<p>LN 用于 <strong>RNN 效果比较明显</strong>，但是在 CNN 上，不如 BN。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ln</span>(<span class="params">x, b, s</span>):</span></span><br><span class="line">    _eps = <span class="number">1e-5</span></span><br><span class="line">    output = (x - x.mean(<span class="number">1</span>)[:,<span class="literal">None</span>]) / tensor.sqrt((x.var(<span class="number">1</span>)[:,<span class="literal">None</span>] + _eps))</span><br><span class="line">    output = s[<span class="literal">None</span>, :] * output + b[<span class="literal">None</span>,:]</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<p>用在四维图像上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Layernorm</span>(<span class="params">x, gamma, beta</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># x_shape:[B, C, H, W]</span></span><br><span class="line">    results = <span class="number">0.</span></span><br><span class="line">    eps = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">    x_mean = np.mean(x, axis=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    x_var = np.var(x, axis=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=True0)</span><br><span class="line">    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)</span><br><span class="line">    results = gamma * x_normalized + beta</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Instance-Normalization"><a href="#Instance-Normalization" class="headerlink" title="Instance Normalization"></a>Instance Normalization</h3><p><strong>论文：</strong><a href="https://arxiv.org/pdf/1607.08022.pdf">Instance Normalization</a><br><strong>论文实现：</strong><a href="https://github.com/DmitryUlyanov/texture_nets">https://github.com/DmitryUlyanov/texture_nets</a></p>
<p>BN 注重对每个 batch 进行归一化，保证数据分布一致，因为判别模型中结果取决于数据整体分布。</p>
<p>但是<strong>图像风格化</strong>中，<strong>生成结果</strong>主要依赖于<strong>某个图像实例</strong>，所以对整个 batch 归一化不适合图像风格化中，因而<strong>对 HW 做归一化</strong>可以加速模型收敛，并且<strong>保持每个图像实例之间的独立</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Instancenorm</span>(<span class="params">x, gamma, beta</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># x_shape:[B, C, H, W]</span></span><br><span class="line">    results = <span class="number">0.</span></span><br><span class="line">    eps = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">    x_mean = np.mean(x, axis=(<span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    x_var = np.var(x, axis=(<span class="number">2</span>, <span class="number">3</span>), keepdims=True0)</span><br><span class="line">    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)</span><br><span class="line">    results = gamma * x_normalized + beta</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Group-Normalization"><a href="#Group-Normalization" class="headerlink" title="Group Normalization"></a>Group Normalization</h3><p><strong>论文：</strong><a href="https://arxiv.org/pdf/1803.08494.pdf">Group Normalization</a></p>
<p>主要是针对 Batch Normalization 对小 batchsize 效果差，GN 将 <strong>channel 方向分 group</strong>，然后每个 <strong>group 内做归一化</strong>，算 (C // G) * H * W 的均值，这样<strong>与 batchsize 无关，不受其约束</strong>。</p>
<img src="/928002b2/9.png" class>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GroupNorm</span>(<span class="params">x, gamma, beta, G=<span class="number">16</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># x_shape:[B, C, H, W]</span></span><br><span class="line">    results = <span class="number">0.</span></span><br><span class="line">    eps = <span class="number">1e-5</span></span><br><span class="line">    x = np.reshape(x, (x.shape[<span class="number">0</span>], G, x.shape[<span class="number">1</span>]/<span class="number">16</span>, x.shape[<span class="number">2</span>], x.shape[<span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line">    x_mean = np.mean(x, axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    x_var = np.var(x, axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), keepdims=True0)</span><br><span class="line">    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)</span><br><span class="line">    results = gamma * x_normalized + beta</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Switchable-Normalization"><a href="#Switchable-Normalization" class="headerlink" title="Switchable Normalization"></a>Switchable Normalization</h3><p><strong>论文：</strong><a href="https://arxiv.org/pdf/1806.10779.pdf">Switchable Normalization</a><br><strong>论文实现：</strong><a href="https://github.com/switchablenorms/Switchable-Normalization">https://github.com/switchablenorms/Switchable-Normalization</a></p>
<p>本篇论文作者认为：</p>
<ol>
<li>归一化虽然提高模型泛化能力，然而归一化层的操作是人工设计的。在实际应用中，解决不同的问题原则上需要设计不同的归一化操作，并没有一个通用的归一化方法能够解决所有应用问题；</li>
<li>一个深度神经网络往往包含几十个归一化层，通常这些归一化层都使用同样的归一化操作，因为手工为每一个归一化层设计操作需要进行大量的实验。</li>
</ol>
<p>因此作者提出自适配归一化方法 Switchable Normalization（SN） 来解决上述问题。与强化学习不同，<strong>SN 使用可微分学习</strong>，为一个深度网络中的每一个归一化层确定合适的归一化操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SwitchableNorm</span>(<span class="params">x, gamma, beta, w_mean, w_var</span>):</span></span><br><span class="line">    <span class="comment"># x_shape:[B, C, H, W]</span></span><br><span class="line">    results = <span class="number">0.</span></span><br><span class="line">    eps = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">    mean_in = np.mean(x, axis=(<span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    var_in = np.var(x, axis=(<span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    mean_ln = np.mean(x, axis=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    var_ln = np.var(x, axis=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    mean_bn = np.mean(x, axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    var_bn = np.var(x, axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    mean = w_mean[<span class="number">0</span>] * mean_in + w_mean[<span class="number">1</span>] * mean_ln + w_mean[<span class="number">2</span>] * mean_bn</span><br><span class="line">    var = w_var[<span class="number">0</span>] * var_in + w_var[<span class="number">1</span>] * var_ln + w_var[<span class="number">2</span>] * var_bn</span><br><span class="line"></span><br><span class="line">    x_normalized = (x - mean) / np.sqrt(var + eps)</span><br><span class="line">    results = gamma * x_normalized + beta</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="在Pytorch上的实现"><a href="#在Pytorch上的实现" class="headerlink" title="在Pytorch上的实现"></a>在Pytorch上的实现</h3><h4 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.BatchNorm1d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">torch.nn.BatchNorm2d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">torch.nn.BatchNorm3d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td><strong>num_features</strong></td>
<td>来自期望输入的特征数，该期望输入的大小为 batch_size x num_features [x width]</td>
</tr>
<tr>
<td><strong>eps</strong></td>
<td>为保证数值稳定性（分母不能趋近或取0），给分母加上的值。默认为1e-5。</td>
</tr>
<tr>
<td><strong>momentum</strong></td>
<td>动态均值和动态方差所使用的动量。默认为0.1。</td>
</tr>
<tr>
<td><strong>affine</strong></td>
<td>布尔值，当设为true，给该层添加可学习的仿射变换参数。</td>
</tr>
<tr>
<td><strong>track_running_stats</strong></td>
<td>布尔值，当设为true，记录训练过程中的均值和方差。</td>
</tr>
</tbody></table>
<p><strong>实现公式：</strong></p>
<img src="/928002b2/2.png" class>

<hr>
<h4 id="LayerNorm"><a href="#LayerNorm" class="headerlink" title="LayerNorm"></a>LayerNorm</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.LayerNorm(normalized_shape, eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td><strong>normalized_shape</strong></td>
<td>输入尺寸 [∗×normalized_shape[0] × normalized_shape[1] × … × normalized_shape[−1]]</td>
</tr>
<tr>
<td><strong>eps</strong></td>
<td>为保证数值稳定性（分母不能趋近或取0），给分母加上的值。默认为1e-5。</td>
</tr>
<tr>
<td><strong>elementwise_affine</strong></td>
<td>布尔值，当设为true，给该层添加可学习的仿射变换参数。</td>
</tr>
</tbody></table>
<p><strong>实现公式：</strong></p>
<img src="/928002b2/3.png" class>

<hr>
<h4 id="InstanceNorm"><a href="#InstanceNorm" class="headerlink" title="InstanceNorm"></a>InstanceNorm</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.InstanceNorm1d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">False</span>, track_running_stats=<span class="literal">False</span>)</span><br><span class="line">torch.nn.InstanceNorm2d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">False</span>, track_running_stats=<span class="literal">False</span>)</span><br><span class="line">torch.nn.InstanceNorm3d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">False</span>, track_running_stats=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td><strong>num_features</strong></td>
<td>来自期望输入的特征数，该期望输入的大小为 batch_size x num_features [x width]</td>
</tr>
<tr>
<td><strong>eps</strong></td>
<td>为保证数值稳定性（分母不能趋近或取0），给分母加上的值。默认为1e-5。</td>
</tr>
<tr>
<td><strong>momentum</strong></td>
<td>动态均值和动态方差所使用的动量。默认为0.1。</td>
</tr>
<tr>
<td><strong>affine</strong></td>
<td>布尔值，当设为true，给该层添加可学习的仿射变换参数。</td>
</tr>
<tr>
<td><strong>track_running_stats</strong></td>
<td>布尔值，当设为true，记录训练过程中的均值和方差。</td>
</tr>
</tbody></table>
<p><strong>实现公式：</strong></p>
<img src="/928002b2/4.png" class>

<hr>
<h4 id="GroupNorm"><a href="#GroupNorm" class="headerlink" title="GroupNorm"></a>GroupNorm</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.GroupNorm(num_groups, num_channels, eps=<span class="number">1e-05</span>, affine=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td><strong>num_groups</strong></td>
<td>需要划分为的groups</td>
</tr>
<tr>
<td><strong>num_features</strong></td>
<td>来自期望输入的特征数，该期望输入的大小为 batch_size x num_features [x width]</td>
</tr>
<tr>
<td><strong>eps</strong></td>
<td>为保证数值稳定性（分母不能趋近或取0），给分母加上的值。默认为1e-5。</td>
</tr>
<tr>
<td><strong>momentum</strong></td>
<td>动态均值和动态方差所使用的动量。默认为0.1。</td>
</tr>
<tr>
<td><strong>affine</strong></td>
<td>布尔值，当设为true，给该层添加可学习的仿射变换参数。</td>
</tr>
</tbody></table>
<p><strong>实现公式：</strong></p>
<img src="/928002b2/5.png" class>

<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h4 id="类似情况"><a href="#类似情况" class="headerlink" title="类似情况"></a>类似情况</h4><ul>
<li>当 <strong>GroupNorm</strong> 中group的数量是 <strong>1</strong> 的时候，是与 <strong>LayerNorm</strong> 是等价的</li>
<li><strong>InstanceNorm</strong> 等价于当 GroupNorm 时 <strong>num_groups</strong> 的数量等于 <strong>num_channel</strong> 的数量</li>
</ul>
<h4 id="每一种方式适合的场景"><a href="#每一种方式适合的场景" class="headerlink" title="每一种方式适合的场景"></a>每一种方式适合的场景</h4><ul>
<li>BatchNorm 是在 batch 上，对小 batchsize 效果不好</li>
<li>LayerNorm 在通道方向上，主要对 RNN 作用明显</li>
<li>InstanceNorm 在图像像素上，用在风格化迁移</li>
<li>GroupNorm 将 channel 分组，然后再做归一化, 在 batchsize &lt; 16 的时候, 可以使用这种归一化</li>
</ul>
<img src="/928002b2/10.png" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/shanglianlm/article/details/85075706">https://blog.csdn.net/shanglianlm/article/details/85075706</a><br><a href="https://zhuanlan.zhihu.com/p/395855181">https://zhuanlan.zhihu.com/p/395855181</a><br><a href="https://blog.csdn.net/liuxiao214/article/details/81037416">https://blog.csdn.net/liuxiao214/article/details/81037416</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>第九艺术-精灵宝可梦历代正统游戏整理</title>
    <url>/ceb095e1.html</url>
    <content><![CDATA[<p>大多数人对宝可梦的了解基本上都来自于动漫番剧，对宝可梦游戏知之甚少，所以本博客对此进行简单介绍。</p>
<p>至于为什么只统计正统作品…当然是因为旁支作品太多啦</p>
<span id="more"></span>

<hr>
<h3 id="第一世代：红-绿-蓝-黄"><a href="#第一世代：红-绿-蓝-黄" class="headerlink" title="第一世代：红 绿 蓝 黄"></a>第一世代：红 绿 蓝 黄</h3><h4 id="《宝可梦红》《宝可梦绿》"><a href="#《宝可梦红》《宝可梦绿》" class="headerlink" title="《宝可梦红》《宝可梦绿》"></a>《宝可梦红》《宝可梦绿》</h4><img src="/ceb095e1/1.webp" class>

<p>《红》《绿》两作于<strong>1996年2月27日</strong>在日本发售，是最早的宝可梦正统游戏，由Game Freak开发、由任天堂发行，游戏平台为Game Boy掌机。</p>
<p>游戏的背景设定在第一世代的关都地区，玩家可以从小火龙、杰尼龟、妙蛙种子中选择一只作为初始伙伴，并且在游戏中御三家只能获得这一次。现在很多游戏软件上都可以下载这些游戏，或者可以下载个GB模拟器。</p>
<h4 id="《宝可梦蓝》"><a href="#《宝可梦蓝》" class="headerlink" title="《宝可梦蓝》"></a>《宝可梦蓝》</h4><img src="/ceb095e1/2.webp" class>

<p>《蓝》于<strong>1996年10月15日</strong>第一次发售，据说当时是通过《月刊COROCORO漫画》以抽签的形式限量发售，不过到了1999年10月10日又在日本全国发售。</p>
<p>《蓝》是《红》和《绿》的增强版，修复了《红》《绿》的大部分BUG，还更换了部分音乐新增了许多新的曲。</p>
<p>但是《蓝》和《红》、《绿》在游戏剧情和内容上并没有太大变化，基本上是一样的。游戏背景依然是平平安安的关都地区。不过在欧美，《蓝》替代了《绿》跟《红》一起发售。</p>
<h4 id="《宝可梦黄》"><a href="#《宝可梦黄》" class="headerlink" title="《宝可梦黄》"></a>《宝可梦黄》</h4><img src="/ceb095e1/3.webp" class>

<p>《黄》于<strong>1999年10月19日</strong>发售，《黄》跟《红》《绿》《蓝》最大的区别在于剧情进行了修改，玩家初始宝可梦必定是皮卡丘，劲敌必定选择伊布。而通过后续的剧情玩家可以获得御三家小火龙杰尼龟跟妙蛙种子。当时《黄》是作为剧场版《超梦的逆袭》纪念作品发售的，所以剧情根据动画做出了修改。</p>
<hr>
<h3 id="第二世代：金-银-水晶"><a href="#第二世代：金-银-水晶" class="headerlink" title="第二世代：金 银 水晶"></a>第二世代：金 银 水晶</h3><h4 id="《宝可梦金》《宝可梦银》"><a href="#《宝可梦金》《宝可梦银》" class="headerlink" title="《宝可梦金》《宝可梦银》"></a>《宝可梦金》《宝可梦银》</h4><img src="/ceb095e1/4.webp" class>

<p>《金银》于<strong>1999年11月21日</strong>在日本发售，依然是由Game Freak开发、由任天堂发行，游戏平台是全新的Game Boy Color掌机，也就是我们常说的GBC。</p>
<p>作为第二世代的第一批游戏，《金银》来到了新的地区城都，也迎来了新的御三家：火球鼠、小锯鳄、菊草叶。而我个人认为《金银》最大的亮点就是玩家在通过一周目的冠军联盟之后，可以来到关都地区，还可以挑战关都地区的道馆。同时《金银》也是该系列游戏首次把神兽用作封面的作品。</p>
<p>关都地区的原型是日本的关东地方，而城都地区则是参考日本的关西地方和东海地方。</p>
<p>关都地区：</p>
<img src="/ceb095e1/5.webp" class>

<p>城都地区：</p>
<img src="/ceb095e1/6.webp" class>

<h4 id="《宝可梦水晶》"><a href="#《宝可梦水晶》" class="headerlink" title="《宝可梦水晶》"></a>《宝可梦水晶》</h4><img src="/ceb095e1/7.webp" class>

<p>《水晶》版本据说是《金银》的资料片，《水晶》于<strong>2000年12月14日</strong>发售，《水晶》首次出现了可供玩家选择的女性角色“克丽丝”而且《水晶》版本首次增加了宝可梦的登场动画。</p>
<hr>
<h3 id="第三世代：红宝石-蓝宝石-绿宝石"><a href="#第三世代：红宝石-蓝宝石-绿宝石" class="headerlink" title="第三世代：红宝石 蓝宝石 绿宝石"></a>第三世代：红宝石 蓝宝石 绿宝石</h3><h4 id="《宝可梦红宝石》《宝可梦蓝宝石》"><a href="#《宝可梦红宝石》《宝可梦蓝宝石》" class="headerlink" title="《宝可梦红宝石》《宝可梦蓝宝石》"></a>《宝可梦红宝石》《宝可梦蓝宝石》</h4><img src="/ceb095e1/8.webp" class>

<p>来到<strong>2002年11月21日</strong>，宝可梦《红蓝宝石》发售，这次依然是由Game Freak开发，任天堂发售，登陆Game Boy Advance掌机平台，也就是GBA。</p>
<p>首先《红蓝宝石》最直观最明显的一点变化就是画面，连游戏里的建筑物都是正常比例了，当然也得益于掌机的进步。</p>
<p>《红蓝宝石》新增了双打对战和135只新的宝可梦。御三家也是全新的:火稚鸡、水跃鱼、木守宫，地区也是全新的芳缘地区。</p>
<p>芳缘地区是根据日本九州岛为原型创作的，也翻译为:丰缘地区。</p>
<img src="/ceb095e1/9.webp" class>

<h4 id="《宝可梦绿宝石》"><a href="#《宝可梦绿宝石》" class="headerlink" title="《宝可梦绿宝石》"></a>《宝可梦绿宝石》</h4><img src="/ceb095e1/10.webp" class>

<p><strong>2004年9月16日</strong>，《红蓝宝石》的资料片《绿宝石》发售，很多玩家入坑宝可梦的国人改版神作《漆黑的魅影》就是由宝石版为蓝本修改而来的，而宝石版本身也非常值得一玩，墙裂推荐！（但是我记得正版的宝石在汉化一方面……因为当年盗版商的原因，什么木木兽（烈空坐）、奇奇兽（盖欧卡）、古拉顿（固拉多），基本上是看图说话）</p>
<img src="/ceb095e1/11.webp" class>

<hr>
<h3 id="第一世代重置：火红-叶绿"><a href="#第一世代重置：火红-叶绿" class="headerlink" title="第一世代重置：火红 叶绿"></a>第一世代重置：火红 叶绿</h3><h4 id="《宝可梦火红》《宝可梦叶绿》"><a href="#《宝可梦火红》《宝可梦叶绿》" class="headerlink" title="《宝可梦火红》《宝可梦叶绿》"></a>《宝可梦火红》《宝可梦叶绿》</h4><p>然后我们回到第一世代，<strong>2004年1月29日</strong>《红》《绿》的重制版《火红》《叶绿》在日本地区发售，同年9月10月分别在北美和欧洲地区发售。</p>
<p>传奇人物“赤爷”赤红就出自该作，以及碧蓝和劲敌青绿。《火红》《叶绿》也算是一代经典了。</p>
<img src="/ceb095e1/12.webp" class>

<img src="/ceb095e1/13.webp" class>

<hr>
<h3 id="第四世代：珍珠-钻石-白金"><a href="#第四世代：珍珠-钻石-白金" class="headerlink" title="第四世代：珍珠 钻石 白金"></a>第四世代：珍珠 钻石 白金</h3><h4 id="《宝可梦珍珠》《宝可梦钻石》"><a href="#《宝可梦珍珠》《宝可梦钻石》" class="headerlink" title="《宝可梦珍珠》《宝可梦钻石》"></a>《宝可梦珍珠》《宝可梦钻石》</h4><img src="/ceb095e1/14.webp" class>

<img src="/ceb095e1/15.webp" class>

<p><strong>2006年9月28日</strong>，由Game Freak开发，任天堂发行，登陆NDS平台，当初第一次玩的时候，惊讶的发现，宝可梦中心和友好商店竟然是立体的！《珍珠钻石》作为第一款登陆DS平台的作品，在游戏中首次出现了3D立体场景。</p>
<p>该作故事背景发生在神奥地区，御三家为小火焰猴、波加曼、嫩苗龟（草苗龟）</p>
<p>神奥地区的原型是日本的北海道岛和国后岛</p>
<img src="/ceb095e1/16.webp" class>

<img src="/ceb095e1/17.webp" class>

<h4 id="《宝可梦白金》"><a href="#《宝可梦白金》" class="headerlink" title="《宝可梦白金》"></a>《宝可梦白金》</h4><img src="/ceb095e1/18.webp" class>

<p><strong>2008年9月13日</strong>，《白金》作为《珍珠钻石》的资料片发售，白金加入了新的骑拉帝纳剧情和新的“反转世界”地图，其余的并没有太大变化。</p>
<hr>
<h3 id="第二世代重置：金心-银灵"><a href="#第二世代重置：金心-银灵" class="headerlink" title="第二世代重置：金心 银灵"></a>第二世代重置：金心 银灵</h3><h4 id="《宝可梦心灵之金》《宝可梦灵魂之银》"><a href="#《宝可梦心灵之金》《宝可梦灵魂之银》" class="headerlink" title="《宝可梦心灵之金》《宝可梦灵魂之银》"></a>《宝可梦心灵之金》《宝可梦灵魂之银》</h4><p>《宝可梦心灵之金》和《宝可梦灵魂之银》在<strong>2009年9月12日</strong>于日本地区发售，是《金》《银》的重制版，同时包含了《水晶》的剧情。</p>
<p>而且《金心》《银灵》中可以让队伍中的第一只宝可梦跟随自己，但是不知道为什么后续作品并没有继续采用这一点。</p>
<img src="/ceb095e1/19.webp" class>

<hr>
<h3 id="第五世代：黑-白"><a href="#第五世代：黑-白" class="headerlink" title="第五世代：黑 白"></a>第五世代：黑 白</h3><h4 id="《宝可梦黑》《宝可梦白》"><a href="#《宝可梦黑》《宝可梦白》" class="headerlink" title="《宝可梦黑》《宝可梦白》"></a>《宝可梦黑》《宝可梦白》</h4><img src="/ceb095e1/20.webp" class>

<p>于<strong>2010年9月18日</strong>发售，《黑白》游戏中新增加了156只宝可梦，同时增加了轮盘对战和三打对战等新的玩法，还有新的季节系统。虽然牺牲了画质但是宝可梦首次动了起来，《黑白》不再像前几作那样，宝可梦都是一个固定的立绘，而是会动的平面像素模型，个人认为这是黑白的最大的亮点，也是宝可梦系列游戏一个极大的突破。</p>
<p>游戏背景为新的合众地区，御三家也是新的:藤藤蛇、水水獭（ta）、暖暖猪。合众地区是以美国纽约为原型设计的</p>
<img src="/ceb095e1/21.webp" class>

<h4 id="《宝可梦黑2》《宝可梦白2》"><a href="#《宝可梦黑2》《宝可梦白2》" class="headerlink" title="《宝可梦黑2》《宝可梦白2》"></a>《宝可梦黑2》《宝可梦白2》</h4><img src="/ceb095e1/22.webp" class>

<p><strong>2012年6月23日</strong>，《黑白2》发售，《黑白2》不是《黑白》的重制版，而是剧情续作兼资料片。游戏中的人物和道馆等全部重新设计，玩家也会以新的主角开始游戏，在剧情方面《黑白》跟《黑白2》都是绝佳。</p>
<img src="/ceb095e1/23.webp" class>

<hr>
<h3 id="第六世代：X-Y"><a href="#第六世代：X-Y" class="headerlink" title="第六世代：X Y"></a>第六世代：X Y</h3><h4 id="《宝可梦X》《宝可梦Y》"><a href="#《宝可梦X》《宝可梦Y》" class="headerlink" title="《宝可梦X》《宝可梦Y》"></a>《宝可梦X》《宝可梦Y》</h4><img src="/ceb095e1/24.webp" class>

<p>该作于<strong>2013年10月12日</strong>全球同步发售，由Game Freak开发，任天堂发行，登陆全新的3DS掌机平台，游戏首次引入了mage进化（百万进化、超级进化）通过手镯和宝可梦身上的钥石来实现。</p>
<p>该作是宝可梦游戏系列首款全3D的游戏，这也是游戏的一大亮点，但是剧情方面比较差劲，部分剧情衔接不太行，而且很多突兀的地方，最后又给人戛然而止的感觉，就挺突然的，而且剧情比较平庸（真的不是黑）我本以为全3D的游戏在神兽初登场的时候应该会有一段很惊艳的3D过场动画吧，神兽部分的剧情应该场面很大的吧（因为前作基本都是这样的），但事实上还是差点，神兽从一个蛋里出来的，而且还是在闪焰队的基地里，就没什么逼格。但是XY的销量确实高而且很高，是3DS上销售最快的游戏。</p>
<p>故事背景是以法国为原型的卡洛斯地区，御三家是新的:呱呱泡蛙、火狐狸、哈力栗。</p>
<img src="/ceb095e1/25.webp" class>

<hr>
<h3 id="第三世代重置：阿尔法蓝宝石-欧米伽红宝石"><a href="#第三世代重置：阿尔法蓝宝石-欧米伽红宝石" class="headerlink" title="第三世代重置：阿尔法蓝宝石 欧米伽红宝石"></a>第三世代重置：阿尔法蓝宝石 欧米伽红宝石</h3><h4 id="《阿尔法蓝宝石》《欧米伽红宝石》"><a href="#《阿尔法蓝宝石》《欧米伽红宝石》" class="headerlink" title="《阿尔法蓝宝石》《欧米伽红宝石》"></a>《阿尔法蓝宝石》《欧米伽红宝石》</h4><p><strong>2014年11月21日</strong>在全球大部分地区发售的宝可梦新作《阿尔法蓝宝石》《欧米伽红宝石》，是《红宝石》《蓝宝石》的重制版，该作也加入了mage进化，同时在剧情上做出了很大的修改，游戏还加入了原版没有的秘密基地的设定，值得一玩。</p>
<img src="/ceb095e1/26.webp" class>

<hr>
<h3 id="第七世代：太阳-月亮-究极日月"><a href="#第七世代：太阳-月亮-究极日月" class="headerlink" title="第七世代：太阳 月亮 究极日月"></a>第七世代：太阳 月亮 究极日月</h3><h4 id="《宝可梦太阳》《宝可梦月亮》"><a href="#《宝可梦太阳》《宝可梦月亮》" class="headerlink" title="《宝可梦太阳》《宝可梦月亮》"></a>《宝可梦太阳》《宝可梦月亮》</h4><img src="/ceb095e1/27.webp" class>

<p>于<strong>2016年11月18日</strong>发售，《太阳》和《月亮》是首款内置中文的版本，也是宝可梦系列游戏在3DS上的最后一作。游戏取消了道馆和徽章的设定，取而代之的是诸岛巡礼。同时加入了类似于“第五技能”的Z招式，还加入了新的81种宝可梦（不包含地区形态）</p>
<h4 id="《宝可梦究极之日》《宝可梦究极之月》"><a href="#《宝可梦究极之日》《宝可梦究极之月》" class="headerlink" title="《宝可梦究极之日》《宝可梦究极之月》"></a>《宝可梦究极之日》《宝可梦究极之月》</h4><img src="/ceb095e1/28.webp" class>

<p><strong>2017年11月17日</strong>，《究极日月》以《日月》资料片发售，相比《日月》新增加了彩虹火箭队剧情、奈克洛兹玛剧情，新增了霸主贴纸和究极调查队等新的内容。游戏背景是以夏威夷为原型的阿罗拉地区，御三家为火斑喵、球球海狮、木木枭。</p>
<img src="/ceb095e1/29.webp" class>

<hr>
<h3 id="第八世代：剑-盾"><a href="#第八世代：剑-盾" class="headerlink" title="第八世代：剑 盾"></a>第八世代：剑 盾</h3><h4 id="《宝可梦剑》《宝可梦盾》"><a href="#《宝可梦剑》《宝可梦盾》" class="headerlink" title="《宝可梦剑》《宝可梦盾》"></a>《宝可梦剑》《宝可梦盾》</h4><img src="/ceb095e1/30.webp" class>

<p>《剑盾》于<strong>2019年11月15日</strong>发售，《剑盾》可以通过DLC来扩充内容，《剑盾》也是断代的一部宝可梦作品，许多宝可梦不可以通信到本作。由Game Freak开发、任天堂发行，登陆switch平台。</p>
<p>《剑盾》中新增加了许多宝可梦的地区形态，以及极巨化玩法、旷野平原等，本作自由度相对来说更高一些。</p>
<p>故事背景是英国为原型的伽勒尔地区，御三家为炎兔儿、泪眼蜥、敲音猴。</p>
<img src="/ceb095e1/31.webp" class>

<p>这里提一嘴:switch上的《去吧皮卡丘》《去吧伊布》并不是宝可梦正统续作，是与“pokemon go”联动的一款非正统游戏，该作可以与pokemon go进行通信。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><table>
<thead>
<tr>
<th>时间</th>
<th>名称</th>
<th>世代</th>
<th>平台</th>
<th>地区</th>
<th>初始</th>
</tr>
</thead>
<tbody><tr>
<td>1996年2月27日</td>
<td>《宝可梦红》《宝可梦绿》</td>
<td>第一世代</td>
<td>Game Boy</td>
<td>关都地区</td>
<td>小火龙 杰尼龟 妙蛙种子</td>
</tr>
<tr>
<td>1996年10月15日</td>
<td>《宝可梦蓝》</td>
<td>第一世代</td>
<td>Game Boy</td>
<td>关都地区</td>
<td>小火龙 杰尼龟 妙蛙种子</td>
</tr>
<tr>
<td>1999年10月19日</td>
<td>《宝可梦黄》</td>
<td>第一世代</td>
<td>Game Boy</td>
<td>关都地区</td>
<td>皮卡丘</td>
</tr>
<tr>
<td>1999年11月21日</td>
<td>《宝可梦金》《宝可梦银》</td>
<td>第二世代</td>
<td>Game Boy Color</td>
<td>城都地区</td>
<td>火球鼠 小锯鳄 菊草叶</td>
</tr>
<tr>
<td>2000年12月14日</td>
<td>《宝可梦水晶》</td>
<td>第二世代</td>
<td>Game Boy Color</td>
<td>城都地区</td>
<td>火球鼠 小锯鳄 菊草叶</td>
</tr>
<tr>
<td>2002年11月21日</td>
<td>《宝可梦红宝石》《宝可梦蓝宝石》</td>
<td>第三世代</td>
<td>Game Boy Advance</td>
<td>芳缘地区</td>
<td>火稚鸡 水跃鱼 木守宫</td>
</tr>
<tr>
<td>2004年9月16日</td>
<td>《宝可梦绿宝石》</td>
<td>第三世代</td>
<td>Game Boy Advance</td>
<td>芳缘地区</td>
<td>火稚鸡 水跃鱼 木守宫</td>
</tr>
<tr>
<td>2004年1月29日</td>
<td>《宝可梦火红》《宝可梦叶绿》</td>
<td>第一世代重置</td>
<td>Game Boy Advance</td>
<td>关都地区</td>
<td>小火龙 杰尼龟 妙蛙种子</td>
</tr>
<tr>
<td>2006年9月28日</td>
<td>《宝可梦珍珠》《宝可梦钻石》</td>
<td>第四世代</td>
<td>NDS</td>
<td>神奥地区</td>
<td>小火焰猴 波加曼 嫩苗龟</td>
</tr>
<tr>
<td>2008年9月13日</td>
<td>《宝可梦白金》</td>
<td>第四世代</td>
<td>NDS</td>
<td>神奥地区</td>
<td>小火焰猴 波加曼 嫩苗龟</td>
</tr>
<tr>
<td>2009年9月12日</td>
<td>《宝可梦心灵之金》《宝可梦灵魂之银》</td>
<td>第二世代重置</td>
<td>NDS</td>
<td>城都地区</td>
<td>火球鼠 小锯鳄 菊草叶</td>
</tr>
<tr>
<td>2010年9月18日</td>
<td>《宝可梦黑》《宝可梦白》</td>
<td>第五世代</td>
<td>NDS</td>
<td>合众地区</td>
<td>藤藤蛇 水水獭（ta） 暖暖猪</td>
</tr>
<tr>
<td>2012年6月23日</td>
<td>《宝可梦黑2》《宝可梦白2》</td>
<td>第五世代</td>
<td>NDS</td>
<td>合众地区</td>
<td>藤藤蛇 水水獭（ta） 暖暖猪</td>
</tr>
<tr>
<td>2013年10月12日</td>
<td>《宝可梦X》《宝可梦Y》</td>
<td>第六世代</td>
<td>3DS</td>
<td>卡洛斯地区</td>
<td>呱呱泡蛙 火狐狸 哈力栗</td>
</tr>
<tr>
<td>2014年11月21日</td>
<td>《阿尔法蓝宝石》《欧米伽红宝石》</td>
<td>第三世代重置</td>
<td>3DS</td>
<td>芳缘地区</td>
<td>火稚鸡 水跃鱼 木守宫</td>
</tr>
<tr>
<td>2016年11月18日</td>
<td>《宝可梦太阳》《宝可梦月亮》</td>
<td>第七世代</td>
<td>3DS</td>
<td>阿罗拉地区</td>
<td>火斑喵 球球海狮 木木枭</td>
</tr>
<tr>
<td>2017年11月17日</td>
<td>《宝可梦究极之日》《宝可梦究极之月》</td>
<td>第七世代</td>
<td>3DS</td>
<td>阿罗拉地区</td>
<td>火斑喵 球球海狮 木木枭</td>
</tr>
<tr>
<td>2019年11月15日</td>
<td>《宝可梦剑》《宝可梦盾》</td>
<td>第八世代</td>
<td>Switch</td>
<td>伽勒尔地区</td>
<td>炎兔儿 泪眼蜥 敲音猴</td>
</tr>
</tbody></table>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv12550482">https://www.bilibili.com/read/cv12550482</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-范数与正则化</title>
    <url>/4cc46bd.html</url>
    <content><![CDATA[<h3 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h3><p>范数(Norm)是具有度量性质的函数，在机器学习中，经常用来<strong>衡量向量的大小</strong>。</p>
<p>范数把一个向量映射为一个非负值的函数，我们可以将一个向量x，经范数后表示<strong>点距离原点的距离</strong>，那么Lp范数定义如下：</p>
<img src="/4cc46bd/1.png" class>

<p>其中p属于R，p大于等于1。</p>
<span id="more"></span>

<hr>
<h3 id="经典范数"><a href="#经典范数" class="headerlink" title="经典范数"></a>经典范数</h3><h4 id="L0范数"><a href="#L0范数" class="headerlink" title="L0范数"></a>L0范数</h4><p>表示统计向量中非零元素的个数(不是严格意义上的范数)</p>
<img src="/4cc46bd/2.png" class>

<p>我们可以通过最小化L0范数，来寻找最少最优的稀疏特征项。但不幸的是，L0范数的最优化问题是一个NP hard问题（L0范数同样是非凸的）。因此，在实际应用中我们经常对L0进行凸松弛，理论上有证明，L1范数是L0范数的最优凸近似，因此通常使用L1范数来代替直接优化L0范数。</p>
<h4 id="L1范数"><a href="#L1范数" class="headerlink" title="L1范数"></a>L1范数</h4><p>表示零元素与非零元素差别非常重要时使用。例如：每当x中某个元素从0增加到m，则对应的L1范数也会增加m。也就是每个元素绝对值之和。也被称为是”稀疏规则算子”。</p>
<img src="/4cc46bd/3.png" class>

<h4 id="L2范数"><a href="#L2范数" class="headerlink" title="L2范数"></a>L2范数</h4><p>欧几里得范数，表示从原点出发到向量x确定的点的欧几里得距离。在快接近源值时L2范数增长缓慢，对于区分恰好是零的元素和非零但值很小的元素的情况就不适用了(转为L1范数)。也就是通常说的欧氏距离。有人把它的回归叫“岭回归”（Ridge Regression），也有人叫它“权值衰减”（Weight Decay）。</p>
<img src="/4cc46bd/4.png" class>

<h4 id="L∞范数"><a href="#L∞范数" class="headerlink" title="L∞范数"></a>L∞范数</h4><p>表示最大范数，只是统计向量中的最大值，也就是最大幅值的元素的绝对值。</p>
<h4 id="Frobenius范数"><a href="#Frobenius范数" class="headerlink" title="Frobenius范数"></a>Frobenius范数</h4><p>类似于L2范数，用来衡量矩阵的大小。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>最后，两个向量的点积也可以用范数来表示：</p>
<img src="/4cc46bd/5.png" class>

<hr>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>为何使用正则化？因为正则化可以避免过拟合的产生和减少网络误差。</p>
<p>表达式：</p>
<img src="/4cc46bd/6.png" class>

<p>第一项表示经验风险，第二项表示正则项。</p>
<p>正则化与范数关系：R(f)就是相关范数表达式。</p>
<h4 id="L1正则"><a href="#L1正则" class="headerlink" title="L1正则"></a>L1正则</h4><p>凸函数，不是处处可微分。得到的是稀疏解（最优解常出现在顶点上，且顶点上的 w 只有很少的元素是非零的）。</p>
<img src="/4cc46bd/7.png" class>

<h4 id="L2正则"><a href="#L2正则" class="headerlink" title="L2正则"></a>L2正则</h4><p>凸函数，处处可微分，且易于优化。</p>
<img src="/4cc46bd/8.png" class>

<h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>Dropout是深度学习中经常采用的一种正则化方法。核心思想是<strong>减少神经元之间复杂的共适应性</strong>。当隐藏层神经元被随机删除之后，使得全连接网络具有了一定的稀疏化，从而有效地<strong>减轻了不同特征的协同效应</strong>。使神经网络中的某些神经元随机失活，让模型<strong>不过度依赖某一神经元</strong>，达到<strong>增强模型鲁棒性</strong>以及<strong>控制过拟合</strong>的效果。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://cloud.tencent.com/developer/article/1509971">https://cloud.tencent.com/developer/article/1509971</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-机器学习中的范数</title>
    <url>/a8f537a.html</url>
    <content><![CDATA[<h3 id="几个基本概念"><a href="#几个基本概念" class="headerlink" title="几个基本概念"></a>几个基本概念</h3><ul>
<li><strong>规范化参数：</strong>机器学习的模型拟合训练数据；</li>
<li><strong>最小化误差：</strong>防止机器学习的模型与训练数据过度拟合；</li>
<li><strong>范数：</strong>机器学习、深度学习等计算机领域内用的比较多的就是迭代过程中收敛性质的判断，一般迭代前后步骤的差值称为范数，用范数表示其大小。</li>
</ul>
<p>常用的是二范数，差值越小表示越逼近实际值，可以认为达到要求的精度，收敛。<strong>范数本质是距离，存在的意义是为了实现比较。</strong></p>
<span id="more"></span>

<hr>
<h3 id="机器学习中的范数"><a href="#机器学习中的范数" class="headerlink" title="机器学习中的范数"></a>机器学习中的范数</h3><h4 id="机器学习中为什么要使用范数"><a href="#机器学习中为什么要使用范数" class="headerlink" title="机器学习中为什么要使用范数"></a>机器学习中为什么要使用范数</h4><p>有监督的机器学习本质是 <strong>minimize your error while regularizing your parameters</strong>，也就是在规则化参数的同时最小化误差。最小化误差是为了让我们的模型拟合我们的训练数据，而规则化参数是防止我们的模型过分拟合我们的训练数据。</p>
<p>因为参数太多，会导致我们的模型复杂度上升，容易过拟合，也就是我们的训练误差会很小。但训练误差小并不是我们的最终目标，我们的目标是希望模型的测试误差小，也就是能准确的预测新的样本。所以，我们需要保证模型“简单”的基础上最小化训练误差，这样得到的参数才具有好的泛化性能（也就是测试误差也小）。</p>
<p>而模型“简单”就是通过规则函数来实现的。另外，规则项的使用还可以约束我们的模型的特性。这样就可以将人对这个模型的先验知识融入到模型的学习当中，强行地让学习到的模型具有人想要的特性，例如稀疏、低秩、平滑等等。要知道，有时候人的先验是非常重要的。前人的经验会让你少走很多弯路，这就是为什么我们平时学习最好找个大牛带带的原因。一句点拨可以为我们拨开眼前乌云，让人醍醐灌顶。对机器学习也是一样，如果被我们人为稍微点拨一下，它肯定能更快的学习相应的任务。只是由于人和机器的交流目前还没有那么直接的方法，目前这个媒介只能由规则项来担当了。</p>
<p>还有几种角度来看待规则化的。规则化符合奥卡姆剃刀(Occam’s razor)原理，它的思想很平易近人：在所有可能选择的模型中，我们应该选择能够很好地解释已知数据并且十分简单的模型。从贝叶斯估计的角度来看，规则化项对应于模型的先验概率。民间还有个说法就是，规则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项(regularizer)或惩罚项(penalty term)。</p>
<hr>
<h4 id="L0范数与L1范数"><a href="#L0范数与L1范数" class="headerlink" title="L0范数与L1范数"></a>L0范数与L1范数</h4><p><strong>L0范数</strong>是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0。换句话说，让参数W是稀疏的。当下风风火火的“压缩感知”和“稀疏编码”的概念用的漫山遍野的“稀疏”就是通过这个思想来实现的。</p>
<p><strong>L1范数</strong>是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）。为什么L1范数会使权值稀疏？有人可能会这样给你回答“它是L0范数的最优凸近似”。实际上，还存在一个更美的回答：任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。说是这么说，W的L1范数是绝对值，|w|在w=0处是不可微。后面会将L1和L2进行对比分析得出为什么L1可以实现稀疏。</p>
<p><strong>既然L0可以实现稀疏，为什么不用L0，而要用L1呢？</strong>上面也提到了一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。一句话总结：L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</p>
<p>到这里，我们大概知道了L1可以实现稀疏，但我们会想，<strong>为什么要稀疏？让我们的参数稀疏有什么好处呢？</strong></p>
<ol>
<li><p><strong>特征选择(Feature Selection)</strong></p>
<p> 大家对稀疏规则化前赴后继的一个关键原因在于它能实现<strong>特征的自动选择</strong>。一般来说，xi的大部分元素（也就是特征）都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。<br> <strong>稀疏规则化算子</strong>的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。</p>
</li>
<li><p><strong>可解释性(Interpretability)</strong></p>
<p> 另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型：y=w1x1+w2x2+…+w1000x1000+b（当然了，为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的w就只有很少的非零元素，例如只有5个非零的wi，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果1000个wi都非0，医生面对这1000种因素，累觉不爱。</p>
</li>
</ol>
<hr>
<h4 id="L2范数"><a href="#L2范数" class="headerlink" title="L2范数"></a>L2范数</h4><p>除了L1范数，还有一种更受宠幸的规则化范数是L2范数。它有两个美称，在回归里面，有人把有它的回归叫“岭回归”（Ridge Regression），有人也叫它“权值衰减”（weight decay）。它的强大功效是改善机器学习里面一个非常重要的问题：过拟合。过拟合就是模型训练时候的误差很小，但在测试的时候误差很大，也就是我们的模型复杂到可以拟合到我们的所有训练样本了，但在实际预测新的样本的时候，糟糕的一塌糊涂。通俗的讲就是擅长背诵知识，却不懂得灵活利用知识，应试能力很强，实际应用能力很差。</p>
<p><strong>为什么L2范数可以防止过拟合？</strong>让L2范数的规则项最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。</p>
<img src="/a8f537a/1.png" class>

<p>一句话总结下：<strong>通过L2范数，我们可以实现了对模型空间的限制，从而在一定程度上避免了过拟合。</strong></p>
<p><strong>L2范数的好处</strong>是什么呢？这里也扯上两点：</p>
<ol>
<li><strong>学习理论</strong>的角度：从学习理论的角度来说，L2范数可以防止过拟合，提升模型的泛化能力。</li>
<li><strong>优化计算</strong>的角度：从优化或者数值计算的角度来说，L2范数有助于处理 condition number 不好的情况下矩阵求逆很困难的问题。</li>
</ol>
<img src="/a8f537a/2.png" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/qq_26369907/article/details/89788593">https://blog.csdn.net/qq_26369907/article/details/89788593</a><br><a href="https://blog.csdn.net/f156207495/article/details/82965093">https://blog.csdn.net/f156207495/article/details/82965093</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>第九艺术-火焰纹章系列整理</title>
    <url>/7a7016a1.html</url>
    <content><![CDATA[<p>作为一个战棋游戏爱好者，本文梳理一下火焰纹章的历史。</p>
<p>火焰之纹章（日文名：ファイアーエムブレム），是Intelligent Systems公司开发，任天堂公司发行的战略角色扮演游戏系列。作为自家大作当然只会在自己的平台上推出，因为任天堂还是一个硬件厂商。</p>
<p>火焰之纹章系列是加贺昭三受到当时日本流行的奇幻小说的影响和日本将棋游戏的启发所设计的以中世纪剑与魔法的奇幻题材为背景的家用机游戏。游戏中的角色主要是骑士、魔法师、剑士和龙人等。</p>
<p>从任天堂时代开始，火焰之纹章系列就一直是玩家们喜爱的游戏之一，战棋的游戏方式总是让玩家沉醉各职业刷怪升级的喜悦中。</p>
<p>2017年2月13日，制作人山上仁志正式宣布，《火焰纹章 回声：另一位英雄王》新增对繁体中文与简体中文的支持，是《火焰纹章》系列的首度官方中文化。</p>
<span id="more"></span>

<hr>
<h3 id="FC时代：共2作"><a href="#FC时代：共2作" class="headerlink" title="FC时代：共2作"></a>FC时代：共2作</h3><h4 id="《火焰之纹章：暗黑龙与光之剑》"><a href="#《火焰之纹章：暗黑龙与光之剑》" class="headerlink" title="《火焰之纹章：暗黑龙与光之剑》"></a>《火焰之纹章：暗黑龙与光之剑》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Shadow Dragon and the Blade of Light</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>FC</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>1990年4月20日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>3M ROM + 64K SRAM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/1.webp" class>

<p>蕴含着火纹小组近三年心血的第一作《火焰之纹章：暗黑龙与光之剑》在日本发售。它讲述了一个发生在名为阿卡内亚大陆的奇幻故事：象征着黑暗的地龙族君主梅德乌斯建立了多鲁亚帝国，它与格鲁尼亚，马凯多尼亚两国结盟并发动了战争，妄图将自己的势力遍布于整个阿卡内亚大陆。百余年前曾用圣剑法尔西昂将梅迪乌斯击败并将其封印的屠龙英雄安利所建立的国家阿利缇亚坚决地反抗多鲁亚帝国的侵略。但由于其兄弟国格拉临阵背叛而全军覆没，国王克内里亚斯也在帝国暗黑祭司加尼弗的恶灵魔法面前战败身亡。年仅十四岁的王子马尔斯在老骑士杰刚和一群年轻部属的保护下，逃亡到了岛国塔利斯并结识了公主希达。3年后，邪恶势力的魔爪伸向塔利斯，王子马尔斯继承英雄王安利的遗志，开始了艰辛的复国之战……</p>
<p>以2000年代的眼光看来，本作无论是剧情表现还是系统设定着实简单且稚嫩。但作为整个系列的第一作，“暗黑龙与光之剑”无疑具有引领业界潮流的重要意义。为S·RPG这种游戏类型正式走上历史舞台奠定了坚实的基础。</p>
<hr>
<h4 id="《火焰之纹章外传》（别称：索菲亚的复苏）"><a href="#《火焰之纹章外传》（别称：索菲亚的复苏）" class="headerlink" title="《火焰之纹章外传》（别称：索菲亚的复苏）"></a>《火焰之纹章外传》（别称：索菲亚的复苏）</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem Gaiden</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>FC</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>1992年3月14日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>2M ROM + 64K SRAM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/2.webp" class>

<p>在很久以前，巴伦西亚大陆分成了南和北。北方是杜马神管理的里柯尔王国，南边是米拉女神掌管的索非亚之国。两国各有分工，由里柯尔王国镇守大陆，索非亚提供丰富的农产品。但两国摩擦愈演愈烈。里柯尔王无奈下顺从了邪神杜马，封闭了米拉神殿。战火在整个大陆蔓延，索非亚城的宰相也一举叛变，还把与他发生冲突的索非亚老臣麦先伯爵赶出城。之后残酷镇压人民的反抗，战乱的消息不久传到了索菲亚南部的一个小村庄，被赶出城的麦先伯爵就住在那里……而后视他为祖父的少年阿鲁姆按照他的嘱咐决定前往米拉神殿查看究竟，故事就这样拉开了帷幕……</p>
<p>与前作系统相异颇多的第二作，大受欢迎。自此FE迷组织化。值得一提的是，外传在系列中是唯一同时具有男女主角的作品。</p>
<hr>
<h3 id="SFC时代：共3作"><a href="#SFC时代：共3作" class="headerlink" title="SFC时代：共3作"></a>SFC时代：共3作</h3><h4 id="《火焰之纹章：纹章之谜》"><a href="#《火焰之纹章：纹章之谜》" class="headerlink" title="《火焰之纹章：纹章之谜》"></a>《火焰之纹章：纹章之谜》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Mystery of the Emblem</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>SFC</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>1994年1月21日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>24M ROM + 64K SRAM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/3.webp" class>

<p>加贺昭三在本作中最大程度地发挥了自己撰写剧本和导演剧作的超凡能力，他对于古代各民族起源与在封建制度下所形成的社会体系、社会思想与社会人文等知识的研究颇为深刻，这为他给作品构筑庞大而深邃的背景打下了坚实的文化基础。无论是龙人族的最初演变还是人类社会的起源发展，他都将之演绎得浅显细致，通俗易懂；他并非能将精力平均且完全地分布给每一个笔下的角色，但却善于以堪寥寥的篇幅让所描述之人物的性格活灵活现，跃然纸上；他所叙述的故事情节将战争与爱情有机地融合在一起，环环相套丝丝入扣，将真挚的情感表露置于庞大的战争画卷中去，显示出娴熟的导演技巧和精妙的剧作安排。篇中的代表人物之一——悲剧的女性尼娜公主为能实现复国之愿甘愿接受月之女神阿尔特弥斯的命运，在实现愿望的同时令她失去了自己所爱和深爱自己的人卡缪，并直接导致昔日战友反目成仇的英雄战争，最终在孤儿院中走完了人生之路……作品以细腻的情怀，幽怨的表述将这位传统的王族女性悲伤的、无力与世俗抗衡的一生表述得淋漓尽致，不仅震撼了所有《纹章》FANS的心，也令许多从未接触过“《FE》系列”的新玩家们感受到了巨大的心灵冲击。</p>
<p>该作发售后很快突破了60万套（最终销量约78万套），成为当时“《FE》系列”中销量最高的作品。日本权威游戏杂志《FAMI通》主编浜村弘一丝毫不吝“史诗”、“完美”等赞美之辞。一些游戏杂志编辑与核心玩家于本作发行后甚至自发组织起了所谓的“FE教”，以显示对FE无上的执着与忠诚。加贺昭三也在经历短暂挫折后成为游戏界的焦点，并荣幸地成为可获得与任天堂老板山内溥对酌小饮之殊荣的少数制作人之一。《纹章之谜》也许并非加贺昭三制作能力最高体现的代表，但确实是让他本人走上人生最高峰的作品。在此后，《火焰之纹章》的声名在S·RPG界如同金字塔顶端一般至高无上，被日本业界诸厂商称为“不可逾越的山峰。</p>
<hr>
<h4 id="《火焰之纹章：圣战之系谱》"><a href="#《火焰之纹章：圣战之系谱》" class="headerlink" title="《火焰之纹章：圣战之系谱》"></a>《火焰之纹章：圣战之系谱》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Genealogy of the War</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>SFC</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>1996年5月14日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>32M ROM + 64K SRAM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/4.webp" class>

<p>《圣战之系谱》的故事脱离了前三作的背景，将舞台转移到遥远的优古德拉尔大陆，古兰贝尔王国由十二圣战的勇者之一的贤者海姆建立，迄今仍由海姆的后嗣治理。现今的国王亚斯穆尔年迈体弱，由王子克尔特代行国政。王国历757年，古兰贝尔王国与东方的依扎克王国发生战争，古兰贝尔诸侯均出兵远征依扎克，西南边境的维尔丹王国乘虚而入，攻陷了诸侯优古维公国的城池并掠走了公主艾汀，留守西南边境的主人公席亚菲公子辛格尔德是艾汀的青梅竹马的好友，于是为了救她而向维尔丹王国进军……剧情的幕布随着辛格尔德的进军慢慢拉开，横跨两代人十六年岁月，版图纵横千里，《圣战之系谱》以其壮绝无双的宏大气魄、有条不紊的信息表述和完善细致的系统设置成为许多火纹FANS心中的神作，而那些被塑造得栩栩如生的人物形象也带给了普通玩家更为深刻的印象。</p>
<p>作为于次时代时期诞生，并承受着更新机种更高性能游戏所带来强大压力的纹章作品，《圣战之系谱》中所涌现的创意是惊人的。前作中骑士职业只有一种类型，新作则根据欧洲中世纪的骑士制度衍生出数种不同类型的骑士职业；增加了种类繁多的个人特技和武器相克性，指挥度，职业数值上限等大量新要素；尤其是横贯上下两代的剧情设定，更让全新设计的，可由玩家控制的爱情培养系统，情侣组合，后代的特技继承与特殊剧情等要素成为令许多玩家乐此不疲的游戏动力；游戏剧情则完全浸染着加贺式戏剧的灵感与创思。</p>
<p>上半部分主人公辛格尔德在战场上所向无敌，却无法抗拒命运齿轮的碾轧沦为统一帝国牺牲品的悲剧性结局以其艺术性来说远远超过为众多专业级玩家好评的《皇家骑士团》（1995年）中任何一段煽情表述。而加贺对日本历史人物明智光秀的偏爱也成为他能游刃有余地塑造出阿尔维斯这个亦正亦邪之个性卓然的角色的根本保障之一。若不是下半部略显苍白老套的“王子复仇记”以及虎头蛇尾的“十二魔将之谜”，可以说圣战系谱剧本的成就完全足以凌驾于同期任何一部以悲情为卖点赚取观众眼泪的文艺作品之上。而下半部的虎头蛇尾剧情，是由于系谱的开发周期过长导致任天堂总部对IS社开发产生了质疑和不满，最终使得横井军平直接以负责人身份接管游戏开发并大刀阔斧的“改革”，使得一款本来能达到巅峰的作品变成了一款半成品，不得不说是火纹历代作品的一大遗憾。游戏制作人才华的表现和游戏企业追逐利益最大化的矛盾则是系谱悲剧的根源。这部游戏也成为加贺昭三与任天堂之间矛盾的导火索。</p>
<hr>
<h4 id="《火焰之纹章：多拉基亚776》"><a href="#《火焰之纹章：多拉基亚776》" class="headerlink" title="《火焰之纹章：多拉基亚776》"></a>《火焰之纹章：多拉基亚776》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Thracia 776</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>SFC</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>1999年9月1日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>32M ROM + 64K SRAM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/5.webp" class>

<p>于1999年9月1日发售的《多拉基亚776》，就本身素质来说相当出色。它的剧情主要以圣战系谱的第五与第六章（即上部与下部之间）到第八章之间的故事为背景，描述前作人物乔安和艾丝琳的儿子利夫如何逃避帝国的追杀，如何发义军南征北战，如何了解与体会民众的苦难，如何与前作主角塞瑞斯王子结盟，最终夺回克诺特和曼斯塔城并消灭罗普特教团势力，解放北多拉基亚大陆的故事。虽其情节主线基本上属于系谱的番外篇章，但却没有流于形式，没有因本作的外传性质而有任何偷懒的地方。主角利夫从单纯地投入复国之战到思索民众的疾苦本源，思索为何而战的改变，体现了加贺昭三原本深受东方贵族血统论影响的思维开始向平民化转变的过程。这也成为《多拉基亚776》在理念与思想上比《圣战之系谱》更加贴近平民意识，也更富有人文性的表征之一。</p>
<p>《多拉基亚776》以35分的成绩进入了《FAMI通》的白金殿堂。</p>
<hr>
<h3 id="GBA时代：共3作"><a href="#GBA时代：共3作" class="headerlink" title="GBA时代：共3作"></a>GBA时代：共3作</h3><h4 id="《火焰之纹章：封印之剑》"><a href="#《火焰之纹章：封印之剑》" class="headerlink" title="《火焰之纹章：封印之剑》"></a>《火焰之纹章：封印之剑》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem:The Binding Blade</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>GBA</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2002年3月29日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>64M ROM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/6.webp" class>

<p>《火焰之纹章：封印之剑》作为GBA掌机的第一部作品，游戏系统承袭了先前的方式，本作剧情也让玩家有口皆碑，同时享受游戏剧情以及游戏内容。除此之外，也充分利用了GBA的通信对战功能，玩家们可以通过对战线，最多能够4名玩家同时进行对战。</p>
<p>《封印之剑》的故事发生在一块名为艾雷布的大陆。很久以前，大陆上的人类与龙族和平共处，彼此友善，但人类日益贪婪的欲望终于促使他们对龙族发动旷日持久的“人龙战争”。当时，以哈尔特姆德为首的八神将以神将器击败了龙族。使龙族消失了数百年。而在《封印之剑》故事发生的时代，哈尔特姆德所创立的国家——伯尔尼王国国王塞菲尔却企图依靠解放龙族来“净化”世界，一个由众多小国组成的联盟国家——利西亚联盟遭到了伯尔尼的入侵，诸侯国之一菲雷公国公子罗伊代替重病的父亲，投入到反抗伯尔尼入侵的战争中。</p>
<p>《封印之剑》最初的命名是《灰色巫女》，但是在游戏开发初期，加贺昭三因为和任天堂的矛盾而离职，撂下挑子，当时业界普遍不看好加贺离职后的火纹作品，但是IS社最终推翻了原来的剧本，并将之改名《封印之剑》，剧情模式有点类似于初代的《暗黑龙与光之剑》，在后来的访谈录中，IS社新的掌门人也表示，加贺离开后，火焰纹章系列将迎来自己的转折点，但也是新的起点。《封印之剑》交给了玩家一份让人满意的答卷。</p>
<p>《封印之剑》以36分的成绩进入了《FAMI通》的白金殿堂。</p>
<hr>
<h4 id="《火焰之纹章：烈火之剑》"><a href="#《火焰之纹章：烈火之剑》" class="headerlink" title="《火焰之纹章：烈火之剑》"></a>《火焰之纹章：烈火之剑》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: The Blazing Blade</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>GBA</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2003年4月25日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>128M ROM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/7.webp" class>

<p>用同样的开发引擎，2倍函数据库，《烈火之剑》就画面的表现力来说比《封印之剑》高很多。《烈火之剑》的故事发生在前作故事的25年前，是《封印之剑》的前传，因此在《烈火之剑》的人物身上可以看到许多前作人物的影子，若是玩过前作的玩家一定会被这种血脉的相连感动。</p>
<p>在萨卡草原上长大的罗鲁卡族少女——琳意外地得知自己是利西亚地方贵族的后人，也是唯一的继承人，自己的真名叫做“琳迪斯”。面对时刻想除掉自己篡权夺位的侯弟，琳在偶遇的忠诚骑士与志士的护卫下与之展开战斗，最后夺回王位。艾利乌德与好友赫克托尔共同踏上征途，却遇到了名为“黑之牙”的义贼组织的干扰，暗黑巫师，异种人，封魔者，冰龙族姐弟……琳的祖孙情，艾利乌德父子情,，赫克托耳的兄弟情都得以感人的表现。</p>
<p>如果说封印的剧情为大气，那烈火的剧情就是温馨。系统除了增加天气对战斗的影响，及玩家所扮演军师的指挥数值对游戏的影响外，《烈火之剑》对新要素的重视远远逊于前作（可能也和时间紧迫有关）。而为数不多的两个创新也着实让人感觉味同嚼蜡。没有什么值得肯定的要素，不过对于输送队成长的判定以及整体作战平衡性来说还是值得称道的。而且本作人设做的相当漂亮，让人眼前一亮。</p>
<p>值得一提的是，烈火之剑是第一个投放欧美市场的《火纹之纹章》作品，其反响出乎预料地热烈，如今全球销量已逾50万。</p>
<hr>
<h4 id="《火焰之纹章：圣魔之光石》"><a href="#《火焰之纹章：圣魔之光石》" class="headerlink" title="《火焰之纹章：圣魔之光石》"></a>《火焰之纹章：圣魔之光石》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: The Sacred Stones</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>GBA</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2004年10月07日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>128M ROM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/8.webp" class>

<p>本作游戏背景设定为新的玛基▪维尔大陆。游戏的主人公是侠义的王室兄妹伊弗列姆和艾瑞珂。当古拉德王国对自己的盟国鲁内斯突然发动猛攻并占领之后，伊弗列姆和艾瑞珂是为数不多的幸存者，于是他们肩负起调查古拉德背叛的源头与平息大陆动乱的重任。玩家从这两个角色的视角体验游戏，并且中间还会有分支情节供选择，从而体验不同角度的情节发展。</p>
<p>而增加了世界地图系统对购买武器、道具、培养角色和了解世界观有不少帮助。“威鲁尼之塔”和“格拉多遗迹”的设定也让追求完美的玩家可以从容地练级。故事情节在老套之中又有新意,悲剧皇子里昂和矛盾的圣骑士奥尔森是全剧中的塑造得最好的人物,使圣魔的人性观得到了很大的提升。</p>
<p>《圣魔之光石》的主题毫无疑问是友情，到了后期与利昂的几场战斗，这一主题开始明朗化，一段段剧情说明了主角二人和利昂之间深厚的情感。直到结局，利昂的悲情独白更是将“友情”这一游戏主题推向了高潮。</p>
<hr>
<h3 id="NGC时代：共1作"><a href="#NGC时代：共1作" class="headerlink" title="NGC时代：共1作"></a>NGC时代：共1作</h3><h4 id="《火焰之纹章：苍炎之轨迹》"><a href="#《火焰之纹章：苍炎之轨迹》" class="headerlink" title="《火焰之纹章：苍炎之轨迹》"></a>《火焰之纹章：苍炎之轨迹》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Path of Radiance</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>NGC</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2005年4月20日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>1.4GFE</td>
</tr>
</tbody></table>
<img src="/7a7016a1/9.webp" class>

<p>15周年的纪念性作品，也是事隔6年以来FE系列第一次重归家用机平台的一部作品。游戏本身相对以前的FE做了许多一反常规的改动，而这些改动都是FE走向一个新境界所必需的。主角艾克在克里米亚王国的乡下生活，在父亲古雷尔的佣兵团里长大的佣兵。他正式成为佣兵的那一年，迪恩王国突然发动侵略战争，佣兵团一行偶遇克里米亚王国未公开身份的公主艾琳西娅并决定保护她。而妹妹米丝特手中发出青蓝色光辉的母亲的遗物——纪念纹章也屡屡成为迪恩军队的目标。带着对亡父的思念和复国的愿望，艾克逐渐成长为一个能独当一面的领主。他征战南北，把两个种族的人连结在一起，感受各国的人民对战争复杂的情感，最终夺回克里米亚王国。</p>
<p>本作剧情跌宕起伏，与之前的作品有着许多不同。“拉格兹”（兽人）这一种族，使得游戏十分饱满。一系列的事件环环相扣，最终在艾克和热爱和平的人们的努力下联系在一起，成为贝奥克（人类）和拉格兹两个种族的人们重归于好的纽带。尤其是“再生之森”这一段过场动画，着实让人感动。剧情深刻地揭示了战争的矛盾，更切合实际而富有人文性。</p>
<p>本作的存档是可以继承到“晓之女神”里去的，存档中部分主要人物的能力，会对该人物在晓女中的初始能力产生影响。若继承包含艾克和塞内里奥A级支援的存档，在晓女中再次满足A级支援则会有隐藏剧情。</p>
<hr>
<h3 id="Wii时代：共1作"><a href="#Wii时代：共1作" class="headerlink" title="Wii时代：共1作"></a>Wii时代：共1作</h3><h4 id="《火焰之纹章：晓之女神》"><a href="#《火焰之纹章：晓之女神》" class="headerlink" title="《火焰之纹章：晓之女神》"></a>《火焰之纹章：晓之女神》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Radiant Dawn</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>Wii</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2007年2月22日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>1DVD</td>
</tr>
</tbody></table>
<img src="/7a7016a1/10.webp" class>

<p>至今为止系列中最异类，也是最让玩家感到震惊的一作。该作出在任天堂的Wii主机上。本作的画面与NGC版相比有明显进步，人物与场地看起来相当精细，使用技能与魔法的效果十分华丽，人物动作也更为丰富，相信该作一定能够让广大爱好者满意。</p>
<p>本作的故事是发生在《火焰之纹章：苍炎之轨迹》故事的3年之后，故事是从迪恩王国的某个村落开始的。虽然前次的战争已经过去3年，但是迪恩王国依旧是满目疮痍，而由于迪因王国身为战败国失去大部分战力，因此受到山贼的侵扰，而拥有特别力量的少女米卡娅正是在这个时候出现，为了救助人民与搭档萨扎一起挺身而出与山贼作战。</p>
<p>玩家在游戏初期时可以选择难度，这一设定相当照顾初次接触该系列的玩友，而老手也可以选择普通或困难模式进行游戏，系列难度高的特点将会充分体现。</p>
<p>本作的主题和剧情十分深刻而耐人寻味，人设也做得十分漂亮，是玩家们不能错过的一作。</p>
<hr>
<h3 id="NDS时代：共2作"><a href="#NDS时代：共2作" class="headerlink" title="NDS时代：共2作"></a>NDS时代：共2作</h3><h4 id="《火焰之纹章：新·暗黑龙与光之剑》"><a href="#《火焰之纹章：新·暗黑龙与光之剑》" class="headerlink" title="《火焰之纹章：新·暗黑龙与光之剑》"></a>《火焰之纹章：新·暗黑龙与光之剑》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Shadow Dragon</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>NDS</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2008年8月3日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>512M ROM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/11.webp" class>

<p>本作为火纹初代的复刻版，游戏系统不但很好的利用NDS双屏的特性，将游戏的单位部署画面和地图画面同时显示出来，而且也追加了触摸笔的操控模式，本作也将支持通过任天堂的Wi-Fi Connection进行全球对战。</p>
<p>主角为大陆上小国的王子马尔斯，当他的祖国遭到同盟国格拉背叛袭击时，他还是个不谙世事的少年王子。而后，在解放全大陆的过程中，他迅速成长为一个成熟、兼具战略眼光和人格魅力的年轻国王。马尔斯作为最初一代的主角，也是火焰之纹章全系列的代表角色之一。</p>
<p>人物能力方面，力量和魔力分开来了。每章中间都增设了1~2个存档点，总体感觉画面比较厚重，但是地图明亮度和网格线浓度都是可以调节的，也让玩家在游戏过程中感觉舒适了不少。</p>
<p>新系统职业横转，职业分为两大系列，除领主、龙人、弩车、舞者、盗贼外均可在本职业所属的系列内进行横转，不同职业间转换对能力和成长率有不同的影响。</p>
<hr>
<h4 id="《火焰之纹章：新·纹章之谜-光与影的英雄》"><a href="#《火焰之纹章：新·纹章之谜-光与影的英雄》" class="headerlink" title="《火焰之纹章：新·纹章之谜 光与影的英雄》"></a>《火焰之纹章：新·纹章之谜 光与影的英雄》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>机种</strong></td>
<td>NDS</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2010年7月15日</td>
</tr>
<tr>
<td><strong>容量</strong></td>
<td>512M ROM</td>
</tr>
</tbody></table>
<img src="/7a7016a1/12.webp" class>

<p>2010年是火纹20周年作品 剧情是1994年推出的SFC版《火焰之纹章：纹章之谜》的大幅改进复刻的作品，这款作品讲述的是《火焰之纹章：暗黑龙与光之剑》之后“英雄战争”的故事。影之主角是本作的最大特色，自定义主角将会作为英雄王背后的英雄全新登场，姓名、性别、兵种以及人物形象都可以由玩家自由设定，可以说是玩家的“分身”。而且影英的成长简直就是怪物级，新手也能轻易练出高能力。DS特有的Wi-Fi通信将会在一周目通关后提供追加地图的下载、对战以及人物的通信租借等等功能。</p>
<p>新系统：</p>
<ol>
<li>新增casual mode，即在我方人员死亡后，在下一章仍可重新出战。此功能一反火纹的常规，可以看作是向新玩家抛出的橄榄枝。对于老玩家来说完全可以无视，新玩家可以试着上手。</li>
<li>新增人物关系图，可以详细了解人物和国家的资料。</li>
<li>加入支援对话。战前有对话系统，可以了解各种事件。</li>
<li>保留NDS上作的职业转换功能。</li>
<li>纹章之谜时只能借助卫星通讯下载的特别关卡在序章完成后会完全开放，这些关卡都很有难度。</li>
</ol>
<hr>
<h3 id="3DS时代：共3作"><a href="#3DS时代：共3作" class="headerlink" title="3DS时代：共3作"></a>3DS时代：共3作</h3><h4 id="《火焰之纹章：觉醒》"><a href="#《火焰之纹章：觉醒》" class="headerlink" title="《火焰之纹章：觉醒》"></a>《火焰之纹章：觉醒》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Awakening</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>3DS</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2012年4月19日</td>
</tr>
</tbody></table>
<img src="/7a7016a1/13.webp" class>

<p>男主角是伊利斯圣王国的年轻王子、英雄王的末裔库洛姆。（CV：杉田智和）。他同时还担任王国自警团团长，守护着祖国的和平。使用王族代代相传的宝剑“法尔西昂”战斗。</p>
<p>本作剧情看点很多，虽然流程很短但十分引人入胜。而且画风是漫画风，与日本欧式RPG人设相似。不论能否接受，本作一定会带给老玩家很多新意。本作依然有玩家自创的角色参战，而且可以和其他角色建立羁绊。世界地图系统恢复。保留特技和奥义系统。战斗画面变得华丽了不少，并且角色发动必杀时新增了充满魄力的特写。支援角色可以直接协同战斗。除画面和系统都有明显的提升外，本作还加入了部分语音，这是继晓女之后第二次出现语音，我们将会看到通过语音表现出更丰富个性的角色们。</p>
<p>《觉醒》以36分的成绩进入了《FAMI通》的白金殿堂。</p>
<hr>
<h4 id="《火焰之纹章if：白夜王国-暗夜王国-透魔王国》"><a href="#《火焰之纹章if：白夜王国-暗夜王国-透魔王国》" class="headerlink" title="《火焰之纹章if：白夜王国/暗夜王国/透魔王国》"></a>《火焰之纹章if：白夜王国/暗夜王国/透魔王国》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem Fates – Birthright/Conquest/Revelations</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>3DS</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2015年6月25日</td>
</tr>
</tbody></table>
<img src="/7a7016a1/14.webp" class>

<p>《火焰之纹章：if》是《火焰之纹章：觉醒》之后的第二款3DS火纹，开发团队是《觉醒》的原班人马。其中关卡设计，系统完成度达到历史新高，主题曲和配乐也饱受好评。与前代不同的是，《if》并不只以欧洲中世纪为背景，而是加入了日本传统元素。《if》的人设由コザキユースケ负责，剧本是《金田一少年事件簿》的故事原作，笔名天树征丸的树林伸先生。在结婚（感情）系统上，《if》在人物设定上引入了日本的萌腐宅元素，打破了前代许多禁忌。常被老玩家认为用力过猛。值得一提的是，《if》是火焰纹章系列中第一部可以同性结婚的作品，是一次不小的突破。从游戏开发画面来看，《if》继承发扬了《觉醒》的特色并有所强化。</p>
<hr>
<h4 id="《火焰之纹章回声：另一位英雄王》"><a href="#《火焰之纹章回声：另一位英雄王》" class="headerlink" title="《火焰之纹章回声：另一位英雄王》"></a>《火焰之纹章回声：另一位英雄王》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem Echoes: Shadows of Valentia</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>3DS</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2017年4月20日</td>
</tr>
</tbody></table>
<img src="/7a7016a1/15.webp" class>

<p>本作是一部复刻作，也是火纹在3ds上的最后一部作品。其原型是作为火纹系列的第二部作品《火焰纹章外传》。在和系列之前在3DS上的另外两部作品，本作有了很大的提升，尽管依然是机能不足的3DS平台，但是能看出来制作组对于本作的用心程度超过之前两作，同时任天堂为了试水中华市场，本作是第一部拥有官方简繁中文的火纹作品。</p>
<p>人设方面扭转了《if》服务精神过盛且充斥面团脸的“一番好意”，使人物看上去重新变得成熟真实，符合本作穿越漫长时空归来的历史感；语音上也不再是半成品状态，角色会完整念完整段台词，并且战斗地图中每当光标移动到一个单位上时，也会立刻有语音做出反应——这对于大部分时间关闭战斗画面的玩家来说算得上是一种不错的调剂，也增强了临场体验，本作最大的亮点是在关键的剧情中会有精美的2D动画通过富有张力的分镜完美烘托出战场氛围。《回声》可以说是出色地完成了火纹系列在3DS上的“最终封箱任务”。</p>
<hr>
<h3 id="Switch时代：目前共1作"><a href="#Switch时代：目前共1作" class="headerlink" title="Switch时代：目前共1作"></a>Switch时代：目前共1作</h3><h4 id="《火焰之纹章：风花雪月》"><a href="#《火焰之纹章：风花雪月》" class="headerlink" title="《火焰之纹章：风花雪月》"></a>《火焰之纹章：风花雪月》</h4><table>
<thead>
<tr>
<th>介绍</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>英文名</strong></td>
<td>Fire Emblem: Three Houses</td>
</tr>
<tr>
<td><strong>机种</strong></td>
<td>NS</td>
</tr>
<tr>
<td><strong>发售日期</strong></td>
<td>2019年7月26日</td>
</tr>
</tbody></table>
<img src="/7a7016a1/16.webp" class>

<p>本作是火纹时隔12年再度登陆家用机平台，并与光荣特库摩合作共同研发，因光荣公司以制作中国三国题材游戏闻名，受此影响本作的故事背景也设定在三国争霸的弗德兰大陆，为了强调时间流逝，岁月沧桑的季节感，制作组以中国成语“风花雪月”来命名副标题。在战斗方面，以往角色战斗场景的单位往往是个人，这次则加入了兵队，对战场的战斗画面迎来了革新，为了让对“战略模拟游戏”敬而远之的玩家也能入手本作，制作组将养成要素作为了游戏系统的重点。玩家通过培养角色，就可以在某种程度上强行过关，即使是不擅长战略模拟游戏的玩家也能轻松游玩。整体画面也借着NS的机能，实现进一步的提升。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><table>
<thead>
<tr>
<th>发售日期</th>
<th>机种</th>
<th>名称</th>
<th>容量</th>
<th>售价</th>
</tr>
</thead>
<tbody><tr>
<td>1990.4.20</td>
<td>FC(NES)</td>
<td>火焰之纹章：暗黑龙与光之剑</td>
<td>3M ROM + 64K SRAM</td>
<td>6000日元</td>
</tr>
<tr>
<td>1992.3.14</td>
<td>FC(NES)</td>
<td>火焰之纹章外传(索菲亚的复苏)</td>
<td>2M ROM + 64K SRAM</td>
<td>6800日元</td>
</tr>
<tr>
<td>1994.1.21</td>
<td>SFC(SNES)</td>
<td>火焰之纹章：纹章之谜</td>
<td>24M ROM + 64K SRAM</td>
<td>9800日元</td>
</tr>
<tr>
<td>1996.5.14</td>
<td>SFC(SNES)</td>
<td>火焰之纹章：圣战之系谱</td>
<td>32M ROM + 64K SRAM</td>
<td>7500日元</td>
</tr>
<tr>
<td>1999.9.1</td>
<td>SFC(SNES)</td>
<td>火焰之纹章：多拉基亚776</td>
<td>32M ROM + 64K SRAM</td>
<td>2500日元 5200日元(卡带版)</td>
</tr>
<tr>
<td>2002.3.29</td>
<td>GBA</td>
<td>火焰之纹章：封印之剑</td>
<td>64M ROM</td>
<td>4800日元</td>
</tr>
<tr>
<td>2003.4.25</td>
<td>GBA</td>
<td>火焰之纹章：烈火之剑</td>
<td>128M ROM</td>
<td>4800日元</td>
</tr>
<tr>
<td>2004.10.7</td>
<td>GBA</td>
<td>火焰之纹章：圣魔之光石</td>
<td>128M ROM</td>
<td>4800日元</td>
</tr>
<tr>
<td>2005.4.20</td>
<td>NGC</td>
<td>火焰之纹章：苍炎之轨迹</td>
<td>1.4G</td>
<td>6800日元</td>
</tr>
<tr>
<td>2007.2.22</td>
<td>Wii</td>
<td>火焰之纹章：晓之女神</td>
<td>1DVD</td>
<td>6800日元</td>
</tr>
<tr>
<td>2008.8.7</td>
<td>NDS</td>
<td>火焰之纹章：新·暗黑龙与光之剑</td>
<td>512M ROM</td>
<td>4800日元</td>
</tr>
<tr>
<td>2010.7.15</td>
<td>NDS</td>
<td>火焰之纹章：新·纹章之谜 光与影的英雄</td>
<td>512MROM</td>
<td>4800日元</td>
</tr>
<tr>
<td>2012.4.19</td>
<td>3DS</td>
<td>火焰之纹章：觉醒</td>
<td></td>
<td>4800日元</td>
</tr>
<tr>
<td>2015.6.25</td>
<td>3DS</td>
<td>火焰之纹章：if</td>
<td></td>
<td>4800日元</td>
</tr>
<tr>
<td>2017.2.2</td>
<td>Android &amp; IOS</td>
<td>火焰之纹章：英雄</td>
<td></td>
<td>免费</td>
</tr>
<tr>
<td>2017.4.20</td>
<td>3DS</td>
<td>火焰之纹章回声：另一位英雄王</td>
<td></td>
<td>6980日元</td>
</tr>
<tr>
<td>2017.9.28</td>
<td>Nintendo Switch &amp; 新3DS</td>
<td>火焰之纹章：无双</td>
<td></td>
<td>8580日元</td>
</tr>
<tr>
<td>2019.7.26</td>
<td>Nintendo Switch</td>
<td>火焰之纹章：风花雪月</td>
<td></td>
<td>6980日元</td>
</tr>
</tbody></table>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://baike.baidu.com/item/%E7%81%AB%E7%84%B0%E4%B9%8B%E7%BA%B9%E7%AB%A0/9705705">https://baike.baidu.com/item/%E7%81%AB%E7%84%B0%E4%B9%8B%E7%BA%B9%E7%AB%A0/9705705</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-脑机接口助力睡眠改善</title>
    <url>/8781df9d.html</url>
    <content><![CDATA[<p>世界上约有27%的人受到睡眠问题的困扰，据最新《2021年运动与睡眠白皮书》显示，中国当前有超3亿人存在睡眠障碍问题。长年累月的睡眠困扰会对人的身心健康造成负面影响，那么我国迅速发展的脑机接口技术近期对睡眠问题提供了怎样的解决方案呢？</p>
<span id="more"></span>

<hr>
<h3 id="便携小巧的脑机接口设备"><a href="#便携小巧的脑机接口设备" class="headerlink" title="便携小巧的脑机接口设备"></a>便携小巧的脑机接口设备</h3><p>在以往医学中，并没有特别方便快捷、好用还便宜的手段来诊断睡眠疾病，已有的医用多导睡眠仪虽是目前睡眠疾病诊断的金判断手段，但因为其连接麻烦影响睡眠、判图复杂诊断效率低的缺点，大部分医生还是依靠主观方式来诊断疾病，因此需要便携小巧的医疗级设备，来帮助越来越多的睡眠障碍患者解决睡眠问题。</p>
<p>下图为多导睡眠仪</p>
<img src="/8781df9d/1.jpg" class>

<p>2021年6月22日，脑陆科技联合神经调控技术国家工程实验室共同举办了首届“脑科学开放日”，并且脑陆科技联合创始人兼CMO吴寒峰先生于会上正式发布了第三代个人消费级脑机接口产品SleepUp，具体算法和细节并未给出详细信息，但据透露SleepUp仅有38g，基于脑电信号采集技术，融合多模态生物信号采集技术，在机器学习算法支持下为用户提供精准的睡眠管理方案，达到了医疗级精准度的睡眠分期结果。</p>
<img src="/8781df9d/2.jpg" class>

<p>同样做到便携小巧的还有云睿智能推出的优梦思UMindSleep额贴式无线脑电睡眠监测设备，能准确采集高精度的脑电、血氧、脉率、体位、体动等多项生命体征参数，自动完成数据采集、上传、分析反馈，为广大亚健康人群及睡眠障碍患者提供实时、连续的睡眠分期监测服务，总体分期准确率达到了83.02%，且是目前世界上通过国际脑电图机标准的体积最小的设备，主机仅重15g。</p>
<img src="/8781df9d/3.jpg" class>

<hr>
<h3 id="不同频率声波引导入睡"><a href="#不同频率声波引导入睡" class="headerlink" title="不同频率声波引导入睡"></a>不同频率声波引导入睡</h3><p>仅通过脑机设备实时判断睡眠阶段并未对睡眠起到直接的改善作用，还需在了解大脑目前脑电波模式后诱导脑电波模式转变才能达到助眠的效果。已经确定的人的脑电波模式主要都包含在30赫兹（Hz）以下的频率中，有如下四类：</p>
<ul>
<li>β模式：频率15-30 Hz，大脑处于高度清醒及活跃状态；</li>
<li>α模式：频率8-14 Hz，大脑处于放松但仍保留意识状态；</li>
<li>θ模式：频率4-7 Hz，大脑处于似睡非睡的潜意识状态；</li>
<li>δ模式：频率0.5-3 Hz，大脑处于深睡状态。</li>
</ul>
<p>脑电波模式与外界交互频率相关，当外界刺激作用于大脑时，有可能使脑电波频率实现模式的转变，这个过程就叫大脑加载。大脑加载最简单的工具就是声音，然而足以有效刺激大脑的声音频率很低，人们无法听见，因此需要采用双声拍技术（Binaural Beat Technology，BBT），即同时给左耳和右耳分别播放两种频率相近但不相同的声波刺激，两种音调的频率差会被大脑感应到从而进行大脑加载。</p>
<p>SleepUp便基于BBT技术，通过识别人体脑电，根据用户大脑神经信号状态，智能匹配不同频段和能量的声波（白噪声和粉噪声），诱导大脑神经信号由兴奋逐步过渡到平静睡眠状态，优化睡眠结构比例，实现了个性化的助眠干预。睡眠质量差关键诱因有两个，一是入睡困难，二是难以进入深睡，目前SleepUp可将清醒到浅睡的平均用时缩短40%，平均深睡比例提高30%。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>与多导睡眠仪相比，SleepUp和UMindSleep更加便携小巧，可多场景应用，为多导睡眠仪的局限性提供了解决方案。与目前市面上流行的手环相比，基于脑机接口的睡眠监测设备可以提供更接近临床睡眠检测的方案。不止于睡眠领域，随着人工智能与脑科学的进一步结合，人工智能发展的未来将是人机协同、人机共生，既不是简单的人类制造、控制、利用机器，更不可能是人工智能取代人类，人机各有所长，互为补充，造福生活中的方方面面。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://www.neurosky.com.cn/%e5%a6%82%e4%bd%95%e5%88%a9%e7%94%a8%e8%84%91%e7%94%b5%e6%b3%a2%e5%8f%98%e5%8c%96%e6%94%b9%e5%96%84%e7%9d%a1%e7%9c%a0%ef%bc%9f/">http://www.neurosky.com.cn/%e5%a6%82%e4%bd%95%e5%88%a9%e7%94%a8%e8%84%91%e7%94%b5%e6%b3%a2%e5%8f%98%e5%8c%96%e6%94%b9%e5%96%84%e7%9d%a1%e7%9c%a0%ef%bc%9f/</a><br><a href="https://www.sohu.com/a/473698733_629135">https://www.sohu.com/a/473698733_629135</a><br><a href="https://www.sohu.com/a/506405196_120996714">https://www.sohu.com/a/506405196_120996714</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11103">https://www.scholat.com/teamwork/showPostMessage.html?id=11103</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-图神经网络（GNN/GCN）论文精读</title>
    <url>/1cd42ec5.html</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>原文地址：<a href="https://staging.distill.pub/2021/gnn-intro/">A Gentle Introduction to Graph Neural Networks</a></p>
<p>原文是一篇博客形式的文章，该文章最大的特点：全篇没有公式，完全用可交互的图来对GNN进行说明。因此，本文适合作为入门教学。</p>
<p>阅读本文前建议先读一读<a href="https://blog.csdn.net/Cyril_KI/article/details/122058881">图神经网络（GNN）的基本原理</a></p>
<p>本文的内容：</p>
<ol>
<li>什么样的数据最适合用图来表达？怎么将这种数据转为图数据？</li>
<li>是什么使图与其他类型的数据不同，以及我们在使用图时必须做出的一些特殊选择。</li>
<li>构建了一个GNN，并对其进行了详细地解释。</li>
<li>提供了一个GNN的playground，用户可以在其中选择参数在线训练GNN。</li>
</ol>
<span id="more"></span>

<hr>
<h3 id="图是什么？"><a href="#图是什么？" class="headerlink" title="图是什么？"></a>图是什么？</h3><p>计算机专业的同学由于学过数据结构，对图肯定很熟悉了。本文给出得图的定义为：<strong>A graph represents the relations (edges) between a collection of entities (nodes).</strong></p>
<p>即：图表示实体（节点）集合之间的关系（边）。</p>
<img src="/1cd42ec5/1.png" class>

<p>其中 V 表示顶点，E 表示边，U 表示全局（<strong>这个后面会有详细解释</strong>）。可以看到每一个定义后面都有一个attributes，这意味着我们不能只关注图的一个<strong>结构信息</strong>，还应该关注<strong>属性信息</strong>，比如节点的邻居数，边的权重，最长路径等等。</p>
<hr>
<h3 id="数据如何表示成图？"><a href="#数据如何表示成图？" class="headerlink" title="数据如何表示成图？"></a>数据如何表示成图？</h3><p>我们在现实生活中已经见过很多类型的图，比如社交网络：顶点为用户，边表示两个用户间存在某种联系，这很容易理解。</p>
<p>本节作者讲述了<strong>如何将两种（图像和文本）看似与graph不相关的数据表示成我们熟悉的graph数据。</strong></p>
<hr>
<h4 id="图像"><a href="#图像" class="headerlink" title="图像"></a>图像</h4><p>在<a href="https://blog.csdn.net/Cyril_KI/article/details/108154104">CNN实战</a>中，我们利用PIL包的Image来处理图像数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Myloader</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Image.<span class="built_in">open</span>(path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>读入彩色图的时候，读出的是一个二维矩阵，矩阵中每个元素（像素）有RGB三个值。因此，我们通常将图像视为具有图像通道的矩形网格，每个像素代表一个节点，并与周围的像素点相连（8个）：</p>
<img src="/1cd42ec5/2.png" class>

<p>假设我们有一张图：244 × 244 × 3，高宽都是244，有RGB三个通道，那么我们该怎么把这个 244 × 244 × 3 的image表示为graph数据呢？</p>
<p>这里需要用到邻接矩阵A，假设我们以其中 25 × 25 个像素点为例：</p>
<img src="/1cd42ec5/3.png" class>

<p><strong>每一个像素点都和周围八个像素点相连，因此邻接矩阵中这八个位置都为1。</strong></p>
<p>因此对于image数据，如果它有25 × 25 25 \times 2525×25个像素点，那么我们就能够建立一个拥有25个节点的图，每个节点可以跟其周围八个节点相连。</p>
<hr>
<h4 id="文本"><a href="#文本" class="headerlink" title="文本"></a>文本</h4><p>文本可以被认为是一个序列，其中<strong>每一个词作为一个节点，每一个词和其下一个词之前有一条有向边：</strong></p>
<img src="/1cd42ec5/4.png" class>

<hr>
<h4 id="其他数据"><a href="#其他数据" class="headerlink" title="其他数据"></a>其他数据</h4><p>除了上述图像和文本外，还有一些数据，除了图以外，我们很难用其他形式来表示他们！</p>
<h5 id="分子"><a href="#分子" class="headerlink" title="分子"></a>分子</h5><p>分子中原子通过作用力连在一起，因此每一个原子可以表示为一个点，原子间键表示为边。 如下图是一个香料分子：</p>
<img src="/1cd42ec5/5.png" class>

<p>以及咖啡因分子：</p>
<img src="/1cd42ec5/6.png" class>

<h5 id="社交网络"><a href="#社交网络" class="headerlink" title="社交网络"></a>社交网络</h5><p>社交网络除了graph外，我们很难再想出其他表示形式。<strong>在社交网络中，我们将个人表示为节点，将他们间的关系表示为边。</strong></p>
<p>比如戏剧中人物关系图：</p>
<img src="/1cd42ec5/7.png" class>

<h5 id="引文图"><a href="#引文图" class="headerlink" title="引文图"></a>引文图</h5><p>将论文抽象为节点，论文A引用了论文B，则有一条有向边A-&gt;B。</p>
<hr>
<h3 id="图中的任务"><a href="#图中的任务" class="headerlink" title="图中的任务"></a>图中的任务</h3><p>图里面的任务主要分为三大类：图级、节点级和边级。在图级任务中，我们预测整个图的属性。对于节点级任务，我们预测图中每个节点的一些属性。对于边级任务，我们希望预测图中边的属性或者是否存在这条边。</p>
<h4 id="图级任务"><a href="#图级任务" class="headerlink" title="图级任务"></a>图级任务</h4><p>在图级任务中，我们的目标是<strong>预测整个图的属性</strong>。 比如对于某一分子，我们可能想要预测该分子的气味，或者它是否会和与疾病有关的受体结合。</p>
<img src="/1cd42ec5/8.png" class>

<p>我们输入的是一张图，输出的是该图的label，比如该图是否有两个环？</p>
<hr>
<h4 id="节点级任务"><a href="#节点级任务" class="headerlink" title="节点级任务"></a>节点级任务</h4><p><strong>节点级任务主要预测单个节点的属性。</strong>节点级预测问题的一个经典示例是空手道俱乐部数据集，该数据集是一个社交网络图，每个节点都具有一个唯一的label。</p>
<p>在network中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">G = nx.karate_club_graph()</span><br><span class="line">nodes = <span class="built_in">list</span>(G.nodes.data())</span><br><span class="line"><span class="built_in">print</span>(nodes)</span><br></pre></td></tr></table></figure>

<p>输出为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[(<span class="number">0</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">1</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">2</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">3</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">4</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">5</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">6</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">7</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">8</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">9</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">10</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">11</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">12</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">13</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">14</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">15</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">16</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">17</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">18</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">19</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">20</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">21</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Mr. Hi&#x27;</span>&#125;), (<span class="number">22</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">23</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">24</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">25</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">26</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">27</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">28</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">29</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">30</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">31</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">32</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;), (<span class="number">33</span>, &#123;<span class="string">&#x27;club&#x27;</span>: <span class="string">&#x27;Officer&#x27;</span>&#125;)]</span><br></pre></td></tr></table></figure>

<p>可以看到，每一个节点的标签要么为Mr. Hi，要么为Officer。在这种情况下，我们就可以建立一个模型对某一个节点的label进行预测。</p>
<p>因此，节点预测的输入是一个图，输出是节点的标签：</p>
<img src="/1cd42ec5/9.png" class>

<h4 id="边级任务"><a href="#边级任务" class="headerlink" title="边级任务"></a>边级任务</h4><p>对于边级任务：给定一些节点，我们希望<strong>预测这些节点中的哪些共享一条边或该边的权值是什么。</strong></p>
<hr>
<h3 id="使用图数据的挑战"><a href="#使用图数据的挑战" class="headerlink" title="使用图数据的挑战"></a>使用图数据的挑战</h3><p>在使用神经网络对图进行处理前，我们得先将图表示成神经网络能够处理的数据类型。</p>
<p>图上的信息有四种：节点属性、边属性、全局属性以及连接性。</p>
<p>图表示的难点在于<strong>怎么来表示图的连接性。</strong>最容易想到的就是邻接矩阵：相连为1否则为0。</p>
<p>不过，使用邻接矩阵来表示连接性的缺点是显而易见的：对于一些大型网络，其节点数可能上百万，并且每个节点的边数变化可能会很大，比如某些节点连接了几万条边，有些节点只连接了一条边，这样邻接矩阵将会非常稀疏，虽然我们可以利用压缩的办法来对这些稀疏矩阵进行存储，但稀疏矩阵的计算一直都是一个难题。</p>
<p>此外，还有一个问题：对于同一个图，我们将矩阵中任何行或列之间进行交换：</p>
<img src="/1cd42ec5/10.png" class>

<p>虽然两个邻接矩阵看起来不一样，但二者表示的却是同一个图。</p>
<p>也就是说，不同的邻接矩阵，可以表示相同的连接性！这意味着如果我设计了一个神经网络，在上述两个不同的矩阵输入后我得保证神经网络的输出是一样的。</p>
<p>对于上面提到的两个问题，一个有效的解决方式是<strong>邻接表：</strong></p>
<p>上图有8个顶点，7条边。对于每个顶点或者每条边的特征我们用一个标量（一般为向量）来表示，全局特征也用一个标量（一般为向量）来表示。对于连接性，不再用邻接矩阵来表示，而是用<strong>邻接列表</strong>来表示。</p>
<p>使用邻接列表来表示连接性的两个好处：</p>
<ol>
<li>对于稀疏矩阵来说，使用邻接列表存储显然更加节省空间。</li>
<li><strong>不存在两个不一样的邻接列表表示同一张图。</strong></li>
</ol>
<hr>
<h3 id="Graph-Neural-Networks"><a href="#Graph-Neural-Networks" class="headerlink" title="Graph Neural Networks"></a>Graph Neural Networks</h3><p>在经历了将数据转为graph以及将graph进行表示后，我们就能使用GNN来对图进行处理了。</p>
<p>一句话概括GNN：<strong>GNN是对图的所有属性（节点、边、全局上下文）进行的可优化的一种变换，它保留了图的对称性（置换不变性）。</strong></p>
<p>简单来说就是，我们初始给定了节点或者边或者全局的属性，<strong>GNN将对这些属性进行变换，但是这种变换不会影响节点之间的连接性，变换优化后的图依旧保持着原图的连接结构。</strong></p>
<p>当然，也<strong>只有在变换后依旧保持着原图的连接结构，我们才能使用这些变换后的属性对图进行预测。</strong>试想在一个社交网络中，原来有朋友关系的节点经过GNN的变换后不再具有朋友关系，此时再用这些变换后的属性对某一对节点进行预测，结果显而易见！</p>
<hr>
<h4 id="最简单的GNN"><a href="#最简单的GNN" class="headerlink" title="最简单的GNN"></a>最简单的GNN</h4><img src="/1cd42ec5/12.png" class>

<p>对于顶点状态向量、边状态向量还有全局的状态向量，我们分别构造一个输入大小等于输出大小的多层感知机，这里多层感知机其实就是我们在<a href="https://blog.csdn.net/Cyril_KI/article/details/122058881">图神经网络（GNN）的基本原理</a>中提到的状态转换函数fw。</p>
<p>经过MLP后，我们就得到了更新后的状态向量。</p>
<p><strong>三个MLP组成了GNN的一层，经过GNN的一层后，原图的节点、边以及全局的状态向量都被更新过，但整个图的结构并没有发生变化。</strong></p>
<p>GNN可以像一般的神经网络那样将多层进行叠加，以求来对图的状态向量进行多次更新。</p>
<hr>
<h4 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h4><p>在<a href="https://blog.csdn.net/Cyril_KI/article/details/122058881">图神经网络（GNN）的基本原理</a>中我们需要一个gw函数来对状态向量进行转换输出，而gw可以是一个FNN。</p>
<p>对于一个简单的二分类问题，比如上面3.2节提到的空手道俱乐部网络图，我们需要对每个节点进行分类，在我们得到每个节点的状态向量后，我们可以搭建一个输出为2的全连接层，然后再经过一个Softmax，就能进行二分类了。多分类问题类似，只要将全连接层的输出改为n即可。</p>
<img src="/1cd42ec5/13.png" class>

<p>将经过最后一层后输出的节点状态向量Vn与一个全连接层相连，就能进行分类任务了。</p>
<p><strong>值得一提的是，这里所有节点都是共用一个全连接层，也就是所有节点共享同一个全连接层的参数。</strong></p>
<p>以上是最简单的一种情况，但我们不得不考虑另外一种情况：<strong>如果我们没有一个节点的向量表示，但我们仍想对该节点进行预测该怎么办？</strong>答案是Pooling，Pooling在<a href="https://blog.csdn.net/Cyril_KI/article/details/112723818">CNN</a>中已经有过接触。</p>
<p>具体如下所示：</p>
<img src="/1cd42ec5/14.png" class>

<p>如果我们没有右上角那个节点的向量表示，此时我们就可以把<strong>与该节点相连的四条边的状态向量以及全局状态向量相加，得到这个节点的状态向量，然后再经过全连接层进行预测。</strong></p>
<p>类似地，如果没有某条边的状态向量，只有节点的状态向量，如下所示：</p>
<img src="/1cd42ec5/15.png" class>

<p>此时我们就可以<strong>把这条边上的两个节点的向量相加得到该边的向量，然后再进行预测。</strong></p>
<p>又比如我们只有节点信息，没有全局信息，而我们想对图的全局标签进行预测：</p>
<img src="/1cd42ec5/16.png" class>

<p>此时同样可以<strong>将图中所有顶点的向量加起来，得到一个全局表示，然后再进行预测。</strong></p>
<p>因此，无论缺少哪一种信息，我们最终都能通过Pooling操作来汇聚已有的信息，进而得到我们想要的信息。</p>
<p>具体来讲，上面描述的GNN可以通过下图概括：</p>
<img src="/1cd42ec5/17.png" class>

<p>我们将原始graph通过一个个GNN层（每一层都有三个MLP，分别对三种状态进行转换），然后，<strong>无论是顶点、边还是全局，都通过同一个全连接层进行输出预测。</strong></p>
<p>上述这种最简单的GNN存在着一个很明显的缺陷：我们在GNN层对节点或者边进行更新时，每层内所有节点共用一个MLP，所有边共用一个MLP，此时我们并没有考虑连接信息，也就是说我们在对节点更新时没有考虑与该节点相连的其余节点或者边，更新边时没有考虑与该边相连的节点。</p>
<p>简单来说，<strong>我们在更新时没有将图的结构信息考虑进去。</strong></p>
<hr>
<h4 id="消息传递"><a href="#消息传递" class="headerlink" title="消息传递"></a>消息传递</h4><p>那么我们怎么在更新时考虑结构信息呢？这点其实在<a href="https://blog.csdn.net/Cyril_KI/article/details/122058881">图神经网络（GNN）的基本原理</a>中已经详细叙述过了：</p>
<img src="/1cd42ec5/18.png" class>

<p>如下图所示：</p>
<img src="/1cd42ec5/19.png" class>

<p>我们在更新每一个节点的向量时，并不只是简单地将该节点的向量通过一个MLP后得到更新后的向量，而是还要考虑<strong>与该节点相连节点的向量</strong>，也就是在下述更新公式中：</p>
<img src="/1cd42ec5/20.png" class>

<p>我们要考虑x_{ne[n]}这一项了。</p>
<p>当然上图这种更新方式并没有太复杂，只是将该节点的向量与其相连节点的向量相加。</p>
<p>考虑一种更为复杂的情况：</p>
<img src="/1cd42ec5/21.png" class>

<p>在进行边的更新时，我们可以<strong>将与该边相连的两个顶点的向量加入到该边的向量中（如果维度不同则需要变换），然后再对该边进行更新。同样，对于某一个节点的更新，我们也可以将与该节点相连的边的向量加入到该节点中，然后再对该节点进行更新。</strong></p>
<p>节点和边之间的消息传递存在一个选择：</p>
<img src="/1cd42ec5/22.png" class>

<p>我们可以<strong>先把边的信息传递给顶点，顶点更新后，再将更新后的顶点信息传递给边，边再更新（上图左），或者相反（上图右）。</strong></p>
<p>还有一种办法是<strong>交替传递</strong>：</p>
<img src="/1cd42ec5/23.png" class>

<p>我们可以同时进行两种操作：<strong>将边的信息给节点，然后节点的信息也给边。此时的节点和边都包含了各自的信息，然后再进行一次传递，将二者的信息互相传递，随后再用两个MLP对节点和边进行更新。</strong></p>
<hr>
<h4 id="全局表示"><a href="#全局表示" class="headerlink" title="全局表示"></a>全局表示</h4><p><strong>对一个large graph来讲，即使我们多次进行消息传递，图中相距较远的两个顶点间也可能无法有效地相互传输信息。</strong></p>
<p>一种解决办法是加入<strong>master node</strong>（主节点）或者<strong>context vector</strong>（上下文向量）。<strong>主节点是一个虚拟的点，我们假设它与图中所有节点都相连，同时它也跟所有的边都相连。</strong></p>
<p>因此在进行顶点或者边的更新时，如果我们加上全局表示U，就能保证所有顶点（边）间都能传递信息。</p>
<hr>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>原文作者做了一件很nb的事情：<strong>在网页中写了一个GNN的具体的演示程序：</strong></p>
<img src="/1cd42ec5/24.png" class>

<p>这个框架演示的是一个Graph Level的预测任务，每个图表示一个分子，我们的任务是预测该分子是否有刺鼻的气味。</p>
<p>在这个演示框架中，我们可以选择的参数有：<strong>GNN的层数、Pooling方式（Mean、Sum或者Max）、节点的嵌入维度、边的嵌入维度以及全局的嵌入维度。</strong></p>
<p>每改变一次这些参数，该框架就会对数据重新训练一遍，然后再给出预测表现（AUC）。</p>
<p>作者通过多次试验，给出了不同的因素（如Pooling方式、嵌入维度大小等）对模型精度的影响，这里就不再细述了，有兴趣的可以自己去看一看原文。</p>
<hr>
<h3 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h3><h4 id="其他类型的图"><a href="#其他类型的图" class="headerlink" title="其他类型的图"></a>其他类型的图</h4><img src="/1cd42ec5/25.png" class>

<p>这里主要介绍了两种其他类型的图：多重图和嵌套图。</p>
<p>所谓<strong>多重图</strong>，就是指<strong>图中一对节点间可以有多种不同类型的边。</strong>比如在社交网络中，两个节点（用户）之间的边，可以表示这两人是熟人、家人或者情侣。<strong>这种情况下，GNN可以通过为不同类型的边设置不同类型的消息传递方式来进行调整。</strong></p>
<p>所谓<strong>嵌套图</strong>，就是说<strong>图中的某一个节点可能就表示一个图。</strong>比如在一个分子网络中，一个节点代表一个分子，如果一个分子能通过某种反应转换为另一个分子，则两个分子之间有一条边。在这个网络中，节点（分子）本身也是一个图（原子-原子）。<strong>在这种情况下，可以让GNN学习分子级别的表示和另一个反应网络级别的表示，并于训练期间在它们之间进行交替。</strong></p>
<p>此外，还有<strong>超图</strong>，超图的一条边可以连接到多个节点，而不仅仅是两个。对于这种情况，<strong>可以通过识别节点社区并分配连接到社区中所有节点的超边来构建超图。</strong></p>
<hr>
<h4 id="采样和批处理"><a href="#采样和批处理" class="headerlink" title="采样和批处理"></a>采样和批处理</h4><p>GNN存在<strong>邻居爆炸</strong>的问题，即：<strong>GNN会不断地聚合图中相邻节点的信息，第L层GNN中的每个目标节点都需要聚合原图中L层以前的所有节点信息。邻点爆炸式增长，使得GNN的minibatch训练极具挑战性。</strong></p>
<p>此外，由于彼此相邻的节点和边的数目不同，我们也不能使用恒定的批量大小。</p>
<p>解决该问题的办法是<strong>从图中进行采样，得到一个子图，然后对子图进行处理。</strong></p>
<p>对一张图进行采样的四种方式如下图所示：</p>
<img src="/1cd42ec5/26.png" class>

<ul>
<li>Random node sampling：先随机采样一些点（Sampled nodes），然后再采样它们的邻居。</li>
<li>Random walk sampling：做一些随机游走，从当前点的邻居节点中进行采样。</li>
<li>Random walk with neighborhood：结合前两种：先随机走一定长度，然后再采样它们的邻居。</li>
<li>Diffusion Sampling：取一个根节点，然后对它的一近邻、二近邻一直到K近邻进行采样，类似于一个BFS。</li>
</ul>
<hr>
<h4 id="Inductive-biases"><a href="#Inductive-biases" class="headerlink" title="Inductive biases"></a>Inductive biases</h4><p>先说一说<strong>CNN的平移不变性</strong>：即使目标的外观发生了某种变化，但是利用CNN依然可以把它识别出来。即图像中的目标无论是被平移，被旋转，还是被缩放，都可以被成功地识别出来。</p>
<p>而在GNN中，也具有图对称性：也就是排列无关性，即使交换了顶点的顺序，GNN对其的作用都保持不变。</p>
<hr>
<h4 id="不同的Pooling方式"><a href="#不同的Pooling方式" class="headerlink" title="不同的Pooling方式"></a>不同的Pooling方式</h4><p>在GNN中，<strong>对节点和边的信息进行Pooling是关键操作</strong>，选择一个最优的Pooling方式是一个比较好的研究方向。</p>
<p><strong>常见的Pooling方式有max、mean和sum</strong>，作者对三者进行了比较：</p>
<img src="/1cd42ec5/27.png" class>

<p>左边这幅图中，有2-4和4-4两个网络，如果我们采用max，二者结果都是4，没法进行区分，而mean和sum可以对二者进行区分；右边这幅图中，max和mean没法区分两种网络，而sum却可以。</p>
<p>因此，<strong>没有一个Pooling方式是明显优于其它Pooling方式的。</strong></p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在<a href="https://blog.csdn.net/Cyril_KI/article/details/122058881">图神经网络（GNN）的基本原理</a>中，我们给出了GNN的Forward过程：</p>
<img src="/1cd42ec5/28.png" class>

<p><strong>原始论文中的Forward是通过一个repeat操作不断地对节点的状态进行更新。</strong>而状态转换函数fw实际上可以是一个神经网络，那么循环操作就可以用下图表示：</p>
<img src="/1cd42ec5/29.png" class>

<p>把上图中的fw理解为MLP（或者其他），就能与本文完整地对应起来了。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1iT4y1d7zP">https://www.bilibili.com/video/BV1iT4y1d7zP</a><br><a href="https://staging.distill.pub/2021/gnn-intro/">https://staging.distill.pub/2021/gnn-intro/</a><br><a href="https://blog.csdn.net/Cyril_KI/article/details/122050679">https://blog.csdn.net/Cyril_KI/article/details/122050679</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-神经网络（STANN）提出了大脑如何运作的新见解</title>
    <url>/df65a8f5.html</url>
    <content><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>生物神经网络主要是指人脑的神经网络，它是人工神经网络的技术原型。人脑是人类思维的物质基础，思维的功能定位在大脑皮层，后者含有大约个神经元，每个神经元又通过神经突触与大约103个其它神经元相连，形成一个高度复杂高度灵活的动态网络。作为一门学科，生物神经网络主要研究人脑神经网络的结构、功能及其工作机制，意在探索人脑思维和智能活动的规律。</p>
<span id="more"></span>

<img src="/df65a8f5/1.png" class>

<p>人工神经网络是生物神经网络在某种简化意义下的技术复现，作为一门学科，它的主要任务是根据生物神经网络的原理和实际应用的需要建造实用的人工神经网络模型，设计相应的学习算法，模拟人脑的某种智能活动，然后在技术上实现出来用以解决实际问题。因此，生物神经网络主要研究智能的机理；人工神经网络主要研究智能机理的实现，两者相辅相成。</p>
<img src="/df65a8f5/2.png" class>

<p>为了更好地了解大脑等复杂器官的功能，科学家们通过准确地了解其详细的细胞结构和其中发生的细胞间通讯，来掌握大脑如何运作，揭示大脑如何运作。</p>
<hr>
<h3 id="研究近况"><a href="#研究近况" class="headerlink" title="研究近况"></a>研究近况</h3><p>多年来，人们从医学、生物学、生理学、哲学、信息学、计算机科学、认知学、组织协同学等各个角度及领域，企图认识并解答上述问题。在寻找上述问题答案的研究过程中，逐渐形成了一个新兴的多学科交叉技术领域，称之为“神经网络”。神经网络的研究涉及众多学科领域，这些领域互相结合、相互渗透并相互推动。不同领域的科学家又从各自学科的兴趣与特色出发，提出不同的问题，从不同的角度进行研究。</p>
<p>哺乳动物的大脑很复杂，由数百万到数千亿个细胞组成，在进行分析时，它们会生成大量数据。其中的挑战在于开发将这些数据集中的信息整合在一起的方法，以生成一个能够可靠地反映器官工作方式的模型。目前，他们拥有能够识别和定位组织中单个细胞的技术，能够确定该组织中每单个细胞的产物是什么。</p>
<img src="/df65a8f5/3.png" class>

<hr>
<h3 id="突破"><a href="#突破" class="headerlink" title="突破"></a>突破</h3><p>近期在贝勒医学院，Samee 博士和他的同事们朝着这个方向迈出了重要的一步。他们开发了一种先进的计算方法，使人们对大脑结构和功能的复杂性有了新的认识，这可能会增强人们对这种复杂器官的理解。</p>
<p>在当前的研究中，Samee 与该作品的第一作者卡诺佐、贝勒和德克萨斯心脏研究所的马丁博士以及贝勒的Zuo 合作开发了一个神经网络模型，用来阐明复杂的组织结构和功能方面的问题，对于用户无论是健康还是疾病都可适用。他们将使用神经网络 (STANN) 的模型称为空间转录组学细胞类型分配。发表于ScienceDirect如下图所示：</p>
<img src="/df65a8f5/4.jpg" class>

<p>他们使用了其他先进、复杂的计算方法，使模型更加严格，将 STANN 和其他方法应用于小鼠嗅球的现有大脑数据集，并开始在大脑的细胞结构和功能中看到非常有趣的模式。大脑由不同的形态层组成，而 STANN 神经网络使研究人员能够预测其细胞组织的详细图片。他们的模型逐层提供了不同细胞类型的精确位置，它们是否相互通信以及通过何种方式进行通信。模型如下图所示：</p>
<img src="/df65a8f5/5.jpg" class>

<p>Samee 和他的同事确定细胞类型组成在形态层内的表现非常一致。例如，在特定层可能具有一定百分比的星形胶质细胞、神经元和小胶质细胞，它们在整个同一层中保持不变。如果我们从同一形态层的不同区域取几个小部分，这些百分比看起来非常相似。但是，当百分比从一层到另一层时，又会发生变化。</p>
<p>该团队在研究细胞定位时还发现了不同的模式。例如，在形态层的一个区域，我们可能会看到星形胶质细胞与嗅觉神经元共存。但在同一形态层的另一个区域，这些细胞可以完全分离。他们还看到两种细胞类型之间，细胞间通讯在形态层的不同区域发生变化，这反映了基因调控网络随着位置的变化而变化。</p>
<hr>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>研究人员假设大脑中的形态层具有不同的空间局部细胞类型群落。群落的细胞类型组成相似，但细胞类型在群落内共定位和交流的方式存在很大差异。这表明脑细胞类型具有执行特定位置功能的空间局部亚型。</p>
<p>这种在单细胞和功能水平上对大脑组织的新详细视图以前从未被描述过。他们在这项工作中开发的神经网络模型方法为其他研究人员提供了一份‘指导手册’，可用于研究大脑或其他器官的其他区域，例如心脏等。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.sciencedaily.com/releases/2021/12/211222153029.htm">https://www.sciencedaily.com/releases/2021/12/211222153029.htm</a><br>&lt;Francisco Jose Grisanti Canozo, Zhen Zuo, James F. Martin, Md. Abul Hassan Samee. Cell-type modeling in spatial transcriptomics data elucidates spatially variable colocalization and communication between cell-types in mouse brain. Cell Systems, 2021; DOI: 10.1016/j.cels.2021.09.004&gt;</p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11106">https://www.scholat.com/teamwork/showPostMessage.html?id=11106</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-GAN论文逐段精读-《Generative Adversarial Nets》</title>
    <url>/e156c7a6.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2014-Generative-Adversarial-Nets.pdf" data-height="500px"></div>

<p>这是李沐博士论文精读的第五篇论文，这次精读的论文是 <strong>GAN</strong>。目前谷歌学术显示其被引用数已经达到了37000+。<strong>GAN</strong> 应该是机器学习过去五年上头条次数最多的工作，例如抖音里面生成人物卡通头像，人脸互换以及自动驾驶中通过传感器采集的数据生成逼真的图像数据，用于仿真测试等。这里李沐博士讲解的论文是 <strong>NeurIPS</strong> 版，与 <strong>arXiv</strong> 版稍有不同。</p>
<p><strong>GAN</strong> 论文链接：<a href="https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf</a></p>
<span id="more"></span>

<hr>
<h3 id="标题、作者、摘要"><a href="#标题、作者、摘要" class="headerlink" title="标题、作者、摘要"></a>标题、作者、摘要</h3><p>首先是论文<strong>标题</strong>，<strong>GAN</strong> 就取自于论文标题首字母，论文标题中文意思是：生成式对抗网络。机器学习里面有两大类模型：一种是<strong>分辨模型</strong>，例如 <strong>AlexNet</strong>、<strong>ResNet</strong> 对数据进行分类或预测一个实数值、另一种就是<strong>生成模型</strong>，用于生成数据本身。<strong>Adversarial</strong> 是对抗的意思，第一次读的时候可能不知道什么意思，先放在这里，接着往下读。最后是 <strong>Nets</strong>，网络的意思，不过建议大家还是写成 <strong>Networks</strong> 比较规范一些。</p>
<p>下面是论文<strong>作者</strong>，一作大家很熟悉了，他的另一个代表作就是深度学习经典书籍（花书）：《深度学习》，通信作者是深度学习三巨头之一，2018年图灵奖的获得者。</p>
<img src="/e156c7a6/1.png" class>

<p>下面是论文<strong>摘要</strong>，摘要总共七句话。</p>
<ul>
<li>前三句话介绍我们提出了一个新的 <strong>framework</strong>， 通过<strong>对抗过程</strong>估计生成模型；我们同时会训练两个模型，一个是生成模型 G，生成模型用来捕获数据的分布，另一个模型是辨别模型 D，辨别模型用来判断样本是<strong>来自于训练数据</strong>还是<strong>生成模型生成的</strong>。生成模型 G 的训练过程是使辨别模型犯错概率最大化实现的，<strong>当辨别模型犯错概率越大，则生成模型生成的数据越接近于真实数据</strong>。整个framework类似于博弈论里的二人对抗游戏。</li>
<li>第四句话是说，在任意函数空间里，存在唯一解，G 能找出训练数据的真实分布，而 D 的预测概率为 1/2，此时辨别模型已经分辨不出样本的来源。</li>
<li>最后就是说生成模型和辨别模型可以通过反向传播进行训练，实验也显示了提出的框架潜能。</li>
</ul>
<img src="/e156c7a6/2.png" class>

<hr>
<h3 id="导言、相关工作"><a href="#导言、相关工作" class="headerlink" title="导言、相关工作"></a>导言、相关工作</h3><p>下面是 <strong>Introduction</strong> 部分，总共3段。</p>
<ul>
<li>第一段说深度学习在判别模型取得了很大的成功，但是在生成模型进展还很缓慢，主要原因是<strong>在最大似然估计时会遇到很多棘手的近似概率计算</strong>，因此作者提出一个新的生成模型来解决这些问题。</li>
<li>第二段作者举了一个例子来解释<strong>对抗网络</strong>。生成模型好比是一个造假者，而判别模型好比是警察，警察需要能区分真币和假币，而造假者需要不断改进技术使警察不能区分真币和假币。</li>
<li>第三段说生成模型可以通过多层感知机来实现，输入为一些随机噪声，可以通过反向传播来训练。</li>
</ul>
<img src="/e156c7a6/3.png" class>

<p>然后是<strong>相关工作部分</strong>，这里有件有趣的事。当时 <strong>GAN</strong> 作者在投稿时，Jürgen Schmidhuber 恰好是论文审稿者，Jürgen Schmidhuber 就质问：“你这篇论文和我的 <strong>PM</strong> 论文很相似，只是方向相反了，应该叫 Inverse PM 才对”。然后Ian就在邮件中回复了，但是两人还在争论。</p>
<p>一直到 <strong>NIPS2016</strong> 大会，Ian 的 GAN Tutorial上，发生了尴尬的一幕。Jürgen Schmidhuber 站起来提问后，先讲自己在1992年提出了一个叫做 Predictability Minimization 的模型，它如何如何，一个网络干嘛另一个网络干嘛，接着话锋一转，直问台上的Ian：“你觉得我这个 PM 模型跟你的 GAN 有没有什么相似之处啊？” 似乎只是一个很正常的问题，可是 Ian 听完后反应却很激烈。Ian 表示：“Schmidhuber 已经不是第一次问我这个问题了，之前我和他就已经通过邮件私下交锋了几回，所以现在的情况纯粹就是要来跟我公开当面对质，顺便浪费现场几百号人听 tutorial 的时间。然后你问我 PM 模型和 GAN 模型有什么相似之处，我早就公开回应过你了，不在别的地方，就在我当年的论文中，而且后来的邮件也已经把我的意思说得很清楚了，还有什么可问的呢？”</p>
<p>关于Jürgen Schmidhuber 和 Ian之间争论的更多趣事可以看这篇文章：<a href="https://zhuanlan.zhihu.com/p/27159510">从PM到GAN——LSTM之父Schmidhuber横跨22年的怨念</a>。</p>
<hr>
<h3 id="模型、理论"><a href="#模型、理论" class="headerlink" title="模型、理论"></a>模型、理论</h3><p>下面开始介绍 <strong>Adversarial nets</strong>。为了学习<strong>生成器</strong>在数据 x 上的分布 p_g，我们定义输入噪声变量 p_z(z)，数据空间的映射用 G(z; θ_g) 表示，其中 G 是一个可微分函数（多层感知机），其参数为 θ_g。我们再定义第二个多层感知机 D(x; θ_d)，其输出为标量。D(x) 表示数据 x 来自真实数据的概率。</p>
<p>下面是训练策略，我们同时训练生成模型 G 和判别模型 D。对于判别模型 D，我们通过<strong>最大化将正确标签分配给训练样本和生成器生成样本的概率</strong>来训练；对于生成模型 G GG，我们通过最小化 log(1−D(G(z))) 来训练，总结为：</p>
<ul>
<li>D(x) 概率越大，判别器训练越好，log D(x) 越大</li>
<li>D(G(z)) 概率越小，判别器训练越好，log(1−D(G(z))) 越大</li>
<li>D(G(z)) 概率越大，生成器训练越好，log(1−D(G(z))) 越小</li>
</ul>
<img src="/e156c7a6/4.png" class>

<p>下图是对抗网络训练的直观示意图，黑色曲线是真实样本，绿色曲线为生成样本，蓝色曲线为判别概率。可以看到在（a）阶段，真实样本和生成样本分布不一致，此时判别器能够正确区分真实样本和生成样本。到（d）阶段，真实样本和生成样本分布几乎一致，此时判别器很难再区分二者，此时判别器输出概率为 1/2。</p>
<img src="/e156c7a6/5.png" class>

<p>算法1是整个对抗网络的正式描述，<strong>对于判别器，我们通过梯度上升来训练；对于生成器，我们通过梯度下降来训练</strong>。</p>
<img src="/e156c7a6/6.png" class>

<p>在实际训练时，公式（1）往往不能提供足够的梯度让生成器去学习。因为在学习的早期阶段，生成器 G 性能很差，判别器 D 有着很高的置信度判别数据来源。在这种情况，log(1−D(G(z))) 存在饱和现象。因此在这个时候，我们通过最大化 log D(G(z)) 来训练生成器 G。</p>
<img src="/e156c7a6/7.png" class>

<p>下面是 <strong>Theoretical Results</strong>，对于任意给定的生成器 G，则<strong>最优的判别器</strong> D 为：</p>
<img src="/e156c7a6/8.png" class>

<p>下面是证明过程，对于给定的生成器 G，判别器 D 通过<strong>最大化期望</strong> V(G,D) 来训练，V(G,D) 为：</p>
<img src="/e156c7a6/9.png" class>

<p>已知 (a, b)∈R^2，函数 y → a log(y) + b log(1−y) 在 a/(a+b) 处取得最大值。</p>
<img src="/e156c7a6/10.png" class>

<p>根据上面的证明，在最优判别器处，则有<strong>最大期望值</strong> −log4。</p>
<img src="/e156c7a6/11.png" class>

<p>最后简单总结下，虽然在本文中，作者做的实验现在来看比较简单，但是整个工作是一个开创性的工作，<strong>GAN</strong> 属于无监督学习研究，而且作者是使用有监督学习的损失函数去训练无监督学习；而且本文的写作也是教科书级别的写作，作者的写作是很明确的，读者只看这一篇文章就能对 <strong>GAN</strong> 有足够的了解，不需要再去看其它更多的文献。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/cg129054036/article/details/121245794">https://blog.csdn.net/cg129054036/article/details/121245794</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-脑机接口（BCI）常用的实验范式</title>
    <url>/c889bfea.html</url>
    <content><![CDATA[<p>脑机接口(Brain Computer Interface，BCI)，或称大脑端口(Direct neural interface)、脑机融合感知(Brain-machine interface)，是指在人或动物脑（或者脑细胞的培养物）与外部设备间建立的直接连接通路。在单向脑机接口的情况下，计算机接受脑传来的命令或者发送信号到脑，但不能同时发送和接收信号。而双向脑机接口允许脑和外部设备间的双向信息交换。</p>
<p>BCI 系统通过对脑电信号的分析和处理，提供用户与外界设备通信和控制的信道，是一种新的人机交互方式。BCI 系统涉及计算机通信与控制、生物医学工程和康复医学等领域，己经成为交叉学科的热点。而基于脑电信号(Electroencephalography，EEG)的脑机接口成为了目前非常实用、先进的脑机接口方式，以揭示和验证大脑神经生理机制，脑认知科学和神经信息等相关内容。</p>
<p>BCI 系统的信号处理过程包括信号获取、特征提取、分类判断等，其中特征提取和分类判断是 BCI 信号处理的关键环节。传统脑电信号的处理方法是对信号进行多次检测并进行均值滤波，再用统计学方法寻找 EEG 的变化规律。但是该方法信息传输率较低，不能满足实时控制的要求。目前普遍采用的是先对离线 EEG 信号进行处理和分析，再进行在线调试。</p>
<p>BCI 系统的信号处理过程</p>
<img src="/c889bfea/1.jpg" class>

<p><strong>这里将介绍目前比较常用的脑机接口范式：运动想象BCI、SSVEP、AEP、P300</strong></p>
<span id="more"></span>

<hr>
<h3 id="运动想象BCI（Motor-Imagery，MI-BCI）"><a href="#运动想象BCI（Motor-Imagery，MI-BCI）" class="headerlink" title="运动想象BCI（Motor Imagery，MI-BCI）"></a>运动想象BCI（Motor Imagery，MI-BCI）</h3><p>基于运动想象的系统主要是将运动想象激发大脑运动皮层脑电节律变化的脑电信号作为输入，通过信号处理部分判断运动想象种类，然后由计算机将运动想象种类翻译成控制命令，最终可以实现人脑与外部设备的通信及控制功能。主要关注的是用于优化被试表现的特征提取和分类技术。早期 BCI 原型是基于进行有意的肢体运动期间的 EEG 模式，比如左手、右手或者脚的运动。</p>
<img src="/c889bfea/2.jpg" class>

<p>为每名被试修改输入特征（如电极位置和频带），以优化分类正确率。后续的研究表明运动想象也能激活大脑主要感觉运动区域，在对侧大脑半球中产生“事件相关去同步”(event-related desynchronization，ERD)，在同侧大脑半球中产生“事件相关同步”(event-related synchronization，ERS)。通过分类器探索感觉运动节律的左、右差异以此来区分运动想象。</p>
<img src="/c889bfea/3.jpg" class>

<p>图片来源于书籍《脑机接口导论》。a.运动想象期间，alpha频带的平均能量(此处指9<del>13Hz，称为运动区mu频带)，EEG信号来自左侧(C3)和右侧感觉运动皮质(C4)。相对于基线(0.5</del>2.5秒)的正、负偏移分别表示频带能量的增加(ERS)和减少(ERD)。在3秒时出现提示并持续1.25秒的时间；b.根据实际的头模型计算出皮质表面在提示出现后625毫秒的ERD分布(改编自Pfurtscheller等人，2000)。</p>
<hr>
<h3 id="SSVEP（Steady-state-visual-evoked-potentials：稳态视觉诱发电位）"><a href="#SSVEP（Steady-state-visual-evoked-potentials：稳态视觉诱发电位）" class="headerlink" title="SSVEP（Steady-state visual evoked potentials：稳态视觉诱发电位）"></a>SSVEP（Steady-state visual evoked potentials：稳态视觉诱发电位）</h3><p>稳态诱发电位由持续波动的刺激（重复频率大于 5Hz）产生。例如，考虑一个能够解码二选一问题的系统。可以用视觉刺激来表示这两个选项（如，屏幕上的按键或者发光二极管 LED），每个视觉刺激以不同的频率闪烁。被试需要关注他/她选择的那个按键（如，注视它）。这样可以在大脑的早期视觉区域（枕区）产生与刺激频率相同的 EEG 信号，这一信号称作稳态视觉诱发电位(SSVEP)。通过对 EEG 刺激进行频域分解（如使用FFT），BCI 能够检测出被试所注视的刺激的频率，从而识别出被试的选择。</p>
<img src="/c889bfea/4.jpg" class>

<p>举一个基于 SSVEP 的 BCI 例子。电话键盘的 12 个键分布在计算机屏幕上 3×4 的矩阵中。按键以不同频率闪烁，频率范围为 6~14Hz。另外一个闪烁的开、关键用来开启或停止其他键的闪烁。为了减少由 alpha 波引起的假阳性率，首先要进行闭眼状态下的筛选试验，当一些频率所对应的能量超过从 4Hz 至 35Hz 频带平均能量的 2 倍时，这些频率就会被排除在刺激频率之外。另外，所有的刺激频率都是频率分辨率的奇数倍，以防止某刺激频率是另一刺激频率的两倍。</p>
<img src="/c889bfea/5.jpg" class>

<p>图片来源于cheng等人(2002)的文章Design and implementation of a brain-computer interface with high transfer rates.</p>
<hr>
<h3 id="听觉诱发电位（Auditory-evoked-potentials，AEP）"><a href="#听觉诱发电位（Auditory-evoked-potentials，AEP）" class="headerlink" title="听觉诱发电位（Auditory evoked potentials，AEP）"></a>听觉诱发电位（Auditory evoked potentials，AEP）</h3><p>研究人员对 P300 的 BCI 进行了改进，探索了将 oddball 范式应用于听觉刺激，以此为基础构建 BCI 系统。听觉刺激由不同频率、时长为 50 毫秒的方波产生的哔哔声构成，哔哔声产生于被试的左侧或右侧。这段哔哔声中包含两种声音，一种是会频繁响起的非目标哔哔声，另一种是偶尔才在被试任一耳朵中独立播放的目标哔哔声。被试的任务是注意（通过计数）在左耳或右耳中响起的目标刺激。BCI 需要检测被试正在留意的是哪个目标（左耳的目标或右耳的目标）。对多次试验中的 39 通道 EEG 信号进行平均，利用 ICA 进行分离，然后用线性 SVM 进行分类。</p>
<img src="/c889bfea/6.jpg" class>

<p>图片来源于Hill等人(2005)的文章An Auditory Paradigm for Brain–Computer Interfaces.</p>
<hr>
<h3 id="P300-BCI刺激范式"><a href="#P300-BCI刺激范式" class="headerlink" title="P300 BCI刺激范式"></a>P300 BCI刺激范式</h3><p>最经典的 P300 脑机接口刺激范式是在 1988 年由 Farwell 和 Donchin 提出的基于 P300 视觉刺激的字符输入系统。该实验范式将 36 个字符排列成一个 6×6 的字符矩阵，并按随机的次序闪烁矩阵中的某一行（或列）的 6 个字符。如下图所示：</p>
<img src="/c889bfea/7.jpg" class>

<p>图片来源于Donchin等人(2000)的文章The Mental Prosthesis: Assessing the Speed of a P300-Based Brain-Computer Interface.</p>
<p>为了拼写一个单词或者发出一个命令，被试必须将注意力集中在矩阵中的字母或命令上，以此来选择组成单词或命令的每个字母。当被试的注意力集中在字母或者命令上时，矩阵的行和列以随机顺序重复闪烁。行和列的每次闪烁（或明暗度增强）持续 100 毫秒，闪烁间隔固定为 500 毫秒或者 125 毫秒。只有当行或者列包含了被试选择的字母或者命令时，被试的大脑才产生明显的 P300。这一信号可以通过使用诸如 LDA 的分类器检测到。因此，通过持续追踪哪个闪烁的行和列引起了最明显的 P300，能够推断出被试选择的字母或者命令。为了有助于保持注意力，通常要求被试对所选择闪烁的次数进行计数。</p>
<img src="/c889bfea/8.jpg" class>

<p>基于 SSVEP 和 P300 的系统主要特点是无需训练，这类系统比较适合于多指令选择的离散控制型应用，如打字系统、操作界面等。由于其能够提供更多的指令，所以目前这类系统所能够达到的传输率和正确率都比基于自发脑电的系统更高。但是需要外界的诱发刺激来产生特征脑电模式，依赖于场景设计，且目前绝大部分系统都是同步控制的。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/u011661076/article/details/121991020">https://blog.csdn.net/u011661076/article/details/121991020</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-什么是SVM支持向量机？</title>
    <url>/6c3d1ed6.html</url>
    <content><![CDATA[<img src="/6c3d1ed6/1.png" class>

<p>想要知道新拿到的水果是梨还是苹果，除了用KNN画个圈，还有什么好办法呢？</p>
<span id="more"></span>

<p>画条线好像也不错，通过将两者所在的空间作出区分，当新样本落在苹果一侧时，我们就认为它是苹果，反之就认为它是梨。</p>
<img src="/6c3d1ed6/2.png" class>

<p>这条线，就是SVM支持向量机。</p>
<img src="/6c3d1ed6/3.png" class>

<p>听上去很简单，不过这条线我们可以这样画，也可以这样画：</p>
<img src="/6c3d1ed6/4.png" class>

<p>哪条线才是最合适的呢？其实除了界限，样本与线的距离同样有意义，它代表着样本分类的可信程度。以苹果这一侧为例：与线的距离最远的苹果，是苹果的可能性最高；离得越近，是苹果的可能性就越低。我们的目标是在两种样本间，找到能让所有样本的分类可信程度最高的那条线。</p>
<img src="/6c3d1ed6/5.png" class>

<p>不必计算所有的距离，只要找到线附近的样本，让它们与线的距离越远越好，这个距离被称为分类间隔，决定了线的样本被称为支持向量，这也是支持向量机名字的由来。</p>
<img src="/6c3d1ed6/6.png" class>

<hr>
<p>如果样本的分布有交叉怎么办？</p>
<img src="/6c3d1ed6/7.png" class>

<p>那我们就关注这些无法被线正确分类的样本与线之间的距离，找到能最小化这个距离的线。</p>
<hr>
<p>如果样本的分布并不理想，无法用直线区分怎么办？</p>
<img src="/6c3d1ed6/8.png" class>

<p>那就通过一定的变换，将它们映射到一个能用直线区分的空间，再寻找分类线。</p>
<hr>
<p>在深度学习出现前，随机森林和SVM是最好用的分类方法。</p>
<p>SVM对样本依赖小，不会过拟合，小样本也能取得不错的效果。</p>
<img src="/6c3d1ed6/9.png" class>

<p>文本分类、垃圾邮件识别、图像分类，甚至分类蛋白质，SVM应用广泛。</p>
<img src="/6c3d1ed6/10.png" class>

<hr>
<img src="/6c3d1ed6/11.png" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1UR4y147AT?p=15">https://www.bilibili.com/video/BV1UR4y147AT?p=15</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-脑机接口重磅突破！“意念打字”准确率超99％</title>
    <url>/fa8431ee.html</url>
    <content><![CDATA[<p>2021年5月12日，Francis R. Willett等人在《自然》上发表题为“<strong>High-performance brain-to-text communication via handwriting</strong>”的论文，文章主要围绕帮助四肢瘫痪患者进行“意念打字”展开研究。</p>
<p>这可不是科幻，最新的脑机接口（BCI）技术已经在这一方面实现突破，而且效率超乎想象，**最高可超99%**。</p>
<p>此前，脑机接口领域的一大研究焦点是恢复患者 “运动技能”，比如通过脑机接口操控机械臂抓取物品，或通过脑机接口移动电脑光标、点击字母输入等。</p>
<p>这次，来自斯坦福大学的研究人员开辟了一条新路径，<strong>他们将人工智能（AI）软件与脑机接口设备结合，成功开发出一套全新的皮质内脑机接口系统，该系统利用大脑运动皮层的神经活动可解码 “手写” 笔迹，并使用递归神经网络（RNN）解码方法将笔迹实时翻译成文本，快速将患者对手写的想法转换为电脑屏幕上的文本</strong>。</p>
<img src="/fa8431ee/1.gif" class>
<p>图1｜通过脑机接口 “手写输入” 的示意图</p>
<span id="more"></span>

<p>研究论文以封面形式发表在最新一期的《自然》杂志上，被视为是该领域的一大技术进步。</p>
<img src="/fa8431ee/2.png" class>
<p>图2｜《Nature》杂志封面（来源：Nature）</p>
<p>该研究论文的作者之一、斯坦福大学霍华德 休斯医学研究所（HHMI）研究员克里希纳· 谢诺伊（Krishna Shenoy）表示，<strong>此次研究的最大的创新是首次破译了与手写笔记有关的大脑信号，可以让瘫痪患者不用手也能快速打字</strong>。他与斯坦福神经外科医生杰米·亨德森（Jaimie Henderson）共同参与了这项研究，论文的第一作者则是同样来自 HHMI 的科学家弗兰克·威利特（Francis Willett）博士。</p>
<p>在实验中，<strong>一名受试者可以每分钟输入 90 个字符，这是此前使用脑机接口打字纪录的两倍多，接近同龄健全人每分钟 115 个字符的智能手机打字速度</strong>，而且在线原始准确率为 94.1%，离线自动校正的准确率超过 99%。</p>
<p>加州大学伯克利分校的神经工程师何塞卡梅纳（Jose Carmena）并未参与这项研究，但他认为，<strong>这项技术有潜力帮助各种残疾人，尽管研究结果是初步的，但 “这是该领域的一大进步。”</strong></p>
<p>美国国立卫生研究院脑科学计划（NIH BRAIN Initiative）主任约翰·恩盖（John Ngai）博士表示：“<strong>这项研究代表了BCI和机器学习技术发展的重要里程碑</strong>，相关研究正在揭示人脑如何控制像通讯这样复杂的过程，为改善神经损伤和瘫痪者的生活提供了重要基础。”</p>
<hr>
<h3 id="脑中笔记的神经表征"><a href="#脑中笔记的神经表征" class="headerlink" title="脑中笔记的神经表征"></a>脑中笔记的神经表征</h3><p>事实上，这项研究其实是脑机接口项目 BrainGate 临床试验的一部分，这是一个多机构联盟项目，旨在帮助那些失去肢体或其他身体功能控制能力的人，比如患有肌萎缩性侧索硬化症（ALS）或脊髓损伤的患者等。实验中被称为 “T5” 的受试者，在 2007 年由于脊髓损伤几乎失去了颈部以下的所有活动能力，手部动作仅限于抽搐和微动。</p>
<p>在实验中，亨德森在 T5 的左侧大脑植入了两个脑机接口芯片，每一个芯片都有 100 个电极，负责接收运动皮层（大脑最外层的一个区域）神经元发出的信号，运动皮层是控制手部运动的区域，这些神经信号通过电线发送到计算机，由人工智能算法解码信号并推测 T5 的手和手指的预期运动。</p>
<p>与真实可见的手写笔迹相比，要 “读取” 想象中的笔迹最难的一点是什么？无疑，是如何捕捉这些笔迹在大脑中的神经表征，以及这些表征能不能用。</p>
<p>为了评估手写的神经表征，受试者 T5 需要按照电脑屏幕给出的指令，一次 “手写” 一个字符，每个字母重复 27 次试验。</p>
<img src="/fa8431ee/3.jpg" class>
<p>图3｜受试者的 “手写” 笔迹</p>
<p>根据以往的经验，研究人员首先使用主成分分析来显示包含最多方差的前三个神经维度特征。</p>
<p>研究人员发现，由于神经活动的高峰和低谷因时间有所不同，可能由于书写速度的波动，神经活动似乎是强烈和可重复的。为了直观地观察笔迹尝试过程中记录的神经活动，他们使用时间比对技术来消除时间变异性，这揭示了每个字符特有的显著一致的神经活动模式。</p>
<p>为了确定神经活动是否编码绘制了每个形状所需的笔尖运动，研究人员通过从试验平均神经活动中线性解码笔尖速度来重建每个字符，容易辨认的字母形状证实了笔尖速度是可靠编码的，代表笔尖速度的神经维度占总神经方差的 30%。</p>
<img src="/fa8431ee/4.jpg" class>
<p>图4｜笔迹的神经表征（来源：Nature）</p>
<p>其次，研究人员采用非线性降维方法（t-SNE），对每个试验的神经活动进行二维（2D）可视化，在对受试者给出 “go” 的提示后记录相关信息。</p>
<p>t-SNE 方法显示了每个字符的神经活动紧密簇和一种主导运动编码，在这种编码中，书写相似的字符更接近，将近邻分类器离线应用到神经活动中，可以对字符进行分类，准确率为 94.1%。</p>
<p>于是，研究人员得出结论，<strong>即使在瘫痪多年后，运动皮层中笔迹的神经表征可能仍足够强大，可以通过脑机接口技术表达出来。</strong></p>
<hr>
<h3 id="能不能解码“手写句子”？"><a href="#能不能解码“手写句子”？" class="headerlink" title="能不能解码“手写句子”？"></a>能不能解码“手写句子”？</h3><p>成功解码手写字母的最终目标，是让瘫痪患者实现流畅的对外交流能力，这需要实时解码 “意念” 手写笔迹，并完整呈现出他们想要表达的信息。</p>
<p>为此，研究人员特意训练了一个递归神经网络，将神经活动转化为描述每个字符在每个时刻被写入的可能性概率，这些概率可以用一种简单的方法来设定阈值，从而发出离散字符，或者通过使用一个大词汇量语言模型进行更广泛的处理，以模拟离线应用的自校正特征。</p>
<p>研究人员在实验中使用了 31 个字符的限定集，包括字母表中的 26 个小写字母，以及逗号、顿号、问号、句号和空格，为了收集实验中递归神经网络的训练数据，他们需要记录 T5 按照电脑显示器上的指示，以自己的速度手写完整句子时的神经活动。</p>
<p>在第一天的实时评估之前，研究人员收集了 3 个试验日内总共 242 句话，这些句子被组合起来训练递归神经网络。在随后每一天的实时测试中收集额外的训练数据，并在评估前重新校准，至最后一天总共产生了 572 个训练句子（包括 31472 个字符）。</p>
<p>为了训练这个递归神经网络，研究人员采用了语音识别中的神经网络方法来克服两个关键挑战：</p>
<p>（1）训练数据中每个字母的书写时间未知（因为 T5 的手瘫痪），这使得应用监督学习技术具有挑战性；</p>
<p>（2）与典型的 RNN 数据集相比，数据集的大小有限，因此很难防止对训练数据的过度拟合。</p>
<p>在这样的基础上，研究人员在 5 天的时间里对递归神经网络的表现进行评估，每天包含 4 个评估块，包含 7-10 个递归神经网络从未接受过训练的句子。受试者 T5 会从屏幕提示中复制每个句子，试图一个字母一个字母地手写，而解码的字符在递归神经网络检测到时实时出现在屏幕上。</p>
<p>经测试，字符出现与 T5 在大脑里 “手写” 之间会有一个短暂的延迟，大概为 0.4-0.7 秒，<strong>令人兴奋的是，整体打字速度很快，平均每分钟可打出 90 个字符，平均错误率仅为 5.4%**。当研究人员使用语言模型离线进行自动更正错误时，整个系统的错误率则进一步降低了，</strong>其字符错误率下降到 0.89%，单词错误率下降到 3.4%**，与世界上最先进的语音识别系统（单词错误率为4–5%）相比，展现出了极好的可用性。</p>
<p>最后，为了探索可能的解码性能限制，研究人员还离线训练了一个新的递归神经网络，使用所有可用的句子以非因果的方式处理整个句子。在这种情况下，<strong>仅出现了 0.17% 的字符错误率</strong>，这表明性能的潜在上限其实很高，尽管这种解码器目前无法向用户提供逐字反馈。</p>
<p>实验结果还证实，当受试者编写自己生成的句子（而不是复制屏幕上的提示句）时，也可以获得较高的性能，**每分钟可打出 73.8 个字符，实时字符错误率为 8.54%，语言模型错误率为 2.25%**。</p>
<hr>
<h3 id="解码器的改进方向"><a href="#解码器的改进方向" class="headerlink" title="解码器的改进方向"></a>解码器的改进方向</h3><p>借助每天收集的 “校准” 数据，研究人员每天也对 “手写笔迹” 解码器进行再训练。</p>
<p>再训练有助于解释随着时间的推移而产生的神经记录变化，这可能是由神经可塑性或电极阵列微动引起的，而理想情况下，为了减轻受试者的负担，应该用最少或不需要校准数据。</p>
<img src="/fa8431ee/5.jpg" class>
<p>图5｜解码器性能变化（来源：Nature）</p>
<p>值得注意的是，实验数据表明，当两个会话之间只经过 2-7 天时，在没有解码器重新训练的情况下，性能显示出了神经记录的短期稳定性。</p>
<p>面对这种情况，研究人员测试了解码器是否可以通过使用语言模型来纠错和重新训练解码器，从而绕过中断用户校准的需要，以无监督的方式重新训练。令人鼓舞的是，无监督再训练的原始错误率仅为 7.3%。</p>
<p>解码器是否能用最少的重新校准数据成功地再训练，也取决于神经活动随时间变化的速度。实验评估了与每个特征相关的神经模式的稳定性，发现短期稳定性很高（相隔 7 天或更短时间），这些结果对临床病例是有希望的，因为它们表明无监督解码器再训练，可能有助于实现高性能。</p>
<p>这项研究实现的每分钟输入 90 个字符，创造了迄今为止报道的相关类型脑机接口技术的最快速度，对于皮质内脑机接口来说，之前最好的方法是用 2D 电脑光标点击输入，每分钟仅可以输入 40 个正确字符，点击式脑机接口的输入速度主要受解码精度的限制，在参数优化过程中增加光标增益以提高打字速度，直到光标移动过快，由于解码错误而变得无法控制为止。</p>
<p>研究人员经对比分析，手写字母可能比点对点运动更容易区分，因为手写字母的神经活动时空模式比直线运动更为多样，而随时间变化的运动模式，从根本上说比点对点运动更容易解码。</p>
<hr>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>据了解，其实目前业内用于恢复患者交流能力的脑机接口有很多种方案。</p>
<p>此次研究人员不仅将脑机接口通信速率提升到了<strong>每分钟 90 个字符</strong>，而且该实时系统还具有通用性（用户可以表达任何句子）、易用性（完全自定节奏，眼睛可以自由移动）和足够精确的特点（94.1% 的原始准确率，在大词汇量语言模型下离线准确率大于 99%），在现实世界中非常有用。</p>
<p>当前的实验结果证明了高性能 “手写” 脑机接口是可能的，但它目前还不是一个完整的、临床上的商用系统，接下来还有更多工作值得探索，比如进一步提高打字性能，扩展字符集、启用文本编辑和删除等操作。</p>
<p>来自华盛顿大学生物工程系的专家帕维斯特拉·拉杰斯瓦兰（Pavithra Rajeswaran）、华盛顿大学电气和计算机工程系专家艾米·奥斯本（Amy L. Orsborn）在评论文章中表示，这项研究仍需要经过试验论证，将电极植入大脑的费用和风险是否合理。另外一点重要的是，打字速度并不是决定这项技术能否落地的唯一因素——这种方法的寿命和健壮性同样需要分析，是否可以推广到其他用户和实验室以外的环境中也至关重要。</p>
<p>目前的微电极阵列技术已被证明在植入后能保持功能超过 1000 天，而随着皮质内微电极阵列技术的成熟，也需要进一步证明其寿命、安全性和有效性，才能广泛应用于临床。</p>
<p>总体来讲，将脑中的 “笔迹” 转化为屏幕上的单词、句子，其技术前景和商用潜力都十分令人鼓舞，人机结合的时代正在走来。</p>
<p>论文完整链接：<a href="https://www.nature.com/articles/s41586-021-03506-2">https://www.nature.com/articles/s41586-021-03506-2</a></p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11157">https://www.scholat.com/teamwork/showPostMessage.html?id=11157</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-BERT论文逐段精读-《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》</title>
    <url>/5f1c011a.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2018-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding.pdf" data-height="500px"></div>

<p><strong>BERT</strong> 论文链接：<a href="https://aclanthology.org/N19-1423.pdf">https://aclanthology.org/N19-1423.pdf</a></p>
<p>BERT: 近 3 年 NLP 最火</p>
<p>CV: 大数据集上的训练好的 NN 模型，提升 CV 任务的性能 —— ImageNet 的 CNN 模型</p>
<p>NLP: BERT 简化了 NLP 任务的训练，提升了 NLP 任务的性能</p>
<p>BERT 如何站在巨人的肩膀上的？使用了哪些 NLP 已有的技术和思想？哪些是 BERT 的创新？</p>
<span id="more"></span>

<hr>
<h3 id="标题-作者"><a href="#标题-作者" class="headerlink" title="标题 + 作者"></a>标题 + 作者</h3><p><strong>BERT</strong>: Pre-training of Deep Bidirectional Transformers for Language Understanding</p>
<p>pre-training: 在一个大的数据集上训练好一个模型 pre-training，模型的主要任务是用在其它任务 training 上。</p>
<p>deep bidirectional transformers: 深的双向 transformers</p>
<p>language understanding: 更广义，transformer 主要用在机器翻译 MT</p>
<p>BERT: 用深的、双向的、transformer 来做预训练，用来做语言理解的任务。</p>
<p>作者：Google AI Language，写作时间短（几个月）</p>
<hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>新的语言表征模型 BERT: <strong>B</strong>idirectional <strong>E</strong>ncoder <strong>R</strong>epresentations from <strong>T</strong>ransformers，基于 ELMo<br>Transformers 模型的双向编码表示</p>
<p>与 ELMo 和 GPT 不同，BERT 从无标注的文本中（jointly conditioning 联合左右的上下文信息）预训练得到 无标注文本的 deep bidirectional representations</p>
<p>pre-trained BERT 可以通过加一个输出层来 fine-tune，在很多任务（问答、推理）有 SOTA 效果，而不需要对特定任务的做架构上的修改。</p>
<p>GPT unidirectional，使用左边的上下文信息 预测未来<br>BERT bidirectional，使用左右侧的上下文信息</p>
<p>ELMo based on RNNs, down-stream 任务需要调整一点点架构<br>BERT based on Transformers, down-stream 任务只需要调整最上层。<br>GPT, down-stream 任务 只需要改最上层。</p>
<p>摘要第一段：和哪两篇工作相关，区别是什么？<br>BERT 是在 GPT 和 ELMo 的基础上的改动。</p>
<p><strong>摘要第二段：BERT 的好处</strong><br>simple and empirically powerful, 11 NLP 任务的SOTA, 绝对精度 + 相对精度（比别人好多少）</p>
<p>摘要写法：<br>第一段：我和另外 2 篇相关工作的区别，改进在哪里？<br>第二段：我的结果特别好，好在什么地方？</p>
<p>Note: BERT 论文写作好 –&gt; 经典<br>工作质量：创新性、效果好 –&gt;  经典</p>
<hr>
<h3 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h3><p>导言第一段：本篇论文关注的研究方向的一些上下文关系<br>Language model pre-training 可以提升 NLP 任务的性能<br>NLP任务分两类：sentence-level tasks 句子情绪识别、两个句子的关系； token-level tasks NER (人名、街道名) 需要 fine-grained output</p>
<p>NLP 预训练很早之前存在，BERT 使 NLP 预训练 出圈了。</p>
<p>导言第二段：摘要第一段的扩充</p>
<p>pre-trained language representations 两类策略：<br><strong>基于特征的 ELMo</strong> (构建和每一个下游任务相关的 NN 架构；训练好的特征（作为额外的特征） 和 输入 一起放进模型)</p>
<p><strong>基于微调参数的 GPT</strong><br>所有的权重参数根据新的数据集进行微调。</p>
<p>介绍别人工作的目的：铺垫自己方法的好</p>
<p>ELMo 和 GPT 预训练时 使用 unidirectional langugage model，使用相同的目标函数<br>语言模型是单向的、预测未来。不是给第 一句、第三句，预测第二句</p>
<p>导言第三段：<br>当前技术的局限性：标准语言模型是 unidirectional 单向的，限制了模型架构的选择。</p>
<p>GPT 从左到右的架构，只能将输入的一个句子从左看到右。句子情感分类任务：从左看到右、从右看到左 都应该是合法的。</p>
<p>token-level tasks：问答 qa 看完整个句子选答案，不是从左往右一步一步看。</p>
<p>如果能 incorporate context from both directions 看两方向的信息，能提升 任务性能。</p>
<p>相关工作的局限性，+ 解决局限性的想法 – &gt; 导言第四段： 如何解决？</p>
<p>BERT 通过 MLM 带掩码的语言模型 作为预训练的目标，来减轻 语言模型的单向约束。inspired by the Close task 1953 </p>
<p>MLM 带掩码的语言模型做什么呢？<br>每次随机选输入的词源 tokens, 然后 mask 它们，目标函数是预测被 masked 的词；类似挖空填词、完形填空。</p>
<p>MLM 和 standard language model （只看左边的信息）有什么区别？<br>MLM 可以看 左右的上下文信息, pre-train deep bidirectional transformer 的基础。</p>
<p>BERT 除了 MLM 还有什么？<br>NSP: next sentence prediction<br>判断两个句子是随机采样的 or 原文相邻，学习 sentence-level 的信息。</p>
<p><strong>文章 3点 贡献：</strong></p>
<ol>
<li><p> bidirectional 双向信息的重要性<br>GPT 只用了 unidirectional 信息；另外 Peter 2018 把从左看到右 和 从右看到左的模型独立训练 + shallow concatenation 拼在一起；BERT 在 bidirectional pre-training 的应用更好</p>
</li>
<li><p>BERT 首个 微调模型，在 sentence-level and token-level task效果好<br>好的预训练模型，不用对特定任务做一些模型架构的改动</p>
</li>
<li><p>BERT 开源，随便用。</p>
</li>
</ol>
<hr>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>近期实验表明，非监督的预训练模型很好，low-resource 任务也能享受 benefit from 深的神经网络。<br>本文贡献：拓展前任的结果到 deep bidirectional architectures，使同样的预训练模型能够处理大量的 NLP 任务</p>
<p><strong>本文故事：</strong></p>
<p>2个相关工作：ELMo 用了 bidirectional 信息，但架构 RNN 老；GPT 架构 Transformer 新，但只用了 unidirectional 信息。</p>
<p>BERT = ELMo 的 bidirectional 信息 + GPT 的新架构 transformer</p>
<p>How?<br>Language model 任务：不是预测未来，而是完形填空。</p>
<p>写作：两个算法的结合，主要工作 – 证明 双向有用</p>
<p>A + B 缝合工作 or C 技术解决 D 领域的问题，不要觉得想法小、不值得写出来；简单朴实的写出来。简单好用 说不定会出圈</p>
<hr>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>2.1 Unsupervised Feature-based approaches<br>非监督的基于特征表示的工作：词嵌入、ELMo等</p>
<p>2.2 Unsupervised Fine-tuning approaches<br>非监督的基于微调的工作：GPT等</p>
<p>2.3 Transfer Learning from Supervised Data<br>在有标号的数据上做迁移学习。</p>
<p>NLP 有标号 的大数据集：natural language inference and machine translation</p>
<p>CV做的还不错，ImageNet 训练好、再做迁移。</p>
<p>NLP 表现不那么好：CV 和 NLP 任务的区别，NLP 数据的不足。</p>
<p><strong>BERT 的作用：</strong><br>NLP 中，在无标号的大量数据集上训练的模型效果 &gt; 有标号、但数据量少一些的数据集上训练效果</p>
<p>CV 采用 BERT 的想法嘛？<br>Yes，在大量无标号的图片上训练的模型，可能比 有标号的 ImageNet 百万图片 效果更好。</p>
<hr>
<h3 id="BERT-模型"><a href="#BERT-模型" class="headerlink" title="BERT 模型"></a>BERT 模型</h3><p>BERT 有哪两步？预训练 + 微调<br>pre-training: 使用 unlabeled data 训练<br>fine-tuning: 微调的 BERT 使用 预训练的参数 初始化，所有的权重参数通过 下游任务的 labeled data 进行微调。<br>每一个下游任务会创建一个 新的 BERT 模型，（由预训练参数初始化），但每一个下游任务会根据自己任务的 labeled data 来微调自己的 BERT 模型。</p>
<p>预训练和微调不是 BERT 的创新，CV里用的比较多。</p>
<p><strong>作者关于预训练和微调的介绍 好吗？</strong><br>好！如果假设读者都知道论文的技术，而只一笔带过（给Ref），不太好。论文写作要自洽，简单的说明就好，避免读者不知道预训练和微调，增加理解文章的障碍。</p>
<img src="/5f1c011a/1.png" class>

<p>预训练的输入：unlabelled sentence pair<br>训练 BERT 的权重</p>
<p>下游任务：创建同样的 BERT 的模型，权重的初始化值来自于 预训练好 的权重。<br>MNLI, NER, SQuAD 下游任务有 自己的 labeled data, 对 BERT 继续训练，得到各个下游任务自己的的 BERT 版本。</p>
<p><strong>Model Architecture</strong></p>
<p>multi-layer bidirectional Transformer encoder<br>一个多层双向 Transformer 的解码器，基于 transfomer 的论文和代码。</p>
<p>写作：第三章这里不讲可以；在第二章相关工作做一定的介绍, i.e., L H</p>
<p>模型调了哪 3 个参数?<br>L: transform blocks的个数<br>H: hidden size 隐藏层大小<br>A: 自注意力机制 multi-head 中 head 头的个数</p>
<p>调了 BERT_BASE （1亿参数）和 BERT_LARGE （3.4亿参数）</p>
<p>Large 模型 层数 L 翻倍 12 – 24；宽度 H 768 – 1024<br>BERT 模型复杂度和层数 L 是 linear, 和宽度 H 是 平方关系。<br>因为 深度 变成了 以前的两倍，在宽度上面也选择一个值，使得这个增加的平方大概是之前的两倍。</p>
<p>H = 16，因为每个 head 的维度都固定在了64。因为你的宽度增加了，所以 head 数也增加了。</p>
<p>BERT_base 的参数选取 和 GPT 差不多，比较模型；BERT_large 刷榜。</p>
<p><strong>超参数换算成可学习参数的大小，transformer架构的回顾</strong></p>
<p>可学习参数的来源：嵌入层 30k * H、transformer块 L * H^2 * 12</p>
<p>嵌入层： 输入是词的字典大小 30k，输出是 H<br>参数：30k （字典大小） * H （hidden size）</p>
<p>嵌入层的输出会进入 transformer 块。</p>
<p>transformer blocks（H^2 * 12）: self-attention mechanism （H^2 * 4）+ MLP（H^2 * 8）</p>
<p>self-attention mechanism 本身无可学习参数; multi-head self-attention mechanism 要对 q, k, v 做投影，每一次投影维度=64 –&gt; A * 64 = H。<br>每一个 q, k, v 都有自己的投影矩阵，合并每个 head 的投影矩阵 –&gt; q, k, v 分别的 H * H 矩阵。</p>
<p>得到输出后还会有一次 H * H 的投影。</p>
<p>Transformer block 里的 self-attention 可学习参数 = H^ 2 * 4</p>
<p>MLP 的 2个全连接层：<br>第一个全连接层输入是 H，输出是 4 * H；<br>第二个全连接层输入是 4 * H，输出是 H。</p>
<p>每一个参数矩阵大小 H * 4H，MLP 中的可学习参数 H^2 * 8</p>
<p>一个 transformer block 的参数量 H^2 * 12，L 个 blocks，L * H^2 * 12</p>
<p><strong>Input/Output Representations</strong></p>
<p>下游任务有处理一个句子 or 处理 2 个句子，BERT 能处理不同句子数量的下游任务，使输入可以是 a single sentence and a pair of sentences (Question answer)</p>
<p>a single sentence: 一段连续的文字，不一定是真正上的语义上的一段句子，它是我的输入叫做一个序列 sequence。</p>
<p>A “sequence” 序列可以是一个句子，也可以是两个句子。</p>
<p>BERT 的输入和 transformer 区别？<br>transformer 预训练时候的输入是一个序列对。编码器和解码器分别会输入一个序列。<br>BERT 只有一个编码器，为了使 BERT 能处理两个句子的情况，需要把两个句子并成一个序列。</p>
<p><strong>BERT 如何切词？</strong></p>
<p>WordPiece, 把一个出现概率低的词切开，只保留一个词出现频率高的子序列，30k token 经常出现的词（子序列）的字典。<br>否则，空格切词 –&gt; 一个词是一个 token。数据量打的时候，词典会特别大，到百万级别。可学习的参数基本都在嵌入层了。</p>
<p>BERT 的输入序列如何构成？ [ CLS ]  +  [ SEP ]</p>
<p>序列开始: [ CLS ] 输出的是句子层面的信息 sequence representation<br>BERT 使用的是 transformer 的 encoder，self-attention layer 会看输入的每个词和其它所有词的关系。<br>就算 [ CLS ] 这个词放在我的第一个的位置，他也是有办法能看到之后所有的词。所以他放在第一个是没关系的，不一定要放在最后。</p>
<p>区分 两个合在一起的句子 的方法：</p>
<ul>
<li>每个句子后 + [ SEP ] 表示 seperate</li>
<li>学一个嵌入层 来表示 整个句子是第一句还是第二句</li>
</ul>
<p>[ CLS ] [Token1] …… [Token n] [SEP] [Token1’] …… [Token m]</p>
<p>每一个 token 进入 BERT 得到 这个 token 的embedding 表示。<br>对于 BERT，输入一个序列，输出一个序列。</p>
<p>最后一个 transformer 块的输出，表示 这个词源 token 的 BERT 的表示。在后面再添加额外的输出层，来得到想要的结果。</p>
<img src="/5f1c011a/2.png" class>

<p>For a given token, 进入 BERT 的表示 = token 本身的表示 + segment 句子的表示 + position embedding 位置表示</p>
<p>BERT 嵌入层：一个词源的序列 –&gt; 一个向量的序列 –&gt; 进入 transformer 块</p>
<p>Token embeddings:  词源的embedding层，整成的embedding层， 每一个 token 有对应的词向量。<br>Segement embeddings: 这个 token 属于第一句话 A还是第二句话 B。<br>Position embeddings: 输入的大小 = 这个序列最长有多长？ i.e., 1024<br>Position embedding 的输入是 token 词源在这个序列 sequence 中的位置信息。从0开始 1 2 3 4 –&gt; 1024</p>
<img src="/5f1c011a/3.png" class>

<p>BERT input representation = token embeddings + segment embeddings + position embeddings </p>
<p>BERT 的 segment embedding （属于哪个句子）和 position embedding （位置在哪里）是学习得来的，transformer 的 position embedding 是给定的。</p>
<p>BERT 关于 pre-train 和 fine-tune 同样的部分 == end</p>
<p><strong>3.1 Pre-training BERT</strong></p>
<p>预训练的 key factors: 目标函数，预训练的数据</p>
<p><strong>Task 1 MLM</strong><br>为什么 bidirectional 好？ MLM 是什么？完形填空</p>
<p>由 WordPiece 生成的词源序列中的词源，它有 15% 的概率会随机替换成一个掩码。但是对于特殊的词源不做替换，i.e., 第一个词源 [ CLS ] 和中间的分割词源 [SEP]。</p>
<p>如果输入序列长度是 1000 的话，要预测 150 个词。</p>
<p>MLM 带来的问题：<strong>预训练和微调看到的数据不一样</strong>。预训练的输入序列有 15% [MASK]，微调时的数据没有 [MASK].</p>
<p>15% 计划被 masked 的词: 80% 的概率被替换为 [MASK], 10% 换成 random token,10% 不改变原 token。但 T_i 还是被用来做预测。</p>
<p>80%, 10%, 10% 的选择，有 ablation study in appendix</p>
<p>unchanged 和 微调中的数据应该是一样的。</p>
<p><strong>Task 2 NSP Next Sentence Prediction</strong></p>
<p>在问答和自然语言推理里都是<strong>句子对</strong>。<br>如果 BERT 能学习到 sentence-level 信息，很棒。</p>
<p>输入序列有 2 个句子 A 和 B，50% 正例，50%反例<br>50% B 在 A 之后，50% 是 a random sentence 随机采样的。</p>
<p>正例：这个人要去一个商店，然后他买了一加仑的牛奶。IsNext<br>反例：这个人去了商店，然后企鹅是一种不能飞的鸟。NotNext</p>
<p>flight ## less, flightless 出现概率不高，WordPiece 分成了 2 个出现频率高的子序列，## 表示 less 是 flightless 的一部分。</p>
<p><strong>Pre-training data</strong></p>
<p>2 个数据集：BooksCorpus (800 M) + English Wikipedia (2500 M)<br>使用一篇一篇文章，而不是随机打断的句子。 a document-level corpus rather than a shuffled sentence-level corpus</p>
<p>transformer 可以处理较长的序列，一整个文本的输入，效果会好一些。</p>
<p><strong>3.2 Fine-tuning BERT</strong></p>
<p>用 BERT 做微调的一般化的介绍。</p>
<p>BERT 和一些基于encoder-decoder的架构为什么不一样？transformer 是encoder-decoder。</p>
<p>整个句子对被放在一起输入 BERT，self-attention 能够在两个句子之间相互看。BERT 更好，但代价是 不能像 transformer 做机器翻译。</p>
<p>在encoder-decoder的架构，编码器看不到解码器的东西。</p>
<p><strong>BERT 做 下游任务</strong></p>
<p>根据下游任务，设计我们任务相关的输入和输出。</p>
<p>好处：模型不怎么变，加一个输出层 softmax 得到 标号 label</p>
<p><strong>怎么样把输入改成想要的句子对？</strong></p>
<ul>
<li>有两个句子的话，当然就是句子 A 和 B。</li>
<li>只有一个句子的话，要做句子分类的话， B 没有。根据下游任务的要求，要么是 [CLS] representation is fed into an output layer for classification 拿到第一个词源 [CLS] 对应的输出做分类 such as entailment or sentiment analysis，或者是 the token representations are fed into an output layer for token-level tasks 拿到对应那些词源的输出做 sequence tagging or question answering 输出。</li>
</ul>
<p>微调比预训练便宜。TPU 1 hour, GPU a few hours.</p>
<p><strong>Section 4 具体对每一个下游任务是怎么样构造输入输出</strong></p>
<hr>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p><strong>4.1 GLUE General Language Understanding Evaluation</strong></p>
<ul>
<li>多个数据集</li>
<li>sentence-level tasks</li>
</ul>
<p>[CLS] 的 BERT 输出表示 + 一个输出层 W，softmax 分类得到 label<br>log(softmax(CW^T)</p>
<p><strong>4.2 SQuAD v1.1</strong><br>Standford Question Answering Dataset</p>
<p>QA 问答：给一段文字，问一个问题，摘录答案。–&gt; 判断答案的开始和结尾。<br>对每个词源 token，判断是不是答案的开始or结尾</p>
<p>学 2 个向量 S 和 E，分别对应这个词源 token 是答案开始词的概率 和 是答案结尾词的概率。</p>
<p>具体计算 每个 token 是答案开始的概率，结尾词类似 E。<br>S 和 第二句话的每个词源 token 相乘 + softmax，得到归一化的概率。<br>P_i = e ^ ( S * T_i ) / \sigma_j ( e ^ ( S * T_j ) )</p>
<p>本文微调时，数据扫三遍，epochs = 3, lr = 5e-5, batch_size = 32</p>
<p>大家实验发现：用 BERT 做微调的时候，结果非常不稳定。同样的参数，同样的数据集，训练 10 遍，variance 方差特别大。</p>
<p>其实很简单，epochs 不够，3 太小了，可能要多学习几遍会好一点。</p>
<p>adam 的不完全版 在长时间训练的 BERT 没问题，训练时间不够，需要 adam 的完全版。</p>
<p><strong>4.3 SQuAD v2.0  表现也很不错</strong></p>
<p><strong>4.4 SWAG</strong></p>
<p>Situations With Adversarial Generations 判断两个句子之间的关系，BERT 和之前的训练没多大区别，效果好。</p>
<p>总结：BERT 在不一样的数据集上，用起来很方便，效果很好。<br>输入表示成“一对句子的形式”，最后拿到 BERT 对应的输出，然后加一个输出层 softmax，完事了。</p>
<p>BERT 对 NLP 整个领域的贡献非常大，有大量的任务用一个相对简单、只改数据输入形式和最后加一个输出层，就可以效果很不错。</p>
<p><strong>5 Ablation studies</strong></p>
<p>看 BERT 每一个组成部分的贡献。</p>
<p>没有 NSP<br>LTR 从左看到右（无 MLM ） &amp; 没有 NSP<br>LTR 从左看到右（无 MLM ） &amp; 没有 NSP + BiLSTM （从ELMo来的想法）</p>
<p>去掉任何一个组成部分，BERT的效果都会有打折，特别是 MRPC。</p>
<p><strong>5.2 Effect of Model Size</strong></p>
<p>BERT_base 110 M 可学习参数<br>BERT_large 340 M 可学习参数</p>
<p>NLP界认为 模型越大，效果越好。BERT 首先证明了大力出奇迹，引发了模型“大”战</p>
<p>现在：GPT-3 1000 亿可学习参数</p>
<p><strong>5.3 Feature-based Approach with BERT</strong></p>
<p>没有微调的 BERT，将pre-trained 得到的 BERT 特征作为一个静态的特征输入，效果没有 + 微调好</p>
<p>卖点：用 BERT 需要微调。</p>
<hr>
<h3 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h3><p>写作：</p>
<ul>
<li>先写 BERT 和 ELMo (bidirectional + RNN)、GPT (unidirectional + transformer) 的区别</li>
<li>介绍 BERT 模型</li>
<li>BERT 实验设置、效果好</li>
<li>结论突出 ‘bidirectional’ 贡献</li>
<li>文章 1个卖点，容易记。</li>
</ul>
<p><strong>但 BERT 是否要选择  ‘bidirectional’  双向性呢？</strong><br>可以写，但也要写 双向性带来的不足是什么？</p>
<p>选择有得有失。<br>GPT 用的是 decoder<br>BERT 用的是 encoder，不好做generative tasks：机器翻译、文本摘要。</p>
<p>分类问题在 NLP 更常见。<br>NLP 研究者喜欢 BERT，较容易的应用在 NLP 中自己想解决的问题。</p>
<p>BERT，完整的解决问题的思路 —- 大家对 DL 的期望<br>训练一个很深、很宽的模型，在一个很大的数据集上预训练好；训练好的模型参数可以解决很多小的问题，通过微调提升小数据集上的性能。</p>
<p>这个模型拿出来之后可以用在很多小的问题上，能够通过微调来全面提升这些小数据上的性能。这个在计算机视觉里面我们用了很多年了。</p>
<p>BERT 把 CV 的套路搬到了 NLP，1个3亿参数的模型，展示：模型越大、效果越好。大力出奇迹。</p>
<p>为什么 BERT 被记住？<br>BERT 用了 ELMo, GPT 更大的训练数据集，效果更好；BERE 也被更大的训练数据集和更大的模型超越。<br>BERT 的引用率是 GPT 的 10 倍，影响力 ✔</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>软件硬件-固态硬盘SSD是如何存储数据的？</title>
    <url>/e921b18a.html</url>
    <content><![CDATA[<p>固态硬盘SSD是如何存储数据的？为什么固态硬盘不能长时间保存数据？NAND FLASH的工作原理？U盘存储卡这些是如何存储数据的？</p>
<img src="/e921b18a/1.png" class>

<p>电脑的固态硬盘、手机的硬盘、U盘还有存储卡都属于闪存，如果再细分的话它们都属于NAND FLASH</p>
<img src="/e921b18a/2.png" class>

<p>接下来我们就来说说它是如何存储信息的</p>
<span id="more"></span>

<p>它存储信息的基本单元是一个浮栅晶体管，下面是结构示意图</p>
<img src="/e921b18a/3.png" class>

<p>和我们平时见的常规晶体管非常相似，不同的是它在断电以后可以存储信息，而常规晶体管不能存储信息。</p>
<p>先说一下常规晶体管的工作原理，红色小球代表电子，当栅极电压为0时，它是截止的</p>
<img src="/e921b18a/4.png" class>

<p>当我们给栅极施加一个5V电压，栅极就能把黄色区域中的电子吸引到绝缘层附近。因为绝缘层的存在，电子都聚集在这一区域，形成了N沟道</p>
<img src="/e921b18a/5.png" class>

<p>如果我们给DS极施加电压，这个晶体管就会有电流流过</p>
<img src="/e921b18a/6.png" class>

<p>而当我们把栅极电压去掉，电子就不会在这一块聚集，没有形成通路，所以晶体管就会截止</p>
<img src="/e921b18a/7.png" class>

<p>这种常规的晶体管只能控制截止和导通，而浮栅晶体管在常规晶体管的基础上多了两层东西，其中一层是隧穿层，另外一层是浮栅层</p>
<img src="/e921b18a/8.png" class>

<p>它是这样存储信息的，也就是写信息。如果想要它存储电荷，必须给它一个高压，比如20V，这样电子就能穿过隧穿层，进入浮栅层。因为有绝缘层的存在，电子再也不能往前移动了，所以被囚禁在了浮栅层</p>
<img src="/e921b18a/9.png" class>

<p>而当我们把电压撤去，这些电子依然会被囚禁在浮栅层。因为隧穿层本质上也是绝缘体，所以它只能被关押着，这样一位数据就被存储进去了</p>
<img src="/e921b18a/10.png" class>

<p>这些电子能被囚禁多长时间也就是固态硬盘可以存储数据的年限，一般新的固态硬盘可以保存的数据年限是10年，因为随着时间的流失，不断地有电子越狱成功，等越狱的电子多到一定数量时，我们保存的数据就不见了</p>
<img src="/e921b18a/11.png" class>

<p>如果我们想释放这些电子，也非常简单，可以在它的衬底上施加高压，这样电子就被吸出来了</p>
<img src="/e921b18a/12.png" class>

<p>我们删除电脑上的数据其实就是在释放这些电子，浮栅晶体管有没有存储电荷就可以代表0和1，上述过程就是电子的写入和擦除的过程</p>
<img src="/e921b18a/13.png" class>

<p>关于它读数据的原理也非常简单，比如当它没有存储电子的时候，我们给栅极一个低压，它就会导通，因为电压低，电子只能被吸引到这里，所以就导通了形成电流</p>
<img src="/e921b18a/14.png" class>

<p>在它的上方会有检测电流的东西，如果检测到电流，说明它没有存储电子</p>
<img src="/e921b18a/15.png" class>

<p>而如果浮栅晶体管存储了电子，我们还给它加原来那个电压，由于浮栅层里面的电子对这些电子有排斥作用，所以这时候晶体管就不能导通，这时候就检测不到电流，或者电流很小，它就是这样读取数据的。</p>
<img src="/e921b18a/16.png" class>

<p>在实际中NAND FLASH都是以块为单位擦除数据的，而以页为单位读写数据</p>
<img src="/e921b18a/17.png" class>

<p>举例来说，这就是一块数据，每一行都是一页数据，在每一列的两端都有两个普通晶体管，这两个晶体管的不同开关状态就可以控制我们的读写和擦除。</p>
<img src="/e921b18a/18.png" class>

<p>行代表字线，列代表位线，一行就是一个字节，这一块数据总共可以存储8个字节。它的每一列晶体管都是串联的，结构上是这样的：每两个晶体管共用一个N区，可以减少制造难度，它的这一列共用一个衬底</p>
<img src="/e921b18a/19.png" class>

<p>其实不止是每一列，它的这一块数据都共用一个衬底，所以只要我们给衬底施加高压，这一整块的数据都会消失。这就是它为什么是以块来擦除数据的原因。</p>
<img src="/e921b18a/20.png" class>

<p>再来说说它为什么以页为单位来读写，因为字线同时连接到了这一页上所有晶体管的栅极，它没法单独的去控制里面的每一个晶体管</p>
<img src="/e921b18a/21.png" class>

<p>比如我们要给某个晶体管写入数据，就需要给这个字线高压，给它的位线写0，其它的如图。这样这一个晶体管在高压下就会存储电荷，而我们不想存储电荷的话，就给它的位线2V电压，这样由于这些晶体管的沟道效应就阻碍的电子进入晶体管的浮栅层，所以它们就没有存储电荷</p>
<img src="/e921b18a/22.png" class>

<p>如果把存储电荷代表0，此时它代表的数据是01111111</p>
<img src="/e921b18a/23.png" class>

<p>其实在真正的实际应用中，一块数据不可能只有8字节，按小存储芯片来说，它的一页数据也得有32,768位，也就是4KB，每一块存储里面含有64个这样的页，也就是一块数据得有256KB。</p>
<p>而一个NAND FLASH里面含有8,192个这样的数据块，总空间就是2,097,152KB，也就是2个G的存储空间</p>
<img src="/e921b18a/24.png" class>

<p>因为它的每一位都需要一个晶体管，所以仅仅2G的存储卡需要存储数据的晶体管得有170亿这么多（以SLC颗粒，最基础的NAND FLASH为例）</p>
<img src="/e921b18a/25.png" class>

<p>最后我们再来说一下为什么固态硬盘有擦写次数要求，也就是擦写多少次，最多的擦写次数目前是10万次</p>
<img src="/e921b18a/26.png" class>

<p>这是因为在擦写的过程中，电子反复在隧穿层进进出出，这就导致隧穿层损坏，不能阻拦电子，失去了隧穿层应有的作用</p>
<img src="/e921b18a/27.png" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/video/BV1644y157mB">https://www.bilibili.com/video/BV1644y157mB</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-读论文(PART II)</title>
    <url>/25a797ad.html</url>
    <content><![CDATA[<p>更多论文请见：<a href="https://github.com/mli/paper-reading">https://github.com/mli/paper-reading</a></p>
<hr>
<h3 id="AlphaFold-2-论文精读-2022-01-24"><a href="#AlphaFold-2-论文精读-2022-01-24" class="headerlink" title="AlphaFold 2 论文精读 (2022-01-24)"></a>AlphaFold 2 论文精读 (2022-01-24)</h3><iframe src="//player.bilibili.com/player.html?aid=338444233&bvid=BV1oR4y1K7Xr&cid=491148105&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<h3 id="CLIP-论文逐段精读-论文精读-2022-02-11"><a href="#CLIP-论文逐段精读-论文精读-2022-02-11" class="headerlink" title="CLIP 论文逐段精读 论文精读 (2022-02-11)"></a>CLIP 论文逐段精读 论文精读 (2022-02-11)</h3><iframe src="//player.bilibili.com/player.html?aid=851425715&bvid=BV1SL4y1s7LQ&cid=505919491&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="双流网络论文逐段精读-论文精读-2022-02-25"><a href="#双流网络论文逐段精读-论文精读-2022-02-25" class="headerlink" title="双流网络论文逐段精读 论文精读 (2022-02-25)"></a>双流网络论文逐段精读 论文精读 (2022-02-25)</h3><iframe src="//player.bilibili.com/player.html?aid=594369770&bvid=BV1mq4y1x7RU&cid=516275778&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="GPT，GPT-2，GPT-3-论文精读-2022-03-04"><a href="#GPT，GPT-2，GPT-3-论文精读-2022-03-04" class="headerlink" title="GPT，GPT-2，GPT-3 论文精读 (2022-03-04)"></a>GPT，GPT-2，GPT-3 论文精读 (2022-03-04)</h3><iframe src="//player.bilibili.com/player.html?aid=296939123&bvid=BV1AF411b7xQ&cid=541096351&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="OpenAI-Codex-论文精读-2022-03-11"><a href="#OpenAI-Codex-论文精读-2022-03-11" class="headerlink" title="OpenAI Codex 论文精读 (2022-03-11)"></a>OpenAI Codex 论文精读 (2022-03-11)</h3><iframe src="//player.bilibili.com/player.html?aid=254746540&bvid=BV1iY41137Zi&cid=546522058&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="DeepMind-AlphaCode-论文精读-2022-03-18"><a href="#DeepMind-AlphaCode-论文精读-2022-03-18" class="headerlink" title="DeepMind AlphaCode 论文精读 (2022-03-18)"></a>DeepMind AlphaCode 论文精读 (2022-03-18)</h3><iframe src="//player.bilibili.com/player.html?aid=637249942&bvid=BV1ab4y1s7rc&cid=546529944&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="斯坦福-2022-年-AI-指数报告精读-2022-03-25"><a href="#斯坦福-2022-年-AI-指数报告精读-2022-03-25" class="headerlink" title="斯坦福 2022 年 AI 指数报告精读 (2022-03-25)"></a>斯坦福 2022 年 AI 指数报告精读 (2022-03-25)</h3><iframe src="//player.bilibili.com/player.html?aid=980013168&bvid=BV1s44y1N7eu&cid=558085961&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="I3D-论文精读-2022-04-01"><a href="#I3D-论文精读-2022-04-01" class="headerlink" title="I3D 论文精读 (2022-04-01)"></a>I3D 论文精读 (2022-04-01)</h3><iframe src="//player.bilibili.com/player.html?aid=640164439&bvid=BV1tY4y1p7hq&cid=563217576&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="视频理解论文串讲（上）-论文精读-2022-04-15"><a href="#视频理解论文串讲（上）-论文精读-2022-04-15" class="headerlink" title="视频理解论文串讲（上） 论文精读 (2022-04-15)"></a>视频理解论文串讲（上） 论文精读 (2022-04-15)</h3><iframe src="//player.bilibili.com/player.html?aid=853205150&bvid=BV1fL4y157yA&cid=576076417&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="参数服务器（Parameter-Server）逐段精读-2022-04-22"><a href="#参数服务器（Parameter-Server）逐段精读-2022-04-22" class="headerlink" title="参数服务器（Parameter Server）逐段精读 (2022-04-22)"></a>参数服务器（Parameter Server）逐段精读 (2022-04-22)</h3><iframe src="//player.bilibili.com/player.html?aid=895626974&bvid=BV1YA4y197G8&cid=577032881&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="视频理解论文串讲（下）-论文精读-2022-04-29"><a href="#视频理解论文串讲（下）-论文精读-2022-04-29" class="headerlink" title="视频理解论文串讲（下） 论文精读 (2022-04-29)"></a>视频理解论文串讲（下） 论文精读 (2022-04-29)</h3><iframe src="//player.bilibili.com/player.html?aid=256025019&bvid=BV11Y411P7ep&cid=586721445&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Pathways-论文精读-2022-05-06"><a href="#Pathways-论文精读-2022-05-06" class="headerlink" title="Pathways 论文精读 (2022-05-06)"></a>Pathways 论文精读 (2022-05-06)</h3><iframe src="//player.bilibili.com/player.html?aid=596075214&bvid=BV1xB4y1m7Xi&cid=586722632&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="GPipe-论文精读-2022-05-27"><a href="#GPipe-论文精读-2022-05-27" class="headerlink" title="GPipe 论文精读 (2022-05-27)"></a>GPipe 论文精读 (2022-05-27)</h3><iframe src="//player.bilibili.com/player.html?aid=811793814&bvid=BV1v34y1E7zu&cid=728450825&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Megatron-LM-论文精读-2022-06-03"><a href="#Megatron-LM-论文精读-2022-06-03" class="headerlink" title="Megatron LM 论文精读 (2022-06-03)"></a>Megatron LM 论文精读 (2022-06-03)</h3><iframe src="//player.bilibili.com/player.html?aid=596898805&bvid=BV1nB4y1R7Yz&cid=728958780&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-最新CNN反超Transfromer之作：ConvNeXt</title>
    <url>/4004cc9d.html</url>
    <content><![CDATA[<p>FAIR于近日（2022年1月13日）提出了仅依靠卷积神经网络构建的ConvNeXt[1]，这个依靠CNN且以传统ResNet为出发点搭建的模型在ImageNet的舞台上超过了Swin-Transfromer而引起广泛关注。（ConvNeXt与Swin-Transfromer基于ImageNet1K/22K数据集的对比如在下图1[1]。）</p>
<img src="/4004cc9d/1.png" class>
<p>图1 在ImageNet上各网络准确率对比</p>
<span id="more"></span>

<p>ConvNeXt的主要设计思路是模仿Swin-Transfromer的设计策略，同时“取其精华，去其糟粕“，整个优化方案可参考下图2[1]。</p>
<img src="/4004cc9d/2.png" class>
<p>图2 基于ResNet的ConvNeXt优化流程</p>
<p>根据图2，我们展开描述优化方案。</p>
<hr>
<h3 id="训练方式优化"><a href="#训练方式优化" class="headerlink" title="训练方式优化"></a>训练方式优化</h3><p>效仿Swin-Transformer，使用以下优化策略：</p>
<ol>
<li><p>将训练Epoch数从90增加到300；</p>
</li>
<li><p>优化器从SGD改为AdamW；</p>
</li>
<li><p>更多的数据增强策略，包括Mixup，CutMix，RandAugment，Random Erasing等；</p>
</li>
<li><p>更多正则策略，包括随机深度，标签平滑，EMA等。</p>
</li>
</ol>
<hr>
<h3 id="宏观设计优化"><a href="#宏观设计优化" class="headerlink" title="宏观设计优化"></a>宏观设计优化</h3><h4 id="改变各个阶段的计算占比"><a href="#改变各个阶段的计算占比" class="headerlink" title="改变各个阶段的计算占比"></a>改变各个阶段的计算占比</h4><p>我们知道传统ResNet的骨干网络分为4个Stage，每个Stage包含若干个Block，其中4个Stage的Block数量比例为3:4:6:3。而ConvNeXt则使用和Swin-Transfromer的相同Block数量比例，调整为3:3:9:3，结果ResNet-50的准确率从78.8%提升至79.4%。</p>
<h4 id="Patch化的Stem"><a href="#Patch化的Stem" class="headerlink" title="Patch化的Stem"></a>Patch化的Stem</h4><p>改变ResNet的Stem层卷积核参数，设计新的Stem层，思路是模仿Transfromer处理图像的方式，即先把图像以栅格的方式划分成一个个单独的patch再进行处理。在ConvNeXt中具体做法是使用stride=4， size=4的卷积核进行卷积，这样滑窗之间不再交集，效果就类似于Transfromer的patch划分，这一操作将准确率获得了0.1%的提升，准确率来到79.5%，更大的stride也降低了计算成本，GFLOPs从4.5降到4.4。</p>
<h4 id="分组卷积（ResNeXt化）"><a href="#分组卷积（ResNeXt化）" class="headerlink" title="分组卷积（ResNeXt化）"></a>分组卷积（ResNeXt化）</h4><p>使用与MobileNet的深度可分离卷积类似的卷积策略，不同的是MobileNet是每个通道单独进行卷积，再通过点卷积融合通道间的信息，ConvNeXt的分组卷积则是把所有通道分为若干组，以组为单位进行卷积，以上卷积思路来自于作者的另一个作品ResNeXt。得益于分离卷积卷积核通道数低的优势，分组卷积GFLOPs从4.4降到了2.4，但准确率降到了78.3%。为了使准确率回升，ConvNeXt把ResNet-50的基础通道数从64增加至96。理所当然的GFLOPs再次增加到了5.3，不过准确率提升到了80.5%。</p>
<h4 id="使用逆瓶颈层"><a href="#使用逆瓶颈层" class="headerlink" title="使用逆瓶颈层"></a>使用逆瓶颈层</h4><p>使用了类似于MobileNetv2中的逆瓶颈层，即按升维-深度卷积-降维的顺序进行卷积操作，值得一说的是ConvNeXt还额外提供了一种不同的逆瓶颈结构，它把深度卷积的顺序提到了首位，这样做是为了后面使用与Swin-Transfromer同样大小的卷积，方便对比的同时防止参数量上升。瓶颈/逆瓶颈的结构可参考下图3[1]。</p>
<img src="/4004cc9d/3.jpg" class>
<p>图3. (a) ResNeXt的瓶颈层架构，(b) ConvNeXt的逆瓶颈层架构，(c)ConvNeXt逆瓶颈结构2</p>
<p>使用逆瓶颈结构的Block后，准确率获得了0.1%的提升，达到80.6%。</p>
<h4 id="更大卷积核"><a href="#更大卷积核" class="headerlink" title="更大卷积核"></a>更大卷积核</h4><p>主要用于对齐Swin-Transfromer、方便比较，在深度卷积中使用同样是7x7的卷积核，无提升。</p>
<hr>
<h3 id="微观优化"><a href="#微观优化" class="headerlink" title="微观优化"></a>微观优化</h3><h4 id="ReLU替换为GELU"><a href="#ReLU替换为GELU" class="headerlink" title="ReLU替换为GELU"></a>ReLU替换为GELU</h4><p>主要为了对齐Swin-Transfromer,方便对比，作者论文指出效果几乎一样（Swin-Transfromer使用GELU）。</p>
<h4 id="更少的激活函数"><a href="#更少的激活函数" class="headerlink" title="更少的激活函数"></a>更少的激活函数</h4><p>Swin-Transfromer的MLP Block中只有一个激活函数，效仿这种设计ConvNeXt也只在逆瓶颈Block中的两个1x1卷积之间使用一层激活层，其他位置删除，有趣的是，这反而带来了0.7个点的提升，准确率来到了81.3%。作者认为可能是过多的非线性计算干扰了特征信息的传递</p>
<h4 id="更少的归一化层以及BN替换为LN"><a href="#更少的归一化层以及BN替换为LN" class="headerlink" title="更少的归一化层以及BN替换为LN"></a>更少的归一化层以及BN替换为LN</h4><p>前者原理同1.4.2。准确率提高了0.1%,达到81.4%。后者则是模仿Transfromer，不过通常来说CNN仅在BN由于样本少出现问题的时候会使用LN，因为LN可能带来性能的下降。出乎意料的是，在ConvNext中（即通过上面的优化后），LN直接替换BN反而带来了0.1%的提升，模型的准确率提升至81.5%。</p>
<h4 id="分离降采样层"><a href="#分离降采样层" class="headerlink" title="分离降采样层"></a>分离降采样层</h4><p>模仿Swin-Transfromer使用与其他运算分离的单独降采样层，具体做法是使用一个stride=2的 size=2的卷积插入到4个Stage之间。为保持模型稳定性，在采样前后街进行归一化操作，这项优化带来了0.5%的提升，模型的准确率提升至82.0% 。</p>
<p>最后整合以上的优化，ConvNeXt的Block的结构如下图4[1]（b）。</p>
<img src="/4004cc9d/4.png" class>
<p>图4： （a）ResNet单个Block （b）ConvNeXt单个Block</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>ViT（Vision Transfromer）是近来CV领域的研究热门方向之一，对传统的CNN研究产生了一定的冲击，ConvNeXt的提出可以说为CNN打了一次“漂亮的反击战”，然而ConvNext更值得一说的是论文中的模型调参思路，精妙的思路使得整篇论文更像是一个“手把手的模型调参教学”，令读者赏心悦目，深受启发。</p>
<p>ConvNeXt代码：<a href="https://github.com/facebookresearch/ConvNeXt">GitHub - facebookresearch/ConvNeXt: Code release for ConvNeXt model</a> </p>
<hr>
<h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><p>[1] Liu, Zhuang, et al. “A ConvNet for the 2020s.” arXiv preprint arXiv:2201.03545 (2022).</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11174">https://www.scholat.com/teamwork/showPostMessage.html?id=11174</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>CS231n: Convolutional Neural Networks for Visual Recognition [2017]</title>
    <url>/7e88b2e5.html</url>
    <content><![CDATA[<h3 id="CS231n简介"><a href="#CS231n简介" class="headerlink" title="CS231n简介"></a>CS231n简介</h3><p>CS231n的全称是<a href="http://vision.stanford.edu/teaching/cs231n/index.html">CS231n: Convolutional Neural Networks for Visual Recognition</a>，即面向视觉识别的卷积神经网络。该课程是<a href="http://vision.stanford.edu/index.html">斯坦福大学计算机视觉实验室</a>推出的课程。</p>
<p><strong>课程描述：</strong>请允许我们引用课程主页上的官方描述如下。</p>
<p>计算机视觉在社会中已经逐渐普及，并广泛运用于搜索检索、图像理解、手机应用、地图导航、医疗制药、无人机和无人驾驶汽车等领域。而这些应用的核心技术就是图像分类、图像定位和图像探测等视觉识别任务。近期神经网络（也就是“深度学习”）方法上的进展极大地提升了这些代表当前发展水平的视觉识别系统的性能。</p>
<p>本课程将深入讲解深度学习框架的细节问题，聚焦面向视觉识别任务（尤其是图像分类任务）的端到端学习模型。在10周的课程中，学生们将会学习如何实现、训练和调试他们自己的神经网络，并建立起对计算机视觉领域的前沿研究方向的细节理解。最终的作业将包括训练一个有几百万参数的卷积神经网络，并将其应用到最大的图像分类数据库（ImageNet）上。我们将会聚焦于教授如何确定图像识别问题，学习算法（比如反向传播算法），对网络的训练和精细调整（fine-tuning）中的工程实践技巧，指导学生动手完成课程作业和最终的课程项目。本课程的大部分背景知识和素材都来源于<a href="https://image-net.org/challenges/LSVRC/2014/index">ImageNet Challenge</a>竞赛。</p>
<span id="more"></span>

<p><strong>课程内容：</strong>课程视频请在Youtube上查看Andrej Karpathy创建的<a href="https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC">播放列表</a>，或是B站搜索。通过查看官方课程表，我们可以看到：CS231n课程资源主要由<strong>授课视频与PPT</strong>，<strong>授课知识详解笔记</strong>和<strong>课程作业</strong>三部分组成。其中：</p>
<ul>
<li><strong>授课视频15课。</strong>每节课时约1小时左右，每节课一份PPT。</li>
<li><strong>授课知识详解笔记共9份。</strong>光看课程视频是不够的，深入理解课程笔记才能比较扎实地学习到知识。</li>
<li><strong>课程作业3次。</strong>其中每次作业中又包含多个小作业，完成作业能确保对于课程关键知识的深入理解和实现。</li>
<li><strong>课程项目1个。</strong>这个更多是面向斯坦福的学生，组队实现课程项目。</li>
<li><strong>拓展阅读若干。</strong>课程推荐的拓展阅读大多是领域内的经典著作节选或论文，推荐想要深入学习的同学阅读。</li>
</ul>
<p><strong>课程评价：</strong>具体如何，大家搜搜CS231n在网络在知乎上的评价！个人认为：入门深度学习CV方向的一门良心课。适合绝大多数想要学习深度学习CV知识的人。</p>
<p><strong>课程不足：</strong>课程后期从RCNN开始就没有课程笔记。</p>
<hr>
<h3 id="课程学习方法"><a href="#课程学习方法" class="headerlink" title="课程学习方法"></a>课程学习方法</h3><p>三句话总结：</p>
<ul>
<li><strong>看授课视频形成概念，发现个人感兴趣方向。</strong></li>
<li><strong>读课程笔记理解细节，夯实工程实现的基础。</strong></li>
<li><strong>码课程作业实现算法，积累实验技巧与经验。</strong></li>
</ul>
<p>引用一下学习金字塔的图，意思大家都懂的：</p>
<img src="/7e88b2e5/1.png" class>

<hr>
<h3 id="CS231n-授课视频"><a href="#CS231n-授课视频" class="headerlink" title="CS231n 授课视频"></a>CS231n 授课视频</h3><h4 id="Lecture-1"><a href="#Lecture-1" class="headerlink" title="Lecture 1"></a>Lecture 1</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447695714&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-2"><a href="#Lecture-2" class="headerlink" title="Lecture 2"></a>Lecture 2</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447560804&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-3"><a href="#Lecture-3" class="headerlink" title="Lecture 3"></a>Lecture 3</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447563868&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-4"><a href="#Lecture-4" class="headerlink" title="Lecture 4"></a>Lecture 4</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447556732&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-5"><a href="#Lecture-5" class="headerlink" title="Lecture 5"></a>Lecture 5</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447555993&page=5" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-6"><a href="#Lecture-6" class="headerlink" title="Lecture 6"></a>Lecture 6</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447568935&page=6" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-7"><a href="#Lecture-7" class="headerlink" title="Lecture 7"></a>Lecture 7</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447612655&page=7" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-8"><a href="#Lecture-8" class="headerlink" title="Lecture 8"></a>Lecture 8</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447677759&page=8" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-9"><a href="#Lecture-9" class="headerlink" title="Lecture 9"></a>Lecture 9</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447667193&page=9" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-10"><a href="#Lecture-10" class="headerlink" title="Lecture 10"></a>Lecture 10</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447674151&page=10" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-11"><a href="#Lecture-11" class="headerlink" title="Lecture 11"></a>Lecture 11</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447668946&page=11" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-12"><a href="#Lecture-12" class="headerlink" title="Lecture 12"></a>Lecture 12</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447691092&page=12" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-13"><a href="#Lecture-13" class="headerlink" title="Lecture 13"></a>Lecture 13</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447688695&page=13" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-14"><a href="#Lecture-14" class="headerlink" title="Lecture 14"></a>Lecture 14</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447684396&page=14" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-15"><a href="#Lecture-15" class="headerlink" title="Lecture 15"></a>Lecture 15</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447695286&page=15" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h4 id="Lecture-16"><a href="#Lecture-16" class="headerlink" title="Lecture 16"></a>Lecture 16</h4><iframe src="//player.bilibili.com/player.html?aid=976948078&bvid=BV1D44y1Y7v8&cid=447695292&page=16" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="CS231n-课程笔记"><a href="#CS231n-课程笔记" class="headerlink" title="CS231n 课程笔记"></a>CS231n 课程笔记</h3><h4 id="Note-1"><a href="#Note-1" class="headerlink" title="Note 1"></a>Note 1</h4><p>原文：<a href="https://cs231n.github.io/python-numpy-tutorial/">python/numpy tutorial</a></p>
<p>翻译：<a href="https://zhuanlan.zhihu.com/p/20878530">Python Numpy教程</a></p>
<p>我们将使用Python编程语言来完成本课程的所有作业。Python是一门伟大的通用编程语言，在一些常用库（numpy, scipy, matplotlib）的帮助下，它又会变成一个强大的科学计算环境。我们期望你们中大多数人对于Python语言和Numpy库比较熟悉，而对于没有Python经验的同学，这篇教程可以帮助你们快速了解Python编程环境和如何使用Python作为科学计算工具。</p>
<h4 id="Note-2"><a href="#Note-2" class="headerlink" title="Note 2"></a>Note 2</h4><p>原文：<a href="https://cs231n.github.io/python-numpy-tutorial/">image classification notes</a></p>
<p>翻译：图像分类笔记<a href="https://zhuanlan.zhihu.com/p/20894041">（上）</a><a href="https://zhuanlan.zhihu.com/p/20900216">（下）</a></p>
<p>该笔记是一篇介绍性教程，面向非计算机视觉领域的同学。教程将向同学们介绍图像分类问题和数据驱动方法，内容列表：</p>
<ul>
<li>图像分类、数据驱动方法和流程</li>
<li>Nearest Neighbor分类器</li>
<li>k-Nearest Neighbor 译者注：上篇翻译截止处</li>
<li>验证集、交叉验证集和超参数调参</li>
<li>Nearest Neighbor的优劣</li>
<li>小结：应用kNN实践</li>
<li>拓展阅读</li>
</ul>
<h4 id="Note-3"><a href="#Note-3" class="headerlink" title="Note 3"></a>Note 3</h4><p>原文：<a href="https://cs231n.github.io/linear-classify/">linear classification notes</a></p>
<p>翻译：线性分类笔记<a href="https://zhuanlan.zhihu.com/p/20918580">（上）</a><a href="https://zhuanlan.zhihu.com/p/20945670">（中）</a><a href="https://zhuanlan.zhihu.com/p/21102293">（下）</a></p>
<p>我们将要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：一个是<strong>评分函数（score function）</strong>，它是原始图像数据到类别分值的映射。另一个是<strong>损失函数（loss function）</strong>，它是用来量化预测分类标签的得分与真实标签之间一致性的。该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。内容列表：</p>
<ul>
<li>线性分类器简介</li>
<li>线性评分函数</li>
<li>阐明线性分类器</li>
<li>损失函数<ul>
<li>多类SVM</li>
<li>Softmax分类器</li>
<li>SVM和Softmax的比较</li>
</ul>
</li>
<li>基于Web的可交互线性分类器原型</li>
<li>小结</li>
</ul>
<h4 id="Note-4"><a href="#Note-4" class="headerlink" title="Note 4"></a>Note 4</h4><p>原文：<a href="https://cs231n.github.io/optimization-1/">optimization notes</a></p>
<p>翻译：最优化笔记<a href="https://zhuanlan.zhihu.com/p/21360434">（上）</a><a href="https://zhuanlan.zhihu.com/p/21387326">（下）</a></p>
<p>该笔记介绍了图像分类任务的第三个关键部分：最优化。内容列表如下：</p>
<ul>
<li>简介</li>
<li>损失函数可视化</li>
<li>最优化<ul>
<li>策略#1：随机搜索</li>
<li>策略#2：随机局部搜索</li>
<li>策略#3：跟随梯度 译者注：上篇截止处</li>
</ul>
</li>
<li>梯度计算<ul>
<li>使用有限差值进行数值计算</li>
<li>微分计算梯度</li>
</ul>
</li>
<li>梯度下降</li>
<li>小结</li>
</ul>
<h4 id="Note-5"><a href="#Note-5" class="headerlink" title="Note 5"></a>Note 5</h4><p>原文：<a href="https://cs231n.github.io/optimization-2/">backprop notes</a></p>
<p>翻译：<a href="https://zhuanlan.zhihu.com/p/21407711">反向传播笔记</a></p>
<p>该笔记本将帮助读者<strong>对反向传播形成直观而专业的理解</strong>。反向传播是利用链式法则递归计算表达式的梯度的方法。理解反向传播过程及其精妙之处，对于理解、实现、设计和调试神经网络非常关键。内容里列表如下：</p>
<ul>
<li>简介</li>
<li>简单表达式和理解梯度</li>
<li>复合表达式，链式法则，反向传播</li>
<li>直观理解反向传播</li>
<li>模块：Sigmoid例子</li>
<li>反向传播实践：分段计算</li>
<li>回传流中的模式</li>
<li>用户向量化操作的梯度</li>
<li>小结</li>
</ul>
<h4 id="Note-6"><a href="#Note-6" class="headerlink" title="Note 6"></a>Note 6</h4><p>原文：<a href="https://cs231n.github.io/neural-networks-1/">Neural Nets notes 1</a></p>
<p>翻译：神经网络笔记1<a href="https://zhuanlan.zhihu.com/p/21462488">（上）</a><a href="https://zhuanlan.zhihu.com/p/21513367">（下）</a></p>
<p>该笔记介绍了神经网络的建模与结构，内容列表如下：</p>
<ul>
<li>不用大脑做类比的快速简介</li>
<li>单个神经元建模<ul>
<li>生物动机和连接</li>
<li>作为线性分类器的单个神经元</li>
<li>常用的激活函数</li>
</ul>
</li>
<li>神经网络结构<ul>
<li>层组织</li>
<li>前向传播计算例子</li>
<li>表达能力</li>
<li>设置层的数量和尺寸</li>
</ul>
</li>
<li>小节</li>
<li>参考文献</li>
</ul>
<h4 id="Note-7"><a href="#Note-7" class="headerlink" title="Note 7"></a>Note 7</h4><p>原文：<a href="https://cs231n.github.io/neural-networks-2/">Neural Nets notes 2</a></p>
<p>翻译：<a href="https://zhuanlan.zhihu.com/p/21560667">神经网络笔记2</a></p>
<p>该笔记介绍了数据的预处理，正则化和损失函数，内容列表如下：</p>
<ul>
<li>设置数据和模型<ul>
<li>数据预处理</li>
<li>权重初始化</li>
<li>批量归一化（Batch Normalization）</li>
<li>正则化（L2/L1/Maxnorm/Dropout）</li>
</ul>
</li>
<li>损失函数</li>
<li>小结</li>
</ul>
<h4 id="Note-8"><a href="#Note-8" class="headerlink" title="Note 8"></a>Note 8</h4><p>原文：<a href="https://cs231n.github.io/neural-networks-3/">Neural Nets notes 3</a></p>
<p>翻译：神经网络笔记3<a href="https://zhuanlan.zhihu.com/p/21741716">（上）</a><a href="https://zhuanlan.zhihu.com/p/21798784">（下）</a></p>
<p>该笔记讲解了神经网络的动态部分，即神经网络学习参数和搜索最优超参数的过程。内容列表如下：</p>
<ul>
<li>梯度检查</li>
<li>合理性（Sanity）检查</li>
<li>检查学习过程<ul>
<li>损失函数</li>
<li>训练集与验证集准确率</li>
<li>权重：更新比例</li>
<li>每层的激活数据与梯度分布</li>
<li>可视化 译者注：上篇翻译截止处</li>
</ul>
</li>
<li>参数更新<ul>
<li>一阶（随机梯度下降）方法，动量方法，Nesterov动量方法</li>
<li>学习率退火</li>
<li>二阶方法</li>
<li>逐参数适应学习率方法（Adagrad，RMSProp）</li>
</ul>
</li>
<li>超参数调优</li>
<li>评价<ul>
<li>模型集成</li>
</ul>
</li>
<li>总结</li>
<li>拓展引用</li>
</ul>
<h4 id="Note-9"><a href="#Note-9" class="headerlink" title="Note 9"></a>Note 9</h4><p>原文：<a href="https://cs231n.github.io/convolutional-networks/">ConvNet notes</a></p>
<p>翻译：<a href="https://zhuanlan.zhihu.com/p/22038289">卷积神经网络笔记</a></p>
<p>内容列表：</p>
<ul>
<li>结构概述</li>
<li>用来构建卷积神经网络的各种层<ul>
<li>卷积层</li>
<li>汇聚层</li>
<li>归一化层</li>
<li>全连接层</li>
<li>将全连接层转化成卷积层</li>
</ul>
</li>
<li>卷积神经网络的结构<ul>
<li>层的排列规律</li>
<li>层的尺寸设置规律</li>
<li>案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）</li>
<li>计算上的考量</li>
</ul>
</li>
<li>拓展资源</li>
</ul>
<hr>
<h3 id="CS231n-课程作业"><a href="#CS231n-课程作业" class="headerlink" title="CS231n 课程作业"></a>CS231n 课程作业</h3><h4 id="Assignment-1"><a href="#Assignment-1" class="headerlink" title="Assignment 1"></a>Assignment 1</h4><p>原文：<a href="https://cs231n.github.io/assignments2016/assignment1/">Assignment #1</a></p>
<p>翻译：<a href="https://zhuanlan.zhihu.com/p/21441838">CS231n课程作业#1简介</a></p>
<p>作业内容：实现k-NN，SVM分类器，Softmax分类器和两层神经网络，实践一个简单的图像分类流程。</p>
<h4 id="Assignment-2"><a href="#Assignment-2" class="headerlink" title="Assignment 2"></a>Assignment 2</h4><p>原文：<a href="https://cs231n.github.io/assignments2016/assignment2/">Assignment #2</a></p>
<p>翻译：<a href="https://zhuanlan.zhihu.com/p/21941485">CS231n课程作业#2简介</a></p>
<p>作业内容：练习编写反向传播代码，训练神经网络和卷积神经网络。</p>
<h4 id="Assignment-3"><a href="#Assignment-3" class="headerlink" title="Assignment 3"></a>Assignment 3</h4><p>原文：<a href="https://cs231n.github.io/assignments2016/assignment3/">Assignment #3</a></p>
<p>翻译：<a href="https://zhuanlan.zhihu.com/p/21946525">CS231n课程作业#3简介</a></p>
<p>作业内容：实现循环网络，并将其应用于在微软的COCO数据库上进行图像标注。实现DeepDream等有趣应用。</p>
<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-ViT论文逐段精读-《An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale》</title>
    <url>/b2650d22.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2020-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE.pdf" data-height="500px"></div>

<p><strong>ViT</strong> 论文链接：<a href="https://openreview.net/pdf?id=YicbFdNTTy">https://openreview.net/pdf?id=YicbFdNTTy</a></p>
<span id="more"></span>

<hr>
<h3 id="速览"><a href="#速览" class="headerlink" title="速览"></a>速览</h3><h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><p>其实核心问题就是考虑如何把图像数据H<em>W</em>C,序列化成一个一个词那种结构，自然就想到将图片crop成一个一个patch，假设有N个patch,维度为p<em>p</em>C,reshape加concate一下就变成个N*p^2C,也就类似词向量。</p>
<hr>
<h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>如下图所示：</p>
<img src="/b2650d22/1.png" class>

<h5 id="图像转序列"><a href="#图像转序列" class="headerlink" title="图像转序列"></a>图像转序列</h5><p>将图片H<em>W</em>C,crop成Ｎ个patch,然后在转换成N*(p^2C),同时为了避免模型结构受到patch size的影响，采用Linear project将不同flatten patchs转换成D维向量。这样的话输入图片数据就成了N*D二维矩阵就和词向量矩阵对应上了。</p>
<img src="/b2650d22/2.png" class>

<h5 id="Position-embeddings"><a href="#Position-embeddings" class="headerlink" title="Position embeddings"></a>Position embeddings</h5><p>作者用一个可学习的embedding向量去将图像位置信息加入到序列中。</p>
<img src="/b2650d22/3.png" class>

<h5 id="learnable-embedding"><a href="#learnable-embedding" class="headerlink" title="learnable embedding"></a>learnable embedding</h5><p>上图中，带*号的粉色框是一个可学习的embedding，记住Xclass,经过encoder后的结果作为整张图像的表示。之所以不用其中一个patch的embedding是因为，这种embedding不可避免带有path的信息，而新增的这个没有语义信息，能更佳反映整张图片。</p>
<img src="/b2650d22/4.png" class>

<h5 id="输入transformer-encoder"><a href="#输入transformer-encoder" class="headerlink" title="输入transformer encoder"></a>输入transformer encoder</h5><p>整个公式如下：</p>
<img src="/b2650d22/5.png" class>

<hr>
<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p>在中等数据集（例如ImageNet），效果不如resnet，但是在大规模数据集上，表现更佳。</p>
<img src="/b2650d22/6.png" class>

<img src="/b2650d22/7.png" class>

<hr>
<p>ViT：过去一年，CV 最有影响力的工作  </p>
<ul>
<li>推翻了 2012 Alexnet 提出的 CNN 在 CV 的统治地位</li>
<li>有足够多的预训练数据，NLP 的 Transformer 搬运到 CV，效果很好 </li>
<li>打破 CV 和 NLP 的壁垒，给 CV、多模态 挖坑</li>
</ul>
<p>ViT效果有多好？</p>
<ul>
<li>CV 任务刷榜</li>
<li>paperwithcode网站 霸榜 ImageNet （基于 ViT）和 COCO ,目标检测（Swin Transformer ICCV 21 best paper：多尺度的 ViT ）的模型</li>
</ul>
<p>四种情况 ViT 都能处理：<br>遮挡、数据分布的偏移（纹理的去除）、鸟头部+对抗的patch、图片打散重新排列组合</p>
<hr>
<h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><p>*<em>An image is worth 16 * 16 words*</em></p>
<p>每一个方格都是 16 * 16 大小，图片有很多 16 * 16 方格 patches –&gt; an image is worth 16 * 16 words</p>
<p>Transformers for image recognition at scale </p>
<p>transformer 去做大规模的图像识别</p>
<p>作者来自 Google research 和 Google brain team</p>
<hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>Transformer 在 NLP 是基本操作，i.e., BERT, GPT3, T5, 但 transformer 在 CV 的应用有限。</p>
<p>CV 里的 attention 是怎么用的呢？<br>attention + CNN, or attention 替换 CNN components 但依然保持 CNN 整体结构。</p>
<p>如何理解 CNN 整体结构不变？<br>ResNet 50 有 4 个 stages (res2 res3 res4 res5), stage 不变，attention 取代 每一个 stage 每一个 block 里的这个操作。</p>
<p>本文怎么看 CV 里的 attention?<br>attention 不用和 CNN 绑在一起，和 我 transformer 组队，在 CV 领域 大杀四方。<br>esp, 大规模数据集做预训练，mid-sized or small 数据集做微调，ViT  SOTA</p>
<p>ViT fewer computational resources to train, really?<br>少的训练资源 ==  TPUv 3 + 2500 天。<br>“fewer” 相对来说</p>
<hr>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>self-attention 架构， esp Transformers，是 NLP 必选模型。主流方式是 BERT 提出的，大规模数据集预训练，在 特定领域的小数据集 做微调。 Transformer 的 计算高效和可扩展性，1000亿参数都还没有 性能饱和 的现象。<br>i.e., MT-N;P 5300亿参数，SOTA，也没有性能饱和的现象。</p>
<p>Transformer 应用在 CV 有<strong>难点</strong>吗？<br>计算像素的 self-attention，序列长，维度爆炸<br>Trnasformer 的计算复杂度是 序列长度 n 的 平方 O（n^2）<br>224 分辨率的图片，有 50176 个像素点，（2d 图片 flatten）序列长度是 BERT 的近 100 倍。</p>
<img src="/b2650d22/8.png" class>

<p>呼应摘要+文献：<strong>CNN 在 CV 领域 火， Transformer, self-attention 在 NLP 领域 火。CV 如何用 attention 呢？</strong><br>CNN 结构 + self-attention or attention 替代卷积</p>
<p>CVPR Wang et al. 2018, Local Network, 网络中的特征图 输入 Transformer<br>ResNet 50 最后一个 stage, res4 的 feature map 14 * 14， 196</p>
<p>降低序列长度的方式：用特征图做 transformer 输入（Wang et al 2018）, replacing the convolutions entirely (Ramachandran et al., 2019 stand-alone attention 孤立自注意力; Wang et al., 2020 axial attention 轴注意力)</p>
<p>stand-alone attention 孤立自注意力<br>用 local window 局部小窗口 控制 transformer 的计算复杂度，有点像 卷积， 卷积也有 locality，局部窗口卷积。</p>
<p>axial attention 轴注意力 –&gt; 2 个 1d 顺序操作，降低计算复杂度<br>图片的序列长度 n = H * W<br>2d 矩阵 拆分为 2个1d 向量，先在 H 高度 dimension 做一次 self-attention，再 W 宽度 dimension 做一次 self-attention</p>
<p><strong>replacing the convolutions entirely 好不好呢？</strong><br>理论高效，但硬件无法加速 –&gt; 此类模型都还没有太大。<br>本段（第二段）总结：在大规模的图像识别上，ResNet 还是效果最好的。</p>
<p><strong>本文 ViT 的工作是什么？</strong><br><strong>现状：</strong>attention 已经在 CV 领域有应用，甚至也有 attention 替代卷积的操作<br><strong>讲故事的角度：</strong>Inspired by the Transformer scaling 可扩展性 success in NLP, we experiment with applying a standard Transformer directly to images, with the fewest possible modifications.<br>标准 Transformer 直接应用于图片，做最少的修改，不做任何针对视觉任务的特定的改变。</p>
<p>The fewest possible modifications 是什么呢？<br>把图片划分成很多 patches，每个 patch 元素 是 16 * 16，序列长度 14 * 14 = 196个元素</p>
<p>每一个 patch 经过一个 FC layer(fully connected layer)得到一个 linear embedding，patches 的 linear embeddings 是 Transformer 的输入。</p>
<p>一个 224 * 224 图片 变成一个 196 个的 16 * 16 图片块（words in NLP）。</p>
<p><strong>为什么 transformer 的训练是 supervised fashion？</strong><br>NLP 的 Transformer 无监督训练 by language model LM or mask language model MLM；CV 任务的 benchmark 使用有监督训练。 </p>
<p>ViT 把 CV 任务当成 NLP 任务，模型使用的是 BERT, Transformer encoder 简洁框架。Transformer 在视觉也有很好的效果。</p>
<p><strong>Transformer in CV，之前有人做吗？</strong><br>ICLR 2020 从输入图片里抽取 2 * 2 patches。 2 * 2 size enough：CIFAR-10 32 * 32 图片，16 * 16 会过大。 抽好 patch 之后，在 patches 上 做 self-attention。 –&gt; 技术上的 Vision Transformer</p>
<p>*<em>ViT 和 ICLR 2 * 2 patches 的区别？*</em></p>
<ul>
<li>ViT证明了 大规模数据集预训练 （NLP 常用）之后的 Transformer，不需要做 针对视觉任务的 修改，比最好的 CNNs 效果差不多 or 甚至更好。</li>
<li>2 * 2 patches applicable only to small-resolution images, ViT handles medium-resolution images as well. </li>
<li>ViT 告诉大家，Transformer 在 vision 领域能拓展到有多好。large 数据集 + large 模型，transformer 能否取代 CNN 地位？</li>
</ul>
<p><strong>引言的最后：</strong><br>最想说的结论 or 最想展示的结果：卖点，不用看完整篇论文，就知道此篇论文的贡献。</p>
<p><strong>ViT 任何情况都很强吗？</strong><br>No<br>mid-sized datasets ImageNet without strong regularization，ViT 比 ResNet of comparable size 弱几个点。</p>
<p><strong>Why 弱？ expected</strong><br>Transformer 比 CNN 少 inductive biases 归纳偏置<br>inductive biases 归纳偏置：先验知识 or 提前的假设<br>CNN 的 inductive biases 是 locality 和 平移等变性 translation equaivariance（平移不变性 spatial invariance）。</p>
<p>locality: CNN用滑动窗口在图片上做卷积。假设是图片相邻的区域有相似的特征。i.e., 桌椅在一起的概率大，距离近的物品 相关性越强。</p>
<p>translation equaivariance：f(g(x)) = g(f(x))<br>f 和 g 函数的顺序不影响结果。<br>f：卷积 g：平移; 无论先做平移 g 还是先做卷积 f , 最后结果一样。<br>CNN 的卷积核 像一个 template 模板，同样的物体无论移动到哪里，遇到了相同的卷积核，它的输出一致。</p>
<p>CNN 有 locality 和 translation equivariance 归纳偏置，–&gt; CNN 有 很多先验信息 –&gt; 需要较少的数据去学好一个模型。</p>
<p>Transformer 没有这些先验信息，只能 从图片数据里，自己学习对 视觉世界 的感知。</p>
<p><strong>怎么验证 Transformer 无 inductive bias 的假设？</strong><br>在 1400万(ImageNet-21K) - 3000 万(JFT-300)得到图片数据集上预训练 trumps inductive bias, ViT +足够训练数据，CV SOTA。</p>
<p>VTAB 融合了 19 个数据集，检测模型的稳健性，ViT的 robustness 也很好。</p>
<p><strong>引言总结：</strong><br><strong>第一段：</strong>Transformer 在 NLP 扩展的很好，没有因为大模型和大数据集而饱和，performance 一直有提升，Transformer 在 CV 里能不能也有大幅度的提升呢？<br><strong>第二段：</strong>前人工作。这么好的 idea 有哪些人做过呢？要讲清楚自己的工作和 related works 的区别<br>之前的工作是 CNN + attention 或者 attention 替代 convolutions，没有工作将 transformer 用到 CV 领域，没有得到很好的扩展效果。<br><strong>第三段：</strong>Vision Transformer 是 standard Transformer with the fewest possible modifications<br>对图片的最少修改是什么？<br>图片变成 16 * 16 的像素块 patches，经过 一个 fc layer 得到的 linear embeddings 输入 transformer<br>ViT 融合了 CV 和 NLP 领域。<br><strong>第四+五段：</strong>show 结果<br>足够多的数据集，ViT 能 SOTA</p>
<hr>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>explored the direct application of Transformers to image recognition. 直接 用 NLP 的 Transformer 来处理图片。</p>
<p><strong>和其它 self-attention in CV 的工作不同：</strong>除了将图片转成 16 * 16 patches + 位置编码 之外，没有额外引入 图像特有的 inductive bias</p>
<p><strong>没有图片的 inductive bias 的好处是什么？</strong><br>不需要对 vision 领域的了解，不需要 domain knowledge，直接把 图片理解成 a sequence of patches, i.e., 一个句子里的很多单词。<br>An image is worth 16 * 16 words. </p>
<p>直接用 NLP 里的 Transformer encoder， simple yet scalable，大规模预训练数据集，效果非常好。</p>
<p><strong>ViT 效果有多好？</strong><br>image classification SOTA, relatively cheap to pre-train</p>
<p><strong>ViT 没有解决的问题？</strong><br>文章挖坑：新问题 or 新模型<br>ViT 挖坑：新模型 ViT<br>**future directions: **新问题 —— CV 除了 image classfication 其他的任务，行不行呢？分割、检测</p>
<p>DETR (Carion et al. 2020) 目标检测的力作，改变了目标检测 出框的方式。ViT 做其它 CV 任务应该效果也很好。</p>
<p>2020年 12 月(ViT 1.5月之后)<br>ViT-FRCNN 检测 detection<br>SETR 分割 segmentation （CVPR 论文 11.15完成写作投稿）<br>（3个月后）Swin Transformer 融合 Transformer 和多尺度设计 </p>
<p>Transformer 是 CV 领域的一个通用的骨干网络 backbone<br>另外一个未来工作方向，自监督的预训练方式。<br>NLP 大的 transformer 模型使用 自监督 预训练，ViT有 initial experiments 证明 自监督预训练也可以，但和有监督的训练有差距 still large gap。</p>
<p>把 ViT 变得很大，would likely lead to improved performance。scaling ViT, ViT-G, ImageNet 90 +%</p>
<p>ViT 挖坑：</p>
<ul>
<li>视觉领域 CV</li>
<li>多模态，一个 transformer 处理 CV 和 NLP</li>
</ul>
<hr>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>Transformer 在 NLP 领域的应用：BERT, GPT<br>Transformer 先在大规模语料库上做预训练，再根据具体的任务数据集进行微调。<br>BERT: denosing mask挖词、完形填空，把masked的词预测出来<br>GPT: language modelling, 预测下一个词 next word prediction<br>完形填空 or 预测下一个词，人为设定。语料句子是完整的，去掉某些词（完形填空） or 最后词（预测下一个词） –&gt; 自监督的训练方式。</p>
<p>self-attention 在视觉领域的应用</p>
<p>self-attention to each pixel：❌<br>224 * 224 image: O(n^2 = 50176)<br>1k, 4k image: 维度爆炸</p>
<p>self-attention to each image with approximations： </p>
<ul>
<li>不用整张图，只用 local neighborhoods，降低序列长度</li>
</ul>
<p>sparse transformer</p>
<ul>
<li>全局注意力的近似</li>
<li>只对 稀疏的点 做注意力</li>
</ul>
<p>scale attention by applying attention in blocks of varying size</p>
<ul>
<li>把自注意力用到不同大小的 blocks</li>
<li>in the extreme case only along individual axes 极端情况，只关心轴， axial self-attention，横轴 + 纵轴</li>
</ul>
<p>小结：以上 self-attention + CV 效果不错，但工程实现加速很难。可在 cpu gpu跑，但大规模训练不行。</p>
<p><strong>和 ViT 最相似的工作：</strong><br>ICLR 2020 2 * 2 patches for CIFAR-10 32 * 32 图片<br><strong>ViT 胜在哪里：</strong>更大的 patches 16 *16 + 更大的训练数据集</p>
<p>CV 中 检测、分类、视频处理、多模态 self-attention with CNNs</p>
<p><strong>另一个相似工作：image GPT</strong><br>GPT 是 NLP 的生成模型，image GPT 无监督预训练，生成模型。</p>
<p>image GPT 也用了 transformer 图片（降低分辨率和 color space）。用训练好的 image GPT or 直接把 image GPT 当成特征提取器， ImageNet 准确率 72%；ViT ImageNet 准确率 88.5%</p>
<p><strong>ps：最近爆火的 MAE</strong><br>在 BEiT 或 MAE 论文之前，生成式网络 在 CV 比 判别式网络 弱很多。<br>MAE 生成式模型 在 ImageNet-1k 做训练，比判别式模型好。分类 ✔，目标检测 ✔ （transfer learning）</p>
<p>还有其它和 ViT 相似的工作吗？</p>
<ul>
<li>用比 ImageNet 还大的数据集做预训练，大力出奇迹</li>
<li>Sun et al 2017 JFT-300M 数据集，CNN 的效果随数据集增加而提升</li>
<li>Djolonga et al 2020 研究大数据集预训练迁移到小数据集的效果 </li>
<li>在 ImageNet-21K 或 JFT-300M 数据集做预训练，迁移到 ImageNet 或 CIFAR-100 效果怎么样</li>
</ul>
<p>本文 ViT 和这些相似论文的关系？<br>ViT 关注 ImageNet-21K 或 JFT-300M 数据集， 不训练 ResNet，训练 Transformer</p>
<p>Related work 写作总结：<br>方方面面相关的都写到了，也列举了非常相似的工作 ICLR 2020 2*2 patches, image GPT 生成模型，大数据集 BIT 相关的文章</p>
<p>Related work 目的：<br>让读者知道在你的工作之前，别人做了哪些工作，你跟他们的区别在哪里</p>
<p>related work 章节的详细不会降低论文的创新性，反而加分，让整个文章变得更简单易懂。</p>
<hr>
<h3 id="ViT模型"><a href="#ViT模型" class="headerlink" title="ViT模型"></a>ViT模型</h3><p>ViT 尽可能使用 original Transformer，享受 Transformer efficient implementations。<br>NLP 中 Transformer 很火，有很多 Transformer 的高效实现</p>
<h4 id="Vision-Transformer-模型图"><a href="#Vision-Transformer-模型图" class="headerlink" title="Vision Transformer 模型图"></a>Vision Transformer 模型图</h4><p>Model overview<br>好图：以图读论文，讲解 ViT 直接复制</p>
<img src="/b2650d22/9.png" class>

<p><strong>Input:</strong> 1 张图<br><strong>Process:</strong> 九宫格 9 patches –&gt; Flattened Patches (3 * 3 –&gt; 1 * 9 拍平) –&gt; Linear Projections —&gt; Patch embedding<br><strong>Why need position embedding?</strong><br>self-attention 所有元素两两算自注意力，和顺序位置无关。但图片的 patches 是有顺序的，+ position embedding</p>
<p>Patch embedding + position embedding == token 包含 图片 patch 信息 和 patch 在原图中的位置信息。</p>
<p><strong>ViT 对 图片的操作：</strong> 划分 patches，flatten patches 的线性投影 + patches 的位置信息，得到输入 transformer 的 tokens</p>
<p>得到 tokens 之后，对 visual tokens 进行 NLP 操作：<br>tokens 传入 Transformer encoder，得到很多输出。</p>
<p><strong>Q: 每一个 token 都有输出，用哪个输出分类呢？</strong><br>借鉴 BERT， extra learnable {class} embedding –&gt;, a special classification token, * in figure 1.<br>也有 position embedding, 0(永远是0)</p>
<p><strong>Q: Why works？self-attention O(n^2)</strong><br>self-attention in transformer encoder，所有的 tokens 在做两两的交互信息。因此，也会和所有的 图片 patches 的 token 交互，从而从图片 patches + position 的 embedding 学到有用信息，最后用做分类判断。</p>
<p><strong>Q: 从怎么得到最后的分类？ 通用MLP Head</strong><br>输入 一个通用的 MLP Head，得到 Class，cross-entropy 损失函数训练模型。</p>
<p><strong>Q: ViT 用了标准的 transformer 结构，ViT的特点是什么？</strong><br>图片 patches 化 + position embedding 转化为 tokens</p>
<p><strong>ViT 前向过程</strong><br><strong>Vision 问题 变成 NLP 问题</strong></p>
<p>图片 X： 224 * 224 * 3 (RGB, 3 channels)<br>patches 数 N： 224 ^ 2 /  16 ^ 2 = 14 ^ 2 = 196<br>每一个 patch 的维度：16 * 16 * 3 (RGB, 3 channels) = 768<br>Linear Projection 全连接层 E: 768( 不变，patch 计算而来 ) * D(embedding_dim) 768 或 更大<br>图片 X * E = patches (196 patches 个数 * 768 每个 patch 的维度) * E ( 768 * D ) = 196 * D (768)</p>
<img src="/b2650d22/10.png" class>

<p>**Vision to NLP done! **<br>a 2d image –&gt; a sequence 1d tokens </p>
<p><strong>Q: 进入 transformer encoder 的序列长度？</strong><br>196 * 768(图片对应的 tokens) 拼接 concatenate [CLS] token (1 * 768) = 197 * 768</p>
<p><strong>Q: position embedding 怎么加 patch embedding？sum()</strong><br>图1 的 1-9 不是真正使用的 position embedding，实际的 position embedding 表，1 - 5 行 代表 图1 的 1 - 5 值。<br>每行向量的维度是 1 * 768<br><strong>相加 sum：</strong><br>patch embedding（197 * 768） + position embedding （(1 CLS + 196 patches) * 768）= （197 * 768）</p>
<img src="/b2650d22/11.png" class>

<p>ViT base: 12 heads<br>MLP：放大 4 倍，再缩小到原维度大小<br>Transfomer encoder 输入输出维度一致，可以直接叠加 L 个</p>
<img src="/b2650d22/12.png" class>

<hr>
<h4 id="Vision-Transformer正文"><a href="#Vision-Transformer正文" class="headerlink" title="Vision Transformer正文"></a>Vision Transformer正文</h4><p>公式的具体值计算，参考上一小节。<br>有了具体含义的公式字符，也不那么可怕了呢 o(<em>￣▽￣</em>)ブ</p>
<p>ViT 用的是 BERT 1d position embedding，图片 2d aware position embedding 结果也差不多。</p>
<p><strong>D.3 Head type and class token 作者的消融实验</strong><br>ViT 除了标准的 transformer，关键部分是 怎么对图片进行预处理 和 怎么对图片最后的输出进行后处理。</p>
<p><strong>class token：证明 标准的 transformer 做视觉，没问题！</strong><br>控制和 NLP 的差异：使用 BERT 的 CLS，CLS 在 NLP 理解为 一个全局的对句子理解的特征；ViT 的 CLS 理解为 一个图像的整体特征。</p>
<p>CLS token + MLP (tanh acitvation) == 分类</p>
<p>CV 通常的 全局特征：i.e., Res50<br>feature map (14 * 14) –&gt; GAP globally average-pooling 全局平均池化 –&gt; a flatten vector 全局的图片特征向量 –&gt; MLP 分类</p>
<p>类似的，Transformer 的 输出元素 + GAP 可以用做全局信息 + 分类吗？ Ok</p>
<p><strong>CV 的 CLS GAP 和 NLP 的 CLS 效果差异不大。</strong></p>
<p>CLS-Token 和 GAP 的 适用参数 不一样。</p>
<p><strong>位置编码： 1d 2d relative 无所谓</strong></p>
<p><strong>1d：</strong>NLP 1, 2, 3, …, 9 D<br><strong>2d：</strong>D / 2 * D / 2<br>11 12 13<br>21 22 23<br>31 32 33</p>
<img src="/b2650d22/13.png" class>

<p><strong>relative: offset</strong><br>绝对距离转相对距离，1 - 9 和 -4, …, 0, …, 4</p>
<p><strong>为啥都是 0.64 左右，无所谓？</strong><br>ViT 直接作用于 14 * 14 patches，而不是 224 * 224 像素。较少数量的 patches 之间的相对位置信息，容易学到。</p>
<hr>
<h4 id="ViT-正文-CLS-continued"><a href="#ViT-正文-CLS-continued" class="headerlink" title="ViT 正文 CLS continued"></a>ViT 正文 CLS continued</h4><p>CLS 可用 GAP global average pooling 替换<br>1d position embedding 可用 2d or relative 替换</p>
<p>ViT 对齐 标准的 transformer，选用 NLP 里常用的 CLS 和 1d position embedding</p>
<p>Appendix: Transformer multi-head 解释，i.e., 卷积解释 in CNN papers</p>
<p><strong>公式总结 ViT 的前向传播过程</strong></p>
<img src="/b2650d22/14.png" class>

<p><strong>Inductive bias</strong></p>
<p>CNN 的 inductive bias: locality 局部性, translation equivalence 平移等变性。在 CNN 模型每一层都有所体现，==》模型的先验知识从头到尾，贯穿整个模型。</p>
<p><strong>ViT 比 CNN 的 inductive bias 少, only MLP</strong><br>In ViT, only MLP layers are local and translationally equivariant, <strong>while the self-attention layers are global.</strong></p>
<p>ViT 的 inductive bias in images：<br>图片 切成 patches；+ position embedding（随机初始化，没有携带 2d 位置信息）</p>
<p>ViT 的 patches 块的 2d 位置信息 + spatial relations 图像块之间的场景信息，都需要重新学。 ==》 <strong>ViT 没有很多 inductive bias</strong> ==》中小型数据集训练 ViT 效果不如 CNN</p>
<p><strong>Hybrid architecture</strong><br>Transformer: 全局建模能力强<br>CNN: data-efficient 不用那么多训练数据</p>
<p>前 CNN + 后 Transformer –&gt; Hybrid archtecture<br><strong>不同的图片预处理方式：</strong>不划分 patches，采用 CNN (Res50 的 feature map 14 * 14 = 196)，过全连接层 <strong>E</strong> Linear projections 得到图片的 embedding</p>
<img src="/b2650d22/15.png" class>

<p><strong>ViT 的图片预处理方式：</strong><br>把一张图划分成 patches，直接过全连接层 fc</p>
<hr>
<h4 id="Fine-tuning-and-higher-resolution"><a href="#Fine-tuning-and-higher-resolution" class="headerlink" title="Fine-tuning and higher resolution"></a>Fine-tuning and higher resolution</h4><p>微调时用大图片尺寸 i.e., 256 * 256， 320 * 320 而不是 224 * 224，效果更好</p>
<p><strong>Q: 预训练好的 ViT 可以在更大尺寸的图片上为条码？</strong><br>if patch size 不变 16 * 16，更大尺寸的图片 –&gt; 序列长度的增加 i.e., 14 * 14 –&gt; 20 * 20 in 320 * 320 image</p>
<p>Transformer 理论上，可以处理任意长度。<br><strong>But，提前训练好的 position embedding 可能失效</strong></p>
<p>1 - 9 的九宫格 图片 patches 位置编码 –&gt;  patches 增多，1 - 25 位置编码</p>
<p><strong>Q: patches 数增多，如何使用 已预训练好的 位置编码呢？</strong><br>2d 插值，torch 的 interpolate 函数实现；但也不是任意长度增加都能保持效果。<br>256 –&gt; 512 –&gt; 768 长度的增加，直接使用差值，最后效果掉点。（采样定理）</p>
<p>插值 interpolate 临时解决方案，ViT 微调时的一个局限。</p>
<p>ViT 用了图片 2d 结构 的 inductive bias 地方：resolution adjustment 尺寸改变 和 patch extraction 抽 patches</p>
<hr>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>对比 ResNet, ViT, Hybrid ViT (CNN 特征图，不是图片直接 patch 化) 的 representation learning capabilities 表征学习能力。</p>
<p>为了了解每个模型预训练好 到底需要多少数据，在不同大小的数据集上预训练，然后在很多 benchmark tasks 做测试。</p>
<p>考虑模型预训练的计算成本时，ViT performs very favourably 表现很好， SOTA + fewer resource 训练时间更少</p>
<p>ViT 的自监督训练，可行，效果也还不错，有潜力；一年之后，MAE 用自监督训练 ViT 效果很好。</p>
<p><strong>4.1 Setup</strong><br><strong>datasets:</strong><br>ImageNet-1K: 1000 classes, 1.3M images<br>ImageNet-21K: 21000 classes, 14M images<br>JFG-300: 303M images Google 不开源</p>
<p>下游任务：分类 CFIAR etc.</p>
<p><strong>Model variants</strong></p>
<p>ViT Base, Large, Huge<br>Layers, Hidden size D, MLP size, Heads 相应增加</p>
<p>模型变体 = (Base, Large, Hugh) + (patch size 表示)<br>ViT-L/16 使用 Large 参数 和 patch 16 * 16 输入</p>
<p>Q: Why patch size in name of model variants?<br>ViT 模型的 patch size 变化时, i.e., 16 * 16 –&gt; 32 * 32 or 8 * 8, 模型的位置编码会变化</p>
<ul>
<li>transformer 输入的序列长度 与 patch size 成反比</li>
<li>patch size 越小，一张图片的 patches 数越多，训练越贵 because of 序列长度的增加</li>
</ul>
<p><strong>结果</strong></p>
<p>ViT-H/4 秀肌肉 刷榜</p>
<img src="/b2650d22/16.png" class>

<p>和 CNN 的工作 BiT-L, Noisy Student 做对比<br><strong>BiT-L:</strong> CNN比较大的模型，ViT论文作者团队自己的工作<br><strong>Noisy Student:</strong> ImageNet 当时表现最好的方法。用 伪标签 pseudo-label 去 self-training</p>
<p>ViT-H/14 训练比 ViT-H/16 贵，效果和 BiT-L 差不多，优势不明显。怎么突出 ViT 的好呢？</p>
<p>ViT 训练更便宜。TPUv3 天数：ViT-H/14 2.5K, BiT-L 9.9K, Noisy Student 12.3K </p>
<p>ViT 优点：效果好 + 训练快</p>
<p><strong>结果分析</strong></p>
<p>Vision Transformer 到底需要多少数据才能训练好？<br>图3 灰色区域 ResNet 的效果，圆圈 ViT 的效果</p>
<p><strong>Take home message: 图 3</strong></p>
<p>如果想用 ViT，至少需要 ImageNet-21K 14M 大小的数据集</p>
<ul>
<li>小于整个数据量，CNN 更合适，更好的利用 inductive bias，ViT 没有特别多 inductive bias 需要更多数据训练。</li>
</ul>
<p>数据集规模比 ImageNet-21K 更大时，Vision Transformer 效果更好，因为可扩展性 scaling 更好。</p>
<img src="/b2650d22/17.png" class>

<p><strong>图 4 Linear few-shot evaluation</strong></p>
<p>图 3 ViT 和 ResNet 比，加了强约束：dropout、weight decay、label smoothing，约束了 ViT 的发挥</p>
<p>linear evalution: 把 ViT 预训练好的模型 直接作为 特征提取器，不 fine-tune，+ 一个 logistic regression 得到分类结果。</p>
<p>Few-shot：5-shot，在 ImageNet 做 linear evaluation 时，每类图片随机选取 5 个 samples，evaluation 很快，做 消融实验。</p>
<p>linear few-shot evaluation 采用 JFT 数据集 10M, 30M, 100M, 300M。来自同一个数据集，数据没有 distribution gap，模型的效果更能体现 Vision Transformer 本身特质。</p>
<p>ViT 图4 效果 和 图3 差不多。<strong>如何用 ViT 做小样本学习，未来研究方向之一。</strong></p>
<p><strong>图 5 用 ViT 比 CNNs 便宜 的实验支持</strong><br>大家的印象：Transformer 又大又贵，很难训练</p>
<img src="/b2650d22/18.png" class>

<p>average-5：ImageNet-real, Pets, Flower, CIFAR10, CIFAR100 平均<br>ImageNet 单独的对比</p>
<p>同等计算复杂度：ViT 比 ResNet 效果好，印证了 ViT 训练更便宜</p>
<p><strong>Q: Hybrid 模型，CNN 抽取出来的特征，能不能帮助 Transformer 更好的学习呢？</strong></p>
<ul>
<li>小模型，Hybrid 模型吸收 CNN 和 Transformer 的优点，效果好。不需要很多的数据预训练，达到 Transformer 的效果 </li>
<li>大模型，Hybrid 模型 和 Transformer 差不多，甚至不如 Transformer 模型。<strong>Why？</strong></li>
</ul>
<p><strong>如何 预处理图像，如何做 tokenization 很重要</strong>，后续论文有研究</p>
<p>整体趋势：模型增加，除了 Hybrid 模型有点饱和（饱和：增加到一个平台值后，不增加了）。ResNet 和 Transformer 都没有饱和。</p>
<p><strong>4.5 Inspecting Vision Transformer</strong></p>
<p>可视化分析 ViT 内部表征 internal representations: <strong>Patch embedding, position embedding</strong><br><strong>ViT 第一层 Linear projection E 学到了什么？</strong></p>
<p>Figure 7 (left) embed RGB value 前 28 个主成分</p>
<img src="/b2650d22/19.png" class>

<p>Vision Transformer 和 CNN 学到的很像，类似 gabor filter 有颜色、纹理， 可以做 plausible basis functions，可以描述每个图像块的底层信息 a low-dimensional representation of the fine structure within each patch.</p>
<p><strong>Position embedding 能学到一些表示位置距离的信息</strong></p>
<ul>
<li>patch 自己本身 相似度高 黄色 1</li>
<li>学到了距离的概念<ul>
<li>(4, 4) 黄色中心点，越边缘，相似度越低，颜色越蓝</li>
</ul>
</li>
<li>学到了 行 和 列 的距离规则<ul>
<li>同行同列，颜色条 的表示<br>虽然是 1d 的 position  embedding，但已经学到了 2d 的图像位置概念；所以换成 2d position 提升不多。</li>
</ul>
</li>
</ul>
<img src="/b2650d22/20.png" class>

<p><strong>Self-attention 有没有起作用？</strong></p>
<p>用 Transformer 的原因：自注意力 能模拟长距离的关系。</p>
<ul>
<li>NLP 一个很长的句子里，开头的一个词和结尾的一个词 可能互相有关联。</li>
<li>CV 里 很远的两个像素点之间 也能做自注意力。</li>
</ul>
<p><strong>ViT 的 self-attention 是不是 很远的像素点也能有交互？</strong><br>ViT-L/16 有 24 层（横坐标值），五颜六色的点：transformer 每层 multi-head 的heads，ViT-L 16 heads, 每一列有 16 个点</p>
<img src="/b2650d22/21.png" class>

<p>纵轴是 mean attention distance<br>d_ab = l_ab * A_ab = ab 两点 pixel 之间的距离差 * ab 两点之间的attention weights<br>d_ab 的大小，反映模型能不能注意到很远的 2 个 pixels</p>
<ul>
<li>self-attention 刚开始能注意到 10 - 110 pixels</li>
<li>self-attention 刚开始就注意到全局的信息；CNN 刚开始第一层的感受野 receptive filed 很小，只能看到附近的 pixel</li>
</ul>
<img src="/b2650d22/22.png" class>

<p>网络加深，模型学到的特征越来越 high level，越来越有语义信息，像素的自注意力距离 越来越远，不是靠邻近的像素点做判断。</p>
<p><strong>证明 自注意力 有学到 很远距离的 pixel 信息，证明 by 图6</strong></p>
<p>ViT 最后一层 output 的 token 的 self-attention 折射（逆向映射）回 原来的输入图片。ViT 真的学到了一些概念：狗、飞机</p>
<img src="/b2650d22/23.png" class>

<p>Globally 全局来说，输出的 token 是融合全局的特征信息，ViT 模型可以关注到 和 classfication 分类相关的图像区域。</p>
<p><strong>4.6 self-supervision</strong></p>
<p>如何用 自监督 的方式 训练一个 vision transformer？</p>
<p>很重要，22页全文，别的结果都在 appendix，自监督的结果在正文。</p>
<p>因为 NLP 的 transformer 都是用 large scale self-supervised pre-training <strong>大规模、自监督</strong> 的方式预训练的。</p>
<p><strong>NLP 的 自监督：</strong>BERT 完形填空 Mask language model，GPT 生成，<strong>预测下一个词</strong> by language model</p>
<p>ViT 借鉴 BERT，创建一个专属于 vision 的目标函数，masked patch prediction。一张图片的某些 patches 随机抹掉，ViT 重建缺失的patches</p>
<p>Note：从 模型、目标函数上，CV 和 NLP 的大一统。</p>
<p>但是，ViT-B/16 with masked patch prediction 在 ImageNet <del>80% 准确率。</del>80% 比 从头训练 ViT 好 2%，比 supervised pre-training 低 4%。</p>
<p><strong>ViT 和 contrastive pre-training 的结合： future work</strong> i.e., MOCOv3, DINO</p>
<p><strong>contrastive learning:</strong> 2020 年 CV 最火的 topic，是所有 自监督学习方法表现最好的。</p>
<hr>
<h3 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h3><p>写作：简洁明了、有轻有重（重要结果放正文），图表清晰。</p>
<p>内容：Vision Transformer 挖了一个大坑：各个角度的分析，提升 or 推广</p>
<p>task 任务角度：ViT 只做了分类，检测、分割、其它领域的任务 future work</p>
<p>ViT 结构的角度：</p>
<ul>
<li>改刚开始的 tokenization</li>
<li>改 transformer block, i.e., self-attention 换成 MLP works<ul>
<li>MetaFormer 认为 transformer work 的原因是 transformer 的架构，不是 transformer 某些特殊的算子</li>
<li>MetaFormer，self-attention 改成 （不能学习的）pooling 池化操作；甚至改成 Identity，不用注意力</li>
</ul>
</li>
<li>改 目标函数：有监督、or 不同的自监督训练方式</li>
</ul>
<p>ViT 的大坑：</p>
<ul>
<li>打通了 CV 和 LP 之间的鸿沟</li>
<li>挖了一个更大的<strong>多模态</strong>的坑<ul>
<li>视频、音频、基于 touch 的信号</li>
<li>各种 modality 的信号都可以拿来用</li>
</ul>
</li>
</ul>
<p><strong>CNN, self-attention, MLP 鹿死谁手？</strong><br>犹未可知，期待下一个改进的 vision transformer</p>
<ul>
<li>一个简洁、高效、通用的视觉骨干网络 CV backbone，甚至完全不用任何标注信息</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>CS231n: Convolutional Neural Networks for Visual Recognition [2019中文]</title>
    <url>/5e158075.html</url>
    <content><![CDATA[<h3 id="Lecture-1-Introduction"><a href="#Lecture-1-Introduction" class="headerlink" title="Lecture 1 : Introduction"></a>Lecture 1 : Introduction</h3><p>计算机视觉发展历史与课程概述</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=148249804&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<h3 id="Lecture-2-Image-Classification-pipeline"><a href="#Lecture-2-Image-Classification-pipeline" class="headerlink" title="Lecture 2 : Image Classification pipeline"></a>Lecture 2 : Image Classification pipeline</h3><p>图像分类：KNN与线性分类器</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=148185525&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-3-Loss-Functions-and-Optimization"><a href="#Lecture-3-Loss-Functions-and-Optimization" class="headerlink" title="Lecture 3 : Loss Functions and Optimization"></a>Lecture 3 : Loss Functions and Optimization</h3><p>线性分类、损失函数与梯度下降</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=148534730&page=3" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-4-Neural-Networks-and-Backpropagation"><a href="#Lecture-4-Neural-Networks-and-Backpropagation" class="headerlink" title="Lecture 4 : Neural Networks and Backpropagation"></a>Lecture 4 : Neural Networks and Backpropagation</h3><p>神经网络与反向传播</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=148888896&page=4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-5-Convolutional-Neural-Networks"><a href="#Lecture-5-Convolutional-Neural-Networks" class="headerlink" title="Lecture 5 : Convolutional Neural Networks"></a>Lecture 5 : Convolutional Neural Networks</h3><p>卷积神经网络</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=149264679&page=5" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-6-Hardware-and-Software"><a href="#Lecture-6-Hardware-and-Software" class="headerlink" title="Lecture 6 : Hardware and Software"></a>Lecture 6 : Hardware and Software</h3><p>深度学习硬件算力基础-GPU和TPU</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=153180244&page=12" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>讲座：加速深度学习计算的算法和硬件</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=156061824&page=14" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>边缘计算案例</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=156061552&page=15" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>深度学习软件编程框架：Tensorflow、Pytorch、Keras</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=153570370&page=16" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-7-Training-Neural-Networks-Part-1"><a href="#Lecture-7-Training-Neural-Networks-Part-1" class="headerlink" title="Lecture 7 : Training Neural Networks, Part 1"></a>Lecture 7 : Training Neural Networks, Part 1</h3><p>训练神经网络（第一部分）</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=150361601&page=7" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-8-Training-Neural-Networks-Part-2"><a href="#Lecture-8-Training-Neural-Networks-Part-2" class="headerlink" title="Lecture 8 : Training Neural Networks, Part 2"></a>Lecture 8 : Training Neural Networks, Part 2</h3><p>训练神经网络（第二部分）</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=151127139&page=8" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-9-Understanding-and-Visualizing-Convolutional-Neural-Networks"><a href="#Lecture-9-Understanding-and-Visualizing-Convolutional-Neural-Networks" class="headerlink" title="Lecture 9 : Understanding and Visualizing Convolutional Neural Networks"></a>Lecture 9 : Understanding and Visualizing Convolutional Neural Networks</h3><p>可视化卷积神经网络</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=151546501&page=6" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>迁移学习与fine tuning</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=153956039&page=10" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>经典卷积神经网络结构案例分析</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=156513619&page=11" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-10-Recurrent-Neural-Networks"><a href="#Lecture-10-Recurrent-Neural-Networks" class="headerlink" title="Lecture 10 : Recurrent Neural Networks"></a>Lecture 10 : Recurrent Neural Networks</h3><p>循环神经网络</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=149629413&page=17" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Lecture-11-CNNs-in-Practice"><a href="#Lecture-11-CNNs-in-Practice" class="headerlink" title="Lecture 11 : CNNs in Practice"></a>Lecture 11 : CNNs in Practice</h3><p>卷积神经网络工程实践技巧</p>
<iframe src="//player.bilibili.com/player.html?aid=86713932&bvid=BV1K7411W7So&cid=154771787&page=9" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<p>后面的貌似太监了</p>
<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-读懂GAN, pix2pix, CycleGAN和pix2pixHD的关系</title>
    <url>/70ef60f6.html</url>
    <content><![CDATA[<h3 id="机器学习的时代"><a href="#机器学习的时代" class="headerlink" title="机器学习的时代"></a>机器学习的时代</h3><p>计算机视觉（Computer Vision, CV）领域近年来发生了巨大的变化。在2012年之前，CV的主要研究方法是使用<strong>人工设计（hand-designed）</strong>的特征完成各种任务。</p>
<img src="/70ef60f6/1.png" class>

<p>2012年使用<strong>深度神经网络（Deep Neural Network, DNN）</strong>在ImageNet的分类任务上取得了巨大成功。</p>
<img src="/70ef60f6/2.png" class>

<p>从此<strong>深度学习（Deep Learning）</strong>的相关研究如火如荼地展开了，比如说下面这三个例子：</p>
<ol>
<li><strong>物体识别（Object detection）</strong> [Redmon etal., 2018]</li>
<li><strong>对人体的理解（Human understanding）</strong> [Guler et al., 2018]</li>
<li><strong>自动驾驶（Autonomous driving）</strong> [Zhao et al., 2017]</li>
</ol>
<img src="/70ef60f6/3.png" class>

<span id="more"></span>

<hr>
<h3 id="图形学中的尝试：趁手的武器-or-白费功夫"><a href="#图形学中的尝试：趁手的武器-or-白费功夫" class="headerlink" title="图形学中的尝试：趁手的武器 or 白费功夫"></a>图形学中的尝试：趁手的武器 or 白费功夫</h3><p>在传统的图形学管线（pipeline）中，输出图像需要经过建模、材质贴图、光照、渲染等一系列繁琐的步骤。</p>
<img src="/70ef60f6/4.png" class>

<p>现在大家看到了Deep Learning的潜力，那我们自然的就有个想法：有没有可能使用Deep Learning简化计算机图形学（Computer Graphics）的研究呢？</p>
<p>一个直接的想法是把DNN“倒过来用”。之前的DNN可能是输入一幅图像，输出一个标签（比如说猫），那我们能不能输入“猫”这个字，输出一张猫的照片呢？</p>
<img src="/70ef60f6/5.png" class>

<p>很遗憾，答案是No！因为这种任务实在太复杂啦！我们很难让DNN凭空输出图像这样的<strong>高维数据（High dimensional data）</strong>（这里的“高维”可以理解成数据量大）。实际上，在很长一段时间里，DNN只能输出数字这种简单的、低分别率的小图像，就像下面这样：</p>
<img src="/70ef60f6/6.png" class>

<p>而想要生成想游戏场景这类的图片，这种方法根本没用。所以，我们必须得想出更厉害的东西完成这项任务！</p>
<hr>
<h3 id="GAN就完了？Naive！"><a href="#GAN就完了？Naive！" class="headerlink" title="GAN就完了？Naive！"></a>GAN就完了？Naive！</h3><p>于是，一个叫做<strong>生成对抗网络（Generative Adversarial Network）</strong>——也就是大名鼎鼎的<strong>GAN</strong>——的东西横空出世。作者是下面这位小哥：</p>
<img src="/70ef60f6/7.png" class>

<p>那么，我们该怎么GAN出图像呢？</p>
<p>一般来说，GAN中包含两种类型的网络 G 和 D。其中，G 为<strong>Generator</strong>，它的作用是生成图片，也就是说，在输入一个<strong>随机编码（random code）</strong> z 之后，它将输出一幅由神经网络<strong>自动生成的、假的图片</strong> G(z)。</p>
<p>另外一个网络 D 为<strong>Discriminator</strong>是用来判断的，它接受 G 输出的图像作为<strong>输入</strong>，然后判断这幅图像的真假，真的输出1，假的输出0。</p>
<img src="/70ef60f6/8.png" class>

<p>在两个网络互相博弈的过程中，两个网络的能力都越来越高：G 生成的图片越来越像真的图片，D 也越来越会判断图片的真假。到了这一步，我们就能“卸磨杀驴”——丢掉 D 不要了，把 G 拿来用作图片生成器。</p>
<p>正式一点儿讲，我们就是要在最大化 D 的能力的前提下，最小化 D 对 G 的判断能力，这是一个最小最大值问题，它的学习目标是：</p>
<img src="/70ef60f6/9.png" class>

<p>为了增强 D 的能力，我们分别考虑输入真的图像和假的图像的情况。上式中第一项的 D(G(z)) 处理的是<strong>假图像</strong> G(z)，这时候评分 D(G(z)) 需要尽力<strong>降低</strong>；第二项处理的是<strong>真图像</strong> x，这时候的评分要高。</p>
<hr>
<h3 id="GAN的局限性"><a href="#GAN的局限性" class="headerlink" title="GAN的局限性"></a>GAN的局限性</h3><p>即便如此，传统的GAN也不是万能的，它有下面两个不足：</p>
<ol>
<li><strong>没有用户控制（user control）能力</strong></li>
</ol>
<p>在传统的GAN里，输入一个<strong>随机</strong>噪声，就会输出一幅<strong>随机</strong>图像。</p>
<img src="/70ef60f6/10.png" class>

<p>但假如用户是有想法，我们想输出的图像是我们想要的那种图像，和我们的输入是<strong>对应的、有关联的</strong>。比如输入一只猫的草图，输出同一形态的猫的真实图片（这里对形态的要求就是一种用户控制）。</p>
<img src="/70ef60f6/11.png" class>

<ol start="2">
<li><strong>低分辨率（Low resolution）和低质量（Low quality）问题</strong></li>
</ol>
<p>尽管生成的图片看起来很不错，但如果你放大看，就会发现<strong>细节相当模糊</strong>。</p>
<img src="/70ef60f6/12.png" class>

<hr>
<h3 id="改善"><a href="#改善" class="headerlink" title="改善"></a>改善</h3><p>前面说过传统的GAN的种种局限，那么现在，我们相应的目标就是：</p>
<ul>
<li>提高 GAN 的<strong>用户控制</strong>能力</li>
<li>提高 GAN 生成图片的<strong>分辨率和质量</strong></li>
</ul>
<p>为了达到这样的目标，总共分三步：</p>
<ol>
<li><strong>pix2pix：</strong>有条件地使用用户输入，它使用<strong>成对的数据（paired data）</strong>进行训练。</li>
<li><strong>CycleGAN：</strong>使用<strong>不成对的数据（unpaired data）</strong>的就能训练。</li>
<li><strong>pix2pixHD：</strong>生成高分辨率、高质量的图像。</li>
</ol>
<img src="/70ef60f6/13.png" class>

<hr>
<h3 id="pix2pix"><a href="#pix2pix" class="headerlink" title="pix2pix"></a>pix2pix</h3><p><strong>pix2pix</strong> 对传统的 GAN 做了个小改动，它不再输入随机噪声，而是输入用户给的图片：</p>
<img src="/70ef60f6/14.png" class>

<p>但这也就产生了新的问题：我们怎样建立输入和输出的<strong>对应关系</strong>。此时 G 的输出如果是下面这样，D 会判断是真图：</p>
<img src="/70ef60f6/15.png" class>

<p>但如果 G 的输出是下面这样的，D 拿来一看，也会<strong>认为是真的图片</strong>。也就是说，这样做并不能训练出输入和输出对应的网络 G，因为是否对应根本不影响 D 的判断。</p>
<img src="/70ef60f6/16.png" class>

<p>为了体现这种对应关系，解决方案也很简单，你可以也已经想到了：我们把 G 的输入和输出一起作为 D 的输入不就好了？于是现在的优化目标变成了这样：</p>
<img src="/70ef60f6/17.png" class>

<p>这项研究还是挺成功的，大家可以去<a href="https://affinelayer.com/pixsrv/">这里</a>在线体验一下demo，把草图（sketch）变成图片。</p>
<img src="/70ef60f6/18.png" class>

<p>当然，有些比较皮的用户输入了奇形怪状的草图，然后画风就变成了这样：</p>
<img src="/70ef60f6/19.png" class>

<hr>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>pix2pix的核心是有了<strong>对应关系</strong>，这种网络的应用范围还是比较广泛的，比如：</p>
<ol>
<li>草图变图片[Isola, Zhu, Zhou, Efros, 2016]：</li>
</ol>
<img src="/70ef60f6/20.png" class>

<ol start="2">
<li>灰度图变彩色图[Isola, Zhu, Zhou, Efros, 2016]：</li>
</ol>
<img src="/70ef60f6/21.png" class>

<ol start="3">
<li>自动着色 Data from [Russakovsky et al. 2015]：</li>
</ol>
<img src="/70ef60f6/22.png" class>

<ol start="4">
<li>交互式着色[Zhang*, Zhu*, Isola, Geng, Lin, Yu, Efros, 2017]：</li>
</ol>
<img src="/70ef60f6/23.png" class>

<hr>
<h3 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h3><p>pix2pix必须使用成对的数据进行训练。</p>
<img src="/70ef60f6/24.png" class>

<p>但很多情况下成对数据是很难获取到的，比如说，我们想把马变成斑马，现实生活中是不存在对应的真实照片的：</p>
<img src="/70ef60f6/25.png" class>

<p>现在我们就用Cycle-constraint Adversarial Network也就是<strong>CycleGAN</strong>解决这个问题。这种网络<strong>不需要成对的数据</strong>，只需要输入数据的一个集合（比如一堆马的照片）和输出数据的一个集合（比如一堆斑马的照片）就可以了。</p>
<img src="/70ef60f6/26.png" class>

<p>但是（没错我又要说但是了），直接使用不成对的数据是不奏效的。网络会直接<strong>忽略输入，随机产生输出</strong>。所以，我们还得对网络增加<strong>限制（constraint）</strong>才行。</p>
<p>那怎么加限制呢？我们来思考一个现实问题。马克吐温认为，如果一把一段话从英文翻译成法文，再从法文翻译回英文，那么你应该得到跟之前原始输入的英文一样的内容。这里也是一样，如果我们把马变成斑马，然后再变回马，那么最后的马和开始输入的马应该是一样的。</p>
<img src="/70ef60f6/27.png" class>

<p>下面讲一下具体技术细节。除了之前提到的把<strong>马变成斑马</strong>的网络 G，我们还需要一个把<strong>斑马变回马</strong>的网络  F。<br>那么，一匹马 x 用 G 变成斑马 s = G(x)，然后再用 F 把它变回马 F(s)，得到的马和一开始的马应该是一样的，也就是 x = F(G(x))。</p>
<img src="/70ef60f6/28.png" class>

<p>反过来，斑马变马再变回斑马也要满足要求，注意这一步最好不要省略。虽然理论上只用一个条件是可以的，但是现实实现中，有很多因素，比如计算的准备度，优化的问题，应用中都是把所有约束都加上。比如说 a = b = c，理论上我们只要要求 (a-b)^2 + (a-c)^2 = 0，但现实中我们都是做 (a-b)^2 + (a-c)^2 + (b-c)^2 = 0。</p>
<img src="/70ef60f6/29.png" class>

<p>我们同时优化 G 和 F，最后就能拿到一个想要的网络 G。</p>
<hr>
<h3 id="CycleGAN为什么有效"><a href="#CycleGAN为什么有效" class="headerlink" title="CycleGAN为什么有效"></a>CycleGAN为什么有效</h3><p>CycleGAN成功的原因在于它分离了<strong>风格（Style）和内容（content）</strong>。人工设计这种分离的算法是很难的，但有了神经网络，我们很容易让它学习者去自动<strong>保持内容而改变风格</strong>。</p>
<p><strong>马变斑马：</strong></p>
<p>两张图片分别是原来的马和 G 变出的斑马：</p>
<img src="/70ef60f6/30.png" class>
<img src="/70ef60f6/31.png" class>

<p><strong>橘子变苹果：</strong></p>
<img src="/70ef60f6/32.png" class>
<img src="/70ef60f6/33.png" class>

<p>可以看到，CycleGAN能够比较准确的找到橘子的位置，并把它变成苹果。</p>
<p><strong>图像风格的迁移：</strong></p>
<img src="/70ef60f6/34.png" class>
<img src="/70ef60f6/35.png" class>

<p><strong>游戏场景替换：</strong></p>
<p>这个应用就很酷了，它以一些德国城市的照片作为输入，成功替换了游戏GTA5中的场景！</p>
<img src="/70ef60f6/36.png" class>
<img src="/70ef60f6/37.png" class>

<p><strong>失败例子</strong></p>
<p>在输入骑马的普京大帝照片时，输出图像里把普京也变成了斑马。</p>
<img src="/70ef60f6/38.png" class>

<p>这是因为，训练图像里并没有骑马的人，所以网络就傻掉了。</p>
<p>目前暂且的解决办法是先用Mask R-CNN做图像分割之后再针对马进行变化，不过这个效果也不好，因为人和马在图像上有重叠的部分。</p>
<hr>
<h3 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h3><p>这里给出<a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">CycleGAN和pix2pix的github项目</a>，这是2017年github最受欢迎的项目之一。</p>
<p>不过这里存在一个严重的问题：CycleGAN只能输出256p/512p的低分辨率图像。</p>
<hr>
<h3 id="pix2pixHD"><a href="#pix2pixHD" class="headerlink" title="pix2pixHD"></a>pix2pixHD</h3><p>我们还剩一个悬而未决的问题：分辨率和图像质量。pix2pixHD就是用来解决这个问题的！</p>
<p>假设我们输入一张高分辨率的草图：</p>
<img src="/70ef60f6/39.png" class>

<p>使用pix2pix，结果很差（之前说过，让网络产生高维数据输出很难）：</p>
<img src="/70ef60f6/40.png" class>

<p>pix2pixHD采取了<strong>金字塔式</strong>的方法：</p>
<ol>
<li>先输出低分辨率的图片。</li>
<li>将之前输出的低分辨率图片作为另一个网络的输入，然后生成分辨率更高的图片。</li>
</ol>
<img src="/70ef60f6/41.png" class>

<p>这样，就把一个困难的问题拆分成了两个相对简单的问题~</p>
<p>最终的效果是，给定下面的高分辨率草图：</p>
<img src="/70ef60f6/42.png" class>

<p>pix2pixHD可以<strong>实时（real time）</strong>产生这样的效果：</p>
<img src="/70ef60f6/43.png" class>

<p>pix2pixHD也支持用户交互，比如加一辆车、添几棵树之类的：</p>
<img src="/70ef60f6/44.png" class>
<img src="/70ef60f6/45.png" class>

<p>pix2pixHD还有许多有趣的应用。</p>
<p>比如用草图生成高分辨率人脸：</p>
<img src="/70ef60f6/46.png" class>
<img src="/70ef60f6/47.png" class>

<p>再比如：</p>
<ul>
<li>图像增强（Image Enhancement）</li>
<li>图像去雾（Image Dehazing）</li>
<li>非监督动作重定向 <a href="https://arxiv.org/abs/1804.05653">Neural Kinematic Networks for Unsupervised Motion Retargetting</a></li>
</ul>
<hr>
<h3 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h3><p>目前生成的斑马视频帧与帧之间的纹理变化较大，为了解决帧之间的连续性问题，新的研究工作应运而生：<a href="https://arxiv.org/abs/1808.06601">Video-to-Video Synthesis</a>。<br>它主要的解决思路有下面三个：</p>
<ol>
<li>输入一段视频中的几帧，检查真假</li>
<li>把前面的帧当做后面帧的输入</li>
<li>使用“optical flow”，具体请看paper</li>
</ol>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文介绍了怎样用神经网络生成图片，我们使用pix2pix完成了基本任务，使用CycleGAN解决了输入数据不成对的问题，最后用pix2pixHD解决了图像分辨率和图像质量的问题。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/gdymind/article/details/82696481">https://blog.csdn.net/gdymind/article/details/82696481</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 1 [2017版]</title>
    <url>/d5d78943.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - Introduction</strong></li>
</ul>
<h3 id="CV–深度学习–神经网络–卷积神经网络"><a href="#CV–深度学习–神经网络–卷积神经网络" class="headerlink" title="CV–深度学习–神经网络–卷积神经网络"></a>CV–深度学习–神经网络–卷积神经网络</h3><img src="/d5d78943/1.png" class>

<ul>
<li>计算机视觉是人工智能中发展最迅速的内容。</li>
<li>2016年思科估计80%的网络数据是像素数据，进入到一个信息爆炸的时代，原因：1、互联网载体；2、传感器–手机、摄像头</li>
<li>互联网暗物质–数据冗余，像素信息很难理解，就像银河系内的暗物质。</li>
<li>YouTube服务器接受150h video/60s。人眼很难给这些数据做标记、分类、索引，操作这些数据需要自动化。</li>
</ul>
<span id="more"></span>

<hr>
<h3 id="CV–跨学科领域"><a href="#CV–跨学科领域" class="headerlink" title="CV–跨学科领域"></a>CV–跨学科领域</h3><img src="/d5d78943/2.png" class>

<ul>
<li>涉及：工程、物理、生物、心理学、计算机科学以及数学</li>
<li>CV–深度学习–神经网络</li>
</ul>
<hr>
<h3 id="斯坦福cs231n类似的课程"><a href="#斯坦福cs231n类似的课程" class="headerlink" title="斯坦福cs231n类似的课程"></a>斯坦福cs231n类似的课程</h3><ul>
<li>cs131 – 本科介绍课程</li>
<li>cs231a – 核心CV课程、课题包括图像处理、成像、3D重建、视频分段、目标识别以及场景理解</li>
<li>cs231n – 神经网络（深度学习）在图像识别中的应用</li>
</ul>
<hr>
<h3 id="CV的简短历史"><a href="#CV的简短历史" class="headerlink" title="CV的简短历史"></a>CV的简短历史</h3><ol>
<li>寒武纪大爆发（BIG BANG）-公元前5.43亿年</li>
</ol>
<ul>
<li>浮游生物漂浮在水中，等着食物进入嘴中，突然有一天生物爆发</li>
<li>澳大利亚研究起源是生物进化出了眼睛，捕捉光线，进行环境信息交换，获取食物。</li>
<li>视觉的出现是大爆发的最主要驱动力</li>
</ul>
<ol start="2">
<li>文艺复兴时期</li>
</ol>
<ul>
<li>现代意义上的相机的出现-达芬奇，现代视觉工程的开端，记录世界，但是没有信息的理解，仅仅是复制。</li>
<li>电影、商用相机（柯达）、摄像机。</li>
</ul>
<ol start="3">
<li>动物视觉原理&amp;架构–Hubel&amp;Wiesel</li>
</ol>
<ul>
<li>将电极放入猫的大脑中，基础视觉皮质（primary visual cortex）– 处理视觉</li>
<li>神经元处理视觉信息，实际上后脑处理视觉部分远离眼睛，50%的大脑参与视觉处理</li>
<li>视觉占据更多资源，因为视觉处理太难了，视觉信息含量大。</li>
<li>猫的实验中，目标是鱼-神经元脉冲，实际上鱼、花、草都不会产生神经元脉冲。更换幻灯片产生边缘切换会激发神经元信号</li>
<li>基础视觉区的神经元是按照列组成，每一列响应不同的线条。</li>
</ul>
<ol start="4">
<li>Block world</li>
</ol>
<ul>
<li>by Lary Roberts in 1963，计算机视觉博士论文，后来从事互联网</li>
<li>大脑对信息的处理是基于边缘和形状，边缘决定结构</li>
</ul>
<ol start="5">
<li>1966年</li>
</ol>
<ul>
<li>人工智能实验室：1、MIT；2、Stanford John McCarthy建立，比计算机科学还要早</li>
<li>AI一次由John McCarthy提出，计算机视觉由MIT开始研究</li>
<li>暑期工程目标，未完成。</li>
</ul>
<ol start="6">
<li>《Vision》–David Marr，1970</li>
</ol>
<img src="/d5d78943/3.png" class>

<ul>
<li>视觉是分层的，图像时多层的：输入层、边缘层、2.5D层、3D（最后重建）</li>
<li>视觉是复杂的，像素的排列组合无穷无尽。</li>
</ul>
<ol start="7">
<li>视觉算法研究</li>
</ol>
<ul>
<li>Generalized Cylinder，1979年：整个世界的形状是有圆柱体组成</li>
<li>Pictorial Structure，1973：物体有简单部分形状组成，各个部位有“弹簧”组成，允许变形</li>
<li>线条边缘，David Lowe，1987：线条边缘，圆形和方形</li>
<li>Normalized Cut，Shi &amp; Malik，1997：第一次使用现实图片，通过感知分组对彩色图片进行分类</li>
<li>Face Detection， Vio &amp; Jones， 2001：黑白条形过滤寻找人脸，第一个人工智能人脸检测算法</li>
<li>“SIFT” &amp; Object Recognition, David Lowe,1999: 特征映射，目标识别</li>
<li>Spatial Pyramid Matching, Lazebnik, Schmid &amp; Ponce, 2006：金字塔特征提取</li>
<li>Histogram of Gradients(HOG),Dalal &amp; Triggs, 2005: 梯度直方图</li>
<li>Deformable Part Model，Felzenswalb, McAllester, Ramanan, 2009：可变形部件模型</li>
</ul>
<ol start="8">
<li>PASCAL 视觉目标检测挑战</li>
</ol>
<ul>
<li>20种目标检测，2006-2012</li>
</ul>
<ol start="9">
<li>Imagenet-2010</li>
</ol>
<ul>
<li>22k种类和14Millon图片，集合的dataset</li>
<li>IMAGENET,大尺寸视觉识别挑战赛（计算机视觉顶级挑战赛）：1000种类，1431167图片</li>
</ul>
<img src="/d5d78943/4.jpg" class>

<ul>
<li>2012年AlexNet-CNN卷积神经网络使得错误率大幅下降，后续都是神经网络模型，2015年已经低于人类的识别率5.1%</li>
</ul>
<hr>
<h3 id="cs231n综述"><a href="#cs231n综述" class="headerlink" title="cs231n综述"></a>cs231n综述</h3><ol>
<li>cs231n聚焦解决图像分类问题–视觉识别中最重要的问题之一</li>
</ol>
<ul>
<li>互联网公司、初创公司、手机拍照、食物识别、电商分类</li>
</ul>
<ol start="2">
<li><p>图像分类：目标检测、图像描述、运动识别</p>
</li>
<li><p>目标检测的压倒性工具——CNN（Convolutional Neural Network）</p>
</li>
</ol>
<img src="/d5d78943/5.png" class>

<ul>
<li>2012年迎来的计算机视觉新起点–CNN的使用，DeepLearning威力得意体现</li>
<li>1998年杨乐昆提出首个卷积神经网络结构：卷积滤波-池化-卷积滤波-池化的结构</li>
<li>2012年AlexNet几乎相同的结构的成功得益于：算力的提升&amp;训练数据的增长</li>
</ul>
<ol start="4">
<li>视觉智能不仅仅是目标识别</li>
</ol>
<ul>
<li>感知分组、识别&amp;3D、场景重建</li>
</ul>
<img src="/d5d78943/6.png" class>

<ul>
<li>图片理解：动作识别、目标关系、语义识别——Visual Genome</li>
<li>愿景：生物视觉系统的强大，看图说话，人500ms后形成一个故事。使我们的生活更好。</li>
<li>相关作业链接：<a href="http://cs231n.github.io/assignments2018/assignment1/">http://cs231n.github.io/assignments2018/assignment1/</a></li>
</ul>
<hr>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 2 [2017版]</title>
    <url>/4c35ef42.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - Image Classification</strong></li>
</ul>
<h3 id="cs231n课程指引"><a href="#cs231n课程指引" class="headerlink" title="cs231n课程指引"></a>cs231n课程指引</h3><ul>
<li>作业1：KNN；线性分类器，SVM、Softmax；两层神经网络；图像特征</li>
<li>Python + Numpy教程：<a href="http://cs231n.github.io/python-numpy-tutorial/">http://cs231n.github.io/python-numpy-tutorial/</a></li>
<li>Google Cloud教程：<a href="http://cs231n.github.io/gce-tutorial/">http://cs231n.github.io/gce-tutorial/</a></li>
</ul>
<hr>
<h3 id="图像分类–CV核心问题"><a href="#图像分类–CV核心问题" class="headerlink" title="图像分类–CV核心问题"></a>图像分类–CV核心问题</h3><ul>
<li>分类识别，种类太多，{狗，猫，飞机……}</li>
<li>数据量太庞大，1080p = 1920 * 1080 * 3 *（255,8bit）</li>
<li>挑战：观测点变化；光照&amp;明暗；变形和姿势；隐藏&amp;遮挡；背景&amp;分辨；种类种族。</li>
</ul>
<img src="/4c35ef42/1.jpg" class>

<span id="more"></span>

<ul>
<li>图像分类器，没有图示的分类器能够解决这个问题。</li>
<li>特征提取，通过提取猫耳朵的形状特征来分类</li>
<li>数据驱动方法：（1）收集数据和标签；（2）使用ML训练分类器；（3）在新图像上进行测试评估性能</li>
</ul>
<img src="/4c35ef42/2.png" class>
<img src="/4c35ef42/3.png" class>

<hr>
<h3 id="分类器1：最近邻算法–KNN"><a href="#分类器1：最近邻算法–KNN" class="headerlink" title="分类器1：最近邻算法–KNN"></a>分类器1：最近邻算法–KNN</h3><ol>
<li>算法的流程：train function 用来记录所有数据及标签；predict寻找最相似训练图片的标签</li>
<li>数据集：采用CIFAR10，10类问题，50000张带标签训练图片，10000张带标签测试图片</li>
<li>使用距离度量来衡量图片相似度<ul>
<li>曼哈特距离，L1范数<img src="/4c35ef42/4.png" class></li>
<li>欧式距离，L2范数<img src="/4c35ef42/5.png" class></li>
<li>L1与L2的比较：<a href="http://vision.stanford.edu/teaching/cs231n-demos/knn/">http://vision.stanford.edu/teaching/cs231n-demos/knn/</a></li>
</ul>
</li>
<li>存在的问题1，训练时间O(1)，预测时间O(n)。训练数据集越大，预测时间越长。</li>
<li>存在的问题2：容易出现过拟合情况，如下图： <img src="/4c35ef42/6.png" class></li>
<li>优化的NN算法–KNN：预测时选择距离最近的K个标签，选择出现最多的标签。在作业中使用np.bicount快速查找。 <img src="/4c35ef42/7.png" class></li>
<li>hyperparameters 超参数调试<ol>
<li>遍历k值和距离度量——选择合适的超参数</li>
<li>合理划分数据集进行超参数调试：交叉验证，将数据集划分N段，选择一段作为验证，其他作为训练集，取多段均值及均方根，寻找最合适参数</li>
</ol>
<ul>
<li>可能的想法：<img src="/4c35ef42/8.png" class></li>
<li>交叉验证法：<img src="/4c35ef42/9.png" class></li>
</ul>
</li>
<li>KNN的缺陷：<ul>
<li>测试速度太慢，尤其是训练集比较大的时候</li>
<li>像素距离度量不是有益的：加BOX；平移；改变色彩还能保持距离一样</li>
<li>维数灾难，多维距离受多参数影响，距离结果易混淆，准确率下降。</li>
</ul>
</li>
</ol>
<p><strong>KNN总结：</strong></p>
<ul>
<li>图像分类使用带标签的训练集开始，在测试集中预测可能的标签</li>
<li>KNN算法预测标签依赖最近的K个训练样本</li>
<li>K值和距离度量方法属于超参数-hyperparameters</li>
<li>使用交叉验证分段式来调试超参数，测试集只用来最后的评估</li>
<li>KNN的使用需要选择合适的环境，限制较大</li>
</ul>
<hr>
<h3 id="分类器2：线性分类器"><a href="#分类器2：线性分类器" class="headerlink" title="分类器2：线性分类器"></a>分类器2：线性分类器</h3><ol>
<li>神经网络就像搭积木，线性分类器就是积木的每一层</li>
<li>图像的内容识别及描述使用的结构是CNN+RNN，如下图： <img src="/4c35ef42/10.png" class></li>
<li>线性分类器通过对图像与标签进行映射 f(x,W) = W ∗ x + b，通过训练使得参数逼近真实模型，如下图讲解 <img src="/4c35ef42/11.png" class></li>
<li>线性分类器的最终训练参数W，显示为图片格式如下，隐约可以看出图像的轮廓，个人理解：滤波作用： <img src="/4c35ef42/12.png" class></li>
<li>线性分类器相当于在M唯空间中使用超平面来分割不同的类</li>
<li>当出现以下情况时，线性分类器将降低效果：类处于相同空间；类所有空间都存在，不具备线性。 <img src="/4c35ef42/13.png" class></li>
<li>线性分类器f(x,W)=W∗x+bf(x,W)=W∗x+b的工作原理：<ol>
<li>相当于在每一个图像的每一个类都给了一个得分系统，计算出对应的值，但是值得准确率与实际可能存在偏差，衡量不准确</li>
<li>根据平分系统计算损失函数，通过损失函数下降的梯度计算参数的偏导，更新W和b参数</li>
<li>重复计算更新，不断降低损失函数，逼近最佳模型，使用最佳模型进行计算，提高准确率</li>
</ol>
</li>
</ol>
<hr>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 3 [2017版]</title>
    <url>/8dbb3082.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - Loss Functions and Optimization</strong></li>
</ul>
<h3 id="损失函数–Loss-Function–-SVM"><a href="#损失函数–Loss-Function–-SVM" class="headerlink" title="损失函数–Loss Function– SVM"></a>损失函数–Loss Function– SVM</h3><ol>
<li><p>损失函数模型：</p>
<ol>
<li>对于N张图片的数据集：其中xi是第i个图像，yi是对应的第i个标签</li>
<li>损失函数应该是每一张图片的损失函数之和，可以用下面的公式来表示： <img src="/8dbb3082/1.png" class>
</li>
</ol>
</li>
<li><p>在得到score之后，可以使用多分类线性SVM</p>
<ol>
<li>对于xi，yi，令s=f(xi,W)，那么SVM可以表示为： <img src="/8dbb3082/2.png" class>
 其中syi代表的是第i张图像正确标签分类所在的scores对应的列，yi对应的值在scores列中对应的C类相同<br> syi≥sj+1的含义是正确的分类要比错误分类的score大1，该项贡献的损失函数为0；反之损失函数正值</li>
<li>详细的一列的计算过程如下，在作业中使用循环和向量化（vectorization）两种，计算方法很巧妙，这里使用循环的理解方式： <img src="/8dbb3082/3.png" class>
 <span id="more"></span>
 对于将猫和青蛙分类错误的情况下，得分较低的损失函数较大；在车的分类中，得分越高的损失函数值较小；而对于一种最理想的情况，正确分类为1，而其他的分类为0，那么损失函数将为0</li>
<li>而最后的损失函数由以下公式得到： <img src="/8dbb3082/4.png" class></li>
</ol>
<ul>
<li>Q1：而对于car分类的值如果有微小改变，在正确的值始终比错误的值大1的情况，损失函数不变；但当差值小于1的时候，损失函数值增大。因此微小改变一般不会对损失函数值产生影响。   </li>
<li>Q2：最小的损失函数值为0，最大的损失函数值为无穷大    </li>
<li>Q3：当W初始值很小，所有的s都近似为0的时候，损失函数的值最终为1    </li>
<li>Q4：当算上正确分类的一行时，那么最终的损失函数趋近1，对于整个训练过程没有影响。</li>
<li>Q5：使用平均和使用和没有太大区别，只是比例不同    </li>
<li>Q6: 如果使用以下均方函数，不会对结果产生太大的影响。  <img src="/8dbb3082/5.png" class></li>
</ul>
</li>
<li><p>正则化（regularization）——防止过拟合，引入W的作用</p>
<ol>
<li>正则化的概念：在特征参数维度较大、训练样本较少情况下，会导致模型过拟合。一方面可以通过丢掉某些参数（dropout等）；另一方法需要加入正则项对特征参数进行惩罚，降低特征参数的影响，通常如下： <img src="/8dbb3082/6.png" class>
 其中公式中 λ 为平衡两者之间的影响，但通常值较大，数量级在10^4以上。<br> 正则化详细地讲解参照网页：<a href="https://www.cnblogs.com/jianxinzhou/p/4083921.html">https://www.cnblogs.com/jianxinzhou/p/4083921.html</a></li>
<li>欧卡姆剃刀：“Among competing hypotheses,the simplest is the best”     William of Ockham, 1285 - 1347</li>
<li>正则化的方法（直接贴图）： <img src="/8dbb3082/7.png" class></li>
<li>L2正则化（权重衰减）：对于使得损失函数相同的特征参数矩阵，优选特征参数矩阵均匀的，[0.25, 0.25, 0.25, 0.25]优于[1, 0, 0, 0]</li>
<li>L1正则化（稀疏特性）：具体还未讲到。</li>
</ol>
</li>
</ol>
<hr>
<h3 id="损失函数–Loss-Function–-Softmax（Multinomial-Logistic-Regression）"><a href="#损失函数–Loss-Function–-Softmax（Multinomial-Logistic-Regression）" class="headerlink" title="损失函数–Loss Function– Softmax（Multinomial Logistic Regression）"></a>损失函数–Loss Function– Softmax（Multinomial Logistic Regression）</h3><ol>
<li>函数公式很简单，参照以下公式：</li>
</ol>
<img src="/8dbb3082/8.png" class>

<p>EXP和normalize的作用将score归一化到[0,1]之间。</p>
<ol start="2">
<li>计算方式：</li>
</ol>
<img src="/8dbb3082/9.png" class>

<p><strong>损失函数总结</strong></p>
<ol>
<li>Softmax对于scores值变化较为敏感，而SVM对于Scores值微小变化不敏感，意味着SVM具有较大鲁棒性，Softmax具有较强灵敏性。</li>
<li>通过数据集和标签（x,y）——&gt;乘以特征参数W和偏置b，计算scores——&gt;通过损失函数计算Loss</li>
<li>如何优化参数，最佳的W—-&gt;Optimization</li>
</ol>
<hr>
<h3 id="最优化-Optimization"><a href="#最优化-Optimization" class="headerlink" title="最优化-Optimization"></a>最优化-Optimization</h3><ol>
<li>最优化问题就像在一个山谷中寻找最低点<ul>
<li>不理智的策略：采用随机的方式去寻找最佳W矩阵，能够寻找到合适的点，但是准确率不高</li>
</ul>
</li>
<li>跟随斜率/梯度<ul>
<li>数值计算斜率的方法如下：  <img src="/8dbb3082/10.png" class>
<ol>
<li>多维的情况下，梯度等同于偏导数，独立对每一维度进行计算</li>
<li>但是对于一个损失函数和W，步长是不确定，同时对于上面的损失函数，是一个W的函数</li>
<li>对于求梯度，可以转换为使用微积分（calculus）求取解析解，(反向传播),再使用学习率进行更新<img src="/8dbb3082/11.png" class></li>
<li>数值法优缺点：估算；速度慢；易于coding</li>
<li>解析法优缺点：准确；速度快；易出错（特别是在某些函数不可导点）</li>
</ol>
</li>
<li>梯度检验：<ol>
<li>如何证明更新后的参数是正确的，可以使用数值解的逼近计算方式来验证求取的梯度是否正确</li>
</ol>
</li>
</ul>
</li>
<li>梯度下降法–随机梯度下降法（SGD-stochastic）<ul>
<li>当数据集比较大的时候，计算代价非常大(占用内存)；计算会非常慢（图像越多，需要优化的参数成倍增长）</li>
<li>使用mini-batch进行训练，通常一组为32/64/128，大小与内存大小成比例，使用这种方法损失函数会在波动中下降。</li>
<li>学习率不同优化速度不同：太高跨度大无法收敛；太小收敛速度慢；较高无法收敛到最佳点，会找到局部最优；合适的值才能有快又好。</li>
<li>其他的梯度下降法还有：Momentum（冲量法）、NAG（牛顿法）、Adagrad、Adadelta、RMSprop等</li>
</ul>
</li>
</ol>
<hr>
<h3 id="图像特征提取"><a href="#图像特征提取" class="headerlink" title="图像特征提取"></a>图像特征提取</h3><ol>
<li>特征提取</li>
</ol>
<img src="/8dbb3082/12.png" class>

<ul>
<li>特征提取作为某些统计特征来进行分类</li>
</ul>
<ol start="2">
<li>推动力</li>
</ol>
<img src="/8dbb3082/13.png" class>

<ul>
<li>特征提取的推动力在于将以前不能区分的类别，通过函数映射变化成为直观可区分的类</li>
</ul>
<ol start="3">
<li><p>实例</p>
<ol>
<li>Color Histogram:通过提取不同颜色通道的值作为特征</li>
<li>Histogram of Oriented Gradients (HoG)：通过提取图像的不同旋转方向的梯度统计直方图来作为特征</li>
<li>Bag of Words：通过提取某些分类的特征作为编码，比如猫的耳朵、青蛙的脚；再通过这些特征作为解码去恢复图片</li>
</ol>
</li>
<li><p>特征提取VS神经网络</p>
</li>
</ol>
<img src="/8dbb3082/14.png" class>

<ul>
<li><p>2012年前图片分类广泛采用特征提取+线性分类（特别是SVM），在特定领域方向具有价值，具有专用性，但缺乏通用性与广泛性。</p>
</li>
<li><p>2012年后imagenet的Alexnet网络已极高的准确率打败传统方法后，随着算力和数据爆炸式增长而崛起。</p>
</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 4 [2017版]</title>
    <url>/a4802501.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - Introduction to Neural Net</strong></li>
</ul>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><h4 id="计算图实例"><a href="#计算图实例" class="headerlink" title="计算图实例"></a>计算图实例</h4><ol>
<li>SVM</li>
<li>AlexNet卷积神经网络</li>
<li>神经网络图灵机</li>
</ol>
<img src="/a4802501/1.png" class>

<span id="more"></span>

<h4 id="反向传播–链式求导法则（核心）"><a href="#反向传播–链式求导法则（核心）" class="headerlink" title="反向传播–链式求导法则（核心）"></a>反向传播–链式求导法则（核心）</h4><ol>
<li>实例1：一个简单的计算</li>
</ol>
<img src="/a4802501/2.png" class>

<ol start="2">
<li>实例2：一个相对复杂的计算</li>
</ol>
<img src="/a4802501/3.png" class>

<p>如果知道sigmoid函数的求导公式，那么可以极大地简化该过程</p>
<img src="/a4802501/4.png" class>

<ol start="3">
<li>神经网络中的反向传播在分支处通过一级级的链式法则求导，使用当前已有的前后值替代。</li>
</ol>
<img src="/a4802501/5.png" class>

<ol start="4">
<li>反向传播在每一个分支点的操作：加法，分发下去；Max，路由选择，选中的相同，未选中的0；乘法，梯度转换。</li>
</ol>
<img src="/a4802501/6.png" class>

<ol start="5">
<li>计算图向后分支的反向传播为相加</li>
</ol>
<img src="/a4802501/7.png" class>

<ol start="6">
<li><p>向量的梯度计算–雅克比矩阵逆推</p>
<ul>
<li>以max函数为例<img src="/a4802501/8.png" class>
实际上max函数的矩阵是一个单位矩阵上，在对角线上max取值正确的为1，错误的为0，反向求导赋予就很方便；因此不需要求雅克比矩阵的所有维度，实际上1个mini-batch的大小为100，矩阵可能为 409600 * 409600，这样一个维度较大，超出内存。实际上并不需要去求一个矩阵，见下面这个例子。</li>
<li>以二次平方项为例<img src="/a4802501/9.png" class>
如上图可见，实际上在反向传播过程，大部分使用的前向函数参数的转置就ok。</li>
</ul>
</li>
<li><p>公式法+一步步逆推讲解矩阵乘法运算</p>
</li>
</ol>
<p>实际上对于一个包含scores和loss函数的公式及求响应的∂L/∂W如下：</p>
<img src="/a4802501/10.png" class>

<p>那么只对于单纯的一个f值而言，那么满足如下公式：</p>
<img src="/a4802501/11.png" class>

<p>那么只对W(1,1)求导而言，f的所有1行都包含对W(1,1)与x一行的乘积，而f中的每个值都是W的一行和x的一列的乘积，无法单纯的表示w(1,1)，但是如果求df/dw(1,1)，由于线性其他项消失，只剩下x(1,:)，因此满足一下公式：</p>
<img src="/a4802501/12.png" class>

<ol start="8">
<li><p>SVM梯度函数推导过程</p>
</li>
<li><p>Softmax梯度函数推导过程</p>
</li>
<li><p>系统结构与框架平台介绍</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">##SVM梯度矩阵表示</span></span><br><span class="line">margin[margin&gt;<span class="number">0</span>] = <span class="number">1</span> <span class="comment"># 大于0返回真值</span></span><br><span class="line">counter_r = np.<span class="built_in">sum</span>(margin, axis=<span class="number">1</span>)</span><br><span class="line">margin[<span class="built_in">list</span>(<span class="built_in">range</span>(num_train)),y] = -counter_r</span><br><span class="line">dW += np.dot(X.T,margin)/num_train +reg*W</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="2层神经网络"><a href="#2层神经网络" class="headerlink" title="2层神经网络"></a>2层神经网络</h3><h4 id="2层神经网络-1"><a href="#2层神经网络-1" class="headerlink" title="2层神经网络"></a>2层神经网络</h4><img src="/a4802501/13.png" class>

<p>传统的1层神经网络能够对前面的图片进行h层的特征处理，第2层可以对经过h层的特征处理</p>
<p>一个2层神经网络的训练代码可能仅仅需要20行，具体的代码训练在assignment1中</p>
<p>一个神经网络与实际神经网络的关系，树突相当于每层的汇聚，轴突相当于激活后的传输：</p>
<img src="/a4802501/14.png" class>

<p>对于每一个神经元会使用激活函数，将线性的结果转换为[0,1]之间，有利于压缩结果的空间，因为实际上神经元识别是有上限的。常用的激活函数有：Sigmoid、Tanh、ReLU、LeakyReLU、Maxout、ELU，各有优缺点</p>
<img src="/a4802501/15.png" class>

<p>常见的2、3层神经网络结构如下：</p>
<img src="/a4802501/16.png" class>

<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li><p>神经网络不是真的神经元，是一种仿真的结果，或者说是给神经网络的结构一个合理的解释</p>
</li>
<li><p>神经网络越大越好，层数越多越好，这个不完全成立，要看实际的情况。太大太深的网络容易过拟合（需要正则化），训练时间过长（无法解决）；当使用简单的数据时，深度起到的作用较少，每特征提取有限</p>
</li>
<li><p>用好已有的框架结构，将会极大地减小工作量</p>
</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 5 [2017版]</title>
    <url>/650efac1.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - Training Neural Networks I</strong></li>
</ul>
<h3 id="作业讲解"><a href="#作业讲解" class="headerlink" title="作业讲解"></a>作业讲解</h3><ul>
<li>Assignment2：CNN训练作业，预训练与细调，CNN先在ImageNet进行大量数据训练，在在小批量数据中进行训练。</li>
</ul>
<h4 id="CNN的迁移学习"><a href="#CNN的迁移学习" class="headerlink" title="CNN的迁移学习"></a>CNN的迁移学习</h4><img src="/650efac1/1.png" class>

<ul>
<li>可以先使用CNN在比如ImageNet这样的大数据集上先进行预训练，熟练好权重和超参数，去掉最上方的分类层，看成是一个固定特征提取器</li>
<li>自己的数据量较少的时候可以仅仅替换最后的分类层；如果有中等规模的数据，可以再细调几层的反向传播层。</li>
<li>已经有人在ImageNet各种数据上进行与训练模型，caffe model zoo，设置好大量超参数</li>
<li>电脑的计算资源是有限的，要权衡时间与效果</li>
</ul>
<span id="more"></span>

<h4 id="CNN发展的历史："><a href="#CNN发展的历史：" class="headerlink" title="CNN发展的历史："></a>CNN发展的历史：</h4><ol>
<li><p>1957年弗兰克-罗森布拉特制作了感知机：硬件实现的、电路电子元件实现的字母识别；激活函数使用的是二阶阶梯函数，没有微分；更新函数通过设置权值来得到比较满意的结果；没有损失函数，也没有反向传播。</p>
 <img src="/650efac1/2.png" class>
</li>
<li><p>1960年多层次感知机：依旧硬件实现；依旧没有反向传播，但是通过学习规则改变来观察是否得到更好结果；程序设计的观念升级，巨大的改变。</p>
 <img src="/650efac1/3.png" class>
</li>
<li><p>1980年鲁姆哈特第一次提出了损失函数、反向传播、梯度下降的概念，当时反向传播训练效果并不好</p>
 <img src="/650efac1/4.png" class>
</li>
<li><p>2006年辛顿Reinvigorated research in Deep Learning：10层无监督学习网络，一层层训练，然后集合在一起，整合起来进行反向传播。</p>
 <img src="/650efac1/5.png" class>

<ul>
<li>不使用预训练的方法是可以行的，但是一定要注意初始化函数的选用</li>
<li>这里使用的Sigmoid激活函数，但并不是合适的，后续会将激活函数的特点</li>
<li>2006年也有其他很多研究，深度学习这个词也是这一年流传，神经网络的变种。</li>
</ul>
</li>
<li><p>2010年-2012年语音识别的领域，神经网络比传统特征提取更加有效果；2012年在机器视觉比赛方面，AlexNet远远强于其他算法</p>
 <img src="/650efac1/6.png" class>

<ul>
<li>原因在于找到了对激活函数进行初始化的方法；GPU的出现导致的算力提升；互联网时代数据量的提升。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><img src="/650efac1/7.png" class>

<ul>
<li>激活函数是用来使得各层神经网络之间不是线性，不然多层神经网络将不起作用</li>
</ul>
<h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><img src="/650efac1/8.png" class>

<ul>
<li>由于模拟了神经元饱和的情况，取值在[0,1]，是历史上最常用的激活函数。</li>
<li>缺点1：饱和神经元，在函数的两边梯度为0，出现梯度消失。只有在sigmoid的激活区，训练才能正常进行下去。</li>
<li>缺点2：sigmoid函数不是中心对称，数据预处理过程总会希望是中心对称的；sigmoid的取值落在0,1之间，经过第一层后，每层 xi 值都是正值，将会导致每梯度值总会是一个方向的正值，这样计算得到的每一层的梯度值都是一个方向，优化只会朝着一个方向逼近，优化走阶梯方向，收敛速度慢。</li>
</ul>
<img src="/650efac1/9.png" class>

<ul>
<li>缺点3：exp()计算成本高、时间长</li>
</ul>
<h4 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h4><img src="/650efac1/10.png" class>

<ul>
<li>tanh相当于一个对称的sigmoid函数，是中心对称的，因此收敛效果比sigmoid好</li>
<li>缺点1：依旧是饱和神经元，在两边梯度为0时，依旧会出现梯度消失的现象。</li>
<li>缺点2：exp的计算依然耗费大量时间。</li>
</ul>
<h4 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h4><img src="/650efac1/11.png" class>

<ul>
<li>ReLU是线性非饱和函数，对SGD的加速效果非常明显，Alex Krizhevsky 指出有 6 倍之多。</li>
<li>ReLU只需要一个阈值就能够得到激活值，计算成本低。</li>
<li>正值的梯度值为1，只要学习率合适，那么对于优化的加速效果就会比较明显，上面的函数在两端时，梯度值下降严重，可能这就是快的原因。</li>
<li>缺点1：在小于0的值，梯度也为0，将没有激活作用。</li>
<li>缺点2：ReLU的神经元比较脆弱，训练过程中容易死掉：在初始化时神经元没有被激活；梯度值较大经过ReLU神经元，学习率太高导致训练中落入死去，导致数据多样化丢失，更新参数后，后续梯度为0.</li>
<li>训练方法：在进行一轮训练后，对梯度值进行检测，如果发现10%到20%的梯度死亡，那么就是学习率设置的太高</li>
</ul>
<h4 id="LeakyReLU-amp-PReLU"><a href="#LeakyReLU-amp-PReLU" class="headerlink" title="LeakyReLU &amp; PReLU"></a>LeakyReLU &amp; PReLU</h4><img src="/650efac1/12.png" class>

<ul>
<li>在负值时，给予-0.01的梯度，用来解决ReLU神经元死亡问题，但有时也并不一定会起作用</li>
<li>当然不一定是0.01，可以是一个参数 αx 形成一个超参数。</li>
</ul>
<h4 id="Exponential-Linear-Units-ELU"><a href="#Exponential-Linear-Units-ELU" class="headerlink" title="Exponential Linear Units(ELU)"></a>Exponential Linear Units(ELU)</h4><img src="/650efac1/13.png" class>

<ul>
<li>ELU是一个0均值的函数，效果会好一些，但实际上ReLU已经够用。纯属锦上添花，可能是用来发论文的，实际上属于学术上走偏的感觉。</li>
</ul>
<h4 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h4><img src="/650efac1/14.png" class>

<ul>
<li>与众不同的函数，改变了计算的变量和计算方式，使用两组参数进行计算，形成两个超平面，求其中的最大值进行计算，求导是最大值那组参数进行梯度更新，不断缩最后的损失函数。</li>
<li>非线性激活函数，仍然具有分段性和高效性</li>
<li>ReLU和Leaky ReLU的一般形式，没有ReLU的缺点，神经元不会失活死掉。</li>
<li>有两组参数值，两倍参数可能觉得方法并不理想，ReLU依然是使用最广泛的。</li>
</ul>
<hr>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><h4 id="Step1-数据预处理"><a href="#Step1-数据预处理" class="headerlink" title="Step1:数据预处理"></a>Step1:数据预处理</h4><img src="/650efac1/15.png" class>

<ul>
<li>PCA算法（主成分分析算法）：通过协方差矩阵可以求得特征向量U，然后把每个数据点，投影到这两个新的特征向量所在空间平面，把协方差矩阵变成对角矩阵；用于数据的降维。</li>
<li>Whiteniing算法：白化算法将协方差矩阵变成单位矩阵，用于使得数据在每一个维度都变得均匀。</li>
<li>过去的图像处理、机器学习中很常用，但是在深度学习中必要性降低。</li>
<li>PCA需要求取一个非常大的协方差矩阵，通常进行局部白化，在图像中加入一个白化过滤器，现在也不是很常用。</li>
</ul>
<h4 id="均值中心化"><a href="#均值中心化" class="headerlink" title="均值中心化"></a>均值中心化</h4><ul>
<li>对一幅图像求取均值，图像的每个像素点减去均值图像</li>
<li>在每个颜色通道上分别计算每个通道的颜色均值，然后通过减去每个通道的均值来进行去中心化</li>
<li>在深度学习中，使用这样的方法就足够，不需要过多的数据预处理，比如PCA和白化。</li>
</ul>
<hr>
<h3 id="权重初始化–很重要"><a href="#权重初始化–很重要" class="headerlink" title="权重初始化–很重要"></a>权重初始化–很重要</h3><h4 id="初始化的重要性"><a href="#初始化的重要性" class="headerlink" title="初始化的重要性"></a>初始化的重要性</h4><ol>
<li><p>假设权值为0，初始化10层网络，这样网络对称，那么每一层都是相同的，梯度值也相同，这样网络就无法得到训练。</p>
</li>
<li><p>方法1：小数字随机初始化，均值为0，标准差为1e-2的高斯分布。</p>
 <img src="/650efac1/16.png" class>

<ul>
<li><p>对于层数较少时是适用的，但是当层数较多时，那么高斯分布的参数，假如有10层，每层的值进行权重乘法以后，后续数值将乘以0.01，这样经过多层以后权重的分布就再也无法保持均值为0，标准差为1e-2的高斯分布。后续分布均值为0,标准差成指数下降，这样在后期只会分布在0上，多层以后输入为0，反向传播过程中求取的梯度值将会非常小，这样在反向传播中，每一层后最后梯度趋于0，这就是梯度消失现象。</p>
<img src="/650efac1/17.png" class>
</li>
</ul>
</li>
<li><p>方法2：使用1来代替0.01进行随机初始化</p>
<ul>
<li><p>对于tanh函数就会出现结果分布在两端-1和1，处于饱和区，后续计算所有神经元都饱和，梯度为0，损失函数将不会变，无法进行反向传播，没有权值得到更新。</p>
<img src="/650efac1/18.png" class>
</li>
</ul>
</li>
<li><p>Reaseonable初始化：使得神经元输出的方差为1。</p>
 <img src="/650efac1/19.png" class>

<ul>
<li><p>对于处于神经网络前面层的让权重输出在合适的范围，后续每层的权重都略有增大，可以有一个在预期中的范围，不饱和也不趋于0，这个方法能够在tanh中得到使用</p>
<img src="/650efac1/20.png" class>
</li>
<li><p>但是对于ReLU的情况，加权计算将失败，ReLU是半边函数,将方差的权重缩小了一半，因此要给他补上一个2。</p>
<img src="/650efac1/21.png" class>

<img src="/650efac1/22.png" class>
</li>
</ul>
</li>
</ol>
<ul>
<li>这些都是策略性的内容，可以使得深度学习走的更远的原因</li>
</ul>
<hr>
<h3 id="Batch-Normalization（批归一）"><a href="#Batch-Normalization（批归一）" class="headerlink" title="Batch Normalization（批归一）"></a>Batch Normalization（批归一）</h3><img src="/650efac1/23.png" class>

<ol>
<li><p>BN的意义</p>
<ul>
<li>随机梯度下降法（SGD）对于训练深度网络简单高效，但人为的去选择参数，比如学习率、参数初始化、权重衰减系数、Drop out比例等。这些参数的选择对训练结果至关重要，以至于我们很多时间都浪费在这些的调参上。那么使用BN（详见论文《Batch Normalization_ Accelerating Deep Network Training by Reducing Internal Covariate Shift》）之后，你可以不需要那么刻意的慢慢调整参数。</li>
<li>在训练的过程中，每一层的激活函数后的输出将会作为后一层的输入，这样当神经网络进行训练后，前级输出极大地影响后续的结果，而进行BN后，归一化的结果将降低前级对后级的影响</li>
</ul>
</li>
<li><p>BN的原理</p>
 <img src="/650efac1/24.png" class>

<ul>
<li>对于N个图像的D维特征，每一层进行均值和方差计算，这样保证每一个特征都满足高斯标准化。</li>
<li>BN插入在激活函数前，这样讲权重乘法后的输入归一到均值为0，方差为1，这样经过激活函数后的输出的数据分布依然保持均匀性。</li>
</ul>
</li>
<li><p>BN的参数调节</p>
 <img src="/650efac1/25.png" class>

<ul>
<li>神经网络学习到的数据本身就是在分布在激活函数两侧，那么归一将会打断前后层的之间的关系，因此引入变换重构，可学习参数γ、β。</li>
<li>同时当2、3式子成立时，相当于取消BN算法。因此当发现BN能够使得网络优化效果增强，可以采用BN算法调节，反之则通过参数取消BN算法。</li>
<li>实际上不是对于每一个特征都拥有一个γ、β，而是对于每一层的特征图，使用参数共享的方式</li>
</ul>
</li>
<li><p>BN的优点</p>
 <img src="/650efac1/26.png" class>

<ul>
<li>优化流向网络中的梯度，支持更高的学习率，能够快速训练模型。</li>
<li>由于使用了归一化的方法，使得每层结果趋向于均值0，方差1，解决梯度消失问题；降低对于合理初始化的依赖性，可以更加随机的使用初始化值</li>
<li>改善正则化策略：作为正则化的一种形式，减少对于dropout的依赖。</li>
<li>可以将训练数据打乱，经过归一化后将会增强统一性，能够提高1%的精度。</li>
<li>在测试时，均值和方差不基于小批量进行计算，可以使用训练过程中的计算得到值的均值。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="跟踪训练过程"><a href="#跟踪训练过程" class="headerlink" title="跟踪训练过程"></a>跟踪训练过程</h3><ol>
<li>预处理数据</li>
</ol>
<img src="/650efac1/27.png" class>

<ol start="2">
<li>选择合适的网络结构</li>
</ol>
<img src="/650efac1/28.png" class>

<ol start="3">
<li><p>迭代输出损失函数和准确率</p>
<ul>
<li>检查损失函数：将正则化参数调大1e3，与无正则化相比，观察损失函数是否增大，增大即是合理的</li>
<li>小批量数据进行训练：关闭正则化，观察损失函数将下降，准确率应该逼近100%</li>
<li>小正则化参数、调节合适学习率：训练时发现损失函数下降很慢，准确率有增大，但是结果较差，属于学习率太低；损失函数出现NaN，表示学习率太高。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="超参数优化"><a href="#超参数优化" class="headerlink" title="超参数优化"></a>超参数优化</h3><ol>
<li><p>交叉验证策略</p>
 <img src="/650efac1/29.png" class>
<ul>
<li>将训练集划分为多个交叉验证集mini-batch，选择不同的参数作为集合，进行小批量参数验证。</li>
<li>使用较少的迭代次数来进行验证哪些参数是合适，损失函数下降快，准确率增大快。</li>
<li>精细化参数设置，长时间进行验证，选择到合适的参数。</li>
<li>探测到损失函数爆炸现象：损失函数增大为原来值的3倍，需要中断函数，减少时间浪费。<img src="/650efac1/30.png" class></li>
<li>使用log空间阈值进行参数搜索<img src="/650efac1/31.png" class></li>
<li>精细化搜索，调节空间域范围<img src="/650efac1/32.png" class></li>
<li>随机搜素使得参数在空间份上更加均匀<img src="/650efac1/33.png" class></li>
<li>监测并可视化准确率，分析哪些参数变动导致准确率变化，推测原因，修正超参数：网络层数；每层神经元数目；学习率、衰减率、更新模型；正则化。</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 6 [2017版]</title>
    <url>/fcec9cc0.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - Training Neural Networks II</strong></li>
</ul>
<h3 id="精细优化"><a href="#精细优化" class="headerlink" title="精细优化"></a>精细优化</h3><h4 id="SGD的优化问题"><a href="#SGD的优化问题" class="headerlink" title="SGD的优化问题"></a>SGD的优化问题</h4><ol>
<li><p>不同维度梯度问题</p>
 <img src="/fcec9cc0/1.png" class>

<ul>
<li>比如在趋近最优解的维度，梯度下降的慢，而在垂直方式梯度下降的快，梯度下降的和方向在偏离正确方向太远，这样优化过程中逼近最优解速度慢，这也是SGD速度最慢的原因</li>
</ul>
</li>
</ol>
<span id="more"></span>

<ol start="2">
<li><p>极值点问题</p>
 <img src="/fcec9cc0/2.png" class>

<ul>
<li>当遇到局部最小值点及鞍点时，SGD会陷入局部最优；由于数据维度较大，很难存在局部最小值点的情况，鞍点的存在可能性更大</li>
<li>个人认为SGD是在每个小批量上进行优化训练，那么实际上损失函数和梯度时存在波动性，这要局部最小值和鞍点不是很严重的话，应该是可以跳出的。</li>
</ul>
</li>
<li><p>噪声问题</p>
 <img src="/fcec9cc0/3.png" class>

<ul>
<li>由于SGD是在小批量上进行测试的，那么实际上优化过程会有很多波动性，这样就会导致优化逼近存在很大噪声。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="SGD-Momentum"><a href="#SGD-Momentum" class="headerlink" title="SGD + Momentum"></a>SGD + Momentum</h4><img src="/fcec9cc0/4.png" class>

<ul>
<li>引入速度V的概念，将以前的梯度考虑进去，给当前梯度更新增加一定的动量，就是梯度实际下降比当前计算的值大，这样即使在鞍点和局部最优点位置也会由于额外引入的动量冲过去，当然如果极致和鞍点区域很大，那么将会导致实际上无法冲过，这样需要增大动量的影响。</li>
<li>实际上如果考虑系数0.1以下时之前的梯度不会再产生影响，那么0.9^22=0.098,0.99^229=0.099,这样实际上动量的影响会不会比较大，实际上在后期时动量的影响增大，可能无法趋近与最佳值，但实际上后期的梯度都很小，一般不会出现这样问题。</li>
<li>实际上从信号处理的角度来讲，相当于给梯度更新增加了一个滑动滤波器，前面的梯度会被一次次以不同的系数划过，这也是能够降低噪声的原因。实际上可以设计一个模板，只取若干梯度及衰减进行更新，但实际上也没有太大意义。</li>
</ul>
<img src="/fcec9cc0/5.png" class>

<ul>
<li>很明显SGD + Momentum的更新方法，速度更快，噪声更小，但是在后期可能存在波动。</li>
</ul>
<hr>
<h4 id="Nesterov-Momentum（NAG）"><a href="#Nesterov-Momentum（NAG）" class="headerlink" title="Nesterov Momentum（NAG）"></a>Nesterov Momentum（NAG）</h4><img src="/fcec9cc0/6.png" class>

<ul>
<li>与传统的Momentum的区别在于，以骑自行陈为例，M相当于在冲量的加速下骑到一个地方，然后根据当前坡度，决定车往哪走。但是NAG相当于在冲量的加速下，先用眼镜看一下前方的位置的坡度，再决定车往哪走，也就是或NAG有预判修正的作用，避免走冤枉路。因此优化过程梯度下降较为平滑</li>
<li>NAG在凸优化问题中，尤其是对平滑度较高的函数有很好的效果，但实际深度学习中由于数据的复杂性，还是需要看实际结果进行参数调整。</li>
<li>变换的目的，是不需要在去算一个预判的梯度，而使用当前参数的梯度进行计算，是一种近似。</li>
</ul>
<hr>
<h4 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h4><img src="/fcec9cc0/7.png" class>

<ul>
<li>这个算法字面的意思就是Adaptive Gradient，自适应学习率，初始使用一个较大的学习率，后期在逼近最优值的过程不断减小学习率。</li>
<li>AdaGrad非常适合样本稀疏的问题，稀疏意味着样本间相似性小，样本稀疏，每次梯度下降的方向以及涉及的变量都可能有很大的差异，这样自适应学习就非常实用。</li>
<li>该算法的缺点是初始的全局学习率需要手工指定，全局学习率过大，优化同样不稳定；学习率过低，在学习过程中学习率不断下降，没到极值可能就停止了。</li>
</ul>
<hr>
<h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><img src="/fcec9cc0/8.png" class>

<ul>
<li>该算法的改进在于将累计梯度信息从全部历史梯度变为当前时间向前的一个窗口期内的积累，有些类似Momentum的速度的累加，这样解决AdaGrad持续下降的问题</li>
<li>实际上类似的还有AdaDelta，该算法还解决了手动设置学习率的问题，不需要手动设置学习率。</li>
</ul>
<hr>
<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><img src="/fcec9cc0/9.png" class>

<p>该算法将Momentum与AdaGrad/RMSProp结合起来，结合两者的优点。</p>
<hr>
<h4 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a>学习率衰减</h4><img src="/fcec9cc0/10.png" class>

<ul>
<li>包括步进下降法；指数衰减法；1/t衰减法</li>
<li>实际上学习率的衰减更适用于Momentum等算法，毕竟Ada类算法都是自带学习率下降的。</li>
</ul>
<hr>
<h4 id="二阶优化-LBFGS"><a href="#二阶优化-LBFGS" class="headerlink" title="二阶优化-LBFGS"></a>二阶优化-LBFGS</h4><img src="/fcec9cc0/11.png" class>

<ul>
<li>利用泰勒二阶展开和牛顿参数来进行参数权重更新，优点是没有超参数，没有学习率，但缺点是用到Hessian矩阵（二阶偏导矩阵）计算量复杂</li>
<li>牛顿近似法（BFGS）–参照《深度学习与计算机视觉》一书P75-P77，讲解很细致。</li>
<li>L-BFGS (Limited memory BFGS):不在存储整个海森矩阵的转置，只存储部分需要使用的。</li>
<li>LBFGS通常在全批量数据，f(x)确定性模式下工作得很好；不要在分割训练集mini-batch上使用它，要在大尺寸随- 机性强训练集上使用。</li>
</ul>
<hr>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul>
<li>在深度学习中的实际应用中，因为问题的高维度和高复杂性的特点，具体使用哪种算法那还是需要具体的尝试，一般情况下带冲量的梯度下降还是主流，但是对于收敛不好的情况下，可能使用自适应算法往往会有意想不到的效果。不过一般的情况是在优化的后期，自适应算法尤其是AdaDelta和RMSProp往往会反复震荡，反而不如带冲量的梯度下降法。</li>
</ul>
<hr>
<h3 id="集成模型与正则化"><a href="#集成模型与正则化" class="headerlink" title="集成模型与正则化"></a>集成模型与正则化</h3><h4 id="集成模型"><a href="#集成模型" class="headerlink" title="集成模型"></a>集成模型</h4><ul>
<li><p>训练多个独立的模型；在测试时取结果的平均值——往往从统计的观点能有2%的额外优化</p>
</li>
<li><p>技巧1：可以使用循环的学习率来优化模型，如下图所示：</p>
</li>
</ul>
<img src="/fcec9cc0/12.png" class>

<ul>
<li>技巧2：对训练的权重进行滑动平均，这样在最后波动位置平均值可能更接近最优值</li>
</ul>
<img src="/fcec9cc0/13.png" class>

<h4 id="L2和L1正则化"><a href="#L2和L1正则化" class="headerlink" title="L2和L1正则化"></a>L2和L1正则化</h4><img src="/fcec9cc0/14.png" class>

<ul>
<li>之前用过的L1、L2正则化，以及集成正则化</li>
</ul>
<h4 id="Dropout原理"><a href="#Dropout原理" class="headerlink" title="Dropout原理"></a>Dropout原理</h4><img src="/fcec9cc0/15.png" class>

<ul>
<li>Dropout通过设定一定的概率来在每一层失活一定的神经元，这样的好处在于能够使得神经网络变得稀疏，从而减少过拟合现象，提高准确率。</li>
<li>Dropout的实现是通过一个掩模矩阵与激活函数结果矩阵相乘，求梯度时采用相同的步骤乘以转置即可。</li>
<li>解释1：丢掉神经元降低网络的冗余性，同时单次训练中，随机地丢弃神经元，减少提取的特征的互相适应性，保证网络的简洁。</li>
<li>解释2：神经网络是一个大的网络，大网络是由不同小网络构成，但是小网络间参数并不能很好的训练，经过随机失活一部分网络后，在失活的神经元输出为0，反向传播经过其及以后的网络也为0，意味着每次训练都是随机地对一个小网络进行参数更新，但是最后这些小网络构成的大网络具备了随机性。</li>
<li>当然也有算法使用固定失活某些神经网络</li>
</ul>
<h4 id="Dropout的Test-time"><a href="#Dropout的Test-time" class="headerlink" title="Dropout的Test time"></a>Dropout的Test time</h4><img src="/fcec9cc0/16.png" class>

<ul>
<li>训练时随机失活一部分网络，但是测试时是一个完整的网络，这样最后的测试输出值偏大，需要进行乘以概率p修正。</li>
<li>当然更常见的做法是在掩模矩阵位置除以整个概率p，也可以修正。</li>
<li>当然实际上期望值与随机失活值是略有不同的，乘以概率p其实会有一些误差，但由于神经元数据大随机性，这点误差可以忽略。</li>
<li>增加网络训练随机性的一般的形式</li>
</ul>
<img src="/fcec9cc0/17.png" class>

<h4 id="梯度检查–确保模型计算的准确性"><a href="#梯度检查–确保模型计算的准确性" class="headerlink" title="梯度检查–确保模型计算的准确性"></a>梯度检查–确保模型计算的准确性</h4><h4 id="数据增加-Augmentation"><a href="#数据增加-Augmentation" class="headerlink" title="数据增加-Augmentation"></a>数据增加-Augmentation</h4><img src="/fcec9cc0/18.png" class>

<ul>
<li>通过对一张图片进行一系列的操作从而增加样本数据量，增加样本多样性，减少标定时间，节约成本。</li>
<li>图像水平翻转，简单而又有效地样本数据增加。</li>
<li>残差网络，训练：随机剪裁、压缩尺度、固定大小随机剪裁；测试：按照5个尺度压缩图片，每个尺度进行4个角+中心，水平翻转。</li>
<li>颜色调整，简单：调整对比度、亮暗、饱和度；复杂，在RGB进行PCA算法、添加颜色偏移在主成分方向、添加颜色偏移到整幅图像。</li>
<li>发挥想象力，还可以有更多方法：扭曲、变形、拉伸、位移、旋转、剪裁、光学畸变等等。</li>
</ul>
<h4 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h4><ul>
<li>BN；DropConnect;Fractional Max Pooling - 部分池化;随机网络深度</li>
</ul>
<hr>
<h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><h4 id="CNN上的迁移"><a href="#CNN上的迁移" class="headerlink" title="CNN上的迁移"></a>CNN上的迁移</h4><img src="/fcec9cc0/19.png" class>

<h4 id="CNN迁移例子"><a href="#CNN迁移例子" class="headerlink" title="CNN迁移例子"></a>CNN迁移例子</h4><img src="/fcec9cc0/20.png" class>

<h4 id="数据驱动、模型使用"><a href="#数据驱动、模型使用" class="headerlink" title="数据驱动、模型使用"></a>数据驱动、模型使用</h4><img src="/fcec9cc0/21.png" class>

<ul>
<li>Caffe: <a href="https://github.com/BVLC/caffe/wiki/Model-Zoo">https://github.com/BVLC/caffe/wiki/Model-Zoo</a></li>
<li>TensorFlow: <a href="https://github.com/tensorflow/models">https://github.com/tensorflow/models</a></li>
<li>PyTorch: <a href="https://github.com/pytorch/vision">https://github.com/pytorch/vision</a></li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 7 [2017版]</title>
    <url>/3d624300.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - Convolutional Neural Networks</strong></li>
</ul>
<h3 id="卷积神经网络历史-略过"><a href="#卷积神经网络历史-略过" class="headerlink" title="卷积神经网络历史-略过"></a>卷积神经网络历史-略过</h3><ul>
<li><p>具体参照Lecture5已经总结</p>
</li>
<li><p>CNN适用于分类、恢复、探测、分割，随着GPU的兴起和互联网数据的增大，CNN现在是无处不在。以风格迁移为例。</p>
</li>
</ul>
<img src="/3d624300/1.png" class>

<span id="more"></span>

<hr>
<h3 id="卷积神经网络层"><a href="#卷积神经网络层" class="headerlink" title="卷积神经网络层"></a>卷积神经网络层</h3><img src="/3d624300/2.png" class>

<ul>
<li>典型的神经网络构成：卷积层+池化层+全连接层</li>
</ul>
<h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><img src="/3d624300/3.png" class>

<ul>
<li><p>三维卷积与一维、二维的卷积意义是一样的，都是滤波器的作用，传统的都是需要人为设置各种特征提取的滤波器，而CNN的滤波器是可以训练出不同功能的，全面而又强大</p>
</li>
<li><p>这个地方关于滤波的内容吴恩达的深度学习课程中讲解的更为透彻。</p>
</li>
</ul>
<img src="/3d624300/4.png" class>

<ul>
<li>经过两层卷积层后的数据结构变化，维度从32<em>32–28</em>28–24*24，宽和高是在缩小，深维度由每层滤波器个数决定。</li>
</ul>
<img src="/3d624300/5.png" class>

<ul>
<li>卷积神经网络不同层提取的特征不一样，越靠前的网络提取的特征越简单，越往后越复杂，可以通过可视化的展现来观察不同层的功能。</li>
</ul>
<img src="/3d624300/6.png" class>

<ul>
<li>经过卷积层后，数据维度变化规律，必须满足输出是整数才能运行，除不尽的情况不合理。</li>
</ul>
<img src="/3d624300/7.png" class>

<ul>
<li>实际上如果我们的层数比较多，100层，经过这样的维度下降后，宽和高无法维系，因此需要使用zero padding来保持维度不变。</li>
</ul>
<img src="/3d624300/8.png" class>

<ul>
<li>实际上对于卷积层，参数包括；滤波器数量K、滤波器大小F、步长S和填充padding；实际上可以用偶数滤波器，但不常见，因为偶数没有中间，通常3是最常见的最小滤波器大小。</li>
</ul>
<img src="/3d624300/9.png" class>

<ul>
<li>1维滤波器经常有特殊用法，用于对不同深度进行成比例混合压缩，重建新的深度维度，而维持长宽不变。</li>
</ul>
<hr>
<h4 id="卷积层与人脑的解释"><a href="#卷积层与人脑的解释" class="headerlink" title="卷积层与人脑的解释"></a>卷积层与人脑的解释</h4><img src="/3d624300/10.png" class>

<hr>
<h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><img src="/3d624300/11.png" class>

<ul>
<li><p>在卷积层尽量保持维度的不变行，但是滤波器数量大的时候，需要经过池化层对数据维度进行降低，与卷积层相同，通常关注池化滤波器大小K以及步长S。</p>
</li>
<li><p>池化包括最大层池化、均值池化等。</p>
</li>
</ul>
<hr>
<h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><ul>
<li>全连接层与之前的神经网络层相同就是用来最后进行分类的层。</li>
</ul>
<hr>
<h3 id="神经网络Cases"><a href="#神经网络Cases" class="headerlink" title="神经网络Cases"></a>神经网络Cases</h3><img src="/3d624300/12.png" class>

<ul>
<li>图片识别错误率下降过程</li>
</ul>
<h4 id="LeNet-5–1998"><a href="#LeNet-5–1998" class="headerlink" title="LeNet-5–1998"></a>LeNet-5–1998</h4><img src="/3d624300/13.png" class>

<h4 id="AlexNet–2012"><a href="#AlexNet–2012" class="headerlink" title="AlexNet–2012"></a>AlexNet–2012</h4><img src="/3d624300/14.png" class>

<h4 id="ZFNet–2013"><a href="#ZFNet–2013" class="headerlink" title="ZFNet–2013"></a>ZFNet–2013</h4><img src="/3d624300/15.png" class>

<h4 id="VGGNet–2014"><a href="#VGGNet–2014" class="headerlink" title="VGGNet–2014"></a>VGGNet–2014</h4><img src="/3d624300/16.png" class>
<img src="/3d624300/17.png" class>

<h4 id="GoogLeNet–2014"><a href="#GoogLeNet–2014" class="headerlink" title="GoogLeNet–2014"></a>GoogLeNet–2014</h4><img src="/3d624300/18.png" class>
<img src="/3d624300/19.png" class>
<img src="/3d624300/20.png" class>

<h4 id="ResNet–2015"><a href="#ResNet–2015" class="headerlink" title="ResNet–2015"></a>ResNet–2015</h4><img src="/3d624300/21.png" class>
<img src="/3d624300/22.png" class>
<img src="/3d624300/23.png" class>
<img src="/3d624300/24.png" class>

<h4 id="计算、时间复杂度、能量复杂度"><a href="#计算、时间复杂度、能量复杂度" class="headerlink" title="计算、时间复杂度、能量复杂度"></a>计算、时间复杂度、能量复杂度</h4><img src="/3d624300/25.png" class>
<img src="/3d624300/26.png" class>

<h4 id="其他结构–雨后春笋般冒出来"><a href="#其他结构–雨后春笋般冒出来" class="headerlink" title="其他结构–雨后春笋般冒出来"></a>其他结构–雨后春笋般冒出来</h4><ul>
<li>Network in Network (NiN)–2014</li>
<li>Identity Mappings in Deep Residual Networks–2016</li>
<li>Wide Residual Networks–2016</li>
<li>Aggregated Residual Transformations for Deep Neural Networks (ResNeXt)–2016</li>
<li>Deep Networks with Stochastic Depth–2016</li>
<li>FractalNet: Ultra-Deep Neural Networks without Residuals–2017</li>
<li>Densely Connected Convolutional Networks–2017</li>
<li>SqueezeNet: AlexNet-level Accuracy With 50x Fewer Parameters and &lt;0.5Mb Model Size–2017</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 8 [2017版]</title>
    <url>/ae9ab7c6.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - Deep Learning Software</strong></li>
</ul>
<h3 id="CPU-和-GPU-对比"><a href="#CPU-和-GPU-对比" class="headerlink" title="CPU 和 GPU 对比"></a>CPU 和 GPU 对比</h3><h4 id="CPU-与-GPU-的比较"><a href="#CPU-与-GPU-的比较" class="headerlink" title="CPU 与 GPU 的比较"></a>CPU 与 GPU 的比较</h4><img src="/ae9ab7c6/1.png" class>

<span id="more"></span>

<p>CPU和GPU都是通用的计算机器，它们可以执行程序和一些指令。但它们在性质上是非常不同的。</p>
<p>CPU只有为数不多的核数，利用多线程技术，可以在硬件上同时运行多个线程，CPU可以同时运行二十种操作，虽然数量不大，但是CPU的线程实际上非常有用，它们可以实现很多操作，并且运行速度非常快，而且它们的运作相互独立。</p>
<p>高端的GPU有成千上万个核，GPU第一个缺点就是它的每一个核运行速度都非常缓慢，第二个缺点是每一个核可以执行的操作没有CPU多，不能跟CPU的核和GPU的核进行直接比较。   GPU的核没有办法独立操作，它们需要共同协作，即GPU多个核共同执行同一项任务，而不是每个核做各自的事情。GPU有大量核数，当我们需要同时执行多种操作的时候，GPU并行处理能力非常棒，但这些事情本质上是相同的。GPU和CPU还有一点需要指明的是内存的概念，CPU有高速缓存，但是相对比较小，我们拥有CPU的大部分缓存，都是依赖于系统内存（在台式机上RAM的容量），而GPU在芯片中内置了RAM，如果是系统RAM和GPU通信，会带来严重的性能瓶颈，所以GPU基本上自己自带相对较大的内存。GPU也有自己的缓存系统，所以在GPU内存和GPU核之间有多级缓存，实际上跟CPU的多级缓存是相似的。</p>
<p>CPU对于通信处理来说是足够的，它们可以做各种各样的事，GPU更擅长于处理高度并行处理的算法，其中一个典型的性能很好又完全适用于GPU的一个算法就是矩阵乘法，CPU可能会串行计算。在这种平行任务，特别是矩阵变得非常庞大的时候，GPU表现更好。</p>
<img src="/ae9ab7c6/4.png" class>

<hr>
<h4 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h4><img src="/ae9ab7c6/5.png" class>

<p>在这些网络上做实验，GPU性能是CPU的64~76倍。</p>
<p>优化过的cuDNN VS 原生CUDA版代码：</p>
<img src="/ae9ab7c6/6.png" class>

<p>所以用GPU时，我们应该使用cuDNN，可以获得更好的性能。</p>
<hr>
<h4 id="实践中的问题"><a href="#实践中的问题" class="headerlink" title="实践中的问题"></a>实践中的问题</h4><p>在实际中有一个问题是，在训练网络的时候模型可能存储在GPU上，比如模型的权重存储在GPU内存上，但是庞大的数据集却存储在电脑硬盘上，如果不小心就可能让从硬盘读取数据的环节成为训练速度的瓶颈，因为GPU速度非常快，它计算正向，反向传播的速度非常快，但是从旋转的机械硬盘上串行地读取数据会拖慢训练速度。有一些解决办法，如果训练数据集非常小，可以把整个数据集读到内存中，也可以用固态硬盘代替机械硬盘，这样读入速度会有较大提升。另外一些常用的思路是在CPU上使用多线程来预读数据，把数据读出内存或者读出硬盘，存储到内存上，这样就能连续不断地将缓存数据比较高效地送给GPU，但是这些做法不容易实现，因为GPU太快了，如果不快速将数据发送给GPU,仅仅读取数据这一项就会拖慢整个训练过程。</p>
<ul>
<li>学生提问1：在写代码时，怎样才能有效地避免前面提到的问题？</li>
<li>从软件上来说，可能能做到的最有效的事情是设定好CPU的预读内容，比如避免这种比较笨的序列化操作，先把数据从硬盘里读出来，等待小批量的数据，一批一批地读完，然后依次送到GPU上，做正向和反向传播，按顺序这样做。如果有多个CPU线程在后台从硬盘中搬运出数据，这样可以把这些过程交错着运行起来，在GPU运行的同时，CPU的后台线程从硬盘中读取数据，主线程等待这些工作完成，在它们之间做一些同步化，让整个流程并行起来。但是这些实现起来比较麻烦，好在现在主流深度学习框架已经替我们完成了这些工作。</li>
</ul>
<hr>
<h3 id="常用深度学习框架"><a href="#常用深度学习框架" class="headerlink" title="常用深度学习框架"></a>常用深度学习框架</h3><p>被主流使用的第一代深度学习框架大多是由学术界完成的，但是下一代深度学习框架全部由工业届产生。</p>
<img src="/ae9ab7c6/2.png" class>

<h4 id="计算图思想和深度学习框架"><a href="#计算图思想和深度学习框架" class="headerlink" title="计算图思想和深度学习框架"></a>计算图思想和深度学习框架</h4><p>无论何时我们进行深度学习，都要考虑构建一个计算图来计算任何我们想要计算的函数。比如在线性分类器的情况下，我们对数据X和权值W进行矩阵乘法或者做一些Loss函数来计算损失，也会使用一些正则项，我们企图把这些不同的操作拼起来，成为图结构。</p>
<img src="/ae9ab7c6/7.png" class>

<p>在大型神经网络面前，这些图结构会非常复杂，有很多不同的层不同的激活函数，不同的权重，如果我们画成计算图会非常庞大，甚至不能画出来，所以深度学习框架意义重大，我们使用这些框架有三个主要原因：</p>
<ol>
<li><p>这些框架可以使我们非常轻松地构建和使用一个庞大地计算图，而且不用自己去管那些细节的东西。</p>
</li>
<li><p>可以很方便地自动计算梯度，可以处理所有反向传播的细节，所有我们可以仅仅考虑如何写出我们网络的前向传播，反向传播会直接被给出。</p>
</li>
<li><p>这些东西可以高效地在GPU上运行，我们不用关注一些底层的硬件上的细节，像cuBLAS,cuDNN,CUDA以及数据在CPU和GPU内存之间的移动。</p>
</li>
</ol>
<p>我们可能能自己用numpy构建一些简单地神经网络，但是Numpy的缺点是它不能运行在GPU上，而且这种情况下只能自己计算梯度。</p>
<hr>
<h4 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h4><img src="/ae9ab7c6/8.png" class>

<p>如图所示，tensorflow中通常可以把计算划分为两个主要阶段，1.首先我们先用一段代码来定义我们的计算图，就是上半部分红色框的部分，2.然后可以定义自己的图，这个图会运行数次，实际上可以将数据输入到计算图中，去实现任意想要的运算。这是tf中非常通用的一种模式，首先用一段代码构建图，然后运行图模型，重复利用它。</p>
<h5 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h5><p>对红色框中代码进行分析：</p>
<p>从顶部的代码可以看到，我们定义了X,Y和W，并且创建了这些变量的tf.placeholder对象，所以这些变量会成为图中的输入结点，这些结点会是图中的入口结点，当我们运行图模型时，会输入数据将它们放到我们计算图中的输入槽中，然后我们用这些输入槽，就是这些符号变量，在这些符号变量上执行各种tensorflow操作以便构建我们想要运行在这些变量上的计算。因此基于这些情况我们做了一个矩阵乘法，使用tf.maximum来实现relu的非线性特性，然后用另一个矩阵乘法来计算我们的输出预测结果，然后我们又用基本的张量运算来计算欧式距离，以及计算目标值y和预测值之间的L2损失。需要指出的是，<strong>这里几行代码没做任何实质上的运算，目前系统里还没有任何数据，我们只是建立计算图数据结构，来告诉tensorflow当输入真实数据时，我们希望最终执行什么操作</strong>。因此这仅仅是建立图模型，没有做任何操作。然后在完成损失值运算后的一行代码是让tf去直接计算损失值在w1和w2方向上的梯度。</p>
<p>对蓝色框中代码进行分析：</p>
<p>这时候我们已经完成了计算图的构建，内存中已经存储了计算图数据结构的数据，现在我们进入一个tensorflow的会话，来实际运行计算图并且输入数据。一旦我们进入会话，就需要建立具体的数据，来输入给计算图。所以大多数时候，tf只是从Numpy数组接受数据，这里我们只是用Numpy为X Y和w1 w2创建具体的数值，并在字典中进行存储。这时候我们才是真正在运行计算图，可以看到我们调用了session.run来执行部分计算图的运算，并且计算需要的值然后向numpy数组再次返回具体的数值。至此我们只是在计算图上完成了正向和反向传播，如果想训练网络，我们只需添加几行代码。</p>
<img src="/ae9ab7c6/9.png" class>

<hr>
<h5 id="变量保存在计算图中"><a href="#变量保存在计算图中" class="headerlink" title="变量保存在计算图中"></a>变量保存在计算图中</h5><p>但是这里有个问题，我们每次用计算图进行前向传播时，我们实际上在对权重进行输入，我们将权重保存成numpy的形式，我们直接将它输入到计算图中，当计算图执行完毕，我们会得到这些梯度值，这些梯度值的个数与权重值的个数一致，这意味着我们每次运行图的时候，我们将从numpy数组中复制权重到tensorflow中才能得到梯度，然后从tf中复制梯度到numpy数组，我们如果只是在cpu中运行可能不是大问题，但是我们曾谈到CPU和GPU之间的传输瓶颈，要在CPU和GPU之间进行数据复制非常耗费资源，所以如果我们的网络非常大，权重值和梯度非常多，这样做就很耗费资源而且很慢，因为每个时钟周期都在CPU和GPU之间拷贝资源。tensorflow已经有了解决方案，这个想法就是将权重w1和w2定义为变量，而不是每次前向传播时都将它们作为需要输入网络的占位符，变量可以存在计算图中，并且当我们在不同时间运行相同计算图时，它都可以保存在计算图中，就是因为它们存在于计算图中，我们需要告诉tf,如何对它进行初始化。在上面的代码中，我们从计算图外部输入这些值，所以我们在numpy中对它进行初始化，但是现在它们存在于计算图中，因此tf复制初始化这些值，所以我们要执行tf.Variable(tf,random_normal((D,H))等操作，如下图：</p>
<img src="/ae9ab7c6/10.png" class>

<p>同样也不是真正地初始化它们，当运行这些代码时，它只是告诉tf，我们需要怎么样进行初始化。在之前的例子中，我们在计算图中计算梯度，然后以numpy array的形式更新权重参数，然后在下一次迭代时利用这些更新过的权重参数，但是我们现在希望在计算图中操作，更新参数的操作也需要成为计算图中的一个操作，所以现在我们利用这个赋值函数，其能够在计算图中改变参数值：</p>
<img src="/ae9ab7c6/11.png" class>

<p>然后这些变化的值会在计算图的多次迭代之后，仍然保存。</p>
<p>当我们执行计算图，训练这个网络的时候，需要首先进行一个全局参数的初始化操作，告诉tf来设置计算图中的这些操作，如下图中第一个箭头所示。当完成初始化后，我们可以以此又一次地运行计算图，这里我们只输入了数据X和标签Y，计算图中的权重参数，我们要求tf帮我们计算loss，如下图第2个箭头所示。</p>
<img src="/ae9ab7c6/12.png" class>

<p>全部代码如下：</p>
<img src="/ae9ab7c6/13.png" class>

<hr>
<h5 id="变量的更新"><a href="#变量的更新" class="headerlink" title="变量的更新"></a>变量的更新</h5><p>但是这里有一个bug，如果我们运行这个代码，把loss打印出来，发现它并没有进行训练：</p>
<img src="/ae9ab7c6/14.png" class>

<p>因为我们必须明确地告诉tensorflow，我们想用new_w1和new_w2来执行操作，我们在显存中建立了这么大的计算图架构，当我们执行操作时，只告诉tf我们想计算loss，但没有执行更新的操作。所以这个问题的解决方案是，我们必须明确地告诉tf来执行这些更新操作，我们需要做的一件事是，我们应该添加new_w1和new_w2作为输出。但是这里还有一个问题，这些new_w1和new_w2都是非常大的tensor，当我们告诉tensorflow我们需要这些输出时，我们在每次迭代中就会在GPU和CPU之间执行这些操作，这样比较麻烦。所以这里有一个小技巧，我们在图中添加一个仿制结点：</p>
<img src="/ae9ab7c6/15.png" class>

<p>因为这些仿制数据的独立性，我们就可以说仿制结点的更新有new_w1和new_w2的数据依赖性，现在当我们执行计算图时，我们同时计算loss和这个仿制节点，这个仿制节点并不返回任何值，因为我们放入节点这个数据依赖保证了当我们执行了更新操作后我们使用了更新的权重参数值。</p>
<ul>
<li><p>学生问题2：我们在上面的程序中，w1和w2放入了计算图中，但X和Y依然用了numpy数据，我们为什么不把X,Y也放入计算图中。</p>
</li>
<li><p>回答：在很多任务中,X和Y是数据集的mini batch，所以它们在每次迭代时都是变化的，因此我们想要在每次迭代都要输入不同的值。若X,Y不是变化的，那么可以将它们放入计算图中。</p>
</li>
<li><p>学生问题3：updates的含义</p>
</li>
<li><p>回答：我们想要的输出是loss和updates,updates并不是一个真的数值，updates返回的是空，因为这个依赖意思是更新依赖于这些赋值操作，但是这些赋值操作在计算图里面都存储于GPU显存中，所以我们在GPU中执行这些更新操作， 而不需要把更新数值从图中拷贝出来，所以updates返回的是空。</p>
</li>
<li><p>学生问题4：为什么tf.group()返回为空？</p>
</li>
<li><p>回答：这是tf的小技巧，在某种方式上group()返回了tf的内部节点操作，我们需要这些节点操作来构建图，但是当我们执行图时，在session.run操作里，我们告诉它我们想要从更新中计算具体值，然后执行完这步操作后它返回空。在tf在构建图和构建图时的真实输出值之间中经常有这种间接操作，当我们执行计算图时实际上会得到一个具体值，但执行更新之后，输出就是空。</p>
</li>
<li><p>学生问题5：为什么loss返回的是值，但update返回的就是空？</p>
</li>
<li><p>回答：这只是更新操作的方法，loss是我们计算的一个值，当我们告诉tf我们想要计算一个tensor时，我们会得到一个具体值。但更新可以看成是一种特殊的数据类型，它并不返回值，它返回为空。</p>
</li>
</ul>
<hr>
<h5 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h5><p>在我们想要执行不同赋值操作的地方，我们需要利用tf.group（），这比较麻烦，tf有便捷的操作来做这些事，就是优化器optimizer。</p>
<img src="/ae9ab7c6/16.png" class>

<p>这里我们用tf.train.GradientDescentOptimizer函数，我们传入学习率这个参数值，然后调用optimizer.minimize来最小化我们的损失函数，通过这个调用我们可以知道这些变量w1和w2在默认情况下被标记为可训练，因此在optimizer.minimize里面，它会进入计算图并在计算图中添加节点，然后计算图计算关于w1和w2的损失梯度，然后用updates执行更新操作，以及进行分组和分配操作，最终会给我们一个更新值。当我们在循环中运行计算图，我们采用相同的模式来计算损失值和更新值，每次我们让计算图进行更新，它就会计算并更新计算图。</p>
<p>还有一个问题是，在上面例子中，我们没有在网络结构中放入偏差，我们使用偏差时必须初始化偏差并让它们保持正确的形式，如下图：</p>
<img src="/ae9ab7c6/17.png" class>

<p>在这个例子中，我们只是显示地说明了X和Y，它们分别是数据和标签的占位符。</p>
<p>现在我们使用h=tf.layers.dense，（相当于定义了隐藏层），我们把X作为输入，单元数为H， 在这一行里，它设置了w1和b1（也就是偏差），它设置了形状正确的变量，并让这些变量存在于计算图中，但对于我们来说可以是隐藏的（这一整句话博主没听懂，如果有错误希望大家能帮忙指出来）。这段代码使用xavier.intializer()来为这些变量建立一个初始化策略，在之前的代码里，我们用tf.randomnormal来做这些事，但现在这种做法帮我们处理了一些细节，而且只是输出了一个h，我们可以看到，这个层里的激活函数是relue激活函数，所以这种方法可以定义很多细节。</p>
<p>人们在tf上建立了许多不同的高级库，其中计算图是相对较低级水平的事物，当我们正在使用神经网络时，我们有层和权重的概念，比起原始的计算图，这些概念是稍微高一点的层次，我们通常考虑的也是稍微高一些的层次，所以这些包可以从高一些的层次出发帮助我们运行神经网络。</p>
<hr>
<h5 id="tensorboard和分布式运行"><a href="#tensorboard和分布式运行" class="headerlink" title="tensorboard和分布式运行"></a>tensorboard和分布式运行</h5><p>我们可以在tf中添加一些代码，从而使用tensorboard画出训练过程中的loss曲线和其他一些内容。tf也可以分布式运行，可以将一张计算图图分块，从而在不同的计算机上运行，目前进行分布式运行，tf是最合适地选择</p>
<img src="/ae9ab7c6/18.png" class>

<hr>
<h4 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h4><p>pytorch内部明确定义了三层对象。</p>
<p>pytorch的张量对象就像numpy数组，它是一种最基本的数组，与深度学习无关，但可以在GPU上运行。</p>
<p>pytorch的变量对象，就是计算图中的节点，这些节点构成了计算图，从而计算梯度等等。</p>
<p>pytorchde的module对象，它是一个神经网络层，可以将这些module组合起来，建立一个大的网络。</p>
<img src="/ae9ab7c6/19.png" class>

<p>对比pytorch和tensorflow，我们可以把张量对应为tf中的numpy array。</p>
<p>pytorch中的变量，与tf中的张量，变量或占位符相似，它们在计算图中都算一个节点。</p>
<p>pytorch的module可以等价为tf.slim，tf.layers或sonnet或其他更高层次架构。</p>
<p>pytorch有一点需要注意的是，因为它的抽象层次很高，而且有像module这样好用得高层抽象模块，这样选择就少了，使用nn.Module就能得到很好的结果，不用担心要使用哪些更高层的封装。</p>
<h5 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h5><img src="/ae9ab7c6/20.png" class>

<p>我们只使用了张量而没使用numpy完成了两层神经网络，首先建立一些随机数据：</p>
<img src="/ae9ab7c6/21.png" class>

<p>然后使用一些操作进行前向传播：</p>
<img src="/ae9ab7c6/22.png" class>

<p>然后按步骤进行反向传播：</p>
<img src="/ae9ab7c6/23.png" class>

<p>然后手动更新权值：</p>
<img src="/ae9ab7c6/24.png" class>

<hr>
<h5 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h5><p>Pytorch的张量和Numpy最大的差别是张量可以在Gpu上运行。我们在CPU上运行的时候，用的dtype是：</p>
<img src="/ae9ab7c6/25.png" class>

<p>而如果要用GPU运行，只需要把dtype改成：</p>
<img src="/ae9ab7c6/26.png" class>

<p>所以我们可以把张量看成numpy加GPU</p>
<hr>
<h5 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h5><p>使用变量的代码如下：</p>
<img src="/ae9ab7c6/27.png" class>

<p>一旦我们把张量转到变量，我们就建立了计算图，可以自动做梯度和其他计算，下图中如果X是一个变量，那么X.data就是张量，x.grad就是另外一个变量，包含了损失对张量x.data的梯度。x.grad.data则是包含这些梯度值的实际的张量。pytorch的张量和变量有相同的API，任何在pythrch张量上可行的代码都可以用变量替换，而且运行同样的代码。</p>
<p>当我们建立了变量，每一次对变量的构造器的调用，都封装了一个张量 ，并且设置了一个二值的标记，告诉构造器我们需不需要计算在该变量上的梯度。</p>
<img src="/ae9ab7c6/28.png" class>

<p>然后是前向传播，与之前使用张量的实现完全一样，因为API是相同的，然后计算预测值，然后计算损失。</p>
<img src="/ae9ab7c6/29.png" class>

<p>然后调用loss.backwards()就可以得到我们需要的所有梯度值</p>
<img src="/ae9ab7c6/30.png" class>

<p>然后我们可以用梯度对权值进行更新：</p>
<img src="/ae9ab7c6/31.png" class>

<p>这些操作看上去都像是numpy的方式，除了梯度是自动求解。</p>
<p>需要注意的是，tf和pytorch中有一点不同就是tf中，我们先构建显示的图，然后重复运行它，而在pytorch中，我们在每次做前向传播时，都要构建一个新的图，这使程序看上去更加简洁。还有就是在pytorch中，我们可以自己定义张量的前向和反向，来构造新的自动求解grad的函数:</p>
<img src="/ae9ab7c6/32.png" class>

<p>然后把这些操作放在计算图中，跟我们以前用Numpy一样：</p>
<img src="/ae9ab7c6/33.png" class>

<p>但是一般情况下我们不需要这种操作，因为基本pytorch都定义好了。</p>
<hr>
<h5 id="nn结构"><a href="#nn结构" class="headerlink" title="nn结构"></a>nn结构</h5><p>用nn结构的代码如下：</p>
<img src="/ae9ab7c6/34.png" class>

<p>nn是一种更高级的封装，我们把模型定义为一些层的组合</p>
<img src="/ae9ab7c6/35.png" class>

<p>循环体中每一次迭代时，我们都可以在模型中前向传送数据得到预测值，把预测值放入损失函数，得到损失值：</p>
<img src="/ae9ab7c6/36.png" class>

<p>然后调用Loss.backward自动计算所有梯度：</p>
<img src="/ae9ab7c6/37.png" class>

<p>然后在模型的所有参数上循环，进行显示的梯度下降操作来更新模型：</p>
<img src="/ae9ab7c6/38.png" class>

<p>我们又一次看到每次做前向传播时，都建立了一张新的计算图。</p>
<p>Pytorch也提供了优化操作，将参数更新的流程抽象出来，并执行Adam之类的更新法则，这里我们建立了一个optimizer对象，告诉它我们想要对模型中的参数进行优化，并且可以设置学习率等超参数：</p>
<img src="/ae9ab7c6/39.png" class>

<p>在计算了梯度之后，我们就可以调用optimizer.step来更新模型中的所有参数：</p>
<img src="/ae9ab7c6/40.png" class>

<hr>
<h5 id="定义nn模块"><a href="#定义nn模块" class="headerlink" title="定义nn模块"></a>定义nn模块</h5><p>我们还可以定义自己的nn模块，我们要写自己的类，这个类把整个模型定义成nn模块中的一个新的类，一个模块可以看成是神经网络中的一层或多层，它可以包含其他模块或者可训练的权重等。</p>
<img src="/ae9ab7c6/41.png" class>

<p>上面例子中，我们通过定义自己的nn模块类，重现之前的两层网络：</p>
<img src="/ae9ab7c6/42.png" class>

<p>在类的初始化操作时，我们分配了linear1和linear2，建立新的模块对象，然后存在类中</p>
<img src="/ae9ab7c6/43.png" class>

<p>现在在前向传播时，我们可以使用自己的内部模块，也可以对变量使用任意的autograd操作来计算网络的输出，下面是forward操作的内容，输入作为一个变量，然后把输入的变量传给self.linear1作为第一层，用clamp函数去计算relu，再把输出传给第二层，然后就得到我们的输出y_pred：</p>
<img src="/ae9ab7c6/44.png" class>

<p>训练的代码基本上与之前一样，建立优化器，不断循环，每次迭代中喂数据给模型，计算梯度</p>
<img src="/ae9ab7c6/45.png" class>

<hr>
<h5 id="dataloaders"><a href="#dataloaders" class="headerlink" title="dataloaders"></a>dataloaders</h5><p>一个dataloader可以建立分批处理，也可以执行上面提到的多线程，它可以用多线程在后台来建立很多批处理和硬盘加载，所以dataloader可以打包数据</p>
<img src="/ae9ab7c6/46.png" class>

<p>在这个示例中当需要执行自己的数据的时候,我们可以编写自己的数据集类可以读取特殊类型的数据。然后在dataloader里打包并且训练它们：</p>
<img src="/ae9ab7c6/47.png" class>

<p>然后我们迭代dataloader对象，每次迭代的过程中都可以产生分批数据，然后在其内部重排数据，多线程加载数据。</p>
<hr>
<h5 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h5><p>pytorch提供了一些预先训练好的模型，如下图，只要让torchvision.model.alexnet(pretrained=True)</p>
<img src="/ae9ab7c6/48.png" class>

<p>然后让它在后台跑，下载预先训练好的权重，然后我们再训练自己的模型。</p>
<hr>
<h5 id="Visdom"><a href="#Visdom" class="headerlink" title="Visdom"></a>Visdom</h5><p>pytorch的visdom包可以可视化很多损失统计，它与tensorboard的不同之处是，tensorboard可以可视化网络结构，但它不可以。</p>
<hr>
<ul>
<li><p>常用的深度学习框架必备的关键点：易制作的大规模计算图（Computational Graphs）；易根据计算图计算梯度；使用GPU。</p>
</li>
<li><p>TensorFlow的Tensorboard可视化程度较高，风场方面观察计算图中的权重变化。</p>
</li>
</ul>
<h5 id="TensorFlow的参考链接"><a href="#TensorFlow的参考链接" class="headerlink" title="TensorFlow的参考链接"></a>TensorFlow的参考链接</h5><img src="/ae9ab7c6/3.png" class>

<ul>
<li>Keras (<a href="https://keras.io/">https://keras.io/</a>)</li>
<li>TFLearn (<a href="http://tflearn.org/">http://tflearn.org/</a>)</li>
<li>TensorLayer (<a href="http://tensorlayer.readthedocs.io/en/latest/">http://tensorlayer.readthedocs.io/en/latest/</a>)</li>
<li>tf.layers (<a href="https://www.tensorflow.org/api_docs/python/tf/layers">https://www.tensorflow.org/api_docs/python/tf/layers</a>)</li>
<li>TF-Slim (<a href="https://github.com/tensorflow/models/tree/master/inception/inception/slim">https://github.com/tensorflow/models/tree/master/inception/inception/slim</a>)</li>
<li>tf.contrib.learn (<a href="https://www.tensorflow.org/get_started/tflearn">https://www.tensorflow.org/get_started/tflearn</a>)</li>
<li>Pretty Tensor (<a href="https://github.com/google/prettytensor">https://github.com/google/prettytensor</a>)</li>
<li>Sonnet (<a href="https://github.com/deepmind/sonnet">https://github.com/deepmind/sonnet</a>)</li>
</ul>
<h5 id="预训练的模型地址"><a href="#预训练的模型地址" class="headerlink" title="预训练的模型地址"></a>预训练的模型地址</h5><ul>
<li>TF-Slim: (<a href="https://github.com/tensorflow/models/tree/master/slim/nets">https://github.com/tensorflow/models/tree/master/slim/nets</a>)</li>
<li>Keras: (<a href="https://github.com/fchollet/deep-learning-models">https://github.com/fchollet/deep-learning-models</a>)</li>
</ul>
<hr>
<h4 id="静态和动态图"><a href="#静态和动态图" class="headerlink" title="静态和动态图"></a>静态和动态图</h4><p>pytorch和tensorflow最大的不同是静态图和动态图。</p>
<img src="/ae9ab7c6/49.png" class>

<p>tensorflow有两个操作阶段，第一步建立计算图，然后运行很多次同一个图，我们把这个叫做静态计算图。</p>
<p>pytorch不同的是，当我们建立一个新的计算图的时候，它会每一次前向传播都更新，所以称为动态计算图。</p>
<hr>
<h5 id="静态图的优势"><a href="#静态图的优势" class="headerlink" title="静态图的优势"></a>静态图的优势</h5><p>其中一个关于静态图的优点是我们只会建一次图，然后不断复用它，然后整个框架会结合一些操作在图上做优化。一些优化器可以很容易地在静态图上进行优化，因为图始终不变。但是对于动态图可能没那么容易。</p>
<img src="/ae9ab7c6/50.png" class>

<p>另外静态图的优点是执行序列化，对于静态图来说，一旦我们建立了图，在内存中就有了这种数据结构代表我的整个网络结构，现在我们可以用这个数据结构在磁盘中序列化，当我们有了整个网络的结构就可以存在文件中，然后可以之后再加载它们，然后运行计算图而不是再去访问最早的代码去建立图，所以在一些部署方案中比较实用。比如我们可以在序列化网络后把它部署到C++环境中，就没必要去重新用原先的代码来建立图所以这是静态图的优势。</p>
<hr>
<h5 id="动态图的优势"><a href="#动态图的优势" class="headerlink" title="动态图的优势"></a>动态图的优势</h5><p>动态图的一个优点是会让代码在某些场景看起来更简洁。</p>
<p>比如我们想做一些条件运算，根据变量z的值想做不同的操作来计算y</p>
<img src="/ae9ab7c6/51.png" class>

<p>在pytorch中我们用的是动态图，所以非常简单，我们可以只用正常的python控制流来操控这个事，因为我们每次都要建图，每次都会执行这个操作，在每次前向传播中可以选择不同的条件来建立不同的图，当我们结束建立，我们还可以反向传播</p>
<img src="/ae9ab7c6/52.png" class>

<p>在tensorflow中就比较复杂了，因为我们只建一次图，这样的控制流操作就需要在tf图中一个明确地操作，所以有tf.cond在tf中，就像是if语句，但它被放到计算图中而不是python那样的控制流中，问题就是我们只会建一次图，所有的可能的控制流路径我们都需要提前建立好，在我们运行前放到图的函数中，这就意味着控制流的操作比较特殊，与python控制流操作不同</p>
<img src="/ae9ab7c6/53.png" class>

<p>在循环关系式中，比如yt=（y(t-1)+xt）*w，每次次我们计算这个公式得到不同大小的数据序列，因为输入序列X的大小不一。</p>
<img src="/ae9ab7c6/54.png" class>

<p>在pytorch中我们可以不关心输入序列的大小，只希望计算相同的关系式。我们在pytorch中只需要一个普通的python循环去循环我们希望展开的次数，并不依赖输入数据的大小，我们的计算图会最终是不同的大小，但是没关系，因为一次只进行一个单元的一次反向传播</p>
<img src="/ae9ab7c6/55.png" class>

<p>但是在tf中，实现起来比较麻烦，由于我们需要首先构建所有的图，所以这个控制流的循环结构中需要在tf图中设置成一个显示的节点。tf几乎用自己的计算图重构了所有编程语言，任何控制流操作，任何数据结构都需要合并在计算图中，因此我们不能够用熟悉的Python命令在写我们喜欢的风格的代码，我们需要重新学习整个tf定义的的控制流操作方法命令。</p>
<img src="/ae9ab7c6/56.png" class>

<p>在循环神经网络中，比如图像描述，我们使用循环网络在一个不同长度的序列上运行，在这个例子中，要生成用来描述图片的句子，依赖于输入数据的序列，句子大小不一样，输入数据的大小也就不一样，这时候动态图就很方便。</p>
<img src="/ae9ab7c6/57.png" class>

<p>还有比如图像问答中，问题的长度不一样，输入的数据也不一样，动态图此时非常方便。</p>
<p>人们可以用动态图做很多cool，具有创造性的应用</p>
<hr>
<h4 id="caffe"><a href="#caffe" class="headerlink" title="caffe"></a>caffe</h4><p>caffe不同于上述架构，很多时候我们不需要写任何代码，就可以训练网络，里面有预存的二进制文件，只需要修改一些配置，不需要写任何代码。</p>
<p>首先将数据格式转换成LMDB格式或者HDF5格式，或者可以将图像文件夹或文本文件夹转换成可以进入caffe的脚本，然后定义计算图的结构，而不需要写代码，只需要修改prototex文件设置计算图的结构。</p>
<img src="/ae9ab7c6/58.png" class>

<p>这些文件的缺点之一是当网络非常大时，这种设置非常不友好，比如152层的resnet结构被预训练在caffe中，它的prototxt文件有7000行，当然prototxt文件不需要自己写，可以用Python脚本生成。</p>
<p>然后在其他peototxt文件里设置学习率，优化算法</p>
<img src="/ae9ab7c6/59.png" class>

<p>完成了所有配置后，运行caffe二进制文件利用train命令运行</p>
<img src="/ae9ab7c6/60.png" class>

<p>caffe有个模型库，放了很多预训练模型，caffe有Python接口，但没有很好的说明文档，需要我们通过源代码来看如何调用接口。</p>
<p>caffe具有很好的前向传播模型，很适合产品化，但是它不依赖Python，在产品应用方面比较好用。</p>
<hr>
<h4 id="tensorflow、pytorch-和-caffe-的比较"><a href="#tensorflow、pytorch-和-caffe-的比较" class="headerlink" title="tensorflow、pytorch 和 caffe 的比较"></a>tensorflow、pytorch 和 caffe 的比较</h4><img src="/ae9ab7c6/61.png" class>

<p>google尝试建立一个网络结构，适用于所有深度学习场景，所有的效果集合在一个架构上也很好，我们只需要学习一种架构就可以在所有的场景上应用，包括分布式系统，产品部署，手机端，科研等所有应用场景。</p>
<p>facebook采用不同的策略，Pytorch更专业一点，针对科学研究将想法写成研究性代码和更快的迭代实现时pytorch非常容易实现。但如果产品化时，比如手机端，pytorch支持不太友好。而caffe在这种产品化情况时表现地很好</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 9 [2017版]</title>
    <url>/b214e4f5.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - 迁移学习之分割、定位与检测</strong></li>
</ul>
<h3 id="概念定义"><a href="#概念定义" class="headerlink" title="概念定义"></a>概念定义</h3><img src="/b214e4f5/1.png" class>

<ul>
<li><p>语义分割将图像不同层次都用轮廓分割出来，实时分割问题更多的是多任务问题，在不同层次上实时的进行图像分割。</p>
</li>
<li><p>分类与定位，分类问题简单的降图像中识别的物体种类输出，定位给出不同物体所在图片中的坐标，可能需要标注框来框出物体所在目标，而分类+定位问题就是两者皆有</p>
</li>
<li><p>目标检测，与分类问题进行比较，主要区别是多物体分类与定位，解决地问题可能更复杂。</p>
</li>
<li><p>不同的图像任务所需的网络架构不同，分类+定位——目标检测——语义分割，问题困难程度不断加深。</p>
</li>
</ul>
<span id="more"></span>

<hr>
<h3 id="分类与定位"><a href="#分类与定位" class="headerlink" title="分类与定位"></a>分类与定位</h3><h4 id="基本分类与定位"><a href="#基本分类与定位" class="headerlink" title="基本分类与定位"></a>基本分类与定位</h4><img src="/b214e4f5/2.png" class>

<ul>
<li><p>将分类定位问题看成一个回归问题，使用L2范数欧式距离来计算损失函数。</p>
</li>
<li><p>下载别人已经前训练过的模型（AlexNex、VGG、GoogleNet），当然自信有时间有装备也可以自己训练模型。得到class scores的全连接层，分类层得到C类。</p>
</li>
<li><p>新建一个回归层（regression head），其实也是全连接层，输出类所在的位置框。</p>
</li>
<li><p>然后通过一张张图像的训练，最后完成分类与定位的训练。</p>
</li>
<li><p>回归有两类回归：不定类回归（class-agnostic regresar）和特定类回归（class-specific regresar），不论使用什么结构，我们在全连接层都使用相同的结构和权值来得到边界框（bounding box）。不定类回归使用1个4坐标Box，特定类回归得到C*4坐标Boxes</p>
</li>
<li><p>回归层可以选择在全连接层后、卷积层后，根据不同网络模型进行选择尝试。</p>
</li>
</ul>
<hr>
<h4 id="人类姿态识别"><a href="#人类姿态识别" class="headerlink" title="人类姿态识别"></a>人类姿态识别</h4><img src="/b214e4f5/3.png" class>

<ul>
<li><p>人类姿态识别，主要根据人姿态由关节决定，通过网络计算出不同关节的位置14连接点（joint positions），从而实现运动姿态识别。</p>
</li>
<li><p>定位基本姿态后，可以根据不同的姿态再去分类识别不同的运动动作。</p>
</li>
</ul>
<hr>
<h4 id="滑动窗口识别–overfeat网络"><a href="#滑动窗口识别–overfeat网络" class="headerlink" title="滑动窗口识别–overfeat网络"></a>滑动窗口识别–overfeat网络</h4><img src="/b214e4f5/4.png" class>

<ul>
<li><p>通过对一张图片进行整张图片进行分割，形成不同的图片，分别对图片进行分类与定位，得到不同框内的概率与定位框，再通过算法将概率和框，整合成一个整体。</p>
</li>
<li><p>缺点是计算量大，需要对每一块不同的层都进行计算，其中有很多的数据冗余。</p>
</li>
<li><p>当然可以使用YOLO算法，对不同坐标只看一次，将图片分割成N张小窗口，最后输出看成是不在是一个M的输出，而是N*M的矩阵，加快计算。</p>
</li>
</ul>
<hr>
<h3 id="检测"><a href="#检测" class="headerlink" title="检测"></a>检测</h3><img src="/b214e4f5/5.png" class>

<ul>
<li><p>检测问题是复杂的，实际上由于检测目标的不确定性，很难将其转换为一个回归问题。</p>
</li>
<li><p>可以将图片一部分输入分类器，形成分类问题，将检测问题转换成分类与定位问题，将会变得简单得多。</p>
</li>
<li><p>但问题是需要将不同的大小、不同的位置都试验一遍，将极大地消耗计算资源。</p>
</li>
<li><p>解决方法：历史上就使用HOG（梯度分布直方图）来进行不同位置的图像特征提取；DPM继承这种方法，线性分类器来进行分类。</p>
</li>
</ul>
<hr>
<h4 id="Region-Proposals"><a href="#Region-Proposals" class="headerlink" title="Region Proposals"></a>Region Proposals</h4><img src="/b214e4f5/6.png" class>

<ul>
<li><p>原理是输入图像，然后输出所有可能存在目标的位置，不可知目标分类器，不关心对象具体的类别，精度不高，但是运算速度非常快</p>
</li>
<li><p>在图中寻找整体相似的色块，形成候选框：选择性搜索，从像素的角度出发，将相似颜色和纹理相邻的像素合并，然后不断的合并，形成大框，在不同的尺寸上进行操作，极大地减少检测的计算量</p>
</li>
</ul>
<hr>
<h4 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h4><img src="/b214e4f5/7.png" class>

<ul>
<li><p>选择感兴趣的区域位置直接进行CNN分类</p>
</li>
<li><p>缺点是训练复杂，下载模型，增加不同层,训练处理速度非常非常慢，测试速度也非常慢。</p>
</li>
</ul>
<hr>
<h4 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h4><img src="/b214e4f5/8.png" class>

<ul>
<li>改善点1：感兴趣区域的提取使用卷积的方式，增加速度</li>
</ul>
<img src="/b214e4f5/9.png" class>

<ul>
<li>改善点2：增加Rol池化层，降低数据量，使用softmax替代SVM。</li>
</ul>
<hr>
<h4 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h4><img src="/b214e4f5/10.png" class>

<ul>
<li>增加感兴趣区域网络（CNN）的方式来提取特征，训练一层新的模型，加快速度，准确率依旧很高。</li>
</ul>
<img src="/b214e4f5/11.png" class>

<ul>
<li>四种常用方法测试速度对比，显而易见RCNN速度太慢，尽量不要使用。</li>
</ul>
<hr>
<h4 id="YOLO-SSD"><a href="#YOLO-SSD" class="headerlink" title="YOLO/SSD"></a>YOLO/SSD</h4><img src="/b214e4f5/12.png" class>

<ul>
<li><p>当然以上的方法还是做不到实时处理，提出了只看一次算法，将图片等分成N块，输出除了包括边界，还增加了一个置信概率，概率最大区域为中心，通过扩大旁边不同的区域，最终实现目标的识别。</p>
</li>
<li><p>处理速度大大增快，能够实现实时处理的要求，</p>
</li>
<li><p>缺点，虽然速度增快了，但是当图片内有很多目标物体时，将很难准确识别所有目标，准确率降低。所以实际应用中，根据不同情况选择哪种方法。</p>
</li>
</ul>
<hr>
<h4 id="复杂密集检测–其实没看懂，得去看论文"><a href="#复杂密集检测–其实没看懂，得去看论文" class="headerlink" title="复杂密集检测–其实没看懂，得去看论文"></a>复杂密集检测–其实没看懂，得去看论文</h4><img src="/b214e4f5/13.png" class>

<img src="/b214e4f5/14.png" class>

<hr>
<h3 id="实时图像分割"><a href="#实时图像分割" class="headerlink" title="实时图像分割"></a>实时图像分割</h3><h4 id="Mask-RNN"><a href="#Mask-RNN" class="headerlink" title="Mask-RNN"></a>Mask-RNN</h4><img src="/b214e4f5/15.png" class>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 10 [2017版]</title>
    <url>/e5cdc3ec.html</url>
    <content><![CDATA[<ul>
<li><strong>CS231n - RNN</strong></li>
</ul>
<h3 id="RNN总体分类"><a href="#RNN总体分类" class="headerlink" title="RNN总体分类"></a>RNN总体分类</h3><img src="/e5cdc3ec/1.png" class>

<ul>
<li><p>循环神经网络，包含了多种结构，适用不同的情况，处理不同的序列，主要分类为：</p>
</li>
<li><p>one2one：Vanilla neural network，最简单的循环神经网络结构</p>
</li>
<li><p>one2many：Image Captioning（图像标注），用于图像生成多个序列的单词</p>
</li>
<li><p>many2one：Sentiment Classification（情感分类），用于将多文本生成一个结果</p>
</li>
<li><p>many2many：machine translate(机器翻译)，用于多序列生成多序列</p>
</li>
<li><p>many2many：帧级别的视频分类</p>
</li>
</ul>
<span id="more"></span>

<hr>
<h4 id="RNN基本结构"><a href="#RNN基本结构" class="headerlink" title="RNN基本结构"></a>RNN基本结构</h4><img src="/e5cdc3ec/2.png" class>

<ul>
<li><p>循环的结构，将t-1的状态和t的输入经过函数f，主要是参数乘以两个状态生成新的当前状态，增加了对以前的状态的依赖性。</p>
</li>
<li><p>在每一个步骤选用的都是相同的更新函数和线性参数。</p>
</li>
<li><p>以tanh为例，RNN的函数与参数如下，tanh在RNN是常用的激活函数：</p>
</li>
</ul>
<img src="/e5cdc3ec/3.png" class>

<ul>
<li>many2many的结构，一般在得到当前的状态后，乘以系数矩阵W_hy使用softmax得到y分类，与实际的y结果做比较，得到当前的损失函数，然后叠加到最终的损失函数来进行后向传播</li>
</ul>
<img src="/e5cdc3ec/4.png" class>

<ul>
<li>many2one的结构，Sentiment Classification（情感分类），用于将多文本生成一个结果</li>
</ul>
<img src="/e5cdc3ec/5.png" class>

<ul>
<li>one2many的结构，Image Captioning（图像标注），用于图像生成多个序列的单词</li>
</ul>
<img src="/e5cdc3ec/6.png" class>

<ul>
<li>many2one+one2many的结构，使用多序列生成单一序列，再通过单1序列经过另一组参数W_hh2来生成多组数据。</li>
</ul>
<hr>
<h4 id="字符级别语言模型"><a href="#字符级别语言模型" class="headerlink" title="字符级别语言模型"></a>字符级别语言模型</h4><img src="/e5cdc3ec/7.png" class>

<ul>
<li>隐藏状态值h，输出层y，再通过softmax生成字符表的概率，one-shot（独热和非独热编码），然后通过反向传播训练W参数</li>
</ul>
<img src="/e5cdc3ec/8.png" class>

<ul>
<li>根据当前的字符推测下一个字符的概率，“hello”，输出层是softmax，然后将输出预测的字符作为下一级的x输入。</li>
</ul>
<hr>
<h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><img src="/e5cdc3ec/9.png" class>

<ul>
<li>最初始的想法是对整个网络进行前向传播，但是对所有网络进行反向传播。但是对于一个实际的RNN的网络，一个网络序列的深度无法确定，可能会很长，实际上不适合对所有的网络进行反向传播</li>
</ul>
<img src="/e5cdc3ec/10.png" class>

<ul>
<li><p>通常会采用对一个块模块进行反向传播，对所有的级别进行前向传播，但是只对一个很小数量的序列进行反向传播。</p>
</li>
<li><p>这样有利于反向传播的稳定性，一方面避免反向传播太长导致梯度消失和梯度爆炸，另一方面保证序列间相关性。</p>
</li>
</ul>
<hr>
<h4 id="RNN模仿威廉莎士比亚进行写作"><a href="#RNN模仿威廉莎士比亚进行写作" class="headerlink" title="RNN模仿威廉莎士比亚进行写作"></a>RNN模仿威廉莎士比亚进行写作</h4><hr>
<h4 id="RNN模仿进行代码写作"><a href="#RNN模仿进行代码写作" class="headerlink" title="RNN模仿进行代码写作"></a>RNN模仿进行代码写作</h4><ul>
<li>RNN能够模仿出注释，但函数很多意义并不明显。</li>
</ul>
<hr>
<h4 id="图像标注：结合CNN和RNN"><a href="#图像标注：结合CNN和RNN" class="headerlink" title="图像标注：结合CNN和RNN"></a>图像标注：结合CNN和RNN</h4><img src="/e5cdc3ec/11.png" class>

<ul>
<li><p>将CNN最后的全连接层和分类层抛弃，将矩阵结果输出到RNN序列上，生成对应的单词进行序列标注</p>
</li>
<li><p>CNN起到提取图像特征的作用，成功进行标注的案例如下：</p>
</li>
</ul>
<img src="/e5cdc3ec/12.png" class>

<hr>
<h4 id="图像标注-注意力模型"><a href="#图像标注-注意力模型" class="headerlink" title="图像标注-注意力模型"></a>图像标注-注意力模型</h4><img src="/e5cdc3ec/13.png" class>

<ul>
<li>让网络能够识别出该集中注意力区域，使用LSTM进行RNN分类。</li>
</ul>
<hr>
<h3 id="普通RNN"><a href="#普通RNN" class="headerlink" title="普通RNN"></a>普通RNN</h3><h4 id="多层次RNN"><a href="#多层次RNN" class="headerlink" title="多层次RNN"></a>多层次RNN</h4><img src="/e5cdc3ec/14.png" class>

<ul>
<li>增强网络效果，增大规模，实际上并不一定就比单层的RNN更好，每1层都使用相同的权重W_hl参数。</li>
</ul>
<hr>
<h4 id="vanilla网络计算图"><a href="#vanilla网络计算图" class="headerlink" title="vanilla网络计算图"></a>vanilla网络计算图</h4><img src="/e5cdc3ec/15.png" class>

<ul>
<li>可以使用变换的方式，将Whh和Whx进行合并成Wh，这样有利于统一矩阵运算。</li>
</ul>
<img src="/e5cdc3ec/16.png" class>

<ul>
<li>梯度爆炸设置阈值，梯度消失改变模型。</li>
</ul>
<hr>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><ul>
<li>RNN存在一个非常大的缺陷，那就是长期依赖性的问题。比如在文本处理中，由于距离短，RNN语言的单复数的关联性还是存在的；但比如“我出生在美国亚利桑那州，现在住在纽约，我说英语”美国与英语的关联性在这么长的距离可能就会失去关联性。</li>
</ul>
<img src="/e5cdc3ec/17.png" class>

<img src="/e5cdc3ec/18.png" class>

<ul>
<li><p>LSTM（Long Short Term）：LSTM 通过刻意的设计来避免长期依赖问题，LSTM 的关键就是细胞状态，水平线在图上方贯穿运行。细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互，信息在状态更新上。</p>
</li>
<li><p>LSTM设计上存在四个门：i（input）、f（forget）、o（output）、g（gate）。其中i/f/o为sigmoid门，范围为（0-1），门控用来更新不同的状态；g门用来根据隐藏状态h和输入x更新细胞状态的主要内容，严格来说g应该算门，应该是状态。</p>
</li>
<li><p>f门用来表征细胞状态被遗忘多少，0完全遗忘、1完全保留；i门和g状态将当前的状态更新到细胞状态中，可能增加了输入的一些要长期保存的特征。将当前细胞状态经过tanh的激活以后，通过o门更新为隐藏状态h。</p>
</li>
<li><p>实际上h与c的相似性比较大，总觉得整个单元结果存在很大的冗余性，而且这样操作隐藏状态h的作用没有发挥的太大，但这是多样性的一个体现。</p>
</li>
<li><p>LSTM存在一个特点：只使用一组权重W进行更新，也不好说是优点还是缺点。</p>
</li>
</ul>
<img src="/e5cdc3ec/19.png" class>

<ul>
<li>反向传播对于细胞状态的更新可以实现在整个网络中进行，形成完整的梯度流。</li>
</ul>
<hr>
<h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><img src="/e5cdc3ec/20.png" class>

<ul>
<li><p>GRU作为LSTM的一个变种，将隐藏状态和细胞状态结合在一起，降低了单元的冗余度，整个单元变得更加简单。</p>
</li>
<li><p>不用在将LSTM的多种门结合到GRU中来解释，r和z都起到了记忆和遗忘作用，将过去的隐藏状态更新到了当前状态。z决定了最终更新是遗忘过去更多，还是忽略当前更多，这是一个概率为1的互补事件。而在当前的临时状态中，r也起到了对过去隐藏状态的保留程度。因此在</p>
</li>
<li><p>与LSTM相比，GRU有3组权重待更新，对于细胞状态中，权重用来表征选择，相当于增加网络的多样性，用来选择对长短期效应的记录，感觉会更加完善，但是如果一组权重就够用，这也就变成冗余性。与LSTM类似，这是一个互补。</p>
</li>
<li><p>每一种LSTM及其变种之间的效率都差别不大，通用型都差不多，但是各自可能有各自的最合适的情况，很难评定谁更优，除非出现一种新的结构，而不是简单的改变。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-CS231n Lecture 11~15 [2017版]</title>
    <url>/94487b5.html</url>
    <content><![CDATA[<h3 id="物体检测和分割"><a href="#物体检测和分割" class="headerlink" title="物体检测和分割"></a>物体检测和分割</h3><p>物体检测模型可以分为<strong>单步模型</strong>和<strong>两步模型</strong>，其中<strong>单步模型</strong>指没有独立地、显示地提取候选区域，直接由输入图像得到其中存在的物体的类别和位置信息的模型，在计算效率上有优势，典型的<strong>单步模型</strong>有：OverFeat、SSD（Single Shot multibox-Detector ）、YOLO（You Only Look Once）等；<strong>两步模型</strong>指有独立的，显示的候选区域提取过程，即先在输入图像上筛选出一些可能存在物体的候选区域，然后针对每个候选区域，判断其是否存在物体，如果存在，就给出物体的类别和位置修正信息，在检测精度上有优势，典型的<strong>两步模型</strong>有：R-CNN、SPPNet、Fast R-CNN、Faster R-CNN、R-FCN、Mask R-CNN等</p>
<p><strong>R-CNN：</strong>主要思路是使用无监督的选择性搜索方法将输入图像中具有相似的颜色直方图特征的区域进行递归合并，产生大量的候选区域，然后从输入图像中截取这些候选区域对应的图像，将其裁剪缩放至合适的尺寸，并送入一个CNN提取的网络中提取特征，最后再送入一个SVM分类器中进行分类和非极大值抑制操作即可得到最终结果，如下图所示可以概括R-CNN的整个过程：</p>
<img src="/94487b5/1.png" class>

<span id="more"></span>

<p><strong>Fast R-CNN：</strong>Fast R-CNN通过卷积网络得到图像的高分辨率特征映射，切分图像的像素，基于备选区域投影到卷积特征映射，从中提取属于备选区域的卷积块。然后用兴趣区域池化层(ROI pooling layer)来使卷积块变为固定尺寸，输入全连接层进行分类。同样有一个多任务损失，需要基于全局反向传播同时学习。它可以重复运用卷积计算，因此时间主要消耗在寻找备选区域。</p>
<img src="/94487b5/2.png" class>

<p><strong>Faster R-CNN：</strong>让卷积网络去预测备选区域，其余与Fast R-CNN相同。神经网络同时处理四件事：备选区域是否是待识别物体，校正包围盒，最终物体识别的损失，最终包围盒补偿的损失</p>
<img src="/94487b5/3.png" class>

<p><strong>Mask R-CNN：</strong>Mask R-CNN将整张输入图像送入卷积网络和训练好的候选框生成网络，然后将候选框投射到卷积特征图上，然后产生两个分支，一个预测出分类类别分数和边界框的坐标，另一个是一个语义分割的微型网络。</p>
<img src="/94487b5/4.png" class>

<hr>
<h3 id="可视化和理解"><a href="#可视化和理解" class="headerlink" title="可视化和理解"></a>可视化和理解</h3><p><strong>特征可视化：</strong>对第一层卷积层可视化,得到的特征图像一般是不同颜色,不同角度的有向边.但是对较深的卷积层可视化得到的图像则没有明显含义，降维(如t-SNE,PCA)可以将高维特征映射为二维图像，排除实验用平均像素遮挡图像中的一部分,然后观察图像分类概率的变化值,得到概率热力图.由此可以判断图像中的哪些部分对分类起关键作用，显著图(Saliency Map)对每个像素做轻微扰动,然后计算像素对分类预测概率的影响,从而得到哪些像素是影响分类的关键部分，梯度上升(Gradient Ascent)修正训练的神经网络的权重,并改变图像的某些像素,来最大化某些中间神经元和类的分值.为了让生成图像符合自然图像,需要加入正则项(图像的L2范数,高斯模糊处理)。</p>
<p><strong>风格迁移：</strong>提取输入图像通过神经网络运行到某一层，接着进行反向传播并且设置该层的梯度等于激活值，然后反向传播到图像并不断更新图像；人工纹理合成算法是将特征转换为Gram矩阵，然后使得两张图像Gram矩阵最相似，在实际应用的过程中，往往会将多层网络的Gram矩阵相似性都考虑进最终结果。</p>
<img src="/94487b5/5.png" class>

<hr>
<h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p><strong>自注意力：</strong>是一种在计算同一序列表示时，权重和序列的位置相关机制，被证明在机器阅读理解，抽象概要和图片描述生成中非常有效。自注意力机制被应用在图片生成描述任务中。图片首先被编码，然后输入到带有自注意力机制的RNN网络中，来学习图片各个特征与描述中每个词之前的映射关系。注意力权重的可视化清晰地的展示了模型每关注一部分特征都会输出一个词。</p>
<img src="/94487b5/6.png" class>

<p><strong>Multi-head自注意力机制：</strong>multi-head注意力机制借助尺度化的点积注意力机制进行并行化多次计算。每个独立的注意力输出通过简单拼接并线性的转换到指定的维度空间。</p>
<img src="/94487b5/7.png" class>

<hr>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p>以下主要是Transformer编码解码模型的主要架构</p>
<img src="/94487b5/8.png" class>

<img src="/94487b5/9.png" class>

<p>**DEtection TRansformer (DETR)**是Facebook研究团队巧妙地利用了Transformer 架构开发的一个目标检测模型。DETR模型由一个预训练的CNN骨干(如ResNet)组成，它产生一组低维特征集。这些特征被格式化为一个特征集合并添加位置编码，输入一个由Transformer组成的编码器和解码器中，和原始的Transformer论文中描述的Encoder-Decoder的使用方式非常的类似。解码器的输出然后被送入固定数量的预测头，这些预测头由预定义数量的前馈网络组成。每个预测头的输出都包含一个类预测和一个预测框。损失是通过计算二分匹配损失来计算的。如下图所示为其基本的结构：</p>
<img src="/94487b5/10.png" class>

<hr>
<h3 id="生成对抗模型"><a href="#生成对抗模型" class="headerlink" title="生成对抗模型"></a>生成对抗模型</h3><h4 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h4><p>基于深度学习的生成式建模的方法主要有AE、VAE、GAN这三大种，其中VAE是基于AE的基础上进行变形的生成模型，而GAN是近年来较为流行并有效的生成式方法。</p>
<p><strong>自编码器(AE)：</strong>AE主要由编码器和解码器组成，整个模型其实就相当于一个压缩解压的一个过程，编码器将真实数据进行压缩到低维隐空间中的隐向量，然后解码器将压缩的隐向量进行解压得到生成数据，当然在训练过程中会将生成数据和真实数据进行比较并更新参数。其实个人感觉其目的就是使得生成数据和输入的真实数据尽量相近，尽可能抓住真实数据的核心关键，如下图所示为AE的基本框架：</p>
<img src="/94487b5/11.png" class>

<p><strong>变分自编码器(VAE)：</strong>VAE就是AE的进化版本，基础结构和AE相差不大，但是在中间隐空间的编码部分并不相同，AE的主要特点是能够模仿或者说和输入的数据尽可能接近缺少创新多样性当然本身AE自编码器就是对输入数据的一个压缩编码所以这也就是AE缺点的原因所在；再说说VAE的主要变化，其主要优势就是在编码器后产生的隐向量的概率分布能够尽量接近某个特定的分布即编码器的直接输出的是所属正态分布的均值和标准差，然后根据均值和方差采样得到隐向量z，这样就可以根据采样的随机性生成具有多样性的生成图像，如下图是VAE的基本框架：</p>
<img src="/94487b5/12.jpg" class>

<p><strong>生成对抗网络GAN：</strong>GAN主要由生成器和判别器构成，两者分别有自己的一个独立的网络结构，生成器生成图像再交给判别器进行判别，通过这样对抗训练的方式交替优化，生成器判别器的对抗也被称为”MinMax游戏“，即判别器最大化真实样本的输出结果，最小化假样本的输出结果，而生成器则相反。如下图所示：</p>
<img src="/94487b5/13.png" class>

<hr>
<h4 id="VAE和GAN之间的区别"><a href="#VAE和GAN之间的区别" class="headerlink" title="VAE和GAN之间的区别"></a>VAE和GAN之间的区别</h4><p>首先GAN和VAE之间在输入数据和生成数据上存在不同，VAE需要两者一一对应方可求其重构损失/误差，而GAN中不需要二者一一对应；其次VAE中隐向量事实上是对输入数据特征的一种表达，在抽象的语义层面上比如改变人的发色特征没那么VAE可直接通过在隐变量空间上插值或嵌入式操作来实现。</p>
<hr>
<h4 id="原始GAN的优化目标"><a href="#原始GAN的优化目标" class="headerlink" title="原始GAN的优化目标"></a>原始GAN的优化目标</h4><img src="/94487b5/14.png" class>

<hr>
<h4 id="原始GAN存在的问题"><a href="#原始GAN存在的问题" class="headerlink" title="原始GAN存在的问题"></a>原始GAN存在的问题</h4><p><strong>梯度消失：</strong>原始GAN的优化目标如上所示，在开始训练的时候生成器一般将会较为灵敏的判断出真假数据，这样造成的结果就是目标损失函数达到饱和，梯度消失，如下图是大概的推断GAN为什么梯度消失的过程：</p>
<img src="/94487b5/15.jpg" class>

<p><strong>模式坍塌：</strong>模式坍塌指的是，在生成器生成假图片的过程中，生成器的泛化能力太弱，只能产生相似或相同的图片无法创新使得生成数据具有多样性，就好比造假钞，只单一的对某一面值的钞票进行造假却无法生成其他面值的钞票。</p>
<hr>
<h4 id="JS散度和KL散度"><a href="#JS散度和KL散度" class="headerlink" title="JS散度和KL散度"></a>JS散度和KL散度</h4><p><strong>KL散度</strong>的定义是两个概率分布的非对称性度量，其描述的是两个概率分布拟合的程度，若两个概率分布相同时则其KL散度为0，如下为KL散度公式：</p>
<img src="/94487b5/16.png" class>

<p><strong>JS散度</strong>的定义是基于KL散度上，但是JS散度主要是用来度量两个概率分布的相似度且JS散度是对称的其值分布在0-1之间，并且JS散度用于原始GAN中的损失函数的推导上，如下为JS散度公式：</p>
<img src="/94487b5/17.png" class>

<p>顺便附上GAN和JS散度之间的关系，其中该目标是使得D的目标函数值最大化（摘自GAN原作者的证明）</p>
<img src="/94487b5/18.png" class>

<hr>
<h4 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h4><p><strong>凸函数</strong>非正式定义：函数内任取集合中两个点并连线，如果线段完全被包含在函数内则为凸函数否则为非凸函数。</p>
<p>大多数的机器学习还是深度学习的问题的一些目标函数大多会转换成凸函数求解，因为凸优化的任何局部最优解即为全局最优因此凸优化更为高效，非凸优化问题较为困难，在可行域的范围内可能存在无数个局部最小点。</p>
<hr>
<h4 id="基于f-散度的GAN目标函数的改进"><a href="#基于f-散度的GAN目标函数的改进" class="headerlink" title="基于f-散度的GAN目标函数的改进"></a>基于f-散度的GAN目标函数的改进</h4><p><strong>f-散度：</strong>f-散度可以理解为KL散度的一般化形式(当对应的f取值为xlogx时即为KL散度)，如下公式所示：</p>
<img src="/94487b5/19.png" class>

<p>当然f-散度具有以下特点：①都是非负实数到实数的映射 ②f(1)=0 ③都是凸函数<br>由于原始GAN函数中使用的是JS散度且损失函数为交叉熵损失函数因此较难使得梯度能够稳定下降使得生成数据推向真实分布，所以出现了其他的f-散度的GAN网络使得最小化生成器中目标函数的散度值以此达到生成分布接近真实分布的目的，例如LSGAN中使用的就是均方误差的f函数，EBGAN使用的是绝对误差的f函数。</p>
<hr>
<h4 id="Lipschitz连续性"><a href="#Lipschitz连续性" class="headerlink" title="Lipschitz连续性"></a>Lipschitz连续性</h4><p><strong>Lipschitz连续性：</strong>Lipschitz连续的定义较为简单，简单来说就是限制f函数的导函数绝对值不超过K其中K&gt;=0，从定义中很明显可以看出Lipschitz连续性的作用就是为了限制连续函数的局部变化最大幅度：</p>
<img src="/94487b5/20.png" class>

<p><strong>谱归一化：</strong>谱归一化常用来归一化判别器的权重，目的是为了让判别器满足Lipschitz连续性，在训练过程中谱归一化会对每一层的权重做奇异值分解，并对奇异值做归一化将其限制在1内，从而使得整个GAN训练网络更加稳定不容易崩塌。</p>
<hr>
<h4 id="IS和FID生成数据评价指标"><a href="#IS和FID生成数据评价指标" class="headerlink" title="IS和FID生成数据评价指标"></a>IS和FID生成数据评价指标</h4><p><strong>IS评价指标：</strong>IS评价指标是指Inception Score即通过Inception网络所计算生成图像分数的方法，公式如下：</p>
<img src="/94487b5/21.png" class>

<p>其中p(y|x)是指给定一张图像将其输入InceptionV3分类网络后输出的类别概率，p(y)指的是生成的图像全部输入InceptionV3网络中得到自己的概率分布并且得到所有类别上的边缘分布。</p>
<p><strong>FID评价指标：</strong>FID评价指的是在InceptionV3的倒数第二层上进行一个真实样本和生产样本的特征图的均值和方差来比较，公式如下：</p>
<img src="/94487b5/22.png" class>

<p><strong>FID和IS的优缺点：</strong>IS更多在于生成数据的质量和多样性的评分，对于生成数据和真实样本之间缺少比较，而FID正弥补了IS的这一缺点，大那是FID计算特征图的均值和方差的方法过于粗糙对于图像细节无法更好的评估。</p>
<hr>
<h4 id="GAN的分类"><a href="#GAN的分类" class="headerlink" title="GAN的分类"></a>GAN的分类</h4><p>GAN可以分为有监督和无监督的方式，其中有监督的GAN要求的是生成图像和输入图像需要一一配对，反之无监督的GAN则不需要一一配对；有监督的GAN比较经典的应用就是超分辨率重建、图像补全等，而无监督的GAN应用有图像风格迁移等</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐课程</category>
        <category>💫CS231n</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-中国科学院心理研究所傅小兰研究员作“心理学视角下的自动表情识别”主题报告</title>
    <url>/26d48d27.html</url>
    <content><![CDATA[<p>2022年1月23日，由中国科学院行为科学重点实验室主办，深圳绿房子心理咨询有限公司、心仪脑平台共同协办的首届情感与认知计算高端论坛在线上召开。此次论坛主题涵盖情感计算、具身认知、人工智能、共情发展与脑科学等。众多国内外著名心理学者参会并分享在心理学、脑科学与人工智能等领域的国际最新科研成果。中国科学院心理研究所所长、党委副书记、研究员、博士生导师傅小兰研究员作为嘉宾作了题为“心理学视角下的自动表情识别”的报告。</p>
<img src="/26d48d27/1.jpg" class>

<span id="more"></span>
<p>图1 首届情感与认知计算高端论坛在线召开</p>
<p>傅小兰研究员首先介绍了表情识别中的基本情绪理论。她指出，当身体产生（生理）变化时，我们感受到这些变化，这就是情绪。这样的生理变化往往是可以通过人眼以及一些传感器设备获取，但是<strong>如何利用这些表现去识别对象的情绪与状态仍然是一大困难。</strong></p>
<p>随后，傅小兰研究员提到<strong>表情是情绪的外在表现</strong>，<strong>可以通过对表情的识别来达到对情绪状态的确认</strong>。同时傅小兰研究员指出，随着对表情识别与情绪判断的研究不断深入，以往的一些方法发生了巨大的改变，其中最为典型的就是<strong>从静态图片到动态视频、从单一的面部动作单元到多模态的表情信息的变化</strong>。根据一些心理学相关的研究表明，动态表情相较于离散出来的单一表情图片能提供更多重要的信息。因为单一的图片只能提供空间维度信息，而动态表情在其基础上还可以提供时间维度上的重要信息。同时为了获得更好的判断结果，当下有不少研究者将面部表情与其他信息，如脑电信号、声音以及头部运动等，融合起来完成情绪的判断。</p>
<img src="/26d48d27/2.jpg" class>
<p>图2 表情识别的研究进展</p>
<p><strong>如何对收集到的情绪数据进行标注</strong>是傅小兰研究员此次报告中的重点，她将标注方法大致分为了四大类。第一类是<strong>体验者的自我评估</strong>，因为情绪本质是一种主观体验，所以该类方法往往更具直接性，可信度较高。第二类方法考虑到部分场景无法获得主观学习者自我评估结果，所以采用<strong>观察者的主观标注</strong>的方法。但考虑到无论是体验者还是观察者的评估都存在一定主观性，所以通过AU动作单元的<strong>基于行为的客观标注</strong>的这类方法就被一些专家学者提出。该类方法根据一些事先定义好的情绪动作单元组合去匹配获得到的人脸的面部特征信息，从而获得对应的情绪标签。这样获得的标签具有一定的客观性与普遍性，同时降低了人力物力的损耗。同时为了更好地表示情绪，不同于以往离散的情绪类型，<strong>引入效价-唤醒度的概念</strong>，使得标注的信息更为精准恰当。</p>
<p>傅小兰研究员还就当前自动表情识别遇到的主要问题进行一一例举及解释。首先，<strong>表情与真实情绪体验的一致性很难保证</strong>，因为不同个体存在差异性，即便相同的情绪状态，不同个体表现出的信息也会存在一定的差异。同时因为上述问题的存在，极易导致<strong>人工标注的结果存在一定误差</strong>，这也是需要解决的一个重要问题。傅小兰研究员还特意指出情绪与表情的变异性，即<strong>一个标签很难代表一类情绪或者表情</strong>。为此，她列举了几个例子，比如彩票中奖和只是单纯因为看电视得到的喜悦感是不一样的，用同样的标签代表这两个状态是不恰当的。</p>
<img src="/26d48d27/3.jpg" class>
<p>图3 表情识别研究存在的问题</p>
<p>报告最后，傅小兰研究员对上述问题提出了自己的一些建议与思路。她指出情绪并非一个静态的结构，而是一个动态的建构过程，在这里构建过程就是主客体的互动过程。在<strong>结合了个体与他人及环境的互动去理解情绪的表现</strong>，得到的结果可能会更为合理准确。</p>
<p><strong>报告人介绍：傅小兰，女，汉族，现任中国科学院心理研究所所长，脑与认知科学国家重点实验室副主任，心理研究所学位评定委员会委员、学术委员会委员，中国心理学会常务理事、秘书长。</strong></p>
<p>线上会议录屏回看<a href="https://appc75jwmhz4298.h5.xiaoeknow.com/v1/course/video/v_61efa386e4b054255d99db21?type=2"><strong>视频链接</strong></a></p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11240">https://www.scholat.com/teamwork/showPostMessage.html?id=11240</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-敢于颠覆性创新，脑机接口或许才是真正开启元宇宙的“钥匙”</title>
    <url>/17109d5c.html</url>
    <content><![CDATA[<p>随着扎克伯格将脸书Facebook改名为Meta，宣布正式进军元宇宙，元宇宙再一次被人们关注起来。相较于早前，人们对于元宇宙只是抽象概念上的想象，通过借助VR等设备来体验人与虚拟世界的交互。如何真正去实现所谓的元宇宙呢？这个答案可能要交给马斯克早前就开始研究的脑机接口技术。</p>
<p>对于脑机接口大家应该都比较熟悉，其可以通过对人类大脑发出的信号进行解析，让外部设备明白人的想法，从而实现让人类通过意念操控外部设备。脑机接口的技术特性使得元宇宙成为一种可能，当人的意识“进入”元宇宙这种虚拟世界，并感受到虚拟世界中的一切，脑机接口就可以帮助实现真正的交互，通过意识实现对设备的操作。</p>
<img src="/17109d5c/1.jpg" class>
<p>图1 Neuralink团队训练一只猴子使用意念操作游戏</p>
<span id="more"></span>

<p>目前，马斯克的Neuralink脑机接口科研公司已经取得了一定进展。在2021年9月，该公司通过将其开发的可以植入人脑的脑机接口设备“Link”移植到一只灵长类动物“猕猴”身上，成功实现了让猕猴通过脑机接口实现对电脑操控，完成对一些简单游戏的操作。然而，Neuralink所要面临的技术问题还有很多。人脑很复杂，每个人的大脑在面对不同事件时所做出的反应也会不同，也就是所发出的信号不同，脑机接口公司在开发设备时如何对这些信号进行精准分析是极大难题。<strong>在保证解析准确性的同时如何实现对于解析速率提升也是相关科研人员不得不面临的难题。</strong></p>
<p>目前，脑机接口在医疗健康领域已取得相当的进展，可以帮助实时监控和测量患者神经系统状态，辅助临床判读、可以评测陷入深度昏迷患者的意识等级、可以测量视/听觉障碍患者神经通路状态协助医生定位病因等等。然而，<strong>元宇宙的概念涉及的应用领域很广泛，面向的人群也是多式多样，如何将脑机接口与其它商业领域结合起来也是一个值得被重视的发展方向，此外，生产出能够让普通用户接受的设备也值得未来去研究</strong>。例如，游戏领域在脑机接口的支持下，游戏玩家可以用意念来控制VR界面的菜单导航和选项控制，获得了独立于传统游戏控制方式之外的新的操作体验；在智能家居领域上，人们也可以用意念控制开关等，甚至控制家庭服务机器人，实现全新意义上的智能体验。我们认为未来随着一系列可穿戴设备比如 AR 眼镜的普及，以及元宇宙的持续建设，基于脑机接口技术的消费电子产品渗透率将持续提升。</p>
<img src="/17109d5c/2.png" class>
<p>图2 虚拟现实+脑机接口概念图</p>
<p>当然，元宇宙这个概念目前虽然很火，甚至被外界质疑有炒作嫌疑，但是我们不可以忽略掉在这个概念下所隐藏的价值——人类对智能与未来的更高期待。脑机接口作为一种人机交互技术，无疑是通往元宇宙这扇大门的钥匙。<strong>在这一具有热度的话题下，科研创新工作应当更加踏实、务实，可以考虑从提升多种信号解析的准确性、提升信号解析的响应速度、提升设备的配适度等与实际应用需求紧密相关的角度进行科研创新。</strong></p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><blockquote>
<p><a href="https://new.qq.com/omn/20211217/20211217A01YFK00.html">https://new.qq.com/omn/20211217/20211217A01YFK00.html</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11251">https://www.scholat.com/teamwork/showPostMessage.html?id=11251</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-AI舞蹈合成系统，以编舞为导向的音乐驱动的舞蹈合成</title>
    <url>/e7de8cee.html</url>
    <content><![CDATA[<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>本篇报告内容来源于网易互娱AI Lab、清华大学的研究人员在SIGGRAPH上发表的《ChoreoMaster : Choreography-Oriented Music-Driven Dance Synthesis》</p>
<img src="/e7de8cee/1.jpg" class>

<span id="more"></span>

<p>音乐和舞蹈自古以来就密不可分，它们的关系随着人类文明的发展而演变。对舞蹈音乐关系的研究形成了一个学科，称为舞蹈音乐学，风格和节奏是音乐和舞蹈中两个相互关联的因素，相对独立，但又密切相关。一方面，遵循相同节奏模式的音乐和舞蹈可能呈现出截然不同的听觉和视觉风格，反之亦然。另一方面，节奏模式的分布与音乐和舞蹈风格密切相关：例如，舒缓的音乐往往节奏柔和，而摇滚音乐的节拍强烈。<strong>保证音乐和舞蹈之间风格、节奏的一致性对于音乐驱动的舞蹈动作合成至关重要。</strong></p>
<p><a href="https://netease-gameai.github.io/ChoreoMaster/Supplemental/ChoreoMaster_Overview.mp4">ChoreoMaster自动合成舞蹈示例视频</a></p>
<p>网易互娱AI Lab、清华大学的研究人员提出ChoreoMaster，一种可用于制作的音乐驱动的舞蹈动作合成系统。给定一段音乐，ChoreoMaster 可以根据音乐的风格、节奏、结构自动生成高质量的舞蹈动作序列。为了实现这一目标，研究人员引入了一种面向编舞的舞蹈音乐嵌入框架，该框架成功地<strong>为音乐和舞蹈片段之间的风格和节奏关系构建了一个统一的舞蹈音乐嵌入空间。然后将学习到的舞蹈音乐嵌入结合到一个面向舞蹈的基于图形的运动合成框架中，该框架可以根据各种舞蹈规则生成高质量的舞蹈动作。</strong></p>
<img src="/e7de8cee/2.jpg" class>
<p>图1：ChoreoMaster 包括两个面向编舞的模块：一个用于捕捉音乐-舞蹈连接的编舞嵌入模块，以及一个基于图形的运动合成模块，用于根据各种编舞规则从输入音乐中生成高质量的舞蹈动作。</p>
<hr>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><h4 id="编舞风格的嵌入空间"><a href="#编舞风格的嵌入空间" class="headerlink" title="编舞风格的嵌入空间"></a>编舞风格的嵌入空间</h4><img src="/e7de8cee/3.jpg" class>
<p>图2：一段连续的舞蹈动作中出现了动作风格不一致</p>
<p>舞蹈表演中风格的一致性是舞蹈作品的基本要求，具体来说是舞蹈中各部分的动作风格的一致性和舞蹈动作风格与音乐风格的一致性。研究人员<strong>采用了一个舞蹈音乐嵌入网络来隐式地模拟音乐和舞蹈风格之间的联系</strong>。关键思想是将音乐和舞蹈片段映射到一个统一的嵌入空间中，其中传达相似情绪和音调的片段紧密聚集在一起。具体来说，研究人员<strong>首先使用未配对的音乐和舞蹈数据独立训练两个分类网络，然后利用配对数据将两个特征空间转换为统一的嵌入空间</strong>，其中音乐和舞蹈项目保持可分类，而配对的音乐和舞蹈项目保持尽可能靠近。</p>
<p>该架构如图 3（左）所示。主要采用[2]作为音乐编码分支的骨干。它由四个卷积块层和两个GRU层组成。舞蹈编码分支与音乐编码分支相似，其中卷积块被图卷积块替换。EM和ED的用途是将音乐和舞蹈序列压缩成嵌入向量ZM和ZD。</p>
<p>为了让音乐和舞蹈动作数据配对，研究人员采用了两阶段的训练程序。第一阶段，使用所有标记的未配对音乐和舞蹈动作数据独立训练音乐和舞蹈动作分支。第二阶段，为了更好地反映学习嵌入空间中的潜在子样式，研究人员还结合了无监督深度嵌入聚类 (DEC) 策略[3]，它能让分类网络的特征空间中的数据更好地聚类。通过这两个阶段的训练，可以将任何音乐和舞蹈片段映射到一个统一的舞蹈音乐嵌入空间中，其中音乐和舞蹈之间的风格一致性可以通过相应嵌入向量之间的欧几里德距离来衡量。</p>
<img src="/e7de8cee/4.jpg" class>
<p>图3：ChoreoMaster包括两个面向编舞的模块：面向编舞的舞蹈音乐嵌入网络包含一个舞蹈音乐风格嵌入网络和一个舞蹈音乐节奏嵌入网络。</p>
<hr>
<h4 id="编舞节奏的嵌入空间"><a href="#编舞节奏的嵌入空间" class="headerlink" title="编舞节奏的嵌入空间"></a>编舞节奏的嵌入空间</h4><img src="/e7de8cee/5.jpg" class>
<p>图4：节奏签名示例。偶数位表示存在规则拍子，而奇数位表示半拍。连续的零表示连奏。</p>
<p>（乐理知识）<br>节拍：是衡量节奏的单位，在音乐中，有一定强弱分别的一系列拍子在每隔一定时间重复出现。<br>拍子：音乐的拍子，是根据乐曲的要求而定的。如果规定的速度为每分钟120拍的时候，那么每一拍占的时间是半秒钟。<br>拍号：是记录节拍/拍子种类的符号。</p>
<p>研究人员将节拍和拍子用于舞蹈动作。通常，音乐拍子对应于音乐中的声音脉冲，而舞蹈拍子对应于身体动作的暂停或急转。为了更好地理解音乐和舞蹈之间的节奏关系，研究人员构建一个由专业艺术家手动指定舞蹈的节拍模式的数据库。</p>
<p><strong>研究人员将每个节拍表示为一个二进制向量，称之为节奏签名，一种统一的舞蹈音乐节奏嵌入的自然综合形式。</strong>由于数据集中的所有舞蹈动作都以四拍计（一个节拍由四个拍子构成）构成，因此，研究人员用8个bit表示节奏签名（见图 4）。在每个节奏签名中，偶数位表示规则拍子（1：存在，0：不存在），它们对应于拍号指示的均匀间隔的标准拍子，而奇数位表示半拍（1：存在，0：不存在），它解释了两个常规小拍之间的节奏点（通常由连音、休止符或小点引起，或者仅仅是因为相邻节拍是由多个较小的节拍构成的）。节奏签名中的连续零表示音乐和舞蹈动作中的连奏或平滑周期。可以使用汉明距离来计算两个节奏签名的差异。</p>
<p>研究人员设计了一个<strong>节奏特征分类网络</strong>，以有效地获取音乐和舞蹈的编舞节奏嵌入。该网络的架构如图3（右）所示；它由三个块组成，有两个单独的音乐特征提取块EMR和舞蹈EDR分别由两个卷积层和一个稠密层构成。最后是一个共享块ERS用于节奏特征分类，由三个密集层构成。对应音乐片段ZM和舞蹈片段ZD的风格嵌入向量分别与EMR和EDR提取的特征向量连接。研究中为EMR网络提供音乐的频谱起始强度曲线[4]和RMS能量曲线；为EDR提供舞蹈运动曲线、两条手轨迹曲率曲线和两条脚接触曲线。</p>
<hr>
<h4 id="基于图的运动合成框架，将学习到的舞蹈音乐嵌入和其他舞蹈规则整合到基于图形的运动合成框架中"><a href="#基于图的运动合成框架，将学习到的舞蹈音乐嵌入和其他舞蹈规则整合到基于图形的运动合成框架中" class="headerlink" title="基于图的运动合成框架，将学习到的舞蹈音乐嵌入和其他舞蹈规则整合到基于图形的运动合成框架中"></a>基于图的运动合成框架，将学习到的舞蹈音乐嵌入和其他舞蹈规则整合到基于图形的运动合成框架中</h4><img src="/e7de8cee/6.jpg" class>
<p>图5：系统通过镜像、混合和重新洗牌使舞蹈动作更多样化。</p>
<p>在ChoreoMaster系统中，运动图中的每个节点都对应一个舞蹈节拍。学习的风格嵌入向量和标记的节奏签名也附加到每个图节点。为了更好地利用现有舞蹈动作数据，系统中采用镜像、混合和重新洗牌的方法使舞蹈动作更多样化（见图5）。镜像操作应用于数据库中的所有运动节拍，而混合和重新洗牌仅在具有相同节奏特征和非常接近的风格编码的节拍之间。</p>
<img src="/e7de8cee/7.jpg" class>
<p>图6：以编舞为导向的舞蹈合成过程。系统中使用了几个面向<strong>舞蹈编排的约束，包括数据项、过渡项和重复/镜像约束</strong>来合成满足专业审美要求的高质量舞蹈动作。</p>
<p>在基于运动图的框架中，每个合成的运动对应于运动图中的一条路径。因此，在ChoreoMaster系统中，为输入音乐合成舞蹈动作可以看作是在图中找到满足各种编排规则（风格一致、舞蹈与音乐节奏对应、舞动动作平滑）的最佳路径（见图6）。系统的目标是将运动图中的舞蹈运动节点分配给每个音乐节拍，并<strong>最小化由数据项、过度项和结构约束项的成本</strong>。其中：</p>
<ul>
<li><p>数据项表示音乐节拍和舞蹈动作节拍之间<strong>风格和节奏匹配的成本</strong>；</p>
</li>
<li><p>过度项表示保持合成运动中相邻运动段之间的<strong>平滑过度的成本</strong>；</p>
</li>
<li><p>结构约束项解决了<strong>音乐和舞蹈之间结构的一致性问题</strong>。编舞者在编舞中经常使用重复/镜像的动作来呼应音乐中重复的片段（相同音乐片段和舞蹈动作相同，以及一个小的音乐片段中经常有对称的动作）。</p>
</li>
</ul>
<hr>
<h3 id="方法对比"><a href="#方法对比" class="headerlink" title="方法对比"></a>方法对比</h3><img src="/e7de8cee/8.jpg" class>
<p>图7：四种不同方法为一首中国传统歌曲生成的舞蹈动作。</p>
<img src="/e7de8cee/9.jpg" class>
<p>图8：普通用户（上）和编舞家、艺术家（下）的用户研究结果。ChoreoMaster比[5,6,7]取得了更高的分数。</p>
<p>项目主页：<a href="https://netease-gameai.github.io/ChoreoMaster/">https://netease-gameai.github.io/ChoreoMaster/</a></p>
<p>论文：<a href="https://netease-gameai.github.io/ChoreoMaster/Paper.pdf">https://netease-gameai.github.io/ChoreoMaster/Paper.pdf</a></p>
<hr>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Chen K, Tan Z, Lei J, et al. Choreomaster: choreography-oriented music-driven dance synthesis[J]. ACM Transactions on Graphics (TOG), 2021, 40(4): 1-13.<br>[2] Choi K, Fazekas G, Sandler M, et al. Convolutional recurrent neural networks for music classification[C]//2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017: 2392-2396.<br>[3] Xie J, Girshick R, Farhadi A. Unsupervised deep embedding for clustering analysis[C]//International conference on machine learning. PMLR, 2016: 478-487.<br>[4] Böck S, Widmer G. Maximum filter vibrato suppression for onset detection[C]//Proc. of the 16th Int. Conf. on Digital Audio Effects (DAFx). Maynooth, Ireland (Sept 2013). 2013, 7.<br>[5] Duan Y, Shi T, Zou Z, et al. Semi-supervised learning for in-game expert-level music-to-dance translation[J]. arXiv preprint arXiv:2009.12763, 2020.<br>[6] Sun G, Wong Y, Cheng Z, et al. DeepDance: music-to-dance motion choreography with adversarial learning[J]. IEEE Transactions on Multimedia, 2020, 23: 497-509.<br>[7] Lee M, Lee K, Park J. Music similarity-based approach to generating dance motion sequence[J]. Multimedia tools and applications, 2013, 62(3): 895-912.</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11442">https://www.scholat.com/teamwork/showPostMessage.html?id=11442</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-《深度合成十大趋势报告（2022）》探索深度合成技术</title>
    <url>/73d5d86d.html</url>
    <content><![CDATA[<p>作为人工智能领域的新领域之一，近几年来，运用深度学习、虚拟现实等算法制作应用于各个方面的图像、语音、视频、虚拟人物等信息的深度合成技术，已在多个领域大量应用。而其中，对与人脸方面的应用需求也与日俱增，这使得人脸方面的深度合成内容的关注度呈现大爆发态势。但是人脸的应用是一把双刃剑，除了给人们生活带来科技化和便捷化之外，也有很多不法分子恶意运用深度合成技术，造成了从个人到企业的声誉和财产方面的损失，这使得社会人心惶惶，对国家安全维护造成了威胁。</p>
<p>其中，深度合成技术指的是用合成类算法中具有代表性的深度学习和虚拟现实来制作文本、虚拟场景、图像、音、视频等信息的技术。</p>
<img src="/73d5d86d/1.png" class>
<p>图1 AI合成技术生成的人脸</p>
<span id="more"></span>

<p>技术的不断变革在造福社会的同时，也必然会对安全造成影响。为了能够给该方向提出正向指引，瑞莱智慧与多个研究中心发表了《深度合成十大趋势报告（2022）》。考虑到要综合各个方面的影响，该报告主要选用了在国内外的10家平台对深度合成技术进行调查，这10家平台分别是爱奇艺、腾讯视频、优酷、哔哩哔哩、抖音、快手、微博、YouTube、Twitter、 TikTok。</p>
<img src="/73d5d86d/2.png" class>
<p>图2 互联网中深度合成视频的发布数量变化趋势</p>
<img src="/73d5d86d/3.png" class>
<p>图3 不同类型内容深度合成视频数量排序</p>
<p>在对多个领域的调研中发现，深度合成在数量上呈现大爆发。具体体现在图2和图3的图形化数据的对比，可以看出深度合成技术在影视、广告、社交等各个商业领域多元化发展。例如芒果卫视推出的AI数字主持人小漾、字节与乐华娱乐联合推出的人气虚拟偶像团体A-Soul、AI有声小说配音和AI电视剧演员换脸等。可以看出视频、语音和文本形式的深度合成技术应用最为普遍。</p>
<p>对上述现象，瑞莱智慧CEO田天解释为，技术不断成熟是深度合成内容迎来爆发式增长的重要原因。这正是由科研人员对于深度合成技术的不断深入的研究，极大的推动了深度合成技术领域的方法提升，这也爆发式的提升了深度合成内容的质量。</p>
<p>深度合成技术为生活提供巨大便利的同时，其大量的开源代码也使得不少心怀不轨的人动歪脑筋。虽然技术是在不断更新与进步，但是目前深度合成技术主要依赖于人工智能模型以及训练数据。故而复杂的网络环境和易获取、易操作的技术，使得不法分子能够轻易伪造音频、视频，构成诸多违法行为。</p>
<img src="/73d5d86d/4.jpg" class>
<p>图4 卡内基梅隆大学研究人员利用人工智能操纵的“深度伪造”视频</p>
<p>因此，当前必须对深度合成技术进行一定的约束，一方面是关于对抗性技术的发展，另一方面是明确对深度合成技术的处罚。这就意味着不仅需要在学术界还是产业界都加大力度力求尽快提升深度伪造技术，而且还需要与时俱进提出解决措施并落实相关法律法规。</p>
<hr>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><blockquote>
<p><a href="https://xw.qq.com/cmsid/20220221A0786X00?f=newdc">https://xw.qq.com/cmsid/20220221A0786X00?f=newdc</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11444">https://www.scholat.com/teamwork/showPostMessage.html?id=11444</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-脑机接口领域迎来新型柔性电极</title>
    <url>/ed180d23.html</url>
    <content><![CDATA[<p>2022年3月25日中国神经外科国际合作研究的论文Topological supramolecular network enabled high-conductivity, stretchable organic bioelectronics在线发表于《科学》期刊（Science，影响因子47.728）。</p>
<img src="/ed180d23/1.jpg" class>
<p>图1：论文首页</p>
<span id="more"></span>

<p>北京天坛医院神经外科联合斯坦福大学化学工程系鲍哲南院士、天津大学化学系胡文平教授的团队创新性地采用导电聚合物的分子设计新策略研发出本征可拉伸电极材料，在加工到2微米尺度下仍能保持可拉伸性和高导电性的特征，实现了可拉伸有机电子器件领域的重大突破。基于柔性的优势，该电极能适形于脑干或神经外科术腔等多种不规则且组织易损伤的场景；基于可拉伸的特性，术中器械牵拉扭转等操作不会损伤纤薄的电极；基于高导电性和高密度的特征，应用该电极能精准定位到单个神经元的精度，以“热图”的形式快速且准确地勾勒脑干神经核团。这是目前世界上精度最高的柔性可拉伸微阵列电极。这种柔性电极和柔性电子器件不仅能让神经外科手术操作更精准，还能作为脑机接口中的核心技术，有望在脑科学研究与临床转化中发挥重要作用。</p>
<img src="/ed180d23/2.jpg" class>
<p>图2：柔性电极材料</p>
<p>据悉，这种材料将运用于在肌肉、神经无法重新再生的情况下，利用脑机接口，获得人发出的命令，通过芯片计算发送到瘫痪的肢体上，让患者重新恢复运动，未来才能够使瘫痪的患者重新站立。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>[1] <a href="https://news.cctv.com/2022/03/28/ARTIgVAFz5xX6IAgmdjjaTkn220328.shtml">https://news.cctv.com/2022/03/28/ARTIgVAFz5xX6IAgmdjjaTkn220328.shtml</a><br>[2] <a href="https://www.bjtth.org/Html/News/Articles/209562.html">https://www.bjtth.org/Html/News/Articles/209562.html</a><br>[3] Jiang, Yuanwen, et al. “Topological supramolecular network enabled high-conductivity, stretchable organic bioelectronics.” Science 375.6587 (2022): 1411-1417.</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11443">https://www.scholat.com/teamwork/showPostMessage.html?id=11443</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-睡眠纺锤波可作为神经退行性疾病检测的生物标志物</title>
    <url>/bfcd8a7b.html</url>
    <content><![CDATA[<p><strong>睡眠纺锤波</strong>，是在非快速眼动睡眠期间大量发生的大脑活动，与认知功能有关。可以通过在头皮上放置非侵入性电极的脑电图（EECs）进行评估。睡眠纺锤波被认为是一种“指纹”，在个体间存在差异，具有高度遗传性，并且在夜间趋于一致。<strong>但目前对于确定哪些睡眠纺锤波参数是重要的还没有共识。</strong></p>
<p>随着全世界范围内的老龄化，神经退行性疾病负担上升，迫切需要一种敏感的认知生物标志物。临床医生可以对个体睡眠时出现的某些脑电波模式进行评估，以帮助他们诊断痴呆症和其他与记忆、语言和思维有关的疾病。</p>
<span id="more"></span>

<p>近日，麻省总医院和贝斯以色列女执事医疗中心的研究人员在 <strong>Sleep</strong> 期刊上发表了一篇题为：Optimal Spindle Detection Parameters for Predicting Cognitive Performance 的研究论文。</p>
<p>这项新研究<strong>描述了纺锤波检测参数设置如何影响纺锤波与认知之间的关联，并确定了与认知表现最相关的参数</strong>。这有助于改善检测这些脑波模式或睡眠纺锤波的自动方法，并将它们与认知功能联系起来。</p>
<img src="/bfcd8a7b/1.jpg" class>

<p>论文主要作者，麻省总医院临床医学研究员 <strong>Noor Adra</strong> 表示：“随着神经退行性疾病负担的上升，迫切需要一种敏感的认知生物标志物。这导致了研究睡眠纺锤波的热潮——一种睡眠期间观察到的大脑活动的振荡模式，以及它们在各种神经精神状况和认知表现中的作用。”</p>
<p>尽管睡眠纺锤波和其他大脑特征代表了神经退行性疾病和精神疾病的潜在电生理标志物，但检测和评估睡眠纺锤波并不简单。论文合著者、麻省总医院神经病学系研究员 <strong>Haoqi Sun</strong> 博士表示“人们已经知道，在大脑中睡眠期间这些短暂的高频事件与认知密切相关，特别是与学习和记忆密切相关。但是当你试图在100多个睡眠记录中检测纺锤波时，事情变得不那么清楚，例如什么是最佳阈值，什么是最佳最小持续时间等等。”</p>
<p>睡眠纺锤波通常通过对脑电图的目视检查进行分析，但自动化方法可以提供更一致的结果。然而，对于这种自动化方法的参数，还没有达成共识。为了解决这些问题，研究人员设计了涉及167名成年人的睡眠相关实验，以描述纺锤波检测参数设置如何影响纺锤波特征与认知之间的关联，并确定与认知表现最相关的参数。</p>
<p>研究小组还发现，<strong>睡眠纺锤波与所谓的流体智力密切相关</strong>，流体智力依赖于抽象思维和解决问题的能力，在痴呆症的早期阶段会下降。Adra表示：“因此，我们的发现支持睡眠纺锤波作为一种基于睡眠的流体智力生物标记物。通过优化这一基于睡眠的认知生物标志物的检测，我们希望能够指导未来的研究，以检测神经退行性变人群中这种生物标志物的敏感性。”</p>
<p>论文通讯作者、麻省总医院神经病学系研究员 <strong>M.Brandon Westover</strong> 博士补充道：“<strong>睡眠纺锤波是睡眠期间大脑活动的许多重要可测量特征之一，它提供了一个了解大脑当前健康状态和个体病患脑部疾病或认知能力下降风险的窗口。</strong>现在我们更好地了解了如何测量睡眠纺锤波，我们可以将其加入到不断增长的大脑健康信息库中——可以在睡眠期间测量的健康指标，这些指标将是我们寻求开发能够保护和增强大脑健康的治疗方法的重要工具。”</p>
<hr>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><blockquote>
<p><a href="https://academic.oup.com/journals/pages/open_access/funder_policies/chorus/standard_publication_model">https://academic.oup.com/journals/pages/open_access/funder_policies/chorus/standard_publication_model</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11469">https://www.scholat.com/teamwork/showPostMessage.html?id=11469</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-ViT论文再整理</title>
    <url>/a5c1ffe6.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2020-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE.pdf" data-height="500px"></div>

<p><strong>ViT</strong> 论文链接：<a href="https://arxiv.org/abs/2010.11929">https://arxiv.org/abs/2010.11929</a></p>
<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=892100567&bvid=BV15P4y137jb&cid=451711833&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>这次李沐博士邀请了亚马逊计算机视觉专家朱毅博士来精读 <strong>Vision Transformer（ViT）</strong>，强烈推荐大家去看本次的论文精读视频。朱毅博士讲解的很详细，几乎是逐词逐句地讲解，在讲解时把 <strong>ViT</strong> 相关领域的研究也都介绍了，听完之后收获满满。</p>
<p><strong>ViT</strong> 应该是过去一年计算机视觉领域影响力最大的一个工作。<strong>ViT</strong> 挑战了<strong>卷积神经网络</strong>在计算机视觉领域的绝对统治地位。<strong>ViT证明如果能在足够大的数据集上去训练，那么就可以不需要卷积神经网络，直接使用标准的 Transformer 也能把视觉问题解决好</strong>。<strong>ViT</strong> 不仅在计算机视觉领域挖了一个大坑；同是它也打破了 <strong>CV</strong> 和 <strong>NLP</strong> 之间的壁垒，在<strong>多模态领域</strong>也挖了一个大坑。可以说，<strong>ViT</strong> 开启了计算机视觉新时代。</p>
<hr>
<h3 id="标题、摘要、引言、结论"><a href="#标题、摘要、引言、结论" class="headerlink" title="标题、摘要、引言、结论"></a>标题、摘要、引言、结论</h3><p>首先是论文<strong>标题</strong>，论文标题的意思是：一张图片等价于很多 16 × 16 的单词，<strong>Transformer</strong> 用于大规模图像识别 。16 × 16 是指将一张图片划分成若干个<strong>块（patch）</strong>，每一个 <strong>patch</strong> 大小为 16 × 16。这样一张图片就可以看作是若干个 <strong>patch</strong> 组成。这篇论文的作者还是蛮多的，有12个作者，可以看出这篇论文工作量确实很大，论文作者全部来自于 <strong>Google</strong>。</p>
<img src="/a5c1ffe6/1.png" class>

<p>下面是论文<strong>摘要</strong>，摘要写的很简洁，总共只有4句话。</p>
<ul>
<li>尽管 <strong>Transformer</strong> 已经成为自然语言处理任务事实上的一种标准，但是在计算机视觉上的应用还是非常有限。</li>
<li>在计算机视觉领域，<strong>注意力机制</strong>要么和卷积神经网络一起使用，要么在保持原有网络结构不变的情况下替换局部的卷积运算（例如 ResNet-50 中把其中每某一个残差块使用注意力机制替代）。</li>
<li><strong>本文证明对卷积神经网络的依赖不是必要的，原始的 Transformer 可以直接应用在一系列小块图片上并在分类任务上可以取得很好的效果</strong>。</li>
<li>在大的数据集上预训练的模型迁移到中小型图片数据集上 (ImageNet, CIFAR-100, VTAB等)，与目前最好的卷积神经网络相比，<strong>ViT 可以取得非常优秀的结果并且需要更少的训练资源</strong>。</li>
</ul>
<p>（但是仍然需要2500天 TPUv3 训练天数，目前的深度学习真的是进入到了大力出奇迹的时刻，在计算资源上学术界很难能比过工业界。）</p>
<img src="/a5c1ffe6/2.png" class>

<p>在介绍<strong>引言</strong>之前，朱毅博士首先介绍了 <strong>Transformer</strong> 用在计算机视觉上的一些难处。主要是如何将<strong>2D图片数据</strong>转换成 <strong>1D数据</strong>？目前 <strong>BERT</strong> 能够处理的序列长度是512，如果直接将图像像素转换成 <strong>1D</strong>。即使是 224 × 224 大小的图片，其序列长度也有5万多，计算复杂度将是 <strong>BERT</strong> 的100倍，如果是检测或分割任务，那计算复杂度就更大了。</p>
<p>引言前两段主要是交代故事背景，在自然语言处理任务上，通常会在大的训练集上去训练 <strong>Transformer</strong>，然后在小的特定任务数据集上去微调。目前可以训练含有上千亿参数的 <strong>Transformer</strong> 模型，且随着模型和数据集的增加，并没有出现饱和现象。在计算机视觉领域，卷积神经网络仍然占据主导。最近一些新的研究，有的将自注意力机制和卷积神经网络结合起来训练（<strong>即在较小的特征图上使用自注意力机制</strong>），这是一种减少序列长度的方法；还有的是使用<strong>局部图片作为输入</strong>，然后使用 <strong>Transformer</strong>，也有论文研究分别在<strong>图像高度或宽度上</strong>使用 <strong>Transformer</strong>，这些都是为了减少序列长度。但以上方法都存在不足，都是针对特定任务来使用，在大规模图像识别数据集， 像 <strong>ResNet</strong> 这样的网络仍然是主流。</p>
<img src="/a5c1ffe6/3.png" class>

<p>下面作者介绍如何将 <strong>Transformer</strong> 用在计算机视觉。首先将图像划分为一个个 <strong>patch</strong>，然后使用全连接网络进行线性变换，这样就得到了 <strong>patch</strong> 线性变换序列，最后将 <strong>patch</strong> 输入到 <strong>Transformer</strong>，这里可以将 <strong>patch</strong> 看成是一个个单词。举个例子，假设图像大小是 224 × 224，划分成 16 × 16 的 <strong>patch</strong>， 则最终会有196个<strong>patch</strong>。可以看到，整篇论文处理流程还是很简洁的，基本上没有什么技术难点。</p>
<p>紧接着作者指出，<strong>Transformer</strong> 与卷积神经网络相比缺少<strong>归纳偏置</strong>，例如<strong>相关性（locality）</strong>和<strong>平移不变性（translation equivariance）</strong>。因此为了得到更好的结果，需要有足够多的训练数据，最后一段就是介绍模型效果，果然效果拔群。</p>
<img src="/a5c1ffe6/4.png" class>

<p>下面是论文<strong>结论部分</strong>。第一段总结本文做的工作，图片处理成 <strong>patch</strong> 序列，然后使用 <strong>Transformer</strong> 去处理，取得了接近或超过卷积神经网络的结果，同时训练起来也更便宜。第二段是未来展望：</p>
<ul>
<li>一是和目标检测和分割结合起来，<strong>ICCV 2021</strong> 最佳论文 <strong>Swin Transformer</strong> 就证明了 <strong>Transformer</strong> 在检测和分割任务也能取得很好的效果；</li>
<li>另一个是自监督预训练，因为本文是有监督预训练，自监督和有监督预训练还存在着很大的差距，最近何恺明博士的新论文 <strong>MAE</strong> 就研究了这个问题；</li>
<li>最后是更大规模的 <strong>ViT</strong>，半年之后作者团队就提出了 <strong>ViT-G</strong>。</li>
</ul>
<img src="/a5c1ffe6/5.png" class>

<hr>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>下面是<strong>相关工作</strong>，总共有6段。第1段说2017年 <strong>Transformer</strong> 被提出来以后，已经成为许多 <strong>NLP</strong> 任务最先进的方法，代表性的工作有 <strong>BERT</strong>（完形填空去预测缺少的词）和 <strong>GPT</strong>（语言模型，预测下一个词）。第2段是说，将自注意力用于图像处理，需要每个像素和每个像素两两交互，复杂度与像素数量平方成正比。因此在图像处理中使用 <strong>Transformer</strong> 需要做一些近似处理，包括在局部图像块用自注意力、使用稀疏的 <strong>Transformer</strong> 以及在轴上使用注意力，这些方法都取得了很好的效果，但是需要复杂的工程能力去实现硬件加速。</p>
<img src="/a5c1ffe6/6.png" class>

<p>接着作者介绍和本文最接近的相关工作，<strong>ICLR 2020</strong> 的这篇论文使用的 <strong>patch</strong> 大小是 2 × 2，处理的数据集是 <strong>CIFAR-10</strong> 数据集，和 <strong>ViT</strong> 很接近，也是从头到尾使用注意力机制来处理。和这篇论文不同之处是我们的工作显示更大规模的预训练可以使得 <strong>Transformer</strong> 能取得比 <strong>CNN</strong> 更好的效果；同时我们使用了更大的 <strong>patch</strong>，我们的模型可以处理中等尺度的图片。下面是自注意力机制和 <strong>CNN</strong> 结合的一些工作，包括图片分类、物体检测、视频处理、文本视频任务等。</p>
<p>另一个最近的工作是 <strong>iGPT</strong>, 将 <strong>Transformer</strong> 用于生成式模型，在 <strong>ImageNet</strong> 上可以取得72%的准确率。我们的工作研究了更大规模的数据集，主要是 <strong>ImageNet-21k</strong> 和 <strong>JFT-300M</strong>。</p>
<img src="/a5c1ffe6/7.png" class>

<hr>
<h3 id="ViT模型、实验"><a href="#ViT模型、实验" class="headerlink" title="ViT模型、实验"></a>ViT模型、实验</h3><p>下面是<strong>ViT模型</strong>介绍，模型总览图如下图所示。输入为一张图片，将图片划分成9个<strong>patch</strong>，划分后的 <strong>patch</strong> 序列经过线性投射层变换得到 <strong>patch embedding</strong> ，与此同时对这些 <strong>patch</strong> 还添加了 <strong>position embedding</strong>，这样每一个 <strong>token</strong> 既包括图像信息又包括了位置信息。这里作者还借鉴了 <strong>BERT</strong>，添加了 <strong>class embedding</strong>，也包括位置信息，最终将这些 <strong>token</strong> 输入到 <strong>Transformer</strong>，最后 <strong>class embedding</strong> 对应的输出经过 <strong>MLP Head</strong> 进行类别判断，整个模型包括 L 个 <strong>Transformer</strong>。</p>
<p>下面是具体实现，假设图像大小是 224 × 224 × 3，划分成 16 × 16 × 3 的 <strong>patch</strong>，则最终会有196个 <strong>patch</strong>。将每一个 <strong>patch</strong> 拉平，则每一个 <strong>patch</strong> 维度变为 768。线性投射层使用 E 表示，维度为 768 × 768 （ D ），D 是参数。则经过线性变换后输出为： X E = 196 × 768 × 768 × 768 = 196 × 768，输出为196个 <strong>token</strong>，每个 <strong>token</strong> 维度为768。因为还有一个 <strong>class token</strong>，位置编码维度为 1 × 768，和 <strong>patch embedding</strong> 直接相加（sum），则最终输入维度为 197 × 768。</p>
<img src="/a5c1ffe6/8.png" class>

<p>下面是论文原文介绍，首先是 <strong>patch embedding</strong> 的处理，然后是 <strong>class embedding</strong> 的处理，最后是 <strong>position embedding</strong> 的处理。 在附录里作者比较了各种 <strong>position embedding</strong> 的实验结果，以及 <strong>class token</strong> 的使用对最终分类结果的影响。为了减少对 <strong>Transformer</strong> 的改动，作者这里还是使用了 <strong>class token</strong> 和 <strong>1D position embedding</strong>。</p>
<img src="/a5c1ffe6/9.png" class>

<p>下面是归纳偏置介绍，主要是所有 <strong>patch</strong> 的空间关系都需要从头去学；另一个是将注意力机制和 CNN 特征图结合起来一起使用，构建混合模型，最后是微调模型以及对大尺度图片的处理。</p>
<img src="/a5c1ffe6/10.png" class>

<p>下面是论文<strong>实验部分</strong>。这里作者主要设计了三种不同大小的 <strong>ViT</strong> 模型，如下表所示。</p>
<img src="/a5c1ffe6/11.png" class>

<p>第一个实验结果是作者分别将 <strong>ViT</strong> 模型在不同的数据集上去预训练，然后在基准数据集上去比较，虽然从表中看到 <strong>ViT-H/14</strong> 比卷积模型 <strong>BiT-L</strong> 准确率高得并不多，但是从训练天数可以看到，<strong>ViT-H/14</strong> 需要的训练天数是 BiTL-L 的 1/4 左右，<strong>训练代价更小</strong>。</p>
<img src="/a5c1ffe6/12.png" class>

<p>图3、4 表明随着预训练数据集的增大，<strong>Transformer</strong> 的效果会渐渐好于 <strong>ResNet</strong>，这表明 <strong>Transformer 有很好的可扩展性</strong>。图5表示，在同样运算能力下，<strong>Transformer</strong> 的效果也是好于 <strong>ResNet</strong>。</p>
<img src="/a5c1ffe6/13.png" class>

<p>下面是一些可视化结果，中间这张图可以看到虽然本文使用的是 <strong>1D</strong> 的位置编码，但是网络仍然能学到不同 <strong>patch</strong> 位置间关系；右边这张图则表示 <strong>Transformer</strong> 学习能力，可以看到随着网络越深，获取全局信息能力越强。</p>
<img src="/a5c1ffe6/14.png" class>

<p>最后作者也做了一个小的自监督实验，证明了 <strong>Transformer</strong> 是优于卷积神经网络，最近大火的 <strong>MAE</strong> 也证明了这一点。</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-MAE论文逐段精读-《Masked Autoencoders Are Scalable Vision Learners》</title>
    <url>/1a00eebb.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2021-Masked-Autoencoders-Are-Scalable-Vision-Learners.pdf" data-height="500px"></div>

<p><strong>MAE</strong> 论文链接：<a href="https://arxiv.org/abs/2111.06377">https://arxiv.org/abs/2111.06377</a><br><strong>MAE</strong> 代码链接：<a href="https://github.com/facebookresearch/mae">https://github.com/facebookresearch/mae</a></p>
<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=592243278&bvid=BV1sq4y1q77t&cid=457423264&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>这一次李沐博士给大家精读的论文是 <strong>MAE</strong>，这是一篇比较新的文章，2021年11月11日才上传到 <strong>arXiv</strong>。这篇文章在知乎上的讨论贴已经超过了一百万个 <strong>view</strong>，但是在英文社区，大家反应比较平淡一点，<strong>Reddit</strong> 或者 <strong>Twitter</strong> 上大家讨论的并不多。</p>
<p><strong>MAE</strong> 这篇论文大家可以看作是 <strong>CV</strong> 版的 <strong>BERT</strong>，作者提出了<strong>非对称的掩码自编码器</strong>用于计算机视觉自监督学习，通过随机掩盖一部分图像 <strong>patch</strong>，再重构图像缺失的 <strong>pixel</strong>。</p>
<hr>
<h3 id="Transformer、BERT、ViT、MAE关系介绍"><a href="#Transformer、BERT、ViT、MAE关系介绍" class="headerlink" title="Transformer、BERT、ViT、MAE关系介绍"></a>Transformer、BERT、ViT、MAE关系介绍</h3><p>李沐博士首先介绍了 <strong>MAE</strong> 和之前精读的论文（<strong>Transformer，BERT，ViT</strong>）之间的关系。</p>


<ul>
<li><strong>Transformer</strong> 是一个纯基于注意力机制的编码器和解码器，在机器翻译的任务上其比基于 <strong>RNN</strong> 的架构要好一点。</li>
<li><strong>BERT</strong> 使用一个 <strong>Transformer</strong> 编码器拓展到更一般的 <strong>NLP</strong> 任务，使用了像<strong>完型填空</strong>一样的自监督训练机制。不需要使用标号去预测一个句子里面不见（masked）的词，从而获取对文本特征抽取的能力。<strong>BERT</strong> 极大地拓展了 <strong>Transformer</strong> 的应用，使其可以在一个大规模的、没有标号的数据上训练出非常好的模型。</li>
<li><strong>ViT</strong> 将 <strong>Transformer</strong> 用到 <strong>CV</strong> 上面，具体来说它把整个图片分割成很多 *<em>16 * 16*</em> 的小方块，每一个方块做成一个词（token），然后使用 <strong>Transformer</strong> 进行训练。当训练数据足够大的时候（1000万或者一个亿的训练样本），<strong>Transformer</strong> 的架构精度优于 <strong>CNN</strong> 架构。</li>
<li><strong>MAE</strong> 可以看作是 <strong>BERT</strong> 的一个 <strong>CV</strong> 版本，基于 <strong>ViT</strong> 把整个训练拓展到没有标号的数据上面，跟 <strong>BERT</strong> 一样通过完型填空来获取图片的一个理解。<strong>MAE</strong> 并不是第一个将 <strong>BERT</strong> 拓展到<strong>CV</strong>上的工作，但是很有可能是这一类工作中未来影响最大的，由于 <strong>BERT</strong> 加速了 <strong>Transformer</strong> 架构在 <strong>NLP</strong> 上的应用，<strong>MA</strong> 也很有可能加速 <strong>Transformer</strong> 在 <strong>CV</strong> 上的应用。</li>
</ul>
<hr>
<h3 id="标题、作者、摘要、示意图、结论"><a href="#标题、作者、摘要、示意图、结论" class="headerlink" title="标题、作者、摘要、示意图、结论"></a>标题、作者、摘要、示意图、结论</h3><p>首先是论文标题，论文标题意思是：带掩码的自编码器是可扩展的视觉学习器。MAE 这个词就来自于论文标题前两个单词。</p>


<ul>
<li>先看后面的词，写论文的时候当你的算法比较快，可以用 <strong>efficient</strong>，如果模型比较大的话，就用 <strong>scalable</strong>；<strong>vision learners</strong> 可以看作是一个 <strong>backbone</strong> 模型，作者这里没有指出是分类器还是检测器、分割器，因为在论文中作者做的实验很多，分类、检测、分割都做了。</li>
<li><strong>masked</strong> 来源于 <strong>BERT</strong>，<strong>BERT</strong> 是 <strong>masked language model</strong>（带掩码的语言模型），类似于完形填空，每次挖掉一些东西，然后去预测挖掉的东西。</li>
<li><strong>autoencoder</strong> 中 <strong>auto</strong> 不是自动的意思，而是 <strong>自</strong> 的意思，表示样本和标号都来自于图像本身，<strong>MAE</strong> 这篇论文是自监督训练，重构的图像像素就来自于图像本身，并没有引入额外的标号。</li>
</ul>
<p>值得学习的是，这一类标题模板 (xx是xx) 是很强有力的句式，把文章的结论总结成一句话了，结论放在 <strong>title</strong> 里，句式也相对客观。</p>
<p>论文<strong>作者</strong>就不过多介绍了，之前也精读了一作的论文（<strong>ResNet</strong>，<strong>MoCo</strong>），最后两位作者是物体检测领域的大佬。</p>
<hr>
<p>下面是论文<strong>摘要</strong>部分，摘要总共有8句话。</p>


<ul>
<li>第1句话可以看作是论文标题的扩展，本文证明了**掩码自编码器(MAE)**是一种可扩展的计算机视觉自监督学习器。</li>
<li>第2-5句介绍了 <strong>MAE</strong> 算法，<strong>MAE</strong> 方法很简单：随机掩盖一部分图像 <strong>patch</strong>，再重构图像缺失的 <strong>pixel</strong>。它有两个核心设计：一是本文开发了一个<strong>非对称的编码器-解码器体系结构</strong>，其中<strong>编码器只在可见的patch上操作</strong>学习特征，轻量级的解码器从<strong>潜在表征和掩码 token</strong> 重建原始图像。二是作者发现<strong>掩盖高比例的输入图像块（例如75%）</strong>，会生成一个非凡而有意义的自监督任务 （可以理解为如果只遮住几个patch的话，插值法就可以得到图像缺失的像素，遮住一大半图像的话，会迫使模型学习更有用的表征 ）。</li>
<li>第6-8句介绍了 <strong>MAE</strong> 的实验效果，将上面两个核心设计结合起来，能够高效率地训练大模型，训练速度提高了3倍多，且模型准确度也提高了；本文提出的可扩展的方法允许学习高容量的模型，这些模型具有很好的通用性，例在使用 <strong>ImageNet-1K</strong> 数据上，一个原始的 <strong>ViT-Huge</strong> 模型获得了最好的准确率 (87.8%)；在<strong>迁移学习</strong>模型性能也优于有监督预训练，同时也表现出很好的可扩展行为。</li>
</ul>
<hr>
<p>下面是论文中重要的<strong>示意图</strong>，一般放在论文第一页的右上角，这是 <strong>MAE</strong> 的结构。</p>


<p>整个训练流程为：输入一张图片，分割成一个个 <strong>patch</strong>，然后随机掩盖一部分 <strong>patch</strong> （图中处理成灰色块）；可见的 <strong>patch</strong> 输入到编码器进行训练得到图像特征；然后训练得到的特征和掩盖的图像块（含有位置信息）输入到解码器，解码器输出为预测的掩盖图像块像素。可以看到这里的编码器和解码器大小不一样，主要的计算量都在编码器，且由于编码器只处理1/4的图像，其计算量也得到了降低，训练速度也提高了。</p>
<p>如果想在其它视觉任务上使用 <strong>MAE</strong>，只需要使用掩码器就行了。输入一张图片，不需要做掩码处理，直接分割成 <strong>patch</strong>，然后得到所有 <strong>patch</strong> 的特征表示，可以看作是这张图片的特征，后面使用分类头、检测头、分割头去预测。</p>
<p>下图是作者在 <strong>ImageNet、COCO</strong> 数据集上的测试结果、以及不同掩码比例后得到的结果（图4），可以看到其重构效果是很拔群的。</p>


<hr>
<p>最后是论文<strong>结论</strong>部分，总共有3段。</p>


<ul>
<li>可扩展的简单的算法是深度学习的核心。这里的简单前提是指作者对 <strong>ViT</strong> 很熟悉，本文训练的方法很简单。在 <strong>NLP</strong> 中，简单的自监督学习方法可以从指数级扩展模型中获益。在计算机视觉中，尽管在自监督学习方面取得了进展，但实际中占统治地位的预训练范式任然是有监督学习。在本文中，我们在 <strong>ImageNet</strong> 和迁移学习中观察到自编码器提供了可扩展的好处。计算机视觉中的自监督学习现在可能正走上与 <strong>NLP</strong> 相似的轨迹。</li>
<li>另一方面，我们注意到<strong>图像和语言是有不同属性的信号</strong>。虽然每一个 <strong>patch</strong> 含有一定语义信息，但它不是语义分割，而且 <strong>MAE 是重构像素，像素不是语义实体</strong>。但是 <strong>MAE</strong> 能够推断出复杂的、整体的重构，表明它已经学会了许多视觉概念。我们假设这种行为是通过 <strong>MAE</strong> 内部丰富的隐藏表示发生的。我们希望这一观点将激励未来的工作。</li>
<li>更广泛的影响，<strong>MAE</strong> 只用了图片本身进行学习，如果图片本身有 <strong>bias</strong> 的话，那么模型可能倾向于某一些图片或 有一些不好的图片，可能会有负面的社会影响；<strong>MAE</strong> 和 <strong>GAN</strong> 类似， 可能生成不存在的内容，有误导大家的可能，如果要使用这个工作，请一定要考虑潜在的影响。</li>
</ul>
<hr>
<h3 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h3><p><strong>导论</strong>前两段介绍了故事背景，现在模型可以很容易过拟合百万张图片并且已经开始需要上亿张图片，但是往往很难访问到这些有标签的数据。这个问题在 <strong>NLP</strong> 可以通过自监督预训练的方式来解决，例如使用自回归语言模型的 <strong>GPT</strong> 和使用掩码自编码的 <strong>BERT</strong>，它们的理论都很简单：移除一部分比例的数据然后学习预测移除的数据，通过这种方式可以训练得到包含千亿参数的模型。</p>
<p>第三段作者说在 <strong>BERT</strong> 之前已经有研究将掩码自编码器（一种通用的去噪声自编码器）用于计算机视觉中。尽管 <strong>BERT</strong> 取得了很大的成功，但自编码器在计算机视觉的应用落后 <strong>NLP</strong>。 于是作者提出疑问：<strong>what makes masked autoencoding differentbetween vision and language?</strong> 作者尝试从三个方面进行回答：</p>
<ul>
<li>二者架构不同， <strong>CNN</strong> 是在规则的网格上运算，并不好加<strong>掩码和位置编码</strong>，不过这个问题已经被 <strong>ViT</strong> 解决了。</li>
<li>视觉和语言的信息密度不同。语言是人类生成的信号，有很高的语义和信息密度。当训练一个模型仅仅对每句话预测少量丢失单词时，任务可以转化成复杂的语言理解问题。相反，图片是有着很多空间冗余的自然信号（一个缺失的块可以由周围的块进行恢复，周围的块包含目标、场景等高级信息）。为了克服这种区别，作者提出了一个简单的策略：<strong>随机mask很大比例的块</strong>。为自监督任务提升了难度，超越了低级别图像统计的理解范畴。</li>
<li>自编码器的 <strong>decoder</strong>，在视觉中，<strong>decoder</strong> 重建像素，因此 <strong>decoder</strong> 的得到是一个相比于目标识别任务更低语义级别的输出。这与语言不同，语言中预测的缺失单词包含了丰富的语义特征。</li>
</ul>
<p>导论最后两段作者介绍了 <strong>MAE</strong> 算法和效果，可以看作是摘要的扩充，作者这里的写法值得一学，通过提出问题，回答问题的方式来引出算法，而且还使用了很多图片，非常加分。</p>


<hr>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>下面是论文<strong>相关工作</strong>部分。作者分别从带掩码的语言模型（<strong>BERT、GPT</strong>）、自编码（<strong>DAE</strong>）、掩码图片编码（<strong>iGPT、BEiT</strong>）、自监督学习（<strong>MoCo</strong>）四个方面进行了介绍。</p>


<hr>
<h3 id="MAE算法、实验"><a href="#MAE算法、实验" class="headerlink" title="MAE算法、实验"></a>MAE算法、实验</h3><p>下面是 <strong>MAE</strong> 算法部分，算法部分篇幅不长，示意图之前我们已经介绍过了，作者从5个方面进行了介绍。</p>
<ul>
<li><strong>Masking</strong>：和 <strong>ViT</strong> 一样，我们将图像分割为规则的非重叠 <strong>patch</strong>。然后，采样对 <strong>patch</strong> 进行采样，并掩码（即移除）剩余的 <strong>patch</strong>。我们的采样策略很简单：按照均匀分布随机对 <strong>patch</strong> 进行采样。具有<strong>高掩蔽率</strong>的随机采样在很大程度上消除了冗余，因此创建了一个无法通过从可见相邻 <strong>patch</strong> 外推来轻松解决的任务，增加了任务的难度，这样高度稀疏的输入可以让我们设计出高效的编码器。</li>
<li><strong>MAE encoder</strong>：编码器使用的是 <strong>ViT</strong>，但仅对可见的、<strong>unmasked</strong> 的 <strong>patches</strong> 进行编码。就像在标准 <strong>ViT</strong> 中一样，<strong>patches</strong> 添加位置嵌入后经线性投影得到 <strong>embedded patches</strong>，编码器由一系列 <strong>transformer block</strong> 组成；编码器只在一小部分子集上操作（例如25%图像块），使得能够训练非常大的编码器。</li>
<li><strong>MAE decoder</strong>：解码器的输入是编码的可见块和 <strong>mask tokens</strong>。每个 <strong>mask token</strong> 都是一个共享可学习的向量，表示要预测的缺失 <strong>patch</strong>。对集合中的所有 <strong>tokens</strong> 添加 <strong>positional embedding</strong>。解码器具有另一系列 <strong>Transformer</strong> 块。这个完整集合中的所有tokens添加positional embedding。解码器具有另一系列Transformer模块。解码器仅在<strong>预训练期间</strong>用于执行图像重构任务。因此，解码器可以独立于编码器设计灵活地设计。作者使用了非常小的解码器进行实验。通过这种非对称设计，所有 <strong>tokens</strong> 仅由轻量级解码器处理，这大大减少了预训练时间。</li>
<li><strong>Reconstruction target</strong>：<strong>MAE</strong> 通过预测每个 <strong>masked patch</strong> 的像素值来重构原始图像。解码器输出为表示 <strong>patch</strong> 的像素值向量。解码器的最后一层是一个 <strong>linear projection</strong> 层，其输出通道的数量等于每个 <strong>patch</strong> 中包含的像素数量。和 <strong>BERT</strong> 类似，作者只计算了 <strong>masked patch</strong> 损失。初次之外，作者还研究了每一个 <strong>patch</strong> 的归一化像素值，在实验中能够进一步提高性能。</li>
<li><strong>Simple implementation</strong>：<strong>MAE</strong> 预训练可以被高效率地实现，并不需要任何专门的稀疏化操作。首先，为每个输入 <strong>patch</strong> 生成一个对应 <strong>token</strong>。接下来，我们随机打乱这些 <strong>token</strong> 列表，并根据掩码率删除列表的最后一部分。然后对剩下的 <strong>patch</strong> 进行编码。编码后，将 <strong>mask tokens</strong> 列表附加到已编码的 <strong>patch</strong> 列表中，并还原此列表顺序，将所有 <strong>token</strong> 目标对齐。解码器对所有 <strong>tokens</strong> 进行解码。</li>
</ul>


<hr>
<p>下面是论文<strong>实验</strong>部分，作者先在 <strong>ImageNet-1K</strong> 数据上进行了<strong>自监督预训练</strong>，然后有监督训练时作者分别进行了<strong>端到端微调（允许修改整个模型所有的可学习参数）</strong>和<strong>线性探测（只修改最后一层线性输出层）</strong>两种方式训练。作者与 <strong>ViT-L-16</strong> 进行了对比，实验发现，从头训练 <strong>ViT-L</strong> 时很强的正则化能够提高 <strong>ViT-16</strong> 分类性能（比原始 <strong>ViT-L</strong> 提高了6个百分点）。即使如此，微调的 <strong>MAE</strong> 只训练了 50个 <strong>epochs</strong> 就能得到84.9的准确率，这说明微调版的准确率依赖于预训练。</p>


<p>下面是论文消融实验的介绍，默认设置如下表灰色阴影部分所示，作者分析了<strong>解码器的深度、解码器宽度、编码器是否使用mask token、重构目标、是否使用数据增强、mask 采样策略</strong>对最终结果的影响。（这一部分就不详细展开了，大家可以去看论文原文）。这里值得注意的是有监督训练时<strong>微调模型比线性探测准确率要高</strong>，这是一个很重要的结果。</p>


<p>下面是其它消融实验结果，从下图中可以看到，<strong>75%的掩码率</strong>对线性评估和微调模型都有好处。这与 <strong>BERT</strong> 相反，<strong>BERT</strong> 中的掩码率为15%。当解码器深度为1时，模型准确率反而还提高了，但是训练速度能够加速4倍左右。</p>


<hr>
<p>下面是与<strong>自监督预训练、有监督预训练</strong>的对比以及<strong>部分微调</strong>的实验。可以看到，<strong>MAE</strong> 都取得了很好的结果，且有监督预训练发现 <strong>MAE</strong> 可以帮助扩大模型尺寸。</p>


<p>最后是<strong>迁移学习</strong>实验，无论是在目标检测、语义分割、分类，<strong>MAE</strong> 预训练后的模型都取得了很好的结果。</p>


<p>整篇文章作者提出的算法很简单，论文结果非常好，而且写作非常流畅，实验很详细，是一篇研究范文。最后，简单总结下 <strong>MAE</strong> 为什么能取得这么好的效果。主要有三点：</p>
<ul>
<li><strong>MAE</strong> 需要盖住更多的块（即掩码率更高），进一步降低了剩余块之间的冗余度，任务变得更复杂</li>
<li>使用一个由 <strong>Tranformer</strong> 组成的解码器，直接还原原始图像像素信息，使得整个流程更加简单一点</li>
<li>同时作者加上了在 <strong>ViT</strong> 之后各项研究的技术，使得整个模型训练更鲁棒，更容易</li>
</ul>
<hr>
<h3 id="MAE-可视化-demo"><a href="#MAE-可视化-demo" class="headerlink" title="MAE 可视化 demo"></a>MAE 可视化 demo</h3><p>下面使用作者提供的交互式模型体验下 <strong>MAE</strong> 的威力。<strong>云端Colab</strong> 地址为：<a href="https://colab.research.google.com/github/facebookresearch/mae/blob/main/demo/mae_visualize.ipynb">https://colab.research.google.com/github/facebookresearch/mae/blob/main/demo/mae_visualize.ipynb</a></p>
<p>首先是导入需要的库和模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># check whether run in Colab</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;google.colab&#x27;</span> <span class="keyword">in</span> sys.modules:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Running in Colab.&#x27;</span>)</span><br><span class="line">    !pip3 install timm==<span class="number">0.4</span><span class="number">.5</span>  <span class="comment"># 0.3.2 does not work in Colab</span></span><br><span class="line">    !git clone https://github.com/facebookresearch/mae.git</span><br><span class="line">    sys.path.append(<span class="string">&#x27;./mae&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    sys.path.append(<span class="string">&#x27;..&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> models_mae</span><br></pre></td></tr></table></figure>

<p>然后是一些使用到的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># define the utils</span></span><br><span class="line"></span><br><span class="line">imagenet_mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">imagenet_std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_image</span>(<span class="params">image, title=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">    <span class="comment"># image is [H, W, 3]</span></span><br><span class="line">    <span class="keyword">assert</span> image.shape[<span class="number">2</span>] == <span class="number">3</span></span><br><span class="line">    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * <span class="number">255</span>, <span class="number">0</span>, <span class="number">255</span>).<span class="built_in">int</span>())</span><br><span class="line">    plt.title(title, fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_model</span>(<span class="params">chkpt_dir, arch=<span class="string">&#x27;mae_vit_large_patch16&#x27;</span></span>):</span></span><br><span class="line">    <span class="comment"># build model</span></span><br><span class="line">    model = <span class="built_in">getattr</span>(models_mae, arch)()</span><br><span class="line">    <span class="comment"># load model</span></span><br><span class="line">    checkpoint = torch.load(chkpt_dir, map_location=<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    msg = model.load_state_dict(checkpoint[<span class="string">&#x27;model&#x27;</span>], strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(msg)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_one_image</span>(<span class="params">img, model</span>):</span></span><br><span class="line">    x = torch.tensor(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># make it a batch-like</span></span><br><span class="line">    x = x.unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">    x = torch.einsum(<span class="string">&#x27;nhwc-&gt;nchw&#x27;</span>, x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># run MAE</span></span><br><span class="line">    loss, y, mask = model(x.<span class="built_in">float</span>(), mask_ratio=<span class="number">0.75</span>)</span><br><span class="line">    y = model.unpatchify(y)</span><br><span class="line">    y = torch.einsum(<span class="string">&#x27;nchw-&gt;nhwc&#x27;</span>, y).detach().cpu()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># visualize the mask</span></span><br><span class="line">    mask = mask.detach()</span><br><span class="line">    mask = mask.unsqueeze(-<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, model.patch_embed.patch_size[<span class="number">0</span>]**<span class="number">2</span> *<span class="number">3</span>)  <span class="comment"># (N, H*W, p*p*3)</span></span><br><span class="line">    mask = model.unpatchify(mask)  <span class="comment"># 1 is removing, 0 is keeping</span></span><br><span class="line">    mask = torch.einsum(<span class="string">&#x27;nchw-&gt;nhwc&#x27;</span>, mask).detach().cpu()</span><br><span class="line">    </span><br><span class="line">    x = torch.einsum(<span class="string">&#x27;nchw-&gt;nhwc&#x27;</span>, x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># masked image</span></span><br><span class="line">    im_masked = x * (<span class="number">1</span> - mask)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># MAE reconstruction pasted with visible patches</span></span><br><span class="line">    im_paste = x * (<span class="number">1</span> - mask) + y * mask</span><br><span class="line"></span><br><span class="line">    <span class="comment"># make the plt figure larger</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = [<span class="number">24</span>, <span class="number">24</span>]</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">    show_image(x[<span class="number">0</span>], <span class="string">&quot;original&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">    show_image(im_masked[<span class="number">0</span>], <span class="string">&quot;masked&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">    show_image(y[<span class="number">0</span>], <span class="string">&quot;reconstruction&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">    show_image(im_paste[<span class="number">0</span>], <span class="string">&quot;reconstruction + visible&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p>下面是加载图片（是一只小狐狸）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load an image</span></span><br><span class="line">img_url = <span class="string">&#x27;https://user-images.githubusercontent.com/11435359/147738734-196fd92f-9260-48d5-ba7e-bf103d29364d.jpg&#x27;</span> <span class="comment"># fox, from ILSVRC2012_val_00046145</span></span><br><span class="line"><span class="comment"># img_url = &#x27;https://user-images.githubusercontent.com/11435359/147743081-0428eecf-89e5-4e07-8da5-a30fd73cc0ba.jpg&#x27; # cucumber, from ILSVRC2012_val_00047851</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(requests.get(img_url, stream=<span class="literal">True</span>).raw)</span><br><span class="line">img = img.resize((<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">img = np.array(img) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> img.shape == (<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># normalize by ImageNet mean and std</span></span><br><span class="line">img = img - imagenet_mean</span><br><span class="line">img = img / imagenet_std</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = [<span class="number">5</span>, <span class="number">5</span>]</span><br><span class="line">show_image(torch.tensor(img))</span><br></pre></td></tr></table></figure>



<p>加载 <strong>MAE 预训练模型</strong>，文件大小有点大（1.2G左右）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This is an MAE model trained with pixels as targets for visualization (ViT-Large, training mask ratio=0.75)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># download checkpoint if not exist</span></span><br><span class="line">!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large.pth</span><br><span class="line"></span><br><span class="line">chkpt_dir = <span class="string">&#x27;mae_visualize_vit_large.pth&#x27;</span></span><br><span class="line">model_mae = prepare_model(chkpt_dir, <span class="string">&#x27;mae_vit_large_patch16&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Model loaded.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>下面运行模型，观察效果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># make random mask reproducible (comment out to make it change)</span></span><br><span class="line">torch.manual_seed(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MAE with pixel reconstruction:&#x27;</span>)</span><br><span class="line">run_one_image(img, model_mae)</span><br></pre></td></tr></table></figure>



<p>下面是另一个 <strong>MAE 预训练模型</strong>，使用了 <strong>GAN loss</strong>，效果会更好一些：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This is an MAE model trained with an extra GAN loss for more realistic generation (ViT-Large, training mask ratio=0.75)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># download checkpoint if not exist</span></span><br><span class="line">!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large_ganloss.pth</span><br><span class="line"></span><br><span class="line">chkpt_dir = <span class="string">&#x27;mae_visualize_vit_large_ganloss.pth&#x27;</span></span><br><span class="line">model_mae_gan = prepare_model(<span class="string">&#x27;mae_visualize_vit_large_ganloss.pth&#x27;</span>, <span class="string">&#x27;mae_vit_large_patch16&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Model loaded.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># make random mask reproducible (comment out to make it change)</span></span><br><span class="line">torch.manual_seed(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MAE with extra GAN loss:&#x27;</span>)</span><br><span class="line">run_one_image(img, model_mae_gan)</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-AI公司称急需用数字技术升级痴呆症护理</title>
    <url>/420daa52.html</url>
    <content><![CDATA[<p>近日，在英国政府确定计划到2024年实现80%社会护理记录的目标后，世界上第一个人工智能（AI）驱动的疼痛评估工具PainChek发布了一份新报告。</p>
<p>在该名为《老年人现代技术疼痛评估的挑战，准则和实践》的白皮书中，确认了对数字技术解决方案的日益需求，以帮助支持护理提供者提供更好的护理结果，并强调了英国护理院在疼痛评估和痴呆症护理方面面临的挑战。</p>
<img src="/420daa52/1.jpg" class>

<span id="more"></span>

<p>Painchek 首席执行官兼董事总经理菲利普·达法斯（Philip Daffas）说：“痴呆症已经成为英国乃至全世界最重要的健康和社会护理问题之一。现在是改变痴呆症护理的时候了，但这只有在英国政府致力于改善和投资于技术支持型护理的情况下才能实现。”</p>
<p>PainChek的人工智能和智能自动化技术实现了分析居民疼痛的面部微表情，特别是针对那些患有痴呆症或认知障碍且无法可靠传达疼痛信息的人。PainChek希望这份报告能为社会护理部门改善痴呆症护理的呼吁增添一份力量，该报告免费提供给英国护理提供者和护理专业人士。预计到2050年，全世界痴呆症患者会是现在数量的三倍。</p>
<img src="/420daa52/2.jpg" class>

<p>据悉，在2019年4月29日，澳大利亚联邦政府养老部长Ken Wyatt宣布向澳大利亚上市公司Painchek提供五百万澳币资金支持其“Painchek®”APP 人工智能认知症病人疼痛医疗检测仪在全澳大利亚约一千家养老院推广使用，执照免费使用一年。这是国际认知症患者疼痛研究成果应用的重大创新和里程碑，是成千上万在养老院居住的认知症患者的重大福音——从此他们的疼痛有望得到有效的减少和更好的管理。</p>
<p>数据指出，住在养老院60%-80%的认知症患者经常出现疼痛病症。这种疼痛的原因通常与认知症患者的肌肉、骨骼、胃肠道、心脏条件、泌尿生殖器感染和褥疮有关。除此之外，口面部疼痛也是经常出现的现象。</p>
<p>疼痛除了导致患者不舒服和情绪低落外，还经常是导致其行为异常的深层次原因。而这最终可能导致不恰当使用抗精神病药物的情况。认知症患者通常无法自己用语言比较准确地描述和表达自己身体疼痛程度，护工虽然有一些检查的方法，但通常比较主观且无法做到实时监测发现并施予适当的处理方案。</p>
<p>“澳大利亚认知症支援组织”（Dementia Support Australia）调查表明50%以上住在养老院的认知症患者没有获得适当的疼痛管理。因此，实时准确地监测到认知症患者的疼痛设备是减少患者疼痛的最有效办法。</p>
<img src="/420daa52/3.jpg" class>

<p>澳大利亚认知症研究人员开发的 “Painchek®”APP认知症患者疼痛医疗检测仪成为了有效管理认知症患者疼痛的最佳解决方案。“Painchek®”APP的研发始于2012年，由“澳大利亚认知症理事会认知症研究基金”资助，西澳大利亚科廷大学药物与生物科学学院Jeff Hughes教授领衔研发课题，后由澳大利亚上市公司Painchek完成产品商业化。</p>
<p>“Painchek®”APP疼痛检测仪使用快捷便利。第一步是护理人员使用“Painchek®”APP智能手机照相机录制一段认知症患者面部短视频、通过面部识别技术研究所拍视频，自动识别那些因疼痛而产生的面部肌肉运动轨迹并记录下来。然后，护理人员使用“Painchek®”APP将他们观察到的患者与疼痛相关的行为（比如：患者如何移动和发声）进行总体评估。最后一步是“Painchek®”APP计算出患者疼痛分值，供护理人员长期监测患者用药和治疗的有效性。</p>
<img src="/420daa52/4.jpg" class>

<p>“Painchek®”APP 是国际上第一部认知症患者疼痛评估医疗设备，已经获得澳大利亚和欧洲医疗设备监管机构认证，并在澳大利亚、新加坡和英国养老院开始得以成功使用。PainChek®已发展成为澳大利亚老年护理行业最常用的临床软件，在英国、北美、新加坡、新西兰和其他地区的影响力迅速扩大。</p>
<p>如今，PainChek®的创新疼痛评估技术被广泛应用于各种环境，包括老年护理机构、医院、残疾支持部门和家庭。迄今为止，已经使用PainChek®完成了85万多项临床评估。PainChek®与护理管理系统集成，覆盖澳大利亚180000多张病床、新西兰25000张病床和英国90000张病床。目前的集成合作伙伴包括AlayaCare、AutumnCare、CareLynx、以人为本的软件、Sarah软件解决方案、HealthMetrics、LeeCare、Management Advantage、Telstra Health、VCare、Medi Map、Access Care Management和MPS等，还有几家即将成立。</p>
<hr>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><blockquote>
<p><a href="https://www.carehomeprofessional.com/digital-tech-urgently-needed-to-level-up-dementia-care-whitepaper-says/">https://www.carehomeprofessional.com/digital-tech-urgently-needed-to-level-up-dementia-care-whitepaper-says/</a><br><a href="https://www.painchek.com/about/our-story/">https://www.painchek.com/about/our-story/</a><br><a href="https://www.sohu.com/a/341214671_180837">https://www.sohu.com/a/341214671_180837</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11547">https://www.scholat.com/teamwork/showPostMessage.html?id=11547</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-如何找研究想法 1</title>
    <url>/502b3cf7.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=592148502&bvid=BV1qq4y1z7F2&cid=457987672&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<p>打补丁法（打脸上最佳(<em>^▽^</em>)</p>
<h3 id="蒸馏原文章的点"><a href="#蒸馏原文章的点" class="headerlink" title="蒸馏原文章的点"></a>蒸馏原文章的点</h3><h4 id="以-MAE-为例"><a href="#以-MAE-为例" class="headerlink" title="以 MAE 为例"></a>以 MAE 为例</h4><img src="/502b3cf7/1.png" class>

<hr>
<h3 id="基于原文章的补丁想自己的点"><a href="#基于原文章的补丁想自己的点" class="headerlink" title="基于原文章的补丁想自己的点"></a>基于原文章的补丁想自己的点</h3><p>（有从ViT+BERT到MAE的分析，再从MAE加上前面整个来看）</p>
<ul>
<li><p>ViT最后一小段</p>
<ul>
<li>怎样把这个东西弄到BERT上去</li>
<li>但原文说效果不如直接在标号上训练效果好</li>
</ul>
</li>
<li><p>MAE</p>
<ul>
<li>遮住更多图片块——冗余度更低，任务更具挑战性</li>
<li>本点可以认为是很强的数据增强：加很多噪声进去</li>
<li>数据增强使模型不那么过拟合：结果证实1600轮训练性能仍在提升</li>
<li>反过来说，坏处是训练特别慢：用更大的数据集更大的模型怎么办？（第一个点get！）</li>
<li>那么可不可以用别的数据增强方法：不需要花那么多时间训练，同时效果也不会差</li>
<li>编码只处理没被遮住的块————上述点延伸而来的加速技巧</li>
</ul>
</li>
<li><p>简单地用全连接层输出像素信息跨度太大</p>
<ul>
<li>MAE</li>
<li>用Transformer来输出（解码）</li>
</ul>
</li>
<li><p>MAE：新的模型，替换掉ViT来看看效果（第二个点get！）</p>
<ul>
<li>如：大家发现Transformer里面，自注意力也好，MLP也好，其实都可以替换，只要架构摆在那里，效果也不错</li>
<li>甚至更打脸，看看CNN行不行</li>
</ul>
</li>
<li><p>BERT的俩损失函数：完形填空/句子对匹配</p>
<ul>
<li>是不是可以加一个额外的损失函数？（第三个点get！）比如最近较火的contrastive learning</li>
</ul>
</li>
</ul>
<p><strong>大家在看论文时，在每一个细节之处都可仔细揣摩揣摩，我来做的时候会用什么别的办法来做呢？</strong></p>
<hr>
<h3 id="实验验证"><a href="#实验验证" class="headerlink" title="实验验证"></a>实验验证</h3><p>想法还需要实验验证：哪个效果最好？</p>
<ul>
<li>有时候做完实验发现想法不是那么回事：但是可以通过<strong>观察结果，得到新的想法</strong>；然后继续，在实验中探寻</li>
<li>其实每个想法对最后的贡献都有那么一点点，揉起来，也可能成一篇文章<ul>
<li>如：MAE揉了俩点，拿掉任何一个，效果应该会打折</li>
</ul>
</li>
</ul>
<hr>
<h3 id="如何打补丁"><a href="#如何打补丁" class="headerlink" title="如何打补丁"></a>如何打补丁</h3><p>补丁咋打？</p>
<ul>
<li>不要在一个上面打太多太多补丁：东一块西一块，会显得比较脏</li>
<li>最好在打补丁时，有一个故事串起来：有时为了故事连续性，拿掉一些不那么重要的补丁也可</li>
</ul>
<p>选啥文打补丁？</p>
<ul>
<li>比较新，空间（脑洞）比较大：没被做过的想法还是很多<ul>
<li>如ViT一出来，马上大量跟进</li>
</ul>
</li>
<li>如一篇论文已经是打补丁论文了，在上面打就很可能很难打到补丁了：作者都试过好多了，再试，很有可能作者早就试过了</li>
<li>掂量自己几斤几两：没有财力支持，不要选“贵”的文章<ul>
<li>MAE已经算比较便宜的一个工作了，一次几千美金，整个论文做几十个甚至上百实验，就大概几十万美金</li>
</ul>
</li>
</ul>
<p>也可以自己做新模型/一些改进使得整个训练加速</p>
<ul>
<li>精度提高？训练更快更便宜？</li>
</ul>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/h5/note-app/view?cvid=14358188&amp;pagefrom=comment">https://www.bilibili.com/h5/note-app/view?cvid=14358188&amp;pagefrom=comment</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫方法技巧</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-2022年计算机视觉领域五大发展趋势</title>
    <url>/5aefd2c1.html</url>
    <content><![CDATA[<p>计算机视觉是使用计算机及相关设备对生物视觉的一种模拟。它的主要任务就是通过对采集的图片或视频进行处理以获得相应场景的三维信息，就像人类和许多其他类生物每天所做的那样。同时，其算法是创新型的关键技术——从自动驾驶汽车到智能工业机械甚至手机上的软件等的基础，也是我们正在努力构建的能像人类自身一样理解和学习周围世界的机器的基础。</p>
<p>到2022年底，计算机视觉技术的市场价值预计将达到480亿美元，并可能成为许多持续创新和突破的来源。<strong>美国《福布斯》杂志网站在近日的报道中，列出了计算机视觉技术在2022年的五大发展和应用趋势。</strong></p>
<img src="/5aefd2c1/1.png" class>
<p>图1 计算机视觉</p>
<span id="more"></span>

<hr>
<h3 id="优化数据的质量"><a href="#优化数据的质量" class="headerlink" title="优化数据的质量"></a>优化数据的质量</h3><p>计算机视觉的飞速发展多亏了深度学习技术的不断进步。基于深度学习的图像识别模型尤其依赖它们被“喂食”的图像的质量，而不仅仅是数量。使用自动提取并标记数据的技术提升对标记数据的质量可使计算机视觉技术能用更少的数据获得同样的结果，从而降低资金投入和计算资源等方面的成本，并开辟出更多新的潜在使用案例。</p>
<hr>
<h3 id="应用于健康和安全领域"><a href="#应用于健康和安全领域" class="headerlink" title="应用于健康和安全领域"></a>应用于健康和安全领域</h3><p>计算机视觉可以帮助防止病毒的大范围传播，特别是在在新冠疫情肆虐期间，科学家们开发出了计算机视觉算法，可以通过寻找感染证据和肺部图像受损情况，帮助诊断患者的病情，同时也能用于监控某人是否遵守社交距离规定以及是否佩戴口罩等。</p>
<p>计算机视觉在安全领域也具有非常高的应用价值。科学家们已经开发出了一些方法，让计算机能够检测建筑工地上的不安全行为，如施工人员没有佩戴安全帽，以及监控重型机械工作范围内的人身安全，如果有人误入工作范围，机械会自动关闭。美国劳工统计局的数据显示，每年有270万人受工伤，越来越多企业加大了在该领域的投入，以减少因疏忽造成的人力和财务成本。</p>
<img src="/5aefd2c1/2.png" class>
<p>图2 自动检测安全帽</p>
<hr>
<h3 id="应用于零售业"><a href="#应用于零售业" class="headerlink" title="应用于零售业"></a>应用于零售业</h3><p>2022年，计算机视觉技术将会在购物和零售领域大力普及。2018 年 1 月，亚马逊在西雅图，开设了第一家主打「无人零售」概念的实体店，Amazon Go，其通过摄像头识别顾客从货架上拿走的物品。2017年，阿里公司也在中国杭州创建了中国第一家的无人超市。</p>
<img src="/5aefd2c1/3.png" class>
<p>图3 Amazon Go无人超市</p>
<p>除了无人超市外，计算机视觉在零售业还有许多其他用途，例如应用于库存管理领域，摄像头可检查货架上商品的摆放情况和仓库内的库存情况，并在必要时自动订购补货。它还被用来监控和了解顾客在商店内的移动模式，以优化商品的摆放位置，当然，也可以用来防止商品被盗。计算机视觉技术另一个越来越流行的使用案例是让客户可以用手机扫描条形码来获取产品信息。而在时装零售业，计算机视觉的一个特别有趣的应用是“虚拟试衣间”，顾客可以在不触摸物品的情况下虚拟试穿物品，甚至可以识别顾客正在试穿的产品，并提供搭配建议。</p>
<hr>
<h3 id="在自动驾驶汽车领域“大显身手”"><a href="#在自动驾驶汽车领域“大显身手”" class="headerlink" title="在自动驾驶汽车领域“大显身手”"></a>在自动驾驶汽车领域“大显身手”</h3><p>计算机视觉已经应用于现有的智能网联汽车领域。智能网联汽车指搭载先进的车载传感器、控制器、执行器等装置，并融合现代通信与网络技术，实现车与人、路、后台等智能信息交换共享，实现安全、舒适、节能、高效行驶，并最终可替代人来操作的新一代汽车。</p>
<p>科学家们已经开发出一些视觉系统，能使用摄像头跟踪驾驶员的面部表情，发出警告信号，如驾驶员可能很疲劳，并有可能在开车时睡着等，调查显示，高达25%的致命和严重交通事故由这一因素引起，因此，这样的技术和措施可以更好地挽救生命。</p>
<img src="/5aefd2c1/4.jpg" class>
<p>图4 驾驶员疲劳检测系统</p>
<p>这项技术已经在货运卡车等商用车辆上使用，到2022年，它有望进入私家车领域。计算机视觉在汽车领域的其他可能用途包括监控乘客是否系好安全带，甚至下车时是否落下钥匙和电话等。</p>
<p>当然，计算机视觉也将在自动驾驶汽车领域发挥重要作用。如特斯拉公司今年宣布，其汽车将主要依靠计算机视觉，而不是使用雷达来为汽车行驶周围的环境建模。</p>
<hr>
<h3 id="应用于边缘计算领域"><a href="#应用于边缘计算领域" class="headerlink" title="应用于边缘计算领域"></a>应用于边缘计算领域</h3><p>边缘计算是指在数据源头的附近，采用开放平台，就近直接提供最近端的服务。边缘计算与云计算相反，云计算是指通过网络，把众多数据计算处理程序分解，通过服务器组成的系统，把这些分解的小程序再处理分析来得到结果。</p>
<p>在计算机视觉领域，边缘计算技术的重要性与日俱增，因为计算机视觉系统经常需要快速作出决定，比如在自动驾驶汽车等领域，因此根本没有时间将数据发送到云。</p>
<p>随着边缘计算的计算速度不断提高，计算机视觉将在安全领域产生重大影响，鉴于企业商业和个人在捕获和使用视频数据的方式上面临更严格的审查和监管，这一点日益重要。使用边缘设备，如配备了计算机视觉的安全摄像头，人们可以动态分析数据，并在没有理由保留数据（如没有检测到可疑活动）的情况下丢弃数据。</p>
<hr>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><blockquote>
<p><a href="https://www.forbes.com/?sh=47ef39c22254">https://www.forbes.com/?sh=47ef39c22254</a><br><a href="https://www.sohu.com/a/535345641_121124378">https://www.sohu.com/a/535345641_121124378</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11564">https://www.scholat.com/teamwork/showPostMessage.html?id=11564</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-MoCo论文逐段精读-Momentum Contrast for Unsupervised Visual Representation Learning</title>
    <url>/885d2d89.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2020-Momentum-Contrast-for-Unsupervised-Visual-Representation-Learning.pdf" data-height="500px"></div>

<p><strong>MoCo</strong> 论文链接：<a href="https://arxiv.org/abs/1911.05722">https://arxiv.org/abs/1911.05722</a></p>
<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=422340209&bvid=BV1C3411s7t9&cid=461830701&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>这次论文精读李沐博士继续邀请了亚马逊计算机视觉专家朱毅博士来精读 <strong>Momentum Contrast（MoCo)**，强烈推荐大家去看本次的论文精读视频。朱毅博士和上次一样讲解地非常详细，几乎是逐词逐句地讲解，在讲解时把 **MoCo</strong> 相关领域的研究也都介绍了，听完之后收获满满。</p>
<p><strong>MoCo</strong> 获得了 CVPR2020 最佳论文提名，是视觉领域使用<strong>对比学习</strong>的一个里程碑工作。<strong>对比学习</strong>目前也是机器学习领域最炙手可热（？）的一个研究方向，由于其简单、有用、强大，以一己之力盘活了从2017年开始就卷的非常厉害的计算机视觉领域。<strong>MoCo 是一个无监督表征学习的工作，其不仅在分类任务，在检测、分割和人体关键点检测任务上都逼近或超越了有监督学习模型</strong>；<strong>MoCo</strong> 的出现证明我们可能<strong>并不需要大量标注好的数据去预训练</strong>。下图中 <strong>Yann LeCun</strong> 将机器学习比作一块蛋糕，强化学习是蛋糕上的樱桃、有监督学习是蛋糕上的奶油、无监督学习才是那块大蛋糕，才是问题的本质，目前很多的大模型都是通过自监督学习得到的。</p>
<img src="/885d2d89/1.png" class>

<hr>
<h3 id="对比学习介绍"><a href="#对比学习介绍" class="headerlink" title="对比学习介绍"></a>对比学习介绍</h3><p>在开始精读论文之前，朱毅博士首先介绍了什么是<strong>对比学习</strong>。如下图所示，有三张图片，图1、2为同一个人不同的表情，图3为dog，<strong>在训练时不会为这三种图片去标注</strong>。将三种图片输入到模型中，模型会得到三张图片各自特征。由于图1、2为同一个人、对比学习就是让特征 f₁ 、 f₂ 比较接近，而特征 f₃ 与另外两个特征在特征空间相距较远，这就是对比学习需要达到的目的。</p>
<img src="/885d2d89/2.png" class>

<p>虽然在对比学习中并不需要为图片进行标注，但是仍然需要知道哪些图片是相似的，哪些图片是不相似的，在计算机视觉中通常使用代理任务来完成。举一个具体的例子 instance discrimination，假设有 n 张图片，选取一张图片 xᵢ，经过裁剪和数据增强后得到两张新的图片 xᵢ¹ 和 xᵢ²，则这两张图片和原来的图片就是相似的，也被称为正样本，其余图片即 j ≠ i，则为负样本。对比学习的灵活之处就在于正负样本的划分，例如同一张图片不同视角可看作为正样本，视频中同一段视频任意两帧可以看为正样本，RGB和深度图也可看作为正样本等等。正是由于其灵活性，对比学习的应用才如此之广。</p>
<img src="/885d2d89/3.png" class>

<hr>
<h3 id="标题、摘要、引言、结论"><a href="#标题、摘要、引言、结论" class="headerlink" title="标题、摘要、引言、结论"></a>标题、摘要、引言、结论</h3><p>先是论文<strong>标题</strong>，论文标题的意思是：使用动量对比去做无监督视觉表征学习，<strong>MoCo</strong> 就来自于论文前两个单词前两个字母。简单介绍什么是<strong>动量</strong>，<strong>动量</strong>在数学上就是加权移动平均。例如 yₜ = m × yₜ₋₁ + (1 − m) × xₜ，yₜ₋₁ 为上一时刻的输出，xₜ 为当前输入，m 为动量参数；当 m 很大时，yₜ 就取决于上一时刻输出，其更新就很缓慢；当 m 很小时，yₜ 就取决于当前时刻输入。</p>
<p>作者团队来自于<strong>FAIR</strong>，就不过多介绍了，五个人谷歌学术引用数达到了50万+。</p>
<img src="/885d2d89/4.png" class>

<hr>
<p>下面是论文<strong>摘要</strong>，摘要写的很简洁，总共只有7句话。</p>
<ul>
<li>第1句话直接介绍主题，我们提出了 <strong>MoCo</strong> 用于无监督视觉表征学习。第2句话意思是我们把对比学习看作是<strong>字典查询</strong>，我们建立了一个动态字典，使用到了<strong>队列</strong>和<strong>移动平均编码器</strong>。</li>
<li>第3句话意思是使用队列和移动平均编码器，我们可以建立一个很大且一致的字典，有助于对比无监督学习。</li>
<li>第4-6句话是模型效果，<strong>MoCo</strong> 在 <strong>ImageNet</strong> 分类上取得了很有竞争力的结果，其中 <strong>linear protocol</strong> 的意思是说将主干网冻结，只训练分类头。更重要的，将 MoCo 学到的特征迁移到下流任务时，在7个检测和分割任务上，<strong>MoCo</strong> 都超过它的有监督预训练对手，<strong>counterpart</strong> 的意思是有监督和无监督训练都使用同一个网络，例如ResNet-50。</li>
<li>最后一句话的意思是，在许多视觉任务上，无监督和有监督特征学习之间的鸿沟被大幅度的填上了。</li>
</ul>
<img src="/885d2d89/5.png" class>

<hr>
<p>下面是论文<strong>引言</strong>部分，总共有6段。</p>
<ul>
<li>第1段说无监督学习在自然语言处理任务中取得了很大的成功，但是在计算机视觉中，仍然是有监督预训练占统治定位。原因可能是各自信号空间的不同。语言任务有着离散的信号空间（单词、词根、词缀等）；但是计算机视觉，原始信号往往是连续、高维的，在构建字典时会有很多问题。</li>
<li>第2段说最近的无监督学习研究都使用了<strong>对比学习</strong>。这些方法可以看作是<strong>构建动态字典</strong>。使用编码器网络将图像或图像块表示成 <strong>key</strong>。无监督学习训练编码器时是这样进行字典查询：<strong>一个编码后的 query 应该和它匹配的 key 相似，而和其它 key 不相似</strong>。这样一个学习就变成了最小化对比损失的问题。</li>
<li>第3段说我们想构建这样的一个字典：<strong>（1）大（2）在训练时保持一致</strong>。大的字典可以让我们采样到想要的连续、高维视觉空间；字典中的 key 应该尽可能使用相同或相似的编码器来表示，这样它们和 <strong>quary</strong> 的比较才能一致。如何让字典又大又一致，作者在后面会详细介绍。</li>
</ul>
<img src="/885d2d89/6.png" class>

<p>第4段说我们提出了 <strong>MoCo</strong> 模型，如下图所示，通过比较 <strong>query</strong> 和 <strong>key</strong> 地相似性来训练编码器。我们用<strong>队列</strong>来存储字典数据，当前时刻数据编码后新的特征入队，最老的数据特征出队，这样字典大小和mini-batch大小就解耦了，就能保证构建一个大的字典；同时使用动量去更新编码器参数，能保证字典中的特征尽可能地一致。使用数学公式表达的话就是：θₖ = mθₖ₋₁ + (1 − m)θq。</p>
<img src="/885d2d89/7.png" class>

<p>第5段介绍了<strong>代理任务</strong>，作者使用个体判别作为代理任务，即同一张图片不同视角的 <strong>query</strong> 和 <strong>key</strong> 看作是相似的。在 <strong>ImageNet</strong> 数据线性分类问题上 <strong>MoCo</strong> 显示出了很有竞争力的结果。第6段作者说无监督学习最主要的目的是将预训练好的特征迁移到下游任务中。在7个检测和分割任务上，<strong>MoCo</strong> 都有着很好的效果。无论是百万张图片还是10亿张图片，<strong>MoCo</strong> 都工作地很好。意味着无监督学习和有监督学习之间的差距越来越小了，在许多应用中逐渐可以替代有监督预训练模型。</p>
<img src="/885d2d89/8.png" class>

<hr>
<p>下面是<strong>结论和讨论</strong>部分，结论就1句话，我们的无监督学习方法在许多计算机视觉数据和任务上都有着很好的结果。<strong>MoCo</strong> 从百万数据到十亿数据性能提升是有的，但是很小，可能是这些大规模数据未充分利用，希望有更高级的代理任务来提高模型性能；有可能将 <strong>MoCo</strong> 调整到像 <strong>masked auto-encoding</strong> 这样的代理任务上（最近作者就提出了大火的 <strong>MAE</strong>）。最后作者希望 <strong>MoCo</strong> 能在其它对比学习研究中有帮助。</p>
<img src="/885d2d89/9.png" class>

<hr>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>下面是论文<strong>相关工作</strong>部分，无监督学习通常包含两方面：<strong>代理任务</strong>和<strong>损失函数</strong>。代理任务通常不是大家实际感兴趣的任务 (如检测、分类、分割)，而是为了学习一个好的数据特征表示；损失函数可以和代理任务分开研究，<strong>MoCo</strong> 关注的就是损失函数研究。</p>
<p>损失函数是为了衡量模型的预测输出和固定目标之间的差异，如通过 <strong>L1、L2</strong> 损失重构像素或通过交叉熵对输入进行分类。对比学习的损失测量的是样本对在特征空间的相似性，在训练过程中，目标通常是不固定的。对抗学习的损失衡量的是概率分布的差异，经常用在无监督数据生成。</p>
<p>各种各样的代理任务被提出来，如重构整张图、重构某个 <strong>patch</strong>、给图片绘上颜色。不同的代理任务可以和对比学习损失函数结合使用，如 <strong>CPC、CMC</strong>。</p>
<img src="/885d2d89/10.png" class>

<hr>
<h3 id="MoCo方法、实验"><a href="#MoCo方法、实验" class="headerlink" title="MoCo方法、实验"></a>MoCo方法、实验</h3><p>下面是论文<strong>方法</strong>部分，对比学习以及最新它的一些最新进展，都可以看作成是训练一个编码器，从而去做一个<strong>字典查询</strong>的任务。假设有一个编码好的查询 <strong>q</strong>，以及一系列已经编码好的样本，也就是 {undefined k₀、k₁、k₂}等，这些可以看作是字典中的 <strong>key</strong>。</p>
<p>这里存在一个假设：在字典中只有一个 <strong>key</strong> 是跟 <strong>query</strong> 匹配的，两个互为正样本对，这个 <strong>key</strong> 叫做 <strong>key positive</strong>（k₊）。定义好了正样本和负样本，接下来就需要一个对比学习的目标函数，这个对比学习的目标函数最好能满足以下要求：（1）当 <strong>q</strong> 和唯一的正样本 k₊ 相似的时候，它的loss值应该比较低；（2）当 <strong>q</strong> 和其他所有的 <strong>key</strong> 都不相似的时候，这个loss的值也应该比较低。通过点积计算相似性，我们使用 <strong>InfoNCE</strong> 当作对比学习损失函数，形式为：</p>
<img src="/885d2d89/11.png" class>

<p>公式中的 τ 是一个温度超参数，是一个标量，如果忽略掉它，就会发现，其实这个 <strong>InfoNCE</strong> 损失就是交叉熵损失，唯一的区别就在于在<strong>交叉熵损失中k指代的是数据集里类别的多少</strong>，但是在对比学习的 <strong>InfoNCE</strong> 损失中，k 指的是<strong>负样本的数量</strong>。</p>
<p>通常来说，查询 <strong>q</strong> 是一个输入 x_q 通过一个编码器 f_q 得到的，同理所有的 <strong>k</strong> 的表示也都是输入 xᵏ 通过一个编码器 fₖ 得到，输入和模型具体的实现是由具体的代理任务决定。既可以是图片，也可以是图片块，或者是含有上下文的一系列的图片块；对于模型，<strong>q</strong> 的编码器和 <strong>key</strong> 的编码器既可以是一样的、也可以是部分共享的，还可以是不一样的。</p>
<img src="/885d2d89/12.png" class>

<hr>
<p>下面介绍<strong>动量对比学习</strong>，对比学习是一种在高维的连续的输入信号上去构建字典的一种方式。高维和连续指的是图片，字典是动态的，之所以是动态的是因为这个字典中的 <strong>key</strong> 都是随机选取的，而且 <strong>key</strong> 的编码器在训练的过程中也是在不停的变化。如果想学一个好的特征，这个字典就必须拥有两个特性（<strong>大</strong>，大的字典能够包含很多语义丰富的负样本，从而有助于学到更有判别性的特征；<strong>一致性</strong>主要是为了模型的训练方便）基于以上动机，作者就提出了动量对比学习。</p>
<ul>
<li><p>首先就是<strong>把一个字典用队列的形式表现出来</strong>。队列其实就是一种数据结构，一般被称作是一个<strong>fifo</strong>（先进先出）的数据结构。作者在这里是用一个队列去代表一个字典，也就是说整个队列就是一个字典，里面的元素就是放进去的 <strong>key</strong>。在模型训练的过程中，每一个 <strong>mini-batch</strong> 就会有新的一批 <strong>key</strong> 被送进来，同时也会有一批老的 <strong>key</strong> 移出去，所以用队列的好处是可以重复使用那些已经编码好的 <strong>key</strong>，而这些 <strong>key</strong> 是从之前的那些 <strong>mini-batch</strong> 中得到的。这样使用了队列之后，<strong>就可以把字典的大小和mini-batch的大小彻底剥离开了</strong>，就可以在模型的训练过程中使用一个比较标准的mini-batch size，一般是128或者是256，但是字典的大小可以变得非常大，它的大小非常灵活，而且可以当作一个超参数一样单独设置。同时在算对比学习目标函数的时候只是取一个近似，而不是在整个数据集上算loss，使用队列的数据结构，可以让维护这个字典的计算开销非常小。</p>
</li>
<li><p>用队列的形式可以使这个字典变得很大，但是也因为使用了非常大的字典，也就是非常长的队列，导致没办法给队列中所有的元素进行梯度回传，也就是说，<strong>key</strong> 的编码器无法通过反向传播的方式去更新它的参数。如果想更新这个 <strong>key</strong> 的编码器，其实有一个非常简单的方法：就是每个训练迭代结束后，将更新好的 f_q 编码器参数直接复制过来给 fₖ 编码器就可以了。这个想法简单确实是简单，但是作者紧接着说这种方式的结果并不好，原因是一个快速改变的编码器降低了这个队列中所有 <strong>key</strong> 的特征的一致性。因此作者提出了<strong>动量更新</strong>的方法，如果将 <strong>key</strong> 编码器参数设为 θₖ，<strong>q</strong> 编码器的参数设为 θ_q，那 θₖ 就是以下面公式进行更新：</p>
</li>
</ul>
<img src="/885d2d89/13.png" class>

<ul>
<li>上式中 m 是动量参数，它是一个0到1之间的数。<strong>q</strong> 的编码器 ，是通过梯度反向回传来更新模型参数，θₖ 除了刚开始是用 θ_q 初始化以外，后面的更新大部分主要是靠自己。如果动量参数 m 设的很大，那么 θₖ 更新就非常缓慢，所以作者接下来说，因为使用了这种动量更新的方式，虽然在队列里的 <strong>key</strong> 都是由不同的编码器产生得到的，但是因为这些编码器之间的区别极小，所以产生的 <strong>key</strong> 的一致性都很强。</li>
</ul>
<img src="/885d2d89/14.png" class>

<ul>
<li><p>下面作者还介绍了 <strong>MoCo</strong> 和之前研究的对比。之前的对比学习研究都可以看作是<strong>字典查找</strong>，但是它们都或多或少受限于<strong>字典的大小</strong>和<strong>字典的一致性</strong>问题，这里作者将之前的方法总结了一下，归纳成了两种结构。第一种就是比较直接的<strong>端到端学习</strong>，如下图所示编码器可以通过梯度回传来更新模型参数。由于模型的正负样本都是从同一个 <strong>mini-batch</strong> 里来的，也就是 x_q 和 xₖ 都是从同一个 <strong>batch</strong> 中来的，它做一次前向传播就能得到所有样本的特征，而且这些样本是高度一致的，因为都是来自一个编码器。听起来确实很美好，编码器能用反向回传学习，特征也高度一致了，但是它的<strong>局限性就在于字典的大小</strong>，因为在端到端的学习框架中，<strong>字典的大小和 mini-batch size 的大小是等价的</strong>，如果想要一个很大的字典，里面有成千上万个 <strong>key</strong> 的话，也就意味着 <strong>mini-batch size</strong> 的大小必须也是成千上万的，这个难度就比较高了。端到端学习的优点在于编码器是可以实时更新的，所以导致它字典里的那些 key 的一致性是非常高的，但是它的缺点在于因为它的字典大小（就是batch-size的大小），导致这个字典不能设置的过大，否则硬件内存吃不消。</p>
</li>
<li><p>在 <strong>memory bank</strong> 中其实就只有一个编码器，<strong>query</strong> 的编码器是可以通过梯度回传来进行更新学习。但是对于字典中的 <strong>key</strong> 是没有一个单独的编码器，<strong>memory bank</strong> 把整个数据集的特征都存到了一起，对于 <strong>ImageNet</strong> 来说，<strong>memory bank</strong> 中就有128万个特征（看上去好像很大，但是每一个特征只有128维，所以即使整个 <strong>memory bank</strong> 中有128万个 <strong>key</strong> ，最后也只需要600M的空间就能把所有的这些key存下来了）。一旦有了这个 <strong>memory bank</strong>，在每次模型做训练的时候，只需要从 <strong>memory bank</strong> 中随机抽样很多的 <strong>key</strong> 出来当作字典就可以了。这里也有一个问题：因为这里的特征都是在不同时刻的编码器得到的，而且这些编码器都是通过梯度回传来进行快速更新的，这也就意味着这里得到的<strong>特征都缺乏一致性</strong>。</p>
</li>
<li><p>显然，无论是<strong>端到端的学习</strong>还是 <strong>memory bank</strong> 的方法，都和作者说的一样，<strong>受限于字典大小</strong>和<strong>特征一致性</strong>这两方面中的至少一个，所以为了解决之前这两种做法的局限性，作者就提出了 <strong>MoCo</strong>。<strong>MoCo</strong> 采用队列的形式去实现字典，从而使得它不像端到端的学习一样受限于 <strong>batch-size</strong> 的大小，同时为了提高字典中特征的一致性，MoCo使用了<strong>动量编码器</strong>。</p>
</li>
</ul>
<img src="/885d2d89/15.png" class>

<p>到这里，其实 <strong>MoCo</strong> 的主要贡献旧已经讲完了，但是如果对<strong>对比学习</strong>不是很熟的人来说可能还是不太理解 <strong>MoCo</strong> 的前向过程到底是什么样子的，可惜的是这篇论文并没有提供一个很直观、形象的模型总览图，取而代之的是伪代码，写得相当简洁明了，理解和复现都比较容易。</p>
<img src="/885d2d89/16.png" class>

<hr>
<p>下面是论文<strong>实验</strong>部分，作者分别在 <strong>ImageNet-1K</strong> 和 <strong>Instagram-1B</strong> 数据集上进行了模型训练，使用的主干网是 <strong>ResNet-50</strong>。首先是<strong>线性分类</strong>结果的展示，在完成了无监督学习的预训练之后，将模型的 <strong>backbone</strong> 冻住，只将它作为一个特征提取器，然后在上面训练一个全连接层去充当分类器，是在 <strong>ImageNet</strong> 验证集上测试，<strong>top-1</strong> 分类准确率。</p>
<ul>
<li><p>如左图所示，三种对比学习方法结果对比：黑色的线表示的是端到端的学习，它的结果只有三个点，因为受限于显卡内存，蓝色的线表示的是 <strong>memory bank</strong> 的形式，它可以用很大的字典，所以它可以随着字典增大一直训练，但是它的效果整体上要比端到端学习和 <strong>MoCo</strong> 的结果都要差一截。作者说这可能是因为特征的不一致性导致的。橙色的线表示 <strong>MoCo</strong>，<strong>MoCo</strong> 确实可以有很大的字典，之所以停在65536这个数字，从图中可以看到，从16384到65536性能也已经比较饱和了，所以再大也可能不会带来更多的性能提升了。如果拿 <strong>MoCo</strong> 和端到端学习的方法做比较，可以发现它们的曲线在刚开始的时候的重合度还是比较高的，但是作者说，因为没有实验的支撑，不知道黑线是否能继续按照现有的趋势继续增长下去，有可能结果会更高，也有可能结果会更低，但是因为做不了实验，所以无从得知。</p>
</li>
<li><p>如下图表格所示，动量使用一个相对较大的值（0.999或者0.9999）的时候性能是最好的，差不多都是59，这就说明了一个变化非常缓慢的编码器是对对比学习有好处的，因为它能够提供一个一致性的特征。但是当把动量逐渐变小，变到0.99或者是0.9的时候，性能的下降就比较明显了，尤其是当直接去掉动量，直接将 <strong>query</strong> 的编码器拿过来当 <strong>key</strong> 编码器用的时候，就会发现不光是性能下降的问题，整个模型甚至都不能收敛。</p>
</li>
<li><p>右下图是和其它分类方法的比较，首先可以发现，对比学习的效果还是不错的，因为准确率要比没有使用对比学习得到得结果要好。作者还强调：在无监督学习中，模型的大小还是非常关键的（模型越大，一般效果就会越好），所以只是比较最后的准确率，而不去关注模型大小的话，就不太公平了，从图中可以看到 <strong>MoCo</strong> 既能在小模型上得到最好的效果，也能在大模型的比较中得到最好的结果。</p>
</li>
</ul>
<img src="/885d2d89/17.png" class>

<p>无监督学习最重要的目标是学习到可迁移的特征，作者用视觉领域中最常见、应用最广的检测任务来做无监督的<strong>MoCo</strong> 预训练模型和 <strong>ImageNet</strong> 的有监督预训练模型之间的比较。表2种第一行使用的是<strong>随机初始化</strong>的模型再做微调，所以它是一个基线网络，分数比较低；第二行使用的是 <strong>有监督ImageNet</strong> 的预训练的模型做初始化然后再做微调，也就是一个比较强的基线结果；最后两行分别是 <strong>MoCo</strong> 在 <strong>ImageNet-1M</strong> 上和在 <strong>Instagram-1</strong> 上做无监督预训练当作模型的初始化，然后再做微调。可以看到大多数结果显示 <strong>MoCo</strong> 在 <strong>ImageNet-1M</strong> 上的预训练就已经超过了有监督的预训练模型。当换成更大的数据集的时候还会有进一步的提升。</p>
<p>接下来作者又再次比较了三种对比学习的检测结果，从表3可以看到 <strong>MoCo</strong> 和前面两种方式比起来确实是好了很多，而且最主要的是之前的两种方法都没有超越有监督预训练模型的结果，只有MoCo是真的超越了。</p>
<img src="/885d2d89/18.png" class>

<p>作者又在 <strong>COCO</strong> 数据上进行了对比。除了在设置a里面 <strong>MoCo</strong> 的模型稍显逊色，在剩下的三个设置下，<strong>MoCo</strong> 预训练的模型都比 <strong>ImageNet</strong> 有监督预训练模型得到的效果要好。</p>
<img src="/885d2d89/19.png" class>

<hr>
<p>最后简单总结下，<strong>MoCo</strong> 在很多的视觉任务上，已经大幅度的把无监督和有监督之间的坑给填上了。<strong>MoCo</strong> 在 <strong>Instagram</strong> 数据集中是要比 <strong>ImageNet</strong> 训练出来的模型要好的，而且是在所有任务上普遍表现的都很好，这说明了 <strong>MoCo</strong> 的可扩展性很好，也就是说如果有更多的数据，<strong>MoCo</strong> 有可能就能学到更好的模型，这和 <strong>NLP</strong> 中得到的结论是一样的，这也符合了无监督学习的终极目标。</p>
<p><strong>MoCo</strong> 这篇论文以及它高效的实现，能让大多数人有机会用普通的GPU就能跑对比学习的实验、做研究。因为 <strong>MoCo</strong> 在各个视觉任务上取得了更好的性能，也激发了很多后续分析性的工作，去研究 <strong>MoCo</strong> 学出来的特征到底和有监督学出来的特征有什么不同，还能从别的什么方向去提高对比学习。</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-一种灵活可塑的新型脑机接口</title>
    <url>/14b111c9.html</url>
    <content><![CDATA[<p>工程研究人员发明了一种先进的脑机接口，具有灵活可模塑的背衬和穿透性微针。为这种脑机接口添加灵活的背衬，可以让设备更均匀地贴合大脑复杂的曲面，更加均匀地分布刺穿皮层地微针。比人类头发细10倍地微针从柔软的背衬中伸出，在不刺穿表面小静脉地情况下穿透脑组织表面，并将来自附近神经细胞地信号均匀地记录在大脑皮层地广阔空间中。</p>
<p>到目前为止，这种新型脑机接口已经在啮齿动物身上进行了测试，并于2月25日发表在了《Advanced Functional Materials》期刊上。这项工作由加州大学圣地亚哥分校电气工程教授Shadi Dayeh 实验室的一个团队和波士顿大学生物医学工程教授Anna Devor带领的研究人员共同领导。</p>
<img src="/14b111c9/1.jpg" class>
<p>图1 使用脑机的小鼠</p>
<span id="more"></span>

<p>这种新的脑机接口与Utah阵列相当并且优于Utah阵列，这是现有的具有穿透性微针地脑机接口地黄金标准。Utah阵列已经被证明可以帮助中风患者和脊髓损伤患者。植入Utah阵列的人可以通过他们的思想来控制机器人肢体和其他设备，这样他们就可以自主完成一部分的日常活动。</p>
<p>新型脑机接口的支持是灵活、可适应和可重新配置，而Utah阵列只有一个不灵活的支持。新型微针阵列背衬的灵活性和一致性有利于大脑和电极之间更紧密地接触，从而可以更好、更均匀地记录大脑活动的信号。研究人员以啮齿动物为模型物种，证实稳定的带宽记录在持续196天的植入期间产生了强大的信号。</p>
<p>此外，软背脑机接口的制造方式允许更大的传感表面，这意味着可以同时监测更大的大脑表面区域。在高级功能材料论文中，研究人员证明了一个具有 1,024 根微针的穿透式微针阵列成功地记录了由大鼠大脑的精确刺激触发的信号。与目前的技术相比，这代表了十倍的微针和十倍的大脑覆盖面积。</p>
<img src="/14b111c9/2.jpg" class>
<p>图2 脑机样式</p>
<hr>
<h3 id="更薄和透明的背衬"><a href="#更薄和透明的背衬" class="headerlink" title="更薄和透明的背衬"></a>更薄和透明的背衬</h3><p>这些软背脑机接口比这类脑机接口的传统玻璃背衬更薄更轻。研究人员在他们的高级功能材料论文中指出，轻质、柔的背衬可以减少与传感器阵列接触的脑组织的刺激。柔性背衬也是透明的。在新论文中，研究人员证明，可以利用这种透明度来进行涉及动物模型的基础神经科学研究，否则这是不可能的。例如，该团队展示了来自穿透微针阵列的同步电记录以及光遗传学光刺激。</p>
<img src="/14b111c9/3.jpg" class>
<p>图3 脑机材质</p>
<hr>
<h3 id="双面光刻制造"><a href="#双面光刻制造" class="headerlink" title="双面光刻制造"></a>双面光刻制造</h3><p>新型大脑传感器背衬的灵活性、更大的微针阵列足迹、可重构性和透明性都归功于研究人员使用的双面光刻方法。从概念上讲，从刚性硅晶片开始，该团队的制造工艺允许他们在刚性硅晶片的两侧构建微观电路和器件。一方面，在硅晶片的顶部添加了一层柔韧的透明薄膜。在该薄膜中，嵌入了钛和金的双层迹线，使迹线与在硅片另一侧制造针的位置对齐。从另一面开始，在添加了柔性薄膜之后，所有的硅都被蚀刻掉了，除了独立的、薄的、尖的硅柱。这些硅尖柱实际上就是微针，它们的底部与在硅被蚀刻掉后留下的柔性层内的钛金迹线对齐。这些钛金迹线通过标准和可扩展的微细加工技术进行图案化，从而以最少的人工劳动实现可扩展的生产。制造过程为数以万计的微针提供了灵活的阵列设计和可扩展性的可能性。</p>
<hr>
<h3 id="未来用处"><a href="#未来用处" class="headerlink" title="未来用处"></a>未来用处</h3><p>未来，新型脑机接口未来可以帮助构建闭环系统，通过信息采集设备采集真实环境的信息，然后将信息转变为电刺激，让行动不便或者意识障碍患者恢复部分机体功能。</p>
<hr>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><blockquote>
<p><a href="https://www.sciencedaily.com/releases/2022/03/220315165029.htm">https://www.sciencedaily.com/releases/2022/03/220315165029.htm</a><br><a href="https://onlinelibrary.wiley.com/doi/full/10.1002/adfm.202112045">https://onlinelibrary.wiley.com/doi/full/10.1002/adfm.202112045</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11589">https://www.scholat.com/teamwork/showPostMessage.html?id=11589</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-植入脑机接口离临床应用还有多远？</title>
    <url>/3e0089b7.html</url>
    <content><![CDATA[<p>2017年3月，约翰逊在一次卡丁车事故中摔断了脖子，导致他的肩膀以下几乎完全瘫痪。他比大多数人都更加清楚这种高位截瘫的境况。因为近几十年来，他的工作就是负责护理瘫痪患者。“非常的无助”他说，“当这种情况发生在我身上时，我什么也做不了，没办法做什么或者付出任何努力。”</p>
<p>后来，约翰逊的康复团队将他介绍给附近位于帕萨迪纳的加州理工学院的研究人员，他们邀请他参加脑机接口的临床试验。尽管被提前告知，这需要数年时间，需要数百次高强度的训练。“我毫不犹豫就答应了”约翰逊说。</p>
<img src="/3e0089b7/1.png" class>
<p>图1：约翰逊用脑机接口拼图作画</p>
<span id="more"></span>

<p>约翰逊在2018年11月植入脑机接口系统，他第一次使用这个系统是在计算机屏幕上移动光标。此后，约翰逊使用脑机接口控制机器人手臂，使用Photoshop软件，玩“射击”电子游戏，现在驾驶模拟汽车穿越虚拟环境，改变速度，转向和应对危险。包括约翰逊在内，估计有35人在大脑中长期植入了脑机接口设备。目前大约十几个实验室进行此类研究，但这个数字正在增加。过去的五年里，这些设备可以恢复的技能范围大大扩大。</p>
<p>为了帮助一个瘫痪病人手写，科学家在瘫痪病人的运动前区植入了电极，并记录他想象书写这些字母时候的神经活动。他们使用这些活动训练了一个机器学习算法。当这个患者想象手写单词的时候，算法解码神经活动判断是哪个字符，并且利用类似于手机预测输入的算法来矫正这个结果。</p>
<img src="/3e0089b7/2.jpg" class>
<p>图2：脑机接口将想法变成手写字符(Willett et al., 2021)</p>
<p>到目前为止，绝大多数用于记录单个神经细胞活动的长期植入物都是由一家公司制造的——总部位于犹他州盐湖城的医疗设备开发商Blackrock Neurotech。但在过去的七年里，对脑机接口的商业兴趣激增。最值得注意的是，2016年，企业家Elon Musk在加利福尼亚州旧金山创立了Neuralink，目标是连接人类和计算机。</p>
<p>然而，将脑机接口推向市场，意味着要把一种仅在少数人中经过原理测试的定制技术转变为可以大规模制造、植入和使用的产品。大型试验需要表明，BCI可以在非研究环境中工作，并明显改善用户的日常生活——并且以市场可以接受的价格。实现这一切的时间表并不确定，德克萨斯州奥斯汀神经技术公司Paradromics的创始首席执行官Matt Angle说：“几千年来，我们一直在寻找治愈瘫痪者的方法，而现在，我们正逐步拥有可以实现这一梦想的技术。”</p>
<hr>
<h3 id="界面演化"><a href="#界面演化" class="headerlink" title="界面演化"></a>界面演化</h3><p>2004年6月，研究人员将电极阵列压入一名因刺伤而瘫痪的男子的运动皮层。他是第一个接受长期BCI植入物的人。像大多数从那以后接受BCI的人一样，他的认知完好无损。他可以想象移动，但他失去了运动皮层和肌肉之间的神经通路。许多实验室在猴子身上研究了几十年后，研究人员学会了从运动皮层神经活动的实时记录中解码猴子的运动(Georgopoulos,1986)。</p>
<img src="/3e0089b7/3.jpg" class>
<p>图3：运动皮层神经细胞群体放电的向量求和决定运动方向（Georgopoulos, 1986）</p>
<p>2006年，一篇具有里程碑意义的论文(Hochberg et al., 2006)描述了这名男子如何学会在计算机屏幕上移动光标，控制电视，以及仅仅通过思考使用机器人手臂和假肢手。这是名为BrainGate的多中心试验中的第一个，这项临床试验今天仍在继续。</p>
<p>今天的BCI用户可以实现更精细的运动控制，获得更广泛的技能。部分原因是研究人员开始在用户的不同大脑区域植入多个BCI电极，并开发了识别有用信号的新方法。但最大的推动力来自机器学习，机器学习提高了解码神经活动的能力。</p>
<hr>
<h3 id="运动自主"><a href="#运动自主" class="headerlink" title="运动自主"></a>运动自主</h3><p>当被问及他们想从辅助神经技术中得到什么时，瘫痪的人最常见回答是“自主”。因为对于那些无法移动四肢的人来说，这通常意味着恢复运动。</p>
<p>一种方法是植入电极，直接刺激一个人四肢的肌肉，并让BCI直接控制这些。克利夫兰凯斯西储大学神经科学家Bolu Ajiboye说：“如果你能捕捉到与控制手部运动相关的皮层信号，就可以绕过脊髓损伤，直接把大脑指令发送到外周肌肉。” Ajiboye现在正在扩展他的系统可以解码的命令信号库，例如抓握力的命令信号。他还想给BCI用户一种触觉，这是几个实验室追求的目标。</p>
<p>2015年，宾夕法尼亚州匹兹堡大学神经科学家Robert Gaunt领导的一个团队报告称，在一个人的体感皮层的手部区域（手部的触觉信息在这里处理）植入了电极阵列。当他们使用电极刺激神经细胞时，这个人感觉到一种像是被触摸的感觉。 后来，Gaunt与同事詹妮弗·科林格联手，推动BCI对机器人手臂的控制。他们一起开发了一个机器人手臂，指尖上嵌入了压力传感器，这些传感器采集的信息通过反向的脑机接口送入体感皮层的电极，以唤起合成的触觉。Gaunt解释说，这并不是一种完全自然的感觉——有时感觉像压力或被戳动，有时更像是震动。尽管如此，触觉反馈使假肢的使用感觉更自然，拿起物体所花费的时间减少了一半，从大约20秒减少到10秒(Flesher et al., 2021)。</p>
<img src="/3e0089b7/4.jpg" class>
<p>图4：触觉信息通过电刺激反馈回大脑以改进运动控制 (Flesher et al., 2021)</p>
<hr>
<h3 id="从动作到意图"><a href="#从动作到意图" class="headerlink" title="从动作到意图"></a>从动作到意图</h3><p>“丧失交流能力是大脑损伤最糟糕的后果之一，”加州大学旧金山分校的神经外科医生、神经科学家Edward Chang（张复伦）说。在早期的脑机接口研究中，受试可以通过想象手部的移动与抓取动作，实现在计算机屏幕上移动光标并点击字母——这提供了一种交流的实现方式。但最近，Chang和其他研究者聚焦于自然表达过程中的动作，并取得了很大进展。</p>
<p>Chang的团队首先研究了大脑中产生音素、并由此产生言语的区域——一个被称为背侧喉皮层的定义尚不明确的脑区。 接着，研究者利用这些发现建立一种语音解码系统，将受试想要表达的语言以文字的方式显示在屏幕上。去年，他们报道该系统可以帮助一位因脑干中风而失去说话能力的人使用预先选定的50个词语交流，其速度可达每分钟15个词语（Moses，2021）。“我们学到最重要的是”，Chang说，“解码完整的词语不再仅仅是一个理论问题，而是真正可以实现的事情。” 与其他备受瞩目的脑机接口系统不同，Chang没有记录单个神经细胞的活动，相反，他将电极放置在皮层表面，记录神经细胞群体的平均活动。这些电极记录的信号不如植入电极所记录的信号那样精准，但是这种方法的侵入性更小（注：两种方法的侵入性哪个更小，尚存在争论）。</p>
<img src="/3e0089b7/5.jpg" class>
<p>图5：通过发音运动皮层的颅内脑电活动解码要说的话（Moses, 2021)</p>
<p>这些研究表明，该领域正在迅速成熟，在西雅图华盛顿大学研究非人类灵长类动物脑机接口的Amy Orsborn说，“临床研究的数量和他们在临床领域取得的飞跃都显著增长，”“随之而来的是商业投资的兴趣。”</p>
<hr>
<h3 id="从实验室到市场"><a href="#从实验室到市场" class="headerlink" title="从实验室到市场"></a>从实验室到市场</h3><p>尽管这些成就吸引了媒体和投资者的大量关注，但该领域距离改善失去行动或说话能力的人们的日常生活还有很长的路要走。目前，研究受试要在短期、高强度的实验中操作脑机接口系统；几乎所有的系统都必须物理地连接到一组计算机上，并由一个科学家团队进行指导操作，他们需要不断地调整和重新校准解码器和相关软件。</p>
<p>许多研究者现在正在与公司合作开发一种可销售的设备。18年来，Blackrock Neurotech的设备一直是临床研究的中流砥柱。</p>
<img src="/3e0089b7/6.jpg" class>
<p>图6：Blackrock Neurotech的植入脑机接口设备</p>
<hr>
<h3 id="未来挑战"><a href="#未来挑战" class="headerlink" title="未来挑战"></a>未来挑战</h3><p>大多数从事脑机接口研究的研究人员对他们面临的挑战持谨慎态度。“如果你仔细想想，它确实比任何其他神经系统设备都要复杂，”Shenoy 说。“要让这项技术更加成熟，可能需要一段艰难的成长阶段。” Orsborn强调，商业设备必须在没有专家监督的情况下可以工作数月甚至数年——此外它们需要在每个用户身上都能良好地工作。她期待机器学习算法的进步可以通过为用户们提供重新校准步骤来解决第一个问题。但是在用户之间实现一致的性能可能会面临更大的挑战。</p>
<p>最后，人们普遍认为伦理监督必须跟上这种快速发展的技术。脑机接口技术带来不少担忧，从隐私到个人自主权。伦理学家强调，用户必须能够完全控制设备的输出。尽管目前的技术无法解码人们的私人想法，但开发人员将拥有用户每次交流的记录，以及有关他们大脑健康的关键数据。</p>
<p>对于本文开头提到的约翰逊来说，他最渴望的是恢复人际关系和触觉反馈，来自亲人的拥抱。“如果我们能够找到负责这些功能的神经细胞，并在未来的某一天以某种方式将它们的信息传送到假肢装置中，那么我会觉得参与这些脑机接口研究是值得的。”</p>
<hr>
<h3 id="完整文章"><a href="#完整文章" class="headerlink" title="完整文章"></a>完整文章</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/TXb5KOhagemylgcLj80m2A">https://mp.weixin.qq.com/s/TXb5KOhagemylgcLj80m2A</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11641">https://www.scholat.com/teamwork/showPostMessage.html?id=11641</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-科技的力量——智能仿生手将温暖传递</title>
    <url>/dcc06430.html</url>
    <content><![CDATA[<p>继埃隆·马斯克在猴子身上应用侵入式脑机接口技术，将 Neuralink 芯片植入猴脑让猴子可以玩电子游戏后，2022 年 5 月 8 日，中国高科技公司 BrainCo（强脑科技）与东业吉顺宣布合作，致力于推动脑机接口技术的发展。</p>
<p>其中，BrainCo 旗下的世界首款智能仿生手 BrainRobotics 不仅于 2019 年 12 月登上美国《时代》杂志封面，被评选为 2019 年度百大最佳发明之一外，还在德国红点产品设计评选中获得了“最佳设计奖”（RedDot: Best of the Best）。发展至今年北京冬残奥期间，智能仿生手更是助力残疾运动员贾红光和郑涛稳定、顺利地完成火炬交接仪式。贾红光表示，时隔 28 年他通过智能仿生手重获了握手的感觉。</p>
<img src="/dcc06430/1.gif" class>

<span id="more"></span>

<p>手作为人体复杂灵活的器官之一，也是人类具有高度智慧的象征。智能仿生手，是一款融合脑机接口技术与人工智能算法的高科技医疗辅具，通过采集、处理人体神经肌肉活动产生的神经电和肌肉电信号来辨识操控者的运动意图，从而实现仿生手的直观控制。</p>
<img src="/dcc06430/2.jpg" class>

<p>如下图所示，通过选取 10 个最关键的活动自由度，利用 6 个微电机驱动手指运动，仿生手指结构，对于手部有残疾的用户甚至可以精准控制仿生手的每根手指，实现脑中所想幻肢动作。</p>
<img src="/dcc06430/3.jpg" class>

<p>此外，智能仿生手配备各类传感器等装置，在手掌部分模拟了人手的仿生弧度，用户可以获得手指运动位置、速度、力量等信息，感知拿捏的过程，像人手一样运动。</p>
<img src="/dcc06430/4.gif" class>

<p>脑机接口作为一种超前沿的科学技术，在VR、医疗、教育及游戏等领域拥有广阔的发展前景，高科技辅助正一步步改变着残障人士的生活，为人类的身心健康助力。</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11714">https://www.scholat.com/teamwork/showPostMessage.html?id=11714</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-对比学习论文综述-1百花齐放</title>
    <url>/b69dcee2.html</url>
    <content><![CDATA[<h3 id="对比学习综述"><a href="#对比学习综述" class="headerlink" title="对比学习综述"></a>对比学习综述</h3><p>发展历程大概可以分为四个阶段：</p>
<ol>
<li><p>百花齐放</p>
<ul>
<li>InstDisc（instance discrimination）</li>
<li>CPC</li>
<li>CMC</li>
<li>在这个阶段中，方法、模型、目标函数、代理任务都还没有统一，所以说是一个百花齐放的时代</li>
</ul>
</li>
<li><p>CV双雄</p>
<ul>
<li>MoCo v1</li>
<li>SimCLR v1</li>
<li>MoCo v2</li>
<li>SimCLR v2</li>
<li>CPC、CMC的延伸工作</li>
<li>SwAV</li>
<li>这个阶段发展非常迅速，上述工作有的间隔一两个月，有的间隔甚至不到一个月，ImageNet上的成绩基本上每个月都在被刷新</li>
</ul>
</li>
<li><p>不用负样本</p>
<ul>
<li>BYOL以及它后续的一些改进</li>
<li>最后SimSiam将所有的方法都归纳总结了一下，融入到了SimSiam的框架中，基本上是用卷积神经网络做对比学习的一个总结性工作</li>
</ul>
</li>
<li><p>transformer</p>
<ul>
<li>MoCo v3</li>
<li>DINO</li>
<li>对于自监督学习来说，无论是对比学习还是最新的掩码学习，都是用Vision Transformer做的</li>
</ul>
</li>
</ol>
<p>这里只是把最有联系的一些工作串到一起，讲述他们的相似之处和不同之处</p>
<span id="more"></span>

<hr>
<iframe src="//player.bilibili.com/player.html?aid=680170801&bvid=BV19S4y1M7hm&cid=472587940&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="百花齐放"><a href="#百花齐放" class="headerlink" title="百花齐放"></a>百花齐放</h3><h4 id="《Unsupervised-Feature-Learning-via-Non-Parametric-Instance-Discrimination》"><a href="#《Unsupervised-Feature-Learning-via-Non-Parametric-Instance-Discrimination》" class="headerlink" title="《Unsupervised Feature Learning via Non-Parametric Instance Discrimination》"></a>《Unsupervised Feature Learning via Non-Parametric Instance Discrimination》</h4><p>InstDisc（instance discrimination）</p>
<p>这篇论文提出了个体判别任务以及memory bank</p>
<img src="/b69dcee2/1.png" class>

<p>图1：本文方法受到有监督学习结果的启发，如果将一张豹子的图片喂给一个已经用有监督学习方式训练好的分类器，会发现他给出来的分类结果排名前几的全都是跟豹子相关的，有猎豹、雪豹，总之从图片来看这些物体都是长非常相近的；而排名靠后的那些判断往往是跟豹子一点关系都没有的类别</p>
<p>通过很多这样的现象，作者觉得让这些图片聚集在一起的原因并不是因为它们有相似的语义标签，而是因为这些照片长得太像了，某一些 object 就是很相似，它们跟另外一些 object 就是不相似，所以才会导致有些分类分数都很高，而有些分数非常低</p>
<p>最后作者根据这个观察提出了个体判别任务：无监督的学习方式就是把按照类别走的有监督信号推到了极致，现在把每一个 instance 都看成是一个类别，也就是每一张图片都看作是一个类别，目标是能学一种特征能把每一个图片都区分开来</p>
<p>所以图一画的很好，起到了一石二鸟的作用：不仅很简单的介绍了研究动机，自然而然地引入了问题，而且用一句话的形式引入了个体判别这个代理任务</p>
<img src="/b69dcee2/2.png" class>

<p>图二讲述了文章中的方法</p>
<ul>
<li>通过一个卷积神经网络把所有的图片都编码成一个特征（这些特征在最后的特征空间里能够尽可能的分开，因为对于个体判别任务来说每个图片都是自己的类，所以说每个图片都应该和别的图片尽量的分开）</li>
<li>训练这个卷积神经网络使用的是对比学习，所以需要有正样本和负样本，根据个体判别这个任务，正样本就是这个图片本身（可能经过一些数据增强），负样本就是数据集里所有其它的图片</li>
<li>做对比学习，大量的负样本特征到底应该存在哪呢？本文用了 memory bank 的形式：就是说把所有图片的特征全都存到 memory bank 里，也就是一个字典（ImageNet数据集有128万的图片，也就是说memory bank里要存128万行，也就意味着每个特征的维度不能太高，否则存储代价太大了，本文用的是128维）</li>
</ul>
<p>前向过程：</p>
<ul>
<li>假如batch size是256，也就是说有256个图片进入到编码器中，通过一个 Res 50，最后的特征维度是2048维，然后把它降维降到128维，这就是每个图片的特征大小</li>
<li>batch size 是 256 的话也就意味着有256个正样本，那负样本从哪来呢？自然是从 memory bank 里随机地抽一些负样本出来。本文抽了4,096个负样本出来</li>
<li>有了正样本也有了负样本，就可以用NCE loss 计算对比学习的目标函数</li>
<li>一旦更新完这个网络，就可以把 mini batch里的数据样本所对应的那些特征，在 memory bank 里更换掉，这样 memory bank 就得到了更新</li>
<li>接下来就是反复这个过程，不停的去更新这个编码 t，不停的更新这个 memory bank，最后学到这个特征尽可能的有区分性</li>
</ul>
<p>本文的方法还有很多细节都设计的非常巧妙</p>
<ul>
<li>比如说 proximal regularization：它给模型的训练加了一个约束，从而能让 memory bank 里的那些特征进行动量式的更新，跟 MoCo 的想法是非常一致的</li>
</ul>
<img src="/b69dcee2/3.png" class>

<p>另外设置里面超参数的设定，比如说算 loss 的时候温度的设置是0.07，选了4,000个负样本，训练是200个epochs，batch size 是256，起始的 learning rate 是0.03，之后其它论文（尤其是 MoCo）所有的这些实验细节，MoCo 都是严格按照 Inst Disc 来的，这些超参数都没有进行更改。<strong>所以说 Inst Disc 这篇论文也是一个里程碑式的工作：它不仅提出了个体判别这个代理任务，而且用这个代理任务和 NCE loss 做对比学习，从而取得了不错的无监督表征学习的结果，同时它还提出了用别的数据结构存储这种大量的负样本，以及如何对特征进行动量的更新，所以真的是对后来对比学习的工作起到了至关重要的推进作用。</strong></p>
<img src="/b69dcee2/4.png" class>

<hr>
<h4 id="《Unsupervised-Embedding-Learning-via-Invariant-and-Spreading-Instance-Feature》"><a href="#《Unsupervised-Embedding-Learning-via-Invariant-and-Spreading-Instance-Feature》" class="headerlink" title="《Unsupervised Embedding Learning via Invariant and Spreading Instance Feature》"></a>《Unsupervised Embedding Learning via Invariant and Spreading Instance Feature》</h4><img src="/b69dcee2/5.png" class>

<p>这是一篇 CVPR 19 的论文，跟其它论文相比，它的影响力可能不是那么大，之所以提一下这篇论文，是因为它可以被理解成是 SimCLR 的一个前身。它没有使用额外的数据结构去存储大量的负样本，正负样本就是来自于同一个 mini-batch，而且它只用一个编码器进行端到端的学习。</p>
<p><strong>这篇文章也没有给自己起名字，所以就像 Inst Disc 一样就叫它 Inva Spread 好了，所以写论文的时候，最好还是给自己的方法起个名字，而不是叫 ours，这样方便别人记住也方便别人引用，也是一个双赢的事情。</strong></p>
<p>本文的想法其实就是最基本的对比学习</p>
<img src="/b69dcee2/6.png" class>

<p>如图1所示，同样的图片通过编码器以后它的特征应该很类似，不同的图片它的特征出来就应该不类似，这就是题目中说的 invariant 和 spreading，就是说对于相似的图片、物体，特征应该保持不变性，但是对于不相似的物体或者完全不沾边的物体，特征应该尽可能的分散开。</p>
<p>具体做法：</p>
<p>代理任务也是选取了个体判别这个任务</p>
<img src="/b69dcee2/7.png" class>

<p>前向过程：</p>
<ul>
<li>如果 batch size 是256，也就是说一共有256个图片，经过数据增强，又得到了256张图片</li>
<li>对于 x1 这张图片来说， x1’ 就是它的正样本，它的负样本是所有剩下的这些图片（包括原始的图片以及经过数据增强后的图片），也就是说正样本是256，负样本是(256 - 1) * 2，就是除去样本本身之外 mini-batch 剩下的所有样本以及它经过数据增强后的样本</li>
<li>它和 Inst Disc 的区别：Inst Disc中，正样本虽然是256，它的负样本是从一个 memory bank 里抽出来的，它用的负样本是4096甚至还可以更大</li>
<li>本文为什么要从同一个 mini-batch 里去选正负样本？因为这样就可以用一个编码器做端到端的训练了，这也就是MoCo里讲过的端到端的学习方式</li>
<li>剩下的前向过程都是差不多的，就是过完编码器以后，再过一层全连接层就把这个特征的维度降的很低，就变成128，正样本比如说上图中绿色的球在最后的特征空间上应该尽可能的接近，但是这个绿色的球跟别的颜色的特征应该尽可能的拉远</li>
<li>本文所用的目标函数也是 NCE loss 的一个变体</li>
<li>这篇论文，刚好属于另一个流派，也就是端到端的学习，而且只用一个编码器，不需要借助外部的数据结构去存储大量的负样本，它的正负样本都来自于同一个 mini-batch</li>
<li>既然它跟 SimCLR 这么像，为什么它没有取得那么好的结果呢？就是之前在 MoCo 那篇论文里反复强调过的，就是这个字典必须足够大，也就是说在做对比学习的时候，负样本最好是足够多，而本文的作者是没有 TPU 的，所以说它的 batch size 就是256，也就意味着它的负样本只有500多个，再加上它还缺少像 SimCLR 那样那么强大的数据增广以及最后提出的那个 mlp projector，所以说呢这篇论文的结果没有那么炸裂，自然也就没有吸引大量的关注，但事实上它是可以理解成 SimCLR 的前身</li>
</ul>
<hr>
<h4 id="《Representation-Learning-with-Contrastive-Predictive-Coding》"><a href="#《Representation-Learning-with-Contrastive-Predictive-Coding》" class="headerlink" title="《Representation Learning with Contrastive Predictive Coding》"></a>《Representation Learning with Contrastive Predictive Coding》</h4><p>CPC(contrastive predictive coding)</p>
<p>一般机器学习分为判别式模型和生成式模型，个体判别显然是属于判别式范畴的，那肯定就会有一些生成式的代理任务，比如最常见的预测型的任务</p>
<p>cpc 这篇论文其实非常厉害，因为它是一个很通用的结构</p>
<img src="/b69dcee2/8.png" class>

<p>图1中描述的是CPC不仅可以处理音频，还可以处理图片、文字以及在强化学习里使用，这里为了简单，它用的是一个音频的信号作为输入。</p>
<p>本文的想法：假如说有一个输入 x（一个持续的序列），t 表示当前时刻，t-i 表示过去的时刻，t+i 表示未来的时刻。把之前时刻的输入全都扔给一个编码器，这个编码器就会返回一些特征，然后把这些特征喂给一个自回归的模型（gar，auto regressive），一般常见的自回归模型，就是 RNN 或者 LSTM 的模型，所以每一步最后的输出，就会得到图中红色的方块（ct，context representation，代表上下文的一个特征表示），如果这个上下文的特征表示足够好（它真的包含了当前和之前所有的这些信息），那它应该可以做出一些合理的预测，所以就可以用 ct 预测未来时刻的这个zt + 1、zt + 2（未来时刻的特征输出）</p>
<p>对比学习在哪里体现的呢？正样本其实就是未来的输入通过编码器以后得到的未来时刻的特征输出，这相当于做的预测是 query，而真正未来时刻的输出是由输入决定的，也就是说它们相对于预测来说是正样本；负样本的定义其实很广泛，比如可以任意选取输入通过这个编码器得到输出，它都应该跟预测是不相似的，这就是cpc定义正负样本的方式</p>
<p>这套思想是很朴实的，把输入序列换成一个句子，也可以说用前面的单词来预测后面的单词的特征输出；如果把这个序列想象成一个图片的 patch 块从左上到右下形成一个序列，就可以用上半部分的图片特征去预测后半部分的图片特征，总之是非常灵活</p>
<hr>
<h4 id="《Contrastive-Multiview-Coding》"><a href="#《Contrastive-Multiview-Coding》" class="headerlink" title="《Contrastive Multiview Coding》"></a>《Contrastive Multiview Coding》</h4><p>CMC(contrastive multiview coding)</p>
<p>cpc是用预测的代理任务做对比学习，cmc这篇论文定义正样本的方式就更为广泛了：一个物体的很多个视角都可以被当做正样本</p>
<p>cmc 的摘要写的非常好：</p>
<ul>
<li>人观察这个世界是通过很多个传感器，比如说眼睛或者耳朵都充当着不同的传感器来给大脑提供不同的信号</li>
<li>每一个视角都是带有噪声的，而且有可能是不完整的，但是最重要的那些信息其实是在所有的这些视角中间共享，比如说基础的物理定律、几何形状或者说它们的语音信息都是共享的</li>
<li>在这里举了个很好的例子：比如一个狗既可以被看见，也可以被听到或者被感受到</li>
<li>基于这个现象作者就提出：他想要学一个非常强大的特征，它具有视角的不变性（不管看哪个视角，到底是看到了一只狗，还是听到了狗叫声，都能判断出这是个狗）</li>
<li>cmc工作的目的就是去增大互信息（所有的视角之间的互信息）</li>
<li>如果能学到一种特征能够抓住所有视角下的关键的因素，那这个特征就很好了，至少解决分类问题不在话下</li>
</ul>
<img src="/b69dcee2/9.png" class>

<p>cmc到底是怎么样去形成正样本和负样本从而去做对比学习的呢？如图一所示，它选取的是 NYU RGBD 这个数据集（这个数据集有同时4个view，也就是有四个视角：原始的图像、这个图像对应的深度信息（每个物体离观察者到底有多远）、SwAV ace normal、这个物体的分割图像）</p>
<p>cmc 的意思是说，虽然这些不同的输入来自于不同的传感器或者说不同的模态，但是所有的这些输入其实对应的都是一整图片，都是一个东西，那它们就应该互为正样本，也就是说，当有一个特征空间的时候，比如图中圆圈所示的特征空间，这四个绿色的点在这个特征空间里就应该非常的接近。这时候如果随机再去挑一张图片，不论是用图片还是用风格的图像（总之属于一个不配对的视角）的话，这个特征就应该跟这些绿色的特征远离</p>
<p>这就是 cmc 定义正负样本的方式，它的正样本来自于多个视角，一旦定义好了正负样本，剩下的工作就大差不差了</p>
<p>cmc 是第一个或者说比较早的工作去做这种多视角的对比学习，它不仅证明了对比学习的灵活性，而且证明了这种多视角、多模态的这种可行性。所以说接下来 open AI，很快就出了 clip 模型：也就是说如果有一个图片，还有一个描述这个图片的文本，那这个图像和文本就可以当成是一个正样本对，就可以拿来做多模态的对比学习</p>
<p>cmc 原班作者人马用对比学习的思想做了一篇蒸馏的工作：不论用什么网络，不论这个网络是好是坏是大是小，只要你的输入是同一张图片，那得到的这个特征就应该尽可能的类似，也就意味着想让 teacher 模型的输出跟 student 模型的输出尽可能的相似，它就通过这种方式把 teacher 和 student 做成了一个正样本对，从而可以做对比学习</p>
<p>所以说让大家意识到对比学习如此灵活，可以应用到不同的领域，cmc 功不可没</p>
<p>一个小小的局限性：当处理不同的视角或者说不同的模态时候，可能需要不同的编码器，因为不同的输入可能长得很不一样，这就有可能会导致使用几个视角，有可能就得配几个编码器，在训练的时候这个计算代价就有点高（比如说在 clip 这篇论文里，它的文本端就是用一个大型的语言模型，比如说 bert，它的图像端就是用一个 vit，就需要有两个编码器），这样其实又回到了刚开始讲ViT时候所说的说这个 Transformer 的好处————Transformer有可能可以同时处理不同模态的数据</p>
<p>事实上现在已经有人这么做了，2021的 ICLR 就有一篇 ma clip，它就用一个 Transformer 去同时处理两个输入模态，效果反而更好，所以说这可能才是 Transformer 真正吸引人的地方：一个网络能处理很多类型的数据，而不用做针对每个数据特有的改进。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>第一阶段大概讲了这四篇论文，可以看到：</p>
<ul>
<li>它们使用的代理任务是不一样的，有个体判别，有预测未来，还有多视角多模态</li>
<li>它们使用的目标函数也不尽相同，有 NCE，有 infoNCE，还有 NCE 的其它变体</li>
<li>它们使用的模型也都不一样，比如说 invariant spread 用了一个编码器；Inst Disc 用一个编码器和 memory bank； cpc有一个编码器，还有一个自回归模型；cmc 可能有两个甚至多个编码器</li>
<li>它们做的任务从图像到视频到音频到文字到强化学习，非常的丰富多彩</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>经验分享-数模经验分享</title>
    <url>/6f80ba45.html</url>
    <content><![CDATA[<img src="/6f80ba45/1.png" class>

<span id="more"></span>

<img src="/6f80ba45/2.png" class>

<hr>
<h3 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h3><img src="/6f80ba45/3.png" class>

<img src="/6f80ba45/4.png" class>

<hr>
<h3 id="数学建模"><a href="#数学建模" class="headerlink" title="数学建模"></a>数学建模</h3><img src="/6f80ba45/5.png" class>

<img src="/6f80ba45/6.png" class>

<img src="/6f80ba45/7.png" class>

<img src="/6f80ba45/8.png" class>

<img src="/6f80ba45/9.png" class>

<img src="/6f80ba45/10.png" class>

<img src="/6f80ba45/11.png" class>

<img src="/6f80ba45/12.png" class>

<img src="/6f80ba45/13.png" class>

<img src="/6f80ba45/21.png" class>

<hr>
<h3 id="竞赛项目"><a href="#竞赛项目" class="headerlink" title="竞赛项目"></a>竞赛项目</h3><img src="/6f80ba45/14.png" class>

<img src="/6f80ba45/15.png" class>

<img src="/6f80ba45/16.png" class>

<img src="/6f80ba45/17.png" class>

<hr>
<h3 id="课余生活"><a href="#课余生活" class="headerlink" title="课余生活"></a>课余生活</h3><img src="/6f80ba45/18.png" class>

<img src="/6f80ba45/19.png" class>

<img src="/6f80ba45/20.png" class>

<hr>
<h3 id="数模论文"><a href="#数模论文" class="headerlink" title="数模论文"></a>数模论文</h3><h4 id="高教社杯全国大学生数学建模竞赛CUMCM"><a href="#高教社杯全国大学生数学建模竞赛CUMCM" class="headerlink" title="高教社杯全国大学生数学建模竞赛CUMCM"></a>高教社杯全国大学生数学建模竞赛CUMCM</h4><h5 id="2019-A题-高压油管的压力控制（省一）"><a href="#2019-A题-高压油管的压力控制（省一）" class="headerlink" title="2019 A题 高压油管的压力控制（省一）"></a>2019 A题 高压油管的压力控制（省一）</h5><div class="pdfobject-container" data-target="./file/modeling/A201919007162_陈宗楠_吴易玲_孔睿.pdf" data-height="500px"></div>

<hr>
<h5 id="2020-C题-中小微企业的信贷决策（省一）"><a href="#2020-C题-中小微企业的信贷决策（省一）" class="headerlink" title="2020 C题 中小微企业的信贷决策（省一）"></a>2020 C题 中小微企业的信贷决策（省一）</h5><div class="pdfobject-container" data-target="./file/modeling/C202019007165_陈宗楠_王冰冰_麦艮廷.pdf" data-height="500px"></div>

<hr>
<h4 id="美国大学生数学建模竞赛MCM-ICM"><a href="#美国大学生数学建模竞赛MCM-ICM" class="headerlink" title="美国大学生数学建模竞赛MCM/ICM"></a>美国大学生数学建模竞赛MCM/ICM</h4><h5 id="2020-A题-Moving-North（H奖）"><a href="#2020-A题-Moving-North（H奖）" class="headerlink" title="2020 A题 Moving North（H奖）"></a>2020 A题 Moving North（H奖）</h5><div class="pdfobject-container" data-target="./file/modeling/2010736.pdf" data-height="500px"></div>

<hr>
<h5 id="2021-C题-Confirming-the-Buzz-about-Hornets（M奖）"><a href="#2021-C题-Confirming-the-Buzz-about-Hornets（M奖）" class="headerlink" title="2021 C题 Confirming the Buzz about Hornets（M奖）"></a>2021 C题 Confirming the Buzz about Hornets（M奖）</h5><div class="pdfobject-container" data-target="./file/modeling/2105921.pdf" data-height="500px"></div>

<hr>
<h5 id="2021-F题-Checking-the-Pulse-and-Temperature-of-Higher-Education（H奖）"><a href="#2021-F题-Checking-the-Pulse-and-Temperature-of-Higher-Education（H奖）" class="headerlink" title="2021 F题 Checking the Pulse and Temperature of Higher Education（H奖）"></a>2021 F题 Checking the Pulse and Temperature of Higher Education（H奖）</h5><div class="pdfobject-container" data-target="./file/modeling/2118464.pdf" data-height="500px"></div>

<hr>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>经验分享-保研经验分享</title>
    <url>/f85a9ea3.html</url>
    <content><![CDATA[<img src="/f85a9ea3/1.png" class>

<span id="more"></span>

<img src="/f85a9ea3/2.png" class>

<hr>
<h3 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h3><img src="/f85a9ea3/3.png" class>

<img src="/f85a9ea3/4.png" class>

<hr>
<h3 id="专业课、竞赛、科研三者的平衡"><a href="#专业课、竞赛、科研三者的平衡" class="headerlink" title="专业课、竞赛、科研三者的平衡"></a>专业课、竞赛、科研三者的平衡</h3><img src="/f85a9ea3/5.png" class>

<img src="/f85a9ea3/6.png" class>

<img src="/f85a9ea3/7.png" class>

<hr>
<h3 id="考-保研与找工作的冲突与联系"><a href="#考-保研与找工作的冲突与联系" class="headerlink" title="考/保研与找工作的冲突与联系"></a>考/保研与找工作的冲突与联系</h3><img src="/f85a9ea3/8.png" class>

<img src="/f85a9ea3/9.png" class>

<hr>
<h3 id="读研与工作之间的选择"><a href="#读研与工作之间的选择" class="headerlink" title="读研与工作之间的选择"></a>读研与工作之间的选择</h3><img src="/f85a9ea3/10.png" class>

<img src="/f85a9ea3/11.png" class>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-对比学习论文综述-2CV双雄</title>
    <url>/d37a9a38.html</url>
    <content><![CDATA[<h3 id="CV双雄"><a href="#CV双雄" class="headerlink" title="CV双雄"></a>CV双雄</h3><p>这里之所以是双雄，其实主要想讲的是MoCo和SimCLR</p>
<span id="more"></span>

<hr>
<h4 id="《Momentum-Contrast-for-Unsupervised-Visual-Representation-Learning》"><a href="#《Momentum-Contrast-for-Unsupervised-Visual-Representation-Learning》" class="headerlink" title="《Momentum Contrast for Unsupervised Visual Representation Learning》"></a>《Momentum Contrast for Unsupervised Visual Representation Learning》</h4><p>MoCo</p>
<p>这次主要就讲和其它工作的区别和联系</p>
<p>MoCo 的主要贡献就是把之前对比学习的一些方法都归纳总结成了一个字典查询的问题，它提出了两个东西</p>
<ul>
<li>队列</li>
<li>动量编码器<br>从而去形成一个又大又一致的字典，能帮助更好的对比学习</li>
</ul>
<p>MoCo跟Inst Disc是非常相似的</p>
<ul>
<li>它用队列取代了原来的 memory bank 作为一个额外的数据结构去存储负样本</li>
<li>它用动量编码器去取代了原来 loss 里的约束项，从而能达到动量的更新编码器的目的，而不是动量的去更新特征，从而能得到更好的结果<br>但是整体的出发点以及一些实现的细节都是非常类似的</li>
</ul>
<p>MoCo 的这个实现细节：</p>
<ul>
<li>首先从模型的角度上来说，它用的是残差网络，它的基线模型都用的是 Res 50，其实 Inst Disc 也用的是 Res 50，模型上是一样的</li>
<li>最后每个图片的特征维度也沿用了128维</li>
<li>它也对所有的特征做了 L2 归一化</li>
<li>至于目标函数，MoCo 采用的是 info NCE，而不是像 Inst Disc 是 NCE 但是算 loss 用的温度也是0.07</li>
<li>数据增强的方式也是直接借鉴过来的</li>
<li>包括后面训练的学习率0.03，训练200个epochs这些也都是跟Inst Disc保持一致的</li>
</ul>
<p>所以，说 MoCo 是 Inst Disc 一个改进型工作也不为过，但是 MoCo 真正出色的地方其实有两点</p>
<ul>
<li>一个是它的改进真的是简单有效，而且有很大的影响力的，比如说它的动量编码器，在后面的 SimCLR、BYOL，一直到最新的对比学习的工作都还在使用。它提出的这个技术不仅在当时帮助 MoCo 第一次证明了无监督学习也能比有监督特征学习的预训练模型好，而且还能产生持续的影响力，帮助之后的工作取得更好的结果，所以它的改进很深刻而且很有效</li>
<li>另外一个可圈可点的地方就是 MoCo 的写作真的是高人一等非常不一样，其实如果是一个简单直白的写作方式，在语言里先介绍对比学习是什么，然后再介绍之前的工作有哪些，比如说有端到端的工作，然后有看 Inst Disc，这个 memory bank 的这个工作，然后它们各自都有各自的缺点和局限性，所以说提出 MoCo，用队列去解决大字典的问题，用动量编码器去解决字典特征不一致的问题，最后结果很好，第一次证明了在下游任务中用一个无监督训预训练的模型也会比有监督预训练的模型好，那这种写法也是一种很简洁直白明了的写作方式，大部分论文的写作都是按照这个套路来的。但是 MoCo 的作者明显就高了一个层次：引言上来先说这个 cv 和 nlp 之间的区别，以及到底为什么无监督学习在 cv 这边做的不好，然后第二段它才开始讲对比学习，但是它也不是细细地去讲对比学习，或者细细的去讲那些方法，而是直接把之前所有的方法都总结成了一个字典查找的问题，所以直接把问题给归纳升华了，然后在这个框架下，就是 cv 和 nlp 大一统的框架以及所有的对比学习也都大一统的框架之下，然后作者提出了 MoCo 这个框架，希望能用一个又大又一致的字典去整体地提高对比学习的性能，那论文的 scope 整体就扩大了，远不是之前的那种简单的写作方式可以比的，而且这样的写作风格呢还延续到了方法部分，在 3.1 里，作者没有先写一个模型总览图，也没有具体说是什么模型、什么任务，而是先从最后的目标函数入手，说是用 info NCE 来做的，先把正负样本定义了一下，然后再去讲网络结构然后再去讲实现细节和伪代码，而且在 3.1 里，为了让 MoCo 看起来更朴实，在这里没有直接定义输入是什么，也没有定义这个网络结构到底是什么样的，它是说什么样的输入都可以，比如说它可以是图片，也可以是图片块，或者是上下文的图片块（文献46其实就是cpc），至于网络，它说 query 的编码器和 key 的编码器既可以是相同的（invariant spread），也可以是部分共享的，还可以是完全不同的（文献56就是cmc，因为是多个视角嘛所以是多个编码器）</li>
</ul>
<p>所以说MoCo这种自顶向下的写作方式也是非常值得借鉴的，但这个真的是需要功力，稍有把握不慎别人可能就看不懂了。</p>
<hr>
<h4 id="《A-Simple-Framework-for-Contrastive-Learning-of-Visual-Representations》"><a href="#《A-Simple-Framework-for-Contrastive-Learning-of-Visual-Representations》" class="headerlink" title="《A Simple Framework for Contrastive Learning of Visual Representations》"></a>《A Simple Framework for Contrastive Learning of Visual Representations》</h4><p>SimCLR(simple contrastive learning)</p>
<p>这个方法真的是够简单，这就是为什么很多博客在介绍对比学习的时候都用 SimCLR 当例子，因为它概念上更容易理解，方法上也很容易解释，只不过 batch size 太大，一般人不好上手</p>
<img src="/d37a9a38/1.png" class>

<ul>
<li>图二里说，如果有一个 mini-batch 的图片，假如说是 x，对这个 mini-batch 里的所有图片做不同的数据增强就会得到 xi 和 xj，同一个图片延伸得到的两个图片就是正样本，也就是说如果 batch size 是 n 的话，正样本个数就是 n，负样本的个数就是这个 batch size 剩下所有的样本以及它们数据增强过后的样本，也就和 invariant spread 里讲的一样，是两倍的 n 减 1</li>
<li>然后当有了正负样本之后通过编码器 f 对它进行编码，这两 f 是共享权重，也就说其实只有一个编码器，如果把它想象成一个 res 50 的话，得到的 h（特征表示）是 2048 维了</li>
<li>SimCLR 的重大创新点其实是在特征之后又加了一个 projector，也就是上图中的 g 函数，它就是一个 mlp 层（只有一个全连接层，后面跟一个 relu 的激活函数），但是就这么简简单单的一层 mlp 能让最后学到的特征在 ImageNet 这个分类任务上直接提点将近 10 个点，这个效果在别的任何的任务里或者说在有监督学习里是很难观测到的，很少有说加一个全连接层就能直接提点 10 个点，所以说是一个非常有趣而且非常惊讶的结果</li>
<li>但是在这个框架里，可以想象出有一个特征之后再做一个非线性变化，就得到了另外一个特征，也就是最后去做对比学习的那个特征，一般这个特征 z，它的维度会小一点，为了跟之前的工作保持一致性，它也用了 128 维</li>
<li>最后要衡量一下正样本之间是不是能达到最大的一致性，它采用的是 normalized temperature-scaled 的交叉熵函数。normalized 就是说在这个特征后面进行了 L2 归一化，temperature-scaled 就是说在这个 loss 成了个 tao，所以说其实这个 loss 跟之前说的 infoNCE loss 也是非常接近的</li>
<li>g 函数只有在训练的时候才用，而在做下游任务的时候，是把 g 函数扔掉了，还是只用 h 这个特征去做下游任务，这样的话跟之前的工作也还是公平对比，因为之前它们如果用 res 50，还是用 res 50 并没有多加一层，加上这个 g 函数只是为了能让模型训练的更好</li>
</ul>
<p>和MoCo比起来确实很简单，这里只有一个编码器，既不需要 memory bank，也不需要队列和动量编码器；正负样本全都是从同一个 mini-batch 里来的；整个前向过程非常的直接，就是图片进入编码器编码然后 projector 降维，最后算个对比学习的 loss，非常符合大家对深度学习工作的期待</p>
<p><strong>前面说 invariant spread 可以看作是 SimCLR 的前身，为什么这么说呢？</strong>本文其实整体的这个思路和结构跟 SimCLR 是基本一致的，SimCLR 跟 Inva Spread 的区别其实都写在 SimCLR 的贡献列表里了</p>
<ul>
<li>首先第一个就是它用了更多的数据增强，它发现对比学习真的是需要很强的数据增强的技术</li>
<li>第二就是它加了一个 g 函数（一个可以学习的分线性的变换，就是一个 mlp 层）</li>
<li>第三就是它们用了更大的 batch size，而且训练的时间更久，它发现这两个策略都能让网络学到的特征变得更好</li>
</ul>
<p><strong>乍一看这些贡献有些读者可能就会觉得这些技术不都或多或少在之前的工作里被提出来过吗？</strong>所以说在这篇论文里，作者专门把相关工作放到了第七节，相当于文章的最后才去讲相关工作，它比较细致的跟之前手工的代理任务做了对比，然后跟最近的对比学习也做了对比，而且作者最后非常谦虚的写了这么一段话：就是说基本上所有的这些单个的这些贡献在之前的工作里都被提出来过了，虽然有的时候这个实现的形式可能不太一样，但是作者强调说 SimCLR 的优越之处就是在于它的成功不是由任何一个单一的设计决定，而是把所有的这些技术结合起来而得到的一个结果，而且作者把详细的消融实验，以及它们的设计选择全都放到了附录里，所以说作者团队真的是非常贴心，而且非常谦虚了</p>
<p>而事实上呢，SimCLR 这篇文章中提出来的很多技术都对后续的工作产生了长远的影响力，比如说在编码器之后加这么一个 mlp 层，在之后的 MoCo v2、BYOL 这些工作里全都有使用；它使用的数据增强的策略在之后的工作里也是被广泛的使用；它使用 lars 这个优化器去做大 batch size 的这个模型训练，之后 BYOL 也采用了同样的策略。总之 SimCLR 真的是够简单，而且为后续的很多研究铺平了道路</p>
<p>最后稍微讲一下SimCLR这篇论文里的贡献</p>
<p>第一个就是<strong>数据增强</strong></p>
<ul>
<li>如下图图4所示，SimCLR 这篇论文使用了这么多的数据增强的方法，从最开始的原始图片，到裁剪，到改变色彩，到旋转，使用 cut out，还有使用高斯的噪声和高斯 blur，以及最后使用 sobel 的这种滤波器。真的是把前人想到的这些数据增强的方式全都用了个遍，然后为了让读者知道，到底哪些数据增强有用，哪些数据增强没用，作者还做了详细的这个消融实验</li>
</ul>
<img src="/d37a9a38/2.png" class>

<ul>
<li>下图中除了最后一列是 average，剩下的数字就是这七种数据增强两两互相合并之后的这个效果如何，比如说中间的对角线其实就是使用一个数据增强，发现其实最有效的两个数据增强就是这个 crop 和这个 color，也就是随机的裁剪和随机的这种色彩变换，其它的数据增强其实最后都是锦上添花、可有可无的，但这两个是必须得有的</li>
</ul>
<p>另外一个就是说 SimCLR 这篇文章提出的非线性变换，也就是说在编码器后面加一层 mlp<br>如图8所示，如果 h 是一个 res 50 出来的特征，也就是 2048 维的话，那z就是经过了 projector 之后的维度，一般是 128</p>
<img src="/d37a9a38/3.png" class>

<ul>
<li>g 函数其实里面就包含了一个全连接层和一个 relu 激活函数</li>
<li>projection head 指的是 non-linear，之所以是 non-linear 是因为有 relu 的激活层（relu 就会把一个线性函数变成非线性）</li>
<li>linear 线性指的是不要 relu，只加一层全连接层就可以了</li>
<li>None 其实就是说像 Inva Spread 或者像 MoCo 一样，直接编码器出来的特征拿去做对比学习，不要 projection head</li>
</ul>
<p>然后会发现两个很有意思的现象</p>
<ul>
<li>第一个就是如果用 non-linear 的层，相比原来什么都不用，结果提了十几个点，所以是非常显著的</li>
<li>第二个就是说 z 最后的维度不论是 32、64 还是 2048 其实都没太大区别，这就是为什么对比学习现在一般都选一个比较低的特征维度，因为 128 就够了，再高再低其实最后的结果也没有太大的变化</li>
</ul>
<p>因为这里提升 10 个点实在是太过诡异，所以作者还做了很多实验<br>去验证这个想法，比如说在表 3 里就做了一些实验，但是也仅仅是一些实验，并不一定能真的证明这个事，至今好像也没有一个理论上的解释</p>
<hr>
<h4 id="《Improved-Baselines-With-Momentum-Contrastive-Learning》"><a href="#《Improved-Baselines-With-Momentum-Contrastive-Learning》" class="headerlink" title="《Improved Baselines With Momentum Contrastive Learning》"></a>《Improved Baselines With Momentum Contrastive Learning》</h4><p>因为 MoCo 和 SimCLR 的结果实在是太过惊艳，所以从 2020 年开始就掀起了一波对比学习的狂潮，基本上每天只要去刷 arxiv，都会有对比学习的论文，这波热浪一直到 20 年年底 Vision Transformer 出来以后才逐渐消退</p>
<p>MoCo v2 其实是一个只有两页的技术报告，严格意义上不算是一篇论文了，但即使只有两页，信息量也是相当大</p>
<p>MoCo v2 主要就是说，在看到 SimCLR 这个比较好的结果以后，它们发现 SimCLR 里的那些技术都是即插即用型的，所以说它们就把那些就拿过来了，它直接说就在 MoCo 上面做很简单的改动，引入了 mlp projection head 以及使用更多的数据增强，就又刷新 ImageNet 上的最好成绩，不仅比之前的 MoCo 高很多，而且比最新的 SimCLR 也要高很多</p>
<p>注意，SimCLR 是 2 月 13 号才放到 arxiv 上的，MoCo v2 是 3 月 9 号就放到 arxiv 上了，所以说这个节奏是相当快的</p>
<p>MoCo v2 具体进行了哪些改进？如下表表1所示</p>
<img src="/d37a9a38/4.png" class>

<p>准确的说就四个方面</p>
<ul>
<li>加了一个 mlp 层</li>
<li>加了更多的数据增强</li>
<li>训练的时候用了 cosine 的 learning rate schedule</li>
<li>训练更长的 epoch，从 200 变到了 800</li>
</ul>
<p>ImageNet 上结果</p>
<ul>
<li>灰色的结果 76.5 属于是有监督的这个基线模型</li>
<li>MoCo v1 只能达到 60.6，差的还是比较远的</li>
<li>就在上面加上这个 projection head mlp 层，一下准确率就提高到 66.2，就长了 6 个点，所以说加 projection head 不光是对 SimCLR 有用，对 MoCo 也有用，其实对其之后的很多方法都有用，像 SwAV 呢也用了，BYOL 也用了</li>
<li>如果使用更强的数据增强，就是也能提三个点，从 60 到 63，但是不如 mlp 提升的多</li>
<li>如果把这个 mlp 和 augmentation 一起用就已经到 67.3 了，就非常高了</li>
<li>再加上这个 cos 的这个学习率，就到 67.5 还能再提 0.2 个点，那这个提升就很小了可以忽略不计</li>
<li>最后如果训练更长的时间，训练 800 epochs，就能再提高到 71.1，SimCLR 结果也是这样，如果它训练更久的话，它的结果也会提升很多，一直到现在为止，就连凯明最新的 MAE 这个工作，也是训练了 1,600 个 epochs，而且的这个效果还在继续往上涨</li>
</ul>
<p>无监督学习真的是训练的越久或者模型越大，它的结果就会越好</p>
<p>接下来作者主要跟SOTA进行了比较，其实也就是MoCov1和 SimCLR这些工作，如下表表2所示</p>
<img src="/d37a9a38/5.png" class>

<ul>
<li>在只训练 200 epochs 的情况下，MoCo v2 比 SimCLR 高了大概一个点</li>
<li>如果训练更长的时间，在训练 800 个 epochs 的时候 MoCo v2 能到 71.1，比 SimCLR 训练了 1,000 个 epochs</li>
</ul>
<p>还要好将近 2 个点，所以就意味着 MoCo v2 能更好的利用数据，能在更短的时间内取得更好的结果</p>
<p>接下来作者又再次强调了一下为什么要用 MoCo 以及 MoCo 相比于 SimCLR 的优越性如上图中表3所示：</p>
<ul>
<li>其实这个优越性就在于硬件：机器的内存以及训练的时长</li>
<li>MoCo v2 的作者使用的机器配置是 8 张 v100 的显卡，MoCo 在普通这个 batch size 256 的情况下就能训练，内存只消耗 5 个 G，其实还有很多的剩余空间，还可以再加大 batch size 或者再增大模型都可以，它非常省内存，而且训练一个模型也只需要 53 个小时，在 ImageNet 这种规模的数据集上来说，两天多的时间已经算是很快了</li>
<li>如果这个时候换成 end-to-end 这种端到端的学习，也就之前说的 invariant spread 或者 SimCLR，这里主要指的就是 SimCLR 我们如果只用小 batch size 是 256 的时候，SimCLR 在小 batch size 的情况下只有 61.9 的结果</li>
<li>相对 MoCo v2 来说就差很多了，为什么呢？因为字典不够大、提供的负样本不够多，所以导致对比学习对比不是很有效，而且不光是效果低，它的内存占用 7.4G 也明显高，训练的时长也多了十几个小时，就是全方位呢都不划算</li>
</ul>
<p>如果想要端到端的这个学习走 4096 的这个 batch size 就是说让它的 performance 变好，变成 66.6，虽然说还没有 MoCo v2 好，但也差不多，性能上比较相近，那它对硬件的要求就太高了</p>
<ul>
<li>比如说对 gpu 的这个内存要求，它需要 93 个 g 的内存，这里画了个脚注，意思就是说这只是估计，因为现在也没有这么大内存的 gpu，所以说它只能估计一下，训练时长当然也就不得而知了</li>
</ul>
<p>因为这种端到端的学习方式，包括 SimCLR、BYOL、SwAV 默认都是用 8 台 8 卡机去做训练的,也就是有 64 张 gpu，才能在一两天这个合理的时间内把训练完成，而 MoCo 只需要一台 8 卡机就可以在两天的时间内完成</p>
<hr>
<h4 id="《Big-Self-Supervised-Models-are-Strong-Semi-Supervised-Learners》"><a href="#《Big-Self-Supervised-Models-are-Strong-Semi-Supervised-Learners》" class="headerlink" title="《Big Self-Supervised Models are Strong Semi-Supervised Learners》"></a>《Big Self-Supervised Models are Strong Semi-Supervised Learners》</h4><p>SimCLR v2</p>
<p>其实 SimCLR v2，只是这篇论文一个很小的部分，它只是说怎么从 v1 变到 v2，就是一个模型上的改进，而事实上都在讲如何去做半监督的学习</p>
<p>它主要想说的体现在它的这个标题里了：非常大的自监督训练出来的模型非常适合去做半监督学习</p>
<p>模型总览图如下图中图3所示</p>
<img src="/d37a9a38/6.png" class>

<p>这篇文章分了三个部分</p>
<ul>
<li>第一部分就是 SimCLR，怎样自监督或者说自监督的对比学习去训练一个大的模型出来</li>
<li>第二部分就是说，一旦有了这么好的一个模型，只需要一小部分有标签的数据，然后去做一下有监督的微调，一旦微调结束了，就相当于有一个 teacher 模型，就可以用这个 teacher 模型去生成很多伪标签，这样就可以在更多的无标签的数据上去做自学习了</li>
</ul>
<p>整个框架其实也是受启发于 google 的另外一篇工作（19年的一篇叫 noisy student 的工作）</p>
<ul>
<li>因为 noisy student 就是在 ImageNet 数据集上先训练了一个 teacher 模型，然后在 JFT 300M 那个数据集上生成了很多的伪标签，最后一起训练了一个 student 模型，而这个 student 的模型算是 ImageNet 上的 SOTA，大概是 88 点多的准确率，霸占了 ImageNet 上这个 sota 很长时间，大概有一年的时间</li>
<li>Vision Transformer 就跟这个 noisy student 比过，因为截止到那个时候，noisy student 还是 ImageNet 上的 SOTA</li>
</ul>
<p>作者其实就在第三页大概花了半页的篇幅来讲了一讲怎么把 v1 变成 v2 了，其实大概就是提高了这三个点：</p>
<ul>
<li>第一个就是大家其实都公认的一个事实，就是用更大的模型，无监督训练就会训练的更好，在这里就换了一个更大的模型，换了一个 152 层的残差网络，同时用了这个 selective kernels，也就是 SK net，这个骨干网络变得非常的强</li>
<li>第二点改进就是，之前 SimCLR 说 protection head 的 mlp 层特别有用，而且 MoCo v2 也证明了特别特别的有用，所以 SimCLR 的作者就想那一层都这么有用了，把它再变深点会不会更有用，所以它就试了试变成两层变成三层这个性能会不会继续提升，最后发现其实就是两层就够了，原来是 fc + relu，现在是 fc + relu + fc + relu，一层变成两层的 mlp，这个效果呢就最好了，就是加深了这个 projection head</li>
<li>第三点改进就是它们也使用了动量编码器（这里说 motivated by [29]，就是 MoCo v2 ，[20]就是 MoCo），就是 SimCLR 的作者发现 MoCo 的这个动量编码器真的很管用，所以也想试一试，事实上动量编码器真的管用，后面 BYOL 都用了动量编码器，但在这里作者说动量编码器在 SimCLR 里的提升并不是很大可能就提了一个点，具体原因它们解释说，因为它们已经有非常大的这个 mini-batch，要么是 4096，要么是 8192，所以它们的负样本已经相当多了，所以不论是从字典的大小，还是从字典里特征一致性来说，SimCLR v2 都已经做的很好了，所以说再加这种队列或者加这种动量编码器其实都不会带来很大的提升</li>
</ul>
<p>总的来说就是三点改进：</p>
<ul>
<li>使用了更大的模型</li>
<li>加深了 projection head</li>
<li>引入了动量编码器</li>
</ul>
<p>如果不算半监督学习的内容的话，SimCLR v2 也是一个 2 页的技术报告，而且不论是 SimCLR v1 还是 v2，都只做了分类这个任务，但是 MoCo 就广泛的很多了，至少做了四五个下游的任务，而且刷了很多的数据集，所以 MoCo 系列工作就更 cv friendly，所以它投的都是 cv 的会议，而 SimCLR v1 就是 ICML，而 SimCLR v2 就是  Neural IPS，所以说<strong>投对口的会议也很重要</strong></p>
<hr>
<h4 id="《Unsupervised-Learning-of-Visual-Features-by-Contrasting-Cluster-Assignment》"><a href="#《Unsupervised-Learning-of-Visual-Features-by-Contrasting-Cluster-Assignment》" class="headerlink" title="《Unsupervised Learning of Visual Features by Contrasting Cluster Assignment》"></a>《Unsupervised Learning of Visual Features by Contrasting Cluster Assignment》</h4><p>SwAV</p>
<ul>
<li>Swap</li>
<li>assignment</li>
<li>views<br>给定同样一张图片，如果生成不同的视角，不同的 views 的话，希望可以用一个视角得到的特征去预测另外一个视角得到的特征，因为所有这些视角的特征按道理来说都应该是非常接近的</li>
</ul>
<p>本文的具体的做法就是把对比学习和之前的聚类的方法合在了一起，当然这么想也不是偶然</p>
<ul>
<li>首先，聚类方法也是一种无监督的特征表示学习方式，而且呢它也是希望相似的物体都聚集在某一个聚类中心附近，不相似的物体尽量推开推到别的聚类中心，所以跟对比学习的目标和做法都比较接近</li>
<li>另外，这篇文章的一作其实之前一直也是做聚类的，它之前就做过 deep cluster 这篇工作，也是一篇非常好的无监督学习的论文</li>
</ul>
<p><strong>具体 SwAV 是怎么和聚类的方法融合起来的呢？</strong></p>
<img src="/d37a9a38/7.png" class>

<ul>
<li>上图图 1 把之前对比学习的方法总结了一下画到了左边，然后把 SwAV 的方法画到了右边，这样就比较好对比</li>
<li>左边当然很好理解了，就是同一个图片，做两次数据增强就得到了 x1、x2，然后所有的样本通过一个编码器，这个编码器有可能就是个 Res 50，也有可能是一个 Res 50 加了一个 projection head，它这里没有明说，反正就是所有的这些都属于一个模型，最后这个模型输出一个特征，一旦有了这个特征，用它做一个对比学习的 loss 就可以了</li>
<li>SwAV 说，这么做虽然比较简单，但是直接拿所有图片的特征跟特征做对比有点原始而且有点费资源，因为所有的图片都是自己的类，所以其实像 MoCo 一样，取了 6 万个负样本，这还只是个近似，因为其实所有的数据集，所有的负样本理应是 128 万个图片</li>
<li>SwAV 的作者就想，能不能不去做近似，能不能借助一些先验信息不去跟大量的负样本比，而去跟一些更简洁的东西比，然后 SwAV 的作者就想出来了，可以去跟聚类的中心比（聚类中心就是右图里的 c，也就是个 prototype，它其实就是个矩阵，它的维度是 d 乘以 k，d 是特征的维度，这里的 d 和特征的 d 是一样的，比如说就是之前说的 128 维，这个 k 就是有多少个聚类中心，在这篇文章中它们选的是 3,000，也就是说你有 3,000 个 cluster center，3,000 这个数字也是之前的一些聚类方法在 ImageNet 数据集上常用的一个参数）</li>
</ul>
<p>SwAV的前向过程</p>
<ul>
<li>前面还是都一样的：一个 mini-batch 的图片，做两次数据增强，得到 x1、x2 分别通过编码器得到最后的特征 z1、z2</li>
<li>有了 z1、z2 之后并不是直接在这个特征上去做对比学习的 loss，而是说先通过 clustering 让特征 z 和 prototype c 生成一个目标，也就是这里的 q1、q2</li>
<li><strong>q1、q2 就相当于 ground truth，那它真正要做的这个代理任务是什么呢？</strong>它的意思是说如果 x1、x2 是正样本的话，那 z1 和 z2 的特征就应该很相似，也就跟之前对比学习一样，z1 和 z2 要尽可能的相似</li>
<li>那如果两个特征非常相似，或者说含有等量的信息的时候，按道理来说应该是可以互相去做预测的，也就是说，如果拿 z1 这个特征去跟 c 去做点乘，按道理来说也是可以去预测 q2；反之亦然，z2 和这个 c 去做点乘也可以预测 q1，所以说点乘之后的结果就是预测，而 ground truth 就是之前按照 clustering 分类而得到的 q1 和 q2</li>
<li>所以通过这种 Swapped prediction，也就是换位预测的方法，SwAV 可以对模型进行训练</li>
</ul>
<p>用聚类的好处到底有哪些？</p>
<ul>
<li>首先，就像 SwAV 这篇论文里讲过的一样，如果要跟很多的负样本去做类比，可能就需要成千上万的负样本，而且即使如此也只是一个近似，而如果只是跟聚类中心做对比，则可以用几百或者最多 3,000 个聚类中心，就足以表示了，因为其实也并没有那么多类，ImageNet 也就 1,000 类，COCO 才 80 类，所以说 3,000 个聚类中心就足够用了，这相对于几万个负样本来说还是小了很多的</li>
<li>第二，这些聚类中心是有明确的语意含义的，如果之前只是随机抽样抽取负样本去做对比的话，那些负样本有的可能还是正样的，而且有的时候抽出来的负样本类别也不均衡，所以不如使用聚类中心有效。其实这就是 SwAV 的基本思想。<strong>（如果对聚类算法比较感兴趣，以先去看 deep cluster deep cluster two，然后再来看这篇 SwAV 的论文）</strong></li>
</ul>
<img src="/d37a9a38/8.png" class>

<ul>
<li>SwAV 的结果非常好，它不仅比我们之前讲过的方法效果好，其实比之后要讲的 BYOL、SimSiam 这些都好，算是卷积神经网络里用 Res 50 分刷的最高的一篇工作，达到了 75.3</li>
<li>上图表里的性能做的还是 ImageNet 的 linear evaluation，也就之前说的提前预训练好一个模型以后，把这个模型的 backbone 冻住，只训练最后的那个全连接层</li>
<li>表中之前不是对比学习的方法都还比较低，可能都是在 60 以下，有了对比学习以后，从 MoCo 开始基本上就上 60 了，然后 CPC v2 刷到 63.8，SimCLR 刷到 70，MoCo v2 刷到 71.1，之后要讲的 BYOL 其实 74点几，SimSiam 也是 74点几</li>
<li>所以说 75.3 就算是最高的了，而且这个 75.3 是你把 backbone 冻住的情况下去做的，如果跟有监督的基线模型去比的话，这个有监督的基线模型是从头到尾都在 ImageNet 上训练，最后的结果也就是 76.5，所以说 SwAV 已经是非常非常逼近这个结果</li>
<li>而且当使用更大的模型的时候，也就是像右图里说的一样，把一个 Res 50 变宽，而且就是这里的 2 倍、4 倍、5 倍这么宽的时候，SwAV 的结果还能不停地涨</li>
<li>当用最大的模型（5 倍的模型）的时候，SwAV 已经跟有监督的模型，差距非常的小，而且 SwAV 也是要比 SimCLR 2、SimCLR 4 要高的，所以说从性能上来讲，SwAV 是真的不错</li>
</ul>
<img src="/d37a9a38/9.png" class>

<p>但其实让 SwAV 有这么好的性能，不光是因为它和聚类的方法融合在了一起，它另外一个主要的性能提升点来自于一个叫 multi crop 的 trick：</p>
<ul>
<li>之前的那些对比的学习方法都是用的两个 crop，也就是说一个正样本对 x1、x2 两个图片，如上图左下角所示，本来我们有一个图片，先把它 resize 到 256 * 256，然后随机 crop 两个224 * 224的图片当成 x1 x2，因为这两张图片都非常大，所以它们重叠的区域也非常多，于是它们就应该代表一个正样本</li>
<li>但总之就是两个 crop，SwAV 的作者就想：用这么大的 crop 明显抓住的是整个场景的特征，如果更想学习这些局部物体的特征，最好能多个 crop，去图片里 crop 一些区域，这样就能关注到一些局部的物体了</li>
<li>但是增加 crop，也就是说增加 view，会增加模型的计算复杂度，因为相当于使用了更多的正样本</li>
<li>那如何能同时使用更多的正样本，而又不增加太多的这个计算成本呢？作者就想到了另外一个办法，就是说做点取舍，原来是取了两个 224 * 224 的 crop，现在把这个 crop 变得小一点，变成 160，也就是说取 2 个 160 的 crop 去争取学全局的特征，然后为了增加正样本的数量，为了学一些局部的特征，再去随机选 4 个小一点 crop，然而这 4 个 crop 的大小是 96 * 96，这样的话，就意味着现在有 6 个视角了，而不是像原来一样只有 2 个视角，所以正样本的数量增多了，但是通过这么一种取舍，整体的计算代价还是差不多的</li>
<li>别看这个想法很简单，这个 multi crop 的技术真的很有用而且它不光是对 SwAV 有用，对其它的对比学习的方法也有用</li>
</ul>
<p>作者在下图图3中就做了一些实验</p>
<img src="/d37a9a38/10.png" class>

<ul>
<li>基线模型就是 2 * 224，它用了 multi crop 的这个技术，就是 2 * 160 加上 4 * 96</li>
<li>如果现在把 multi crop 的技术用到 SimCLR 上会发现它涨了 2.4 个点，这个涨幅还是非常明显，所以说其实如果把 multi crop 这个技术用到 BYOL 上有可能 BYOL 会比 SwAV 的效果高</li>
<li>接下来作者又对比了一些聚类的方法，对于聚类的这些方法用 multi crop 的方式提点就更多了，对于这几个方式来说都提了 4 个多点，更是非常显著</li>
<li>所以我们可以看到，如果没有这个 multi crop 的这个技术，把这四个点拿掉，其实 SwAV 的性能也就跟 MoCo v2 是差不多的，也就是说一个纯聚类的方法，或者说聚类和对比学习结合的方法其实也并没有什么优势，真正提点的是 multi crop 的技术</li>
<li>multi crop 这个技术其实非常朴实了，它其实就是一种思想，就是说全局的和这个局部的特征都要关注，所以说接下来的很多工作，也都借鉴是 multi crop 的这个技术，而不是 SwAV 这篇工作本身</li>
</ul>
<p>这里简单提一下：</p>
<p>CPC v2 其实也是融合了很多的技巧，它用了更大的模型、用了更大的图像块、做了更多方向上的预测任务，把 batch norm 换成了 layer norm，而使用了更多的数据增强，所以这一系列操作下来，CPC v2 直接就把 CPC v1 之前在 ImageNet 上 40 多的准确率一下就拔到 70 多</p>
<p>informing 其实是 cmc 的作者做的一个分析型的延伸性工作，它论文本身的名字叫 What Makes for Good Views for Contrastive Learning（我们到底选什么样的视角才能对对比学习最好？）</p>
<ul>
<li>它主要是提出了一个 InfoMin 的原则，就是最小化互信息 minimi mutual information，那乍一听觉得可能有点奇怪，因为之前大家做的都是 maximize mutual information，都是想要两个视角之间的互信息达到最大，为什么作者这里就想让它达到最小呢？</li>
<li>其实这里也不是严格意义上的最小，作者其实想说的是，他想要不多不少的互信息，如果最大化互信息以后比所需要的互信息要多，也是一种浪费，而且有可能泛化做的不好，但如果互信息比所需求的这个互信息要少，有可能达不到最优的性能，所以这个才是作者的本意，就是不能一味的最大化这个互信息，而是要不多不少刚刚好</li>
<li>然后按照 Info Min 的原则选择合适的数据增强，然后拿到合适的对比学习的视角以后，作者发现对于很多的方法都有提升，它们最后在 ImageNet 上也有73，也是相当不错的</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>其实到了第二阶段很多细节都处于统一了，比如说</p>
<ul>
<li>目标函数都是用 infoNCE 或者 infoNCE 类似的目标函数去算的</li>
<li>模型最后也都归一到用一个编码器后面加一个 projection head</li>
<li>都采用了更强的数据增强</li>
<li>都想用这个动量编码器</li>
<li>都尝试着训练的更久</li>
<li>最后在 ImageNet 上的准确度也逐渐逼近于有监督的基线模型</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-结合虚拟现实和脑机接口来探测情绪</title>
    <url>/d2dbdbbb.html</url>
    <content><![CDATA[<p>你知道高兴、愤怒的情绪这些情绪从哪里来的吗？人为什么会生气、害怕？人们常常说，黑暗使我恐惧，美食美景让我快乐，这背后的原理又是什么？</p>
<p>简单来说，情绪是对外部刺激的一种应激反馈，而情绪的产生，则是大脑处理外部信息得出的结果。而大脑是生命中最大的谜团之一，多年来为了解大脑的运作规律和处理复杂情绪的过程，神经科学家们进行了各种各样的实验。常用的一种方式，就是用EEG等大脑监控设备，来观察人暴露在不同的场景中，脑电波会产生什么样的变化。</p>
<span id="more"></span>

<p>传统的脑研究实验，会为被试展示各种各样的二维视频或者图片，希望勾起他们记忆中在特定场景所产生的情绪。而近期，德国马克斯普朗克研究所（马普所）的一个团队[1]发现，相对二维的视频照片。沉浸式的VR模拟效果更好，他们使用 VR 和 EEG 来研究人脑处理情绪的原理，并测试并证实了情绪觉醒与顶枕 α 功率之间的关联。</p>
<img src="/d2dbdbbb/1.jpg" class>

<p>该研究为了探测情感唤醒与自然刺激下的顶枕 α 功率之间的关联，科研人员招募 37 名被试，让他们在 VR 中体验沉浸式过山车场景。</p>
<img src="/d2dbdbbb/2.jpg" class>

<p>通过 EEG 脑机接口，研究人员记录被试的在体验 VR 场景的脑电波变化，并与他们的兴奋等情绪反馈进行匹配。</p>
<img src="/d2dbdbbb/3.jpg" class>

<p>根据脑电数据，该研究验证了 α 力量调节所反映的神经机制——特别是在顶枕区域——也包含了关于一个人经历沉浸式和情绪激发体验的主观情绪状态信息。验证了一个人的情绪激动的程度与 α 振荡有关，其中 α 振荡是指振荡强度越低，人脑的兴奋程度就越高。</p>
<p>人类的情绪通常是从真实的回忆、互动中产生的，因此要了解大脑的日常运作方式，则需要在尽可能真实的场景中观察脑活动。</p>
<p>传统的方法通过二维的视频或者图片刺激情绪的效果并不理想，在实验室条件下难以复制真实、发自内心的人类情感，因此取得的进展有限。相比之下，VR 体验可以唤起更多自然情感，将 VR 用于神经科学研究的优势是，它可以营造自然的环境，同时具有实验室般的可控性。利用 VR 技术科研人员可以通过逼真的场景刺激被试的真实情感，在实验中更能采集到准确的数据。</p>
<p>现有 VR 技术存在的一大限制，就是可能长时间使用可能会引起使用者眩晕、恶心，在该研究中也有一人出现不良反应而暂停实验，因此，将VR用于科学实验的安全性值得关注，除了舒适性问题外，VR 在实验场景的应用依然存在一些局限，如该研究中 VR 过山车的高度等参数难以精确设定，未来需要支持更多定制的实验系统。</p>
<p>尽管如此，在该实验展现了 VR 技术与 BCI 结合的潜力，成功从EEG信号中解码出不同程度的主观体验的情绪。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/Zh7yRM__YfXwMhT220ZyZg">为什么说VR暴露实验比传统方案更有效？</a></p>
</blockquote>
<blockquote>
<p>[1]<a href="https://www.eurekalert.org/news-releases/938381">S. M. Hofmann, F. Klotzsche, A. Mariola, V. Nikulin, A. Villringer, and M. Gaebler, “Decoding subjective emotional arousal from EEG during an immersive virtual reality experience,” eLife, vol. 10, p. e64812, Oct. 2021, doi: 10.7554/eLife.64812.</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11790">https://www.scholat.com/teamwork/showPostMessage.html?id=11790</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-对比学习论文综述-3不用负样本</title>
    <url>/df64ed12.html</url>
    <content><![CDATA[<p>其实第二阶段里讲的 SwAV 就已经有不用负样本的对比学习这个趋势了，它可以算是一个承上启下的工作，因为它也没有用负样本，它用的是聚类中心，但它毕竟还是有一个明确的对比的对象</p>
<p>接下来要讲的 BYOL 和 SimSiam 其实就是正样本自己在玩，已经没有负样本或者聚类中心这样明确的一个对比的东西去做对比了</p>
<span id="more"></span>

<hr>
<h3 id="《Boostrap-Your-Own-Latent：A-New-approach-to-Self-Supervised-Learning》"><a href="#《Boostrap-Your-Own-Latent：A-New-approach-to-Self-Supervised-Learning》" class="headerlink" title="《Boostrap Your Own Latent：A New approach to Self-Supervised Learning》"></a>《Boostrap Your Own Latent：A New approach to Self-Supervised Learning》</h3><p>BYOL 其实就是这句话的头几个字母</p>
<ul>
<li>Bootstrap 就是说如果已经有什么东西了，然后在它之上进行改造</li>
<li>latent 就是特征的意思（latent、hidden、feature、embedding 其实都是特征的意思，就是各种花里胡哨的用法而已）</li>
</ul>
<p>BYOL 的意思就是自己跟自己学，左脚踩右脚就上天了，所以说是一篇很有意思的论文</p>
<p>为什么作者很有自信说是 a new approach to self supervised learning，因为它完全没有用任何形式的负样本</p>
<p>为什么不用负样本就这么新奇、这么吸引人注意？</p>
<ul>
<li>因为在对比学习中，负样本是一个约束，如果在算目标函数的时候只有正样本，其实目的就只有一个，那就是让所有相似的物体的特征也尽可能的相似，那这个时候就有一个很明显的捷径：如果一个模型不论给它什么输入，它都返回同样的输出，这样的话，它出来的所有的特征都是一模一样的，那拿这个去算对比学习的 loss 就都是零，意思就是模型直接就躺平了，它直接用这个捷径解就能完美解决问题 loss 永远是 0 模型根本都不用学</li>
<li>只有加上负样本这个约束，就是说不光相似的物体要有相似的特征，然后不相似的物体也要有不相似的特征。这样模型才有动力去继续学，因为如果输出的所有特征都一样，那负样本的 loss 就无穷大，所以它必须想办法让正样本和负样本的 loss 都往下降，达到一个最优解</li>
<li>所以说，负样本在对比学习里是个必须的东西，它能防止模型学到捷径，很多论文里也管这个叫 model collapse 或者 learning collapse，就是模型坍塌或者学习坍塌，说白了就是什么也没学到，负样本就是为了限制这种情况的发生</li>
<li>但 BYOL 之所以神奇就是它没有用负样本，正样本自己跟自己学最后在 ImageNet 上也达到了 74.3 的 top-1 准确率，也是相当高了</li>
</ul>
<p>因为 BYOL 是 20 年 6 月份出来的，跟 SwAV 是同期的工作，所以它不用跟 SwAV 去比，那在这之前 74.3 就是最高的</p>
<p>BYOL 为什么能够做到不需要负样本？</p>
<p>下图是模型总览图</p>
<img src="/df64ed12/1.webp" class>

<p>BYOL的前向过程：</p>
<ul>
<li>一个 mini-batch 的输入 x 经过两次数据增强以后，就得到了 v 和 v’，然后图片通过编码器得到特征</li>
<li>上面这一支通过的编码器叫 fθ，下面这个通过的编码器呢叫 fε，两个编码器使用是同样的网络架构，但是它们的参数不同</li>
<li>fθ 是随着梯度更新而更新的，而这个 fε 跟 MoCo 一样是用 moving average 的形式去更新的，其实就是使用了动量编码器</li>
<li>这里得到的特征，如果是 res 50 的话就是 2048 维的一个特征</li>
<li>接下来跟 SimCLR 一样用了一个 projection head，这里叫 projector，就是通过 gθ 这个函数得到 zθ 的特征，zθ 在这里是 256 维，比之前的 128 大了一点，发现这个效果好一点</li>
<li>同样地，gε 其实跟 gθ 是一样的网络结构，但是参数不一样，也是通过动量的方式去更新的</li>
<li>之前对比学习的方法，当得到这两个特征 zθ 和 zε 以后，就像 SimCLR 一样需要让它们尽可能接近，需要达到 maximum agreement，但是 BYOL 没有这么做，它又加了新一层的一个叫 predictor 的东西 qθ，qθ 跟 gθ 的网络结构是完全一样的，也是一个 mlp，然后就得到了一个新的特征 q(zθ)，为了让这个预测跟下面的 zε 尽可能一致，就把原来的匹配问题换成了现在的预测问题</li>
<li>这个跟 SwAV 也有点像，因为 SwAV 也是把配对问题换成了预测问题，但是 SwAV 还是借助了一个聚类中心来帮助做这个预测任务的，但是 BYOL 真的是什么都没有，就是自己去预测自己，然后这个模型就学起来了</li>
<li>sg 就是 stop gradient，这里是没有梯度的，跟 MoCo 就很像，上面一支相当于是个 query 编码器，下面一支相当于是 key 的编码器，key 的编码器都是 query 编码器的动量更新，但不一样的是它的代理任务不一样，它相当于是用自己一个视角的特征去预测另外一个视角的特征，通过这种预测型的任务完成模型的训练</li>
</ul>
<p>这就是 BYOL 的训练过程，看起来相当简单，而且作者说跟别的工作一样，当训练完成以后只有这个编码器留下了，剩下所有的东西都被拿掉了，最后 yθ，也就是这个 2048 维的特征去做下游任务</p>
<ul>
<li>它训练网络的时候用的目标函数直接用的是 mean square erro（mse los）<br>因为现在是两个向量，一个是预测的 qθ(zθ)，一个是 target zε，现在是想让它们尽可能的接近，所以算一个 mse loss 就可以了</li>
<li>这个跟之前对比学习用的那些目标函数全都不一样，所以说 BYOL 虽然看起来有 SimCLR 的影子，也有 MoCo 的影子，比如说 SimCLR 的 projection head、MoCo 的动量编码器，但是它用的目标函数不一样，而且也没有用负样本，就用这种自己预测自己的方式学到了很好的特征表示</li>
<li>所以说在它放到 arxiv 之后，reddit、twitter、知乎全都引起了剧烈的讨论，因为大家都觉得很不可思议，不用负样本，模型的学习怎么能不坍塌，其实作者也觉得很神奇，所以它后面也提供了一些解释，但是它的解释比较中规中矩没有什么意思</li>
</ul>
<hr>
<h3 id="《understanding-self-supervised-and-contrasive-learning-with-“Boostrap-Your-Own-Latent”-BYOL-》"><a href="#《understanding-self-supervised-and-contrasive-learning-with-“Boostrap-Your-Own-Latent”-BYOL-》" class="headerlink" title="《understanding self-supervised and contrasive learning with “Boostrap Your Own Latent”(BYOL)》"></a>《understanding self-supervised and contrasive learning with “Boostrap Your Own Latent”(BYOL)》</h3><p>“如何去理解 BYOL”</p>
<p>这篇博客的作者其实也是看到 BYOL 之后觉得非常有意思，所以就尝试复现了一下，结果在复现的时候遗漏了一个小细节，从而导致它的模型训练不动，出现了这个模型坍塌的现象</p>
<p>作者觉得毕竟这是在 DeepMind 的工作，可信度还是非常高的，应该不是论文的问题，肯定是它们自己复现的问题，所以自己就去仔细检查了</p>
<ul>
<li>检查结果发现确实是遗漏了一个很小的细节，这个细节跟 batch norm 有关</li>
</ul>
<p>在讲这个发现之前，先来看一下 batch norm 带来了什么麻烦，因为之前没有好好说 projection head 里面具体的结构，所以先来复习一下</p>
<p>下图所示是 SimCLR 的结构图</p>
<img src="/df64ed12/2.webp" class>

<p>SimCLR 就是说一个图片进了编码器以后就得到了这个 embedding，就是特征 y（2048 维），然后把它扔给 gθ，就是一个 projection head，也就是图中右侧的 mlp</p>
<ul>
<li>这个 mlp 由一个全连接层、一个 batch norm、一个 ReLU 激活函数、一个全连接层、一个 batch norm 的结构组成</li>
<li>第一个全连接层的维度是 2048 * 2048</li>
<li>第二个全连接层的维度是 2048 * 128，就把维度降下去了，这个 128 的特征就是最后用来做对比学习的特征</li>
<li>注意：这里面有两个 batch norm 操作</li>
</ul>
<p>接下来再看一下 MoCo v2（MoCo v1 没有用 projection head），MoCo v2 的模型结构如下图所示</p>
<img src="/df64ed12/3.webp" class>

<ul>
<li>MoCo v2确实是用了projection head，就是 gθ，但是它的 gθ 里面是没有 batch norm 的，就是直接全连接层、ReLU然后又全连接层</li>
<li>第一个全连接层还是 2048 * 2048</li>
<li>第二个全连接层还是 128</li>
</ul>
<p>再来看 BYOL，模型结构如下图所示</p>
<img src="/df64ed12/4.webp" class>

<ul>
<li>gθ、gε 都是 projection head</li>
<li>qθ 是 prediction head</li>
</ul>
<p>这三个东西用的都是同样的结构，如图右侧紫色的 mlp 结构所示，这个结构里面是全连接层 + batch norm + ReLU + 全连接层 ，第二个全连接层后面没有 batch norm，但是第一个后面是有 batch norm，也就是因为这点小小的差别造成了这个发现</p>
<p>为什么呢？因为像 MoCo v2 的代码写的实在是太好了，而且又是基于 pytorch，所以这篇博客的作者就是借鉴 MoCo v2 来复现的 BYOL ，但是因为 MoCo v2 里 projection head 没有 batch norm，所以他们在复现 BYOL 的时候，这里也没有用 batch norm，所以它的 mlp 就是全连接层 + relu + 全连接层，然后模型的学习就坍塌了，然后这篇博客的作者就觉得实在是太奇怪了，所以赶紧又做了一些额外的实验，如下表所示</p>
<img src="/df64ed12/5.webp" class>

<ul>
<li>第二列指的是 projector 里到底用不用 batch norm，还是是用别的归一化方式</li>
<li>第三列指的是 prediction 里到底用不用 batch norm，还是是用别的归一化方式</li>
<li>目标函数：对于对比学习的方式来说用的是交叉熵函数，对于 BYOL 来说都用的是 L2，也就是 MSE loss</li>
<li>performance 性能其实是在一个 STL-10 的数据集上做的，不是 ImageNet，但是衡量标准还是准确度</li>
</ul>
<p>上表做了哪些实验</p>
<ul>
<li>最后一行 random 是说有一个随机初始化的残差网络，然后拿这个残差网络去抽特征，然后在这个特征上训练一个全连接层，最后的结果是 28.8，这个就是随机结果，就是根本没有学习的结果</li>
<li>第二行表示如果做的是正确的 BYOL，就是说在 projection head 和 prediction head 里头都用了 batch norm，最后的结果是 57.7，这个就是最高，也就是正确的结果</li>
<li>但其实刚开始做的实验做的是倒数第三行（no normalization），就是没有归一化，既没有在 projection head 的里头用 batch norm，也没有在 predictor 用 batch norm，最后的结果只有 28.3，跟随机的结果一模一样，也就是说模型坍塌了什么都没有学到</li>
<li>然后作者就尝试了几种变体，做了消融实验：要么在 projection head 里用 batch norm，不在 prediction 里用，要么就是在 projection 里不用，在 prediction 里用，最后发现，只要哪块放一个 batch norm，最后的结果就还行，就算 48 有点低，但至少说明模型在学习没有坍塌</li>
<li>作者这时候就强烈怀疑，肯定是 batch norm 惹的事了，正常的想法很自然，下一步就说换一个归一化式行不行，就换成 layer norm，作者就在 projection head 和 prediction head 里面都用了 layer norm，然后发现性能确实就又掉下去了，又变成 29.4，就跟随机一样了，也就是说模型又坍塌了，又什么都没学到</li>
<li>所以，作者最后总结说 BYOL 训练的时候不坍塌，肯定是跟 batch norm 有一点关系</li>
<li>那有什么关系呢？作者说现在有一个简单的结论：batch norm 这个操作是把一个 batch 里所有样本的特征拿过来算一下它们的均值方差，也就是 running mean running variance，然后用整个 batch 算来的均值和方差做归一化，这也就意味着，当在算某个正样本的 loss 时，其实也看到了其它样本的特征，也就是说这里面是有信息泄露的，MoCo 里有一个操作叫做 Shuffling BN ，也就是为了防止这种信息泄露的，博客的作者就说，因为有这种信息泄漏的存在，所以可以把这个 batch 里的其它样本想成是一种隐式的负样本</li>
<li>换句话说，当有了 batch norm 的时候，BYOL 其实并不光是正样本在自己跟自己学，它其实也在做对比，它做的对比任务就是说当前的正样本这个图片跟平均图片有什么差别，而这个平均图片就是 batch norm 产生的，还有之前很多图片的总结量，这就跟 SwAV 很像了，因为 SwAV 就是没有跟负样本去比，而是找了个聚类中心去比，而这里 batch norm 生成的平均图片，其实就相当是一种聚类中心的意思，也就这篇作者说的 mode (众数)，就是中值的意思</li>
</ul>
<p>所以说，这篇博客的作者认为 batch norm 是 BYOL 能够成功的关键，其实是做了一种隐式的对比学习，这个观点很快就被大家所接受了，因为听起来确实很合理，而且它后面做了很多实验，也全都验证了它的观点，batch norm 确实至关重要，拿掉 batch norm 以后模型就是不好训练，对超参数的设置非常的敏感，稍有不慎它就啥也不学了</p>
<p>但是 BYOL 的作者看到这个以后就急了就觉得说如果真是这样的话，如果真的要用这种方式去解释的话，BYOL 的创新性就大大降低了，因为它还是没有逃脱出对比学习的范畴，它还是找了一个东西去做对比，所以赶紧做实验看看能不能找到另外一种解释，为什么 BYOL 能够不模型坍塌</p>
<p>BYOL 的作者很快就找到了另外一种方式去解释这个现象，迅速写了一篇论文(BYOL works even without batch statistics)来做回应，它的题目上来就说 BYOL 即使在没有 batch norm 的时候照样能工作，而且它甚至把这个 even 斜体了，真的就是用来回应上面提到的那篇博客。因为 BYOL 的作者不想让大家觉得 BYOL 的成功是依赖于 batch norm，然后 BYOL 的作者做了一系列非常详细的实验看看问题到底出在哪，实验结果如下表所示</p>
<img src="/df64ed12/6.webp" class>

<ul>
<li>这个实验就是说在 encoder 编码器，就是 Res50 里到底用 batch norm、layer norm，还是什么都不用，还有在 projector 里到底用 batch norm、layer norm，还是什么都不用，或者说在 predictor 里到底用 batch norm、layer norm，还是什么都不用</li>
<li>虽然就这么一个小小的表格，但其实里面的跑的实验是相当多的，做了一个非常完整的消融实验，而且这里还和 SimCLR 去比了，因为其实 BYOL 就是基于 SimCLR 做的，它跟 SimCLR 非常像</li>
</ul>
<p>作者发现了几个现象</p>
<ul>
<li>batch norm 确实是比较关键，因为只要是没有 batch norm 的地方，SimCLR 都工作的很好，可能有一些性能下降，但是都还在学，BYOL 全都没有再学了，模型坍塌了</li>
<li>通过这个完整的消融实验，作者还发现了几个特例，正是这些特例帮助作者找到了另外一个可以解释的理由：即使当 projector 有 bn 的时候，BYOL 还是训练失败了，这个就不能解释 batch norm 很关键了，因为如果 batch norm 真的很关键，如果真的能在这个隐式负样本提供对比学习的话，训练就不应该失败</li>
<li>还有就是当编码器和 project 都没有用 batch norm 的时候，SimCLR 也失败了，因为 SimCLR 没有 predictor，所以说这里 predictor 就无所谓了，意思就是说当什么归一化都不用的时候，不光是 BYOL，SimCLR 也不行，它即使用了负样本也训练不出来，所以这就再次证明了，batch norm 不是提供了一个隐式的负样本，因为这里即使给它显式的负样本了，它还是训练不出来</li>
<li>所以这时 BYOL 的作者和原来博客的作者后来就达成了一个比较一致的结论，就是说 batch norm 跟它原来的设计初衷一样，它主要的作用就是能帮助这个模型稳定训练，它能提高模型的训练稳健性，从而不会导致模型坍塌，BYOL 的作者又把这个结论进一步延伸，然后给出来了一个可以解释的理由，如果一开始就能让模型初始化的比较好，后面的训练即使离开了 batch norm 也没有问题</li>
<li>于是作者就做了另外一个实验，就是用 group norm 和 weight standardization，group norm 就是一种归一化的方式，而 weight standardization 就是一种模型初始化的方式，这一套方法其实是 vit 的原班作者在他们之前的论文 BEiT 里提出来了，也就是现在很多人说的 ResNet v2 就是用这种方式做训练，然后换上这种初始化方式以后，BYOL 的作者发现又能训练 74 左右的 top-1 准确率了，跟原来论文里用 batch norm 的那个 74.3 的结果非常接近</li>
<li>所以作者最后再次强调说 group norm 或者 weight standardization 都没有计算批统计量，所以说这个版本的 BYOL，也就是说这个 73.9 的 BYOL 是没有跟 mini batch 里其它的样本做对比的，意思就是说没有隐式的对比，也就意味着说 BYOL 还是一个全新的方式，它就是很厉害，就是能自己跟自己学，模型就能学的很好，不需要这种假设 batch norm 提供的一个隐式的这个对比学习的项，就是说大家不要被那篇博客带跑偏了，赶紧来 follow BYOL 这个套路，这个套路没问题，别再去管负样本的事了</li>
</ul>
<p>其实这篇论文也只有4页，因为它就是用来回应那个博客，也没想着说真的发论文，目的达到了就行</p>
<hr>
<h3 id="《Exploring-Simple-Siamese-Representation-Learning》"><a href="#《Exploring-Simple-Siamese-Representation-Learning》" class="headerlink" title="《Exploring Simple Siamese Representation Learning》"></a>《Exploring Simple Siamese Representation Learning》</h3><p>就是 simple Siamese network，其实在 BYOL 放到 arxiv 上之后，就已经有很多研究者在做对对比学习的分析性工作了，因为大家发现，对比学习的成功好像是被很多很小的点堆起来的性能，比如说我们一路走来可以看到用了新的 projection head、训练的时间更长、用了更多的数据增强或者用动量编码器、用更大的 batch size，总之好像都缺一不可，对比学习的性能好像是一点一点被这么堆上去的</p>
<p>这样就不是很好，不方便分析，因为有太多点了，所以不知道从哪分析起，也不知道每个点到底带来了哪些贡献，所以凯明团队又再次出手，把整个过程化繁为简了一下，最后提出了 SimSiam</p>
<p>这个结构有多简单，就是说不需要用负样本（因为它基本上是跟 BYOL 是非常像的，所以说它不需要负样本）、不需要大的 batch size，不需要动量编码器，然后即使在这种情况下，这个 SimSiam 不仅不模型坍塌，而且还能取得很好的结果</p>
<p>具体的模型总览图如下图所示</p>
<img src="/df64ed12/7.webp" class>

<ul>
<li>之所以叫 siamese network（孪生网络）是因为一般会有两个编码器，这两个编码器一般网络结构是一样的，而且一般是要共享参数的，所以才叫孪生网络</li>
<li>整体架构是跟 BYOL 非常一样的：一个图片变成 x1、x2，然后经过过两个编码器，有一个 predictor，其实 predictor 出来的就是要去预测另外一个编码器出来的特征</li>
<li>这里跟 BYOL 唯一的不一样就是它没有用动量编码器</li>
</ul>
<p>如果我们简单看一下伪代码，如下图所示，就会发现是真的简单，整个前向过程其实就这么几行</p>
<img src="/df64ed12/8.webp" class>

<ul>
<li>D 函数就是怎么去算 loss，算的是一个 negative cosine similarities loss，说白了就是一个 MSE loss</li>
<li>至于前向过程也跟上图中的一样，得到两个视角 x1、x2 以后，先过编码器去得到特征 z1、z2，然后再通过 predictor 得到 p1、p2 的预测，因为有两个预测，所以这里也是一个对称性的 loss，就是说，既可以做从 p1 预测 z2，也可以做用 p2 预测 z1 的任务，但因为加了两次，所以说这里也要除以 2</li>
<li>l 就是最后的 loss</li>
<li>梯度回传更新网络</li>
</ul>
<p>作者还做了很多实验，比如说 batch size 对模型训练的影响、还有 batch norm 对模型训练的影响，而这些都跟 BYOL 非常像，这里就不一一展开了，最后作者得到一个结论：之所以 SimSiam 能够成功训练，不会有模型坍塌，主要是因为有 stop gradient 这个操作的存在</p>
<p>作者还提出了一个假设，而且在第五节里做了一个 hypothesis：因为有了 stop gradient 这个操作的存在，所以 SimSiam 这个结构是可以把它想象成一个EM的算法</p>
<ul>
<li>EM 算法真是无所不在，感觉很多事情最后都可以归结到 EM 算法去解释，都有点量子力学那个意思</li>
</ul>
<p>这里作者的意思是说因为有了 stop gradient 这个操作之后，这一个训练过程或者说这一套模型参数其实就被人为劈成了两份，就相当于在解决两个子问题一样，模型的更新其实也是在交替进行的，作者接下来又做了一些推导，写的非常好，推荐大家可以去看一下，其实到最后应该可以把它理解成是一个 k-means 这个聚类问题</p>
<ul>
<li>k-means其实就是分两步走的，每次先要把所有的点分配给一些聚类中心，一旦分配好了以后，再去更新这个聚类中心，然后再周而复始地去做这个操作</li>
</ul>
<p>从这个角度来说 SimSiam 又跟 SwAV 有点关系了，于是作者其实在最后还画了这么一张图如下图所示，这张图真的画的非常好，它把所有孪生网络的做法都归纳到在这里，然后做一下总结和对比</p>
<img src="/df64ed12/9.webp" class>

<ul>
<li>SimCLR：SimCLR 因为是端到端的学习，所以说两边都有梯度回传，但是它还是做的一个对比任务</li>
<li>SwAV：做的也是一个对比任务，但它并没有跟负样本去比，而是跟聚类中心去比的，那聚类中心是通过SK算法得到的</li>
<li>BYOL：BYOL 就有一个新的贡献（就是 predictor，图中已经单独画出来了），它就不是一个对比任务，变成一个预测任务了，要用左边去预测右边，同时还使用了动量编码器</li>
<li>SimSiam：整体跟 BYOL 非常像，左边其实就是一模一样，只不过右边没有用动量编码器，所以这个对比还是比较简洁明了的</li>
</ul>
<p>最后再看一下结果如下表所示，之前 BYOL 也没有看结果，鉴于 SimSiam 是一个总结性的工作，它跟之前里程碑式的工作都有对比，所以看这个表格就足够了</p>
<img src="/df64ed12/10.webp" class>

<p>在 ImageNet 上 linear classification 的结果：这里比较的都是重量级工作，比如 SimCLR、MoCo v2、BYOL</p>
<ul>
<li>从 batch size 来说，只有 MoCo v2 和 SimSiam 是可以用 256 的，其它工作都要用更大的 batch size，所以说凯明大佬的工作真的是好 follow</li>
<li>前两项工作 SimCLR 和 MoCo v2 要用负样本，但是对于 BYOL 来说就完全没有用，SwAV 用的是聚类中心</li>
<li>对于动量编码器来说，SimCLR 没有用，SimCLR v2 用了，但是 v1 没有用，MoCo v2 和 BYOL 用了，SwAV 没有用</li>
<li>总的来说，SimSiam 就是这些都没有用</li>
<li>看结果的话发现在训练 100 个 epochs 的时候，SimSiam 的结果是最好的，所以说明它学的非常快，但是随着训练的推进慢慢就不行了，涨幅比较慢，到最后也是有 71.3，但是这个时候 BYOL 已经有 74.3 这么高了（其实之前也有做过很多实验，发现动量编码器真的是很好用，也非常能提点的一个东西，所以可能这也是为什么 BYOL 能够训练的这么好）</li>
<li>当然作者在 SimSiam 这篇论文里，它只是想说把这些 trick 全拿掉照样能训练，所以说它没有用动量编码器</li>
<li>再来看 SwAV，SwAV 只有 71.8，这个应该是没有用 multi crop 的技术，所以这就跟之前讲 SwAV 的时候说的一样，就是如果不用 multi crop，SwAV 就跟 MoCo v2 差不多，还不如 MoCo v2，所以说只从分类来说，最强的方法就是 BYOL</li>
</ul>
<p>下游任务如下表所示</p>
<img src="/df64ed12/11.webp" class>

<ul>
<li>前面几个做的是物体检测，最后做的是一个实例分割，就是 cv 人必做的两个下游任务</li>
<li>这里可以看到有一个比较有趣的现象，就是说针对下游任务的 transfer 来说，MoCo v2 和 SimSiam 其实是表现最好的，BYOL 和 SwAV 也不错，但是跟 MoCo v2 和 SimSiam 比还都差了一到两个点，差距还是比较明显，所以说直到现在，如果想去尝试一些 idea，或者说尝试去做一些对比学习的工作时，还是会用 MoCo v2 当基线模型，因为真的是训练快、训练的稳，而且下游任务迁移的好</li>
</ul>
<p>当然还有一篇论文叫 Barlow Twins，是 Yann LeCun 组的一篇论文，因为宣传的很厉害，所以说很多人也都知道，那篇论文就是把目标函数给换掉了，它既不是在做对比也不是在做预测，它是生成了一个关联矩阵叫 cross correlation matrix，然后它希望这个矩阵能跟一个 identity matrix（就是对角线是 1，其它部分都是 0 的矩阵）尽量相似，其实说白了也是一样的意思，就是它希望正样本相似性尽量都逼近于 1，然后跟别的样本尽量的不相似，相似性尽可能是 0，所以说就是换了个目标函数，其它的网络结构、训练方式都大同小异，而且他们放 arxiv 的时间也比较晚，已经是 21 年的 3 月份了，这个时候对于 cv 来说，早都已经是 Vision Transformer 的时代了，所以很快呢就被淹没了</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-对比学习论文综述-4Transformer+总结</title>
    <url>/a48553aa.html</url>
    <content><![CDATA[<p>第四阶段主要是讲 Transformer 是怎么和对比学习有机结合起来的，在这个阶段主要就是简单的讲一下 MoCo v3 和 DINO 这两篇工作</p>
<span id="more"></span>

<hr>
<h3 id="《An-Empirical-Study-of-Training-Self-Supervised-Vision-Transformers》"><a href="#《An-Empirical-Study-of-Training-Self-Supervised-Vision-Transformers》" class="headerlink" title="《An Empirical Study of Training Self-Supervised Vision Transformers》"></a>《An Empirical Study of Training Self-Supervised Vision Transformers》</h3><p>MoCo v3 这篇论文虽然题目说的是自监督的 Vision Transformer，但其实 MoCo v3 只是一种架构，所以说卷积神经网络也可以用，Vision Transformer 也可以用</p>
<p>事实上 MoCo v3 怎么从 v1、v2 变到 v3，作者只用了一页去讲，大部分的篇幅都在讲自监督的训练、ViT 有多不稳定、发现了一个什么样的问题以及怎样用一个小小的改进就能让这个训练变得更稳定、效果也更好，这个写法就跟 SimCLR v2 有点像</p>
<ul>
<li>SimCLR v1 变到 v2，其实只用了半页的篇幅去写，剩下大部分的东西都是在讲这怎么做半监督学习</li>
</ul>
<p>而 MoCo v3 大部分的篇幅都是在讲怎么样去提高 ViT 训练的稳定性，所以就是为什么这篇论文的题目叫做一个实验性的 study</p>
<p>摘要还是一贯的直白，上来就写这篇论文并没有描述一个新的方法，接下来作者就说其实这篇论文就是做了一个很直接、很小的一个改动，让自监督的 ViT 训练的变得更稳定了，但是不得不写一篇论文来把这个发现告诉大家，因为自监督的训练 Vision Transformer 已经是大势所趋了，这里有很多有趣的发现，所以我们分享给大家看，所以这篇论文的影响力依旧很大，它是 ICCV 21 的一篇口头报告论文</p>
<p>在讲训练稳定性之前，先看一下 MoCo v3 的架构，因为没有模型总览图，所以直接看伪代码如下图所示</p>
<img src="/a48553aa/1.webp" class>

<ul>
<li>MoCo v3 其实就相当于是 MoCo v2 和 SimSiam 的一个合体</li>
<li>整体的框架来说，它还是有两个网络，一个是 query 编码器，一个是 key 编码器，而且 key 的编码器是动量编码器，最后的目标函数用的是对比学习的 loss，所以说从这个角度讲，它是个 MoCo v2</li>
<li>但是如果仔细看细节就会发现，query 编码器现在除了这个骨干网络之外，它还有 projection head，还有 prediction head，这个其实就是 BYOL，或者说是 SimSiam</li>
<li>而且它现在这个目标函数也用的是一个对称项，就是说它既算 query1 到 key2 的，也算这个从 query2 到 key1 的，从这个角度讲它又是 SimSiam</li>
<li>所以说，MoCo v3 就是 MoCo v2 和 SimSiam 一个很自然的一个延伸工作</li>
<li>因为 Vision Transformer 的出现，所以说作者就很想把卷积神经网络换掉换成 Vision Transformer，看看结果到底会变得如何，是不是自监督学习加上 Vision Transformer 就能取得像 nlp 那边的成功，然后就迅速试了一下，把骨干网络从一个残差网络换成了 ViT，下图展示的是一个 ViT 自监督训练的一个训练曲线</li>
</ul>
<img src="/a48553aa/2.webp" class>

<ul>
<li>作者发现当 batch size 比较小的时候其实还好，这个曲线比较平滑，比如说图中的橘黄线和蓝线在当 batch size 比较小的时候就比较平滑，不会出什么问题，这个效果也还行</li>
<li>但是当 batch size 变大了以后，作者就发现这个曲线会莫名出现这种情况：训练的时候突然准确度就掉下来一下，再训练一段时间后又掉下来一下，虽然说它每次还能很快的恢复上去，但是恢复上去就不如原来的那个准确度高了，最后这个准确度也会差很多</li>
<li>按道理来说，一般大 batch size 会得到更好的结果，但是在这里大 batch size 反而得到了更差的结果，作者就觉得这是一个问题，这个问题得解决，如果能解决训练的这个问题，很有可能就能用更大的 batch size 去训练一个更大的 Vision Transformer 从而得到更好的结果</li>
<li>在训练与分割的网络时候也会有这种情况发生，知乎上有人看到 MoCo v3 这篇论文以后也说，之前在训练别的任务的时候也遇到过类似的问题，有人也采用类似的方式解决了这个问题，有人也就没有管，所以说有的时候很小的一个问题，也可以是一个问题的很好的出发点</li>
<li>针对这个问题，MoCo v3 的作者就提出来一个小 trick，他是怎么想到这个解决方式的呢？他观察了一下训练的时候每一层回传梯度的情况，这个是比较常见的操作，一般如果网络训练的不好，而且不知道为什么的时候，一般首先就是要去查一下梯度，然后作者就发现，当每次 loss 有这种大幅的震动导致这个准确度大幅下降的时候，梯度也会有一个波峰，而这个波峰其实是发生在第一层，就是在做 patch projection 时候</li>
<li>这个 patch projection 是什么呢？如果读过 Vision Transformer 的论文就知道，这个其实是属于模型的第一步，属于 tokenization 的那个阶段————就是如何把一个图片把打成 patch，然后给它一个特征。</li>
<li>这一步是怎么做的呢？其实就是一个可以训练的全连接层，能训练当然是好事，但是如果每次梯度都不正常，那还不如不训练，所以说作者就简单的尝试一下，如果不训练，直接冻住结果会怎样，所以就随机初始化了一个 patch projection 层，然后把它冻住，就是整个训练过程中都不变，结果发现问题就解决了，而且很神奇的是这个 trick 不光是对 MoCo v3 有用，它对 BYOL 也有用，如果用 BYOL 那套框架，把残差网络换成 Vision Transformer，刚开始就把 patch projection 层冻住，一样能获得更平滑的训练曲线，获得更好的训练结果</li>
</ul>
<p>在这篇论文之后也有很多研究者意识到了第一步 tokenization 阶段的重要性，所以也有很多后续的工作去改进</p>
<p>第一阶段说白了，如果不想改 Transformer 这个模型本身，因为它又简单扩展性越好，所以说如果中间这一块我们不动，那能改的除了开始就是结尾，那开始就是 tokenization 阶段，结尾就是改目标函数</p>
<hr>
<h3 id="《Emerging-Properties-in-Self-Supervised-Vision-Transformers》"><a href="#《Emerging-Properties-in-Self-Supervised-Vision-Transformers》" class="headerlink" title="《Emerging Properties in Self-Supervised Vision Transformers》"></a>《Emerging Properties in Self-Supervised Vision Transformers》</h3><p>DINO 这篇论文也说的是一种自监督训练 Vision Transformer 的方式，但这篇文章主要的卖点是：Vision Transformer 在自监督训练的情况下会有一些非常有趣的特性，它把它效果最炸裂的这些图片放到了图一如下图所示，放到了文章开头</p>
<img src="/a48553aa/3.webp" class>

<ul>
<li>这个图的意思就是说一个完全不用任何标签信息训练出来的 Vision Transformer，如果把它的自注意力图拿出来进行可视化的话，会发现它能非常准确的抓住每个物体的轮廓，这个效果甚至能直接媲美对这物体做分割，比如说图中像牙刷还有长颈鹿，这些物体的边界抠的非常的精准，甚至比很多做无监督分割的工作都要做的好</li>
</ul>
<p>DINO 具体操作如下图所示</p>
<img src="/a48553aa/4.webp" class>

<ul>
<li>其实它的方法倒不是说多新，跟之前的一系列对比学习的工作都非常的相似，就是换了个方式来讲故事，至于 DINO 这个名字，来自于它的题目 self distillation with no labels，就是 distillation 和 no label</li>
<li>整个框架叫一个蒸馏的框架，至于为什么是自蒸馏，其实就跟 BYOL 一样，因为自己跟自己学或者自己预测自己，所以就是自蒸瘤</li>
<li>对于 MoCo 来说，左边的网络叫做 query 编码器，右边叫做 key 编码器，对于 BYOL 来说，左边叫做 online network，右边叫做 target network，DINO 其实就是延续的 BYOL，它只不过是换了个名字，把左边叫成 student 网络，右边叫成 teacher 网络</li>
<li>因为 student 要预测 teacher，所以可以把 teacher 网络的输出想成是 ground truth</li>
<li>至于具体的前向过程，跟 BYOL 或者跟 SimSiam 都是非常类似的，同样就是当有同一个图片的两个视角以后，用 x1、x2 通过编码器得到了两个特征，这个编码器自然也是有 projection head、prediction head</li>
<li>为了避免模型坍塌，DINO 做了另外一个额外的操作，叫做 centering，这个操作就是把整个 batch 里的样本都算一个均值，然后减掉这个均值，其实就算是 centering，这个就很像是 BYOL 对于 batch norm 的讨论，因为 batch norm 也是对整个 batch 里的样本做了一个均值和方差</li>
<li>最后有一个 stop gradient 的操作然后用 p1 去预测 p2</li>
</ul>
<p>再看伪代码如下图所示</p>
<img src="/a48553aa/5.webp" class>

<p>它真的跟 MoCo v3 实在是太像了，尤其是前像过程不就是一模一样吗，就只有目标函数稍微有点不一样，这里多了一个 centering 的操作，防止模型坍塌</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>MoCo v3 和 DINO 这两篇工作，从方法和模型角度上来说，其实它们跟第三阶段基本是一模一样的，主要就是融合了 Vision Transformer</p>
<p>到这里就把过去两三年比较有代表性的对比学习的工作都串了一遍，这里我们就再画一张大图如下图所示，整体再快速的把这些工作再过一遍，看一下它们之间的联系与不同</p>
<img src="/a48553aa/6.webp" class>

<ul>
<li><p>从最开始的 Inst Disc 开始，它提出了个体判别的任务，而且它提出用一个 memory bank 的外部数据结构去存储负样本，从而能达到一个又大又一致的字典去做对比学习</p>
</li>
<li><p>如果不用外部结构的话，另外一条路就是端到端的学习，也就是 Inva Spread 这篇论文做的，它就只用了一个编码器，从而可以端到端的学习，但因为受限于 batch size 太小，所以说它的性能不够好</p>
</li>
<li><p>CPC v1 这篇论文提出了 infoNCE 这个 loss，而且 CPC v1 是一个预测型的代理任务，不仅可以做图像，还可以去做音频、视频、文字和加强学习，是一个非常全能的结构</p>
</li>
<li><p>最后还有 CMC 这个工作，它就把两个视角的任务扩展到了多个视角，从而给接下来多视角或者多模态的这个对比学习打下了铺垫</p>
</li>
<li><p>另外还有一篇论文 deep cluster 并没有讲，它是基于聚类学习的，当时还没有用对比学习</p>
</li>
<li><p>接下来就进入了第二阶段，第二阶段主要是 MoCo v1 开始，它算是 Inst Disc 的一个延伸性工作，它把 memory bank 变成了一个队列，然后把动量更新特征，变成了动量更新编码器，从而能预训练一个很好的模型</p>
</li>
<li><p>MoCo 也是第一个能在很多视觉的下游任务上，让一个无监督预训练的模型比有监督预训练模型表现好的方法，它属于使用外部数据结构的</p>
</li>
<li><p>自然端到端的学习肯定也有延伸性的工作，也就是 SimCLR v1，SimCLR v1 跟 Inva Spread 方法是很像的，但是它用了很多的技术，比如说加大了 batch size，用了更多的数据增强，加了一个 projection head，训练的更长时间，总之所有的这些技术堆起来让 SimCLR 在 ImageNet 取得了非常好的的结果</p>
</li>
<li><p>然后 CPC v1 把这些技术也全都拿来用了一遍，CPC v2 就直接比 CPC v1 在 ImageNet 上高了 30 多个点</p>
</li>
<li><p>最后 CMC 把这些都分析一下，提出了一个 info Min 的这个原则，它说两个样本或者两个视角之间的互信息，要不多不少才是最好的</p>
</li>
<li><p>然后 MoCo 的作者看到 SimCLR 用的这些技术确实都很管用，所以就把这些即插即用的技术拿过来用在 MoCo 上，就有了 MoCo v2，MoCo v2 的效果就比 MoCo v1 和 SimCLR v1 都要好</p>
</li>
<li><p>然后 SimCLR 的作者也对模型进行了一些改动，得到了 SimCLR v2，但 SimCLR v2 主要是去做半监督学习的</p>
</li>
<li><p>之前提 deep cluster 主要就是为了引出 SwAV，SwAV 就是把聚类学习和对比学习结合起来的一个工作，也取得了不错的结果，但它这个不错的结果主要是来自于它提出的 multi crop 的技术，如果没有这个技术，它其实跟 SimCLR 或者 MoCo v2 的结果都是差不多的</p>
</li>
<li><p>第三阶段就来到了 BYOL 这个方法，因为处理负样本实在是太过麻烦，所以 BYOL 就说能不能不要负样本，能不能不去跟负样本做对比，结果它们发现还真行，就自己跟自己学，把一个对比任务变成一个预测任务就可以了，而且目标函数也很简单，不再使用 info NCE，而是用一个简单的 mse loss 就可以训练出来</p>
</li>
<li><p>但是大家都觉得很不可思议，所以立马就有一篇这个博文出来，它们就假设说 BYOL 能够工作主要是因为有 batch norm，这个 batch norm 提供了一种隐式的负样本，所以 BYOL 能够正常训练而不会模型坍塌</p>
</li>
<li><p>但是 BYOL 的作者很快就又发了另外一篇论文叫 BYOL v2，通过做了一系列实验以后，最后说 batch norm 只是帮助了模型的训练，如果能用另外一种方式能提供一个更好的模型初始化，BYOL 不需要 batch norm 提供的那些 batch 的统计量照样能工作，就把之前博客里提出来假设给打破了，但它们提出的其实也只是另外一个新的假设</p>
</li>
<li><p>紧跟着 BYOL，SimSiam 就出来了，SimSiam 就把之前的工作都总结了一下，因为它觉得之前的这些论文都在一点一点往上堆技术，那如果堆的太多了就不好分析了，这个领域也就不好再推进下去了，所以 SimSiam 就化繁为简，又提出来一个很简单的孪生网络的学习方法，它既不需要用大的 batch size，也不需要用动量编码器，也不需要负样本，然后照样能取得不错的结果，SimSiam 提出的假设就是说 stop gradient 这个操作是至关重要的，因为有这个操作的存在，所以 SimSiam 可以看成是一种 EM 算法，通过逐步更新的方式避免模型坍塌</p>
</li>
<li><p>另外还有一篇工作叫 barlow twins，它主要就是更换了一个目标函数，把之前大家做的这种对比或者预测变成了两个矩阵之间去比相似性，因为它已经是 21 年 3 月提出来的，所以很快就淹没在了 Vision Transformer 这波洪流之中</p>
</li>
<li><p>最后第四阶段就来到了 Vision Transformer，主要讲的两个工作就是 MoCo v3 和 DINO，其实都是把骨干网络从残差换成了 ViT，主要学习的方法其实是没有改变的</p>
</li>
<li><p>但是换成 Vision Transformer 以后，面临的问题都是训练不稳定或者不好训练，所以他们就提出了各自的方法：MoCo v3 提出来把 patch projection layer 冻住，DINO 就提出把 teacher 网络的输出先做一下归一化，做一下 centering。这 2 种方式都能有效的提高模型训练的稳健性，防止模型坍塌，让 Vision Transformer 用自监督的方式也能训练的很好</p>
</li>
<li><p>到此，又把所有的这些工作快速的串了一遍，现在对比学习还是一个很火的方向，虽然说可能没有 Vision Transformer 那么火，而且尤其是 MAE 火爆了以后，大家都去尝试掩码学习，而不是去尝试对比学习了，所以说对比学习又从一个火爆发展期变成了一个发展潜伏期</p>
</li>
<li><p>但是我对它的前途还是非常看好的，毕竟多模态的对比学习还是一个主流，CLIP 的效果就很好，而且在多模态里面，图像和文本对之间的对比学习 loss 还是一个标准的目标函数，基本上所有的工作都有在用，而且对比学习它属于一个想法而不是具体的一个工作，它在几十年之前就已经提出来了，所以接下来我们应该还是会看到很多对比学习的工作的，很期待对比学习跟其它方法的结合</p>
</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-对比学习论文综述-总结再整理</title>
    <url>/f08f0e17.html</url>
    <content><![CDATA[<p>今天分享一下李沐大神团队带来的对比学习串烧。该 talking 讲述的是对比学习在计算机视觉领域的发展历程。</p>
<iframe src="//player.bilibili.com/player.html?aid=680170801&bvid=BV19S4y1M7hm&cid=472587940&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<img src="/f08f0e17/1.jpg" class>

<hr>
<h3 id="第一阶段：百花齐放"><a href="#第一阶段：百花齐放" class="headerlink" title="第一阶段：百花齐放"></a>第一阶段：百花齐放</h3><p>方法、模型都没有统一，目标函数，代理任务也没有统一，所以说是一个百花齐放的年代。</p>
<h4 id="InstDise"><a href="#InstDise" class="headerlink" title="InstDise"></a>InstDise</h4><p><a href="https://arxiv.org/pdf/1805.01978.pdf">InstDise 论文传送门</a></p>
<img src="/f08f0e17/2.jpg" class>

<p>举个例子，将一张豹子的图片输入到一个有监督数据分类的分类器中，与其相似度较高的图片都是美洲虎或者猎豹，倒不是因为他们之间的语义相似性很高，主要是因为他们的图片之间实在太相似了。因此，作者将这种有监督的任务发挥到极致，提出了个体判别任务，作者将每一张图片都看作是一个类别，希望模型可以学习图片的表征，从而把各种图片都区分出来。</p>
<img src="/f08f0e17/3.jpg" class>

<p>作者的方法就是使用一个卷积神经网络，将图片作为输入，获得图片的低纬向量表征，让这些向量可以表示这些图片，因为作者将每一个图片都视为是单独的类别，因此，向量的表征应该尽可能的分散开来。</p>
<p>训练这个神经网络的方法是对比学习，所以需要有正样本，需要有负样本。正样本就是图像本身，可能经过数据增强，负样本就是数据集中其余的所有图片，该文章使用一个 memory bank 存储这些负样本，imagenet 中有 128w 的数据，意味着 memory bank 有 128w 行，因为负样本太多了，如果使用较高的维度表示图片的话，对于负样本的存储代价过高，因此作者让向量维度为 128 维。</p>
<p>让我们简单的走一下这个前向传播的过程，假设模型的 batchsize 是 256，有 256 张图片进入 CNN 网络，将 256 张图片编码为 128 维的向量。因为 batchsize 是 256，因此有 256 个正样本。负样本来自 memory bank，每次从 memory bank 中随机采样出 4096 个负数样本，利用 infoNCE loss 去更新 CNN 的参数。本次更新结束后，会将 CNN 编码得到的向量替换掉 memory bank 中原有的存储。就这样循环往复的更新 CNN 和 memory bank，最后让模型收敛，就训练好一个 CNN encoder 了。</p>
<p>InstDise 提出了个体判别这个代理任务，而且用这个代理任务和 nce loss 去做对比学习取得了不错的无监督表征学习的结果，同时提出了用别的结构存储这些大量的负样本，以及如何进行动量的更新，为后续的对比学习的工作产生了推进的作用。</p>
<hr>
<h4 id="InvaSpread"><a href="#InvaSpread" class="headerlink" title="InvaSpread"></a>InvaSpread</h4><p><a href="https://arxiv.org/pdf/1904.03436.pdf">InvaSpread 论文传送门</a></p>
<p>可以理解为是 SimeCLR 的前身。InvaSpread 并没有用额外的数据结构存储大量的负样本，他就是用 mini batch 中的数据作为负样本，而且使用一个编码器进行端到端的学习。</p>
<img src="/f08f0e17/4.jpg" class>

<p>该工作的思路就是对比学习。相同的图片所提取的特征应该比较类似，不同图片所提取的特征应该不类似。</p>
<p>该文章的代理任务也是实体判别任务，这里着重讲一下该文章中正例和负例的选择。</p>
<img src="/f08f0e17/5.jpg" class>

<p>该文章设置的 batchsize 是 256。首先利用数据增广，将每个图片增广一次，也就是将 256 张图片变为 512 个图片了。之后将 512 张图片通过 CNN 编码为向量，并使用一个全连接层将数据的维度降低。之后将图片 xi 和其经过增广后的图片 xi’ 作为正样本，其余的 512-2 张图片都认为是负样本。所以总计有 256 个正例，有 2×(256-1) 张负例。之后让正例之间的距离拉近，让正例与负例之间的距离拉远。</p>
<p>该文章的思路和 SimCLR 的思路差不多，都设计用 batch 中的数据作为正例和负例，但是该文章取得的效果没有 SimCLR 的效果那般炸裂。主要是因为本文所选取的字典长度不够大，batchsize 仅为 256，本文也没有设计 SimCLR 那种投影函数和多样的数据增广方法，因此本文取得的效果不如 SimCLR 那么好。</p>
<p>以上两篇工作都是使用实例检测作为代理任务的，接下来介绍的这篇文章是利用其他代理任务进行对比学习的。</p>
<hr>
<h4 id="CPC"><a href="#CPC" class="headerlink" title="CPC"></a>CPC</h4><p><a href="https://arxiv.org/pdf/1807.03748.pdf">CPC 论文传送门</a></p>
<img src="/f08f0e17/6.jpg" class>

<p>该模型是一个普适任务的模型，可以将音频，视频，文本等序列作为输入，利用生成的方式进行对比学习。该模型将序列的一部分输入到一个 encoder genc 中得到对应的向量表征，再将这些向量表征输入到一个自回归器 gar 中，从而得到对序列的预测序列。作者认为一个好的 encoder 是可以编码出序列的特征，并且可以通过自回归模型得到未来的预测。这个过程是如何应用对比学习的呢？</p>
<p>作者将真正的未来序列放入到 encoder genc 中，将得到的嵌入表示作为正例，将其他的序列作为负例，进行对比学习的训练。</p>
<p>CPC 利用预测的特征进行对比学习，这样的方法可以用在各种以序列为输入的任务上，可以用在音频、视频、文本、以及图片的 patch 序列中，都可以使用这种生成的任务。</p>
<hr>
<h4 id="CMC"><a href="#CMC" class="headerlink" title="CMC"></a>CMC</h4><p>在 CPC 利用预测的部分做对比学习后，CMC 使用了更为广泛的负例产生的机制，进行学习。</p>
<p><a href="https://arxiv.org/pdf/1906.05849.pdf">CMC 论文传送门</a></p>
<img src="/f08f0e17/7.jpg" class>

<p>CMC 定义正负样本的方式：CMC 使用的数据集是 NYU RGBD 数据集，该数据集包含一张图片的四种 view 数据增强结果。该文章将多 view 作为正例，将其他图片以及其他图片的 views 作为负例子，进行训练。</p>
<p>CMC 的成功，让我们认识到对比学习可以如此的灵活，Open AI 团队的工作 CLIP 将图片-文本对作为输入，将互相匹配的图像-文本对作为正例，将不匹配的作为负例。同时 CMC 的原班人马利用对比学习做知识蒸馏，他们认为相同的样本在不同的编码器下得到的结果应该尽可能的相似，因此设计的 teacher 和 student 编码得到的相同图片的向量互为正例，不同图片得到的输出作为负例，利用对比学习的思路进行知识蒸馏。</p>
<p>但是问题在于 multi view 的工作可能需要多个编码器进行编码，训练代价可能有点高。比如 CLIP，就是用大型的语言编码器 BERT 对语言模型进行编码，用视觉模型 VIT 对视觉信息进行编码。</p>
<p>第一阶段介绍以上四篇工作，可以看到以上的工作代理任务不尽相同，其中有个体判别，有预测未来，还有多视角多模态。使用的目标函数也不尽相同，有 NCE，infoNCE 以及其变体。使用的模型也可以是不同的，比如 InvaSpread 使用的是相同的编码器对 key 和 query 进行编码，CMC 对 key 和 query 使用的是不同的编码，是百花齐放的。</p>
<hr>
<h3 id="第二阶段：MOCO和simCLR双雄"><a href="#第二阶段：MOCO和simCLR双雄" class="headerlink" title="第二阶段：MOCO和simCLR双雄"></a>第二阶段：MOCO和simCLR双雄</h3><h4 id="MOCO-v1"><a href="#MOCO-v1" class="headerlink" title="MOCO v1"></a>MOCO v1</h4><p><a href="https://arxiv.org/pdf/1911.05722.pdf">MOCO v1 论文传送门</a></p>
<p>主要贡献就是把之前对比学习的一些方法归纳为一个字典查询问题。提出了一个队列，一个动量编码器，从而形成一个又大又一致的字典，帮助更好的进行对比学习。</p>
<img src="/f08f0e17/8.jpg" class>

<p>MOCO 和 InstDise 有很多类似的地方，但是 MOCO 对 InstDise 的改进可以说是简单又有效，其提出用队列替换 memory bank 以及提出了动量更新的方式，对效果有显著的提升，同时对后续工作也产生了深远的影响。</p>
<hr>
<h4 id="simCLR-v1"><a href="#simCLR-v1" class="headerlink" title="simCLR v1"></a>simCLR v1</h4><p><a href="https://arxiv.org/pdf/2002.05709.pdf">simCLR v1 论文传送门</a></p>
<img src="/f08f0e17/9.jpg" class>

<p>假如有一个 minibatch 的图片，对整个 minibatch 的所有图片做数据增强，对图片 x 做不同的数据增强就会得到 xi 和 xj。同一个图片延申得到的两个图片就是正样本，比如 batchsize 是 n 的话，那么正样本就是 n，这个 batchsize 剩下的所有的样本以及其经过数据增强后得到的都是负样本，也就是 2(n-1)。有了正负样本之后，对其进行编码，通过一个编码器 f(·) 得到正负样本的编码结果 h。simCLR 的创新点就是在得到数据的编码之后在后面加了一个编码层 g(·) 函数，就是一个 MLP 层，得到较低维度的特征 zi 和 zj，用其进行对比学习，拉近正例之间的距离，拉远负例之间的距离。但是需要注意的一点就是投影函数仅仅在训练的时候才使用，在测试的时候是不使用的，测试的时候仅仅使用编码器 f(·)。加上投影函数的目的也仅仅是想让模型训练的更好。</p>
<p>SimCLR 和 InvaSpread 非常接近，不同之处在于：</p>
<ol>
<li>SimCLR 使用了更多的数据增强</li>
<li>加入了投影的 g(·) 函数</li>
<li>就是 SimCLR 用了更大的 batchsize，且训练的时间更久</li>
</ol>
<img src="/f08f0e17/10.jpg" class>

<p>SimCLR 使用了以上的数据增强的方式</p>
<img src="/f08f0e17/11.jpg" class>

<p>同时对各种数据增强方式进行了详细的消融实验</p>
<img src="/f08f0e17/12.jpg" class>

<p>作者还对这个投影层做了一些实验，可以看到使用非线性变化的效果是十分显著的，同时对于对比学习维度变化，似乎并不会对效果产生影响。</p>
<hr>
<h4 id="MOCO-v2"><a href="#MOCO-v2" class="headerlink" title="MOCO v2"></a>MOCO v2</h4><p><a href="https://arxiv.org/pdf/2003.04297.pdf">MOCO v2 论文传送门</a></p>
<img src="/f08f0e17/13.jpg" class>

<img src="/f08f0e17/14.jpg" class>

<p>MOCO v2 相当于是把 SimCLR 中值得借鉴的地方拿来借鉴。</p>
<p>比如其中 MLP 的投影层，更多的数据增强方式，cosine learning rate schedule，以及更多的迭代 epoch。其中 supervised 是 backbone 在有监督训练中进行训练的结果。在加入了 SimCLR 的一些改进点后，确实取得了模型性能的进步。</p>
<img src="/f08f0e17/15.jpg" class>

<p>作者对比了 MOCO v2 和 SimCLR 在相同的 epoch 和 batch 下的效果对比，在较小的 batch 和 epoch 下，MOCO v2 取得了较好的效果，在较大的 batch 和 epoch 下，也取得了较好的效果。</p>
<img src="/f08f0e17/16.jpg" class>

<p>作者将 MOCO v2 和 SimCLR 的算力作对比，发现 SimCLR 在 batch 较少的情况下无法发挥效果，在 batch 多的情况下才可以出效果，但是算力要求太高了。所以 MOCO 是一个对于计算资源要求不是很高，但是却很有效的模型。</p>
<hr>
<h4 id="SimCLR-v2"><a href="#SimCLR-v2" class="headerlink" title="SimCLR v2"></a>SimCLR v2</h4><p><a href="https://arxiv.org/pdf/2006.10029.pdf">SimCLR v2 论文传送门</a></p>
<img src="/f08f0e17/17.jpg" class>

<p>SimCLR v2 文章提出了一套用自监督网络作半监督训练的流程，该流程是用大网络（SimCLR v2）作自监督的预训练，预训练部分是没有特定下游任务的，因此不具备下游任务知识；之后使用少部分有标注的数据对模型进行微调，从而让模型学习下游任务的特定知识；让微调的模型作为 teacher 模型，为更多的数据打伪标签，从而实现自学习。</p>
<p>SimCLR v1 是如何升级到 SimCLR v2 的呢？</p>
<ol>
<li>如果使用更大的模型，则无监督训练就会训练的更好，所以 SimCLR v2 使用了 ResNet-152 并且使用了 selective kernels，从而让骨干网络更加强悍</li>
<li>原来的非线性投影层是十分有效的，那么更深的非线性层会不会更加有效呢？于是作者尝试使用 2 层，3 层，最后发现 2 层的效果是最好的</li>
<li>作者尝试了 MOCO 的动量编码器，发现效果是有提升的，但是提升的不是非常显著，大概是一个百分点，原因是 SimCLR v2 已经有很大的 batchsize 了，所以不需要太多的动量以及队列的负样本了</li>
</ol>
<hr>
<h4 id="SwAV"><a href="#SwAV" class="headerlink" title="SwAV"></a>SwAV</h4><p><a href="https://arxiv.org/pdf/2006.09882.pdf">SwAV 论文传送门</a></p>
<img src="/f08f0e17/18.jpg" class>

<p>以往的基于对比学习的方法都是将一个实例 x 通过两次数据增强变为 x1 和 x2，之后利用编码器对其进行编码，从而得到嵌入向量 z1 和 z2，之后使用对比学习的 loss 更新这个 encoder。</p>
<p>即使以往的工作是非常有效并且简洁的，但是因为负样本太多了，从而造成资源的浪费，即使是 MOCO 这样用近似的方式用 6w 个负样本，但是总共还是有 128w 个负样本的，所以 SwAV 的作者去想，能不能不做近似呢？可不可以使用先验信息，不去和大量的负样本对比，而是和一些更加简洁的东西去比呢？所以 SwAV 的作者想，可以和聚类的中心进行对比，这个聚类中心就是 C ，维度是 3000 × 向量维度，3000 表示聚类中心的数量。</p>
<p>前向过程依旧是一个样例 x 经过两个数据增强转化为 x1 和 x2，之后经过编码器得到 z1 和 z2，让 z1 和 z2 和聚类中心 C 进行聚类，从而得到 ground truth 的标签 Q1 和 Q2，模型让 z1 和 C 预测 Q2，让 z2 和 C 预测 Q1。通过这种交叉预测的方式对模型进行更新。</p>
<p>SwAV 的优势在于：</p>
<ol>
<li>如果是和负例进行对比的话，需要和成千上万个负例进行对比，即使是 MOCO 中 6w 个负例，也只是一个近似的值，但是聚类的话，就仅仅需要和 3000 个聚类核心即可</li>
<li>这些聚类中心是有含义的，而如果像之前一样用负样本进行对比学习的话，有的负样本不均衡，有的还可能是正样本，不如聚类中心有效</li>
</ol>
<img src="/f08f0e17/19.jpg" class>

<p>第二个贡献就是 multi-crop 的思想，以往的对比学习方法都是在一张 256 × 256 的图片上用两个 224 × 224 的 crop 求两个正样本，但是因为 crop 过大了，所选取的 crop 都是基于全局特征的。但是可能很多局部特征才是非常有价值的，SwAV 使用了一种 multi-crop 的思路进行操作，即选择了两个 160 × 160 的 crop 去搞定全局特征，选择 4 个 96 × 96 的 crop 去搞定局部特征。这样在计算量变化不大的情况下，可以获取更多的正样本。</p>
<img src="/f08f0e17/20.jpg" class>

<p>到了第二阶段，其实很多细节都趋于统一了，比如目标函数都是使用 infoNCE，模型都归一为用一个 encoder + projection head 了，大家都采用了一个更强的数据增强，都想用一个动量编码器，也都尝试训练更久。</p>
<hr>
<h3 id="第三阶段：不用负样本的对比学习"><a href="#第三阶段：不用负样本的对比学习" class="headerlink" title="第三阶段：不用负样本的对比学习"></a>第三阶段：不用负样本的对比学习</h3><p>其实SwAV已经是不用负样本了，但是他还是和一个聚类的中心这样明确的对比对象进行比较，一下介绍的 BYOL 和 SimSiam 就是正样本自己在和自己玩，已经没有正样本，或者聚类中心这样明确的对比对象了。</p>
<h4 id="BYOL"><a href="#BYOL" class="headerlink" title="BYOL"></a>BYOL</h4><p><a href="https://arxiv.org/pdf/2006.07733.pdf">BYOL 论文传送门</a></p>
<p>其实之前使用负样本的学习方法相当于给模型提供一个约束。如果模型的输入只有正样本，那么模型需要让正样本之间的距离尽量的缩小，那么模型可能会想到一个捷径从而很好的解决这个问题，就是模型直接对所有样本的数据都是一致的，这样所有正样本之间的距离无限接近，但是模型这样躺平是学习不到实例的特征的，是无效的。因此添加了负样本对模型造成一个约束，就是让正样本之间的距离接近，让负样本之间的距离拉远，这样可以对模型进行约束，不让模型躺平，所以负样本在模型中是一个必须的东西，可以防止模型躺平，学到这个捷径解。但是 BYOL 的神奇之处在于模型没有使用负样本，仅仅是模型自己和自己去学，但是也实现了很不错的效果。</p>
<img src="/f08f0e17/21.jpg" class>

<p>让我们看看 BYOL 的前向过程，一个实例 x 经过两次数据增强得到 v 和 v’，之后经过两个编码器 fθ 和 fξ，得到啷个嵌入向量 yθ 和 y’ξ ，其中两个编码器的模型架构一样，但是参数并不相同，fξ 通过动量更新，而不是反向传播更新。得到的向量再经过两个投影层 gθ 和 gξ，同样的两个投影层也是架构一样，但是参数不一致，前者是通过梯度下降进行更新，后者是通过动量更新，得到两个嵌入向量 zθ 和 z’ξ。之后将 zθ 输入到一个预测层 qθ 中，得到 qθ(zθ)，让 qθ(zθ) 和 z’ξ 无限接近，使用 mean squared error 进行参数更新，利用正样本对正样本的预测，实现模型的学习。</p>
<hr>
<h4 id="Siamese"><a href="#Siamese" class="headerlink" title="Siamese"></a>Siamese</h4><p><a href="https://arxiv.org/pdf/2011.10566.pdf">Siamese 论文传送门</a></p>
<p>Siamese 不需要用负样本，不需要大的 batchsize，不需要动量编码器，即使在这种条件下，Siamese 不仅没有模型谈谈，反而取得了很好的模型效果。</p>
<img src="/f08f0e17/22.jpg" class>

<img src="/f08f0e17/23.jpg" class>

<p>前向过程是一个实例 x 经过数据增强变为 x1 和 x2，之后经过孪生的 encoder f，得到嵌入 z1 和 z2，之后经过预测层得到 p1 和 p2，之后让 p1 预测 z2，用 p2 去预测 z1，进行模型的训练。</p>
<img src="/f08f0e17/24.jpg" class>

<p>对比了不同的基于孪生网络的学习例子。SimCLR 使用的是端到端的训练，两个 encoder，SwAV 是和聚类中心进行对比的，BYOL 是一个预测任务，其使用的是动量编码器，SimSiam 也是预测任务，但是使用的是 stop gradiant 的方式进行预测的。</p>
<hr>
<h3 id="第四阶段：transformer"><a href="#第四阶段：transformer" class="headerlink" title="第四阶段：transformer"></a>第四阶段：transformer</h3><p>在 vision transformer 之后，因为其大大提升了 encoder 的效果，所以很多对比学习任务打算使用 vision transformer 作为 backbone 进行对比学习，涌现出了两篇工作，分别是 MOCO v3 和 DINO。</p>
<h4 id="MOCO-V3"><a href="#MOCO-V3" class="headerlink" title="MOCO V3"></a>MOCO V3</h4><p><a href="https://arxiv.org/pdf/2104.02057.pdf">MOCO V3 论文传送门</a></p>
<img src="/f08f0e17/25.jpg" class>

<p>MOCO v3 有点像 MOCO v2 和 SimSiam 的结合。使用对比学习，还有对称的 loss。</p>
<img src="/f08f0e17/26.jpg" class>

<p>作者发现当把 backbone 从 ResNET 换为 VIT 后，虽然较小的 batch 效果还可以，但是一旦 batch 变大，模型就出现了不稳定的情况。</p>
<p>作者观察了一下模型梯度回传时候的梯度情况。当每次 loss 有大幅的震动，导致准确度大幅下降的时候，梯度也会有一个波峰，波峰发生在第一层，在作 patch projection 的时候，因为这一层经常出现问题，所以作者尝试将这一层 fix 住，之后再进行训练，得到了很平滑的 loss 曲线。</p>
<hr>
<h4 id="DINO"><a href="#DINO" class="headerlink" title="DINO"></a>DINO</h4><p><a href="https://arxiv.org/pdf/2104.14294.pdf">DINO 论文传送门</a></p>
<img src="/f08f0e17/27.jpg" class>

<p>为了避免模型坍塌，其在 teacher 中使用了一个 centering 操作，即对 batch 求均值，之后让 batch 中的所有实例减去这个均值，对 batch 中的样本求归一化的操作。</p>
<img src="/f08f0e17/28.jpg" class>

<img src="/f08f0e17/29.jpg" class>

<p>最后就是整体的过一遍。</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/452087382">https://zhuanlan.zhihu.com/p/452087382</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>跟李沐学AI-读论文(PART III)</title>
    <url>/5d0f6484.html</url>
    <content><![CDATA[<p>更多论文请见：<a href="https://github.com/mli/paper-reading">https://github.com/mli/paper-reading</a></p>
<hr>
<h3 id="DETR-论文精读-2022-06-10"><a href="#DETR-论文精读-2022-06-10" class="headerlink" title="DETR 论文精读 (2022-06-10)"></a>DETR 论文精读 (2022-06-10)</h3><iframe src="//player.bilibili.com/player.html?aid=596977764&bvid=BV1GB4y1X72R&cid=731507888&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<h3 id="Zero-论文精读-2022-06-17"><a href="#Zero-论文精读-2022-06-17" class="headerlink" title="Zero 论文精读 (2022-06-17)"></a>Zero 论文精读 (2022-06-17)</h3><iframe src="//player.bilibili.com/player.html?aid=257146056&bvid=BV1tY411g7ZT&cid=737409803&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="DALL·E-2-2022-07-08"><a href="#DALL·E-2-2022-07-08" class="headerlink" title="DALL·E 2 (2022-07-08)"></a>DALL·E 2 (2022-07-08)</h3><iframe src="//player.bilibili.com/player.html?aid=770625648&bvid=BV17r4y1u77B&cid=766807720&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="ViLT-论文精读-2022-07-29"><a href="#ViLT-论文精读-2022-07-29" class="headerlink" title="ViLT 论文精读 (2022-07-29)"></a>ViLT 论文精读 (2022-07-29)</h3><iframe src="//player.bilibili.com/player.html?aid=771465420&bvid=BV14r4y1j74y&cid=787181762&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="CLIP-改进工作串讲（上）-2022-09-02"><a href="#CLIP-改进工作串讲（上）-2022-09-02" class="headerlink" title="CLIP 改进工作串讲（上） (2022-09-02)"></a>CLIP 改进工作串讲（上） (2022-09-02)</h3><iframe src="//player.bilibili.com/player.html?aid=857636079&bvid=BV1FV4y1p7Lm&cid=821473237&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="CLIP-改进工作串讲（下）-2022-09-16"><a href="#CLIP-改进工作串讲（下）-2022-09-16" class="headerlink" title="CLIP 改进工作串讲（下） (2022-09-16)"></a>CLIP 改进工作串讲（下） (2022-09-16)</h3><iframe src="//player.bilibili.com/player.html?aid=515513817&bvid=BV1gg411U7n4&cid=834281325&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-Deepmind用机器学习指导数学直觉论文逐段精读-《Advancing mathematics by guiding human intuition with AI》</title>
    <url>/cd0f8eee.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2021-Advancing-mathematics-by-guiding-human-intuition-with-AI.pdf" data-height="500px"></div>

<p>论文链接：<a href="https://www.nature.com/articles/s41586-021-04086-x.pdf">https://www.nature.com/articles/s41586-021-04086-x.pdf</a></p>
<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=380508665&bvid=BV1YZ4y1S72j&cid=479659575&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p>2021年12月2日的 nature 封面文章，如何用机器学习帮助数学公式的证明？<br>标题：AI 辅助的直觉<br>ML 模型不难，从 ML 角度有提升空间</p>
<ul>
<li>近 100 行代码 83%；AutoGulon 不到 10 行代码，97%；可解释性损失</li>
</ul>
<p>Nature 封面文章，增大房子的面积，ML 在别的领域盖房子</p>
<ul>
<li>研究新领域的重要问题 eg. ML 筛选出数学变量最重要的部分，数学家根据重要的变量 来猜想变量之间的关系</li>
</ul>
<p>ML 模型的改进：把房子加高</p>
<p>Nature （周刊：新闻、观点、原创性的研究工作） 和 science 一流期刊</p>
<ul>
<li>包含所有科学研究的话题，AI 领域一年发不到 10 篇</li>
<li>图很好看，质量高</li>
</ul>
<p>本文的标题：通过 AI 来指导人类的直觉、来推进数学的发展<br>Open access：开源、任意下载；影响力会更大</p>
<p>AI 怎么在数学定理的发现中起到作用的呢？<br>本文的 ML 和 数学两个问题：topo 拓扑学 和 表示论<br>技术细节在 appendix 里</p>
<hr>
<h3 id="标题和作者"><a href="#标题和作者" class="headerlink" title="标题和作者"></a>标题和作者</h3><p>AI 来指导人的直觉从而推进数学的进展<br>审稿快 &lt; 3月：7月10号投稿、9月30号接受<br>作者多：DeepMind + 数学家的单位</p>
<ul>
<li>2个通讯作者：<ul>
<li>一作：干活</li>
<li>最后一个作者：项目的技术负责人</li>
</ul>
</li>
<li>倒数第二个作者：DeepMind 的 CEO, 21 nature 文章 based on google scholar<ul>
<li>Science 少一点，nature 和 DeepMind 总部都在英国</li>
<li>编辑的对可靠的研究者的稿件的处理优先级 会高一些 —&gt; 2个多月接受 + nature 封面</li>
</ul>
</li>
<li>数学家贡献排名稍后，本文的数学结论已发表</li>
</ul>
<hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p><strong>数学套路</strong>：发现一些模式、把这些模式公式化 or 证明一些猜想，最后推导定理</p>
<ul>
<li>先有结论、提出猜想；再试图证明猜想<ul>
<li>数学归纳法：n=1、2、3的简单例子，找规律；泛化到 n 的情况；再试图证明结论</li>
</ul>
</li>
<li>数学有很多公开的、未解决的问题</li>
</ul>
<p><strong>AI套路</strong>：拿点数据、跑跑实验、看看实验结果；根据结果找可解释性的结论</p>
<p>1960 年 已经有<strong>数学家用计算机辅助</strong>来发现模式和公式化猜想</p>
<ul>
<li>BSD猜想，千禧年 2000年 （美国克雷数学研究所 (Clay Mathematics Institute,CMI)）提出的七大问题之一</li>
<li>BSD 猜想，数学家用计算机辅助计算一些简单的情况，从而抽象出一个更一般的结论</li>
<li>只有庞加莱猜想被解决</li>
<li>1900 年 希尔伯特提出了23个猜想，推动数学的发展</li>
</ul>
<p>计算机辅助数学计算的例子</p>
<ul>
<li>图论：按照某种性质的图有多少个，计算机遍历所有的组合、统计结果；根据计算得到的图个数结果，猜想数学结论</li>
<li>Richard 计算机理论研究者，一个算法的复杂度的上下限，通过计算机模拟逼近曲线的形状，然后猜想数学结论 or 证明的思路是什么</li>
</ul>
<p><strong>摘要 1 + 2 句 == 背景</strong><br><strong>细化本文主题</strong>：2个例子显示了 ML 对数学领域的结论的证明的有用性<br>本文觉得应该如何用 ML 来帮助数学家发现新的猜想 or 定理？</p>
<ul>
<li>ML 发现潜在的猜想 or 定理模式和数学对象之间的关系</li>
<li>归因技术找到最重要的数学对象，数学家可以着重考虑这几个重要的成份</li>
</ul>
<p><strong>本文主旨</strong>：提供 ML 帮助数学猜想的 framework<br>examples：结 knot（面粉团的捏出来的各个样子都是等价的；代数结构和几何结构的关系）；对称群的组合不变猜想（）</p>
<p><strong>本文 level</strong>：搭建了数学家和 ML 之间的桥梁，吸收优势，促进领域发展</p>
<p>本文有 2 个故事讲述 ML 辅助发现 拓扑结 和 表示论 的数学结论</p>
<ul>
<li>数学门槛有一点高，需要理解数学名词</li>
<li>ML 用到别的领域 or 任何一个领域的技术拓展应用到别的领域时，都希望有该领域的基础知识</li>
</ul>
<hr>
<h3 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h3><p><strong>导论第一段：</strong></p>
<p><strong>数学套路：发现一些模式、提出一些猜想</strong></p>
<ul>
<li>猜想是什么呢？可能是真、or 在有些情况还没有被证实为真的一些命题</li>
<li>定理是什么？数学的美；数学定理可以覆盖所有的东西<ul>
<li>CS 代码写出思想 by 几行代码；可能几百行代码处理各种情况的 corner cases</li>
</ul>
</li>
</ul>
<p><strong>数学家和数据、计算机、AI的关系是什么呢？</strong></p>
<ul>
<li>数据辅助：高斯 根据手算质数表 提出 质数定理</li>
<li>计算机辅助：bsd 猜想；or 计算机来计算 Π 的一万位</li>
<li>但 AI 没有特别帮助 数学家</li>
</ul>
<p><strong>本文的 motivation 是什么？常见句式</strong></p>
<ul>
<li>之前的结果 好 且 有用，但无法一般化的推广</li>
<li>结果不错 + 一般化，但是没有重要的结果被发现</li>
<li>常见句式：<ul>
<li>前人工作效果好、但不够一般化；本文更加一般化</li>
<li>前人工作可以处理很一般的情况，但结果不够好；本文结果更好</li>
<li>我的工作和这两类工作都不一样</li>
</ul>
</li>
</ul>
<p><strong>导言第二段：AI 在数学的应用</strong></p>
<p><strong>AI 在数学领域能够干什么呢？</strong></p>
<ul>
<li>AI 搜索空间可以很广、为数学猜想提供反例</li>
<li>数学猜想有一个反例，猜想不成立；和 cs 不同，打一个补丁 if else 即可</li>
<li>生成一些 symbolic solutions 计算软件 mathematica</li>
<li>在一些数学物体里找 一些特别的架构</li>
</ul>
<p><strong>本文和已有工作的不同是什么？</strong></p>
<ul>
<li><p>AI 帮助发现定理和猜想，夸张 example：AI 帮你写数学论文</p>
<ul>
<li>之前的工作，在某一块 or 方面 辅助数学家做一些事情</li>
</ul>
</li>
<li><p>告诉数学家，有一个很强大的工具，可以帮你证明顶里，快来用！</p>
</li>
<li><p>有监督的学习 AI 发现了 2个 新的定理！</p>
</li>
</ul>
<hr>
<h3 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h3><p>AI 指导数学的直觉</p>
<p>数学的直觉 在 数学研究中很重要</p>
<ul>
<li>Terry tao（陶哲轩 Terence Chi-Shen Tao，澳籍华人数学家）博客中的一句话</li>
<li>复杂的数学问题 需要 严谨的公式化 + 好的直觉</li>
<li>大胆假设、仔细求证</li>
</ul>
<p>本文描述了一个一般化的方法，数学家使用 ML 工具 来帮助定理发现<br>数学家的直觉：需要思考 2个 不同的数学物体之间的联系，猜 x(z) 和 y(z) 的联系</p>
<ul>
<li>z 是某一个特定的物体</li>
<li>X(z) 表示的是在某一些方面对 z 的刻画</li>
<li>Y(z) 表示的是另外一些数学概念对 z 的刻画</li>
</ul>
<p><strong>ML 怎么描述  x(z) 和 y(z) 的联系呢？</strong></p>
<ul>
<li>用一个函数 f, x(z) 是输入特征， y(z) 是输出标签。</li>
<li>如果 ML 可以学到一个函数 f，可以告诉数学家 x(z) 和 y(z) 是有联系的</li>
</ul>
<p><strong>Example ML 描述 2个 数学对象之间的联系</strong></p>
<ul>
<li>Z 是一个凸的多面体；多面体 i.e., 正方体</li>
<li>x(z) 是 （顶点数 int、边数 int、体积 R、表面积 R）</li>
<li>y(z) 是 凸多面体 z 的 面 的数量</li>
</ul>
<p>x(z) * (-1, 1, 0, 0) + 2 = y(z)<br>凸多面体的边数 - 其定点数 + 2 = 该凸面体的面数<br>线性回归：和一个 四维向量 做点积 + 2<br>ML 学习 1个 四维的常数值，得到学习的常数值后，用严格的数学推理来证明猜想</p>
<p><strong>更复杂的例子，ML 要学的函数 f 更复杂、维度更高；需要更复杂的机器学习模型</strong></p>
<hr>
<h3 id="一篇新闻"><a href="#一篇新闻" class="headerlink" title="一篇新闻"></a>一篇新闻</h3><p>作者 | Ben Dickson<br>译者 | Sambodhi</p>
<p>DeepMind 研究人员最近发表了一篇题为《通过用人工智能引导人类直觉来推进数学》（Advancing mathematics by guiding human intuition with AI）的论文，认为深度学习能够帮助发现被人类科学家忽视的数学关系。很快，这篇论文在科技媒体上引起了广泛的关注。</p>
<p>一些数学家和计算机科学家对 DeepMind 的工作及其论文中所取得的成果表示赞赏，称其具有突破性。其他人则对此持怀疑态度，认为这篇论文和它在大众媒体上的报导，可能夸大了深度学习在数学中的应用。</p>
<hr>
<h4 id="一种基于机器学习的数学发现框架"><a href="#一种基于机器学习的数学发现框架" class="headerlink" title="一种基于机器学习的数学发现框架"></a>一种基于机器学习的数学发现框架</h4><img src="/cd0f8eee/1.jpg" class>

<p>数学家们首先对两个数学对象之间的关系做出假设。为了验证这一假设，他们使用计算机程序为这两种类型的对象生成数据。接下来，一种监督式机器学习模型算法对这些数字进行计算，并尝试调整其参数，将一种类型的对象映射到另一种类型的对象。</p>
<p>研究人员写道：“在这个回归过程中，机器学习最重要的贡献在于，只要有足够的数据，就可以学习到一系列可能的非线性函数。”</p>
<p>如果训练过的模型比随机猜测的表现更好，那么它可能表明这两个数学对象之间确实存在着可发现的关系。通过使用不同的机器学习技术，研究人员能够发现与问题更相关的数据点，改进他们的假设，生成新的数据，并训练新的模型。通过重复这些步骤，他们可以缩小合理猜想的范围，并加速得到最终解决方案。</p>
<p>DeepMind 的科学家将该框架描述为“直觉的试验台”，它可以快速验证“关于两个量之间关系的直觉是否值得追求”，并为它们可能存在的关系提供指引。</p>
<p>利用这个框架，DeepMind 的研究人员通过使用深度学习得出了“两项基本的新发现，一项是拓扑学，另一项是表示论。”</p>
<p>这项工作的一个有趣之处在于，无需庞大的算力，而算力已经成为 DeepMind 研究的支柱。根据该论文，在这两项发现中使用的深度学习模型可以在“一台只有一个图形处理单元的机器上”在几个小时内进行训练。</p>
<hr>
<h4 id="纽结与表示"><a href="#纽结与表示" class="headerlink" title="纽结与表示"></a>纽结与表示</h4><img src="/cd0f8eee/2.jpg" class>

<p>纽结是空间中的一条闭合曲线，可以用各种方式定义。随着其交叉点数量的增加，它们将会变得更复杂。研究人员想看看他们是否可以利用机器学习来发现代数不变量和双曲不变量之间的映射，这是定义纽结的两种根本不同的方式。</p>
<p>研究人员写道：“我们假设，在一个纽结的双曲不变量和代数不变量之间存在一种未被发现的关系。”</p>
<p>使用 SnapPy 软件包，研究人员可以生成“签名”、1 个代数不变量和 12 个有希望的双曲不变量，可用于 170 万个纽结，最多有 16 个交叉点。</p>
<p>接下来，他们创建了一个全连接的前馈神经网络，这个网络具有三个隐藏层，每个隐藏层有 300 个单元。他们训练深度学习模型，将双曲不变量的值映射到签名上。他们的初始模型能够以 78% 的准确率预测签名。通过进一步的分析研究，他们在双曲不变量中发现了一个较小的参数集，可以预测签名。研究人员完善了他们的猜想，生成了新的数据，重新训练了他们的模型，并得出了一个最终的定理。</p>
<p>研究人员将该定理描述为“连接纽结的代数和几何不变量的首批结果之一，它有着很多有趣的应用。”</p>
<p>“我们预计，在低维拓扑学中，这种新发现的自然斜率和签名之间的关系将会有许多其他应用。”研究人员写道：“如此简单而又深刻的关系，在这个早已被广泛研究的领域里却被忽视了，真是太不可思议了。”</p>
<img src="/cd0f8eee/3.jpg" class>

<p>论文的第二个结果也是对称性的两种不同观点的映射，它的复杂性远远超过了纽结。</p>
<p>在本例中，他们使用了一种图神经网络（graph neural network，GNN），以求 Bruhat 区间图和 Kazhdan-Lusztig（KL）多项式之间的关系。图神经网络的一个好处就是能够对庞大的、单凭头脑难以处理的图进行计算和学习。深度学习将区间图作为输入，尝试预测相应的 KL 多项式。</p>
<p>同样，通过生成数据，训练深度学习模型，并重新调整过程，科学家们能够得出一个可证明的猜想。</p>
<hr>
<h4 id="大众对-DeepMind-数学人工智能的反应"><a href="#大众对-DeepMind-数学人工智能的反应" class="headerlink" title="大众对 DeepMind 数学人工智能的反应"></a>大众对 DeepMind 数学人工智能的反应</h4><p>谈到 DeepMind 在纽结理论方面的发现，内布拉斯加大学林肯分校的纽结理论家 Mark Brittenham，在接受《自然》（Nature）采访时说：“作者用一种很直接的方法，证实了不变量是相关的，这一事实告诉我们，在这一领域中，存在着许多我们尚未充分了解的、非常基本的事物。”Brittenham 还说，DeepMind 的这项技术在发现惊人的联系上，比起其他将机器学习应用于纽结的努力，它是很新颖的。</p>
<p>以色列特拉维夫大学的数学家 Adam Zsolt Wagner 也接受了《自然》杂志的采访，他说，DeepMind 提出的方法可以证明对某些类型的问题有价值。</p>
<p>Wagner 有将机器学习应用于数学的经验，他称：“如果没有这种工具，数学家可能就会花上好几个星期甚至几个月去证明某个公式或者定理，而这些公式和定理最后都会被证明是错误的。”但他也补充说，目前还不清楚它的影响会有多广泛。</p>
<hr>
<h4 id="持怀疑态度的理由"><a href="#持怀疑态度的理由" class="headerlink" title="持怀疑态度的理由"></a>持怀疑态度的理由</h4><p>继 DeepMind 的研究成果在《自然》杂志上发表后，纽约大学计算机科学教授 Ernest Davis 发表了一篇自己的论文，就 DeepMind 关于结果的框架以及深度学习在普通数学中的应用的局限性提出了一些重要问题。</p>
<p>关于 DeepMind 的论文中提出的第一个结果，Davis 观察到，纽结理论并不是深度学习优于其他机器学习或统计方法的典型问题。</p>
<p>纽结问题只有 12 个输入特征，其中只有三个是相关的。而输入特征和目标变量之间的数学关系很简单。</p>
<p>Davis 写道：“很难理解为什么有 20 万个参数的神经网络会成为首选的方法；简单、传统的统计方法或支持向量机更适合。”</p>
<p>在第二个项目中，深度学习的作用更为重要。“与使用通用深度学习架构的纽结理论项目不同，神经网络被精心设计，以满足对这个问题更深层次的数学知识。此外，深度学习在预处理数据上比在原始数据上工作得更好，错误率大约是 1/40。”他写道。</p>
<p>Davis 称，一方面，这些研究结果与那些批评的观点形成了鲜明的对比，即把领域知识纳入深度学习中是非常困难的。他写道：“另一方面，深度学习的爱好者经常称赞深度学习是一种‘即插即用’的学习方法，它可以用原始数据来解决手头的任何问题；这与这种赞誉相悖。”</p>
<p>在这些任务中，要成功应用深度学习，可能在很大程度上依赖于训练数据的生成方式和数学结构的编码方式。这说明该框架可能适用于一小类数学问题。</p>
<p>“寻找生成和编码数据的最佳方式涉及理论、经验、艺术和实验的混合。这一切的重担都落在了人类专家身上，”他写道。“深度学习可以是一种强大的工具，但也不是万能的。”</p>
<p>Davis 提醒道，在当前关于深度学习的炒作氛围中，“存在着一种异常的动机，让人们关注深度学习在这项研究中的作用，而不只是 DeepMind 的机器学习专家，甚至是数学家。”</p>
<p>Davis 总结说，就像在这篇文章中所提到的，深度学习最好被视为“实验数学工具箱中的另一种分析工具，而非一种全新的数学方法。”</p>
<p>值得注意的是，原始论文的作者也指出了他们的框架的一些局限性，例如“它需要生成对象表示的大型数据集的能力，并且模式在可计算的示例中是可检测的。此外，在某些领域，在这个范式中可能很难学习到感兴趣的函数。”</p>
<hr>
<h4 id="深度学习与直觉"><a href="#深度学习与直觉" class="headerlink" title="深度学习与直觉"></a>深度学习与直觉</h4><p>其中一个争议主题是，该论文宣称，深度学习是“引导直觉”。Davis 形容这一说法是“非常不准确的描述，即对数学家在使用这样的深度学习时，得到了或者期望得到什么帮助。”</p>
<p>直觉是人类和人工智能的重要区别之一。这是一种比随机猜测更好的决策能力，并且在大部分时间里，它可以引导你走上正确的方向。正如迄今为止人工智能的历史所显示的那样，在海量数据中，并没有预定义的规则和模式能够捕捉到直觉。</p>
<p>“在数学的世界中，‘直觉’一词意味着，一个概念或证明可以建立在人们对熟悉的领域（如数字、空间、时间或运动）根深蒂固的感觉上，或者以某种其他方式‘有意义’或‘似乎正确’，而不需要明确的计算或逐步推理。”Davis 写道。</p>
<p>Davis 认为，为了获得对数学概念的直观掌握，往往需要通过多个具体的例子来进行，但这并非统计学上的相关工作。换句话说，你不会通过运行数百万个例子和观察某些模式重复出现的百分比来获得直觉。</p>
<p>这意味着，并不是深度学习模型让科学家直观地理解他们所定义的概念、所证明的定理以及所提出的猜想。</p>
<p>Davis 写道：“深度学习所做的，是给他们提供一些建议，告诉他们问题的哪些特征看起来重要，哪些看起来不重要。这并不值得嗤之以鼻，但也不应该被夸大。”</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://bdtechtalks.com/2021/12/13/deepminds-machine-learning-mathematics/">https://bdtechtalks.com/2021/12/13/deepminds-machine-learning-mathematics/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-智能电子听诊系统的研究</title>
    <url>/4a882850.html</url>
    <content><![CDATA[<h3 id="智能电子听诊系统介绍"><a href="#智能电子听诊系统介绍" class="headerlink" title="智能电子听诊系统介绍"></a>智能电子听诊系统介绍</h3><p>智能电子听诊系统分为家用版和医用版。医用版听诊器由听诊器和智音APP组成，如图1所示。医生使用蓝牙耳机连接听诊器后，听诊器显示将输出患者心率等体征数据。医生也可配合智音APP使用听诊器，以实现心肺音高度分离听诊、异地医院间的远程会议等。目前的产品的数字化听诊方式可满足无接触听诊、在线听诊、远程听诊等要求。在疫情期间，这样的产品已经为国内外十余家公司提供服务。</p>
<img src="/4a882850/1.jpg" class>
<p>图1  医用版电子智能听诊系统</p>
<span id="more"></span>

<p>家用版听诊器需要配合相应的APP使用。如图2所示，采集筛选的心肺音均可在APP上长期记录与听取。系统还可以做健康检测报告。系统可应用于早期发现心血管疾病的征兆，发现婴儿呼吸道感染，以及长期的心肺音疾病检测。</p>
<img src="/4a882850/2.jpg" class>
<p>图2  家用版电子智能听诊系统</p>
<hr>
<h3 id="技术原理介绍"><a href="#技术原理介绍" class="headerlink" title="技术原理介绍"></a>技术原理介绍</h3><p>作品的主要技术是数字感知和噪声控制还有心肺音分离技术。</p>
<p>心肺音信号微弱是心肺音采集的难题，本产品通过自研的基于自由曲面的声学共鸣腔设计减少共鸣腔体积，提高心肺音传导增益。为避免外界环境噪声影响医生做出准确判断， 本产品通过前置模拟音频处理电路，实现快速环境噪音衰减滤波，降低微弱听诊信号的量化误差。利用心肺音信号的准 周期特性，借助卷积非负矩阵分解方法（NMF），在时频域将 心肺音和环境噪声分离，提高心肺音信噪比，抑制外环境噪声。</p>
<p>一般心音的频率范围为 10 ～ 320 Hz，肺音的频率范围为60 ～ 600 Hz。于心音和肺音在时域和频域内都有重叠，导致难以通过传统的带通滤波器有效分离。为解决两者在线性时频域混叠的问题，文中提出了一种基于正则化 NMF 的心肺音分离方法。该方法对采集的心肺音混合信号进行处理，获得心肺音混合信号的时频谱 ；对时频谱中 20 ～ 100 Hz 部分取列平均，得到心音的幅模时序模板 ；根据心音的幅模时序模板构造心音时序结构正则项，对时频谱进行非负矩阵分解，抽取心音信号时频谱的估计和肺音信号时频谱的估计；心音信号时频谱的估计和肺音信号时频谱的估计重构出心音和肺音的时域信号。</p>
<hr>
<h3 id="应用前景介绍"><a href="#应用前景介绍" class="headerlink" title="应用前景介绍"></a>应用前景介绍</h3><p>无接触式听诊有效保护了医患双方的健康。相对于国内外电子听诊器采用的带通滤波器、小波去噪等方法，本产品以卷积非负矩阵分解法和前置模拟音频处理电路抑制噪声，在提高心肺音增益的同时降低微弱信号的量化误差，实现高精度降噪。同时，本产品提出了一种盲分离技术，可实现心肺音快速有效分离，提供更准确的病理指标及更可靠的听诊依据，为远程医疗平台提供数据接口。目前，占我国市场份额较大的智能听诊器所面向的人群、地区较为单一，辐射范围有限，且功能及检测精确度不及本项目产品。设计的产品将分期、分重点逐步覆盖医院、偏远地区基层医疗卫生站、家庭用户、养老机构及幼儿园等，价廉质优，具有广阔的应用前景。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2021&amp;filename=WLWJ202110002">https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2021&amp;filename=WLWJ202110002</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=11874">https://www.scholat.com/teamwork/showPostMessage.html?id=11874</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-面部动作单元检测方法进展与挑战</title>
    <url>/cda9211f.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2020-面部动作单元检测方法进展与挑战.pdf" data-height="500px"></div>

<span id="more"></span>

<hr>
<h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p><strong>人脸动作编码系统</strong>从人脸解剖学的角度定义了一组<strong>面部动作单元（action unit, AU）</strong>，用于精确刻画人脸表情变化。每个面部动作单元描述了一组脸部肌肉运动产生的表观变化，其组合可以表达任意人脸表情。</p>
<p>AU 检测问题属于<strong>多标签分类问题</strong>，其挑战在于<strong>标注数据不足、头部姿态干扰、个体差异和不同 AU 的类别不均衡等</strong>。</p>
<p>为总结结近年来 AU 检测技术的发展，文章系统概述了 2016 年以来的代表性方法，根据输入数据的模态分为<strong>基于静态图像、基于动态视频以及基于其他模态的 AU 检测方法</strong>，并讨论在不同模态数据下为了降低数据依赖问题而引入的<strong>弱监督 AU 检测方法</strong>。</p>
<ul>
<li>针对<strong>静态图像</strong>，进一步介绍基于局部特征学习、AU 关系建模、多任务学习以及弱监督学习的 AU 检测方法</li>
<li>针对<strong>动态视频</strong>，主要介绍基于时序特征和自监督 AU 特征学习的 AU 检测方法</li>
</ul>
<p>最后，文章对比并总结了各代表性方法的优缺点，并在此基础上总结和讨论了面部 AU 检测所面临的挑战和未来发展趋势。</p>
<hr>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><h4 id="FACS-与-AU"><a href="#FACS-与-AU" class="headerlink" title="FACS 与 AU"></a>FACS 与 AU</h4><p>1978 年，美国心理学家 Ekman 从面部解剖学角度首次提出<strong>面部运动编码系统（facial action coding system, FACS）</strong>。<strong>FACS</strong>定义了 44 个<strong>面部运动单元（action unit, AU）</strong>，并具体定义了每个 AU 的作用区域、运动表观特征以及各种表情的 AU 构成。</p>
<img src="/cda9211f/1.png" class>

<p>每个 AU 均表示一种具有特定语义的脸部肌肉运动，如 AU1 表示眉毛内角提升运动，AU2 表示眉毛外角提升等。AU 可以被单独激活，也可以被组合激活。任何的脸部事件，都可以表示成若干 AU 的组合。例如，微笑可以表述为嘴角拉升（AU12）和脸颊提升（AU6）的组合。</p>
<img src="/cda9211f/2.png" class>

<p>FACS 的提出对当代自动人脸表情分析技术的发展起着至关重要的作用，相比于 Ekman（1971）定义的 6 类原型表情（愤怒、厌恶、恐惧、高兴、悲伤和惊讶），FACS 提供了一种更客观、更细粒度的面部表情描述方法。此外，通过采用一系列固定的人脸参数表示表情和人脸行为，FACS 避免了 6 类原型表情框架中因观测者不同而引入的标注歧义性。</p>
<hr>
<h4 id="总结-AU-发展与展望"><a href="#总结-AU-发展与展望" class="headerlink" title="总结 AU 发展与展望"></a>总结 AU 发展与展望</h4><p>自动化的 AU 检测技术得到了广泛的关注和应用。通过计算机自动检测 AU 及其组合，有助于准确分析面部表情和理解个体情绪，并在驾驶员疲劳检测、病患疼痛估计、刑侦测谎、影视评估和广告评估等场景中具有良好的应用前景。随着以深度学习为代表的机器学习技术的发展，以及人脸检测、对齐和识别技术的不断完善，AU 检测技术也取得了明显的进步，与此同时，AU 检测技术仍然面临诸多挑战。为总结和讨论 AU 检测方向的近期发展，文章对过去 5 年该方向出现的代表性方法进行了分类、评述、总结和展望。文章将首先介绍 AU 检测任务的定义、挑战和评测数据情况，然后从静态图像 AU 检测、视频 AU 检测和其他模态 AU 检测等角度对相关方法进行概述，其中重点介绍了当前主流的基于深度学习的 AU 检测方法。之后文章从性能评测的角度对一些主流的 AU 检测方法进行了对比，最后讨论了 AU 检测方向的未来发展趋势。</p>
<hr>
<h3 id="问题定义与挑战"><a href="#问题定义与挑战" class="headerlink" title="问题定义与挑战"></a>问题定义与挑战</h3><h4 id="AU-检测的定义"><a href="#AU-检测的定义" class="headerlink" title="AU 检测的定义"></a>AU 检测的定义</h4><p>AU 检测的目标是估计输入人脸图像或者视频序列中各 AU 是否被激活。给定一幅输入图像或一段视频序列，AU 检测流程可以分为以下几个阶段：</p>
<ol>
<li>人脸检测、跟踪与对齐<ul>
<li>输入图片：判断是否包含人脸，并确定人脸位置与裁剪人脸区域</li>
<li>输入视频：动态人脸检测和跟踪，检测人脸区域后还需要定位面部特征点并据此对其人脸以消除3维刚性的头部运动</li>
</ul>
</li>
<li>AU 特征提取<ul>
<li>AU 特征提取是 AU 检测系统的核心组成部分</li>
<li>常用的 AU 特征包括几何特征、手工设计的各种表观特征以及通过深度学习模型提取的深度特征</li>
</ul>
</li>
<li>检测 AU 的激活状态<ul>
<li>提取输入图像或视频帧的 AU 特征后，依据特征估计 AU 激活状态</li>
<li>需要针对每个 AU 采用单独的二分类方法，或针对多个 AU 采用多标签分类方法</li>
</ul>
</li>
</ol>
<hr>
<h4 id="AU-检测的主要挑战"><a href="#AU-检测的主要挑战" class="headerlink" title="AU 检测的主要挑战"></a>AU 检测的主要挑战</h4><p>作为一个典型的视觉模式识别问题，AU 检测存在一些独有的难点，主要包括：</p>
<ol>
<li>标注数据不足：不同人的面部动作强度不同、尺度范围的面部细微变化不同</li>
<li>实际应用场景中 AU 数据的复杂性问题</li>
<li>面部 AU 的个体差异问题</li>
</ol>
<hr>
<h4 id="FACS-数据库及评测协议"><a href="#FACS-数据库及评测协议" class="headerlink" title="FACS 数据库及评测协议"></a>FACS 数据库及评测协议</h4><p>在过去的几十年里，业界发布了多个公开的 FACS 数据库，用于统一评测相应方法的 AU 检测精度，并推动相关技术的发展。</p>
<p>早期大多在严格限定的环境下采集，受试者在固定的头部姿态下按照要求摆拍出相应的面部表情，如 CK(Cohn-Kanade) 和 MMI(Maja Pantic, Michel Valstar Initiative)</p>
<p>自 2011 年以来，越来越多的机构和研究者开始关注个体的自发表情，所采集的数据库包含了受试者在限定条件下诱发的自发表情，如受试者在观看电影片段时自然流露的面部表情，如 DISFA(Denver Intensity of Spontaneous Facial Action) 和 BP4D。2016 年以后，业界逐步发布了一些开放场景下采集的 FACS 数据库，如 EmotioNet 和 GFT(Sayette Group Formation)。这些数据库中的人脸图像或视频收集自互联网等自然场景，其中人物的面部表情呈现出丰富的多样性。</p>
<hr>
<h3 id="AU-检测方法进展"><a href="#AU-检测方法进展" class="headerlink" title="AU 检测方法进展"></a>AU 检测方法进展</h3><p>根据输入数据的不同，当前 AU 检测方法可以分为基于静态图像(image-based)的方法、基于动态视频序列(video-based)的方法，以及基于其他模态（如点云、红外图像等）的方法。</p>
<p>考虑到 AU 本质是人脸局部区域的肌肉运动，并且各个 AU 的激活存在共生和互斥关系，因此基于静态图像的 AU 检测方法多尝试编码输入图像的局部特征，建模 AU 之间的依赖关系。此外激活的面部动作单元引起的表观变化将显著影响面部特征点的位置分布，因此当前有一些方法采用了同时估计面部特征点坐标和检测 AU 激活状态的多任务学习方法，用于提升 AU 检测精度。此外，由于 FACS 数据库中只有有限的标注样本，大量的研究工作尝试采用弱监督方法增加训练数据的多样性，提升 AU 检测模型的泛化性能。</p>
<p>基于动态视频的 AU 检测方法除了具有图像空间层面的特征表示能力，还能够在时间维度上编码连续帧之间的时序信息，因此能够准确感知视频序列中低强度 AU 的激活状态。为了降低模型对于标注训练数据的依赖，一些文献尝试以不同帧之间的运动信息为监督信号，采用自监督的方式学习 AU 特征。</p>
<p>为减轻头部姿态变化，以及光照变化带来的不利影响，出现了一些采用点云或红外图像的 AU 检测方法。</p>
<hr>
<h4 id="基于静态图像的-AU-检测方法"><a href="#基于静态图像的-AU-检测方法" class="headerlink" title="基于静态图像的 AU 检测方法"></a>基于静态图像的 AU 检测方法</h4><h5 id="局部特征学习"><a href="#局部特征学习" class="headerlink" title="局部特征学习"></a>局部特征学习</h5><p>因为每个面部动作单元描述了一组脸部肌肉运动产生的局部表观变化，所以显式学习 AU 的局部特征表示将有助于提升 AU 检测精度。为了学习输入人脸图像的局部特征，常用的方法有均匀分块方法、基于特征点的手工裁剪方法，以及基于注意力机制的自适应局部区域感知方法。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2016</td>
<td>Zhao</td>
<td>设计了一种含有局部连接层的卷积神经网络模型</td>
<td>该方法将输入的卷积特征图划分为均匀的子区域，并针对每个子区域采用不同的卷积核进行局部区域特征学习</td>
</tr>
<tr>
<td>2017, 2018</td>
<td>Li</td>
<td>采用面部特征点裁剪出人脸的局部特征图</td>
<td>为解决基于均匀分块的方法无法在不同头部姿态下裁剪出语义对齐的人脸局部区域的问题</td>
</tr>
<tr>
<td>2016</td>
<td>Jaiswal, Valstar</td>
<td>通过每幅图像的面部特征点手工计算出一系列二值掩膜，裁剪出图像的局部区域用于局部特征学习</td>
<td></td>
</tr>
<tr>
<td>2019</td>
<td>Ma</td>
<td>通过手工设计的方法，明确定义出每个 AU 对应的面部区域，并将 AU 检测问题转化为通用的物体检测问题</td>
<td>与均匀分块相比，使用面部特征点裁剪出的局部区域具有良好的语义对齐特性，有效提升了 AU 检测精度</td>
</tr>
</tbody></table>
<p>然而，基于面部特征点的局部区域裁剪方法仍然存在两个主要问题：</p>
<ol>
<li>裁剪规则依靠人为主观设计，裁剪数量不统一，难以公平比较不同裁剪方法的优劣</li>
<li>各种裁剪方法均采用大小统一的裁剪尺寸，灵活性有限</li>
</ol>
<p>为解决上述问题，一些工作尝试采用注意力机制的方法学习 AU 的局部特征表示。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2018</td>
<td>Shao</td>
<td>通过在线预测的面部特征点初始化多路注意力模板，并在模型的训练过程中自动修正注意力模板的中心位置</td>
<td></td>
</tr>
<tr>
<td>2019</td>
<td>Ertugrul</td>
<td>采用面部特征点在人脸图像上裁剪出 9 个局部区域，随后采用特征层面的自注意力机制融合局部特征，以表达人脸不同区域的重要程度</td>
<td></td>
</tr>
</tbody></table>
<p>相比手工设定的人脸局部区域中心坐标，基于注意力机制的局部特征学习方法具有更优的灵活性，模型能够在训练过程中自动注意到与 AU 紧密相关的非规则区域。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2019</td>
<td>Shao</td>
<td>采用通道和空间层面的双重注意力机制学习输入图像的 AU 注意力模板，并采用条件随机场建模注意力模板中像素之间的关联关系</td>
<td>该方法在推断 AU 相关的注意力模板时不需要依赖面部特征点，因而具有良好的灵活性</td>
</tr>
</tbody></table>
<p>然而由于当前的 FACS 数据库中只包含少量（几十个）的受试者，因此所学习的注意力模板难以准确捕捉未知个体的 AU 位置分布，采用条件随机场等方法修正注意力模板则增加了模型训练和推断的复杂度，不利于实际部署使用。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2017, 2018</td>
<td>Ali, Albiero</td>
<td>基于面部特征点裁剪出一定量的人脸局部区域，采用局部特征学习的方式检测输入图像的 AU 状态</td>
<td>在跨姿态 AU 检测任务上取得了良好的效果</td>
</tr>
</tbody></table>
<p>除了上述显式学习局部特征的方法，部分文献尝试隐式学习输入图像的局部特征。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2016</td>
<td>Han</td>
<td>提出了一种增量集成的学习方法，该方法借鉴集成学习的思想，从输入图像的特征中自动选择出具有判别性的 AU 特征子集</td>
<td>能够有效减轻有限训练数据条件下 AU 检测模型过拟合的风险</td>
</tr>
<tr>
<td>2018</td>
<td>Han</td>
<td>考虑到不同的 AU 激活于不同尺度的人脸局部区域，提出了一种迭代式的模型训练方法，能够同时学习卷积核尺寸和卷积核参数</td>
<td>该方法能够为不同的 AU 学习出不同尺寸的卷积核，具有良好的解释性，其不足之处在于需要为每个 AU 训练单独的检测模型，模型在训练阶段无法进行有效的 AU 关联学习</td>
</tr>
</tbody></table>
<hr>
<h5 id="AU-关系建模方法"><a href="#AU-关系建模方法" class="headerlink" title="AU 关系建模方法"></a>AU 关系建模方法</h5><p>AU 往往以组合的方式被激活，如惊讶表情一般包含了眉毛和嘴巴区域多个 AU 的组合，如 AU2（眉毛外角提升），AU26（下巴下降）等，因此显式建模 AU 之间的共生和互斥关系能够进一步提升 AU的检测精度。较早的 AU 关系建模方法多采用贝叶斯网络或波尔兹曼机建模 AU 在特征或标签层面的依赖关系，并取得了一定进展。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2017</td>
<td>Wang</td>
<td>采用贝叶斯网络建模 AU 之间的依赖及互斥关系</td>
<td>该方法采用训练样本的 AU 标签优化贝叶斯网络的参数及连接结构，并在推断阶段使用贝叶斯网络辅助推断测试样本的估计标签</td>
</tr>
<tr>
<td>2018</td>
<td>Hao</td>
<td>进一步提出采用包含隐变量的多层贝叶斯网络</td>
<td>该网络能够同时建模隐变量之间的依赖关系以及可见变量（AU标签）之间的依赖关系</td>
</tr>
<tr>
<td>2017</td>
<td>Wang</td>
<td>采用多层的玻尔兹曼机同时建模 AU 在特征和标签层面的关系</td>
<td></td>
</tr>
<tr>
<td>2019</td>
<td>Wang</td>
<td>尝试采用玻尔兹曼机建模 AU 标签的联合分布特性，并利用预训练的玻尔兹曼机为无标签数据分配伪标签</td>
<td>用于提升训练数据的多样性</td>
</tr>
</tbody></table>
<p>上述采用贝叶斯网络或者玻尔兹曼机的 AU 关系建模方法不足之处在于没有耦合图像特征提取和 AU 关联学习，限制了相关方法的 AU 检测精度。</p>
<p>基于深度学习的相关工作开始以端到端的方式同时进行 AU 特征学习和 AU 关联学习。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2018</td>
<td>Corneanu</td>
<td>提出了一种深度结构预测网络，该方法采用图模型建模 AU 依赖关系，并采用迭代的消息传递机制更新 AU 预测结果</td>
<td></td>
</tr>
<tr>
<td>2019</td>
<td>Niu</td>
<td>采用图卷积网络建模 AU 标签之间的依赖关系，并使用 FACS 数据库的标注信息初始化 GCN 的邻接矩阵</td>
<td></td>
</tr>
<tr>
<td>2019</td>
<td>Li</td>
<td>进一步采用门控图神经网络传递局部面部特征之间的依赖关系</td>
<td>提升用于 AU 检测的特征表示能力</td>
</tr>
</tbody></table>
<p>这些方法能够在模型训练的过程中将 AU 关联知识嵌入到所学习的 AU 特征表示中，不但在 FACS 数据库上取得了更高的检测精度，所训练的模型同时能够较好地应对轻微的面部遮挡。然而，上述方法中图神经网络各个节点之间的连接关系依赖不同数据库的 AU 标签联合分布特性，最终训练得到的 AU 检测模型难以应用于跨数据库测试和验证，灵活性较低。</p>
<hr>
<h5 id="多任务学习方法"><a href="#多任务学习方法" class="headerlink" title="多任务学习方法"></a>多任务学习方法</h5><p>考虑到面部特征点表示的人脸形状信息有助于面部动作单元的检测，并且激活的面部动作单元引起的表观变化将显著影响面部特征点的位置分布，因此采用同时估计面部特征点坐标和 AU 激活状态的多任务学习方法有助于提升 AU 检测精度。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2016</td>
<td>Wu, Ji</td>
<td>提出了一种约束联合的级联回归框架。该方法在估计面部特定点坐标位置时。使用了人脸的局部表观特征，以及当前预测的面部动作单元状态信息；在预测面部动作单元激活状态时，使用了人脸的局部表观特征，以及当前预测的面部特征点坐标位置信息</td>
<td>面部特征点坐标估计和面部动作单元检测在模型的训练过程中互相促进，最终两个子任务都取得了相应的性能提升</td>
</tr>
<tr>
<td>2018</td>
<td>Shao</td>
<td>提出了基于注意力机制的多任务学习方法。该多任务学习方法中，面部特征点定位被当做辅助任务，所学习到的特征被送入 AU 检测子任务中，用于提升 AU 检测精度</td>
<td></td>
</tr>
</tbody></table>
<p>此外，离散表情分类和 AU 检测具有紧密的语义关联，已有一些工作联合学习这两个任务。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2018</td>
<td>Jyoti</td>
<td>采用多任务学习方法同时预测输入图像中的人脸位置、面部动作单元状态，以及 7 类离散表情的概率分布</td>
<td>该方法在深度网络模型的不同层级分别估计上述 3 个任务，一方面实现了模型的参数共享，另一方面模型的浅层特征在训练过程中能够得到精确的监督信号</td>
</tr>
<tr>
<td>2019</td>
<td>Wang</td>
<td>使用十字绣网络模型同时学习面部动作单元检测和 7 类离散表情分类任务</td>
<td>该方法采用了可学习的参数用于自适应共享子任务之间的底层特征，并在 AU 检测任务上取得了显著的精度提升</td>
</tr>
</tbody></table>
<p>上述多任务学习方法合理利用了外部数据和标签信息，有效提升了 AU 检测精度。从提升 AU 检测精度的角度出发，多任务学习中 AU 检测任务可以被进一步设计为主任务，其他任务可以被设计为辅助任务。此外，多任务学习过程中可以引入其他的相关任务，如情感维度估计等。</p>
<hr>
<h5 id="基于图像的弱监督方法"><a href="#基于图像的弱监督方法" class="headerlink" title="基于图像的弱监督方法"></a>基于图像的弱监督方法</h5><p>为了降低模型对于标注训练数据的依赖，一些研究者提出了半监督、弱监督的模型学习方法。</p>
<p>半监督 AU 检测方法在模型训练阶段同时使用了标注数据和无标注数据，并尝试在模型的训练过程中为无标注数据推断伪标签，随后将伪标签数据加入模型的训练过程中以提升数据的多样性和丰富性。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2019</td>
<td>Niu</td>
<td>与传统的协同训练方法不同，采用权重正交的 AU 分类器学习训练样本的不同视图。针对无标签的训练数据，该方法通过最小化两个分类器输出分布距离的方式，确保两个分类器的预测结果具有一致性</td>
<td></td>
</tr>
</tbody></table>
<p>弱监督 AU 检测方法在模型的训练过程中使用噪声标注或不完整标注的数据用于模型训练。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2018</td>
<td>Zhao</td>
<td>针对噪声标签，采用了一种谱聚类的方法，在模型的训练过程中迭代纠正训练数据的标注标签</td>
<td></td>
</tr>
<tr>
<td>2018</td>
<td>Wang</td>
<td>针对不完整标注，根据离散表情和 AU 的先验知识为训练样本推断初步的 AU 伪标签，并构造了基于多标签排序损失的弱监督学习方法</td>
<td>该方法在训练阶段不需要依赖 AU 标注标签</td>
</tr>
<tr>
<td>2018</td>
<td>Wang</td>
<td>根据 AU 和离散表情的联合分布统计结果为训练样本推断出 AU 伪标签，并通过对抗训练确保模型预测的 AU 标签分布与推断的 AU 标签分布一致</td>
<td></td>
</tr>
<tr>
<td>2019</td>
<td>Peng, Wang</td>
<td>把面部动作单元识别和表情图像生成当作一个对偶任务，在训练阶段利用部分标注的 AU 数据和完全标注的离散表情数据进行模型训练，并通过对抗训练确保模型所生成的 AU 标签和离散表情标签的联合分布与真实的联合分布一致</td>
<td></td>
</tr>
<tr>
<td>2018</td>
<td>Zhang</td>
<td>基于表情相关的 AU 概率分布以及表情无关的 AU 概率分布，设计了用于训练 AU 检测模型的多个约束项</td>
<td>实现了训练阶段无 AU 标注样本条件下的 AU 检测</td>
</tr>
</tbody></table>
<p>上述半监督和弱监督 AU 检测方法能够在一定程度上缓解模型对于标注数据的依赖。总体而言，当前弱监督的 AU 检测方法往往借助于离散表情和 AU 之间的联合分布等先验知识，其存在两个关键问题：</p>
<ol>
<li>联合分布的统计来源数据不足</li>
<li>统计结果不统一</li>
</ol>
<p>由此推断的 AU 伪标签具有相当的歧义性，在此基础上训练得到的 AU 检测模型与监督方法相比并不具备优势。如何更合理地利用离散表情和 AU 之间的先验知识，在此基础上利用无标注或者弱标注的外部数据提升 AU 训练样本的多样性，具有显著的探索空间。</p>
<hr>
<h4 id="基于动态视频的-AU-检测方法"><a href="#基于动态视频的-AU-检测方法" class="headerlink" title="基于动态视频的 AU 检测方法"></a>基于动态视频的 AU 检测方法</h4><img src="/cda9211f/3.png" class>

<p>动态的视频序列天然包含了更丰富的上下文信息，能够准确反映面部动作的渐变过程（起始——高潮——结尾），因而视频对于面部动作的产生具有更准确的描述能力。已有的研究结果表明，在模型的训练过程中综合利用时序信息有助于<br>提升低强度 AU 的检测精度。当前基于动态视频的 AU 检测方法主要采用长短时记忆单元 LSTM 或 3 维卷积神经网络 3D-CNN 建模视频帧的时序特征，或者利用视频帧之间的光流信息进行 AU 检测。此外，为了减轻模型对于标注数据的依赖，一些工作采用视频之间的运动信息作为监督信号，以自监督的方法学习 AU 特征。</p>
<hr>
<h5 id="时序特征学习方法"><a href="#时序特征学习方法" class="headerlink" title="时序特征学习方法"></a>时序特征学习方法</h5><p>当前基于视频的时序特征学习方法往往首先采用卷积神经网络 CNN 提取逐帧的空间特征，然后采用 LSTM 建模时序信息。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2016</td>
<td>Jaiswal, Valstar</td>
<td>采用一种结合 CNN 和双向长短时记忆单元 Bi-LSTM 的时序特征学习方法，该网络模型能够同时学习输入图像的几何特征、局部表观特征，以及时序特征</td>
<td></td>
</tr>
<tr>
<td>2017, 2018</td>
<td>Chu, Mei</td>
<td>采用一种联合 CNN 和 LSTM 的时序特征学习方法，该方法使用 CNN 提取图像的空间特征，使用 LSTM 建模视频帧之间的时序特征</td>
<td></td>
</tr>
<tr>
<td>2017</td>
<td>Li</td>
<td>基于联合 CNN 和 LSTM 的方法，采用面部特征点裁剪出图像的一组局部区域，并结合 LSTM 建模输入视频帧之间的时序特征</td>
<td></td>
</tr>
<tr>
<td>2019</td>
<td>Yang</td>
<td>采用 3D-CNN 建模输入视频帧的时序特征，并融合目标帧图像的空间特征进行 AU 检测</td>
<td></td>
</tr>
</tbody></table>
<p>此外，一些工作采用视频帧之间的信息差异用于 AU 检测。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2019</td>
<td>Wu</td>
<td>根据目标帧与中性人脸帧之间的差异学习与身份无关的 AU 特征表示。该方法需从视频序列中手工标记出中性人脸图像，并在模型的训练过程中输入来自同一视频的两帧图像</td>
<td>在针对未知个体进行 AU 检测时具有良好的泛化能力，其缺点在于训练和测试阶段均需要输入个体的中性人脸图像</td>
</tr>
</tbody></table>
<p>另外还有一些方法尝试利用任意连续不同帧之间的光流信息进行 AU 检测。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2019</td>
<td>Yang</td>
<td>采用单帧人脸图像作为模型输入，首先预测出输入人脸图像与中性人脸图像之间的光流信息，然后使用光流信息进行 AU 检测</td>
<td>该方法在测试阶段不需要输入个体的中性人脸图像，具有更强的灵活性</td>
</tr>
</tbody></table>
<hr>
<h5 id="基于动态视频的自监督-AU-检测方法"><a href="#基于动态视频的自监督-AU-检测方法" class="headerlink" title="基于动态视频的自监督 AU 检测方法"></a>基于动态视频的自监督 AU 检测方法</h5><p>近年来出现了一些基于动态视频的自监督 AU 检测方法。自监督方法在训练阶段通过定义无注释的前置任务，为下游任务的特征学习提供代理监督信号。考虑到面部动作单元的激活本质是人脸局部区域肌肉的运动，该类运动信息天然存在于人脸视频的不同帧之间，因此视频帧之间的运动信息可直接作为前置任务的代理监督信号，用于学习得到适用于下游 AU 检测任务的图像特征。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2018</td>
<td>Wiles</td>
<td>提出了一种自监督的人脸属性特征学习方法（Fab-Net），该方法设计了一种编码器——解码器的模型结构</td>
<td>实验证明该方法学习得到的特征可用于离散表情分类、AU 检测等多种人脸分析任务</td>
</tr>
<tr>
<td>2019</td>
<td>Li</td>
<td>进一步设计了一种孪生循环自编码网络，以自监督的方式从无标注视频数据中学习出与头部姿态无关的 AU 特征</td>
<td>通过面部动作的先验知识，设计了一系列自监督约束，所学习的 AU 特征具有良好的头部姿态无关性，并取得了良好的 AU 检测效果</td>
</tr>
</tbody></table>
<p>总体而言，基于视频的弱监督 AU 检测方法合理利用了 AU 的定义及先验知识，能够有效缓解 FACS 标注不足的问题，并具有更强的解释性。然而，该类方法在训练阶段依赖海量的无标注视频数据。相比于性能提升的增益，训练数据量的增长更为显著，这一点也是自监督学习方法的通用问题。此外，当前自监督学习方法并不能端到端地进行 AU 检测。如何在自监督学习方法的训练阶段合理利用一些标注数据，提升训练数据的性能增益是一个值得探索的研究方向。</p>
<hr>
<h4 id="其他模态-AU-检测方法"><a href="#其他模态-AU-检测方法" class="headerlink" title="其他模态 AU 检测方法"></a>其他模态 AU 检测方法</h4><p>除了采用静态图像和动态视频，近期开始有一些研究工作尝试采用其他模态数据用于 AU 检测。与图像相比，点云数据具有更高的分辨率和丰富的空间信息，并且具有良好的姿态无关性。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2019</td>
<td>Reale</td>
<td>在人脸的五官附近手工选择 16 个点，并以这些点为中心，采样出相应的局部点云用于 AU 检测</td>
<td></td>
</tr>
</tbody></table>
<p>此外采用红外图像进行 AU 检测能够显著减轻光照变化带来的影响。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>作者</th>
<th>方法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>2019</td>
<td>Liu</td>
<td>采用红外图像辅助 AU 检测，该方法使用 CNN 提取图像特征，该特征被同时用于 AU 检测，以及重建输入图像所对应的红外图像</td>
<td>该方法所学习的 AU 特征具有更强的光照不变性</td>
</tr>
</tbody></table>
<p>实际场景中个体呈现的面部表情往往伴随着丰富的头部姿态变化、遮挡等情形，且图像中容易出现明显的光照变化。采用点云、红外图像等数据进行 AU 检测能够在一定程度上解决 RGB 图像模态过于单一的问题，并能够有效减轻头部姿态和光照变化等不利因素的影响。然而目前相关的数据库较少，采集点云或红外等数据具有较高的经济代价。</p>
<hr>
<h3 id="代表性-AU-检测方法性能对比"><a href="#代表性-AU-检测方法性能对比" class="headerlink" title="代表性 AU 检测方法性能对比"></a>代表性 AU 检测方法性能对比</h3><p>下表列举了 2016 年以来的代表性 AU 检测方法，以及这些方法在 BP4D、DISFA 数据库上的平均检测精度 F1-score。（F1-score 是精确度和召回率的调和平均数）</p>
<img src="/cda9211f/4.png" class>

<p>结果表明：</p>
<ol>
<li>当前基于静态图像的弱监督 AU 检测方法与监督方法相比并不具备性能优势（说明相关的弱监督方法具有明显的挖掘空间，该类方法需要进一步结合 AU 的问题定义和先验知识，合理利用外部数据和标注信息）</li>
<li>与采用静态图像相比，基于动态视频的 AU 检测方法能够取得更高的检测精度，说明视频帧之间的时序信息具有重要意义</li>
<li>基于动态视频的 AU 检测方法中，除了建模连续帧之间的时序特征，另外采用注意力机制关注人脸的局部关键区域，综合利用监督学习方法和弱监督学习方法，有望进一步提升 AU 检测精度</li>
</ol>
<p>各种代表性方法采用了不同的深度学习模型结构：</p>
<ol>
<li>ResNet 网络结构<ul>
<li>AU R-CNN（Ma, 2019）采用了 ResNet-101</li>
</ul>
</li>
<li>VGG 网络结构<ul>
<li>ROI（Li, 2017）</li>
<li>ROI-T1（Li, 2017）采用了 VGG-16</li>
<li>AU SRERL（Li, 2017）采用了 VGG-19</li>
</ul>
</li>
<li>自行设计的网络结构<ul>
<li>JAA-Net（Shao, 2018）</li>
<li>ARL（Shao, 2019）采用的模型结构包含两层块状结构，每层块状结构包含三路并行分支用于提取多尺度特征</li>
<li>PAttNet（Ertugrul, 2019）采用了一种轻量级模型结构，该结构仅包含 3 个卷积层和 1 个全连接层</li>
<li>DSIN（Corneanu, 2018）采用了自行设计的网络结构，包含 8 个卷积层和 2 个全连接层</li>
<li>TCAE（Li, 2019）采用了一种全卷积结构，包含 8 个卷积层</li>
</ul>
</li>
</ol>
<p>识别结果表明，采用多层的残差网络结构有助于取得更高的 AU 检测精度。</p>
<hr>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>作为一种客观的人脸表情分析手段，面部动作单元检测相关技术一方面取得了相当的进展，另一方面仍然不能完全满足实际应用需求。相关方法仍然存在较大的探索空间，目前尚有如下关键问题值得关注：</p>
<ol>
<li>FACS 数据库标注不足的问题<ul>
<li>基于 AU 的先验知识，综合利用无标注的图像或视频数据学习鲁棒的、判别性更强的 AU 特征</li>
</ul>
</li>
<li>不同姿态下 AU 检测问题<ul>
<li>充分挖掘视频序列里自然包含的 AU 和头部姿态变化，采用弱监督的方法学习出与头部姿态无关的 AU 特征，减轻头部姿态变化带来的影响</li>
<li>考虑采用 3 维点云等输入数据有望实现不同姿态下鲁棒的 AU 检测</li>
</ul>
</li>
<li>领域适应 AU 检测问题<ul>
<li>可以考虑采用对抗等方法学习得到与领域无关的 AU 特征</li>
</ul>
</li>
<li>不常见 AU 检测精度过低的问题<ul>
<li>需要一方面增大训练数据，另一方面借鉴当前应对长尾分布数据的新思路，设计出适用于 AU 检测的新方法，提升激活频率较低的 AU 识别精度</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-2019微表情综述Analysis on Emotion Detection and Recognition Methods using Facial Microexpressions</title>
    <url>/da2179f4.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2019_Analysis_on_Emotion_Detection_and_Recognition_Methods_using_Facial_Microexpressions._A_Review.pdf" data-height="500px"></div>

<p>论文链接：<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8969925">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8969925</a></p>
<span id="more"></span>

<hr>
<h3 id="自动分析的步骤"><a href="#自动分析的步骤" class="headerlink" title="自动分析的步骤"></a>自动分析的步骤</h3><p>面部表情的自动分析包括三个步骤：<strong>获取面部图像</strong>，<strong>提取并表示感兴趣的数据</strong>，<strong>识别表情</strong></p>
<hr>
<h3 id="面部表情计算分析的局限性"><a href="#面部表情计算分析的局限性" class="headerlink" title="面部表情计算分析的局限性"></a>面部表情计算分析的局限性</h3><p>表情包含有关人脸身份和表情变化的信息，因此提取的特征通常是表情变化和身份特征的混合体。</p>
<ol>
<li><p><strong>光照影响。</strong>从不同方向和不同强度照亮面部的方式对特征提取有重大影响。如果关键区域（例如眼睛或嘴巴）的光线昏暗，这会影响特征提取并干扰面部表情识别。</p>
</li>
<li><p><strong>只关注于姿势。</strong>心理学家将这些表情按姿势或自发性进行分类，在外观和时间特征方面彼此不同。而自动化检测的面部表情识别系统专注于姿势表情，而我们的日常交互具有自发的面部表情，这大大降低了这些自动化系统的识别准确性。</p>
</li>
<li><p><strong>持续时间短，强度低，数据集小。</strong>大多数研究人员面临着基于微表情识别情绪的一个很大限制是缺乏标准的微表情数据库，这使得训练精确的微表情识别系统非常困难。</p>
</li>
</ol>
<hr>
<h3 id="数据表示的方法"><a href="#数据表示的方法" class="headerlink" title="数据表示的方法"></a>数据表示的方法</h3><p>数据表示有两种方法：<strong>基于特征的几何方法</strong>和<strong>基于外观的方法</strong></p>
<ol>
<li><p>基于特征的几何方法<br>在基于特征的几何方法中，使用图像处理技术提取脸部点（唇角，眼中心，眉毛边缘和鼻尖），获得的坐标将创建代表脸部几何形状的特征向量。</p>
</li>
<li><p>基于外观的方法<br>基于外观的方法逐帧分析视频，并使用图像过滤器提取特征向量。这可以应用在整个脸部或特定区域。</p>
</li>
</ol>
<hr>
<h3 id="面部表情识别方法"><a href="#面部表情识别方法" class="headerlink" title="面部表情识别方法"></a>面部表情识别方法</h3><ol>
<li>基于图像</li>
<li>基于视频</li>
<li>基于3D表面</li>
</ol>
<p>识别过程包括一些特定步骤，如下图：</p>
<img src="/da2179f4/1.png" class>

<p>其中最重要的几步有：<strong>面部检测</strong>，<strong>预处理</strong>，<strong>面部特征提取</strong>，<strong>识别</strong>。</p>
<hr>
<h3 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h3><p>面部表情与面部动作不同，将中立状态与任何其他情感表情进行比较时，识别它们要容易得多。此外，面部具有永久性特征和暂时性特征。<strong>眼睛和嘴唇充当永久性特征，而面部线条和表情皱纹充当暂时性特征。</strong></p>
<p>微表情具有三个重要特征：<strong>持续时间短，强度低，它们是原型面部表情的片段。</strong></p>
<p>面部动作编码系统（FACS）是人类面部运动的分类系统，其基础是最初由Carl-Herman开发并由Ekman，Friesen和Joseph进行更新的系统，具有44个动作单元（AU）来描述面部表情。</p>
<p>与情绪有关的七个基本面部动作可以由脸部以下区域表示：<strong>双眉的左右边缘</strong>，<strong>眼睛的左右边缘</strong>，<strong>嘴巴</strong>和<strong>脸颊的左右边缘</strong></p>
<hr>
<h3 id="最近研究"><a href="#最近研究" class="headerlink" title="最近研究"></a>最近研究</h3><ol>
<li><p>Yao S , He N , Zhang H , et al. Micro-expression recognition by feature points tracking[C]// International Conference on Communications. IEEE, 2014.</p>
<p> 因为跟踪每个重要特征点以进行微表达检测需要大量数据，Yao等[11]决定选择特定的工作点和相关的动作单位（AU）（如唇缘），因为它们更易于检测和追踪。提出了一种微表情识别跟踪和特征点量化的方法。面部区域通过训练霍夫森林（HF）以提取特征点。在测试过程中，第一个图像帧被分为几个区域，面部区域将通过HF进行嘴唇轮廓描绘测试。跟踪学习检测算法接收嘴唇边缘的位置，并且可以自己学习和跟踪特征点。该方法适用于嘴部位置非常重要的情绪。所提出的方法解决了选择对准基本点的位置限制问题，并提供了对微表达的可靠描述。</p>
<p> <strong>主要选择检测的部位有：</strong><br> <strong>a. 嘴唇边缘作为特征点。与鼻子边缘和眉毛边缘点相比，嘴唇边缘的变化更加明显，这意味着嘴唇边缘的特征点更易于检测和跟踪。</strong><br> <strong>b. 选择动作单元12和16。动作单元12和16两者均与唇缘特征点有关系。 这些动作单元可以代表两种基本情绪，即快乐和厌恶。</strong></p>
</li>
<li><p>Zhang Z , Cui L , Liu X , et al. Emotion Detection Using Kinect 3D Facial Points[C]// IEEE/WIC/ACM International Conference on Web Intelligence. ACM, 2016.</p>
<p> 也基于面部点，但是3D，Zhang[5]等建议识别三种不同类型的人类情感：悲伤，快乐和中立。 本文运用 Kinect V2.0记录人的面部表情在一段时间内的变化（他们邀请参与者自己做的数据集）。对于每个帧，将捕获1347个面部3D点，从中选择100个关键面部点。 然后，使用移动中间滤波器消除噪声，并将数据流划分为具有均匀尺寸的几个切片（考虑样本），从中提取有效属性。对这三类表情的分类效果较好，但是没有考虑光照等环境干扰，并且是从整个面部提取点，根据FACS编码，应该从眉毛眼睛嘴唇等提取特征点会更有说服力。</p>
<p> <strong>主要运用3D面部检测部位：</strong><br> <strong>每个帧检捕获出1347个面部点并提取出更具代表性的100个点进行时域、频域、时频域的特征提取。</strong>（计算点之间的偏差、峰度、标准差，对每个轴进行傅立叶变换，分别计算功率谱密度（PSD）的均值和标准差等）</p>
</li>
<li><p>Wang, Su-Jing, Yan, Wen-Jing, Li, Xiaobai,等. Micro-Expression Recognition Using Color Spaces[J]. 2015.</p>
<p> Wang等 [2]提出了一种不同的方法，颜色空间模型，张量独立颜色空间（TICS）。 具有微表达的彩色视频被视为四阶张量，即四维数组。前两个维是空间信息，第三个维是时间信息，第四个维是颜色信息。他们将第四维从RGB转换为TICS，其中颜色分量尽可能独立。同时还基于FACS编码系统定义了一组关注区域（ROI），并为每个ROI计算动态纹理直方图。</p>
<p> <strong>主要检测部位：</strong><br> <strong>将面部动作单元AU划分为大的16块ROI，每个ROI对应一个或多个AU。</strong></p>
</li>
<li><p>Davison A K , Lansley C , Ng C C , et al. Objective Micro-Facial Movement Detection Using FACS-Based Regions and, Baseline Evaluation[J]. 2016.</p>
<p> Davison等[12]基于FACS定义了一个由26个区域组成的人脸模板，然后使用3D HOG（定向梯度）直方图提取每个区域的时间特征。他们在卡方距离中搜索局部区域的细微面部运动。 最后，使用自动峰值检测器来检测超出自适应基线阈值的微动。该方法通过忽略不助于面部肌肉运动的面部区域来改善局部特征表示。</p>
<p> <strong>主要检测部位：</strong><br> <strong>与（3）类似，根据FACS将面部区域分成26个区域。</strong></p>
</li>
<li><p>Li X , Yu J , Zhan S . Spontaneous facial micro-expression detection based on deep learning[C]// 2016 IEEE 13th International Conference on Signal Processing (ICSP). IEEE, 2016.</p>
<p> [17]的作者使用深度多任务学习方法来训练用于面部界标定位的深度卷积神经网络（CNN），这在微表情分析中至关重要。面部区域分为12个ROIS。 然后，他们将鲁棒的光流方法与HOOF功能相结合，以评估面部肌肉的运动方向。作为检测微表达的分类器，他们使用了SVM。</p>
<p> <strong>主要检测部位：</strong><br> <strong>检测出68个标志点，并根据此与FACS编码将面部分为12个ROIS。</strong></p>
</li>
</ol>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>有多种面部检测方法：</p>
<ul>
<li>特定的操作点[11]</li>
<li>3D点[5]</li>
<li>色彩空间模型[2]</li>
<li>基于FACS的面部模板[12]</li>
<li>动态图[14]</li>
<li>Gabor小波滤波器[8]</li>
<li>向量量化和码本选择[16]</li>
<li>CNN [17，18，19]</li>
</ul>
<p>同样，对于情感检测，可以使用：</p>
<ul>
<li>跟踪学习检测算法[11]</li>
<li>不同种类的分类器[5，8，14，15，17]</li>
<li>直方图[2，12，13，17]</li>
<li>神经网络[18，19]</li>
</ul>
<p>尽管人脸检测和情感识别使用了不同的方式，但是识别的准确性在70％至85％的范围内，仅在特定情况下更高[13]，对于某些类型的情感则更易于检测[8，15]。这些自动的面部表情识别系统将注意力集中在姿势上的表情上，而不是自发地出现在我们的日常互动中。这是可以解释的，因为要检测后者要困难得多。</p>
<hr>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>[1] V. Bettadapura, “Face expression recognition and analysis: the state of the art”, ArXiv 2012.<br>[2] S.-J. Wang, W.-J. Yan, X. Li, G. Zhao, C.-G. Zhou et al., “Micro-expression recognition using color spaces”, IEEE Transactions on Image Processing, 24(12), 2015, pp. 6034–6047.<br>[3] D. Matsumoto, J. LeRoux, C. Wilson-Cohn et al., “A new test to measure emotion recognition ability: Matsumoto and Ekman’s Japanese and Caucasian Brief Affect Recognition Test (JACBART)”, Journal of Nonverbal Behavior, 24(3), 2000, pp. 179-207.<br>[4] T. Wu, S. Fu, G. Yang, “Survey of the facial expression recognition research”, International Conference on Brain Inspired Cognitive Systems, 2012, pp. 392–402.<br>[5] Z. Zhang, L. Cui, X. Liu, T. Zhu, “Emotion detection using Kinect 3D facial points”. IEEE/WIC/ACM International Conference on Web Intelligence (WI), 2016.<br>[6] R. Sharma, B. Kaushik, “Facial expression recognition: a survey”, International Journal of Computer Applications, 153, 2016, pp. 32-36.<br>[7] B. Bhushan, “Study of facial micro-expressions in psychology”, Understanding Facial Expressions in Communication, pp. 265–286, 2014.<br>[8] P. Zhang, X. Ben, R. Yan, C. Wu, C. Guo, “Micro-expression recognition system”, Optik - International Journal for Light and Electron Optics, 127(3), 2016, pp. 1395–1400.<br>[9] W.-J. Yan, S.-J. Wang, Y.-J. Liu, Q. Wu, X. Fu, (2014). “For micro-expression recognition: database and suggestions”, Neurocomputing, 136, 2014, pp. 82–87.<br>[10] M. Takalkar, M. Xu, Q. Wu, Z. Chaczko, “A survey: facial micro-expression recognition”. Multimedia Tools and Applications, 77(15), 2017, pp. 19301–19325.<br>[11] S. Yao, N. He, H. Zhang, O. Yoshie, “Micro-expression recognition by feature points tracking”, 10th International Conference on Communications (COMM), 2014.<br>[12] A. Davison, W. Merghani, C. Lansley, C.-C. Ng, M.H. Yap, “Objective micro-facial movement detection using FACS-based regions and baseline evaluation”. 13th IEEE International Conference on Automatic Face &amp; Gesture Recognition, 2018, pp.642-649.<br>[13] A. Davison, W. Merghani, M.H. Yap, “Objective classes for micro-facial expression recognition”, Journal of imaging, 4, 2018.<br>[14] F. Xu, J. Zhang, J. Z. Wang, “Microexpression identification and categorization using a facial dynamics map”, IEEE Transactions on Affective Computing, 8(2), 2017, pp. 254–267.<br>[15] L. Stanciu, F. Blidariu, “Emotional states recognition by interpreting facial features”, E-Health and Bioengineering Conference (EHB), 2017, pp. 273-276.<br>[16] X. Huang, G. Zhao, X. Hong, W. Zheng, M. Pietikäinen, “Spontaneous facial micro-expression analysis using Spatiotemporal Completed Local Quantized Patterns”. Neurocomputing, 175, 2016, pp. 564–578.<br>[17] X. Li, J. Yu, S. Zhan, “Spontaneous facial micro-expression detection based on deep learning”. IEEE 13th International Conference on Signal Processing (ICSP), 2016, pp. 1130-1134.<br>[18] R. Breuer, R. Kimmel, “A deep learning perspective on the origin of facial expressions”, Computer Vision and Pattern Recognition, ArXiv 2017.<br>[19] M. Takalkar, M. Xu, “Image based facial micro-expression recognition using deep learning on small datasets”, International Conference on Digital Image Computing: Techniques and Applications (DICTA), 2017<br>[20] H. Costin, C. Rotariu, I. Alexa, et al., “TELEMON - A complex system for real time medical telemonitoring”, 11th Int. Congress of the IUPESM/World Congress on Medical Physics and Biomedical Engineering, Munich, Germany, Sept. 07-12, 2009.</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://blog.csdn.net/weixin_45440065/article/details/106231607">https://blog.csdn.net/weixin_45440065/article/details/106231607</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>CSIG云上微表情-第7期（2020）-基于深度学习方法的微表情识别与检测</title>
    <url>/346fffd0.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=627623900&bvid=BV1At4y1e7ck&cid=250990541&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<p>微表情能够揭示人类试图隐藏的真实情绪。微表情识别的研究旨在让机器有足够的智能，能够从人脸视频序列中识别人类的真实情绪。为了促进心理学领域和计算机视觉领域针对微表情的进一步研究，由中国图象图形学学会（CSIG）举办、CSIG机器视觉专业委员会承办，中国科学院心理研究所的王甦菁博士组织一系列云上微表情的学术活动。本次云上微表情讲座将阐述西南大学电子信息工程学院情感计算课题组在过去五年内同国内外合作单位，围绕深度学习方法在微表情识别与检测中的研究工作，由彭敏、张志豪和王重阳三位博士研究生进行报告。</p>
<hr>
<h3 id="Part-1-视频和最大帧的识别"><a href="#Part-1-视频和最大帧的识别" class="headerlink" title="Part 1 视频和最大帧的识别"></a>Part 1 视频和最大帧的识别</h3><p>（彭敏，博士研究生，中科院重庆绿色智能技术研究院）<br>（陈通，教授，西南大学电子信息工程学院）</p>
<img src="/346fffd0/1.png" class>

<hr>
<h4 id="研究一：基于视频的端到端微表情识别"><a href="#研究一：基于视频的端到端微表情识别" class="headerlink" title="研究一：基于视频的端到端微表情识别"></a>研究一：基于视频的端到端微表情识别</h4><img src="/346fffd0/2.png" class>

<p>两个常用的微表情数据集：CASME I、CASME II</p>
<p>如何用现有的深度学习网络去训练两个有限集的微表情数据样本，两个数据集帧率不同</p>
<p>如何把视频输入到网络里去训练</p>
<img src="/346fffd0/3.png" class>

<p>提出了双尺度的深度神经网络，双通道（结构相同，考虑到数据量有限所以模型相对浅层避免过拟合）</p>
<p>对于帧率不同用双通道，60帧单通道、120帧双通道</p>
<p>输入的并不是原始序列，而是经过了光流处理，解决个体差异和背景噪声的问题，光流也是相对比较稀疏的特征，更好地提取表情的运动关系</p>
<img src="/346fffd0/4.png" class>

<p>比单尺度和传统方法都好</p>
<img src="/346fffd0/5.png" class>

<p>使用3D卷积神经网络去提取时序信息，输入的是光流特征，相对于原始信息更容易收敛、不容易抖动</p>
<p>结合不同的帧率尺度，能提取更多信息（相对与归一到同一个帧率）</p>
<img src="/346fffd0/6.png" class>

<p>使用卷积神经网络，但数据量有限，能否使用现有的图像数据集进行与训练？</p>
<p>整个视频输入存在数据冗余，很多帧是没有用的，微表情持续时间短、局部运动，微弱的时空信息</p>
<hr>
<h4 id="研究二：基于最大帧的端到端微表情识别"><a href="#研究二：基于最大帧的端到端微表情识别" class="headerlink" title="研究二：基于最大帧的端到端微表情识别"></a>研究二：基于最大帧的端到端微表情识别</h4><img src="/346fffd0/7.png" class>

<p>视频输入改为某一帧输入（标注）</p>
<img src="/346fffd0/8.png" class>

<p>权重初始化、宏表情数据集进行数据迁移、注意力机制残差模块</p>
<img src="/346fffd0/9.png" class>

<p>三个层进行特征融合Channel Concat</p>
<img src="/346fffd0/10.png" class>

<img src="/346fffd0/11.png" class>

<p>参数量增长不明显，但结果比较客观</p>
<img src="/346fffd0/12.png" class>

<p>可视化分析：愤怒表情。第三列加入了注意力比较符合</p>
<img src="/346fffd0/13.png" class>

<p>利用最大帧的方式比较可行，基于最大帧更多考虑的是哪一帧能展现更多信息</p>
<img src="/346fffd0/14.png" class>

<p>漏掉了很多表情的持续信息，能否考虑非人工标注的最大帧？</p>
<p>挖掘视频帧集合，更能表现微表情信息？</p>
<hr>
<h3 id="Part-2-基于卷积网络和滑动窗处理的检测"><a href="#Part-2-基于卷积网络和滑动窗处理的检测" class="headerlink" title="Part 2 基于卷积网络和滑动窗处理的检测"></a>Part 2 基于卷积网络和滑动窗处理的检测</h3><p>（张志豪，博士研究生，中科院心理所）<br>（陈通，教授，西南大学电子信息工程学院）<br>（傅小兰，研究员，中科院心理所）</p>
<img src="/346fffd0/15.png" class>

<img src="/346fffd0/19.png" class>

<img src="/346fffd0/16.png" class>

<img src="/346fffd0/17.png" class>

<img src="/346fffd0/18.png" class>

<img src="/346fffd0/20.png" class>

<img src="/346fffd0/21.png" class>

<img src="/346fffd0/22.png" class>

<img src="/346fffd0/23.png" class>

<img src="/346fffd0/24.png" class>

<img src="/346fffd0/25.png" class>

<img src="/346fffd0/26.png" class>

<img src="/346fffd0/27.png" class>

<img src="/346fffd0/28.png" class>

<p>这个长视频大约持续200帧，真实的峰值帧约为第91帧，最大值检测为第152帧（但实际这一帧在眨眼），使用滑动窗更准确，更能排除其他的运动干扰</p>
<img src="/346fffd0/29.png" class>

<img src="/346fffd0/30.png" class>

<p>（该项目是第一个使用深度学习来对微表情进行检测的）</p>
<hr>
<h3 id="Part-3-基于最大帧和相邻帧融合的识别"><a href="#Part-3-基于最大帧和相邻帧融合的识别" class="headerlink" title="Part 3 基于最大帧和相邻帧融合的识别"></a>Part 3 基于最大帧和相邻帧融合的识别</h3><p>（王重阳，博士研究生，伦敦大学学院人机交互中心）<br>（陈通，教授，西南大学电子信息工程学院）</p>
<p>最大帧有它的好处，基于视频也有它的好处，能不能融合起来？</p>
<img src="/346fffd0/32.png" class>

<p>跨数据集的微表情识别，有哪些因素是比较重要的？是否使用单帧是足够的？</p>
<img src="/346fffd0/31.png" class>

<p>对每个视频段获取最大帧，一般是由数据采集者给定，不然假定是视频的中间帧（以及前后各32帧作为临近帧）</p>
<p>空间特征是单独的一个CNN，时序特征用两层的LSTM（输入前先用光流法提取更数值化的特征）</p>
<img src="/346fffd0/33.png" class>

<p>通过深度学习仅用时序是最好的，其次是融合的效果。仅用最大帧降低了很多</p>
<img src="/346fffd0/34.png" class>

<p>微表情的时序特征对于跨数据集非常重要，只用最大帧的话效果是大打折扣的，跨数据集时信息量不足。</p>
<img src="/346fffd0/35.png" class>

<p>微表情的信息是比较稀疏的，用视频的话信息量有些冗余，猜想存在一段帧集合使得识别率达到最高。</p>
<img src="/346fffd0/36.png" class>

<p>给定一个视频段，对每一帧提取空间特征，通过一个新设计的可适应性的关键帧挖掘机制，筛选出n个最有信息量、最能代表当前表情的关键帧，再用一个GRU网络进行识别。全程是端到端的，无需使用光流，即输入一个视频，就能得到结果。</p>
<img src="/346fffd0/37.png" class>

<p>仅用时序的注意力机制的话效果并不好，所以在时序的注意力之上，提出了额外的机制</p>
<ol>
<li>局部的自注意力机制的学习</li>
<li>加权之后的帧进行全局比较，得到全局关联系数（一个index的指针列表）</li>
<li>对这个指针列表进行稀疏筛选</li>
</ol>
<img src="/346fffd0/38.png" class>

<p>提升非常高！！</p>
<img src="/346fffd0/39.png" class>

<p>那三步的消融实验，组合起来最有效</p>
<img src="/346fffd0/40.png" class>

<p>网络的设计是有一定的泛化性的，只要是输入的视频是稀疏的，想要找到特殊帧基本都有效。使用了一个宏表情的视频数据库CK+，做了一个hold-out validation，根据这个网络及其变种（输入全部帧并不筛选、进行时域插值），依然能得到很好的结果，比起同时期发表的对于CK+的paper也是很有可比性的。</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐讲座</category>
      </categories>
  </entry>
  <entry>
    <title>CCF学生领航计划（SPP）第一期-英文学术论文写作指南</title>
    <url>/268942.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=257653921&bvid=BV1aY411T7aF&cid=753603997&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<p>这是 <strong>CCF</strong> 专门制定的<strong>学生领航计划</strong>中的一个系列活动，希望对于<strong>刚入门</strong>或者<strong>刚刚准备写学术论文</strong>的同学有所帮助和启发。</p>
<p>本次报告面向刚刚开始从事科学研究或者将要从事科学研究的低年级研究生和高年级本科生，提供一次规范且系统的“科研与英文论文写作”入门学习，本次活动的亮点和意义主要包括以下几方面：（1）从内容组织上看，本次报告并非笼统的介绍论文写作方法论，而是以一系列鲜活的论文实例对比一篇论文高水平论文和一篇普通论文的各组成部分（标题、摘要、引言、相关工作、研究方法、实验分析、总结与展望、参考文献等），详细分析他们在写作逻辑、英文规范、图表等各方面的差别，并总结形成论文各部分的写作可规范建议，为刚刚开始英文写作的学生提供具有实操参考价值的写作范例；（2）从讲者讲述方式看，讲者在报告中贯穿了本人从学生走到科研道路上的经验、教训和心路历程，让学生对高水平学术论文的写作不再停留于“表面套路和繁荣”，而是通过规范的写作思维和方法深入理解科学问题、清晰展现科研成果，形成一套自身可不断迭代完善的科研方法，同时严格遵守学术道德。</p>
<p><strong>讲者简介：</strong>于静，中国科学院信息工程研究所副研究员，CCF YOCSEF总部AC委员，CCF多媒体技术专业委员会委员。于静致力于计算机视觉领域研究，尤其关注计算机视觉-自然语言处理相结合的跨模态智能领域。在TIP, TMM, PR等国际期刊和ICML, CVPR, AAAI, ACM MM, IJCAI, WWW等国际会议发表学术论文40余篇，亦担任TMM, PR, CVPR, ICCV, AAAI, IJCAI等学术期刊和会议审稿人。主持和参与国家自然科学基金、国家重点研发计划项目、中科院战略性先导科技专项项目等各类国家级/省部级科研课题10余项，面向国家网络安全需求提供跨模态分析技术和解决方案。<br><strong>个人主页：</strong><a href="https://mmlab-iie.github.io/">https://mmlab-iie.github.io/</a><br><strong>B站：</strong><a href="https://space.bilibili.com/301285406">于老师的日常</a></p>
<p><strong>报告题目：</strong>《英文学术论文写作基础》</p>
<p><strong>报告摘要：</strong>本报告首先介绍学术研究与学术论文写作的关系，引出刚刚开始从事科学研究的低年级研究生和高年级本科生在英文学术论文写作中常见的问题及原因。报告重点以一些具体论文实例介绍高水平英文学术论文的科学思维、写作规范和修改过程，详细剖析一篇高水平论文在标题、摘要、引言、相关工作、研究方法、实验分析、总结与展望、参考文献等各部分的写作思路、相互关系、常见问题及改进方法，分享论文写作和论文修改的关键时间节点和建议，以及我本人从学生走到科研道路上的经验、教训和心路历程，希望对同学们有所启发和鼓励。</p>
<hr>
<h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p>研究报告主要分为 <strong>6 个方面</strong>：</p>
<img src="/268942/1.png" class>

<p><strong>此次第一期</strong>主要重点讲前两部分，从<strong>价值观</strong>和一些<strong>方法论</strong>上面去给大家做基础性的介绍，内容包括：</p>
<ol>
<li>做什么样的学术研究</li>
<li>学术研究和文写作之间关系</li>
<li>怎样以 CCF A 类的论文的标准去要求自己</li>
</ol>
<p><strong>第二期</strong>会深入到具体实操性的方法，包括但不限于：</p>
<ol>
<li>图表怎么画</li>
<li>英文怎样写得通俗易懂</li>
<li>行文逻辑规范</li>
<li>日常上面怎么样去积累</li>
</ol>
<p>因为大部分时间大家其实还是独立做科研的，希望通过这一次培训，大家至少达到 70 分以上的能够独立写论文、做科研的能力。</p>
<hr>
<h3 id="学术研究和论文写作"><a href="#学术研究和论文写作" class="headerlink" title="学术研究和论文写作"></a>学术研究和论文写作</h3><img src="/268942/2.png" class>

<h4 id="什么是学术研究？"><a href="#什么是学术研究？" class="headerlink" title="什么是学术研究？"></a>什么是学术研究？</h4><p><strong>技术</strong><br>比喻成走野路。在工程项目里会遇到特别多没有解决的实际应用场景里的问题，这些问题其实就会涉及到现有的一些成熟的技术。针对这个问题，比如说做数据清洗、数据分析、数据处理，以及怎样把这些技术组合起来，去解决一个实际中从来没有见过的一个新的应用问题。我们把这个问题以比喻成在一个特别大的荒无人烟的山区里去走一条野路，我需要自己踏出一条路，但是前景目标是非常明确的。</p>
<p><strong>学术研究</strong><br>比喻成攀珠峰。是在一个从来没有人去做的未知方向上，你能够去达到一个更高的制高点，这其实是没有人走过的路，也没有人尝试甚至未知的一条路，所以其实学术上面希望我们有这种对未知世界、未知知识的一个探索能力。</p>
<p><strong>科研</strong><br>比喻成逛景区。在这技术和学术中间还有一条路，其实也是很多论文或者说身边一些同学在做的一些工作。我们现在很多学术研究的问题，是给好了数据集、给好了一些 matrix 评测的标准、甚至给好了到底要做哪些实验，这样的实验方法你只需要在上面刷出来一个最新的指标，然后在既定的一条路上把所有该做的实验都做过，这样的工作可能简单的称之为科研。其实这条路大家已经规定好了，只需要按部就班地做出来。这其实也是现在很多审稿人遇到的一个问题，就是发现所有的论文内容都很规范，所有的实验基本上都做了，但是看不到它对这个领域和知识的推进，这其实也是并不是今天这个报告里想给大家去重点介绍的，所以今天想说重点是怎样在学术方面能够使科研往前探索，以及怎么样清晰地表达清楚。</p>
<hr>
<img src="/268942/3.png" class>

<h4 id="为什么要做学术研究？"><a href="#为什么要做学术研究？" class="headerlink" title="为什么要做学术研究？"></a>为什么要做学术研究？</h4><p>不管读硕士、读博士、还是本科期间就已经开始做科研，大家的目的是什么？目标是什么？有些同学可能是想毕业、想挣更多的钱、想继续读书……还有很多确实有自己的兴趣爱好、有这种好奇心想探索未知等等，大家的期待其实都是不一样的。在不一样的期待的情况下，发现其实读书做科研的整个过程，其实在这三个方面都给了我们从短期到长期非常大的系统性的培养。</p>
<img src="/268942/4.png" class>

<p><strong>最初的一个阶段</strong><br>也就是在读博士期间最容易体会到的，就是我们是否具备系统地解决问题的能力，包括做科研的过程。其实这样的一个过程，跟你做其他任何事情，不管你工作还是组织一次活动，都是一样的。</p>
<ol>
<li>到底要解决一个什么样的问题（怎么样发现问题），发现一个值得研究的问题。</li>
<li>基于这个问题，要怎样系统性的调研，其他人的成果做了哪些方法、做成什么程度、有什么样的问题。</li>
<li>根据现有的一些情况，提出一个更可行、可有效的方法，以及通过实验、实践的方式去验证，最后复盘不断地强化这个思维模式和整个解决问题的能力。</li>
</ol>
<p>所以其实在整个的工作，甚至整个的人生的各种方面的这些问题上面，其实都是一样的方法论，但是在读博士期间，你会有这样的压力和对自己的强化的训练的过程，培养起来你这样非常系统的一个能力。</p>
<p><strong>培养科学素养</strong><br>所谓的科学素养就是对一个问题认识、分析、逻辑表达的能力。每年顶会录用上千篇文章，很多同学在初步读论文的时候就想到底有哪些论文是值得读的，哪些是要泛泛地读，其实在这里面它的质量和它对你的启发是参差不齐的。怎么样快速做出判断，找到引领性的这种工作去跟随，其实就是在读完博士之后或者博士期间能够具备一个对学术能力以及学术影响力的一个判断。此外具备了这样的判断能力，在写论文、在输出、在大会和别人沟通的时候，你就会建立这种结构化的思考方式（现在有哪些类型的方法，怎样去有条理地梳理清楚）。学术不是一个闭门造车的过程，通过大量交流、清晰地表达观点，甚至是非常尖锐而且前沿的一些观点，这个也是做科研能够培养起来的一个科学素养。</p>
<p><strong>长线思维</strong><br>最主要的可能对整个人生有长期作用的，就是你的价值观。怎么做到能不急功近利、怎么在投稿被拒甚至延毕的这样一个不断挑战自己的过程中，不患得患失、稳步地推进、交流共享、持续互惠地积累，这个是一个建立长线思维，甚至是你能够走多高、走多远的一个本源的动力。</p>
<p>所以做科研其实在这三个层面上，这 12 个方面都能够提高我们的能力，后面可以更关注于怎么样去提高这些底层的能力，下一次报告会重点去讲一些我们实操层面方法论的东西。</p>
<hr>
<img src="/268942/5.png" class>

<h4 id="科研的过程"><a href="#科研的过程" class="headerlink" title="科研的过程"></a>科研的过程</h4><p>在科研早期，其实都会对一个领域从初步认识开始，有些老师可能会让你直接去调研，有些可能给你一个 idea 让你直接去做，不管是怎样一种方式，你都会从 0 ~ 1 开始完成第一个工作，这个时候是需要老师给你比较详细的指导，然后你把第一个工作做到极致，发表第一篇 CCF A 类的论文，这个是你的第一个阶段。</p>
<p>进入到第一个阶段之后，其实在做的过程中就会知道有很多觉得做的不完善的地方、可以改进的地方，就有各种各样的不靠谱的 idea。有了这些 idea 之后，就会不断地跟老师再去深入讨论，这个时候你也不知道哪个 idea 是靠谱，能够在发出高水平论文。所以这个时候你在跟老师碰撞的过程中，确定了第二阶段要做的工作选题，然后再把它做到极致，发表出来你第二篇的 CCF A 类的论文。</p>
<p>这个过程之后，你会发现你做这些小的研究点不足以激起你的兴趣了，你就开始进入到研究阶段的中期，开始想做更有一些影响力、更挖掘本质的一些共性的、底层的问题。这个时候其实又会花你大量的时间精力去思考和调研，你这个时候其实也具备了一定的独立做科研的能力、独立找问题的能力，这个时候你能够自己有靠谱的 idea、找到合适的问题，然后把它做到极致，完成你的第三篇 CCF A 类的论文，这个时候其实你的能力已经又达到了一个新的高度（我们这里面的所有的文章数量都不是绝对的，只是体现你的能力的提升过程）。</p>
<p>到博士的中后期，你发现已经能做出比较有影响力的工作之后，其实又陷入了一个新的瓶颈，就是怎么样在博士毕业之后去延续做你的科研，甚至做 5 年、10 年这样你的一个学术生涯。这个时候在博士的后期你就需要去探索更广阔的方向，去拓展你的眼界，决定后面要怎么样去发展。这个时候其实更关键的一个是当你能独立做科研，不管是你去学术界还是企业界，你需要去带团队、去独立地承担一个方向的研究。那么这个时候你能不能具备指导你的师弟师妹他们从 0 ~ 1 完成他们的第一篇 CCF A 类的论文，这个时候其实又是带团队、培养人的一个能力的提升，到这个时候之后你就开始找教职或者规划你的方向，以及在毕业之后申请 funding。</p>
<p>所以其实整个的就像现在这里讲可能是一个相对完整的研究生涯的一个培养、上学阶段的培养的过程，但是每个同学可能经历的阶段不一定完全契合，所以今天我希望能够跟大家一起去探讨怎么样从 0 ~ 1 去完成第一篇 CCF A 类的论文。</p>
<hr>
<img src="/268942/6.png" class>

<h3 id="学术论文与写作思路"><a href="#学术论文与写作思路" class="headerlink" title="学术论文与写作思路"></a>学术论文与写作思路</h3><p>研究过程和论文写作过程内容是一致的。选择研究领域、选择领域问题、提出研究问题的设计方法、实验验证、最后总结，这个是整个的研究过程。研究过程里在每一个过程中涉及到的方法都不太一样。当然确定的主题的时候，很多同学可能有导师指导，也可能导师指导的时间并不多，需要自己去找方向或者找人请教。那么在确定了方向之后，需要去大量的阅读文献，这里面其实前两部分在下一次报告里面会给大家讲具体怎么样去选文章、读文章、积累文章、讲文章以及从中找到 idea。到下一个阶段时要提出一个合理的方法，这方法足够新、足够好、足够可行，这些是在真正去实操之前要确定的，接着通过大量的实验去验证和分析。</p>
<p>所以整个的研究过程基本是这样的，那么对应我们的写作过程是什么样的呢？后面会把整个的写作过程和研究过程中对应上，希望大家就说不只停留在理解怎么写作，其实你在思考写的过程中，对应你在研究的过程中，整个研究过程中也要用相同的思维方式去做研究，这样写的时候才不至于发现没有动机、idea 也说不圆等等一系列的问题。</p>
<hr>
<h4 id="写论文遇到的问题"><a href="#写论文遇到的问题" class="headerlink" title="写论文遇到的问题"></a>写论文遇到的问题</h4><p>在我们真正去讲写论文的方法之前，我们先归纳一下，看看我们到底现在写论文都有哪些问题？</p>
<img src="/268942/7.png" class>

<p>这个是特别明显的一个问题，就是老师和同学的一个认知存在不一致。可能学生希望老师一步一步的指导，老师又可能有时候希望学生带我。怎样和老师达成一个特别好的协作关系？其实科研老师和学生就是一个互相合作、互相促进的关系。</p>
<img src="/268942/8.png" class>

<p>第二个你发现你论文写出来的东西，在你眼中好像特别宏大，然后导师眼中可能就是一堆垃圾，审稿人眼中可能就是小学生的作文。所以问题是你选择了一个很好的主题，并且做出了很好的实验结果，但是你写出来的东西并没有真正的把你的这能力体现出来，或者说你论文的水平、科研研究成果的水平，是一个很大的问题。</p>
<img src="/268942/9.png" class>

<p>另外一个，当我能够很好构思的时候，我发现没办法准确地表达我的主题。可能一开始设计的很完美、想象的很好，但是最终画出来的就像一个草图一样。怎么样去准确表达，其实背后的原因也是有没有把逻辑和底层贡献想清楚。</p>
<img src="/268942/10.png" class>

<p>另外就是我们的论文，很多时候审稿人经常会给大家提的叫做 over claim 对吧？你在 Attract 或者 Introduction 的时候，把这个问题和贡献说得很大，但是方法和实验结果并没法去印证所说的这些问题，所以整个论文的 story 是前后不一致的。</p>
<img src="/268942/11.png" class>

<p>这样的问题其实在我们真正的写论文之初，就需要把所有的内容都考虑进去。其实另外一个也是我觉得最大的一个问题：持续的拖延。可能觉得写一个 A 类论文其实只是可能所有工作的 10%，但其实我觉得写论文甚至能占到了 40% 甚至以上，它其实和你的科研是同步协同去完成的，所以科研拖延写论文是一个很大的问题。</p>
<img src="/268942/12.png" class>

<p>最后一个，你自己觉得老师反馈给你有问题、同学反馈给你有问题的时候，你觉得总是越改越差、越改越不知道怎样去把论文向 A 类的水平去改好，所以如何去逐步完善我觉得可以去思考。</p>
<img src="/268942/13.png" class>

<p>前面这些问题导致我们本来一个很好的科研成果（可能是一个 A 类的研究成果），通过拖延以及这些问题，导致最后可能发了一个 C 类水平的论文，这些其实都是我们很常见的问题。</p>
<img src="/268942/14.png" class>

<p>归纳一下前面列了这么多的问题，其实不管是别人看不懂还是文章表达不清楚，本质上还是你的写作思路存在一定的偏差：你以为可以这么写，但其实有更科学的方法；赶不上 deadline；英文规范，包括怎样把这个表达得更准确；日常积累，防止你到最后 deadline 的时候才知道工作量有多大。</p>
<img src="/268942/15.png" class>

<hr>
<h4 id="论文应该怎么样去写"><a href="#论文应该怎么样去写" class="headerlink" title="论文应该怎么样去写"></a>论文应该怎么样去写</h4><p>今天我们主要介绍写作思路，就是学术论文到底应该怎么样去写。</p>
<img src="/268942/16.png" class>

<p>在一篇论文真正开始做之前，其实很大程度上就决定了你这个论文到底能不能发一篇 A 的会议或者期刊。这个论文到底研究的内容是不是在探究一些本质性的科学问题，这个其实就决定了能不能发 A 类。</p>
<img src="/268942/17.png" class>

<p>举个例子，这两篇论文跨越了 10 年，右边的是在 2011 年的时候发的一篇 CCF C 类的一个期刊，左侧是前两年发在 CCF A 类上面的一个期刊会议。这两个工作其实都是在做跨模态融合的一个工作，就是本质上它解决的问题在方法上面都是类似的，但是在 2011 年的时候做这个工作其实方法非常简单，当时还是手工定制的特征，我们发现这些特征好像有一些互补的性质，就最简单的就拼在一起把它融合，然后获得了更好的 performance。在当时没有深度学习、没有这么多开源代码的情况下，还是做了很多大量的实验、出了很多代码，所以可以认为有一些 contribution。但是从现在来看，左侧的这一个工作其实也同样是在做信息融合，但是更想探究一些本质的问题，比如说在讨论这个人对感知的信息、消防栓认识的时候，到底都从哪几个角度去判断的？这些信息在大脑里怎样去融合关联，这种机制怎样去体现在机器的模型设计上面？</p>
<p>这个机制从人去做到这件事是受到了启发，是现在做信息融合甚至关联知识的一个比较关注的问题，而且方法通过验证后也具有普适性。所以左边和右边如果刚入门的同学觉得他们都是在做信息融合、特征融合，方法论上都差不多，但是为什么左边能发 A 右边只能发 C，其实我想说再从它们的利益和提出的问题上面就很多的差别差距。我们现在总结一下 A 类的其实在问题上有理有据的，而且是足够具体的一个问题，现在大量的论文都说想解决一个什么问题，比如想解决信息融合不好的问题，这其实并不是一个具体的问题。而 CCF C 类的或者说更低水平一些的论文，可能就说现在这个研究很热、都在研究哪种工作，所以我们也去研究这个问题，这就是差别。在方法上面 A 类的论文大家去分析，可以看到它的每一步的设计，它的目的和它的出发点都是非常明确的。但是你看 C 类或者说其他的论文讲述的方式就是我第一步怎么做，第二步怎么做，第三步怎么做，它其实是一个像是技术报告一样的写法。</p>
<p>在实验方面，A 类的论文会逐一的去把所有动机和模型设计的一些机制全都证明，但是大部分现在的论文，甚至觉得有一些看起来发了不错的会议和期刊的论文，也是缺乏分析的，可能只是说我达到了 SOTA，把大家做的实验 obligation 什么都做一遍，就觉得 ok 了，审稿人可能挑不出来太大的毛病，但其实我不觉得这种论文是值得大家去借鉴和跟随的，所以后面会去给大家讲科研跟写作的关系，以及我们可能遇到的问题，就是想从本质上跟大家说，背后的这些对科研的认识、对写作的认识，其实决定于你在真正写作的时候会投入多大精力、以怎样的态度去对待他，也是决定了你到底能把这个东西写成什么样。</p>
<hr>
<img src="/268942/18.png" class>

<h4 id="动笔"><a href="#动笔" class="headerlink" title="动笔"></a>动笔</h4><p>我们什么时候就可以开始写？其实在真正决定要开始做一个方向的时候，就会有一个PPT，就相当于一个 project 的 slice，就开始总结所有的思路，当然除了实验结果以外。当你有了实验初步的比较靠谱的结果之后，就可以开始动笔写 introduction 了，因为在做实验完善的时候甚至你在读最新的论文的时候，你会发现写的哪些是不自洽的，你会不断的完善思路，指导你后面所有的方法和实验的写作。</p>
<hr>
<img src="/268942/19.png" class>

<h4 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h4><p>什么叫标题？标题其实就是对这个工作到底解决了什么样的核心问题，最大的技术创新是什么的一个问题，如果你没有给它明确的定义，其实你是没法解决它的。所以你把大概方法做出来、基本上有初步结果的时候，你就要去思考你的贡献和到底解决的核心问题是什么。题目其实非常重要，好的标题一定要反映出问题是什么、最大的创新是什么。</p>
<img src="/268942/20.png" class>

<p>另外就是这个题目要起的易于传播、易于记忆，否则大家去引用你的工作或者提到你的工作的时候，还要花特别长的时间去描述，其实是不利于你的影响力扩散的。</p>
<p>比如说第一个问题，第一个题目 from shallow to deeper。这个题目看到的时候，其实你对它到底做了些啥，可能没有什么概念，但现在同学包括很多论文往往非常喜欢起这样的题目，看起来很高大上，但是我觉得论文还是以朴实为主，真正的点到本质问题明确地说清楚为主，所以这个题目我觉得是太宽泛。</p>
<p>第二个这个也是组里的同学曾经写过的一个题目，他想起一个比较好的模型的名字，然后他把它的整个的标题里面涉及到这个名字的一些首字母或者什么的，它可能出现在不同单词的不同的位置，它把它变大变成大写字母，然后把它还 let 出来。但这种题目如果你作为题目是非常不规范的，我们知道正常的题目肯定是每个单词的首字母大写，大家不要写这种题目。</p>
<p>第三个就是像这种 understanding like humans，虽然说它本身是有这些认知机理的启发的，但是大家记住很多现在科研或者科学领域没有确定的东西，不要拿它来做题目，就让审稿人觉得你很偶尔肯定或者是你做的东西并没有一个真实的依据。</p>
<p>然后第四个比如 graph neural networks for image text motion。如果这个是在 2017 年出现的一个工作，那时候 GNN 刚出现也许你把它用在了 image 上面是一个好的题目，但如果放在了三四年之后，现在这个题目完全看不到你和大量的现有工作的一个差别。</p>
<p>然后下一个题目大家可以看 plug-and-play novel tree loss function，upgraded transformer framework。这个工作把大量的形容你工作的一些形容词放在了你的题目里，其实是非常的冗余且浪费了大量精力，抓不到这个工作最终的一个技术上的创新。</p>
<p>然后最后一个其实也是我觉得大部分同学起的模型的题目叫比如说像 KBGN 就是没有任何含义，也不朗朗上口，可能是一些你的关键词、首字母的缩写，但是其实不利于传播。</p>
<img src="/268942/21.png" class>

<p>大家可以看到我这里其实也列了几个我觉得起的比较好的一些 CV NLP 模式 learning 的题目，他们其实都是符合我们刚才说的逻辑的，包括比如说现在 CV 里面在做这个图文生成的，你看题目非常简洁，它的核心技术能力就是在没见过的情况下你能够去生成，然后它解决的问题就是图到文或者文到图的generation。然后包括微软亚研做的 swin transformer，怎样提一个朗朗上口的的名字，同时这里面涉及到方法 shifted windows，以及做的一些核心的技术和解决的问题，当然我刚说的不一定所有的题目都会覆盖，但是我觉得在一个你初步第一篇工作的时候，尽量还要把你的这些核心的东西能够明确的在题目里体现清楚，就不要搞特别玄的一些题目。</p>
<hr>
<img src="/268942/22.png" class>

<h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>摘要其实是题目的一个扩展，它其实包含了包括动机、亮点、效果等等。这些关键的问题，我拿 CVPR2020 有代表性给大家讲一下摘要包含哪几个部分，所以大家以后写论文其实就去 check 一下你自己的论文，每一句话是不是在表达这个内容以及句和句之间是不是这样的逻辑关系，我觉得你的摘要就可以达到 60 分了。</p>
<img src="/268942/23.png" class>

<p>这篇摘要里面它做的是一个场景图生成的一个工作，那么它在前两句话就先说明了现在场景图生成这个任务，它面临的技术挑战是什么。那么基于这个挑战，现有方法存在的问题是什么？一句话就把它说清楚，不要再罗列 relative work。第三部分不一定是一句，但是尽量很简短的就表明你的方法大概的思路是什么，一句话能概括你的方法的思路。方法概括完了之后，它到底亮点是什么？就是我为什么基于这个思路能够解决上面现有的这些方法实现不了、解决不了的问题，能够很逻辑自洽的去把这个问题能够解释清楚。最后一部分也就是点明你方法的优势，还 let 你的一个 contribution 是什么，你的适用性广、是不是达到 SOTA，如果有实验的好的 performance 你也可以放上，所以摘要基本上一定要大部分 cover 这些部分的内容，而且它们之间的逻辑肯定是环环相扣的。</p>
<hr>
<img src="/268942/24.png" class>

<h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p>引言我觉得是论文最难写的部分，所以可能大部分老师帮同学改的时间最长的就是引言。</p>
<img src="/268942/25.png" class>

<p>引言和 Abstract 内容覆盖的内容是一致的，只是引言的内容会是 Abstract 更详细的一个扩展和说明，我用相同的颜色标明了其实相同表达的内容。比如说在 Introduction 上的第一段，我们也需要对现在的背景做很详细的介绍，引出我们的问题。</p>
<p>大部分同学分不清楚在讲背景时候提出的问题和你后面讲 related work 的时候提出的问题，它们俩之间到底什么样的关系？我想说特别重要的就是你在讲背景的时候，你点出的问题是你做的 task 或者你要解决你做的领域里面最核心的本质的问题。比如说我们这里面解决的是基于知识的数学问答，就是人看一个东西的时候，人是既能关联到它的视觉表象，又能关联它的语义，又能关联到外部知识，怎么样让它机器能够 adapt 的去关联这些信息，其实就是你要解决好任务的本质问题。所以这个东西是本质问题，那么你在 relative work 的时候，也就是在第二部分的时候，你要把现有的方法基本上觉得这个任务归纳成几类，每一类存在什么样的一个问题。</p>
<p>然后就是一个很具体的小问题了，而你的背景是一个大背景，而你在评价现有方法的时候，一定是你真的读过这些文章，你是准确对它理解了，而且你的评价是客观的，不是为了突出你的 contribution 去故意贬低某些方法的不足，然后在后面我们怎么样去介绍我们自己的方法，既然你就把问题很明确的点出来之后，你的方法就要说你具体 1 2 3 步怎么样去自洽的解决了这个问题。这个时候大家有的时候经常忽略做了一个这样的方法，它为什么能够解决这个问题，以及每一步的哪一个环节到底是解决了这个问题，这个是需要你在这一部分要把它明确的说出来的，而不需要你展开讲具体的怎么做。</p>
<p>然后最后一部分凝练你的 contribution，这一块其实是大部分同学在写第一篇文章的时候都比较欠缺的，怎么样去准确的评估你的 contribution？我这里给大家可以几个角度的思考：</p>
<ol>
<li>是否提了一个新的问题</li>
<li>是否我提了一个 dataset、新的 task，比如说我解决这个问题，大家从来没有从认知的角度去做，我第一次从这个角度去做，我探索了一个什么样的新的方法，或者说我提了一个什么样的新的框架，在这个框架下面你是不是有新的方法？对这个框架问题的一些新的方法，它是不是达到了新的 SOTA，以及你是不是具备除了达到 SOTA 以外额外的新的能力，比如说你有组合泛化的能力，你有推理的能力等等，这些都是你可以写到 contribution</li>
</ol>
<p>但是大家记住就像做 PPT 一样，你的任何一个 contribution 只表达一个意思，你说的一点只表达一个意思，你不要把这些又有结果又有方法都写在一个 contribution 里面。如果它不足以撑起一个 contribute 标准，建议你还是能从刚才提的这几个角度或者其他的更重要的角度去总结你的贡献。</p>
<hr>
<img src="/268942/26.png" class>

<h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><p>相关工作一定要包括需要理解本文相关的这些知识，不要把它只在正文里当做一个参考文献。</p>
<p>第二个就是所有跟你解决这个问题相关技术上的一些方法，不管是你这个 task 上的方法还是你用到的这个技术，它相关的一些 related work，因为你提到你的 contribution 是什么，你 contribution 相关的这些不同维度的 related work 都要去介绍，但是绝对不要罗列对应的论文。</p>
<p>另外我们做的是图神经网络相关的方法，这个方法相关的一些工作，以及我所有最后几行 highlight 的部分都是现有方法和我们方法的一个最大的区别，就是我们在现有方法上我们这篇文章的 contribution 是什么？所以大家做的时候一定要把这个东西总结出来，否则你的 related work 其实对于审稿人对于你这篇论文的加分是没有的，所以其实你在写完方法之后，你其实就可以写 related work 了，因为你就知道你的方法涉及到哪几方面的技术。</p>
<hr>
<img src="/268942/27.png" class>

<h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>方法这一块我觉得应该是论文最好写，也是大家最熟悉的一部分。如果说 introduction 一定要尽早写，方法就可以做完实验的时候就可以开始写了，甚至你开始做的时候也可以开始写。方法最主要的就是你要换位思考，你要真正的把逻辑梳理清楚之后，考虑哪些模块要先写、哪些要后写、哪些重点写、哪些简略写，而不要以你真正在整个科研过程中投入时间的比例，去划分你写作的这一部分的比例。</p>
<p>另外一个很大的一个问题，就是大家缺少对模型设计的动机分析，就是大家只是 step 1 2 3，但是为什么这样设计、这一步到底在解决整个问题的链条里起到了什么样的关键作用？这个是需要在你的论文里写出来的。</p>
<img src="/268942/28.png" class>

<img src="/268942/29.png" class>

<p>刚才讲了 A 和 C 最大的一个区别，基本上现在看好的论文都会有一个特别一目了然的 framework，也就是很多审稿人他可能还不看你的内容细节实现的什么，就看你 framework 就知道你论文的 contribution 问题在哪儿，所以非常关键。那么下一次我会重点可能拿一个工作去给大家讲到底 framework 怎么从 0 ~ 1 的把图画出来。这个画出来之后基本上你的所有方法的组织和写法之间的关联就非常清晰了。我们看 framework 其实输入和输出要非常明显，然后到底包含了哪几个模块，你的构建可能又分三部分，然后你的推理又分两部分，这些你要非常清晰的，甚至拿一个具体的例子贯穿你整个模型的框架，这样是最好理解的。一图胜千言，你很难用文字那么准确的把你的内容表达出来。</p>
<img src="/268942/30.png" class>

<p>你的图其实和你的正文里的小标题，这个章节和子章节要一一对应，而且他们之间肯定是逻辑一致的。当然它们之间到底是什么逻辑，这个小标题的名字怎么样最准确，而且要表达你创新性的方式，这个标题是很要去花时间琢磨的。</p>
<img src="/268942/31.png" class>

<p>接着你在具体的每一个小章节前面是需要花一段去讲你这个方法的 motivation 的，所以我标绿的其实都是在讲你这一部分的方法到底要解决什么样的问题、这个方法和上一步是什么样的关系，以及我这个方法做完之后它能达到什么样的效果，便于后面一步或者整个问题的解决。所以这些一定要有一段，但是现在其实大家都是欠缺的，好多时候为什么审稿人觉得整个看下来看不太出来你的问题，是因为你其实没有写清楚。</p>
<img src="/268942/32.png" class>

<p>然后在后面你具体的一个方法，一个大的步骤下来，它其实还有很多小的细节，大家可能有的时候半页之后，具体的就是一个步骤、第一个公式、第二公式、第三个公式，让审稿人很难去抓住你的逻辑，所以你其实可以用这种加粗或者小标题的形式，把你的内部的逻辑表达出来，在题目上也要慎重的去考虑。</p>
<img src="/268942/33.png" class>

<p>最后你在介绍整个方法之前，一定要有总的一段话去把问题梳理清楚、去把整个模型设计的逻辑和方法总体介绍清楚。你如果不在这说明的话，审稿人在他的意见里面肯定也会质疑，所以你在大量的可行方法之中，你为什么选择要把它说清楚，或者说它可以尝试不同的方法。</p>
<hr>
<img src="/268942/34.png" class>

<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>其实最主要的大家有的时候会遇到你的实验和你的方法、动机并没有形成一个整体印证，而是各论各的，虽然实验可能确实放了十几二十个实验，但是大部分实验都是在说一些不痛不痒的东西，比如说你做了好多的参数分析，然后你做了特别多的可视化，但是你又没有真的体现你要解决的问题。比如说你具有泛化能力对吧？你怎么样做实验证明你有泛化能力。那么你想解决的问题到底应该通过哪样特殊的实验去证明，这种实验可能甚至你需要自己去设计，甚至提一些自己的 metric 去证明，在你真正设计实验的时候，你要诚实的去举例子，不要总是跑 1 个的跑 10 个，然后拿 1 个最好的出来，这样其实你代码开源之后，follow 你的人无法验证或者无法复现，对你其实是减分的，你整个学术生涯是这篇论文是跟随你一辈子的。你后面的分析一定要给出合理的解释，不要只有一个实验结果，或者说我的所有的分析都是告诉它数据长什么样，数据是什么样，谁比谁多，这个不叫分析，你把背后为什么会这样，和你的设计有什么样的关联要说清楚。</p>
<p>另外最重要的这个 limitation 就是任何的方法如果你说不清它的边界，你就很难说出它具备什么样的能力，就像刚才说的你为什么要先写一个标题，标题其实就是在定义你的边界，那么你的方法也是你最后说出实验之后，你的方法到底什么样的数据适应，什么样的不适应，它就有什么样的特点，你必须把这个能分析出来，而不是自己凭空的去解释。</p>
<p>最好的方法就是你大量的去看优秀的论文，我其实觉得 machine learning 的论文大家可以好好去学习一下，因为它一定会证明它在各种的任务领域上都具有这种通用的能力，所以它是一个很好的基础性的机器学习的方法，那么这种方法论文里面的实验就设计得非常多、非常巧妙，分析也非常深入，所以大家多去看看 machine learning 的论文我觉得是有帮助的。</p>
<img src="/268942/35.png" class>

<img src="/268942/36.png" class>

<p>我想说明的一点，你在讲方法、讲实验的时候，一定要有层次、有逻辑，不要一股脑的把所有的比如说 obligation 就一股劲这样讲。比如说我的 obligation 分成哪几个维度对吧？我横向的维度对吧？我每个模块是怎么样的，然后我纵向的我每一个模块内部。我把关键方法替换掉又是怎么样的，然后我又去和其他的就是一些方法去比较，这里面的 obligation 一定要有层次，而且基于层次去组织你所有的模型。同样的你的方法的可解释性，通过可视化也好、通过一些其他的模块证明也好，也是要有层次的。可解释在哪几个方面可解释，它解释了什么样的内容，它都是要有对应的依据和你的论文里对应的分层地介绍。</p>
<img src="/268942/37.png" class>

<img src="/268942/38.png" class>

<hr>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><img src="/268942/39.png" class>

<p>最后结论其实有时候就是很难区分结论和 Abstract 的区别，那结论其实最主要的就是你的发现是什么。你做了这么多的分析和实验，最后的发现和总结，而且你要介绍你自己的这部分东西的总结，不要把整个大背景、对整个领域的所有问题都解决了，就不要夸大，尽量简洁。另外最终你要把你的 future work，就是你方法具有哪些的局限性之后，你下一步怎么做，其实也便于这个领域的人看你是不是可以沿着你这个方向要继续往前做 follow 你。</p>
<img src="/268942/40.png" class>

<hr>
<h4 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h4><img src="/268942/41.png" class>

<hr>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><img src="/268942/42.png" class>

<p>另外参考文献，虽然到最后审稿人可能已经没有精力和时间去看了，但是这个决定于你这个人的一个科学素养。是不是按照期刊会议的格式大小写名字拼写是不是正确，是不是有些会议全称有些就是缩写，这些其实都会影响审稿人对你整个的科研水平的一个判断。</p>
<hr>
<h4 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a>小总结</h4><img src="/268942/43.png" class>

<p>其实我想跟大家说整个的科研过程，我的学生在一开始确定要做这个的时候，就已经开始写边做科研边去完善它的 paper，当然最一开始没有真的写一个 paper，他只是弄了一个 PPT slice。</p>
<p>然后接着你在真正靠谱的结果出来之后，你就可以刚才写你的这些方法实验，包括你的 introduction，那么你在有第一版的 paper 之后，你自己其实就知道哪个实验做的还不够完善，你就边去完善实验，边去再写你的实验内容图表，然后再改十几次，可能最后可能才能赶上一个 deadline。</p>
<p>所以基本上周期的长度大概就跟大家一个学期上课的长度是一样的，就跟你上课大家老师先讲背景知识，然后再讲每一章，然后最后让你做作业，然后期末再有 1 个考试，其实整个就是科研的过程，如果是你第一个工作的话，其实这个 4 个月是一个我觉得比较大部分同学需要经历的一个过程。</p>
<hr>
<h4 id="其他拓展"><a href="#其他拓展" class="headerlink" title="其他拓展"></a>其他拓展</h4><img src="/268942/44.png" class>

<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><img src="/268942/45.png" class>

<p>我们今天讲的所有论文，从标题到最后参考文献，所有的内容我想大家一定要围绕一个关键点就是我们的问题。你既然已经定位到这个问题了，你所有的内容都要围绕你怎么样去定义问题、解决问题、证明你解决了问题，以及你问题解决的到什么程度，这样的一个闭环环环相扣的去说明你的方法。</p>
<p>那么其实如果我们只掌握了写作思路，我觉得它可能只是我们看路的一只眼睛，那么大家其实刚才有那么多的问题对吧？我写不完，然后我写不好我改不好怎么办？其实后面我们在下一次报告里面，我们就会讲怎么样去写作，怎么样规范的、专业的围绕读者的需求去写，以及怎么样在我们的日常积累过程中把我们的 idea、我们的数学功底、我们的英文功底、我们的写代码的能力，以及我们找 idea 的能力都能积累下来。</p>
<img src="/268942/46.png" class>

<p>那么我想有这几方面，大家就可以非常开心的像笑脸一样去面对自己的科研生涯，然后积累自己刚才说从方法论到认知能力，再到自己的长线的价值观的一个系统性的培养。</p>
<p>所以期待下一次我们的报告《学术论文写作规范和日常积累》，和大家继续分享后两部分的内容。</p>
<img src="/268942/47.png" class>

<p>这里面我也给大家介绍了留下一些参考书，其实第一本书叫做 the craft of research，我在组里面其实花了一个学期的时间，让每一个同学分别讲一章去这个介绍，其实它是一个文科的讲怎么做科研的书，它的问题、思考的角度和总结的方法适用于任何一个学科，所以特别推荐给大家。</p>
<p>然后另外北大董彬老师，他在北大讲一门课叫研究型学习，他这门课当然特别有意思，我跟他交流就是他会把学生在一个学期分成两组，完全模拟整个的你做科研和投稿审稿的所有的过程，所以大家可以去看它有一个官网有课程的内容和 PPT，大家可以去学习。</p>
<p>最后我想再送给大家一句，我特别喜欢也是鼓励我的一句话：只要你敢想，而且一直持续不断的去坚持做，你就可以到达任何地方，你可以做成任何事儿。</p>
<p>所以我希望大家能够去坚持自己感兴趣的能做好的东西，然后有什么问题大家都可以随时交流，这些其实在你的人生整个的发展过程中，是会对你有非常大的帮助，任何困难都是提高的最大动力。好，我今天的报告内容就到这了，好，谢谢各位同学。</p>
<hr>
<h3 id="QA-环节"><a href="#QA-环节" class="headerlink" title="QA 环节"></a>QA 环节</h3><ul>
<li><strong>Q：从本科开始学习计算机技术到研究生阶段找到研究方向之前，这一段时期内关于科研我都可以做些什么，有没有大概的步骤之类的？</strong><br>A：你现在想大二就开始做科研是吧？其实之前带过这种本科同学去做科研，其实他的目标比较明确，可能我想保研、要不然我想出国、然后就想还是做一些能发论文的这种 idea，所以我其实觉得比较适合本科去做的是最好能够找到一个有具体研究方向的老师，然后给你具体的一个技术点的指导，然后你沿着这个点，你可以去找一篇经典，或者说现在比较新的文章去复现，然后基于复现的结果接着调研相关的一些小问题，相关的一些工作，然后把这些工作能够找到一些关联和启发，在你复现的结果之上可能做一些 inquiry mental 的改进。我觉得这个是一开始你需要先去了解领域，你要动手去做一些东西，而不是停留在大量的可能读 paper 调研，因为可能你读完之后还是没有特别深的感觉，但是你具体到底从哪个点去着手，我觉得如果身边没有一个指导的话，你自己可能可以去看一下最近一两年的顶级会议上大家都在做什么，然后找一个感兴趣的方向。所以我的建议可能是觉得还是从具体的方法、具体的一个技术点着手去做一些改进的方法，然后后面你可能有想法了，你第二个、第三个你再去提一些比较深入的 idea。</li>
</ul>
<hr>
<ul>
<li><strong>Q：老师能不能快速讲一下会议怎么改成期刊</strong><br>A：之前我记得王昌栋老师上次学术论文写作工作坊还专门详细讲了内容。主要我觉得有几点，你真正的改的时候，你在框架或者模型，还有是不是能够具有更好的领域或者任务的泛化，这些要提一个更通用或者说更新、更往前推进的一个方法，而不能你 conference paper 的原始模型，你可能就是多做了一些实验，现在是行不通的啊。但是另外有一些现在至少 CV 的一些期刊是不接收 6 页以上，我记得是 6 页以上会议再转期刊的这样的文章，所以他更希望去接受原创性的文章。如果说期刊接收改会议的文章的话，你一定要在方法上面，比如说 contribution 明显要比你的 conference paper 要多一些内容，另外你的 related work 也要做相应的扩展，因为你的方法涉及到更多的内容，另外你的模型可能已经不是原始针对一个或者针对一类方法的一个模型，可能它是一个框架，框架可以适配到任何现有的一些模型上面去，这当然只是一种思路了，以及你的实验是不是超过了你的 conference paper 另外达到一个新的 SOTA。还有更多的可解释、可分析性的这些东西。当然这里说的比较粗略了，你可以去对比一下有发会议和期刊的论文。</li>
</ul>
<hr>
<ul>
<li><strong>Q：Introduction 里面的方法介绍是要侧重挑战还是问题呢？</strong><br>A：我理解一下，你认为的挑战是现在大背景解决这个问题的就是共性的一个挑战，你的问题是现在相关方法里面存在的具体方法上的问题。如果我理解得对的话，我想说这两个都是重要的。首先你的科学问题要找准，你这篇文章的 contribution 是能发 A 还是能发 C 才能立住，那么这个立住了之后，你的方法就是你做的事肯定是重要的，审稿人就能认可。接着你的方法是不是新的，是不是对解决这个问题有贡献的，你总结出来的现有方法的问题，就是体现后面解决的方法是不是新的一个依据。因为现在方法也有很多，比如说我这个 fusion 的方法可能比较简单，我换一个更复杂的、更新的、别的领域的迁移过来，这个其实并没有针对这个问题去解决，你只是做了一些 incremental 的改进，那么现在的方法其实你从不同的维度去看它解决这个本质问题到底存在什么样的缺陷，你把这个东西真的能概括出来。后面其实提的方法，其实大家就相对的能接受，这两个是环环相扣的，都挺重要的。</li>
</ul>
<hr>
<ul>
<li><strong>Q：Contribution 和 Abstract 有什么区别？</strong><br>A：我们一般都是在 Introduction 最后一段会讲我的 contribution，其实在 Introduction 里和 Abstract 里其实是对应的，只是它的写法和它的体量不太一样。你可以看到在 Abstract 里面，其实它也包含了 Introduction 里刚才所有的内容。然后最后一部分就是你的 contribution，但只是说你在你这个地方 Abstract 的一点 contribution 的时候，相对的是最本质、最核心的 contribution，但是在你的 Introduction 里讲 contribution 的时候，一定要和你前面的方法、你的问题详细的去展开讲。这个框架也好，具体的技术也好，它到底对这个领域有什么样的推进作用，因为你有篇幅了，你就可以把它展开的讲得更细一点。</li>
</ul>
<hr>
<ul>
<li><strong>Q：推不推荐研究生写综述？那么写综述的时候，咱们今天讲的方法有区别吗？</strong><br>A：写综述我觉得分两个阶段：一个是你刚入门的时候，刚入门的时候，我其实不觉得它叫一个综述，可能是你的调研报告，因为这个时候其实你对一个领域并没有深入的，你对这个本质问题的理解，或者说你对这些工作真正的 contribution 的一个定位，所以这个时候你是把这些工作调研出来，你把它能够有效的分类组织，然后找到核心的问题，这个时候我觉得是你可以发一些偏总结性的这种，如果有接收的话，我觉得是好的，因为它能够让你用尽量凝练的语言，尽量全面的调研，把现在你要做这个事儿，能够有一个驱动力的让你调研清楚，而且可能你比如说毕业还算一篇文章对吧？综述算的话，它也算你的工作。但是其实我觉得你所谓的真正的综述应该是你真正比如说你到了博士中后期，比如说你就做跨模态的问答视觉问答，你做了大量的工作，而且你对这个领域已经非常理解了，你这个时候可能就针对这个小问题，你写一篇综述，其实综述最大的作用是除了给入门的同学看，更多的是给这个领域正在做的人看。大家更想看的是你后面到底有哪些 challenge 的可做的一些 problem，然后一些大家关注的现在方法的缺陷，以及这些方法到底在什么场景下能适用，以及它的整个的横向的比较，所以可能到你的后期你才能真正的把这个东西写得更深入。所以我其实建议如果是前期你想做这件事儿，你又不想浪费所有你总结出来的成果，你可以把它写成一个轻量级的调研报告，然后能接收的这种期刊或者会议上。另外其实现在有很多博客对吧？你也可以放影响力也挺大的。你在中后期的时候，我觉得其实你写完综述之后，你自己的大的博士论文或者硕士论文，其实就有很多的很好的素材，不管早还是晚，其实都是要去总结的。</li>
</ul>
<hr>
<ul>
<li><strong>Q：工作后去互联网企业可能涉及更多具体业务项目的开发，如何在此过程当中保持提升学术的敏感度？</strong><br>A：在高校里面的跟企业界里面的业务工作里面是有些差别的，那么业务工作上的重点可能更多是解决一些 corner case，然后学校里面更多的是在公开数据上提升一些 common case 的性能，那么这两者的学术研究区别和注意点，其实我也很希望同学们都能够真的关注。尤其是我们国内，现在大家、企业、各种行业真实的问题是什么？现在学术界尤其是大模型出来之后，我们其实在 follow 的工作都是在解决国外的一些大厂他们提的一些问题去在解决这些问题。但是国内其实你真正在工作里面，你实际业务上面，到底就是说除了一些具体的就是细节的问题之外，你觉得它本质问题可能是什么？其实你真正做了之后你就能有感觉的，而不是真正我们像 dataset 里面，你 dataset 本来就有你真正提问题的人，他未必都是真正理解问题的人，所以你自己去有感觉之后，你再回来看这种问题可能用什么样的方法去解决，我觉得这个其实是促进科研，而且能够把你的实际需求和找到的本质问题能够协同起来去做的。现在我觉得国内很多时候是这两个东西是分割的，这很考验怎么从工程里提炼本质问题的能力，所以如果你能提炼出来，就像比如做一个视频的配乐的生成，它本身是一个学术问题，但是它又是在真正的互联网，比如说视频有很大的这种应用的场景和真实背后的问题，省去了大量的人力资源。所以如果你能够找到一个关联本质问题，再去关注学术界的这些技术，你看待这些技术的视角和它对于真正解决企业界的问题能贡献的你做的东西可能会更有影响力。因为我们计算机毕竟还是一个 application 的学科。</li>
</ul>
<hr>
<ul>
<li><strong>Q：对于本科生而言有什么手段，或者是什么途径可以找到导师？</strong><br>A：如果说你在本科期间并没有接触过科研，或者说看过论文，其实我觉得这个还挺难的，因为其实你具体要做哪个方向，我之前跟北大董斌老师聊，他会有一个去考察学生的特别好的两个问题，第一个就是你为什么要来这儿，你为什么要来我们实验室？第二个就是你到底比如说未来3年、5年你有什么样的计划？其实你自己需要去网上寻找，其实如果一个老师做 research 比较长的，他都会有自己的主页，不管是各种公开的这种学术网站，还是这种教育类型的网站，你去看大家的研究方向，你去看大家的 paper，然后可能大概了解他的方向，你去调研这个方向是不是你自己真的感兴趣的研究内容。然后你再看哪些人是在做这些方向，以及哪个老师可能对这个东西做的，其实同样一个方向，大家侧重点也是非常有不一样的。另外你去问一下比如发邮件，老师其实都挺 nice 的，你去问一下今年是不是有名额招生，然后如果有的话，老师是不是可以一起在线或者什么机会去沟通一下，但是前提我特别建议大家一定要想清楚刚才那两个问题，我为什么要来这儿，对我未来要达到一个什么样的目标，其实老师是希望同学们尤其是做科研的同学，是要有自己独立的判断和批判的思维的。</li>
</ul>
<hr>
<ul>
<li><strong>Q：国外的学生有些导师指导比较少，以及授课是硕士没做过科研，那么他问如何做研究，发出第一篇就自己做研究发出第一篇论文</strong><br>A：后面下一期可能会给大家讲怎么样，如果在没有老师的情况下，或老师指导有限的情况下，你能够自力更生。这里面可以讲一讲初步的方法论，一方面你即使有老师、知道老师的作用是什么，老师的作用并不是告诉你这个 idea 能发 A 然后这个 idea 就是你就沿着做，第一步、第二步怎么做，做这种其实最大的问题就是学生在做完了这个之后，他完全不知道下面要做什么，以及在他写论文的时候完全不知道我为什么要做这个东西，他是写不出来，刚才我说的所有的每一个环节里面分析以及 contribution, motivation 这些东西的。所以我建议大家真的在你第一个阶段，即使没老师指导这其实是对你厚积薄发最大的一个能力培养的黄金时期。<br>就跟刚才本科的同学一样，你先要确定一个自己感兴趣的方向，在你真正想做科研的时候，其实你就应该先想好这个问题。在已知方向的情况下，你找到好问题以及找到好问题之后，你怎么把它做出来，并且表达出来、投出去，怎么样去调研定位问题，这里面平时怎么样去选论文、读论文、讲论文、积累 idea，以及基于这些论文你去找核心的问题，我觉得下次报告我会真的重点会讲这个东西。<br>第二个就是你怎么样把你做出来的东西写好。其实这次如果你能够后面再返过来想一想这次报告的话，可能对写作非常有帮助。<br>第三个我觉得特别关键的就是你一定要建立你的学术交流，任何的不管是你有没有老师指导，你一定要走出去，不管是咱们这种学术的报告，还是你线下的这种报告，甚至你有机会可以去参加一些国际学术活动，要去给别人介绍你的工作，通过别人的反馈，通过比你能力强、水平高的人对你的评价，去判断你哪里有问题，否则就像你写论文一样，那就越改越差，你自己是什么水平都很难定位清楚对吧？<br>所以你需要通过这种反馈，你不要认为他是在 challenge 你，你要认为任何对你的质疑，你只要能够更合理的回答出来说服他，其实你自己的东西是在提高的，所以这个过程是非常必要的，我觉得这三个是比较关键的。</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐讲座</category>
      </categories>
  </entry>
  <entry>
    <title>CSIG云上微表情-第11期（2020）-结合计算机视觉的微表情检测与识别</title>
    <url>/5e299907.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=415822781&bvid=BV18V411b7VS&cid=272458571&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<h3 id="Part-1-基于深度学习的微表情识别介绍"><a href="#Part-1-基于深度学习的微表情识别介绍" class="headerlink" title="Part 1 基于深度学习的微表情识别介绍"></a>Part 1 基于深度学习的微表情识别介绍</h3><img src="/5e299907/1.png" class>

<img src="/5e299907/2.png" class>

<p>相对与macro-expression，micro-expression更加细微，肉眼来看很难判别出来，希望通过算法来识别微表情</p>
<img src="/5e299907/3.png" class>

<p>数据集-&gt;预处理-&gt;特征提取-&gt;微表情识别-&gt;分类</p>
<p>微表情识别：宏表情迁移到微表情、基于顶点帧、基于动作单元AU</p>
<img src="/5e299907/4.png" class>

<img src="/5e299907/5.png" class>

<p>利用已有的AU关联</p>
<img src="/5e299907/6.png" class>

<p>输入的两个维度：node feature、adjacency matrix</p>
<p>N代表节点的数量，d代表每个的特征维度</p>
<p>每个GCN layer跟CNN层有异曲同工之妙（这不就跟全连接到卷积，从全局连接到部分连接；卷积到图网络，局部连接到全局自定义连接。更加稀疏了么，而且自由度更高，消除了不必要的节点连接冗余）</p>
<img src="/5e299907/8.png" class>
<img src="/5e299907/7.png" class>

<p>在普通的CNN提取人脸特征下，加入了一个AU检测的GCN，然后concat进行分类</p>
<img src="/5e299907/9.png" class>
<img src="/5e299907/10.png" class>

<p>基于上一篇论文，但思路跟前面有一点点不一样。先汇入一个3D ConvNet作为Backbone，然后经过三层GCN和sagpool，得出有用的节点信息进行分类</p>
<img src="/5e299907/11.png" class>

<p>提出AU-ICGAN去生成微表情的data。attention mask是为了将注意集中在人脸而不是背景，color mask集中注意在rgb这个通道</p>
<img src="/5e299907/12.png" class>

<p>（loss有点多看不太懂，前四个是对单张图片的，后面三个是对于视频序列的）</p>
<img src="/5e299907/13.png" class>
<img src="/5e299907/14.png" class>
<img src="/5e299907/15.png" class>
<img src="/5e299907/16.png" class>
<img src="/5e299907/17.png" class>

<p>人脸存在不对称性，多模态等…看看能不能提升准确度</p>
<hr>
<h3 id="Part-2-Local-Temporal-Pattern-and-Data-Augmentation-for-Micro-Expression-Spotting"><a href="#Part-2-Local-Temporal-Pattern-and-Data-Augmentation-for-Micro-Expression-Spotting" class="headerlink" title="Part 2 Local Temporal Pattern and Data Augmentation for Micro-Expression Spotting"></a>Part 2 Local Temporal Pattern and Data Augmentation for Micro-Expression Spotting</h3><img src="/5e299907/18.png" class>

<img src="/5e299907/19.png" class>

<p>样本量很少，5个数据集加起来也就800个左右，对机器学习很有挑战性。</p>
<img src="/5e299907/20.png" class>

<p>2013~2014年发布了CASME有小幅上升，微表情检测的F1-score &lt; 0.1，对于实际应用十分有挑战性。</p>
<img src="/5e299907/21.png" class>

<p>微表情的三个特点：持续时间短、微表情运动强度低、非常局部的面部运动。</p>
<p>主流的两种思路：比较峰值帧之间的特征（相当于传统的图像处理的方法 or 结合机器学习来做一个比较）、</p>
<img src="/5e299907/22.png" class>

<p>特征的局部提取、融合、时域上检测帧与帧之间的差别，检测到一段时间内最大的峰值为微表情，缺点是检测到的不一样是微表情，可能只是当前区间内一个比较显著的特征（并非微表情特征），由于先前已融合特征所以微表情的局部特征有可能已经被忽略掉了，优点是考虑到了微表情时长的变化。</p>
<img src="/5e299907/23.png" class>

<img src="/5e299907/24.png" class>

<p>考虑时域特征、机器学习+数据扩增、提出了一个叫做晚期融合的方法（Late fusion from local to global）</p>
<img src="/5e299907/25.png" class>

<ol>
<li>局部时空特征</li>
<li>晚期的时空融合</li>
<li>基于Hammerstein模型的数据扩增</li>
<li>一个新的验证方法和度量标准</li>
</ol>
<img src="/5e299907/26.png" class>

<p>从全局到局部再到全局，预处理、特征提取、融合与检测</p>
<img src="/5e299907/27.png" class>

<p>只选取了12个兴趣区域，眉毛、嘴角还有鼻子，鼻子作为头部运动的整体参考，区域的尺度选择是眼角内部距离的1/5。</p>
<img src="/5e299907/28.png" class>

<p>分析是基于时序的，对每一帧提取ROI，然后对这些ROI序列进行基于时序上的PCA处理，图上每个点代表一帧，点的分布代表每帧视频在时域上的分布。点与点之间的距离越长，变化得越明显；点与点之间的距离越短，变化就比较微弱。</p>
<img src="/5e299907/29.png" class>

<p>通过计算点与点之间的距离，来发现微表情的变化特征。这条曲线也就是局部时域特征</p>
<img src="/5e299907/30.png" class>

<img src="/5e299907/31.png" class>

<p>筛选一下，好的就是S-patterns，能比较好代表微表情特征，坏的就是Non-S-patterns</p>
<img src="/5e299907/32.png" class>

<p>用SVM分类一下</p>
<img src="/5e299907/33.png" class>

<p>这是第二个贡献，在检测到哪些区域发生了类似微表情的活动以后，才做一个晚期的融合。将过长或过短的检测区间去除掉。</p>
<img src="/5e299907/34.png" class>

<p>鼻子作为整体参考，可能是发生了整体的头部运动。</p>
<img src="/5e299907/35.png" class>

<img src="/5e299907/36.png" class>

<p>限制：使用CASME I大概只有78个LTPs被认为是S-patterns，所以需要进行数据扩增（基于Hammerstein模型）</p>
<img src="/5e299907/37.png" class>

<p>Hammerstein模型替代了LTP selection</p>
<img src="/5e299907/38.png" class>

<p>（这玩意啥，没看懂，有点像机器学习，训练两个参数）</p>
<img src="/5e299907/39.png" class>

<img src="/5e299907/40.png" class>

<img src="/5e299907/41.png" class>

<img src="/5e299907/42.png" class>

<img src="/5e299907/43.png" class>

<p>可以把 CASME I 变成 1w 多个样本</p>
<img src="/5e299907/44.png" class>

<img src="/5e299907/45.png" class>

<img src="/5e299907/46.png" class>

<img src="/5e299907/47.png" class>

<img src="/5e299907/48.png" class>

<img src="/5e299907/49.png" class>

<img src="/5e299907/50.png" class>

<img src="/5e299907/51.png" class>

<img src="/5e299907/52.png" class>

<img src="/5e299907/53.png" class>

<img src="/5e299907/54.png" class>

<img src="/5e299907/55.png" class>

<img src="/5e299907/56.png" class>

<p>提出了一个对微表情检测的评判标准</p>
<img src="/5e299907/57.png" class>

<img src="/5e299907/58.png" class>

<p>一些对未来的展望</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐讲座</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-Detecting Disorders of Consciousness in Brain Injuries From EEG Connectivity Through Machine Learning</title>
    <url>/de33d265.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/【2021_IEEE_Trans】Detecting_Disorders_of_Consciousness_in_Brain_Injuries_From_EEG_Connectivity_Through_Machine_Learning.pdf" data-height="500px"></div>

<span id="more"></span>

<hr>
<img src="/de33d265/1.PNG" class>

<img src="/de33d265/2.PNG" class>

<img src="/de33d265/3.PNG" class>

<img src="/de33d265/4.PNG" class>

<img src="/de33d265/5.PNG" class>

<img src="/de33d265/6.PNG" class>

<img src="/de33d265/7.PNG" class>

<img src="/de33d265/8.PNG" class>

<img src="/de33d265/9.PNG" class>

<img src="/de33d265/10.PNG" class>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-Quantifying arousal and awareness in altered states of consciousness using interpretable deep learning</title>
    <url>/a443a9c1.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/【2022_NatComm】Quantifying_arousal_and_awareness_in_altered_states_of_consciousness_using_interpretable_deep_learning.pdf" data-height="500px"></div>

<span id="more"></span>

<hr>
<img src="/a443a9c1/1.PNG" class>

<img src="/a443a9c1/2.PNG" class>

<img src="/a443a9c1/3.PNG" class>

<img src="/a443a9c1/4.PNG" class>

<img src="/a443a9c1/5.PNG" class>

<img src="/a443a9c1/6.PNG" class>

<img src="/a443a9c1/7.PNG" class>

<img src="/a443a9c1/8.PNG" class>

<img src="/a443a9c1/9.PNG" class>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>CSIG云上微表情-第12期（2021）-有限多源数据下的微表情识别方法</title>
    <url>/a1b0d33c.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=331395121&bvid=BV1nA411u7mp&cid=289604674&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<img src="/a1b0d33c/1.png" class>

<h3 id="微表情概述"><a href="#微表情概述" class="headerlink" title="微表情概述"></a>微表情概述</h3><img src="/a1b0d33c/2.png" class>

<img src="/a1b0d33c/3.png" class>

<img src="/a1b0d33c/4.png" class>

<img src="/a1b0d33c/5.png" class>

<hr>
<h3 id="发展现状"><a href="#发展现状" class="headerlink" title="发展现状"></a>发展现状</h3><img src="/a1b0d33c/6.png" class>

<img src="/a1b0d33c/7.png" class>

<img src="/a1b0d33c/8.png" class>

<img src="/a1b0d33c/9.png" class>

<hr>
<h3 id="深度模型"><a href="#深度模型" class="headerlink" title="深度模型"></a>深度模型</h3><img src="/a1b0d33c/10.png" class>

<p>时空预处理：人脸分割，人脸对齐，运动放大</p>
<img src="/a1b0d33c/11.png" class>

<img src="/a1b0d33c/12.png" class>

<p>mark是人工定义的特征，基于能量的（统计学）</p>
<p>每个k帧（10帧、20帧…）做一个帧与帧之间的差，取一个绝对值or绝对值的平方累加（L1 or L2 范数），然后得到一幅图。变化大的地方能量高，取阈值就根据二八法则。</p>
<img src="/a1b0d33c/13.png" class>

<img src="/a1b0d33c/14.png" class>

<img src="/a1b0d33c/15.png" class>

<img src="/a1b0d33c/16.png" class>

<img src="/a1b0d33c/17.png" class>

<img src="/a1b0d33c/18.png" class>

<img src="/a1b0d33c/19.png" class>

<img src="/a1b0d33c/20.png" class>

<img src="/a1b0d33c/21.png" class>

<img src="/a1b0d33c/22.png" class>

<img src="/a1b0d33c/23.png" class>

<img src="/a1b0d33c/24.png" class>

<img src="/a1b0d33c/25.png" class>

<img src="/a1b0d33c/26.png" class>

<img src="/a1b0d33c/27.png" class>

<img src="/a1b0d33c/28.png" class>

<img src="/a1b0d33c/29.png" class>

<img src="/a1b0d33c/30.png" class>

<img src="/a1b0d33c/31.png" class>

<hr>
<h3 id="问题与挑战"><a href="#问题与挑战" class="headerlink" title="问题与挑战"></a>问题与挑战</h3><img src="/a1b0d33c/32.png" class>

<p>如何平衡样本的数量？？（关键）</p>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐讲座</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-U-Net原理分析与代码解读</title>
    <url>/8607332c.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2015-U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation.pdf" data-height="500px"></div>

<p><strong>U-Net</strong> 论文链接：<a href="https://arxiv.org/pdf/1505.04597.pdf">https://arxiv.org/pdf/1505.04597.pdf</a></p>
<span id="more"></span>

<hr>
<h3 id="Unet-背景介绍"><a href="#Unet-背景介绍" class="headerlink" title="Unet 背景介绍"></a>Unet 背景介绍</h3><p>Unet 发表于 2015 年，属于 FCN 的一种变体。Unet 的初衷是为了解决生物医学图像方面的问题，由于效果确实很好后来也被广泛的应用在语义分割的各个方向，比如卫星图像分割，工业瑕疵检测等。</p>
<p>Unet 跟 FCN 都是 Encoder-Decoder 结构，结构简单但很有效。Encoder 负责特征提取，你可以将自己熟悉的各种特征提取网络放在这个位置。由于在医学方面，样本收集较为困难，作者为了解决这个问题，应用了图像增强的方法，在数据集有限的情况下获得了不错的精度。</p>
<hr>
<h3 id="Unet-网络结构与细节"><a href="#Unet-网络结构与细节" class="headerlink" title="Unet 网络结构与细节"></a>Unet 网络结构与细节</h3><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><img src="/8607332c/1.jpg" class>

<p>如上图，Unet 网络结构是对称的，形似英文字母 U 所以被称为 Unet。整张图都是由蓝/白色框与各种颜色的箭头组成，其中，<strong>蓝/白色框表示 feature map；蓝色箭头表示 3x3 卷积，用于特征提取；灰色箭头表示 skip-connection，用于特征融合；红色箭头表示池化 pooling，用于降低维度；绿色箭头表示上采样 upsample，用于恢复维度；青色箭头表示 1x1 卷积，用于输出结果。</strong>其中灰色箭头 copy and crop 中的 copy 就是 concatenate 而 crop 是为了让两者的长宽一致</p>
<p>可能你会问为啥是 5 层而不是 4 层或者 6 层，emmm，这应该去问作者本人，可能对于当时作者拿到的数据集来说，这个层数的表现更好，但不代表所有的数据集这个结构都适合。我们该多关注这种 Encoder-Decoder 的设计思想，具体实现则应该因数据集而异。</p>
<p>Encoder 由卷积操作和下采样操作组成，文中所用的卷积结构统一为 <strong>3x3 的卷积核，padding 为 0 ，striding 为 1</strong>。没有 padding 所以每次卷积之后 feature map 的 H 和 W 变小了，在 skip-connection 时要注意 feature map 的维度(其实也可以将 padding 设置为 1 避免维度不对应问题)，pytorch 代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.Sequential(nn.Conv2d(in_channels, out_channels, <span class="number">3</span>),</span><br><span class="line">              nn.BatchNorm2d(out_channels),</span><br><span class="line">              nn.ReLU(inplace=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<p>上述的两次卷积之后是一个 <strong>stride 为 2 的 max pooling</strong>，输出大小变为 1/2 *(H, W)：</p>
<img src="/8607332c/2.jpg" class>

<p>pytorch 代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>上面的步骤重复 5 次，最后一次没有 max-pooling，直接将得到的 feature map 送入 Decoder。</p>
<hr>
<h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p>feature map 经过 Decoder 恢复原始分辨率，该过程除了卷积比较关键的步骤就是 upsampling 与 skip-connection。</p>
<p>Upsampling 上采样常用的方式有两种：<strong>1.<a href="https://zhuanlan.zhihu.com/p/77201674">FCN</a> 中介绍的反卷积；2. 插值。</strong>这里介绍文中使用的插值方式。在插值实现方式中，bilinear 双线性插值的综合表现较好也较为常见 。</p>
<p>双线性插值的计算过程没有需要学习的参数，实际就是套公式，这里举个例子方便大家理解(例子介绍的是参数 align_corners 为 Fasle 的情况)。</p>
<img src="/8607332c/3.jpg" class>

<p>例子中是将一个 2x2 的矩阵通过插值的方式得到 4x4 的矩阵，那么将 2x2 的矩阵称为源矩阵，4x4 的矩阵称为目标矩阵。双线性插值中，目标点的值是由离他最近的 4 个点的值计算得到的，我们首先介绍如何找到目标点周围的 4 个点，以 P2 为例。</p>
<img src="/8607332c/4.jpg" class>

<p>第一个公式，目标矩阵到源矩阵的坐标映射：</p>
<img src="/8607332c/5.svg" class>
<img src="/8607332c/6.svg" class>

<p>为了找到那 4 个点，首先要找到目标点在源矩阵中的<strong>相对位置</strong>，上面的公式就是用来算这个的。P2 在目标矩阵中的坐标是 (0, 1)，对应到源矩阵中的坐标就是 (-0.25, 0.25)。坐标里面居然有小数跟负数，不急我们一个一个来处理。我们知道双线性插值是从坐标周围的 4 个点来计算该坐标的值，(-0.25, 0.25) 这个点周围的 4 个点是(-1, 0), (-1, 1), (0, 0), (0, 1)。为了找到负数坐标点，我们将源矩阵扩展为下面的形式，中间红色的部分为源矩阵。</p>
<img src="/8607332c/7.png" class>

<p>我们规定 f(i, j) 表示 (i, j)坐标点处的像素值，对于计算出来的对应的坐标，我们统一写成 (i+u, j+v) 的形式。那么这时 i=-1, u=0.75, j=0, v=0.25。把这 4 个点单独画出来，可以看到目标点 P2 对应到源矩阵中的<strong>相对位置</strong>。</p>
<img src="/8607332c/8.jpg" class>

<p>第二个公式，也是最后一个。</p>
<p><strong>f(i + u, j + v) = (1 - u) (1 - v) f(i, j) + (1 - u) v f(i, j + 1) + u (1 - v) f(i + 1, j) + u v f(i + 1, j + 1)</strong></p>
<p>目标点的像素值就是周围 4 个点像素值的加权和，明显可以看出离得近的权值比较大例如 (0, 0) 点的权值就是 0.75 * 0.75，离得远的如 (-1, 1) 权值就比较小，为 0.25 * 0.25，这也比较符合常理吧。把值带入计算就可以得到 P2 点的值了，结果是 12.5 与代码吻合上了，nice。</p>
<p>pytorch 里使用 bilinear 插值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>CNN 网络要想获得好效果，skip-connection 基本必不可少。Unet 中这一关键步骤融合了底层信息的位置信息与深层特征的语义信息，pytorch 代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.cat([low_layer_features, deep_layer_features], dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>这里需要注意的是，<strong>FCN 中深层信息与浅层信息融合是通过对应像素相加的方式，而 Unet 是通过拼接的方式。</strong></p>
<p>那么这两者有什么区别呢，其实 在 ResNet 与 DenseNet 中也有一样的区别，Resnet 使用了对应值相加，DenseNet 使用了拼接。<strong>个人理解在相加的方式下，feature map 的维度没有变化，但每个维度都包含了更多特征，对于普通的分类任务这种不需要从 feature map 复原到原始分辨率的任务来说，这是一个高效的选择；而拼接则保留了更多的维度/位置 信息，这使得后面的 layer 可以在浅层特征与深层特征自由选择，这对语义分割任务来说更有优势。</strong></p>
<hr>
<h3 id="代码解读"><a href="#代码解读" class="headerlink" title="代码解读"></a>代码解读</h3><h4 id="网络模块定义"><a href="#网络模块定义" class="headerlink" title="网络模块定义"></a>网络模块定义</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubleConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;(convolution =&gt; [BN] =&gt; ReLU) * 2&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, mid_channels=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> mid_channels:</span><br><span class="line">            mid_channels = out_channels</span><br><span class="line">        self.double_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, mid_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(mid_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(mid_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.double_conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Down</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Downscaling with maxpool then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool_conv = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            DoubleConv(in_channels, out_channels)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.maxpool_conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">up</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; up path</span></span><br><span class="line"><span class="string">        conv_transpose =&gt; double_conv</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_ch, out_ch, Transpose=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(up, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#  would be a nice idea if the upsampling could be learned too,</span></span><br><span class="line">        <span class="comment">#  but my machine do not have enough memory to handle all those weights</span></span><br><span class="line">        <span class="keyword">if</span> Transpose:</span><br><span class="line">            self.up = nn.ConvTranspose2d(in_ch, in_ch//<span class="number">2</span>, <span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># self.up = nn.Upsample(scale_factor=2, mode=&#x27;bilinear&#x27;, align_corners=True)</span></span><br><span class="line">            self.up = nn.Sequential(nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>),</span><br><span class="line">                                    nn.Conv2d(in_ch, in_ch//<span class="number">2</span>, kernel_size=<span class="number">1</span>, padding=<span class="number">0</span>),</span><br><span class="line">                                    nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">        self.conv = double_conv(in_ch, out_ch)</span><br><span class="line">        self.up.apply(self.init_weights)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x1, x2</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">            conv output shape = (input_shape - Filter_shape + 2 * padding)/stride + 1</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        x1 = self.up(x1)</span><br><span class="line"></span><br><span class="line">        diffY = x2.size()[<span class="number">2</span>] - x1.size()[<span class="number">2</span>]</span><br><span class="line">        diffX = x2.size()[<span class="number">3</span>] - x1.size()[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        x1 = nn.functional.pad(x1, (diffX // <span class="number">2</span>, diffX - diffX//<span class="number">2</span>,</span><br><span class="line">                                    diffY // <span class="number">2</span>, diffY - diffY//<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        x = torch.cat([x2,x1], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">m</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Conv2d:</span><br><span class="line">            init.xavier_normal(m.weight)</span><br><span class="line">            init.constant(m.bias,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OutConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(OutConv, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="网络结构整体定义"><a href="#网络结构整体定义" class="headerlink" title="网络结构整体定义"></a>网络结构整体定义</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Unet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_ch, out_ch, gpu_ids=[]</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Unet, self).__init__()</span><br><span class="line">        self.loss_stack = <span class="number">0</span></span><br><span class="line">        self.matrix_iou_stack = <span class="number">0</span></span><br><span class="line">        self.stack_count = <span class="number">0</span></span><br><span class="line">        self.display_names = [<span class="string">&#x27;loss_stack&#x27;</span>, <span class="string">&#x27;matrix_iou_stack&#x27;</span>]</span><br><span class="line">        self.gpu_ids = gpu_ids</span><br><span class="line">        self.bce_loss = nn.BCELoss()</span><br><span class="line">        self.device = torch.device(<span class="string">&#x27;cuda:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self.gpu_ids[<span class="number">0</span>])) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        self.inc = inconv(in_ch, <span class="number">64</span>)</span><br><span class="line">        self.down1 = down(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        <span class="comment"># print(list(self.down1.parameters()))</span></span><br><span class="line">        self.down2 = down(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down3 = down(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        self.drop3 = nn.Dropout2d(<span class="number">0.5</span>)</span><br><span class="line">        self.down4 = down(<span class="number">512</span>, <span class="number">1024</span>)</span><br><span class="line">        self.drop4 = nn.Dropout2d(<span class="number">0.5</span>)</span><br><span class="line">        self.up1 = up(<span class="number">1024</span>, <span class="number">512</span>, <span class="literal">False</span>)</span><br><span class="line">        self.up2 = up(<span class="number">512</span>, <span class="number">256</span>, <span class="literal">False</span>)</span><br><span class="line">        self.up3 = up(<span class="number">256</span>, <span class="number">128</span>, <span class="literal">False</span>)</span><br><span class="line">        self.up4 = up(<span class="number">128</span>, <span class="number">64</span>, <span class="literal">False</span>)</span><br><span class="line">        self.outc = outconv(<span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">        self.optimizer = torch.optim.Adam(self.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line">        <span class="comment"># self.optimizer = torch.optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0005)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self</span>):</span></span><br><span class="line">        x1 = self.inc(self.x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)</span><br><span class="line">        x4 = self.drop3(x4)</span><br><span class="line">        x5 = self.down4(x4)</span><br><span class="line">        x5 = self.drop4(x5)</span><br><span class="line">        x = self.up1(x5, x4)</span><br><span class="line">        x = self.up2(x, x3)</span><br><span class="line">        x = self.up3(x, x2)</span><br><span class="line">        x = self.up4(x, x1)</span><br><span class="line">        x = self.outc(x)</span><br><span class="line">        self.pred_y = nn.functional.sigmoid(x)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_input</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        self.x = x.to(self.device)</span><br><span class="line">        self.y = y.to(self.device)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">optimize_params</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.forward()</span><br><span class="line">        self._bce_iou_loss()</span><br><span class="line">        _ = self.accu_iou()</span><br><span class="line">        self.stack_count += <span class="number">1</span></span><br><span class="line">        self.zero_grad()</span><br><span class="line">        self.loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accu_iou</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># B is the mask pred, A is the malanoma </span></span><br><span class="line">        y_pred = (self.pred_y &gt; <span class="number">0.5</span>) * <span class="number">1.0</span></span><br><span class="line">        y_true = (self.y &gt; <span class="number">0.5</span>) * <span class="number">1.0</span></span><br><span class="line">        pred_flat = y_pred.view(y_pred.numel())</span><br><span class="line">        true_flat = y_true.view(y_true.numel())</span><br><span class="line"></span><br><span class="line">        intersection = <span class="built_in">float</span>(torch.<span class="built_in">sum</span>(pred_flat * true_flat)) + <span class="number">1e-7</span></span><br><span class="line">        denominator = <span class="built_in">float</span>(torch.<span class="built_in">sum</span>(pred_flat + true_flat)) - intersection + <span class="number">2e-7</span></span><br><span class="line"></span><br><span class="line">        self.matrix_iou = intersection/denominator</span><br><span class="line">        self.matrix_iou_stack += self.matrix_iou</span><br><span class="line">        <span class="keyword">return</span> self.matrix_iou</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_bce_iou_loss</span>(<span class="params">self</span>):</span></span><br><span class="line">        y_pred = self.pred_y</span><br><span class="line">        y_true = self.y</span><br><span class="line">        pred_flat = y_pred.view(y_pred.numel())</span><br><span class="line">        true_flat = y_true.view(y_true.numel())</span><br><span class="line"></span><br><span class="line">        intersection = torch.<span class="built_in">sum</span>(pred_flat * true_flat) + <span class="number">1e-7</span></span><br><span class="line">        denominator = torch.<span class="built_in">sum</span>(pred_flat + true_flat) - intersection + <span class="number">1e-7</span></span><br><span class="line">        iou = torch.div(intersection, denominator)</span><br><span class="line">        bce_loss = self.bce_loss(pred_flat, true_flat)</span><br><span class="line">        self.loss = bce_loss - iou + <span class="number">1</span></span><br><span class="line">        self.loss_stack += self.loss</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_current_losses</span>(<span class="params">self</span>):</span></span><br><span class="line">        errors_ret = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> self.display_names:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(name, <span class="built_in">str</span>):</span><br><span class="line">                errors_ret[name] = <span class="built_in">float</span>(<span class="built_in">getattr</span>(self, name)) / self.stack_count</span><br><span class="line">        self.loss_stack = <span class="number">0</span></span><br><span class="line">        self.matrix_iou_stack = <span class="number">0</span></span><br><span class="line">        self.stack_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> errors_ret</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eval_iou</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            self.forward()</span><br><span class="line">            self._bce_iou_loss()</span><br><span class="line">            _ = self.accu_iou()</span><br><span class="line">            self.stack_count += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<hr>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>Unet 基于 Encoder-Decoder 结构，通过拼接的方式实现特征融合，结构简明且稳定。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/79204199">https://zhuanlan.zhihu.com/p/79204199</a><br><a href="https://zhuanlan.zhihu.com/p/150579454">https://zhuanlan.zhihu.com/p/150579454</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-FCN论文逐段精读-《Fully Convolutional Networks for Semantic Segmentation》</title>
    <url>/f1f283d3.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2015-Fully-Convolutional-Networks-for-Semantic-Segmentation.pdf" data-height="500px"></div>

<p><strong>FCN</strong> 论文链接：<a href="https://arxiv.org/pdf/1411.4038.pdf">https://arxiv.org/pdf/1411.4038.pdf</a></p>
<p>这篇文章是关于将全卷积网络端到端（End-to-End)地训练，并将其用于语义分割。</p>
<span id="more"></span>

<hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>作者提出了使用全卷积神经网络来接受任意大小的输入，并产生与之相匹配的输出，这样的一个网络在训练和推理的环节效率都很高。作者将这样的密集预测网络与之前的典型的卷积神经网络进行联系，将这些模型的优秀表征能力迁移到语义分割任务中来。进一步地，作者提出了一种用于语义分割的新架构，它可以将网络中提取的深层次的、粗略的语义信息与较浅层次的、较为精准的表征信息进行结合，提高了语义分割的准确性。此模型在多个标准数据集上都达到了 SOTA。</p>
<hr>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>卷积神经网络在图像分类，目标检测方面都有广泛的应用，进一步地就产生了需要为图像中的每一个像素进行分类——语义分割的需求。先前的基于卷积网络的语义分割方法都有着自己的局限性，这也是本文工作所要解决的。</p>
<img src="/f1f283d3/1.png" class>

<p>作者提出的基于 FCN 进行端到端、像素到像素的训练可以在图像语义分割任务中达到 SOTA，且不需要多余的约束机制。本文的工作是首次端到端地训练 FCN 网络用于逐像素预测。模型的训练和推理都是基于整个图像的，在网络中由于上采样层 upsampling 的存在，允许进行下采样的 pooling 操作。</p>
<p>​在本文的工作之前，对图像逐 Patch 进行训练是主流，但是这样的方式相比于 FCN 效率大大降低。同时，本文的方法并没有使用预处理或者后处理，比如：超像素、候选区域等。本文的方法将近来主流的卷积神经网络转换为密集预测，在迁移它们的表征能力的同时进行 fine-tuning.</p>
<p>​语义分割任务具有它固有的内在矛盾：全局的信息决定了是图像中的目标什么，但是局部的信息表示了该目标在哪里。在本文中，作者定义了一种新的跨越连接（Skip connection）来整合深层次的、粗粒度的语义信息与浅层次的、细粒度的表征信息。</p>
<hr>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>作者介绍了关于全卷积神经网络、密集预测的相关研究工作以及它们在图像语义分割中的应用，并总结出这些方法的相似之处：</p>
<ul>
<li>模型较小，限制了模型能力及感受野；</li>
<li>使用patchwise进行训练</li>
<li>在模型中加入了后处理，例如：超像素投影、随机正则化、局部分类等；</li>
<li>输入移位和输出交错以实现密集输出</li>
<li>多尺度金字塔处理</li>
<li>使用了饱和的非线性函数tanh</li>
<li>模型集成</li>
</ul>
<p>本文所提出的基于 FCN 的语义分割方法并没有使用上述的各种机制，但在文章中作者进行了 patchwise 训练的对比，同时进行了网络内部上采样的讨论。</p>
<hr>
<h3 id="全卷积神经网络"><a href="#全卷积神经网络" class="headerlink" title="全卷积神经网络"></a>全卷积神经网络</h3><h4 id="采用分类器进行稠密预测"><a href="#采用分类器进行稠密预测" class="headerlink" title="采用分类器进行稠密预测"></a>采用分类器进行稠密预测</h4><p>典型的识别网络、包括 LeNet、AlexNet 以及更深的卷积模型都是接受固定大小的输入，得到非空间的输出。因为全连接层的存在使得这些网路丢弃了特征图的空间信息。然而，全连接层也可以看成是一种特殊的卷积层，相当于这些“卷积层”的卷积核覆盖整个特征空间。所以可以将 FC 层转化为 Conv 层使得它们可以接受任意尺寸的输入、并输出对每个像素的分类结果。这种转换如 Fig02 所示：</p>
<img src="/f1f283d3/2.png" class>

<p>空间性的输出非常适合于进行语义分割任务，因为在语义分割中每一个输出单元的 ground truth（标签）都是已知的，前向及后向处理都变得很简单，也能够利用卷积层固有的计算效率与优化。</p>
<hr>
<h4 id="Shift-and-stitch-是一种滤波器稀疏"><a href="#Shift-and-stitch-是一种滤波器稀疏" class="headerlink" title="Shift-and-stitch 是一种滤波器稀疏"></a>Shift-and-stitch 是一种滤波器稀疏</h4><p>在这一节当中作者阐释了 Shitf-and-stitch 这样一种上采样（upsampling）的方式。这个方法首先出现在 <a href="https://arxiv.org/pdf/1312.6229.pdf">Overfeat</a> 论文中，关于 Shift-and-stitch 的详细解析，可以参考文章：<a href="https://zhuanlan.zhihu.com/p/56035377">Shift-and-stitch理解</a> 在本文的模型中，作者并没有使用这种方式，这种方式等同于使用了卷积进行上采样。</p>
<hr>
<h4 id="上采样是一种步幅卷积的反向形式"><a href="#上采样是一种步幅卷积的反向形式" class="headerlink" title="上采样是一种步幅卷积的反向形式"></a>上采样是一种步幅卷积的反向形式</h4><p>作者提到，另一种可以用于在粗粒度的深层次输出和密集像素之间构建联系的方法是插值，比如通过双线性插值。可以通过某个像素周边的四个像素来决定当前像素的值。另外，上采样的过程同样可以看成 stride 为上采样因子倒数的“微步长卷积”。一般就是对 output 进行填充，然后再卷积。反卷积的前向后向过程与卷积类似，从某种程度上可以看成“互逆”的过程。所以它很方便地在原有的卷积网络架构中进行拓展。</p>
<hr>
<h4 id="逐Patch训练是一种有损失的抽样"><a href="#逐Patch训练是一种有损失的抽样" class="headerlink" title="逐Patch训练是一种有损失的抽样"></a>逐Patch训练是一种有损失的抽样</h4><p>​作者提到，全图像的训练与逐 Patch 训练在某些条件下是一致的，这要求对于每一个 batch 由当损失下的所有感知域组成。然而，在一幅图像中随机随着 patch 进行 patch-wise 训练损失限制为其空间项的随机抽样子集，这样做是有损失的。作者在后面做了逐 patch 训练，与 FCN 方式相比发现并没有促进收敛或者性能上的提升，这说明这说明全图像训练是有效且高效的。</p>
<hr>
<h3 id="分割架构"><a href="#分割架构" class="headerlink" title="分割架构"></a>分割架构</h3><p>作者将应用于大规模图像分类的卷积模型进行迁移，对它们进行了密集预测以及上采样方式的优化，同时基于之前的模型进行 fine-tuning。随后，作者提出了一种新的跨层次连接的架构。在 PASCAL VOC2011 数据集上训练了一个多项式回归模型用以做对比，同时以图像语义分割的标准指标 mIoU 进行评价。</p>
<hr>
<h4 id="从分类器到密集FCN"><a href="#从分类器到密集FCN" class="headerlink" title="从分类器到密集FCN"></a>从分类器到密集FCN</h4><p>作者首先选用了在大规模图像分类上被证明有较好性能的 AlexNet、VGG-16 以及 GoogleNet 作为改进目标，在 GoogleNet 中仅使用最后一个 loss layer（去除辅助分类器），同时抛弃了最后的平均池化层以提高性能。对于所有的 CNN 模型，将最后的 FC 层都转换为 Conv 层。同时对所有的上采样输出进行通道数为 21（classess + background）的 1 x 1 卷积进行密集预测。表 1 是三个改进模型在 PASCAL VOC2011 数据集上的表现：</p>
<img src="/f1f283d3/3.png" class>

<p>可以看到在平均交并比上，VGG-16 为 Base 的模型效果更好。</p>
<hr>
<h4 id="结合分类与位置信息"><a href="#结合分类与位置信息" class="headerlink" title="结合分类与位置信息"></a>结合分类与位置信息</h4><p>定义一种新的全卷积网络用作语义分割任务，通过调整用于分类的卷积分类器可以在语义分割任务上达到较好的性能。本文基于 VGG-16 模型提出了基础的 FCN-32s、跨层信息融合的 FCN-16s 以及 FCN-8s,模型原理如图 3 所示：</p>
<img src="/f1f283d3/4.png" class>

<p>由图 3 可以看出，FCN-32s 模型就是在 VGG16 模型的 5 次下采样之后得到的得分输出直接进行 32x 上采样，恢复到原图尺寸。而 FCN-16s 则是将 pool5 的得分输出进行 2x 上采样，恢复到原始图像的 1/16，然后再与 pool4 的得分输出直接相加。（注：这里的得分输出是指经过 1 x 1 卷积进行通道拓展，n_channels = 21)。最后，FCN-8s 是在 FCN-16s 的基础上将输出 2x 上采样，再直接加上 pool3 的得分输出得到 1/8 尺度的 output，最后再进行 8x 采样恢复尺寸。本文提出的基于 VGG-16 模型的 FCN-32s、FCN-16s，以及 FCN-8 在语义分割中的实际效果如图 4 所示：</p>
<img src="/f1f283d3/5.png" class>

<hr>
<h4 id="实验框架"><a href="#实验框架" class="headerlink" title="实验框架"></a>实验框架</h4><p><strong>Optimizeation</strong> 在优化过程中，作者对对所有的 score-layer（即进行 1 x 1 卷积的层）进行 0 初始化，作者通过实验发现，随机初始化对于模型性能和训练没有益处。同时，本文提出的 FCN 系列的模型中都保留了 VGG-16 中的 Dropout 层。</p>
<p><strong>Fine-tuning</strong> 训练时，每个模型都进行了端到端的 fine-tuning，如果只是在原 VGG-16 分类器的层上进行 fine-tuning 只能达到最好性能的 70%，各模型的实验结果如表 2 所示：</p>
<img src="/f1f283d3/6.png" class>

<p><strong>Patch Sampling</strong> 同时，作者还进行了 patch-wise training 的对比试验。之前的文献表明，patch-wise 的训练中由于进行随机采样，数据的方差较大，这有利于加速模型收敛。（？？？）在研究这种 trade-off 的过程中，作者通过空间上的损失采样来进行，同时为每种训练方式（full image training VS patch-wise training)独立地选定一个概率 p，以这个概率保留掉最后一层的神经元，同时为每个 batch 中的图像数量乘上一个因子 1/p（0 &lt; p &lt; 1）以扩大 batch_size。对比实验结果如图 5 所示：</p>
<img src="/f1f283d3/7.png" class>

<p>同时进行了全图像训练、50% 采样训练、25% 采样训练三种方式，通过实验结果可以看出，patch-wise 的训练方式在促进模型收敛上并没有显著的优势（左图）。同时，右图显示了模型收敛的相对时间，可以发现由于 patch-wise 方式在每个 batch 中需要训练的图像数量更多，速度更慢。所以本文并没有采用这种训练方式。</p>
<p><strong>Class Balancing</strong> 在面对类别不平衡的问题时，全卷积网络的训练可以对最后的损失进行类别的加权。</p>
<p><strong>Dense Prediction</strong> 最后一个反卷积层的卷积核的参数被固定为双线性插值，但是中间各层的反卷积被初始化为双线性上采样，在训练的过程中不断学习。</p>
<p><strong>Augmentation</strong> 通过镜像“mirror”和抖动“jittering”（在最粗略的预测尺度上，向每个方向拓展 32 个 pixel）但这并没有实际的性能提升</p>
<hr>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>评价指标：</p>
<img src="/f1f283d3/8.png" class>

<ul>
<li>pixel accuracy 指的是像素准确性，n_ij 表示原本属于类别 i 的像素被分类到类别 j 中的像素个数，t_i = ∑_j n_ij 表示类别 i 中所有的像素个数。pixel accuracy 是把所有正确预测类别的像素数量求和再除以所有的像素数量。</li>
<li>mean accuracy 是指平均准确率，对每个类别的 accuracy 取平均。</li>
<li>mean IU 平均交并比，将每个类别的正确预测像素数量 n_ii 除以本类别像素数量 t_i 除以本类别像素数量 i<br>的像素的并集 (t_i + ∑_j n_ij - n_ii)，再除以类别 n_cl。</li>
<li>按类别频率加权的IU</li>
</ul>
<p>下面的表 3 显示了 FCN-8s 模型与之前的 SOTA 模型 SDS 以及 R-CNN 在 PASCAL VOC 2011、2012 数据集上的性能比较：</p>
<img src="/f1f283d3/9.png" class>

<p>可以看到本文提出的 FCN-8s 模型在常用的 mean IU 指标上有着较大的提升，同时也大幅度降低了模型的推理时间。图 6 显示了 FCN-8s 模型与 SDS 语义分割的效果：</p>
<img src="/f1f283d3/10.png" class>

<p>可以发现 FCN-8s 在精细的结构修复、区分相近且相邻的目标的能力以及对应于目标遮挡的鲁棒性上都更胜一筹。</p>
<hr>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>将用于图像分类的卷积模型扩展到语义分割，并用多分辨率层组合改进体系结构，极大地提高了架构的能力，同时简化和加快了学习和推理。</p>
<hr>
<h3 id="FCN模型的不足"><a href="#FCN模型的不足" class="headerlink" title="FCN模型的不足"></a>FCN模型的不足</h3><ol>
<li>对于目标的边缘分割仍旧很平滑，对细节的处理不敏感。</li>
<li>采用基于 CNN 的密集预测，在给每个像素点分类时没有考虑到像素点之间的关系，即没有利用好这种上下文的关系。</li>
</ol>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/56035377">https://zhuanlan.zhihu.com/p/56035377</a><br><a href="https://blog.csdn.net/qq_39109729/article/details/109557050">https://blog.csdn.net/qq_39109729/article/details/109557050</a><br><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf">https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf</a><br><a href="https://github.com/wkentaro/pytorch-fcn/tree/master/torchfcn/models">https://github.com/wkentaro/pytorch-fcn/tree/master/torchfcn/models</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-FCN与CNN</title>
    <url>/fbfabfe3.html</url>
    <content><![CDATA[<h3 id="回顾-CNN"><a href="#回顾-CNN" class="headerlink" title="回顾 CNN"></a>回顾 CNN</h3><p>通常 CNN 网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量（这就丢失了空间信息）。以 AlexNet 为代表的经典 CNN 结构适合于图像级的分类和回归任务，因为它们最后都期望得到整个输入图像的一个数值描述（概率），比如 AlexNet 的 ImageNet 模型输出一个 1000 维的向量表示输入图像属于每一类的概率(softmax归一化)。</p>
<p>下图中的猫, 输入 AlexNet, 得到一个长为 1000 的输出向量, 表示输入图像属于每一类的概率, 其中在 “tabby cat” 这一类统计概率最高。</p>
<img src="/fbfabfe3/1.jpg" class>

<span id="more"></span>

<p><strong>传统的基于 CNN 的分割方法：</strong>为了对一个像素分类，使用该像素周围的一个图像块作为 CNN 的输入用于训练和预测。这种方法有几个缺点：一是存储开销很大。例如对每个像素使用的图像块的大小为 15 x 15，然后不断滑动窗口，每次滑动的窗口给 CNN 进行判别分类，因此则所需的存储空间根据滑动窗口的次数和大小急剧上升。二是计算效率低下。相邻的像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算也有很大程度上的重复。三是像素块大小的限制了感知区域的大小。通常像素块的大小比整幅图像的大小小很多，只能提取一些局部的特征，从而导致分类的性能受到限制。</p>
<p><strong>CNN 的输入是图像，输出是一个结果，或者说是一个值，一个概率值。</strong></p>
<p><strong>FCN 提出所追求的是，输入是一张图片是，输出也是一张图片，学习像素到像素的映射。</strong></p>
<hr>
<h3 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h3><p>全卷积网络(FCN)则是从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。</p>
<p>FCN 对图像进行像素级的分类，从而解决了语义级别的图像分割(semantic segmentation)问题。与经典的 CNN 在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全联接层＋softmax输出）不同，FCN 可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的 feature map 进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。</p>
<p>最后逐个像素计算 softmax 分类的损失, 相当于每一个像素对应一个训练样本。下图是 Longjon 用于语义分割所采用的全卷积网络(FCN)的结构示意图：</p>
<img src="/fbfabfe3/2.jpg" class>

<p><strong>简单的来说，FCN 与 CNN 的区别在把于 CNN 最后的全连接层换成卷积层，输出的是一张已经Label好的图片。</strong>因为语义分割需要输出整张图片的分割图，所以要求网络中的特征图至少是二维的，这样才能通过上采样还原到输入图片的同等大小。这就需要替换掉全连接层，改换为卷积层。</p>
<hr>
<h4 id="全连接层转化为卷积层"><a href="#全连接层转化为卷积层" class="headerlink" title="全连接层转化为卷积层"></a>全连接层转化为卷积层</h4><ol>
<li>说一下卷积层和全连接层的区别：卷积层为局部连接；而全连接层则使用图像的全局信息。可以想象一下，最大的局部是不是就等于全局了？这首先说明全连接层使用卷积层来替代的可行性。</li>
<li>究竟使用卷积层代替全连接层会带来什么好处呢？答案：可以让卷积网络在一张更大的输入图片上滑动，得到每个区域的输出（这样就突破了输入尺寸的限制）。</li>
</ol>
<p>论文里 Fully Convolutional Networks for Semantic Segmentation 介绍的很清楚，解读如下：</p>
<p>以 Alexnet 为例，最后一层为 7 x 7 x 256，得到后面 4096 个神经元；但是如果使用 7 x 7 的卷积核对前面的 featuremap 继续卷积（padding=0），不也可以得到 1 x 1 x 4096 的向量吗。如果图片大一点，例如 384 x 384，那么 Alexnet 最后一层大小就是 12 x 12 x 256，经过 7 x 7 卷积核就是 6 x 6 x 4096，这时 6 x 6 = 36 个神经元就有了位置信息，如下图所示：</p>
<img src="/fbfabfe3/3.jpg" class>

<p>第一个连接区域是 [7 x 7 x 512] 的全连接层，令其滤波器尺寸为 Kernel = 7，这样输出数据体就为 [1 x 1 x 4096] 了；第二个全连接层，令其滤波器尺寸为 Kernel = 1，这样输出数据体为 [1 x 1 x 4096]；最后一个全连接层也做类似的，令其 Kernel = 1，最终输出为 [1 x 1 x 1000]。</p>
<p>实际操作中，每次这样的变换都需要把全连接层的权重 W 重塑成卷积层的滤波器。</p>
<p>经过多次卷积（还有 pooling）以后，得到的图像越来越小,分辨率越来越低（粗略的图像），那么 FCN 是如何得到图像中每一个像素的类别的呢？为了从这个分辨率低的粗略图像恢复到原图的分辨率，FCN 使用了上采样。例如经过 5 次卷积(和pooling)以后，图像的分辨率依次缩小了2, 4, 8, 16, 32倍。对于最后一层的输出图像，需要进行 32 倍的上采样，以得到原图一样的大小。</p>
<hr>
<h4 id="heatmap"><a href="#heatmap" class="headerlink" title="heatmap"></a>heatmap</h4><p>heatmap 其实就是 featuremap，本来是很小的图片经过全卷积得到 1 * 1 * n 的特征，那么输入大一点的图片时就会变成 m * m * n，这里的 m * m 就是 heatmap。</p>
<hr>
<h4 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h4><p>这个上采样是通过反卷积（deconvolution）实现的。对第 5 层的输出（32倍放大）反卷积到原图大小，得到的结果还是不够精确，一些细节无法恢复。于是 Jonathan 将第 4 层的输出和第 3 层的输出也依次反卷积，分别需要 16 倍和 8 倍上采样，结果就精细一些了。下图是这个卷积和反卷积上采样的过程：</p>
<img src="/fbfabfe3/4.jpg" class>

<p>解释一下三次上采样：</p>
<img src="/fbfabfe3/5.jpg" class>

<p>如上图所示，对原图像进行卷积 conv1、pool1 后原图像缩小为 1/2；之后对图像进行第二次 conv2、pool2 后图像缩小为 1/4；接着继续对图像进行第三次卷积操作 conv3、pool3 缩小为原图像的 1/8，此时保留 pool3 的 featureMap；接着继续对图像进行第四次卷积操作 conv4、pool4，缩小为原图像的 1/16，保留 pool4 的 featureMap；最后对图像进行第五次卷积操作 conv5、pool5，缩小为原图像的 1/32，然后把原来 CNN 操作中的全连接变成卷积操作 conv6、conv7，图像的 featureMap 数量改变但是图像大小依然为原图的 1/32，此时图像不再叫 featureMap 而是叫 heatMap。</p>
<p>现在我们有 1/32 尺寸的 heatMap，1/16 尺寸的 featureMap 和 1/8 尺寸的 featureMap，1/32 尺寸的 heatMap 进行 upsampling 操作之后，因为这样的操作还原的图片仅仅是 conv5 中的卷积核中的特征，限于精度问题不能够很好地还原图像当中的特征，因此在这里向前迭代。把 conv4 中的卷积核对上一次 upsampling 之后的图进行反卷积补充细节（相当于一个插值过程），最后把 conv3 中的卷积核对刚才 upsampling 之后的图像进行再次反卷积补充细节，最后就完成了整个图像的还原。</p>
<p>下图是 32 倍、16 倍和 8 倍上采样得到的结果的对比，可以看到它们得到的结果越来越精确：</p>
<img src="/fbfabfe3/6.jpg" class>

<p>为什么会这样呢？</p>
<p>这里就涉及到一个<strong>感受域</strong>（receptive field）的概念。较浅的卷积层（靠前的）的感受域比较小，学习感知细节部分的能力强，较深的隐藏层（靠后的），感受域相对较大，适合学习较为整体的、相对更宏观一些的特征。所以在较深的卷积层上进行反卷积还原，自然会丢失很多细节特征。</p>
<hr>
<h4 id="反卷积"><a href="#反卷积" class="headerlink" title="反卷积"></a>反卷积</h4><img src="/fbfabfe3/7.jpg" class>

<p><strong>优点和不足：</strong></p>
<p>与传统用 CNN 进行图像分割的方法相比，FCN 有两大明显的优点：一是可以接受任意大小的输入图像，而不用要求所有的训练图像和测试图像具有同样的尺寸。二是更加高效，因为避免了由于使用像素块而带来的重复存储和计算卷积的问题。</p>
<p>同时 FCN 的缺点也比较明显：一是得到的结果还是不够精细。进行 8 倍上采样虽然比 32 倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感。二是对各个像素进行分类，没有充分考虑像素与像素之间的关系，忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/32037333">https://zhuanlan.zhihu.com/p/32037333</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-FCN全卷积网络论文阅读及代码实现</title>
    <url>/e70eab89.html</url>
    <content><![CDATA[<p>Full Convolutional Networks 即全卷积神经网络，这是 2015 年的一篇语义分割方向的文章，是一篇比较久远的开山之作。它是语义分割方向的鼻祖，后面的文章很多都借鉴了这篇文章的思想，掌握好基础我们才能飞的更高。本篇文章分为两部分: 论文解读与代码实现。</p>
<div class="pdfobject-container" data-target="./file/paper/2015-Fully-Convolutional-Networks-for-Semantic-Segmentation.pdf" data-height="500px"></div>

<p><strong>FCN</strong> 论文链接：<a href="https://arxiv.org/pdf/1411.4038.pdf">https://arxiv.org/pdf/1411.4038.pdf</a></p>
<span id="more"></span>

<hr>
<h3 id="论文解读"><a href="#论文解读" class="headerlink" title="论文解读"></a>论文解读</h3><h4 id="语义分割介绍"><a href="#语义分割介绍" class="headerlink" title="语义分割介绍"></a>语义分割介绍</h4><p>语义分割（Semantic Segmentation）的目的是对图像中<strong>每一个像素点进行分类</strong>，与普通的分类任务只输出某个类别不同，语义分割任务输出是与<strong>输入图像大小相同的图像</strong>，输出图像的每个像素对应了输入图像每个像素的类别。</p>
<img src="/e70eab89/1.jpg" class>

<hr>
<h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p>FCN 的基本结构很简单，就是全部由卷积层组成的网络。用于图像分类的网络一般结构是<strong>卷积-池化-卷积-池化-全连接</strong>，其中<strong>卷积和全连接层</strong>是有参数的，池化则没有参数。论文作者认为全连接层让目标的<strong>位置信息</strong>消失了，只保留了<strong>语义信息</strong>，因此将全连接操作更换为卷积操作可以同时保留<strong>位置信息及语义信息</strong>，达到给每个像素分类的目的。网络的基本结构如下:</p>
<img src="/e70eab89/2.jpg" class>

<p>输入图像经过卷积和池化之后，得到的 feature map 宽高相对原图缩小了数倍，例如下图中，提取特征之后”特征长方体”的宽高为原图像的 1/32，为了得到与原图大小一致的输出结果，需要对其进行上采样（upsampling），下面介绍上采样的方法之一-反卷积（图中最终输出的”厚度”是 21，因为类别数是 21，每一层可以看做是原图像中的每个像素属于某类别的概率，coding 的时候需要注意一下）。</p>
<img src="/e70eab89/3.jpg" class>

<hr>
<h4 id="反卷积"><a href="#反卷积" class="headerlink" title="反卷积"></a>反卷积</h4><p>反卷积是上采样（unsampling）的一种方式，论文作者在实验之后发现反卷积相较于其他上采样方式例如 bilinear upsampling 效率更高，所以采用了这种方式。</p>
<p>关于反卷积的解释借鉴了这一篇：<a href="https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0">https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0</a>，英文 OK 的小伙伴推荐看原文，讲的很通透。</p>
<p>先看看正向卷积，我们知道卷积操作本质就是矩阵相乘再相加。现在假设我们有一个 4x4 的矩阵，卷积核大小为 3x3，步幅为 1 且不填充，那么其输出会是一个 2x2 的矩阵，这个过程实际是一个<strong>多对一</strong>的映射：</p>
<img src="/e70eab89/4.jpg" class>

<p>从上图也可以看出，卷积操作其实是保留了位置信息的，例如输出矩阵中左上角的数字”122”就对应了原矩阵左上方的 9 个元素。</p>
<p>那么如何将结果的 2x2 的矩阵”扩展”为 4x4 的矩阵呢(<strong>一对多</strong>的映射)。4x16 的卷积核矩阵与 16x1 的输入矩阵相乘，得到了 4x1 的输出矩阵，达到了多对一映射的效果，那么将卷积核矩阵转置为 16x4 乘上输出矩阵 4x1 就可以达到一对多映射的效果，因此反卷积也叫做转置卷积。具体过程如下:</p>
<img src="/e70eab89/5.jpg" class>

<img src="/e70eab89/6.jpg" class>

<p>总结来说，全卷积网络的基本结构就是”<strong>卷积-反卷积-分类器</strong>“，通过卷积提取位置信息及语义信息，通过反卷积上采样至原图像大小，再加上深层特征与浅层特征的融合，达到了语义分割的目的。</p>
<hr>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>大佬实现了简单版本的 FCN，代码地址 <a href="https://github.com/FroyoZzz/CV-Papers-Codes">github</a></p>
<p>VGG16 网络代码，forward 返回了卷积过程中各层的输出，以便后面与反卷积的特征做融合：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, pretrained=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VGG, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conv1 1/2</span></span><br><span class="line">        self.conv1_1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu1_1 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv1_2 = nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu1_2 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.pool1 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conv2 1/4</span></span><br><span class="line">        self.conv2_1 = nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu2_1 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2_2 = nn.Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu2_2 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.pool2 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conv3 1/8</span></span><br><span class="line">        self.conv3_1 = nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu3_1 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv3_2 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu3_2 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv3_3 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu3_3 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.pool3 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conv4 1/16</span></span><br><span class="line">        self.conv4_1 = nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu4_1 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv4_2 = nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu4_2 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv4_3 = nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu4_3 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.pool4 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conv5 1/32</span></span><br><span class="line">        self.conv5_1 = nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu5_1 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv5_2 = nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu5_2 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv5_3 = nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.relu5_3 = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.pool5 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># load pretrained params from torchvision.models.vgg16(pretrained=True)</span></span><br><span class="line">        <span class="keyword">if</span> pretrained:</span><br><span class="line">            pretrained_model = vgg16(pretrained=pretrained)</span><br><span class="line">            pretrained_params = pretrained_model.state_dict()</span><br><span class="line">            keys = <span class="built_in">list</span>(pretrained_params.keys())</span><br><span class="line">            new_dict = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> index, key <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.state_dict().keys()):</span><br><span class="line">                new_dict[key] = pretrained_params[keys[index]]</span><br><span class="line">            self.load_state_dict(new_dict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.relu1_1(self.conv1_1(x))</span><br><span class="line">        x = self.relu1_2(self.conv1_2(x))</span><br><span class="line">        x = self.pool1(x)</span><br><span class="line">        pool1 = x</span><br><span class="line"></span><br><span class="line">        x = self.relu2_1(self.conv2_1(x))</span><br><span class="line">        x = self.relu2_2(self.conv2_2(x))</span><br><span class="line">        x = self.pool2(x)</span><br><span class="line">        pool2 = x</span><br><span class="line"></span><br><span class="line">        x = self.relu3_1(self.conv3_1(x))</span><br><span class="line">        x = self.relu3_2(self.conv3_2(x))</span><br><span class="line">        x = self.relu3_3(self.conv3_3(x))</span><br><span class="line">        x = self.pool3(x)</span><br><span class="line">        pool3 = x</span><br><span class="line"></span><br><span class="line">        x = self.relu4_1(self.conv4_1(x))</span><br><span class="line">        x = self.relu4_2(self.conv4_2(x))</span><br><span class="line">        x = self.relu4_3(self.conv4_3(x))</span><br><span class="line">        x = self.pool4(x)</span><br><span class="line">        pool4 = x</span><br><span class="line"></span><br><span class="line">        x = self.relu5_1(self.conv5_1(x))</span><br><span class="line">        x = self.relu5_2(self.conv5_2(x))</span><br><span class="line">        x = self.relu5_3(self.conv5_3(x))</span><br><span class="line">        x = self.pool5(x)</span><br><span class="line">        pool5 = x</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pool1, pool2, pool3, pool4, pool5</span><br></pre></td></tr></table></figure>

<p>FCN 网络，结构也很简单，包含了反卷积以及与浅层信息的融合：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FCNs</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, backbone=<span class="string">&quot;vgg&quot;</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(FCNs, self).__init__()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        <span class="keyword">if</span> backbone == <span class="string">&quot;vgg&quot;</span>:</span><br><span class="line">            self.features = VGG()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># deconv1 1/16</span></span><br><span class="line">        self.deconv1 = nn.ConvTranspose2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">512</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># deconv1 1/8</span></span><br><span class="line">        self.deconv2 = nn.ConvTranspose2d(<span class="number">512</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(<span class="number">256</span>)</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># deconv1 1/4</span></span><br><span class="line">        self.deconv3 = nn.ConvTranspose2d(<span class="number">256</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(<span class="number">128</span>)</span><br><span class="line">        self.relu3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># deconv1 1/2</span></span><br><span class="line">        self.deconv4 = nn.ConvTranspose2d(<span class="number">128</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn4 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.relu4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># deconv1 1/1</span></span><br><span class="line">        self.deconv5 = nn.ConvTranspose2d(<span class="number">64</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, output_padding=<span class="number">1</span>)</span><br><span class="line">        self.bn5 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">        self.relu5 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Conv2d(<span class="number">32</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        features = self.features(x)</span><br><span class="line"></span><br><span class="line">        y = self.bn1(self.relu1(self.deconv1(features[<span class="number">4</span>])) + features[<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">        y = self.bn2(self.relu2(self.deconv2(y)) + features[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        y = self.bn3(self.relu3(self.deconv3(y)) + features[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        y = self.bn4(self.relu4(self.deconv4(y)) + features[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        y = self.bn5(self.relu5(self.deconv5(y)))</span><br><span class="line"></span><br><span class="line">        y = self.classifier(y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>

<p>训练，每个 epoch 会保存一个模型，默认保存在./models下：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>

<p>我的训练结果，上面一行是预测值，下面一行是目标值：</p>
<p>5 个 epoch 时：</p>
<img src="/e70eab89/7.jpg" class>

<p>10 个 epoch 时：</p>
<img src="/e70eab89/8.jpg" class>

<p>20 个 epoch 时：</p>
<img src="/e70eab89/9.jpg" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/77201674">https://zhuanlan.zhihu.com/p/77201674</a><br><a href="https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0">https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0</a><br><a href="https://github.com/FroyoZzz/CV-Papers-Codes">https://github.com/FroyoZzz/CV-Papers-Codes</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-NUWA再度升级！赋予视觉艺术无限创造力</title>
    <url>/c2ef7750.html</url>
    <content><![CDATA[<p><strong>NUWA</strong>(<strong>N</strong>eural vis<strong>U</strong>al <strong>W</strong>orld re<strong>A</strong>tion)是微软亚洲研究院开发的多模态模型，通过自然语言指令，NUWA可以实现文本、图像、视频之间的生成、转换和编辑。近日，微软亚洲研究院公布了新的研究成果，在高分辨率、大图像的横向延展方面进行持续研究后，提出了NUWA-Infinity模型，可以生成任意分辨率的图像或长时间视频，弥补了NUWA模型在生成、编辑的图像和视频分辨率较低的缺陷。简单说，NUWA-Infinity会根据图像的不同层次内容扫描每一帧画面，不断渲染生成高像素、连续的大图。</p>
<p>接下来一起领略NUWA-Infinity的无限创造力吧。</p>
<p>比如让梵高的《星空》突破相框的限制。</p>
<img src="/c2ef7750/1.gif" class>

<span id="more"></span>

<p>亦或者让AI创造一副“新”的《清明上河图》。</p>
<img src="/c2ef7750/2.jpg" class>

<p>也可以让静止的图片动起来。</p>
<img src="/c2ef7750/3.jpg" class>

<img src="/c2ef7750/4.gif" class>

<p>NUWA-Infinity的研发初衷是希望降低高质量的视觉艺术创作的门槛，使创作者可以在一定程度上摆脱对专业设备的依赖、减少创作时间成本，让更多人可以更好地发挥自己的创意，拥有成为日常创作者的机会。与NUWA相比，这个全新升级的模型在分辨率和可变大小视觉艺术作品生成方面具有更优的性能，并支持五个高分辨率视觉任务的生成。</p>
<p>微软亚洲研究院研究员段楠说，“NUWA-Infinity从底层形成了一套全局自回归的生成机制，不仅可以对图片进行延展式的生成，也可以应用于视频预测创作，而这也是我们接下来要攻克的研究课题。”通过全局自回归建模视觉块之间的依赖关系和局部自回归建模视觉词之间的依赖关系，让NUWA-Infinity能够生成全局一致且局部细节丰富的高质量图像和视频。同时提出任意方向控制器（Arbitrary Direction Controller, ADC）来决定合适的生成顺序并学习顺序感知的位置嵌入。此外，模型还引入附近上下文池（Nearby Context Pool, NCP）进行局部生成图像的缓存。</p>
<img src="/c2ef7750/5.jpg" class>
<p>NUWA-Infinity的模型概述</p>
<p>与其他多模态生成模型相比，NUWA-Infinity的优势在于可以从给定文本、图像或视频生成与之相关的任意形状、任意大小的高分辨率图像，以适配不同设备、平台和场景。更重要的是该模型还支持长时间视频的生成，比如图像动画的制作。NUWA-Infinity极大地弥补了市场上现有技术仅支持生成大小有限的视觉内容及创作成本高昂的不足。研发团队将继续推动NUWA的演进，在构思、美学、效率方面持续强化NUWA的能力。AI加持的视觉创作已经在影视、游戏、动漫等行业得到一定的应用，其发展趋势也会更加接近符合人类的审美和需求，NUWA-Infinity传递出一种信号：艺术无门槛，它会张开双手拥抱所有灵感。</p>
<p>链接：<a href="https://mp.weixin.qq.com/s/g-1EVy2LGQ8EBgqRPeExEw">https://mp.weixin.qq.com/s/g-1EVy2LGQ8EBgqRPeExEw</a></p>
<p>演示页面：<a href="https://nuwa-infinity.microsoft.com/">https://nuwa-infinity.microsoft.com/</a></p>
<hr>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul>
<li>[1] Wu, Chenfei, Jian Liang, Xiaowei Hu, Zhe Gan, Jianfeng Wang, Lijuan Wang, Zicheng Liu, Yuejian Fang, and Nan Duan. “NUWA-Infinity: Autoregressive over Autoregressive Generation for Infinite Visual Synthesis.” arXiv preprint arXiv:2207.09814 (2022).</li>
</ul>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12060">https://www.scholat.com/teamwork/showPostMessage.html?id=12060</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-如何判断（你自己的）研究工作的价值</title>
    <url>/4e32fb79.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=465786953&bvid=BV1oL411c7Us&cid=487717373&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<p><strong>怎样判断一个工作的意义以及自己写论文的时候如何讲自己的故事（偏人工智能技术类）</strong></p>
<p>核心：用有<strong>新意</strong>的方法<strong>有效</strong>地解决一个研究问题</p>
<hr>
<h3 id="研究"><a href="#研究" class="headerlink" title="研究"></a>研究</h3><p>这里关注的是技术类的问题，这里面主要有两大类问题</p>
<ul>
<li>研究问题</li>
<li>工程问题：<strong>绝大部分问题都是工程问题</strong></li>
</ul>
<p>比如说算法比较占内存，跑不动，首先想到的是能不能买一些内存，如果买的内存够用的话那就没问题了；然后再看看代码能否进行优化，能否换一个实现的方式，使得在不改变算法的同时节省内存</p>
<p>再比如模型的精度不够，首先看能否利用增加数据的方法来解决问题，或者在采样的时候，有更好的传感器进行采样</p>
<p>如果对一个问题，能够提出几种方案，而且这些方案在没有尝试的情况下就能知道是能够解决问题的，那么很有可能这个问题就是一个<strong>工程问题</strong></p>
<p>对<strong>研究问题</strong>来说，一定是比较困难的问题，根本就不知道如何解决，或者说有一些想法，但是在实施这些想法之前比不知道是否可行，而且对于一般的研究问题，前面的一些想法通常来说是不行的</p>
<hr>
<h3 id="有效"><a href="#有效" class="headerlink" title="有效"></a>有效</h3><p>有效是一个相对的概念，并不是一个绝对的概念，因为对于绝大部分论文来讲，它无法彻底地解决一个研究问题</p>
<p>比如说人工智能在做了50年的研究之后仍然没有解决人工智能的终极问题：智能</p>
<p>这里的有效性是说，<strong>对于某一个研究问题来讲，相对于之前的工作，当前工作解决问题的有效性有所提升</strong></p>
<hr>
<h3 id="新意（novelty）"><a href="#新意（novelty）" class="headerlink" title="新意（novelty）"></a>新意（novelty）</h3><p>也是一个相对的概念，就算是一个很有新意的东西，等到它出来一段时间之后，也就不再有新意了</p>
<p>具体来讲，这里的新意指的是<strong>对所在领域的研究者有新意，也就是说，在做相同方向的研究者并没有想到过用相同的方法</strong></p>
<p>所以并不要求方法一定是前人没有提到过，很有可能是很多年前别人已经用过了，但是随着时间的流逝，大家已经不记得了；或者是所用到的方法在别的领域有人用，但是在自己所在的研究领域并没有太多了解</p>
<p>在写文章的时候，研究工作最后也应该总结成一句话：有什么样的方法，怎么样有新效地解决了什么样的研究问题</p>
<ul>
<li>在写摘要的时候会先说要解决什么样的研究问题，方法的新意在哪里，最后结果如何</li>
</ul>
<hr>
<h3 id="量化版本"><a href="#量化版本" class="headerlink" title="量化版本"></a>量化版本</h3><img src="/4e32fb79/1.png" class>

<h4 id="问题大小"><a href="#问题大小" class="headerlink" title="问题大小"></a>问题大小</h4><p>可以粗糙地分为3档</p>
<ul>
<li>1：比如说对前面的工作在某一个点上做的不好的地方做了改进</li>
<li>10：比如说计算机视觉中某一个视觉的子任务</li>
<li>100：比如说提升机器对图片的理解或者机器对文字的理解</li>
<li>当然还可以更大，比如说解决通用的人工智能，就可以达到1000甚至更大</li>
</ul>
<hr>
<h4 id="有效性"><a href="#有效性" class="headerlink" title="有效性"></a>有效性</h4><p>也可以粗糙地分为3档</p>
<ul>
<li>1：比如说关心的是一个模型的精度，可能比前面的模型精度高了一点点</li>
<li>10：比如说领域内的工作一年之内能把一个数据集的精度提升10个点，能提升一个点也是相当不错了</li>
<li>100：比如说一个工作就能将数据集的精度提升5个点，甚至是10个点</li>
<li>当然取决于问题的不同，对有效性的定义也是不一样的，但是对于一个技术问题来说，通常就关心三个问题：1、效果：比如说精度；2、规模：比如说成本的降低；3、安全</li>
</ul>
<hr>
<h4 id="新意度"><a href="#新意度" class="headerlink" title="新意度"></a>新意度</h4><p>也可以粗糙地分为3档</p>
<ul>
<li>1：表示大家并不感到意外，比如说用的方法大家都知道，而且知道使用之后的结果大概是什么样子</li>
<li>10：表示有一定新意度，比如在某个方面用某一个技术解决了还不错的问题</li>
<li>100：表示所用的技术之前大家并不熟悉，使用之后打开了新世界的大门</li>
<li>新意也不是绝对的，对于技术类的工作来说，很难有一个技术之前从来没有出现过</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在以上三个方向上都拿满分很难，有时候在两个方向上拿满分都是一件非常困难的事情，所以就需要考虑能不能在一个指标上拿满分；如果无法在任何一个指标上拿满分，就需要考虑是否能做到三个指标都能够均衡地达到10，这也是很不错的；如果能够在某两个指标上达到10，还是值得一写的，如果写的比较好的话，也是一个比较好的工作，否则的话，建议想一想在其他方向上是不是还有突破，至少在另外一个指标上拿到10</p>
<p>在实际问题中，很难做到精确的分类，很多时候只有一个大概的判断，所以以上框架只是作为一个参考</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv14907058">https://www.bilibili.com/read/cv14907058</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫方法技巧</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-近期脑机接口研究动态</title>
    <url>/a5e4553a.html</url>
    <content><![CDATA[<p><strong>脑机接口到底是什么？</strong></p>
<p>简单来讲，脑机接口是指在人或动物大脑与外部设备之间创建的直接连接，实现脑与设备的信息交换，具体工作方式如下图1。</p>
<img src="/a5e4553a/1.png" class>
<p>图1 脑机接口工作方式</p>
<span id="more"></span>

<p>具体来讲，有三种实现方式：</p>
<p>一种是非侵入式的，就相当于戴个帽子，或者在脑袋上贴很多电极，根据电流等指标去推测我们的大脑正在干什么。</p>
<p>第二种是部分侵入式的，植入到颅腔里面，但是不碰到灰质。</p>
<p>而与另一个自己硬核对话的马斯克的 Neuralink 公司采用的则是第三种方式，即所谓(侵入式)的，就是往我们的脑袋里放一块芯片，通过这个芯片来采集神经元细胞的信号，然后传输到脑外。</p>
<p>下面是近期脑机接口研究动态：</p>
<p><strong>国内首例介入式脑机接口动物试验成功完成</strong></p>
<p>近日，由南开大学人工智能学院段峰教授科研团队牵头研发的国内首个介入式脑机接口技术在北京成功完成动物试验，该技术只需通过类似心脏搭桥的微创手术便可实现脑机连接，整个手术植入过程可在两小时内完成。其通过脑电信号检测技术获取神经系统的电活动变化，再对这些信号进行分类识别，分辨出引发脑电变化的动作意图，再用计算机把人的思维活动转变成命令信号驱动外部设备，从而在没有肌肉和外围神经直接参与的情况下，实现人脑对外部环境的直接控制。</p>
<img src="/a5e4553a/2.jpg" class>
<p>图2 羊脑内实现介入式脑机接口</p>
<p>本次试验是国内首次在羊脑内实现介入式脑机接口，如图2，突破了介入式脑电电极、血管内脑电采集等核心技术，完成了支架、导管等神经介入器械产品研制，解决了传统侵入式脑机接口对脑区造成不可逆损伤的弊端，填补了国内介入式脑机接口领域空白，对推动我国脑科学领域发展具有重要意义。</p>
<p>据悉，此次试验的成功，标志着我国在脑机接口、介入机器人研究领域达到国际先进水平。</p>
<p><strong>脑机接口初创公司Synchron在美国患者身上做的第一例植入手术</strong></p>
<p>7月6日，纽约西奈山医疗中心(Mount Sinai West medical center)的一名医生将一个由电线和电极组成的1.5英寸长的植入物插入一名ALS(肌萎缩性侧索硬化症)患者的脑部血管，如图3。人们希望，失去行动和说话能力的病人通过思维意念能够上网，通过电子邮件和文本进行交流——该设备将把他的想法转化为发送给电脑的命令。</p>
<img src="/a5e4553a/3.png" class>
<p>图3 Synchron stentrode 设备</p>
<p>该技术背后的初创公司Synchron已经将其设备植入澳大利亚的四名患者身上，这些患者没有出现副作用，并且能够执行发送网络消息和进行在线购物等任务。最近的手术是该公司在美国进行的第一次手术，使其领先于包括埃隆·马斯克的Neuralink公司在内的竞争对手。“这项手术的特殊之处在于其意义和巨大的潜力，”执行该手术的神经介入外科医生Shahram Majidi博士表示。</p>
<hr>
<h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/6B7Y4hWSfTtzzEv30DVjPw">https://mp.weixin.qq.com/s/6B7Y4hWSfTtzzEv30DVjPw</a><br><a href="https://mp.weixin.qq.com/s/7o4Fy0BNwVZKVUOyhJbMbA">https://mp.weixin.qq.com/s/7o4Fy0BNwVZKVUOyhJbMbA</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12087">https://www.scholat.com/teamwork/showPostMessage.html?id=12087</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-Swin Transformer论文精读-《Swin Transformer: Hierarchical Vision Transformer using Shifted Windows》</title>
    <url>/7b9e85bd.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2021-Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows.pdf" data-height="500px"></div>

<p>论文链接：<a href="https://arxiv.org/pdf/2103.14030.pdf">https://arxiv.org/pdf/2103.14030.pdf</a></p>
<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=850677660&bvid=BV13L4y1475U&cid=483320545&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p>Swin Transformer 是 ICCV 21 的最佳论文，它之所以能有这么大的影响力主要是因为在 ViT 之后，Swin Transformer 通过在一系列视觉任务上的强大表现 ，进一步证明了 Transformer 是可以在视觉领域取得广泛应用的</p>
<p>Swin Transformer 是 3 月份传到 arxiv 上的，4 月份代码库就放出来了，紧接着 5 月 12 号又放出来了自监督版本的 Swin Transformer–moby，其实就是把 MoCo 的前两个字母和 BYOL 的前两个字母合在了一起，从方法上和性能上其实和 MoCo v3 和 DINO 都差不多，只是换了个骨干网络，所以在上一篇对比学习串讲中也没有提这篇论文</p>
<p>接下来过了一个月，Swin Transformer 就被用到了视频领域，推出了 Video-Swin-Transformer，在一系列数据集上都取得了非常好的效果</p>
<ul>
<li>比如说在 k-400 这个数据集上就已经达到了 84.9 的准确度</li>
</ul>
<p>7月初的时候，因为看到了有 MLP Mixer 这篇论文，把 Swin 的思想用到了 MLP 里，推出了 Swin MLP</p>
<p>8月初的时候，把 Swin Transformer 用到了半监督的目标检测里，然后取得了非常好的效果</p>
<p>10月份的时候获得了 ICCV 的最佳论文奖</p>
<p>12月份受到了 BEiT 和 MAE 的推动，用 Swin Transformer 基于掩码自监督学习的方式做了一个叫 SimMIM 的论文</p>
<p>所以说在这大半年的时间里，原作者团队就以每个月一篇论文的速度，基本把视觉领域所有的任务都刷了个遍，而且 Swin Transformer 不光应用范围广，效果也非常的炸裂</p>
<p>Paperswithcode 网站上可以看到它在每个数据集上的表现如何，鉴于 Swin Transformer 的提出主要是用来做视觉的下游任务，所以主要看一下 COCO 和 ADE20K 这两个数据集上的表现</p>
<img src="/7b9e85bd/1.png" class>

<ul>
<li>上图展示了各种模型在 COCO 数据集上的表现</li>
<li>在 COCO 数据集的排行榜上排名第一的是一个叫 Swin V2 的模型，其实也是作者原班人马提出的 Version2，就是做了一个更大版本的 Swin Transformer，有 30 亿参数而且提出了一系列技术使得 Swin Transformer 可以在 1536 * 1536 的图片上做预训练，最后下游任务的效果就非常的好，COCO 都已经被刷到 63.1 了（去年大家用卷积神经网络的时候还在 54、55 的准确度上挣扎</li>
<li>排名第二的是一个叫 Florence 的模型，这是一个多模态的工作，它里面负责视觉的那部分用的是一个叫 CoSwin 的模型，也是 Swin Transformer 的一个变体</li>
<li>再往下 GLIP 也是用的 Swin large， Soft Teacher 也是 Swin large，DyHead 也是 Swin large，总之排名前十的方法全都用到了 Swin Transformer</li>
</ul>
<img src="/7b9e85bd/2.png" class>

<ul>
<li>上图展示了各种模型在 ADE20K 数据集上的表现</li>
<li>排名第一的还是 Swin V2 ，因为模型实在是太大了</li>
<li>排名二、三、四的都是一个叫 SeMask 的论文，也是基于 Swin large 的</li>
<li>第五名 BEiT 用的是 ViT，而不是 Swin</li>
<li>紧接着后面排名 6、7、8、9 全都还是用的是 Swin Transformer</li>
</ul>
<p>所以说，在 Swin Transformer 作者团队不懈的努力下，Swin Transformer 在大部分视觉领域很多数据集上都取得了最好的结果，这就导致 Swin Transformer 成了视觉领域一个绕不开的 Baseline，接下来再想在这些数据集上刷分或者说再想发这些领域的论文，多多少少都得提到 Swin Transformer 或者跟它比，所以说它的影响力是巨大的</p>
<hr>
<h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><p>Swin Transformer 是一个用了移动窗口的层级式的 Vision Transformer</p>
<ul>
<li>Swin：来自于 Shifted Windows ，S 和 win，Shifted Window（移动窗口）也是 Swin Transformer 这篇论文的主要贡献</li>
<li>层级式 Hierarchical</li>
</ul>
<p>其实 Swin Transformer 就是想让 Vision Transformer 像卷积神经网络一样，也能够分成几个 block，也能做层级式的特征提取，从而导致提出来的特征有多尺度的概念</p>
<p>作者团队来自 MSRA</p>
<ul>
<li>MSRA 经常被誉为是研究者的黄埔军校，从里面出来了一众大佬，而且产出了一系列非常有影响力的工作，比如说大家耳熟能详的、现在单篇引用已经超过 10 万的 ResNet，也是四位作者都在 MSRA 的时候完成的工作</li>
</ul>
<hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>这次精读的版本是作者在 8 月 17 号又重新上传的一个更新版本，里面的内容和细节都更多一些</p>
<p>这篇论文提出了一个新的 Vision Transformer 叫做 Swin Transformer，它可以被用来作为一个计算机视觉领域一个通用的骨干网络</p>
<ul>
<li>之所以这么说，是因为 ViT 在结论的部分指出，他们那篇论文只是做了分类任务，把下游任务比如说检测和分割留给以后的人去探索，所以说在 ViT 出来之后，大家虽然看到了 Transformer 在视觉领域的强大潜力，但是并不确定 Transformer 能不能把所有视觉的任务都做掉，所以 Swin Transformer 这篇论文的研究动机就是想告诉大家用 Transformer 没毛病，绝对能在方方面面上取代卷积神经网络，接下来大家都上 Transformer 就好了</li>
</ul>
<p>但是直接把 Transformer 从 NLP 用到 Vision 是有一些挑战的，这个挑战主要来自于两个方面</p>
<ul>
<li>一个就是尺度上的问题。因为比如说现在有一张街景的图片，里面有很多车和行人，里面的物体都大大小小，那这时候代表同样一个语义的词，比如说行人或者汽车就有非常不同的尺寸，这种现象在 NLP 中就没有</li>
<li>另外一个挑战是图像的 resolution 太大了，如果要以像素点作为基本单位的话，序列的长度就变得高不可攀，所以说之前的工作要么就是用后续的特征图来当做 Transformer 的输入，要么就是把图片打成 patch 减少这个图片的 resolution，要么就是把图片画成一个一个的小窗口，然后在窗口里面去做自注意力，所有的这些方法都是为了减少序列长度</li>
</ul>
<p>基于这两个挑战，本文的作者就提出了 hierarchical Transformer，它的特征是通过一种叫做移动窗口的方式学来的</p>
<ul>
<li>移动窗口的好处：不仅带来了更大的效率，因为跟之前的工作一样，现在自注意力是在窗口内算的，所以这个序列的长度大大的降低了；同时通过 shifting 移动的这个操作，能够让相邻的两个窗口之间有了交互，所以上下层之间就可以有 cross-window connection，从而变相的达到了一种全局建模的能力</li>
</ul>
<p>然后作者说这种层级式的结构不仅非常灵活，可以提供各个尺度的特征信息，同时因为自注意力是在小窗口之内算的，所以说它的计算复杂度是随着图像大小而线性增长，而不是平方级增长，这其实也为作者之后提出 Swin V2 铺平了道路，从而让他们可以在特别大的分辨率上去预训练模型</p>
<p>因为 Swin Transformer 拥有了像卷积神经网络一样分层的结构，有了这种多尺度的特征，所以它很容易使用到下游任务里，所以在这篇论文里，作者不光是在 ImageNet-1K 上做了实验，而且达到了非常好的准确度 87.3；而且还在密集预测型的任务上，比如说物体检测、物体分割上取得了很好的成绩，比如说在 COCO 上刷到 58.7 的 AP，比之前最好的方法高了 2.7 个点；然后在语义分割上，ADE 上也刷到了 53.5，比之前最好的方法高了 3.2 个点</p>
<p>这些数据集其实都是大家常刷的数据集，在上面往往只要能提升一个点，甚至可能不到一个点，只要故事讲的好可能都能发论文，但是 Swin Transformer 都提的大概 3 个点，提升是相当显著的，所以作者说这种基于 Transformer 的模型在视觉领域是非常有潜力的</p>
<p>为了凸显这篇文章的贡献，也就是 Shifted Windows 移动窗口的作用，这个版本又加了一句话：对于 MLP 的架构用 shift window 的方法也能提升，这句话其实这个版本才加入的，之前第一个版本就是投稿上那篇论文其实没有这句话，因为当时还没有 MLP Mixer 这篇论文</p>
<hr>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>引言的前两段其实跟 ViT 非常一致，都是先说在视觉领域，之前卷积神经网络是主导地位，但是 Transformer 在 NLP 领域用的这么好，所以也想把 Transformer 用到视觉领域里面</p>
<p>但因为 ViT 已经把这件事干了，所以说 Swin Transformer 在第三段的开始说他们的研究动机，是想证明 Transformer 是可以用作一个通用的骨干网络，就是对所有视觉的任务，不光是分类，在检测、分割视频上也都能取得很好的效果</p>
<img src="/7b9e85bd/3.png" class>

<ul>
<li>图一如上图所示，作者先说了一下 Vision Transformer，把它放在右边做对比</li>
<li>Vision Transformer 就是把图片打成 patch，因为 ViT 里用的 patch size 是 16 * 16 的，所以说这里的 16 ×，也就意味着是 16 倍的下采样率，这也就意味着每一个 patch，也就是每一个 token，自始至终代表的尺寸都是差不多的；每一层的 Transformer block 看到 token 的尺寸都是 16 倍下采样率。虽然它可以通过这种全局的自注意力操作，达到全局的建模能力，但是它对多尺寸特征的把握就会弱一些</li>
<li>对于视觉任务，尤其是下游任务比如说检测和分割来说，多尺寸的特征是至关重要的，比如说对目标检测而言，运用最广的一个方法就是 FPN（a feature pyramid network：当有一个分层式的卷积神经网络之后，每一个卷积层出来的特征的 receptive field（感受野）是不一样的，能抓住物体不同尺寸的特征，从而能够很好的处理物体不同尺寸的问题；对于物体分割任务来说，那最常见的一个网络就是 UNet，UNet 里为了处理物体不同尺寸的问题，提出来一个叫做 skip connection 的方法，当一系列下采样做完以后，去做上采样的时候，不光是从 bottleneck 里去拿特征，还从之前也就是每次下采样完之后的东西里去拿特征，这样就把那些高频率的图像细节又全都能恢复出来了，当然分割里大家常用的网络结构还有 PspNet、DeepLab，这些工作里也有相应的处理多尺寸的方法，比如说使用空洞卷积、使用 psp 和 aspp 层</li>
<li>总之，对于计算机视觉的下游任务，尤其是密集预测型的任务（检测、分割），有多尺寸的特征是至关重要的</li>
</ul>
<p>但是在 ViT 里处理的特征都是单一尺寸，而且是 low resolution，也就是说自始至终都是处理的 16 倍下采样率过后的特征，所以说，它可能就不适合处理这种密集预测型的任务，同时对 ViT 而言，自注意力始终都是在最大的窗口上进行，也就是说始终都是在整图上进行的，所以它是一个全局建模，它的复杂度是跟随图像的尺寸进行平方倍的增长，像检测和分割领域，一般现在常用的输入尺寸都是 800 * 800 或者 1000 * 1000，之前虽然用 patch size 16 能处理 224 * 224 的图片，但是当图片变到这么大的时候，即使用 patch size 16，序列长度还是会上千，计算复杂度还是难以承受的</p>
<p>所以基于这些挑战，作者提出了 Swin Transformer，Swin Transformer 其实是借鉴了很多卷积神经网络的设计理念以及先验知识</p>
<ul>
<li>比如说为了减少序列的长度、降低计算复杂度，Swin Transformer 采取了在小窗口之内算自注意力，而不是像 ViT 一样在整图上算自注意力，这样只要窗口大小是固定的，自注意力的计算复杂度就是固定的，整张图的计算复杂度就会跟图片的大小而成的线性增长关系，就是说图片增大了 x 倍，窗口数量也增大了 x 倍，计算复杂度也就乘以 x，而不是乘以 x 的平方</li>
<li>这个就算是利用了卷积神经网络里的 Locality 的 Inductive bias，就是利用了局部性的先验知识，同一个物体的不同部位或者语义相近的不同物体还是大概率会出现在相连的地方，所以即使是在一个 Local，一个小范围的窗口算自注意力也是差不多够用的，全局计算自注意力对于视觉任务来说，其实是有点浪费资源的</li>
<li>另外一个挑战是如何生成多尺寸的特征，卷积神经网络为什么会有多尺寸的特征？主要是因为有 Pooling（池化）这个操作，池化能够增大每一个卷积核能看到的感受野，从而使得每次池化过后的特征抓住物体的不同尺寸，所以类似的 Swin Transformer 也提出来了一个类似于池化的操作叫做 patch merging，就是把相邻的小 patch 合成一个大 patch，这样合并出来的这一个大 patch 其实就能看到之前四个小 patch 看到的内容，它的感受野就增大了，同时也能抓住多尺寸的特征</li>
</ul>
<img src="/7b9e85bd/4.png" class>

<ul>
<li>所以所上图中图一左边所示，Swin Transformer 刚开始的下采样率是 4 倍，然后变成了 8 倍、16 倍，之所以刚开始是 4× 的，是因为最开始的 patch 是 4 * 4 大小的，一旦有了多尺寸的特征信息，有了这种 4x、8x、16x 的特征图，那自然就可以把这些多尺寸的特征图输给一个 FPN，从而就可以去做检测了</li>
<li>同样的道理，有了这些多尺寸的特征图以后，也可以把它扔给一个 UNET，然后就可以去做分割了</li>
<li>所以这就是作者在这篇论文里反复强调的，Swin Transformer 是能够当做一个通用的骨干网络的，不光是能做图像分类，还能做密集预测性的任务</li>
</ul>
<p>第四段主要就开始讲 Swin Transformer 一个关键的设计因素————移动窗口的操作，如下图中图二所示</p>
<img src="/7b9e85bd/5.png" class>

<ul>
<li>如果在 Transformer 第 L 层把输入或者特征图分成小窗口的话，就会有效的降低序列长度，从而减少计算复杂度</li>
<li>图中每一个灰色的小 patch 是最基本的元素单元，也就是图一中 4 * 4 的 patch；每个红色的框是一个中型的计算单元，也就是一个窗口</li>
<li>在 Swin Transformer 这篇论文里，一个小窗口里面默认有七七四十九个小 patch 的</li>
</ul>
<p><strong>shift 的操作</strong></p>
<img src="/7b9e85bd/6.png" class>

<ul>
<li>如果用一个大的蓝色的正方形来描述整体的特征图，其实 shift 操作就是往右下角的方向整体移了两个 patch，也就变成了像下图中右图的格式</li>
</ul>
<img src="/7b9e85bd/7.png" class>

<ul>
<li>然后在新的特征图里把它再次分成四方格，如下图中右图所示</li>
</ul>
<img src="/7b9e85bd/8.png" class>

<ul>
<li>最后 shift 完就能得到下图中红线标出的结果了</li>
</ul>
<img src="/7b9e85bd/9.png" class>

<p>这样的好处是窗口与窗口之间可以进行互动，因为如果按照原来的方式，就是没有 shift，这些窗口之间都是不重叠的，如果每次自注意力的操作都在小的窗口里头进行了，每个窗口里的 patch 就永远无法注意到别的窗口里的 patch 的信息，这就达不到使用 Transformer 的初衷</p>
<ul>
<li>因为 Transformer 的初衷就是更好的理解上下文，如果窗口都是不重叠的，那自注意力真的就变成孤立自注意力，就没有全局建模的能力</li>
<li>但如果加上 shift 的操作，每个 patch 原来只能跟它所在的窗口里的别的 patch 进行交互，但是 shift 之后，这个 patch 就可以跟新的窗口里的别的 patch 就进行交互了，而这个新的窗口里所有的 patch 其实来自于上一层别的窗口里的 patch，这也就是作者说的能起到 cross-window connection，就是窗口和窗口之间可以交互了</li>
</ul>
<p>再配合上之后提出的 patch merging，合并到 Transformer 最后几层的时候，每一个 patch 本身的感受野就已经很大了，就已经能看到大部分图片了，然后再加上移动窗口的操作，它所谓的窗口内的局部注意力其实也就变相的等于是一个全局的自注意力操作了</p>
<ul>
<li>这样就是既省内存，效果也好</li>
</ul>
<p>第五段作者再次展示了一下结果，因为 Swin Transformer 的结果确实非常好，最后一段作者就展望了一下，作者说他们坚信一个 CV 和 NLP 之间大一统的框架是能够促进两个领域共同发展的</p>
<ul>
<li>确实如此，因为人在学习的过程中也是一个多模态的学习过程，但 Swin Transformer 还是利用了更多视觉里的先验知识，从而在视觉任务上大杀四方</li>
<li>但是在模型大一统上，也就是 unified architecture 上来说，其实 ViT 还是做的更好的，因为它真的可以什么都不改，什么先验信息都不加，就能让 Transformer 在两个领域都能用的很好，这样模型不仅可以共享参数，而且甚至可以把所有模态的输入直接就拼接起来，当成一个很长的输入，直接扔给 Transformer 去做，而不用考虑每个模态的特性</li>
</ul>
<hr>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>这篇论文提出了 Swin Transformer，它是一个层级式的 Transformer，而且它的计算复杂度是跟输入图像的大小呈线性增长的</p>
<p>Swin Transformerr 在 COCO 和 ADE20K 上的效果都非常的好，远远超越了之前最好的方法，所以作者说基于此，希望 Swin Transformer 能够激发出更多更好的工作，尤其是在多模态方面</p>
<p>因为在 Swin Transformer 这篇论文里最关键的一个贡献就是基于 Shifted Window 的自注意力，它对很多视觉的任务，尤其是对下游密集预测型的任务是非常有帮助的，但是如果 Shifted Window 操作不能用到 NLP 领域里，其实在模型大一统上论据就不是那么强了，所以作者说接下来他们的未来工作就是要把 Shifted Windows 用到 NLP 里面，而且如果真的能做到这一点，那 Swin Transformer 真的就是一个里程碑式的工作了，而且模型大一统的故事也就讲的圆满了</p>
<hr>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>跟 ViT 的相关工作非常相似，作者先大概讲了一下卷积神经网络，然后又讲了一下自注意力或者 Transformer 是如何用来帮助卷积神经网络的，最后纯 Transformer 用来做视觉里的骨干网络</p>
<hr>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>主要分为两大块</p>
<ul>
<li>大概把整体的流程讲了一下，主要就是过了一下前向过程，以及提出的 patch merging 操作是怎么做的</li>
<li>基于 Shifted Window 的自注意力，Swin Transformer 怎么把它变成一个 transformer block 进行计算</li>
</ul>
<p>模型总览图如下图所示</p>
<img src="/7b9e85bd/10.png" class>

<hr>
<h4 id="前向过程"><a href="#前向过程" class="headerlink" title="前向过程"></a>前向过程</h4><ul>
<li>假设说有一张 224 * 224 * 3（ImageNet 标准尺寸）的输入图片</li>
<li>第一步就是像 ViT 那样把图片打成 patch，在 Swin Transformer 这篇论文里，它的 patch size 是 4 * 4，而不是像 ViT 一样 16 * 16，所以说它经过 patch partition 打成 patch 之后，得到图片的尺寸是 56 * 56 * 48，56 就是 224 / 4，因为 patch size 是 4，向量的维度 48，因为 4 * 4 * 3，3 是图片的 RGB 通道</li>
<li>打完了 patch ，接下来就要做 Linear Embedding，也就是说要把向量的维度变成一个预先设置好的值，就是 Transformer 能够接受的值，在 Swin Transformer 的论文里把这个超参数设为 c，对于 Swin tiny 网络来说，也就是上图中画的网络总览图，它的 c 是 96，所以经历完 Linear Embedding 之后，输入的尺寸就变成了 56 * 56 * 96，前面的 56 * 56 就会拉直变成 3136，变成了序列长度，后面的 96 就变成了每一个 token 向量的维度，其实 Patch Partition 和 Linear Embedding 就相当于是 ViT 里的 Patch Projection 操作，而在代码里也是用一次卷积操作就完成了</li>
<li>第一部分跟 ViT 其实还是没有区别的，但紧接着区别就来了</li>
<li>首先序列长度是 3136，对于 ViT 来说，用 patch size 16 * 16，它的序列长度就只有 196，是相对短很多的，这里的 3136 就太长了，是目前来说 Transformer 不能接受的序列长度，所以 Swin Transformer 就引入了基于窗口的自注意力计算，每个窗口按照默认来说，都只有七七四十九个 patch，所以说序列长度就只有 49 就相当小了，这样就解决了计算复杂度的问题</li>
<li>所以也就是说，stage1 中的 swin transformer block 是基于窗口计算自注意力的，现在暂时先把 transformer block 当成是一个黑盒，只关注输入和输出的维度，对于 Transformer 来说，如果不对它做更多约束的话，Transformer 输入的序列长度是多少，输出的序列长度也是多少，它的输入输出的尺寸是不变的，所以说在 stage1 中经过两层 Swin Transformer block 之后，输出还是 56 * 56 * 96</li>
<li>到这其实 Swin Transformer 的第一个阶段就走完了，也就是先过一个 Patch Projection 层，然后再过一些 Swin Transformer block，接下来如果想要有多尺寸的特征信息，就要构建一个层级式的 transformer，也就是说需要一个像卷积神经网络里一样，有一个类似于池化的操作</li>
</ul>
<p>这篇论文里作者就提出 Patch Merging 的操作，Patch Merging 其实在之前一些工作里也有用到，它很像 Pixel Shuffle 的上采样的一个反过程，Pixel Shuffle 是 lower level 任务中很常用的一个上采样方式</p>
<p><strong>Patch Merging</strong> 操作举例如下图所示</p>
<img src="/7b9e85bd/11.png" class>

<ul>
<li>假如有一个张量，Patch Merging 顾名思义就是把临近的小 patch 合并成一个大 patch，这样就可以起到下采样一个特征图的效果了</li>
<li>这里因为是想下采样两倍，所以说在选点的时候是每隔一个点选一个，也就意味着说对于这个张量来说，每次选的点是1、1、1、1</li>
</ul>
<img src="/7b9e85bd/12.png" class>

<ul>
<li>其实在这里的 1、2、3、4 并不是矩阵里有的值，而是给它的一个序号，同样序号位置上的 patch 就会被 merge 到一起，这个序号只是为了帮助理解</li>
<li>经过隔一个点采一个样之后，原来的这个张量就变成了四个张量，也就是说所有的 1 都在一起了，2 在一起，3 在一起，4 在一起，如果原张量的维度是 h * w * c ，当然这里 c 没有画出来，经过这次采样之后就得到了 4 个张量，每个张量的大小是 h/2、w/2，它的尺寸都缩小了一倍</li>
<li>现在把这四个张量在 c 的维度上拼接起来，也就变成了下图中红线所画出来的形式，张量的大小就变成了 h/2 * w/2 * 4c，相当于用空间上的维度换了更多的通道数</li>
</ul>
<img src="/7b9e85bd/13.png" class>

<ul>
<li>通过这个操作，就把原来一个大的张量变小了，就像卷积神经网络里的池化操作一样，为了跟卷积神经网络那边保持一致（不论是 VGGNet 还是 ResNet，一般在池化操作降维之后，通道数都会翻倍，从 128 变成 256，从 256 再变成 512），所以这里也只想让他翻倍，而不是变成 4 倍，所以紧接着又再做了一次操作，就是在 c 的维度上用一个 1 * 1 的卷积，把通道数降下来变成 2c，通过这个操作就能把原来一个大小为 h * w * c 的张量变成 h/2 * w/2 * 2c 的一个张量，也就是说空间大小减半，但是通道数乘 2，这样就跟卷积神经网络完全对等起来了</li>
</ul>
<p>整个这个过程就是 Patch Merging，经历过这次 Patch Merging 操作之后，输出的大小就从 56 * 56 * 96 变成了 28 * 28 * 192，经过 stage2 中的 Transformer block，尺寸是不变的，所以出来之后还是 28 * 28 * 192</p>
<img src="/7b9e85bd/14.png" class>

<p>这样第二阶段也就完成了，第三和第四阶段都是同理，都是先进来做一次 Patch Merging，然后再通过一些 Swin Transformer block，所以维度就进一步降成了 14 * 14 * 384 以及 7 * 7 * 768</p>
<p>这里其实会发现，特征图的维度真的跟卷积神经网络好像，因为如果回想残差网络的多尺寸的特征，就是经过每个残差阶段之后的特征图大小也是 56 * 56、28 * 28、14 * 14，最后是 7 * 7</p>
<img src="/7b9e85bd/15.png" class>

<p>而且为了和卷积神经网络保持一致，Swin Transformer 这篇论文并没有像 ViT 一样使用 CLS token，ViT 是给刚开始的输入序列又加了一个 CLS token，所以这个长度就从 196 变成了 197，最后拿 CLS token 的特征直接去做分类，但 Swin Transformer 没有用这个 token，它是像卷积神经网络一样，在得到最后的特征图之后用global average polling，就是全局池化的操作，直接把 7 * 7 就取平均拉直变成 1 了</p>
<ul>
<li>作者这个图里并没有画，因为 Swin Transformer 的本意并不是只做分类，它还会去做检测和分割，所以说它只画了骨干网络的部分，没有去画最后的分类头或者检测头，但是如果是做分类的话，最后就变成了 1 * 768，然后又变成了 1 * 1,000</li>
</ul>
<img src="/7b9e85bd/16.png" class>

<ul>
<li>如果是做ImageNet的话，这样就完成了整个一个分类网络的前向过程</li>
</ul>
<p>所以看完整个前向过程之后，就会发现 Swin Transformer 有四个 stage，还有类似于池化的 patch merging 操作，自注意力还是在小窗口之内做的以及最后还用的是 global average polling，所以说 Swin Transformer 这篇论文真的是把卷积神经网络和 Transformer 这两系列的工作完美的结合到了一起，也可以说它是披着 Transformer 皮的卷积神经网络</p>
<hr>
<h4 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h4><p>这篇论文的主要贡献就是基于窗口或者移动窗口的自注意力，这里作者又写了一段研究动机，就是为什么要引入窗口的自注意力，其实跟之前引言里说的都是一个事情，就是说全局自注意力的计算会导致平方倍的复杂度，同样当去做视觉里的下游任务，尤其是密集预测型的任务，或者说遇到非常大尺寸的图片时候，这种全局算自注意力的计算复杂度就非常贵了，所以就用窗口的方式去做自注意力</p>
<hr>
<h5 id="窗口划分举例"><a href="#窗口划分举例" class="headerlink" title="窗口划分举例"></a>窗口划分举例</h5><p>原图片会被平均的分成一些没有重叠的窗口，拿第一层之前的输入来举例，它的尺寸就是 56 * 56 * 96，也就说有一个维度是 56 * 56 张量，然后把它切成一些不重叠的方格，也就是下图中用橘黄色表示的方格</p>
<img src="/7b9e85bd/17.png" class>

<ul>
<li>每一个橘黄色的方格就是一个窗口，但是这个窗口并不是最小的计算单元，最小的计算单元其实还是之前的那个 patch，也就意味着每一个小窗口里其实还有 m * m 个 patch，在 Swin Transformer 这篇论文里一般 m 默认为 7，也就是说，一个橘黄色的小方格里有七七四十九个小 patch</li>
<li>现在所有自注意力的计算都是在这些小窗口里完成的，就是说序列长度永远都是七七四十九</li>
<li>原来大的整体特征图到底里面会有多少个窗口呢？其实也就是每条边 56 / 7 就 8 个窗口，也就是说一共会有 8 * 8 等于 64 个窗口，就是说会在这 64 个窗口里分别去算它们的自注意力</li>
</ul>
<hr>
<h4 id="基于窗口的自注意力模式的计算复杂度"><a href="#基于窗口的自注意力模式的计算复杂度" class="headerlink" title="基于窗口的自注意力模式的计算复杂度"></a>基于窗口的自注意力模式的计算复杂度</h4><p>说到底，基于窗口的自注意力计算方式能比全局的自注意力方式省多少呢？在 Swin Transformer 这篇论文里作者就给出了一个大概的估计，它给出了两个公式如下图所示</p>
<img src="/7b9e85bd/18.png" class>

<ul>
<li>公式（1）对应的是标准的多头自注意力的计算复杂度</li>
<li>每一个图片大概会有 h * w 个 patch，在刚才的例子里，h 和 w 分别都是 56，c 是特征的维度</li>
<li>公式（2）对应的是基于窗口的自注意力计算的复杂度，这里的 M 就是刚才的 7，也就是说一个窗口的某条边上有多少个 patch</li>
</ul>
<hr>
<h4 id="公式推算"><a href="#公式推算" class="headerlink" title="公式推算"></a>公式推算</h4><p>以标准的多头自注意力为例</p>
<img src="/7b9e85bd/19.png" class>

<ul>
<li>如果现在有一个输入，自注意力首先把它变成 q k v 三个向量，这个过程其实就是原来的向量分别乘了三个系数矩阵</li>
<li>一旦得到 query 和 k 之后，它们就会相乘，最后得到 attention，也就是自注意力的矩阵</li>
<li>有了自注意力之后，就会和 value 做一次乘法，也就相当于是做了一次加权</li>
<li>最后因为是多头自注意力，所以最后还会有一个 projection layer，这个投射层会把向量的维度投射到我们想要的维度</li>
</ul>
<p>如果这些向量都加上它们该有的维度，也就是说刚开始输入是 h * w * c</p>
<img src="/7b9e85bd/20.png" class>

<ul>
<li>首先，to_q_k_v()函数相当于是用一个 h * w * c 的向量乘以一个 c * c 的系数矩阵，最后得到了 h * w * c。所以每一个计算的复杂度是 h * w * c^2，因为有三次操作，所以是三倍的 h * w * c^2</li>
<li>然后，算自注意力就是 h * w * c 乘以 k 的转置，也就是 c * h * w，所以得到了 h * w * h * w，这个计算复杂度就是(h * w)^2 * c</li>
<li>接下来，自注意力矩阵和 value 的乘积的计算复杂度还是 (h * w)^2 * c，所以现在就成了 2 * (h * w)^2 * c</li>
<li>最后一步，投射层也就是 h * w * c 乘以 c * c 变成了 h * w * c ，它的计算复杂度就又是 h * w * c^2</li>
<li>最后合并起来就是最后的公式（1）</li>
</ul>
<p>基于窗口的自注意力计算复杂度又是如何得到的呢？</p>
<ul>
<li>因为在每个窗口里算的还是多头自注意力，所以可以直接套用公式（1），只不过高度和宽度变化了，现在高度和宽度不再是 h * w，而是变成窗口有多大了，也就是 M * M，也就是说现在 h 变成了 M，w 也是 M，它的序列长度只有 M * M 这么大</li>
<li>所以当把 M 值带入到公式（1）之后，就得到计算复杂度是 4 * M^2 * c^2 + 2 * M^4 * c，这个就是在一个窗口里算多头自注意力所需要的计算复杂度</li>
<li>那我们现在一共有 h/M * w/M 个窗口，现在用这么多个窗口乘以每个窗口所需要的计算复杂度就能得到公式（2）了</li>
</ul>
<p>对比公式（1）和公式（2），虽然这两个公式前面这两项是一样的，只有后面从 (h * w)^2 变成了 M^2 * h * w，看起来好像差别不大，但其实如果仔细带入数字进去计算就会发现，计算复杂的差距是相当巨大的，因为这里的 h * w 如果是 56 * 56 的话， M^2 其实只有 49，所以是相差了几十甚至上百倍的</p>
<p>这种基于窗口计算自注意力的方式虽然很好地解决了内存和计算量的问题，但是窗口和窗口之间没有通信，这样就达不到全局建模了，也就文章里说的会限制模型的能力，所以最好还是要有一种方式能让窗口和窗口之间互相通信起来，这样效果应该会更好，因为具有上下文的信息，所以作者就提出移动窗口的方式</p>
<p>移动窗口就是把原来的窗口往右下角移动一半窗口的距离，如果 Transformer 是上下两层连着做这种操作，先是 window 再是 shifted window 的话，就能起到窗口和窗口之间互相通信的目的了</p>
<p>所以说在 Swin Transformer 里， transformer block 的安排是有讲究的，每次都是先要做一次基于窗口的多头自注意力，然后再做一次基于移动窗口的多头自注意力，这样就达到了窗口和窗口之间的互相通信。如下图所示</p>
<img src="/7b9e85bd/21.png" class>

<ul>
<li>每次输入先进来之后先做一次 Layernorm，然后做窗口的多头自注意力，然后再过 Layernorm 过 MLP，第一个 block 就结束了</li>
<li>这个 block 结束以后，紧接着做一次 Shifted window，也就是基于移动窗口的多头自注意力，然后再过 MLP 得到输出</li>
<li>这两个 block 加起来其实才算是 Swin Transformer 一个基本的计算单元，这也就是为什么 stage1、2、3、4 中的 swin transformer block 为什么是 <em>2、</em>2、<em>6、</em>2，也就是一共有多少层 Swin Transformer block 的数字总是偶数，因为它始终都需要两层 block 连在一起作为一个基本单元，所以一定是 2 的倍数</li>
</ul>
<p>到此，Swin Transformer 整体的故事和结构就已经讲完了，主要的研究动机就是想要有一个层级式的 Transformer，为了这个层级式，所以介绍了 Patch Merging 的操作，从而能像卷积神经网络一样把 Transformer 分成几个阶段，为了减少计算复杂度，争取能做视觉里密集预测的任务，所以又提出了基于窗口和移动窗口的自注意力方式，也就是连在一起的两个 Transformer block，最后把这些部分加在一起，就是 Swin Transformer 的结构</p>
<p>其实作者后面还讲了两个点</p>
<ul>
<li>一个是怎样提高移动窗口的计算效率，他们采取了一种非常巧妙的 masking（掩码）的方式</li>
<li>另外一个点就是这篇论文里没有用绝对的位置编码，而是用相对的位置编码</li>
</ul>
<p>但这两个点其实都是为了提高性能的一些技术细节，跟文章整体的故事已经没有多大关系了</p>
<img src="/7b9e85bd/22.png" class>

<ul>
<li>上图是一个基础版本的移动窗口，就是把左边的窗口模式变成了右边的窗口方式</li>
<li>虽然这种方式已经能够达到窗口和窗口之间的互相通信了，但是会发现一个问题，就是原来计算的时候，特征图上只有 4 个窗口，但是做完移动窗口操作之后得到了 9 个窗口，窗口的数量增加了，而且每个窗口里的元素大小不一，比如说中间的窗口还是 4 * 4，有 16 个 patch，但是别的窗口有的有 4 个 patch，有的有 8 个 patch，都不一样了，如果想做快速运算，就是把这些窗口全都压成一个 patch 直接去算自注意力，就做不到了，因为窗口的大小不一样</li>
<li>有一个简单粗暴的解决方式就是把这些小窗口周围再 pad 上 0 ，把它照样 pad 成和中间窗口一样大的窗口，这样就有 9 个完全一样大的窗口，这样就还能把它们压成一个 batch，就会快很多</li>
<li>但是这样的话，无形之中计算复杂度就提升了，因为原来如果算基于窗口的自注意力只用算 4 个窗口，但是现在需要去算 9 个窗口，复杂度一下提升了两倍多，所以还是相当可观的</li>
<li>那怎么能让第二次移位完的窗口数量还是保持 4 个，而且每个窗口里的 patch 数量也还保持一致呢？作者提出了一个非常巧妙的掩码方式，如下图所示</li>
</ul>
<img src="/7b9e85bd/23.png" class>

<ul>
<li>上图是说，当通过普通的移动窗口方式，得到 9 个窗口之后，现在不在这 9 个窗口上算自注意力，先再做一次循环移位（cyclic shift）</li>
<li>经过这次循环移位之后，原来的窗口（虚线）就变成了现在窗口（实线）的样子，那如果在大的特征图上再把它分成四宫格的话，就又得到了 4 个窗口，意思就是说移位之前的窗口数也是 4 个，移完位之后再做一次循环移位得到窗口数还是 4 个，这样窗口的数量就固定了，也就说计算复杂度就固定了</li>
<li>但是新的问题就来了，虽然对于移位后左上角的窗口（也就是移位前最中间的窗口）来说，里面的元素都是互相紧挨着的，他们之间可以互相两两做自注意力，但是对于剩下几个窗口来说，它们里面的元素是从别的很远的地方搬过来的，所以他们之间，按道理来说是不应该去做自注意力，也就是说他们之间不应该有什么太大的联系</li>
<li>解决这个问题就需要一个很常规的操作，也就是掩码操作，这在 Transformer 过去的工作里是层出不穷，很多工作里都有各式各样的掩码操作</li>
<li>在 Swin Transformer 这篇论文里，作者也巧妙的设计了几种掩码的方式，从而能让一个窗口之中不同的区域之间也能用一次前向过程，就能把自注意力算出来，但是互相之间都不干扰，也就是后面的 masked  Multi-head Self Attention（MSA）</li>
<li>算完了多头自注意力之后，还有最后一步就是需要把循环位移再还原回去，也就是说需要把 A、B、C 再还原到原来的位置上去，原因是还需要保持原来图片的相对位置大概是不变的，整体图片的语义信息也是不变的，如果不把循环位移还原的话，那相当于在做 Transformer 的操作之中，一直在把图片往右下角移，不停的往右下角移，这样图片的语义信息很有可能就被破坏掉了</li>
<li>所以说整体而言，上图介绍了一种高效的、批次的计算方式，比如说本来移动窗口之后得到了 9 个窗口，而且窗口之间的 patch 数量每个都不一样，为了达到高效性，为了能够进行批次处理，先进行一次循环位移，把 9 个窗口变成 4 个窗口，然后用巧妙的掩码方式让每个窗口之间能够合理地计算自注意力，最后再把算好的自注意力还原，就完成了基于移动窗口的自注意力计算</li>
</ul>
<hr>
<h4 id="掩码操作举例"><a href="#掩码操作举例" class="headerlink" title="掩码操作举例"></a>掩码操作举例</h4><p><strong>掩码可视化</strong></p>
<img src="/7b9e85bd/24.png" class>

<ul>
<li>作者通过这种巧妙的循环位移的方式和巧妙设计的掩码模板，从而实现了只需要一次前向过程，就能把所有需要的自注意力值都算出来，而且只需要计算 4 个窗口，也就是说窗口的数量没有增加，计算复杂度也没有增加，非常高效的完成了这个任务</li>
</ul>
<p>在方法的最后一节也就是 3.3 节，作者大概介绍了一下他们提出的 Swin Transformer 的几个变体</p>
<ul>
<li>Swin Tiny</li>
<li>Swin Small</li>
<li>Swin Base</li>
<li>Swin Large</li>
</ul>
<p>Swin Tiny 的计算复杂度跟 ResNet-50 差不多，Swin Small 的复杂度跟 ResNet-101 是差不多的，这样主要是想去做一个比较公平的对比</p>
<p>这些变体之间有哪些不一样呢？其实主要不一样的就是两个超参数</p>
<ul>
<li>一个是向量维度的大小 c</li>
<li>另一个是每个 stage 里到底有多少个 transform block</li>
</ul>
<p>这里其实就跟残差网络就非常像了，残差网络也是分成了四个 stage，每个 stage 有不同数量的残差块</p>
<hr>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>首先是分类上的实验，这里一共说了两种预训练的方式</p>
<ul>
<li>第一种就是在正规的 ImageNet-1K（128万张图片、1000个类）上做预训练</li>
<li>第二种方式是在更大的 ImageNet-22K（1400万张图片、2万多个类别）上做预训练</li>
</ul>
<p>当然不论是用 ImageNet-1K 去做预训练，还是用 ImageNet-22K 去做预训练，最后测试的结果都是在 ImageNet-1K 的测试集上去做的，结果如下表所示</p>
<img src="/7b9e85bd/25.png" class>

<ul>
<li>上半部分是 ImageNet-1K 预训练的模型结果</li>
<li>下半部分是先用 ImageNet-22K 去预训练，然后又在 ImageNet-1K 上做微调，最后得到的结果</li>
<li>在表格的上半部分，作者先是跟之前最好的卷积神经网络做了一下对比，RegNet 是之前 facebook 用 NASA 搜出来的模型，EfficientNet 是 google 用 NASA 搜出来的模型，这两个都算之前表现非常好的模型了，他们的性能最高会到 84.3</li>
<li>接下来作者就写了一下之前的 Vision Transformer 会达到什么效果，对于 ViT 来说，因为它没有用很好的数据增强，而且缺少偏置归纳，所以说它的结果是比较差的，只有 70 多</li>
<li>换上 DeiT 之后，因为用了更好的数据增强和模型蒸馏，所以说 DeiT Base 模型也能取得相当不错的结果，能到 83.1</li>
<li>当然 Swin Transformer 能更高一些，Swin Base 最高能到 84.5，稍微比之前最好的卷积神经网络高那么一点点，就比 84.3 高了 0.2</li>
<li>虽然之前表现最好的 EfficientNet 的模型是在 600 * 600 的图片上做的，而 Swin Base 是在 384 * 384 的图片上做的，所以说 EfficientNet 有一些优势，但是从模型的参数和计算的 FLOPs 上来说 EfficientNet 只有 66M，而且只用了 37G 的 FLOPs，但是 Swin Transformer 用了 88M 的模型参数，而且用了 47G 的 FLOPs，所以总体而言是伯仲之间</li>
<li>表格的下半部分是用 ImageNet-22k 去做预训练，然后再在 ImageNet-1k 上微调最后得到的结果</li>
<li>这里可以看到，一旦使用了更大规模的数据集，原始标准的 ViT 的性能也就已经上来了，对于 ViT large 来说它已经能得到 85.2 的准确度了，已经相当高了</li>
<li>但是 Swin Large 更高，Swin Large 最后能到87.3，这个是在不使用 JFT-300M，就是特别大规模数据集上得到的结果，所以还是相当高的</li>
</ul>
<p>接下来是目标检测的结果，作者是在 COCO 数据集上训练并且进行测试的，结果如下图所示</p>
<img src="/7b9e85bd/26.png" class>

<ul>
<li>表2（a）中测试了在不同的算法框架下，Swin Transformer 到底比卷积神经网络要好多少，主要是想证明 Swin Transformer 是可以当做一个通用的骨干网络来使用的，所以用了 Mask R-CNN、ATSS、RepPointsV2 和SparseR-CNN，这些都是表现非常好的一些算法，在这些算法里，过去的骨干网络选用的都是 ResNet-50，现在替换成了 Swin Tiny</li>
<li>Swin Tiny 的参数量和 FLOPs 跟 ResNet-50 是比较一致的，从后面的对比里也可以看出来，所以他们之间的比较是相对比较公平的</li>
<li>可以看到，Swin Tiny 对 ResNet-50 是全方位的碾压，在四个算法上都超过了它，而且超过的幅度也是比较大的</li>
<li>接下来作者又换了一个方式做测试，现在是选定一个算法，选定了 Cascade Mask R-CNN 这个算法，然后换更多的不同的骨干网络，比如 DeiT-S、ResNet-50 和 ResNet-101，也分了几组，结果如上图中表2（b）所示</li>
<li>可以看出，在相似的模型参数和相似的 Flops 之下，Swin Transformer 都是比之前的骨干网络要表现好的</li>
<li>接下来作者又做了第三种测试的方式，如上图中的表2（c）所示，就是系统层面的比较，这个层面的比较就比较狂野了，就是现在追求的不是公平比较，什么方法都可以上，可以使用更多的数据，可以使用更多的数据增强，甚至可以在测试的使用 test time augmentation（TTA）的方式</li>
<li>可以看到，之前最好的方法 Copy-paste 在 COCO Validation Set上的结果是55.9，在 Test Set 上的结果是 56，而这里如果跟最大的 Swin Transformer–Swin Large 比，它的结果分别能达到 58 和 58.7，这都比之前高了两到三个点</li>
</ul>
<p>第三个实验作者选择了语义分割里的ADE20K数据集，结果如下图所示</p>
<img src="/7b9e85bd/27.png" class>

<ul>
<li>上图表 3 里可以看到之前的方法，一直到 DeepLab V3、ResNet 其实都用的是卷积神经网络，之前的这些方法其实都在 44、45 左右徘徊</li>
<li>但是紧接着 Vision Transformer 就来了，那首先就是 SETR 这篇论文，他们用了 ViT Large，所以就取得了 50.3 的这个结果</li>
<li>Swin Transformer Large 也取得了 53.5 的结果，就刷的更高了</li>
<li>其实作者这里也有标注，就是有两个“+”号的，意思是说这些模型是在 ImageNet-22K 数据集上做预训练，所以结果才这么好</li>
</ul>
<p>消融实验的实验结果如下图所示</p>
<img src="/7b9e85bd/28.png" class>

<ul>
<li>上图中表 4 主要就是想说一下移动窗口以及相对位置编码到底对 Swin Transformer 有多有用</li>
<li>可以看到，如果光分类任务的话，其实不论是移动窗口，还是相对位置编码，它的提升相对于基线来说，也没有特别明显，当然在 ImageNet 的这个数据集上提升一个点也算是很显著了</li>
<li>但是他们更大的帮助，主要是出现在下游任务里，就是 COCO 和 ADE20K 这两个数据集上，也就是目标检测和语义分割这两个任务上</li>
<li>可以看到，用了移动窗口和相对位置编码以后，都会比之前大概高了 3 个点左右，提升是非常显著的，这也是合理的，因为如果现在去做这种密集型预测任务的话，就需要特征对位置信息更敏感，而且更需要周围的上下文关系，所以说通过移动窗口提供的窗口和窗口之间的互相通信，以及在每个 Transformer block 都做更准确的相对位置编码，肯定是会对这类型的下游任务大有帮助的</li>
</ul>
<hr>
<h3 id="点评"><a href="#点评" class="headerlink" title="点评"></a>点评</h3><p>除了作者团队自己在过去半年中刷了那么多的任务，比如说最开始讲的自监督的Swin Transformer，还有 Video Swin Transformer 以及 Swin MLP，同时 Swin Transformer 还被别的研究者用到了不同的领域</p>
<img src="/7b9e85bd/29.png" class>

<p>所以说，Swin Transformer 真的是太火，真的是在视觉领域大杀四方，感觉以后每个任务都逃不了跟 Swin 比一比，而且因为 Swin 这么火，所以说其实很多开源包里都有 Swin 的实现</p>
<ul>
<li>百度的 PaddlePaddle</li>
<li>视觉里现在比较火的 pytorch-image-models，就是 Timm 这个代码库里面也是有 Swin 的实现的</li>
<li>同时 Hugging Face 估计也是有的</li>
</ul>
<p>虽然前面已经说了很多 Swin Transformer 的影响力啊已经这么巨大了，但其实他的影响力远远不止于此，论文里这种对卷积神经网络，对 Transformer，还有对 MLP 这几种架构深入的理解和分析是可以给更多的研究者带来思考的，从而不仅可以在视觉领域里激发出更好的工作，而且在多模态领域里，相信它也能激发出更多更好的工作</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv14877004">https://www.bilibili.com/read/cv14877004</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-AlphaFold 2 论文精读-《Highly accurate protein structure prediction with AlphaFold》</title>
    <url>/20ee1ad6.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2021-Highly-accurate-protein-structure-prediction-with-AlphaFold.pdf" data-height="500px"></div>

<p>论文链接：<a href="https://www.nature.com/articles/s41586-021-03819-2.pdf">https://www.nature.com/articles/s41586-021-03819-2.pdf</a></p>
<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=338444233&bvid=BV1oR4y1K7Xr&cid=491148105&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="用AlphaFold进行非常精确的蛋白质结构的预测-AlphaFold2"><a href="#用AlphaFold进行非常精确的蛋白质结构的预测-AlphaFold2" class="headerlink" title="用AlphaFold进行非常精确的蛋白质结构的预测(AlphaFold2)"></a>用AlphaFold进行非常精确的蛋白质结构的预测(AlphaFold2)</h3><ul>
<li>发表于 2021 年 7 月 15 日 Nature</li>
<li>DOI: 10.1038/s41586-021-03819-2</li>
<li>自然和科学杂志评选为2021年最重要的科学突破之一</li>
<li>2021 年 AI 在科学界最大的突破</li>
</ul>
<hr>
<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><ul>
<li>2020 年 11 月 30 号, deepmind 博客说 AlphaFold 解决了 50 年以来生物学的大挑战</li>
<li>2021 年 7 月 15 日华盛顿大学的 Protein Design 团队在发布在 8 月 15 日将在 Science 上发表了一个 RoseTTAFold, 使用深度神经网络进行蛋白质结构的预测</li>
</ul>
<hr>
<h4 id="文章结构"><a href="#文章结构" class="headerlink" title="文章结构"></a>文章结构</h4><ul>
<li>摘要</li>
<li>导论: 一页半</li>
<li>alphafold2: 两页出头, 模型介绍以及训练细节</li>
<li>结果分析: 一页</li>
<li>相关工作: 非常短</li>
<li>讨论</li>
<li>附录方法的细节</li>
<li>SI: 50页, 详细的解释了每个模型里面的细节</li>
</ul>
<hr>
<h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p><strong>问题</strong></p>
<ul>
<li>蛋白质对于生命来说是必要的, 了解蛋白质的结构有助于理解蛋白质的功能</li>
<li>蛋白质是长的氨基酸序列, 不稳定, 容易卷在一起, 从而形成独特的3d结构, 从而决定了蛋白质的功能</li>
<li>预测的困难(蛋白质折叠问题), 只知道很少一部分蛋白质的结构, 实验上通过冷冻方法观察费时费力</li>
</ul>
<p><strong>现有方法</strong></p>
<ul>
<li>AlphaFold1 精度不够, 不在原子的精度</li>
<li>AlphaFold2 能够达到原子的精度</li>
<li>AlphaFold2 使用了物理和生物学的知识, 也同样使用了深度学习</li>
</ul>
<p><strong>应用型的文章</strong></p>
<ul>
<li>问题对于领域来说重不重要</li>
<li>结果的好坏, 是不是解决了这个问题</li>
<li>找新问题或者开发新模型</li>
</ul>
<hr>
<h4 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h4><img src="/20ee1ad6/1.png" class>

<p><strong>a 图</strong></p>
<ul>
<li>x 轴: 参赛队伍</li>
<li>y 轴: 特定置信区间内, 平均预测的位置和真实的位置在的一个平均的区别(单位是埃)</li>
<li>AlphaFold 是 1A, 碳原子的大小大概是 1.5A</li>
<li>表述结果: 将绝对值变为相对值, 从 1A 到原子精度, 例如图片识别比人类还要好</li>
</ul>
<p><strong>b, c, d图</strong></p>
<ul>
<li>实验室和计算出来的结果, b 错误率比较小, c 和相对值进行比较, e 复杂的图形</li>
</ul>
<p><strong>e 图</strong></p>
<ul>
<li>模型大概</li>
</ul>
<img src="/20ee1ad6/2.png" class>

<p>PDB 数据集上 AlphaFold2 的精度</p>
<ul>
<li>a 图: 描述数据误差分布结果</li>
</ul>
<hr>
<h4 id="模型和训练"><a href="#模型和训练" class="headerlink" title="模型和训练"></a>模型和训练</h4><img src="/20ee1ad6/3.png" class>

<h5 id="AlphaFold2算法总览图"><a href="#AlphaFold2算法总览图" class="headerlink" title="AlphaFold2算法总览图"></a>AlphaFold2算法总览图</h5><p><strong>输入：</strong>蛋白质氨基酸的序列<br><strong>输出：</strong>对每个氨基酸序列预测三维空间位置</p>
<p>可以大致分为三部分：</p>
<ol>
<li>第一部分: 抽特征, 主要是两大类特征, 不同序列的特征以及氨基酸之间的特征</li>
</ol>
<ul>
<li>直接导入神经网络</li>
<li>从基因数据库里搜索相似的序列(MSA, 多序列比对), 可以认为是字符串匹配过程</li>
<li>氨基酸直接的关系(Pairing), 其中是每个是一对氨基酸之间的关系, 最好是一对氨基酸在三维空间的距离(但是不知道)</li>
<li>结构数据库中搜索序列, 真实的氨基酸对之间的信息, 得到很多模板</li>
</ul>
<ol start="2">
<li>第二部分: 编码器</li>
</ol>
<ul>
<li>将前面抽取的特征和后面的东西拼起来进入编码器</li>
<li>输入是两个三维的张量，MSA 表示(s, r, c)，Pair 表示(r, r, c)，s 行(第 1 行是要预测的蛋白质, s-1为数据库匹配得到的)，r 个氨基酸，长度为 c 的向量表示每个氨基酸</li>
<li>进入 Transform 的架构(Evoformer)，关系不再是一维的序列而是二维的矩阵，输入的是两个不同的张量，通过 48 个块抽取特征</li>
</ul>
<ol start="3">
<li>第三部分: 解码器</li>
</ol>
<ul>
<li>解码器拿到编码器的输出, 目标氨基酸的表示(r, c)和氨基酸对之间的表示(r, r, c)</li>
</ul>
<p><strong>回收机制</strong></p>
<ul>
<li>将编码器的输出和解码器的输出通过回收机制变成了编码器的输入, 迭代思想或者复制三倍深度更深</li>
<li>回收梯度不反传, 经过 56 层(48+8)就能计算梯度</li>
</ul>
<hr>
<h5 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h5><img src="/20ee1ad6/4.png" class>

<p><strong>编码器的架构(一块)</strong></p>
<ul>
<li>多头自注意力的模块</li>
<li>残差链接 &amp; MLP</li>
<li>信息交互: 氨基酸对的信息可以加入序列的建模中, 序列的信息也可以加入到氨基酸对的信息</li>
<li>自注意力机制，序列中按行和按列的自注意力机制，氨基酸对中通过物理信息(三角不等式)来设计QKV</li>
<li>不共享权重</li>
</ul>
<img src="/20ee1ad6/5.png" class>

<img src="/20ee1ad6/6.png" class>

<p><strong>编码器第一个模块(MSA row-wise gated self-attention with pair bias)详细的示意图</strong></p>
<ul>
<li>row-wise: 在 MSA 中每次拿出一行做一个序列, 做多头自注意力机制</li>
<li>gated: 将每个头做一次线性投影以及 sigmoid 计算, 之后和 attention 的输出点乘, 完成门的操作</li>
<li>pair bias: QK 是 Q 的氨基酸和K的氨基酸的相似度, 这个和 pair 表示有一定的相似的, 将 pair 经过线性投影到 h 维, 从而添加到 QK 中</li>
</ul>
<img src="/20ee1ad6/7.png" class>

<p><strong>编码器第二个模块(MSA column-wise gated self-attention)</strong></p>
<ul>
<li>和之前的区别: 按行, 无对信息做偏移加入</li>
</ul>
<img src="/20ee1ad6/8.png" class>

<p><strong>编码器第三个模块MLP(MSA transition layer)</strong></p>
<ul>
<li>自注意力机制主要是混合不同元素之间的信息，做信息的提炼主要还是在 MLP 的模块中</li>
<li>将 c 转变为 4c(来自 transform), relu, 之后变为 c</li>
<li>线性层的权重对每个元素是共享的</li>
</ul>
<img src="/20ee1ad6/9.png" class>

<p><strong>编码器第四个模块(Outer product mean)</strong></p>
<ul>
<li>序列信息融入到氨基酸对的表示中</li>
<li>需要将两个矩阵转化为一条向量</li>
<li>两个矩阵做外积(s, c, 1) + (s, 1, c) -&gt; (s, c, c)</li>
<li>在 s 维度上取均值</li>
<li>矩阵拉直, 再投影到 c_z, 加入到对表示</li>
</ul>
<img src="/20ee1ad6/10.png" class>

<p><strong>编码器第五个模块(Triangular self-attention around starting node)</strong></p>
<ul>
<li>和 MSA row-wise gated self-attention with pair bias 比较像</li>
<li>自注意力机制计算时, 看i, j, k三角的关系, 即 ij + ik &lt; jk(两边和大于第三边)</li>
</ul>
<p><strong>编码器第五个模块(Triangular self-attention around ending node)</strong></p>
<ul>
<li>和 Triangular self-attention around starting node 的区别从按行做 softmax 转变为按列做 softmax</li>
<li>由于先做行后做列, 使得向量是不对称的</li>
</ul>
<img src="/20ee1ad6/11.png" class>

<p><strong>编码器第六个模块(triangular multiplicative update using “outgoing” edges)</strong></p>
<ul>
<li>氨基酸对信息进行交互, 为了替代自注意力模块, 但是没能替换成</li>
<li>r &gt; s</li>
<li>ij 之间的信息由所有的 ik 和 jk 信息汇总(遍历 k)</li>
</ul>
<p><strong>编码器第六个模块(triangular multiplicative update using “incoming” edges)</strong></p>
<ul>
<li>从 ik 和 jk 转变为 ki 和 kj, 对称性的交换</li>
<li>氨基酸对之间消息的传递</li>
</ul>
<hr>
<h5 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h5><p><strong>蛋白质 3d 结构表达</strong></p>
<ul>
<li>每个原子的空间的绝对值, 不能使用</li>
<li>使用相对位置, 下一个氨基酸相对于上一个氨基酸的位置, 使用了欧几里得变换或者说刚体变换</li>
</ul>
<img src="/20ee1ad6/12.png" class>

<p>关系氨基酸下面每个原子可以旋转的角度</p>
<img src="/20ee1ad6/13.png" class>

<p><strong>解码器</strong></p>
<ul>
<li>预测主干的旋转和偏移和枝叶的旋转</li>
<li>IPA 拿到了氨基酸序列以及主干信息</li>
<li>不断的调整</li>
<li>原始认为在原点</li>
<li>共享权重, 像 lstm</li>
</ul>
<img src="/20ee1ad6/14.png" class>

<img src="/20ee1ad6/15.png" class>

<p><strong>解码器模块-IPA, Invariant Point Attention</strong></p>
<ul>
<li>不动点: 计算距离时不管做什么样的全局变换都不会影响 softmax 里或者输出的值</li>
<li>注意力机制, i 和 j 后面两个氨基酸的位置相隔比较远, 那么他们就不应该那么相似</li>
<li>解码器中显示的加入了位置的信息</li>
<li>经过 IPA 的序列信息理由有位置信息</li>
</ul>
<img src="/20ee1ad6/16.png" class>

<p><strong>解码器模块 - Backbone update</strong></p>
<ul>
<li>对第 i 个氨基酸预测它的变换, R 旋转, t 偏移</li>
<li>旋转矩阵需要是正交的</li>
<li>将 s_i 投影到 6 维里, 通过代数获得有效的矩阵</li>
</ul>
<hr>
<h5 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h5><p><strong>其他的详细内容</strong></p>
<ul>
<li>特征如何抽取, 序列信息有长有短, 搜索到的也有长有短</li>
<li>如何将位置信息放入, transform 出了名的对位置信息不敏感</li>
<li>回收机制如何执行</li>
</ul>
<p><strong>损失函数</strong></p>
<ul>
<li>主损失函数: FAPE, 根据预测的变换将蛋白质还原, 对应的原子在真实中和预测出来的位置, 这两距离的相减</li>
</ul>
<p><strong>使用没有标号的数据</strong></p>
<ul>
<li>使用 noisy student self-distillation</li>
<li>核心思想: 先在有标号的数据集上训练一个模型, 然后预测未标号的数据集, 将其中置信的拿出来和有标号的组成新的数据, 重新再训练模型</li>
<li>核心关键点: 加噪音, 防止错误标号进入训练级. 加入噪音, 例如大量的数据增强, 甚至把标号改变, 模型能够处理这些不正常的标号</li>
</ul>
<p><strong>BERT</strong></p>
<ul>
<li>任务: 随机遮住一些氨基酸或者把一些氨基酸做变换, 然后像 BERT 一样去预测这些被遮住的氨基酸</li>
<li>训练时加入上述任务, 整个模型对整个序列的键模上更加好一点</li>
</ul>
<p><strong>训练参数</strong></p>
<ul>
<li>序列长度是 256</li>
<li>batchsize 是 128</li>
<li>128 个 TPUv3 上训练</li>
<li>初始训练 7 天, 额外的微调还需 -4 天, 计算两属于中等</li>
<li>最大的问题是内存不够, 几百 GB</li>
</ul>
<p><strong>预测性能(以V100为准)</strong></p>
<ul>
<li>256 个氨基酸, 5min</li>
<li>384 个氨基酸, 9min</li>
<li>2500 个氨基酸, 18h</li>
</ul>
<hr>
<h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><img src="/20ee1ad6/17.png" class>

<p><strong>消融实验</strong></p>
<ul>
<li>A, casp-14 和 PDB 的结果, 其中灰线是基线, 比 0 大结果好, 比 0 小结果差</li>
<li>使用自蒸馏（使用额外的没有标注的数据集进行训练）效果较好</li>
<li>去掉数据或者模块的结果</li>
<li>我的网络虽然复杂, 但是没有一块能够去掉</li>
</ul>
<p>编码器的消融（回收）, 对于简单的可以只做一次不需要回收, 而对于复杂的 4 次之后仍有上升的趋势</p>
<hr>
<h4 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h4><ul>
<li>正文比较短, 主要讲问题和模型性能, 对于模型细节比较少</li>
<li>对于复杂算法使用相对简单的篇幅进行介绍, 可以学习</li>
<li>细节为什么要这么做, 借鉴了很多技术来试</li>
<li>提出了：块里面做信息的交互，回收机制，无监督的数据集进行训练</li>
</ul>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv14980922">https://www.bilibili.com/read/cv14980922</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-CLIP论文逐段精读-《Learning Transferable Visual Models From Natural Language Supervision》</title>
    <url>/e17abfce.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2021-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision.pdf" data-height="500px"></div>

<p>今天介绍一篇OpenAI的神作CLIP，文章发表在ICML-2021，于2021年3月挂在arXiv上的。</p>
<p>论文链接：<a href="https://arxiv.org/pdf/2103.00020.pdf">https://arxiv.org/pdf/2103.00020.pdf</a><br>Blog传送门：<a href="https://openai.com/blog/clip/">https://openai.com/blog/clip/</a><br>Code传送门：<a href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a></p>
<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=851425715&bvid=BV1SL4y1s7LQ&cid=505919491&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>（此部分翻译为主）</p>
<p>当前的计算机视觉（CV）模型通常被训练用于预测有限的物体类别。这种严格的监督训练方式限制了模型的泛化性和实用性，因为这样的模型通常还需要额外的标注数据来完成训练时未曾见过的视觉“概念”。直接从图片的描述文本中学习是一个有潜力的选择，因为这样我们可以获取更多的监督信号。这篇文章中，我们证明了利用一个简单的预训练任务（即预测哪个文本描述对应当前图像）在一个从互联网上搜集的4亿个（图像，文本）对的数据集上可以取得SOTA的图像表征。预训练完之后，在下游任务上，我们可以通过用自然语言（文本）匹配视觉概念（图像）从而实现zero-shot transfer。我们在30个不同类型的下游CV任务上进行了基准测试，并展示了我们模型强大的迁移能力，其在很多下游任务上不需要任何额外的数据也能比拟完全supervised的模型。比如，我们的模型在ImageNet上的zero-shot accuracy能达到在ImageNet上全监督训练的ResNet-50的性能。</p>
<hr>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>在NLP中，预训练的方法目前其实已经被验证很成功了，像BERT和GPT系列之类的。其中，GPT-3从网上搜集了400 billion byte-pair-encoded tokens进行预训练然后可以在很多下游任务上实现SOTA性能和zero-shot learning。这其实说明从web-scale的数据中学习是可以超过高质量的人工标注的NLP数据集的。</p>
<p>然而，对于CV领域，目前预训练模型基本都是基于人工标注的ImageNet数据集（含有1400多万张图像），那么借鉴NLP领域的GPT-3从网上搜集大量数据的思路，我们能不能也从网上搜集大量图像数据用于训练视觉表征模型呢？</p>
<p>作者先是回顾了并总结了和上述相关的两条表征学习路线：</p>
<ol>
<li>构建image和text的联系，比如利用已有的（image，text）pair数据集，从text中学习image的表征；</li>
<li>获取更多的数据（不要求高质量，也不要求full labeled）然后做弱监督预训练，就像谷歌使用的JFT-300M数据集进行预训练一样（在JFT数据集中，类别标签是有噪声的）。具体来说，JFT中一共有18291个类别，这能教模型的概念比ImageNet的1000类要多得多，但尽管已经有上万类了，其最后的分类器其实还是静态的、有限的，因为你最后还是得固定到18291个类别上进行分类，那么这样的类别限制还是限制了模型的zero-shot能力。<br>这两条路线其实都展现了相当的潜力，前者证明paired text-image可以用来训练视觉表征，后者证明扩充数据能极大提升性能，即使数据有noise。于是high-level上，作者考虑从网上爬取大量的（text，image）pair以扩充数据，同时这样的pairs是可以用来训练视觉表征的。作者随即在互联网上采集了4亿个（text，image）对，准备开始训练模型。</li>
</ol>
<hr>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><h4 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h4><p>海量的（image，text）数据有了，问题是怎么设计并高效地训练模型。作者提出CLIP的模型，可以认为是ConVIRT[1]的简化版。这里先简单回顾下ConVIRT (咋一看是不是觉得CLIP和ConVIRT一模一样)</p>
<img src="/e17abfce/1.jpg" class>

<p>VonVIRT用（image，text）对来训练模型，其有一个image encoder和一个text encoder，训练目标是让两路的representation尽可能得一致（对偶地最大化表征的agreement），其中gv和gu函数是一个non-linear得projection head，负责分别将图像和文本表征投影到一个shared的空间，从而计算距离。</p>
<img src="/e17abfce/2.jpg" class>

<img src="/e17abfce/3.jpg" class>

<p>其实就是构造了一个对称的contrastive loss，在一个batch内预测谁是正样本。</p>
<p>基于ConVIRT，CLIP主要做出了以下简化：</p>
<ul>
<li>ConVIRT中的image encoder的参数是ImageNet初始化的，而CLIP直接用random初始化</li>
<li>ConVIRT的projection head是non-linear的，而CLIP采用linear的projection</li>
<li>CLIP去掉了ConVIRT中text transformation（指均匀从text中采样句子），因为CLIP数据集中很多指出过一次的（image，text）</li>
<li>CLIP的image transformation只用了resize和squared crop</li>
<li>CLIP loss中的temperature参数τ是可学的</li>
</ul>
<p>于是CLIP的预训练模型就有了：</p>
<img src="/e17abfce/4.jpg" class>

<p>一个batch里有N对（image，text），然后和ConVIRT一样做对称的contrastive learning，伪代码如下：</p>
<img src="/e17abfce/5.jpg" class>

<hr>
<h4 id="Inference-Zero-shot-prediction"><a href="#Inference-Zero-shot-prediction" class="headerlink" title="Inference / Zero-shot prediction"></a>Inference / Zero-shot prediction</h4><p>一旦CLIP训练好了，我们就可以做zero-shot prediction了，如图所示：</p>
<img src="/e17abfce/6.jpg" class>

<p>步骤可以整理成下面这样：</p>
<ul>
<li>Sample所有N个class，得到N个input text，都经过text encoder编码得到对应的N个class text embedding（我这里之所叫embedding而不叫representation是想说明这个特征是经过encoding和projection得到的）</li>
<li>Sample一个要预测的image，得到其image embedding</li>
<li>以N个text embedding为key，以当前image embedding为query，算cosine相似度，相似度最高的即为Top-1的prediction class</li>
</ul>
<p>预测过程的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> clip</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> CIFAR100</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the model</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">model, preprocess = clip.load(<span class="string">&#x27;ViT-B/32&#x27;</span>, device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download the dataset</span></span><br><span class="line">cifar100 = CIFAR100(root=os.path.expanduser(<span class="string">&quot;~/.cache&quot;</span>), download=<span class="literal">True</span>, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the inputs</span></span><br><span class="line">image, class_id = cifar100[<span class="number">3637</span>]</span><br><span class="line">image_input = preprocess(image).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">text_inputs = torch.cat([clip.tokenize(<span class="string">f&quot;a photo of a <span class="subst">&#123;c&#125;</span>&quot;</span>) <span class="keyword">for</span> c <span class="keyword">in</span> cifar100.classes]).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate features</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    image_features = model.encode_image(image_input)</span><br><span class="line">    text_features = model.encode_text(text_inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pick the top 5 most similar labels for the image</span></span><br><span class="line">image_features /= image_features.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">text_features /= text_features.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">similarity = (<span class="number">100.0</span> * image_features @ text_features.T).softmax(dim=-<span class="number">1</span>)</span><br><span class="line">values, indices = similarity[<span class="number">0</span>].topk(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the result</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nTop predictions:\n&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> value, index <span class="keyword">in</span> <span class="built_in">zip</span>(values, indices):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;cifar100.classes[index]:&gt;16s&#125;</span>: <span class="subst">&#123;<span class="number">100</span> * value.item():<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><h5 id="text-encoder"><a href="#text-encoder" class="headerlink" title="text encoder"></a>text encoder</h5><p>作者统一采用GPT-2里的Transformer（63M-parameter 12-layer 512-wide model with 8 attention heads）。输入句子的最大长度为76。</p>
<h5 id="image-encoder"><a href="#image-encoder" class="headerlink" title="image encoder"></a>image encoder</h5><p>这里作者一共训练了8个不同的image encoder（5 ResNets &amp; 3 ViTs），分别如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_MODELS = &#123;</span><br><span class="line">    <span class="string">&quot;RN50&quot;</span>: <span class="string">&quot;https://openaipublic.azureedge.net/clip/models/afeb0e10f9e5a86da6080e35cf09123aca3b358a0c3e3b6c78a7b63bc04b6762/RN50.pt&quot;</span>,</span><br><span class="line">    <span class="string">&quot;RN101&quot;</span>: <span class="string">&quot;https://openaipublic.azureedge.net/clip/models/8fa8567bab74a42d41c5915025a8e4538c3bdbe8804a470a72f30b0d94fab599/RN101.pt&quot;</span>,</span><br><span class="line">    <span class="string">&quot;RN50x4&quot;</span>: <span class="string">&quot;https://openaipublic.azureedge.net/clip/models/7e526bd135e493cef0776de27d5f42653e6b4c8bf9e0f653bb11773263205fdd/RN50x4.pt&quot;</span>,</span><br><span class="line">    <span class="string">&quot;RN50x16&quot;</span>: <span class="string">&quot;https://openaipublic.azureedge.net/clip/models/52378b407f34354e150460fe41077663dd5b39c54cd0bfd2b27167a4a06ec9aa/RN50x16.pt&quot;</span>,</span><br><span class="line">    <span class="string">&quot;RN50x64&quot;</span>: <span class="string">&quot;https://openaipublic.azureedge.net/clip/models/be1cfb55d75a9666199fb2206c106743da0f6468c9d327f3e0d0a543a9919d9c/RN50x64.pt&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ViT-B/32&quot;</span>: <span class="string">&quot;https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ViT-B/16&quot;</span>: <span class="string">&quot;https://openaipublic.azureedge.net/clip/models/5806e77cd80f8b59890b7e101eabd078d9fb84e6937f9e85e4ecb61988df416f/ViT-B-16.pt&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ViT-L/14&quot;</span>: <span class="string">&quot;https://openaipublic.azureedge.net/clip/models/b8cca3fd41ae0c99ba7e8951adf17d267cdb84cd88be6f7c2e0eca1737a03836/ViT-L-14.pt&quot;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中ResNets做了一个小的修改：将ResNet编码出来的结果再经过一个attention pooling（比如一个2048x7x7的feature，用attention pooling成一个2048x1的feature）；对于ViTs也做了一个小的修改：在tokens（patch tokens和pos tokens相加）被送到Transformer之前，让tokens先经过一个layer norm层，此外参数的初始化和原来的ViTs也有微小的不同。</p>
<h5 id="Other-configuration"><a href="#Other-configuration" class="headerlink" title="Other configuration"></a>Other configuration</h5><ul>
<li>optimizer：Adam</li>
<li>training epochs：32</li>
<li>batch size：32768</li>
<li>precision：half-precision</li>
</ul>
<hr>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><p>实验部分这里重点focus在CV相关部分。</p>
<h4 id="Zero-shot-CLIP-v-s-Linear-Probe-on-ResNet50"><a href="#Zero-shot-CLIP-v-s-Linear-Probe-on-ResNet50" class="headerlink" title="Zero-shot CLIP v.s. Linear Probe on ResNet50"></a>Zero-shot CLIP v.s. Linear Probe on ResNet50</h4><img src="/e17abfce/7.jpg" class>

<p>CLIP的胜率在16/27，已经很强了，因为CLIP是zero-shot的，即没有用下游任务的数据，而linear probed ResNet50用了下游数据进行finetune逻辑回归分类器的参数。</p>
<hr>
<h4 id="Prompt-engineering-and-ensembling"><a href="#Prompt-engineering-and-ensembling" class="headerlink" title="Prompt engineering and ensembling"></a>Prompt engineering and ensembling</h4><p>作者默认prompt模板是：”A photo of a {label}.”，但作者发现这样的模板还是有点粗糙，可以考虑加一些context比如”A photo of a {label}, a type of pet.”。对于不同类型任务，作者做了一些手动的、特定的prompt工程。</p>
<p>从另一个角度，一张图的text描述其实有很多种的，只要text的核心语义和image相同就行，那么我们还可以做一些ensemble，比如ensemble一下”A photo of a big {label}.”和”A photo of a small {label}.”。</p>
<img src="/e17abfce/8.jpg" class>

<p>可以发现，采用Prompt engineering+ensembling的效果比只用没有上下文的类别名好得多。</p>
<p>（PS：作者这里的发现直接motivate了之后的CoOp[2]，CoCoOp[3]之类learnable prompting的工作，后面有时间我会专门写一期关于这个的。）</p>
<hr>
<h4 id="Few-shot-CLIP-v-s-SOTA-ImageNet-SSL-methods"><a href="#Few-shot-CLIP-v-s-SOTA-ImageNet-SSL-methods" class="headerlink" title="Few-shot CLIP v.s. SOTA (ImageNet) SSL methods"></a>Few-shot CLIP v.s. SOTA (ImageNet) SSL methods</h4><img src="/e17abfce/9.jpg" class>

<p>y: 20个测试数据集上的平均得分; x: shots</p>
<ul>
<li>Zero-shot CLIP的性能和4-shot CLIP差不多</li>
<li>Few-shot CLIP的performance远高于之前的SOTA模型</li>
</ul>
<hr>
<h4 id="How-many-shots-is-needed-for-achieving-zero-shot-performance"><a href="#How-many-shots-is-needed-for-achieving-zero-shot-performance" class="headerlink" title="How many shots is needed for achieving zero-shot performance"></a>How many shots is needed for achieving zero-shot performance</h4><img src="/e17abfce/10.jpg" class>

<p>Few-shot (linear probing) CLIP （保持CLIP encoder 参数fixed，加一层逻辑回归分类器微调）平均需要20.8-shots才能match zero-shot CLIP性能。这里相当于保持了the same CLIP feature space上，观察few-shot finetuning和zero-shot的性能差异。这里其实说明通过自然语言学到的视觉概念比少量样本finetune学到的好。</p>
<hr>
<h4 id="Linear-probing-CLIP-performance"><a href="#Linear-probing-CLIP-performance" class="headerlink" title="Linear probing CLIP performance"></a>Linear probing CLIP performance</h4><p>这里不再是few-shot linear probing了，而是全量数据的linear probing，我们来看下其跟zero-shot性能的对比：</p>
<img src="/e17abfce/11.jpg" class>

<p>总体上，两者的性能是正相关的，此外，大部分情况下linear probing的性能要好不少。</p>
<p>再来一个linear probing的天梯图：</p>
<img src="/e17abfce/12.jpg" class>

<p>CLIP GOAT！！！</p>
<hr>
<h4 id="Robustness-to-Natural-Distribution-Shift"><a href="#Robustness-to-Natural-Distribution-Shift" class="headerlink" title="Robustness to Natural Distribution Shift"></a>Robustness to Natural Distribution Shift</h4><p>作者在ImageNet的7个shift datasets上观察各模型的平均性能。</p>
<img src="/e17abfce/13.jpg" class>

<p>说实话，做domain adaptation（DA）/generalization（DG）的人看到这里应该挺兴奋，新的鲁棒特征来啦。不过问题来了，左边这张图是不是也反映了representation learning比DA、DG technique更重要呢？（那么，我们真的需要花那么大力气去卷DA嘛… 说不定通过这种大规模pretraining就能很大程度上解决domain shift的问题。但另一方面，DA、DG也可以在这些pretraining得到的表征上锦上添花。怎么说都有道理，但我更prefer to CLIP这类表征学习的意义。</p>
<p>CLIP的实验非常丰富，这里只是抛砖引玉地挑了几个我个人觉得比较有意思的实验讲，具体地还是推荐大家去看原文。</p>
<hr>
<h3 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h3><p>这个部分往往容易被人忽略，但其实个人觉得，limitation和conclusion部分往往有作者们更深入的思考，这里简单总结下CLIP的limitation：</p>
<ul>
<li>CLIP的zero-shot性能虽然总体上比supervised baseline ResNet-50要好，但其实在很多任务上比不过SOTA methods，因此CLIP的transfer learning有待挖掘</li>
<li>CLIP在这几种task上zero-shot性能不好：fine-grained分类（花的分类、车的分类之类的）、抽象的任务（如计算图中object的个数）以及预训练时没见过的task（如分出相邻车辆的距离）。BTW，在这些任务上zero-shot性能不好，不代表CLIP pretrained encoders就没用了，CLIP encoders还是能提供很强的视觉先验的</li>
<li>Zero-shot CLIP在真正意义上的out-of-distribution data上性能不好，比如在OCR中</li>
<li>尽管CLIP zero-shot classifier能在很广泛的任务上work，但究其本质CLIP还是在有限的类别中进行对比、推理，而不能像image caption那样完全的flexible地生成新的概念（如：词），这是CLIP功能上的缺陷，CLIP终究不是生成模型</li>
<li>CLIP仍然没有解决深度学习poor data efficiency的问题，结合CLIP和self-training可能是一个能提高data efficiency的方向</li>
<li>CLIP的方法论上也存在几个缺陷：在训练和挑选CLIP模型时，作者采用在几个数据的validation performance来做指导，这其实是不准确的，因为它不能完全代表CLIP的zero-shot性能。如果，设计一套框架来evaluate zero-shot performance对于之后的研究是很重要的</li>
<li>CLIP的训练数据是从网上采集的，这些image-text pairs没有做data clear和de-bias，这可能会使模型有一些social biases</li>
<li>很多视觉任务很难用text来表达，如何用更高效的few-shot learning方法优化CLIP也很重要</li>
</ul>
<p>到此，CLIP基本讲完，总体来说，对于深度学习来说是优化时代意义的，这可能标志着我们即将迎来data-centric deep learning时代，印证了Andrew Ng的一句名言：“Your model is good enough. Foucs on the data!”(大概这个意思，词句不完全准确)。</p>
<hr>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><blockquote>
<p>[1] <a href="https://arxiv.org/pdf/2010.00747.pdf">Zhang Y, Jiang H, Miura Y, et al. Contrastive learning of medical visual representations from paired images and text[J]. arXiv preprint arXiv:2010.00747, 2020.</a><br>[2] <a href="https://arxiv.org/pdf/2109.01134.pdf">Zhou K, Yang J, Loy C C, et al. Learning to prompt for vision-language models[J]. arXiv preprint arXiv:2109.01134, 2021.</a><br>[3] <a href="https://arxiv.org/pdf/2203.05557.pdf">Zhou K, Yang J, Loy C C, et al. Conditional Prompt Learning for Vision-Language Models[J]. arXiv preprint arXiv:2203.05557, 2022.</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/486857682">https://zhuanlan.zhihu.com/p/486857682</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-CLIP预训练模型综述</title>
    <url>/aeaeca7a.html</url>
    <content><![CDATA[<h3 id="什么是CLIP"><a href="#什么是CLIP" class="headerlink" title="什么是CLIP"></a>什么是CLIP</h3><p>Title: Learning transferable visual models from natural language supervision<br>paper：<a href="https://arxiv.org/pdf/2103.00020">https://arxiv.org/pdf/2103.00020</a><br>代码：<a href="https://github.com/OpenAI/CLIP">https://github.com/OpenAI/CLIP</a></p>
<p>2021开年，顶着地表最强语言模型GPT-3的光环，OpenAI在自然语言处理领域一路高歌猛进，推出两个跨越文本与图像次元的模型：DALL·E和CLIP，前者可以基于文本生成图像，后者则可以基于文本对图片进行分类，两者都意在打破自然语言处理和计算机视觉两大门派“泾渭分明”的界限，实现多模态AI系统。CLIP是一个预训练模型，就像BERT、GPT、ViT等预训练模型一样。首先使用大量无标签数据训练这些模型，然后训练好的模型就能实现，输入一段文本（或者一张图像），输出文本（图像）的向量表示。CLIP和BERT、GPT、ViT的区别在于，CLIP是多模态的，包含图像处理以及文本处理两个方面内容，而BERT、GPT是单文本模态的，ViT是单图像模态的。</p>
<span id="more"></span>

<hr>
<h3 id="作者提出CLIP的动机"><a href="#作者提出CLIP的动机" class="headerlink" title="作者提出CLIP的动机"></a>作者提出CLIP的动机</h3><ol>
<li><p>现有CV模型大多都只能预测已知的图像类别，对于没有见过的图像类别，需要额外的信息才能识别。那么文本其实就提供了这样的额外信息。所以利用图像对应的文本数据，也许就能使模型能够分辨未见类的图像。</p>
</li>
<li><p>最近NLP领域中出现的BERT、GPT等预训练模型表明，用大规模的无监督数据训练模型，可以在多个下游NLP任务上获得非常好的结果，有些甚至超过使用人工标注的数据训练出的模型。而现有的CV模型基本都是基于人工标注的数据集训练的（比如ImageNet），那么仿照NLP中预训练模型，如果使用大量无监督（也就是非人工标注）的图像，CV模型能否实现突破呢？</p>
</li>
<li><p>目前也有很多研究者注意到natural language在CV中的作用，并尝试利用起来。但是实际的实验结果通常低于其他特殊设计的使用有监督数据的模型。但是作者认为，他们在CV模型中加入natural language数据后实际结果不够好的原因可能是数据规模仍然不够大，而不是natural language数据对CV无用。</p>
</li>
</ol>
<hr>
<h3 id="CLIP的预训练数据是什么？"><a href="#CLIP的预训练数据是什么？" class="headerlink" title="CLIP的预训练数据是什么？"></a>CLIP的预训练数据是什么？</h3><p>预训练数据是作者新构建的WIT数据集。鉴于现有CV数据集仍然不够大，且很少包含足够的natural language数据（大多CV数据集中的文本数据只是图像的类别指示，比如dog，cat等单词），所以作者从网上爬了4亿个图像-文本对，构建了数据集WIT（WebImageText）。WIT数据集中的文本都是图像相关的sentence，而不是single word，因此提供了足够的natural language数据。</p>
<hr>
<h3 id="CLIP的预训练任务是什么？"><a href="#CLIP的预训练任务是什么？" class="headerlink" title="CLIP的预训练任务是什么？"></a>CLIP的预训练任务是什么？</h3><p>CLIP的预训练任务是预测给定的图像和文本是否是一对（paired），使用对比学习（contrastive learning）的loss。</p>
<p>本文采取了对比学习的方法来预训练CLIP。直接将image对应的text sentence作为一个整体，来判断text和image是否是一对。对于一个包含N个图像-文本对的batch而言，其中正样本是每张图像及其对应的文本，一共有N个，而其他所有图像和文本的组合都是不成对的，也就是负样本是N×N-N个。</p>
<hr>
<h3 id="CLIP的结构？"><a href="#CLIP的结构？" class="headerlink" title="CLIP的结构？"></a>CLIP的结构？</h3><p>如下图所示，CLIP的主要结构是一个文本编码器Text Encoder和一个图像编码器Image Encoder，然后计算文本向量和图像向量的相似度以预测它们是否为一对</p>
<img src="/aeaeca7a/1.png" class>

<p>CLIP将图像和文本先分别输入一个图像编码器image_encoder和一个文本编码器text_encoder，得到图像和文本的向量表示 I-f 和 T_f 。然后将图像和文本的向量表示映射到一个joint multimodal sapce，得到新的可直接进行比较的图像和文本的向量表示 I_e 和T_e （这是多模态学习中常用的一种方法，不同模态的数据表示之间可能存在gap，无法进行直接的比较，因此先将不同模态的数据映射到同一个多模态空间，有利于后续的相似度计算等操作）。然后计算图像向量和文本向量之间的cosine相似度。最后，对比学习的目标函数就是让正样本对的相似度较高，负样本对的相似度较低。</p>
<hr>
<h3 id="clip做出的贡献"><a href="#clip做出的贡献" class="headerlink" title="clip做出的贡献"></a>clip做出的贡献</h3><p>总结一下 clip这篇工作最大的贡献，在我看来就是他打破了之前这种固定种类标签的范式，意思就是说不论在你收集数据集的时候，还是在训练模型的时候，你都不需要像imagenet一样啊做1000类，或者像Coco一样做80类了，你直接就搜集这种图片文本的配对，然后用无监督的方式，要么去预测它的相似性，要么去生成它，总之呢是跟这种固定多少类别的范式呢说拜拜了。</p>
<p>这样的好处呢就是不仅在处理数据的时候更方便，训练起模型呢更方便，那最主要的就是在你做推理的时候呢更方便，甚至可以去zero short的啊做各种各样的分类任务，所以在clip这边工作出来之后，很快呢就一大批工作迅速跟进。那到现在为止，其实像物体检测、物体分割、啊视频动作识别、检索还有多模态，还有图像生成，基本上是每个领域都有利用clip的这个后续工作，它的影响力啊可见一斑。那如果我们按照沐神之前讲的那个如何判断一个工作的这个价值来说，clip在我看来呢应该就是100×100×100从新一度的角度来说，clip打破了这种固定类别标签的做法，彻底放飞了视觉模型的这个训练过程，引发了一大批后续的工作，所以新意度呢无疑是很高的，那从有效性上来说呢那就更不用说了，做了这么多数据集，效果这么好，泛化性能也这么好，甚至在某些情况下呢比人的这个 zero shot的性能还好，那有效性呢也毋庸置疑是100分。</p>
<p>最后呢就是问题大小，那 clip呢用一个模型就能解决大部分的这个分类任务，而且是zero shot的去解决这个问题本身呢就已经很大了。更何况呢你只要利用这个clip训练好的模型，再在其他领域里稍微适配一下，就能把别的领域的任务也全都做掉。所以说它这个问题大小啊也是100分，clip模型的这个灵活性和它的高效性，能让我们看到一点啊这个人工智障变人工智能的希望。所以综合从这三个角度来看， clip都是一篇价值极高的论文。</p>
<hr>
<h3 id="为什么CLIP要采用对比学习的方法"><a href="#为什么CLIP要采用对比学习的方法" class="headerlink" title="为什么CLIP要采用对比学习的方法"></a>为什么CLIP要采用对比学习的方法</h3><p>OpenAI是一家从来不愁计算资源的公司，他们喜欢将一切都gpt化(就是做生成式模型)； ​ 但是以往的工作表明(ResNeXt101-32x48d, Noisy Student EfficientNet-L2),训练资源往往需要很多，何况这些都只是在ImageNet上的结果，只是1000类的分类任务，而CLIP要做的是开发世界的视觉识别任务，所以训练的效率对于自监督的模型至关重要； ​ 而如果任务改为给定一张图片去预测一个文本(或者给定一个文本去预测一张图片)，那么训练效率将会非常低下(因为一个图片可能对应很多种说法，一个文本也对应着很多种场景)； ​ 所以与其做默写古诗词，不如做选择题！(只要判断哪一个文本与图片配对即可)； ​ 通过从预测任务改为只预测某个单词到只选出配对的答案，模型的训练效率一下提升了4倍。</p>
<hr>
<h3 id="什么是zero-shot"><a href="#什么是zero-shot" class="headerlink" title="什么是zero-shot"></a>什么是zero-shot</h3><p>举个通俗的例子：假设斑马是未见过的类别，但根据描述和过去知识的印象即马（和马相似）、老虎（有条纹）、熊猫（颜色）相似进行推理出斑马的具体形态，从而能对新对象进行辨认。（如下图所示）零次学习就是希望能够模仿人类的这个推理过程，使得计算机具有识别新事物的能力。</p>
<img src="/aeaeca7a/2.png" class>

<p>这是zero-shot介绍时常用的一张图，从见过的类别（第一列）中提取特征（如：外形像马、条纹、黑白），然后根据对未知类别特征的描述，测试未见过的类别。</p>
<p>从字面上来看，<strong>即是对某（些）类别完全不提供训练样本，也就是没有标注样本的迁移任务被称为零次学习。</strong> zero-shot learning是为了能够识别在测试中出现，但在训练中没有遇到过的数据类别，<strong>我们可以学习到一个映射X-&gt;Y。</strong>如果这个映射足够好的话，我们就可以处理没有看到的类了，故可以被认为是迁移学习。</p>
<hr>
<h3 id="“zero-shot”践行者：按词分图的CLIP"><a href="#“zero-shot”践行者：按词分图的CLIP" class="headerlink" title="“zero-shot”践行者：按词分图的CLIP"></a>“zero-shot”践行者：按词分图的CLIP</h3><p>如果说DALL·E是GPT-3在图像领域的延伸，那CLIP就是主打“zero-shot（零样本）”，攻破视觉领域的深度学习方法的三大难题。</p>
<ol>
<li><p><strong>训练所需大量数据集的采集和标注，会导致的较高成本。</strong></p>
</li>
<li><p><strong>训练好的视觉模型一般只擅长一类任务，迁移到其他任务需要花费巨大成本。</strong></p>
</li>
<li><p><strong>即使在基准测试中表现良好，在实际应用中可能也不如人意。</strong></p>
</li>
</ol>
<p><strong>CLIP全称是Contrastive Language-Image Pre-training，根据字面意思，就是对比文本-图像预训练模型，只需要提供图像类别的文本描述，就能将图像进行分类。</strong></p>
<p><strong>怎么分？为什么能分？</strong></p>
<p>为了识别出未曾见过的类别（图像或文本），Zero-shot这一概念可以追溯到十年前，而目前计算机视觉领域应用的重点是，利用自然语言作为灵活的预测空间，实现泛化和迁移。</p>
<hr>
<h3 id="文中多次提到的Zero-shot-transfer-of-CLIP-是什么意思？"><a href="#文中多次提到的Zero-shot-transfer-of-CLIP-是什么意思？" class="headerlink" title="文中多次提到的Zero shot transfer of CLIP 是什么意思？"></a>文中多次提到的Zero shot transfer of CLIP 是什么意思？</h3><p>本文的CLIP预训练时使用的数据集是WIT，而在ImageNet、STL10、Food101、CIFAR10、MNIST等其他数据集上直接测试。这意味着CLIP在训练时没有见过ImageNet这些数据集中的图像，那么这种测试实际上就是zero shot的。</p>
<p>一个测试例子可以看下图，假设要测试的数据集是ImageNet，那么，因为CLIP在训练时用的所有数据来自WIT，而没有任何ImageNet的数据，所以CLIP在ImageNet上进行测试实际上就是Zero shot的。由于ImageNet中text数据只有表示图像类别的car，dog，bird等single word，而CLIP训练时text数据是sentence，为了弥补训练和测试的gap，作者将ImageNet中所有类别单词扩展为一句话“ A photo of a {car/dog/…/bird}. ” ，作为图像对应的sentence（该操作实际上是prompt engineering）。</p>
<p>下图中Text Encoder和Image Encoder是已经训练好的CLIP中的文本和图像编码器，要对任意一张来自ImageNet的图像进行分类，只需要将该图像输入Image Encoder中得到它的向量表示I1。然后将ImageNet数据集中所有类别标签扩展成的sentence输入Text Encoder，得到所有类别的向量表示T1—TN，然后计算I1与T1—TN的相似度，其中相似度最高的就是该图像对应的text数据，也就是该图像的分类结果。</p>
<img src="/aeaeca7a/3.png" class>

<hr>
<h3 id="CLIP的“足”与“不足”"><a href="#CLIP的“足”与“不足”" class="headerlink" title="CLIP的“足”与“不足”"></a>CLIP的“足”与“不足”</h3><ol>
<li><p>从CLIP流程，看三大问题如何解决</p>
<p> 简单来说，CLIP的任务就是识别一张图像所出现的各种视觉概念，并且学会它的名称。比如当任务是对猫和狗的图片进行分类，CLIP模型就需要判断，目前处理的这张图片的文字描述是更偏向于“一张猫的照片”，还是一张狗的照片。</p>
<p> 在具体实现上，有如下流程：预训练图像编码器和文本编码器，得到相互匹配的图像和文本，基于此，CLIP将转换为zero-shot分类器。此外，数据集的所有类会被转换为诸如“一只狗的照片”之类的标签，以此标签找到能够最佳配对的图像。</p>
 <img src="/aeaeca7a/4.png" class>

<p> 在这个过程中，CLIP也能解决之前提到的三大问题。</p>
<ul>
<li>昂贵的数据集：25000人参与了ImageNet中1400万张图片的标注。与此相比，CLIP使用的是互联网上公开的文本-图像对，在标注方面，也利用自监督学习、对比方法、自训练方法以及生成建模等方法减少对人工标注的依赖。</li>
<li>只适用于单一任务：由于已经学会图片中的各种视觉概念，所以CLIP可以执行各种视觉任务，而不需要额外的训练和调整。如下也展示了CLIP模型识别各类型图像中视觉概念,无论是食物、场景还是地图，都是有不错的表现。</li>
<li>实际应用性能不佳：基准测试中表现好的模型在实际应用中很可能并没有这么好的水平。就像学生为了准备考试，只重复复习之前考过的题型一样，模型往往也仅针对基准测试中的性能进行优化。但CLIP模型可以直接在基准上进行评估，而不必在数据上进行训练。</li>
</ul>
</li>
<li><p>CLIP的“足”：高效且灵活通用</p>
<p> CLIP需要从未经标注、变化多端的数据中进行预训练，且要在“zero-shot”，即零样本的情况下使用。GPT-2/3模型已经验证了该思路的可行性，但这类模型需要大量的模型计算，为了减少计算量，OpenAI的研究人员采用了两种算法：对比目标（contrastive objective）和Vision Transformer。前者是为了将文本和图像连接起来，后者使计算效率比标准分类模型提高了三倍。</p>
</li>
<li><p>CLIP的“不足”：复杂任务仍有差距</p>
<p> 尽管CLIP在识别常见物体上表现良好，但在如计算图像中物品数量、预测图片中物品的位置距离等更抽象、复杂的任务上，“zero-shot”CLIP表现仅略胜于随机分类，而在区分汽车模型、飞机型号或者花卉种类时，CLIP也不好。</p>
<p> 且对于预训练阶段没有出现过的图像，CLIP泛化能力也很差。例如，尽管CLIP学习了OCR，但评估MNIST数据集的手写数字上，“zero-shot”CLIP准确率只达到了88％，远低于人类在数据集中的99.75％精确度。最后，研究人员发现，CLIP的“zero-shot”分类器对单词构造或短语构造比较敏感，但有时还是需要试验和错误“提示引擎”的辅助，才能表现良好。</p>
<p> CLIP是判别模型，预计它之后在图像领域会作为预训练模型，有更多的应用</p>
</li>
</ol>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://blog.csdn.net/zcyzcyjava/article/details/126558368">https://blog.csdn.net/zcyzcyjava/article/details/126558368</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫精读经典</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-帮助瘫痪者移动、说话和触摸的大脑阅读设备</title>
    <url>/63f0c81a.html</url>
    <content><![CDATA[<h3 id="要闻"><a href="#要闻" class="headerlink" title="要闻"></a>要闻</h3><p>2017年3月，约翰逊在一次卡丁车事故中摔断了脖子，使他肩膀以下几乎完全瘫痪。他比大多数人都更了解自己的现实。几十年来，他一直是瘫痪患者的照顾者。但后来约翰逊的康复团队将他介绍给了附近位于帕萨迪纳的加州理工学院（Caltech）的研究人员，他们邀请他参加脑机接口（BCI）的临床试验。这首先需要神经外科手术将两个电极网格植入他的皮层。这些电极会在神经元放电时记录他大脑中的神经元，研究人员将使用算法来解码他的想法和意图。然后，该系统将使用约翰逊的大脑活动来操作计算机应用程序或移动假肢设备。总而言之，这将需要数年时间，并且需要数百次强化培训课程。“我真的没有犹豫。”约翰逊说。</p>
<p>约翰逊于2018年11月首次使用植入的BCI，他在电脑屏幕上移动光标。“感觉就像《黑客帝国》一样，”他说。“我们连接到计算机，瞧瞧，我只要想一想就能移动光标”。</p>
<img src="/63f0c81a/1.png" class>
<p>图一： 瘫痪的人使用他们的大脑活动控制假肢</p>
<span id="more"></span>

<p>此后，约翰逊使用BCI来控制机械臂，使用Photoshop软件，玩“射击”视频游戏，在驾驶模拟汽车穿越虚拟环境，改变速度，转向和对危险做出反应。“我总是对我们能做的感到震惊，”他说，“这真是太棒了。</p>
<p>约翰逊是35名长期植入大脑BCI的人之一。只有大约十几个实验室进行这样的研究，但这个数字还在增长。在过去的五年中，这些设备可以恢复的技能范围已经大大扩展。仅去年一年，科学家们就描述了一名研究参与者使用一种机械臂，这种手臂可以直接向他的大脑发送感官反馈。</p>
<img src="/63f0c81a/2.png" class>
<p>图二：詹姆斯·约翰逊（James Johnson）使用他的神经界面通过混合图像来创造艺术。</p>
<p>到目前为止，绝大多数用于记录单个神经元的植入物都是由一家公司制造的：Blackrock Neurotech，一家位于犹他州盐湖城的医疗设备开发商。但在过去七年中，对BCI的商业兴趣激增。最值得注意的是，2016年，企业家埃隆·马斯克（Elon Musk）在加利福尼亚州旧金山推出了Neuralink，目标是将人类和计算机联系起来。该公司已筹集了3.63亿美元。去年，Blackrock Neurotech和其他几家较新的BCI公司也吸引了大量的资金支持。</p>
<p>然而，将BCI推向市场将需要将一种定制的技术（仅在少数人中进行道路测试）转变为可以大规模制造，植入和使用的产品。大型试验需要证明BCI可以在非研究环境中工作，并以市场可以支持的价格明显改善用户的日常生活。实现这一切的时间表尚不确定，但该领域是看涨的。“几千年来，我们一直在寻找某种方法来治愈瘫痪的人，”德克萨斯州奥斯汀市神经技术公司Paradromics的创始首席执行官Matt Angle说。“现在我们实际上正处于拥有可以利用这些技术的技术的风口浪尖。</p>
<hr>
<h3 id="接口演进"><a href="#接口演进" class="headerlink" title="接口演进"></a>接口演进</h3><p>2004年6月，研究人员将一个电极网格压入一名因刺伤而瘫痪的男子的运动皮层。他是第一个接受长期BCI植入物的人。像大多数接受过脑临床感染的人一样，他的认知是完整的。他可以想象移动，但他失去了运动皮层和肌肉之间的神经通路。经过在许多猴子实验室中工作了几十年，研究人员已经学会了从运动皮层活动的实时记录中解码动物的运动。他们现在希望从同一区域的大脑活动中推断出一个人的想象运动。</p>
<p>2006年，一份具有里程碑意义的报纸描述了这个人如何学会在电脑屏幕上移动光标，控制电视，并通过思考使用机器人手臂和手。该研究由Leigh Hochberg共同领导，他是罗德岛州普罗维登斯布朗大学和波士顿马萨诸塞州总医院的神经科学家和重症监护神经学家。这是名为BrainGate的多中心试验套件中的第一个，该试验一直持续到今天。</p>
<p>实验视频链接：<a href="https://www.youtube.com/watch?v=O6Qw3EDBPhg">https://www.youtube.com/watch?v=O6Qw3EDBPhg</a></p>
<hr>
<h3 id="电机独立性"><a href="#电机独立性" class="headerlink" title="电机独立性"></a>电机独立性</h3><p>当被问及他们希望从辅助神经技术中得到什么时，瘫痪患者最常回答“独立性”。对于无法移动四肢的人来说，这通常意味着恢复运动。一种方法是植入直接刺激人自己四肢肌肉的电极，并让BCI直接控制这些肌肉。“如果你能捕捉到与控制手部运动相关的原生皮质信号，你基本上可以绕过脊髓损伤，直接从大脑到外围，”俄亥俄州克利夫兰凯斯西储大学的神经科学家Bolu Ajiboye说。</p>
<p>2017年，Ajiboye和他的同事描述了一名参与者，他使用这个系统进行复杂的手臂运动，包括喝一杯咖啡和给自己喂食。“当他第一次开始研究时，”Ajiboye说，“他必须非常认真地思考他的手臂从A点移动到B点。但随着他接受更多的训练，他可以考虑移动他的手臂，它就会移动。参与者还重新获得了手臂的主人翁感。可以释放瘫痪肌肉的读心术装置</p>
<p>Ajiboye现在正在扩展他的系统可以解码的命令信号库，例如用于抓握力的命令信号。他还希望给BCI用户一种触觉，这是几个实验室都在追求的目标。</p>
<p>2015年，由宾夕法尼亚州匹兹堡大学的神经科学家罗伯特·冈特（Robert Gaunt）领导的一个研究小组报告说，在一个人的躯体感觉皮层的手部区域植入了一个电极阵列，在那里处理触摸信息。当他们使用电极刺激神经元时，这个人会感觉到类似于被触摸的东西。</p>
<p>冈特随后与匹兹堡的同事詹妮弗·科林格（Jennifer Collinger）联手，后者是一名神经科学家，负责推动BCI对机器人手臂的控制。他们一起塑造了一个机械臂，其指尖嵌入了压力传感器，该传感器被送入植入体感皮层的电极中，以唤起合成的触觉。Gaunt解释说，这不是一种完全自然的感觉——有时感觉像是压力或被刺激，有时更像是嗡嗡声。然而，触觉反馈使假肢使用起来感觉更加自然，并且拾取物体所需的时间减少了一半，从大约20秒减少到10秒。</p>
<p>将阵列植入具有不同角色的大脑区域可以通过其他方式为运动增加细微差别。神经科学家理查德·安德森（Richard Andersen）正在加州理工学院领导约翰逊参与的试验，他正试图通过利用后顶叶皮层（PPC）来解码用户更抽象的目标，PPC形成了移动的意图或计划。也就是说，它可能编码“我想要喝一杯”的想法，而运动皮层将手指向咖啡，然后将咖啡送到嘴里。</p>
<p>Andersen的团队正在探索这种双重输入如何帮助BCI表现，对比单独或一起使用两个皮质区域。未发表的结果表明，约翰逊的意图可以在PPC中更快地解码，“与编码运动的目标一致”，安徒生实验室的高级研究员泰森·阿弗拉洛（Tyson Aflalo）说。相比之下，运动皮层活动在整个运动中持续存在，他说，“使轨迹不那么紧张”。这种新型的神经输入正在帮助约翰逊和其他人扩展他们能做的事情。约翰逊使用驾驶模拟器，另一名参与者可以使用她的BCI弹奏虚拟钢琴。</p>
<hr>
<h3 id="迈向意义"><a href="#迈向意义" class="headerlink" title="迈向意义"></a>迈向意义</h3><p>“与脑损伤相关的最具破坏性的结果之一是丧失沟通能力，”加州大学旧金山分校的神经外科医生兼神经科学家Edward Chang说。在早期的BCI工作中，参与者可以通过想象他们的手移动，然后想象抓住“点击”字母来在计算机屏幕上移动光标 - 提供一种实现沟通的方式。但最近，Chang和其他人通过瞄准人们自然用来表达自己的运动取得了快速进展。通过游标控制进行通信的基准 ，大约每分钟 40 个字符， 由加利福尼亚州斯坦福大学神经科学家Krishna Shenoy领导的团队于2017年设定。</p>
<p>然后，去年，这个小组报告了3这种方法使研究参与者丹尼斯·德格雷（Dennis Degray）能够将速度提高一倍，他可以说话，但从脖子以下瘫痪。谢诺伊的同事弗兰克·威利特（Frank Willett）向德格雷建议，当他们从他的运动皮层录制时，他想象手写（参见“将思想变成文字”）。系统有时很难解析与以类似方式手写的字母相关的信号，例如r，n和h，但通常它可以轻松区分字母。解码算法在基线时的准确率为95%，但是当使用类似于智能手机预测文本的统计语言模型进行自动校正时，这一比例跃升至99%。</p>
<img src="/63f0c81a/3.png" class>
<p>图三：加州大学旧金山分校的神经科学家爱德华·张（Edward Chang）（右）帮助一名瘫痪的男子通过连接到计算机的大脑植入物说话。</p>
<hr>
<h3 id="从实验室到市场"><a href="#从实验室到市场" class="headerlink" title="从实验室到市场"></a>从实验室到市场</h3><p>许多领先的学者现在正在与公司合作开发适销对路的设备。相比之下，Chaudhary在蒂宾根共同创立了一家非营利性公司ALS Voice，为处于完全锁定状态的人们开发神经技术。</p>
<p>贝莱德Neurotech的现有设备18年来一直是临床研究的中流砥柱，它希望在一年内推出BCI系统，主席Florian Solzbacher表示。去年11月，当监管医疗器械的美国食品和药物管理局（FDA）将该公司的产品置于快速审查流程中，以促进商业开发时，该公司又向前迈进了一步。</p>
<p>这个可能的第一款产品将使用四个植入阵列，并通过电线连接到小型化设备，Solzbacher希望这将展示如何改善人们的生活。“我们不是在谈论功效提高5%，10或30%，”他说。“人们可以做一些他们以前做不到的事情。Blackrock Neurotech还在开发一种完全可植入的无线BCI，旨在使其更易于使用，并消除在用户颅骨中安装端口的需要。Neuralink和Paradromics的目标是从一开始就在他们正在开发的设备中具有这些功能。</p>
<img src="/63f0c81a/4.png" class>
<p>图四：“stentrode”接口可以从血管内部翻译大脑信号，而无需进行开放脑手术。</p>
<hr>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><p>“人与人之间的差异是我认为我们不知道问题范围的原因，”Orsborn说。在非人类灵长类动物中，即使电极定位的微小变化也会影响哪些电路被抽取。她怀疑，在不同个体的思考和学习方式以及用户的大脑受到各种条件的影响方面，也存在重要的特质。</p>
<p>最后，人们普遍认识到，道德监督必须与这种快速发展的技术保持同步。BCI存在多种问题，从隐私到个人自治。伦理学家强调，用户必须保持对设备输出的完全控制。虽然目前的技术无法解码人们的私人想法，但开发人员将拥有用户每次通信的记录，以及有关其大脑健康的关键数据。此外，BCI还存在一种新型的网络安全风险。</p>
<p>参与者还存在一种风险，即他们的设备可能不会永远得到支持，或者制造它们的公司会倒闭。已经有一些情况表明，当用户的植入设备不受支持时，他们感到失望。</p>
<p>然而，Degray渴望看到BCI覆盖更多的人。他说，他最希望从辅助技术中得到的是能够挠挠眉毛。“每个人都看着椅子上的我，他们总是说，“哦，那个可怜的家伙，他不能再打高尔夫球了。这很糟糕。但真正的恐怖是在半夜，当一只蜘蛛走过你的脸时，这是坏事。”</p>
<p>对于约翰逊来说，这是关于人际关系和触觉反馈，来自亲人的拥抱。“如果我们能够映射负责此事的神经元，并在未来某一天以某种方式将其设置成假肢设备，那么我将对自己在这些研究中的努力感到满意。”</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://doi.org/10.1038/d41586-022-01047-w">https://doi.org/10.1038/d41586-022-01047-w</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12146">https://www.scholat.com/teamwork/showPostMessage.html?id=12146</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-Neuron报道，成功从四肢瘫痪患者大脑皮层中解码抓取动作和言语信号</title>
    <url>/40768857.html</url>
    <content><![CDATA[<img src="/40768857/1.jpg" class>

<p>脊柱损伤、中风或神经系统疾病导致很多人失去运动或说话能力，他们的生活受到严重困扰。研究大脑如何对动作和语言进行编码有助于恢复患者的运动和言语功能。</p>
<span id="more"></span>

<hr>
<h3 id="研究背景及目的"><a href="#研究背景及目的" class="headerlink" title="研究背景及目的"></a>研究背景及目的</h3><p>抓握和操作日常用品的能力是独立生活中完成大多数日常任务所需的基本技能。脊髓损伤（Spinal cord injury,SCI）引发的部分或完全瘫痪会不可逆转地降低患者的自主性，导致功能损伤或丧失。手和前臂功能的恢复以及言语交流对于四肢瘫痪患者和患有某些神经疾病的患者（如肌萎缩侧索硬化症，ALS）非常重要。</p>
<p>脑机接口（Brain-machine interfaces,BMI）可以通过直接记录大脑的神经活动并解码这些信号来控制外部设备，如机械臂或手，从而赋予四肢瘫痪患者更大的独立性。最近，有研究指出脑机接口可利用神经信号重建言语功能。</p>
<p>边缘上回（SMG）是后顶叶皮质（PPC）、腹侧运动前皮质（PMV）和初级感觉皮质（S1）的一个亚区域，这些脑区是皮质抓握回路的关键组成部分。SMG参与处理复杂工具使用期间的运动活动。经颅磁刺激（TMS）和功能磁共振成像（FMRI）实验也表明SMG参与语言处理和言语工作记忆，表明其可能参与言语产生。然而SMG参与语音解码尚未得到证明。</p>
<hr>
<h3 id="研究方法"><a href="#研究方法" class="headerlink" title="研究方法"></a>研究方法</h3><p>一名颈椎C5级脊髓损伤的参与者被招募参加了脑机接口临床试验。</p>
<p>植入的靶区为左腹侧运动前皮质（PMV）、边缘上回（SMG）和初级体感皮质（S1）。当参与者执行想象的到达和抓取任务时，使用功能磁共振成像确定PPC和PMV内的确切植入位置。受试者在不同方向上进行精确抓握、强力抓握或伸展。对于S1植入物的定位，受试者在功能磁共振成像期间接触到肱二头肌、前臂和鱼际隆起上有残留感觉的区域，并报告接触次数。</p>
<p>实验任务：通过从“人类抓取数据库”中获取的视觉图像，提示五种不同的抓取任务，以检查SMG、PMV和S1中与想象抓取相关的神经活动。</p>
<p>Go/No-Go任务：呈现一个绿色圆圈（Go条件）或一个红色圆圈（No-Go条件后），参与者被指示想象在Go条件正常执行提示抓取，对No-Go条件不做任何事情，示例如图1所示。在每个训练日，进行“运动想象任务”（与Go任务相同）、“口头抓握任务”和“口头颜色任务”，以便在任务之间进行比较。</p>
<p>在Go/No-Go版本的任务中，SMG和PMV的示例单元的平滑放电率显示了对抓取“Sphere3Finger”的神经元调制，如图2所示。与No-Go试验的动作阶段相比，运动意象在Go试验的动作阶段引起了强烈的反应。</p>
<img src="/40768857/2.png" class>
<p>图1  用于提示四肢瘫痪的人类的运动图像</p>
<img src="/40768857/3.jpg" class>
<p>图2  对抓取“Sphere3Finger”的神经元调制</p>
<p>Go实验和No-Go实验在SMG, PMV围棋测试中50ms时间箱中所掌握的频道百分比分别如图3（A），图3（B）所示。</p>
<img src="/40768857/4.jpg" class>
<p>图3  SMG, PMV围棋测试中50ms时间箱中所掌握的频道百分比</p>
<p>Go实验和No-Go实验测试过程中ITI、提示阶段和动作阶段窗口中每个抓握调优的单位的堆叠百分比分别如图4（A)，图4（B）所示。</p>
<img src="/40768857/5.jpg" class>
<p>图4  ITI、提示阶段和动作阶段窗口中每个抓握调优的单位的堆叠百分比</p>
<p>GO实验中在 SMG 和 PMV 的围棋试验中，提示和动作分析窗口之间的调谐单元重叠，如图5所示。</p>
<img src="/40768857/6.jpg" class>
<p>图5  提示和动作分析窗口之间的调谐单元重叠</p>
<hr>
<h3 id="研究结果"><a href="#研究结果" class="headerlink" title="研究结果"></a>研究结果</h3><p>这项研究首次表明，人类SMG中的单个神经元群体编码各种想象抓取。并且发现了一个对想象抓握和口语进行编码的区域，扩展了认知BMI的概念。在BMI中，来自大脑高级认知区域的信号可以提供大量有用的大脑信号。这项研究为神经系统损伤患者的康复具有推动作用。</p>
<hr>
<h3 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h3><p>Wandelt S K, Kellis S, Bjånes D A, et al. Decoding grasp and speech signals from the cortical grasp circuit in a tetraplegic human[J]. Neuron, 2022, 110(11): 1777-1787. e3.</p>
<p>参考来源：<a href="https://mp.weixin.qq.com/s/kMhCp6kVzNAYHePYSqQB-w">https://mp.weixin.qq.com/s/kMhCp6kVzNAYHePYSqQB-w</a></p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12173">https://www.scholat.com/teamwork/showPostMessage.html?id=12173</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>软件硬件-X99从入门到精通</title>
    <url>/7793e847.html</url>
    <content><![CDATA[<img src="/7793e847/1.png" class>

<span id="more"></span>

<hr>
<h3 id="X99-「E5-v3-E5-v4-Extreme-i7」"><a href="#X99-「E5-v3-E5-v4-Extreme-i7」" class="headerlink" title="X99 「E5 v3 / E5 v4 / Extreme i7」"></a>X99 「E5 v3 / E5 v4 / Extreme i7」</h3><img src="/7793e847/2.webp" class>

<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><ul>
<li>所有的正式版双路E5处理器「E5 26xx」都不能超倍频</li>
<li>一般单路「E5 16xx」而且是同代至尊i7马甲的，一部分可以超频（1620v2，v3，16xxv4 除外）</li>
<li>并非所有的 ES QS E5 处理器可以超倍频</li>
</ul>
<p>对于下文提到的处理器，除非特别说明，均不能超倍频</p>
<p>小白 / 考虑装新机 / 不差预算 / 非硬件玩家 /  <strong>请直接选择12代Intel 或者 Zen3</strong> （此时 AM5 还没发布）</p>
<hr>
<h4 id="Q1-为什么不做-X79-了"><a href="#Q1-为什么不做-X79-了" class="headerlink" title="Q1 为什么不做 X79 了"></a>Q1 为什么不做 X79 了</h4><p>由于 Haswell / Broadwell 架构，IPC 相比 Snb 和 Ivy 有提升，指令集更全，游戏性能表现更好（大概是 3.7G 的 haswell 吊打 4.2G 的Snb）。</p>
<hr>
<h4 id="Q2-X99-平台的优点"><a href="#Q2-X99-平台的优点" class="headerlink" title="Q2 X99 平台的优点"></a>Q2 X99 平台的优点</h4><ul>
<li>E5 v3 鸡血补丁（v4不支持）</li>
<li>洋垃圾大船，价格便宜，DDR4 内存白菜价</li>
<li>可玩性不错，可选项多，既可以高频六核、八核主打游戏，也可以十二核、十六核，轻度生产力</li>
<li>得益于最近几年游戏多核优化提升，使用多核处理器玩网游也不会有太大瓶颈（LOL已证明是<strong>6线程</strong>优化，CSGO是<strong>8线程</strong>优化）</li>
<li>⚠️<strong>超线程不能当做物理核心</strong>用，超线程技术本质上只是起一个<strong>协调作用</strong>，4C8T的处理器仍然还是4个物理核心，对于一些对超线程利用率不高（物理核心效率 &gt; 超线程核心）的游戏来说，<strong>提升物理核心数，也不失为一种解决方案</strong><ul>
<li>4790K 4.5GHz 4C8T 371帧</li>
<li>5820K 4.5GHz 6C12T 582帧</li>
<li>5960X 4.6GHz 8C16T 535帧</li>
<li>帧数最大值  10400F <strong>6C 4.0G</strong> &lt; 10105F <strong>4C 4.2G</strong></li>
<li>稳定性（1% Low 帧） 10400F <strong>6C 4.0G</strong> &gt; 10105F <strong>4C 4.2G</strong></li>
<li>多核带来的帧数稳定性，只靠提升单核性能是带不来的</li>
<li>CSGO 帧数数据分析（Benchmark 同一场景）</li>
</ul>
</li>
<li>Haswell / Broadwell 目前仍有一战之力（Skylake挤牙膏）游戏表现比X79好很多</li>
</ul>
<hr>
<h4 id="Q3-推荐用什么板，DDR3？DDR4？RECC？寨板？正规板？"><a href="#Q3-推荐用什么板，DDR3？DDR4？RECC？寨板？正规板？" class="headerlink" title="Q3 推荐用什么板，DDR3？DDR4？RECC？寨板？正规板？"></a>Q3 推荐用什么板，DDR3？DDR4？RECC？寨板？正规板？</h4><ul>
<li>如果手里有 DDR3 内存，而且用功耗不高的处理器，可以选择 X99-DDR3 寨板</li>
<li>但是如果手里目前没有 D3 内存，强烈建议直接买 DDR4（寨板或者正规板）<ul>
<li>DDR4 (非RECC) 内存现在白菜价，DDR4 末代，技术也非常成熟了，4根科赋 1JR 4G 200 元左右（3200 C16）</li>
<li>DDR4 内存将来可以直接升级 12 代</li>
</ul>
</li>
<li>预算不足可以上 DDR4 寨板，DDR3 真的没有什么买的必要了，价格也没有差太多</li>
<li>X99 正规主板相比于寨板的优势<ul>
<li>支持超倍频</li>
<li>内存超频支持</li>
<li>BIOS</li>
<li>扩展</li>
</ul>
</li>
<li>X99 主板目前闲鱼均价 500 左右，砍价基本能在 450 成交（玩 X99 的人不多）</li>
</ul>
<hr>
<h4 id="Q4-E5-v3-和-E5-v4-的区别"><a href="#Q4-E5-v3-和-E5-v4-的区别" class="headerlink" title="Q4 E5 v3 和 E5 v4 的区别"></a>Q4 E5 v3 和 E5 v4 的区别</h4><p>E5 v3 对应 4 代至尊 i7 (58xx,59xx)，Haswell - E 架构 22nm 工艺</p>
<p>E5 v4 对应 5 代至尊 i7 (68xx,69xx)，Broadwell - E 架构 14nm （没有+++）工艺</p>
<ul>
<li>IPC 提升 5% 左右</li>
<li>外观区别</li>
<li>E5 v3 有鸡血补丁，E5 v4 没有</li>
<li>E5 v4 的内存控制器可能会好一些</li>
</ul>
<hr>
<h4 id="Q5-i9-7900X-比-i7-6950X-便宜-为什么？"><a href="#Q5-i9-7900X-比-i7-6950X-便宜-为什么？" class="headerlink" title="Q5 i9 7900X 比 i7 6950X 便宜 为什么？"></a>Q5 i9 7900X 比 i7 6950X 便宜 为什么？</h4><p>这个问题可以分为以下五点，是我认为当前时期劝退 X299 的主要原因</p>
<ul>
<li>价格仍有下降空间，IPC相比上代提升没那么大（不够吸引人）</li>
<li>没有寨板</li>
<li>X299 主板比 X99 贵</li>
<li>Skylake-X 的 Mesh 总线和阉割的三级缓存相比于上两代（Haswell-E / Broadwell-E）的 ring 总线，内存延迟偏高，对于游戏玩家来说是致命的（超 Mesh 频率会带来巨大的功耗提升）</li>
<li>79xx 是硅脂U，X99 都是钎焊</li>
</ul>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv18381885">https://www.bilibili.com/read/cv18381885</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-你（被）吐槽过论文不够 novel 吗？</title>
    <url>/6ac8ae8e.html</url>
    <content><![CDATA[<img src="/6ac8ae8e/1.png" class>

<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=211258873&bvid=BV1ea41127Bq&cid=502265464&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<p>新意度 * 有效性 * 问题大小 = 研究价值</p>
<ul>
<li>有效性：实验结果的好坏</li>
<li>问题大小：所在研究领域研究者和论文的多少</li>
<li>新意度：和前面的工作相比之下的新奇程度</li>
</ul>
<hr>
<h3 id="Novelty-in-Science"><a href="#Novelty-in-Science" class="headerlink" title="Novelty in Science"></a>Novelty in Science</h3><p>审稿人经常把复杂度、困难度、技术度与新意度搞混在一起</p>
<ul>
<li>建议在评审的时候应该把新意度这个词拿掉，换成优美（beauty）</li>
<li>如果是偏理论问题的研究的话，上述对于研究价值的定义公式就不再适用了，对于一个理论问题来说很难判断领域的大小，有效性也不是很好判断，所以理论研究者对于一个文章的判断通常会使用两个词：深刻（是否揭示了本质的东西）和优美（定理本身和证明是否有美感）</li>
<li>优美不太好量化，与个人的审美观和品味很相关，但是它的好处是它把技术性和复杂性从里面剥夺出来了，因为美和技术、复杂是没有太多关系的，比如对一个油画来说简单也很好看，复杂也很好看</li>
</ul>
<p>因为美不太好定义，所以作者举例说明了常见的误区</p>
<ol>
<li><strong>用复杂度来衡量新意度，很多审稿人认为简单的想法是没有新意的</strong>（这是一个常见的但是又不是那么正确的审稿意见）</li>
<li><strong>用困难度衡量新意度</strong></li>
<li><strong>用惊讶衡量新意度</strong></li>
<li><strong>用技术上的新意性来衡量一篇工作的新意性</strong></li>
<li><strong>用有效性或者价值来衡量新意度</strong></li>
</ol>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>新意度！=复杂度、困难度、惊讶度、技术新意度、有效性</strong></p>
<p><strong>新意度~=优美，要懂得欣赏</strong></p>
<ul>
<li>审稿人经常把新意度错误地归结到右边五项之一</li>
<li>新意度更多地是关于想法是否优美，所以在读文章或者审文章的时候要懂得欣赏</li>
</ul>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://perceiving-systems.blog/en/post/novelty-in-science">https://perceiving-systems.blog/en/post/novelty-in-science</a><br><a href="https://www.bilibili.com/read/cv15200155/">https://www.bilibili.com/read/cv15200155/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫方法技巧</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-世界机器人大会报告：机器人十大前沿热点领域(2022-2023)</title>
    <url>/6e835366.html</url>
    <content><![CDATA[<img src="/6e835366/1.png" class>

<p>上月底，在2022世界机器人大会闭幕式上，大会发布了《机器人十大前沿热点领域（2022-2023）》。该报告根据国家“十四五”发展规划，面向国家智能制造发展战略需求，结合“硬科技”最新发展前沿与趋势，调研走访在机器人领域具备技术领先水平和特色应用优势的骨干企业，组织拜访了来自于知名高校、研究机构的机器人相关领域专家学者，系统分析梳理了权威智库和知名战略咨询公司的机器人相关研究报告、机器人创新创业的分析报告，归纳出2022-2023年机器人十大前沿技术；并结合我国国情和机器人产业发展现状，提出了2022-2023年十大机器人应用热点产品。</p>
<p>中国电子学会嵌入式系统与机器人分会主任委员、北京航空航天大学教授王田苗，世界机器人大会专家委员会委员、北京航空航天大学研究员陶永等专家为该报告的发布提供支持。</p>
<span id="more"></span>

<p>以下是报告详细内容：</p>
<img src="/6e835366/2.png" class>

<hr>
<h3 id="机器人十大前沿技术"><a href="#机器人十大前沿技术" class="headerlink" title="机器人十大前沿技术"></a>机器人十大前沿技术</h3><img src="/6e835366/3.png" class>

<img src="/6e835366/4.png" class>

<img src="/6e835366/5.png" class>

<img src="/6e835366/6.png" class>

<img src="/6e835366/7.png" class>

<img src="/6e835366/8.png" class>

<img src="/6e835366/9.png" class>

<img src="/6e835366/10.png" class>

<img src="/6e835366/11.png" class>

<img src="/6e835366/12.png" class>

<img src="/6e835366/13.png" class>

<hr>
<h3 id="十大机器人应用热点产品"><a href="#十大机器人应用热点产品" class="headerlink" title="十大机器人应用热点产品"></a>十大机器人应用热点产品</h3><img src="/6e835366/14.png" class>

<img src="/6e835366/15.png" class>

<img src="/6e835366/16.png" class>

<img src="/6e835366/17.png" class>

<img src="/6e835366/18.png" class>

<img src="/6e835366/19.png" class>

<img src="/6e835366/20.png" class>

<img src="/6e835366/21.png" class>

<img src="/6e835366/22.png" class>

<img src="/6e835366/23.png" class>

<img src="/6e835366/24.png" class>

<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg4MzYzNDgwMQ==&amp;mid=2247544755&amp;idx=1&amp;sn=53e20610cca9d8baef82c19b733ba61a">https://mp.weixin.qq.com/s?__biz=Mzg4MzYzNDgwMQ==&amp;mid=2247544755&amp;idx=1&amp;sn=53e20610cca9d8baef82c19b733ba61a</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-如何在多块GPU上训练大模型？</title>
    <url>/1833c598.html</url>
    <content><![CDATA[<p>今天来看一篇工程优化文章，关于如何在多块GPU上训练大模型，作者Lilian Weng现为OpenAI应用人工智能研究负责人，主要从事机器学习、深度学习和网络科学研究。</p>
<p>原文链接：<a href="https://lilianweng.github.io/posts/2021-09-25-train-large/">How to Train Really Large Models on Many GPUs?</a></p>
<span id="more"></span>

<hr>
<h3 id="Training-Parallelism"><a href="#Training-Parallelism" class="headerlink" title="Training Parallelism"></a>Training Parallelism</h3><h4 id="Data-Parallelism"><a href="#Data-Parallelism" class="headerlink" title="Data Parallelism"></a>Data Parallelism</h4><p>DP最朴素的方法是复制相同的模型权重参数到多个workers上，给每个worker一部分数据来同时处理。<br>如果模型size大于单个GPU节点内存时，这种方法是不能work的。GeePS (Cui et al. 2016) 提出了将暂时不用的模型参数卸载回CPU上。这种数据交换传输通常在后端进行，不会干扰训练。</p>
<p>在每个minibatch结束后，workers需要同步梯度或参数，以保证学习效率，有两种主流的同步方法，包括它们的优缺点：</p>
<ol>
<li><strong>批量同步并行 Bulk synchronous parallels (BSP)</strong>: worker在每个Mini-batch结束时同步数据，这种方法保证了模型权重传递的及时性，但每台机器都必须排队等待其他机器发送梯度。</li>
<li><strong>异步并行 Asynchronous parallel (ASP)</strong>: 每个GPU采用异步方式处理数据，这种方法避免了不同机器之间的相互等待或暂停，但影响了权重传递的时效，降低了统计学习效率。而且即使增加计算时长，也不会加快训练的收敛速度。<br>在每一次迭代（x ＞1）的中间某些地方都需要同步全局梯度，该特征在<strong>分布式数据并行（Distribution Data Parallel，DDP）</strong>中被称为“<strong>梯度累积（gradient accumulation）</strong>”。<strong>分桶梯度(bucketing gradients)避免立即执行AllReduce操作，而是将多个梯度存储到一个AllReduce中以提高吞吐量，并基于计算图优化计算和通信调度。</strong></li>
</ol>
<img src="/1833c598/1.png" class>

<hr>
<h4 id="Model-Parallelism"><a href="#Model-Parallelism" class="headerlink" title="Model Parallelism"></a>Model Parallelism</h4><p>模型并行（Model parallelism，MP）用于解决模型权重不能放在单个节点的情况，计算和模型参数被分片到多台机器进行处理。和DP不同的是，DP中每个worker都有一个模型的完整副本，而MP只在一个worker上分配部分模型参数，因此对内存和计算的需求要小很多。</p>
<p>深度神经网络通常包含一个堆叠层，如果逐层拆分将连续的小层分配到工作层分区，操作起来并不难，但通过大量具有顺序依赖性的Workers来运行每个数据batch会花费大量的等待时间，计算资源的利用率也严重不足。</p>
<img src="/1833c598/2.png" class>

<hr>
<h4 id="Pipeline-Parallelism"><a href="#Pipeline-Parallelism" class="headerlink" title="Pipeline Parallelism"></a>Pipeline Parallelism</h4><p>PP结合了MP和DP，来减少无效的时间。主要的思路是：将minibatch分割成多个microbatches，每个相同stage的worker同时处理一个microbatches。注意，每个microbatch包含两次传递，前后和后向。内部worker通信只传输激活（前向）和梯度（后向）。这种传输的调度方式和梯度被聚合的方式在不同的方法中又有区别。workers的数量，也被称为“pipeline depth”。</p>
<p>在 GPipe (Huang et al. 2019) 方法中，多个微批次处理结束时会同时聚合梯度和应用。同步梯度下降保证了学习的一致性和效率，与worker数量无关。如图3所示，“Bubble”仍然存在，但比图2少了很多。给定m个均匀分割的微批次和d个分区，假设每个微批次向前和向后都需要一个时间单位，则Bubble的占比为：</p>
<img src="/1833c598/3.png" class>

<p>GPipe论文表明，如果微批次的数量超过分区数量4倍（m&gt;4d），则“Bubble”开销几乎可以忽略不计。</p>
<p>GPipe在吞吐量上可以取得和设备数量相近的线性加速，尽管它并不能总是保证模型参数被均匀地分布在不同的worke节点上。</p>
<img src="/1833c598/4.png" class>

<p>PipeDream (Narayanan et al. 2019)方法要求每个worker交替处理向前和向后传递的消息（1F1B）。它将每个模型分区命名为“stage”，每个stage worker可以有多个副本来并行运行数据。这个过程使用循环负载均衡策略在多个副本之间分配工作，以确保相同minibatch 向前和向后的传递发生在同一副本上。</p>
<img src="/1833c598/5.png" class>

<p>由于PipeDream没有在所有worker batch结束时同步全局梯度，1F1B 很容易导致微批次向前和向后传递中使用了不同的权重，降低学习效率。对此，PipeDream提供了一些解决的思路：</p>
<p><strong>缓存权重【Weight stashing】</strong>：每个worker跟踪多个模型版本，给定数据 batch 的向前和向后传递相同版本的权重。</p>
<p><strong>垂直同步【Vertical sync】</strong>：不同模型权重版本与激活和梯度一起在全局worker之间传递，计算采用上一个worker传播的相对应的缓存版本。这个过程确保了worker之间的版本一致性（不同于GPipe，采用异步计算）。</p>
<p>在训练开始时，PipeDream会先分析模型每一层的计算内存和时间成本，然后将层划分为不同的stage进行优化，这是个动态规划问题。</p>
<img src="/1833c598/6.png" class>

<p>随后，有两个PipeDream的变体被提出来，以节省由模型缓存所带来的内存占用。</p>
<p><strong>PipeDream-flush</strong>增加了定期刷新全局同步管道的功能，就像GPipe一样，这种方式虽然牺牲了一点吞吐量，但显著减少了内存占用（仅需要维护单一版本的模型权重）。</p>
<img src="/1833c598/7.png" class>

<p><strong>PipeDream-2BW</strong>维护了两套模型权重参数。“2BW”代表“双缓冲权重（double-buffered weights）”，它会在每个微批次生成一个新的模型版本K（K&gt;d）。由于一些剩余的向后传递仍然依赖于旧版本，新的模型版本无法立即取代旧版本，但因为只保存了两个版本，内存占用的也被大大降低了。</p>
<img src="/1833c598/8.png" class>

<hr>
<h4 id="Tensor-Parallelism"><a href="#Tensor-Parallelism" class="headerlink" title="Tensor Parallelism"></a>Tensor Parallelism</h4><p>模型并行和管道并行都会垂直拆分模型，而张量并行（Tensor Parallelism，TP）是将张量运算的计算水平划分到多个设备上。</p>
<p>以Transformer为例。Transformer架构主要由多层MLP和自注意力块组成。Megatron-LM（Shoeybi et al.2020）采用了一种简单的方法来并行计算层内MLP和自注意力。</p>
<p>MLP层包含GEMM（通用矩阵乘法）和非线性GeLU传输。如果按列拆分权重矩阵A，可以得到：</p>
<img src="/1833c598/9.png" class>

<p>注意力块根据上述分区并行运行GEMM的 查询（Q）、键（K）和 权重（V），然后与另一个GEMM组合以生成头注意力结果。</p>
<img src="/1833c598/10.png" class>

<img src="/1833c598/11.png" class>

<p>Narayanan et al. (2021)提出将管道、张量和数据并行与新的管道调度策略相结合，提出了一种名为PTD-P的新方法。该方法不仅在设备上能够定位一组连续的层（“模型块”），还可以为每个wokers分配多个较小的连续层子集块（例如，设备1具有第1、2、9、10层；设备2具有第3、4、11、12层；每个具有两个模型块）</p>
<p>每个batch中，微批次的数量应精确除以wokers数量（m）。如果每个worker有v个模型块，那么与GPipe调度相比，管道的“bubble”时间可以减少 v 倍。</p>
<img src="/1833c598/12.png" class>

<hr>
<h3 id="Mixture-of-Experts-（MoE）"><a href="#Mixture-of-Experts-（MoE）" class="headerlink" title="Mixture-of-Experts （MoE）"></a>Mixture-of-Experts （MoE）</h3><p>为了突破模型大小的限制，谷歌后来提出一种混合专家（MoE）方法，其核心理念是：集成学习，它假设集成多个弱学习器就会拥有一个强学习器。</p>
<p>在深度神经网络中，混合专家（MoE）通过连接多个专家的门机制（gating mechanism）实现集成（Shazeer等人，2017）。门机制激活不同网络的专家以产生不同的输出。作者在论文将其命名为“稀疏门控专家混合层（sparsely gated MoE）”。</p>
<p>仅一个MoE层包含：</p>
<ol>
<li>前馈网络专家n；</li>
<li>可训练的门控网络G，通过学习n个专家的概率分布，将流量路由到几个特定的专家。</li>
</ol>
<p>根据门控输出，并非每个专家都必须进行评估。当专家的数量太大时，可以考虑使用两层MoE。</p>
<img src="/1833c598/13.png" class>

<p>G将输入与可训练权重矩阵Gg相乘，然后执行softmax：</p>
<img src="/1833c598/14.png" class>

<p>由于这个过程会产生密集的门控制向量，不利于节省计算资源，而且</p>
<img src="/1833c598/15.png" class>

<p>时也不需要评估专家。所以，MoE层仅保留了顶部k值，并通过向G中添加高斯噪声改进负载平衡，这种机制被称为噪声top-k门。</p>
<img src="/1833c598/16.png" class>

<p>为了避免门控网络可能始终偏向少数强势专家的自我强化效应，Shazeer等人（2017）提出了通过额外重要损失的软约束，以鼓励所有专家拥有相同的权重。其数值相当于每个专家的分批平均值变异系数的平方：</p>
<img src="/1833c598/17.png" class>

<p>其中，CV是变异系数，失重的w_aux​是可调节的超参数。由于每个专家网络只能获得小部分训练样本（“收缩批次问题”），所以在MoE中应该尽可能使用大batch，但这又会受到GPU内存的限制。数据并行和模型并行的应用可以提高模型的吞吐量。</p>
<img src="/1833c598/18.png" class>

<hr>
<h3 id="Other-Memory-Saving-Designs"><a href="#Other-Memory-Saving-Designs" class="headerlink" title="Other Memory Saving Designs"></a>Other Memory Saving Designs</h3><h4 id="CPU-Offloading"><a href="#CPU-Offloading" class="headerlink" title="CPU Offloading"></a>CPU Offloading</h4><p>如果GPU内存已满，可以将暂时未使用的数据卸载到CPU，并在以后需要时将其读回（Rhu等人，2016）。不过，这种方法近年来并不太流行，因为它会延长模型训练的时间。</p>
<hr>
<h4 id="Actiavation-Recomputation"><a href="#Actiavation-Recomputation" class="headerlink" title="Actiavation Recomputation"></a>Actiavation Recomputation</h4><p>激活重新计算，也称“激活检查点”或“梯度检查点”（Chen et al，2016），其核心思路是牺牲计算时间来换取内存空间。它减少了训练 ℓ 层深层神经网络到 O(sqrt(ℓ)) 的内存开销，每个batch只消耗额外的前向传递计算。</p>
<p>具体来说，该方法将层网络平均划分为d个分区，仅保存分区边界的激活，并在workers之间进行通信。计算梯度仍然需要在分区内层进行中间激活，以便在向后过程中重新计算梯度。在激活重新计算的情况下，用于训练 M(l) 是：</p>
<img src="/1833c598/19.png" class>

<p>它的最低成本是：O(sqrt(ℓ))当d=sqrt(ℓ)时。</p>
<p>激活重新计算的方法可以得出与模型大小有关次线性内存开销，如下图：</p>
<img src="/1833c598/20.png" class>

<hr>
<h4 id="Mixed-Precision-Training"><a href="#Mixed-Precision-Training" class="headerlink" title="Mixed Precision Training"></a>Mixed Precision Training</h4><p>Narang &amp; Micikevicius et al. (2018)介绍了一种使用半精度浮点（FP16）数训练模型而不损失模型精度的方法。</p>
<img src="/1833c598/21.png" class>

<p>其中涉及三种关键技术：</p>
<ul>
<li><strong>全精度权重复制：</strong>保持累积梯度的模型权重的全精度（FP32）复制。对于向前和向后的传递的信息做四舍五入至半精度处理，因为每次梯度更新（即梯度X学习率）太小，可能无法完全包含在FP16范围内。</li>
<li><strong>缩放损失：</strong>放大损失以更好地处理小幅度的梯度（见图16），放大梯度以使其向可表示范围的右侧部分（包含较大的值）移动，从而保留可能丢失的值。</li>
<li><strong>算术精度：</strong>对于常见的网络算法（如矢量点积、矢量元素求和归约），将部分结果累加到FP32中，然后输出保存为FP16。逐点操作可以在FP16或FP32中执行。</li>
</ul>
<img src="/1833c598/22.png" class>

<p>在这项实验中，图像分类、更快的R-CNN等不需要损失缩放，但其他网络，如多盒SSD、大LSTM语言模型是需要损失缩放的。</p>
<hr>
<h4 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h4><p>模型权重在向前和向后传递的过程中会消耗大量内存。考虑到这两种传递方式会花费大量时间，Jain（Jain et al，2018）提出了一种数据编码策略，即在第一次传递后压缩中间结果，然后将其解码用于反向传播。</p>
<p>Jain和团队研发的Gist系统包含两种编码方案：一是特定于层的无损编码，包括 ReLU-Pool和 ReLU-Conv模式；二是有攻击性的有损编码，主要使用延迟精度缩减（DPR）。需要注意的是，第一次使用特征图时应保持高精度，第二次使用时要适度降低精度。这项实验表明，Gist可以在5个最佳图像分类DNN上减少2倍的内存开销，平均减少1.8倍，性能开销仅为4%。</p>
<hr>
<h4 id="Memory-Efficient-Optimizer"><a href="#Memory-Efficient-Optimizer" class="headerlink" title="Memory Efficient Optimizer"></a>Memory Efficient Optimizer</h4><p>优化器也会消耗内存。以主流的Adam优化器为例，其内部需要维护动量和方差，这两者与梯度和模型参数比例基本相同。这意味着，我们需要节省4倍模型权重的内存。</p>
<p>为了减少内存消耗，学术界已经提出了几款主流优化器。与Adam相比，Adafactor（Shazeer et al.2018）优化器没有存储全部动量和变化，只跟踪移动平均数的每行和每列总和，然后根据这些总和估计二阶矩。</p>
<p>SM3（Anil et al.2019）优化器采用了一种不同的自适应优化方法。</p>
<p>ZeRO（Rajbhandari et al.2019）零冗余优化器节省了大型模型训练在两方面的内存消耗：</p>
<ol>
<li>大多数内存由模型状态消耗，包括优化器状态（例如Adam动量和方差）、梯度和参数。混合精度训练也需要大量内存，因为除了FP16版本之外，优化器还需要保存FP32参数和其他优化器状态的副本。</li>
<li>剩余部分被激活、临时缓冲区以及不可用的碎片内存消耗。</li>
</ol>
<p>ZeRO结合了ZeRO-DP和ZeRO-R两种方法。ZeRO-DP是一种增强的数据并行，避免了模型状态的简单冗余。它以动态的方式跨多个并行数据划分优化器状态、梯度和参数，以最小化通信量。ZeRO-R使用分区激活二次计算、恒定缓冲区大小和动态内存碎片，以优化剩余状态的内存消耗。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/qq_32275289/article/details/124377578">https://blog.csdn.net/qq_32275289/article/details/124377578</a><br><a href="https://lilianweng.github.io/posts/2021-09-25-train-large/">https://lilianweng.github.io/posts/2021-09-25-train-large/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-学习报告-脑机接口技术如何改善意识障碍的诊断</title>
    <url>/f1834bd9.html</url>
    <content><![CDATA[<p>本篇学习报告介绍一篇2022年发表的论文《How brain-computer interface technology may improve the diagnosis of the disorders of consciousness: A comparative study》，论文探究了BCI技术如何改善意识障碍患者的诊断，得出了脑机接口主动范式可能有助于评估意识水平，提高临床的诊断精度的结论。</p>
<span id="more"></span>

<hr>
<h3 id="研究背景与内容"><a href="#研究背景与内容" class="headerlink" title="研究背景与内容"></a>研究背景与内容</h3><p>意识障碍（DOC）和闭锁综合征（LIS）的诊断仍然是一个巨大的临床挑战。最严重的DOC类型是昏迷，其特征是对命令活感觉刺激没有意识反应。觉醒综合征（UWS）是一种稍微不那么严重的状态，在这种状态下，眼睛可以张开但不会有其他反应性变化。而对于最小意识状态（MCS），它的特征是对外部刺激有自发的反应。在完全闭锁综合征（CLIS）中，即使患者具有完整的认知功能，也无法进行自主运动，因此无法进行交流。</p>
<p>在床边评估无法沟通或表现出意志行为的患者的认知能力和意识功能非常困难。由此产生的诊断错误具有重大的伦理意义。患有 DOC 的人的家人必须就持续的医疗护理、治疗或康复选择、住房、探视，甚至停止生命支持做出艰难的决定。这些家庭和患者需要有关患者剩余意识功能和康复可能性的准确信息。</p>
<p>目前大多数的研究都是基于单一评估。由于DOC患者可能在会话内和会话间表现出高度可变的BCI范例，因此单一评估可能会导致误导性结果。</p>
<p>在本文中，比较了CRS-R和基于振动触觉P300的BCI范式在跨多个评估会话中检测命令跟踪的效率。</p>
<hr>
<h3 id="被试和实验方法"><a href="#被试和实验方法" class="headerlink" title="被试和实验方法"></a>被试和实验方法</h3><p>表1 被试信息</p>
<img src="/f1834bd9/1.jpg" class>

<h4 id="神经行为评估"><a href="#神经行为评估" class="headerlink" title="神经行为评估"></a>神经行为评估</h4><p>一位经验丰富的神经科医生使用 CRS-R 来区分意识水平。该量表由六个分量表组成，探索听觉、视觉和运动功能，以及唤醒状态和交流功能。在没有证据表明对刺激有意志反应的情况下睁眼（自发或刺激后）导致 UWS 的诊断，而口头命令的执行、视觉固定或追踪、有意交流或有害刺激的定位表示 MCS。这组患者根据第一组语言处理中的证据进一步细分为 MCS + 或 MCS -，通过命令跟随或交流来表达。</p>
<hr>
<h4 id="基于脑机接口的评估"><a href="#基于脑机接口的评估" class="headerlink" title="基于脑机接口的评估"></a>基于脑机接口的评估</h4><p>在每次 CRS-R 给药的同一天，在至少休息 2 小时后，每位患者使用 mindBEAGLE 系统参加了基于 BCI 的session。该系统之前已在健康受试者和不同患者组中进行了验证，包括一台笔记本电脑、一个脑电图放大器、一个带有 8 个湿式有源电极的盖子和三个振动触觉刺激器。当患者处于舒适的坐姿或仰卧位时，将帽子安全地放在头皮上，将左右刺激器轻轻固定在相应的手腕上，并将第三个（牵引器）刺激器固定在背部（如图1所示）。</p>
<p>每个实验块由30个实验组成。每个实验包含8个刺激（每个100毫秒，刺激开始之间400毫秒）。</p>
<img src="/f1834bd9/2.jpg" class>
<p>图1 脑机接口范式</p>
<hr>
<h4 id="信号处理和分类"><a href="#信号处理和分类" class="headerlink" title="信号处理和分类"></a>信号处理和分类</h4><p>在每次运行期间，系统记录原始脑电图数据和每次刺激的开始，并训练一个分类器，该分类器相应地将每个受试者的目标与非目标区分开来。获取的 EEG 数据在 0.1 和 30 Hz 之间进行带通滤波，以消除基线偏移并消除大多数 EMG 伪影。</p>
<p>信号处理的过程如图2所示。</p>
<img src="/f1834bd9/3.png" class>
<p>图2 信号处理步骤</p>
<p>在数据处理结束时，系统以百分比计算中值准确度。由于目标刺激与非目标刺激的比率为 1:7，因此机会准确率为 12.5%。该准确度表明系统将目标刺激与其他刺激区分开来的能力，并可能反映每个患者遵循指令和计算目标刺激的能力。</p>
<hr>
<h4 id="评估结果"><a href="#评估结果" class="headerlink" title="评估结果"></a>评估结果</h4><p>表2展示了CRS-R和基于BCI的评估所获得的结果，以及重复CRS-R的最终临床诊断。</p>
<p>表2 评估结果</p>
<img src="/f1834bd9/4.jpg" class>

<hr>
<h3 id="总结与思考"><a href="#总结与思考" class="headerlink" title="总结与思考"></a>总结与思考</h3><p>本文比较了两种评估方法：标准化的临床工具（CRS-R）和基于振动触觉诱发电位的P300的BCI范式。</p>
<p>实验设计旨在克服这组患者由于严重的脑损伤而导致的运动和认知限制。关于感觉刺激方式，我们使用了独立于视觉的范式，考虑到从临床实践中收集的证据表明，大多数 DOC 患者缺乏对颈部和视觉追踪和注意力的控制。</p>
<p>用这两种方法在7周内重复评估取得了显着的效果。正如之前报道的，第一次CRS-R低估了患者的行为反应，导致数名患者错误地诊断为 UWS。在随后的CRS-R 重复中，14 名最初无反应的患者中有 7 名开始表现出命令跟随或其他意志行为的迹象，因此改变了他们在 MCS 中的诊断。其中六人在第1个session的 BCI 范式中表现出主动命令跟随，表明对这种神经生理学方法的命令跟随高度敏感。</p>
<p>总体而言，本文探索了 BCI 范式的表现与临床状况之间存在密切关系。所有 MCS 患者在 BCI 范例中都表现出一定的反应能力，他们没有表现出任何处理语言和执行命令的能力。这一证据证实了认知能力和可观察到的行为现象之间可能存在的分离。</p>
<p>因此，将基于BCI的主动范式整合到 DOC的临床诊断中可能有助于确认或挑战基于行为评估的无反应临床判断，为自愿心理过程提供可重复的证据。这些信息可以支持有关维持生命的治疗、强化康复计划、疼痛治疗的决策，并加强家人和朋友与患者的互动。随着进一步的研究，检测其他ERP探索情绪活动或使用非EEG信号的其他BCI范例不仅可以提高诊断准确性和预测，还可以提供有关每个患者的特定的治疗方案。</p>
<hr>
<h3 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h3><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9404379/">Spataro, Rossella, et al. “How brain-computer interface technology may improve the diagnosis of the disorders of consciousness: A comparative study.” Frontiers in Neuroscience 16 (2022).</a></p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12257">https://www.scholat.com/teamwork/showPostMessage.html?id=12257</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫知识分享</category>
      </categories>
  </entry>
  <entry>
    <title>微表情-微表情数据集简介</title>
    <url>/21278805.html</url>
    <content><![CDATA[<h3 id="微表情数据集简介"><a href="#微表情数据集简介" class="headerlink" title="微表情数据集简介"></a>微表情数据集简介</h3><p>以下数据集均为公开数据集，其中 MEVIEW 是在真实场景中捕捉微表情；SMIC, SAMM, MMEW, CASME, CASME II, CAS(ME)2 and CAS(ME)3 数据集在实验室环境下，通过观看视频诱发微表情，后者相比前者减少了多余动作污染的机会。</p>
<p>除SMIC外，SAMM, MMEW, CASME, CASME II and CAS(ME)2数据集均标注了onset frame, apex frame, offset frame 和AUs标签。</p>
<p>数据集虽然公开，但仍需签订协议进行申请，有些学生就可以申请，有些则需要导师申请。如需申请，请前往官网查看细节。</p>
<span id="more"></span>

<hr>
<h3 id="MEVIEW"><a href="#MEVIEW" class="headerlink" title="MEVIEW"></a>MEVIEW</h3><p>2017年发布，由一些在非实验室环境下的 真实视频片段组成，诱发场景为扑克牌游戏和电视访谈。</p>
<p>数据集可分为7个情感类型：happiness, contempt, disgust, surprise, fear, anger and unclear emotions。</p>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><img src="/21278805/1.jpg" class>

<h4 id="数据集信息"><a href="#数据集信息" class="headerlink" title="数据集信息"></a>数据集信息</h4><ul>
<li>包含包含40 个微表情视频样本</li>
<li>样本标签包含7种情感类型，happiness(6 samples), contempt(6), disgust(1), surprise(9), fear(3), anger(2) and unclear(13)</li>
<li>受试人员16人</li>
</ul>
<h4 id="视频信息"><a href="#视频信息" class="headerlink" title="视频信息"></a>视频信息</h4><ul>
<li>每个片段平均长度为3秒</li>
<li>分辨率为（resolution）1280×720</li>
<li>每秒帧数（fps) 25。</li>
</ul>
<h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li>提供AUs标签</li>
<li>场景真实</li>
<li>同时由于场景真实，很少能从正面拍摄到脸部</li>
<li>参与者仅仅16人</li>
</ul>
<h4 id="官网链接"><a href="#官网链接" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href="http://cmp.felk.cvut.cz/new_pages/">CMP – Center for Machine Perception @ CTU in Prague (cvut.cz)</a></p>
<h4 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://cmp.felk.cvut.cz/~cechj/ME/">Spotting Facial Micro-Expressions ‘In the Wild’ (cvut.cz)</a></p>
<hr>
<h3 id="SMIC"><a href="#SMIC" class="headerlink" title="SMIC"></a>SMIC</h3><p>THE SPONTANEOUS MICRO-EXPRESSION DATABASE (SMIC)</p>
<p>2013年发布，数据集包含三个数据子集，它们区别在于使用了不同类型的相机——1)HS，使用高帧率相机；2）VIS，使用普通相机；3）NIR，使用近红外线相机,消除光照影响；数据集可分为3种情感类型：positive, negative and surprise</p>
<h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><img src="/21278805/2.jpg" class>

<h4 id="数据集信息-1"><a href="#数据集信息-1" class="headerlink" title="数据集信息"></a>数据集信息</h4><ul>
<li>包含三种不同类型相机拍摄的视频子集，总样本数量为306</li>
<li>样本标签包含3种情感类型，positive（107）, negative（116） and surprise（83）</li>
<li>HIS子集受试人员为16，NIR和VIS为8</li>
</ul>
<h4 id="视频信息-1"><a href="#视频信息-1" class="headerlink" title="视频信息"></a>视频信息</h4><p>对于HS数据子集</p>
<ul>
<li>包含164个微表情视频片段</li>
<li>分辨率为（resolution）1280×720</li>
<li>每秒帧数（fps) 100</li>
</ul>
<p>对于VIS和NIR数据子集</p>
<ul>
<li>均包含71个微表情视频片段</li>
<li>分辨率为（resolution）640*480</li>
<li>每秒帧数（fps) 25</li>
</ul>
<h4 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li>仅3种情感类型</li>
<li>情感标签基于参与者自我报告，可能不准确</li>
<li>未提供动作单元(AUs)标签</li>
</ul>
<p>AUs是个体肌肉或肌肉群的基本动作，是根据面部动作编码系统(FACS)定义，一种根据面部表情来分类人类面部动作的系统。如高兴表情对应的AUs可以是AU6(脸颊上升)+AU12(嘴角拉伸)</p>
<p>扩展版的<strong>SMIC-E</strong>中，提供了包含非微帧的长视频，可以用于微表情检测</p>
<h4 id="官网链接-1"><a href="#官网链接-1" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href="https://www.oulu.fi/en/university/faculties-and-units/faculty-information-technology-and-electrical-engineering/center-machine-vision-and-signal-analysis">SMIC - Spontaneous Micro-expression Database | Center for Machine Vision and Signal Analysis (oulu.fi)</a></p>
<h4 id="相关论文-1"><a href="#相关论文-1" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://ieeexplore.ieee.org/document/6553717">A Spontaneous Micro-expression Database: Inducement, collection and baseline | IEEE Conference Publication | IEEE Xplore</a></p>
<p><a href="https://ieeexplore.ieee.org/document/6126401">Recognising spontaneous facial micro-expressions | IEEE Conference Publication | IEEE Xplore</a></p>
<p><a href="https://xueshu.baidu.com/usercenter/paper/show?paperid=a4ce8b06557870de76987bbcb6d62657&site=xueshu_se&hitarticle=1">Facial Action Coding System (FACS): a Technique for the Measurement of Facial Actions - 百度学术 (baidu.com)</a></p>
<hr>
<h3 id="CASME"><a href="#CASME" class="headerlink" title="CASME"></a>CASME</h3><p>2013年发布，由中国科学院提供，采用完全控制的实验室环境，实验期间保持中性表情，通过观看高情感视频诱发微表情，并提供4个灯以减少电流带来的灯光闪烁现象。</p>
<h4 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h4><img src="/21278805/3.jpg" class>

<h4 id="数据集信息-2"><a href="#数据集信息-2" class="headerlink" title="数据集信息"></a>数据集信息</h4><ul>
<li>包含微表情视频样本195</li>
<li>受试者人数35，平均年龄22.03，亚洲人</li>
<li>样本标签包含8种情感类型, categories: Amusement (5),Disgust (88), Sadness (6), Contempt (3), Fear (2), Tense (28), Surprise (20), Repression (40)</li>
</ul>
<h4 id="视频信息-2"><a href="#视频信息-2" class="headerlink" title="视频信息"></a>视频信息</h4><ul>
<li>分辨率为（resolution）640<em>480 和 1280</em>720</li>
<li>每秒帧数（fps) 60</li>
<li>视频中人脸尺寸 150*190</li>
</ul>
<h4 id="优缺点-2"><a href="#优缺点-2" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li>提供了AU labels</li>
<li>视频中人脸较小</li>
<li>样本标签分布不均匀</li>
</ul>
<h4 id="官网链接-2"><a href="#官网链接-2" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href="http://casme.psych.ac.cn/casme/e1">Welcome to Professor Fu’s Lab (psych.ac.cn)</a></p>
<h4 id="相关论文-2"><a href="#相关论文-2" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://ieeexplore.ieee.org/document/6553799/">CASME database: A dataset of spontaneous micro-expressions collected from neutralized faces | IEEE Conference Publication | IEEE Xplore</a></p>
<hr>
<h3 id="CASME-II"><a href="#CASME-II" class="headerlink" title="CASME II"></a>CASME II</h3><p>2014年发布，其可以视为CASME的扩展，采用高速相机，每秒帧数200；视频中的人脸尺寸更大；每个情感类别样本数量变得均衡些。</p>
<h4 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h4><img src="/21278805/4.jpg" class>

<h4 id="数据集信息-3"><a href="#数据集信息-3" class="headerlink" title="数据集信息"></a>数据集信息</h4><ul>
<li>包含微表情视频样本 247</li>
<li>受试者 26，平均年龄22.59，亚洲人</li>
<li>样本标签包含5种情感类型, Happiness (33 samples), Repression (27), Surprise (25), Disgust (60) and Others (102);</li>
</ul>
<h4 id="视频信息-3"><a href="#视频信息-3" class="headerlink" title="视频信息"></a>视频信息</h4><ul>
<li>分辨率为（resolution）640*480</li>
<li>每秒帧数（fps) 200</li>
<li>视频中人脸尺寸 280*340</li>
</ul>
<h4 id="优缺点-3"><a href="#优缺点-3" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li>样本标签分布较均匀</li>
<li>人脸尺寸变大</li>
</ul>
<h4 id="官网链接-3"><a href="#官网链接-3" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href="http://casme.psych.ac.cn/casme/e2">欢迎访问傅小兰课题组网站 (psych.ac.cn)</a></p>
<h4 id="相关论文-3"><a href="#相关论文-3" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://xueshu.baidu.com/usercenter/paper/show?paperid=b432a5e2a3444f09e53a0915b6721364&site=xueshu_se">CASME II: An Improved Spontaneous Micro-Expression Database and the Baseline Evaluation - 百度学术 (baidu.com)</a></p>
<hr>
<h3 id="CAS-ME-2"><a href="#CAS-ME-2" class="headerlink" title="CAS(ME)^2"></a>CAS(ME)^2</h3><p>2018年发布，其进一步扩展，增加了受试者的宏观表情和微观表情样本，数据集被划分为A、B两部分，A中有87个包含微表情和宏表情的长视频，B中有300个宏表情样本，57个微表情样本。情感类型包含三分类 positive, negative, surprise and others 或更细致的 anger，sadness ，anger， fear， disgust，happiness，surprise ，helpless，pain，confused，happyiness，sympathy。</p>
<h4 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h4><img src="/21278805/8.jpg" class>

<h4 id="数据集信息-4"><a href="#数据集信息-4" class="headerlink" title="数据集信息"></a>数据集信息</h4><ul>
<li>标注微表情视频样本有57，宏表情样本300个</li>
<li>受试者 22，平均年龄22.59，亚洲人</li>
<li>平均视频长度148秒</li>
</ul>
<h4 id="视频信息-4"><a href="#视频信息-4" class="headerlink" title="视频信息"></a>视频信息</h4><ul>
<li>分辨率为（resolution）640*480</li>
<li>每秒帧数（fps) 30</li>
</ul>
<h4 id="优缺点-4"><a href="#优缺点-4" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li>数据集中包含宏表情与微表情视频样本，更适合微表情检测工作</li>
<li>不仅提供了区间标注，也提供了情感类型的标注</li>
</ul>
<h4 id="官网链接-4"><a href="#官网链接-4" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href="http://casme.psych.ac.cn/casme/e3">欢迎访问傅小兰课题组网站 (psych.ac.cn)</a></p>
<h4 id="相关论文-4"><a href="#相关论文-4" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://ieeexplore.ieee.org/document/7820164">CAS(ME)-: A Database for Spontaneous Macro-Expression and Micro-Expression Spotting and Recognition | IEEE Journals &amp; Magazine | IEEE Xplore</a></p>
<hr>
<h3 id="CAS-ME-3"><a href="#CAS-ME-3" class="headerlink" title="CAS(ME)3"></a>CAS(ME)3</h3><p>2022年发布，数据集以三个特点：</p>
<ol>
<li><strong>大规模数据。</strong>征集216个对象，提供约8小时的视频，超过8,000,000帧，包括人工标注1030个微表情，3364个宏表情，避免数据库的偏差</li>
<li><strong>多模态分析。</strong>首次提供了深度信息作为额外的模态，并采集了总时长超过13000秒的生理和语音信号，有助于多模式的微表情分析</li>
<li><strong>无监督学习。</strong>改数据库野，提供了1508个未标注的视频，超过4,000,000帧，提供建立无监督微表情分析方法的数据平台。</li>
<li><strong>高生态效度。</strong>为了使数据更接近真实场景，通过模拟犯罪模式诱发微表情。</li>
</ol>
<h4 id="示例-5"><a href="#示例-5" class="headerlink" title="示例"></a>示例</h4><img src="/21278805/5.jpg" class>

<h4 id="数据集信息-5"><a href="#数据集信息-5" class="headerlink" title="数据集信息"></a>数据集信息</h4><p>包含A,B,C三部分，受试者共 247，男女比112/135，平均年龄22.74，标准偏差1.75，亚洲人</p>
<img src="/21278805/6.jpg" class>

<h5 id="PartA"><a href="#PartA" class="headerlink" title="PartA"></a>PartA</h5><p>使用情感视频诱导产生微表情,每个受试者观看13个情感视频</p>
<ul>
<li>包含100个受试者</li>
<li>微表情934个，宏表情3143个</li>
<li>微表情样本标签包含7种情感类型, Happiness (64 samples), Disgust (281), Fear(93), Anger(70), Sadness(64), Surprise (201) and Others (170)</li>
</ul>
<img src="/21278805/7.png" class>

<h5 id="PartB"><a href="#PartB" class="headerlink" title="PartB"></a>PartB</h5><p>使用情感视频诱导产生微表情，包含116个受试者，1508个未标注视频片段</p>
<h5 id="PartC"><a href="#PartC" class="headerlink" title="PartC"></a>PartC</h5><p>通过模拟犯罪模式诱发微表情</p>
<ul>
<li>31个受试者</li>
<li>包含116个微表情，347个宏表情</li>
<li>收集了相关生理信号，心率、声音信号</li>
</ul>
<h4 id="视频信息-5"><a href="#视频信息-5" class="headerlink" title="视频信息"></a>视频信息</h4><ul>
<li>分辨率为（resolution）1280*720</li>
<li>每秒帧数（fps) 30</li>
</ul>
<h4 id="优缺点-5"><a href="#优缺点-5" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li>数据集目前最大</li>
<li>引入深度图像信息，及其它生理信息</li>
</ul>
<h4 id="官网链接-5"><a href="#官网链接-5" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href="http://casme.psych.ac.cn/casme/e4">CAS(ME)3 Database (psych.ac.cn)</a></p>
<h4 id="相关论文-5"><a href="#相关论文-5" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://ieeexplore.ieee.org/abstract/document/9774929/media#media">CAS(ME)3: A Third Generation Facial Spontaneous Micro-Expression Database with Depth Information and High Ecological Validity | IEEE Journals &amp; Magazine | IEEE Xplore</a></p>
<hr>
<h3 id="SAMM"><a href="#SAMM" class="headerlink" title="SAMM"></a>SAMM</h3><p>The Spontaneous Actions and Micro-Movements.</p>
<p>2016年发布，与CASME数据集系列相似，也是在完全控制的实验室环境下进行，并控制灯光防止造成图像闪烁。情感类型包括 contempt, disgust, fear, anger, sadness, happiness and surprise。</p>
<h4 id="示例-6"><a href="#示例-6" class="headerlink" title="示例"></a>示例</h4><img src="/21278805/9.jpg" class>

<h4 id="数据集信息-6"><a href="#数据集信息-6" class="headerlink" title="数据集信息"></a>数据集信息</h4><ul>
<li>包含微表情视频样本 159</li>
<li>受试者 32，平均年龄33.24，来自13个种族</li>
<li>样本标签包含8种情感类型: Happiness (26 samples), Fear (8), Surprise (15), Anger(57), Disgust (9) ,Sadness (6), Contempt(12) and Others (26)</li>
</ul>
<h4 id="视频信息-6"><a href="#视频信息-6" class="headerlink" title="视频信息"></a>视频信息</h4><ul>
<li>分辨率为（resolution）2040*1088</li>
<li>每秒帧数（fps) 200</li>
<li>视频中人脸尺寸 400*400</li>
</ul>
<h4 id="优缺点-6"><a href="#优缺点-6" class="headerlink" title="优缺点"></a>优缺点</h4><p>包含AUs标签，指出Apex帧<br>fps高，视频分辨率大，人脸尺寸大</p>
<h4 id="官网链接-6"><a href="#官网链接-6" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href="http://www2.docm.mmu.ac.uk/STAFF/M.Yap/dataset.php">MH Yap - Datasets/Software (mmu.ac.uk)</a></p>
<h4 id="相关论文-6"><a href="#相关论文-6" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://ieeexplore.ieee.org/document/7492264">SAMM: A Spontaneous Micro-Facial Movement Dataset | IEEE Journals &amp; Magazine | IEEE Xplore</a></p>
<hr>
<h3 id="SAMM-Long"><a href="#SAMM-Long" class="headerlink" title="SAMM Long"></a>SAMM Long</h3><p>SAMM Long数据集是SAMM数据集的扩展，包含147个长视频，这些视频中标注了343个宏表情和159个微表情。</p>
<h4 id="数据集信息-7"><a href="#数据集信息-7" class="headerlink" title="数据集信息"></a>数据集信息</h4><ul>
<li>包含微表情视频样本 147个，其中79个包含了微表情</li>
<li>受试者 29</li>
<li>微表情标注159个，宏表情标注343个</li>
</ul>
<h4 id="视频信息-7"><a href="#视频信息-7" class="headerlink" title="视频信息"></a>视频信息</h4><ul>
<li>分辨率为（resolution）2040*1088</li>
<li>每秒帧数（fps) 200</li>
<li>视频中人脸尺寸 400*400</li>
</ul>
<h4 id="优缺点-7"><a href="#优缺点-7" class="headerlink" title="优缺点"></a>优缺点</h4><p>相比于CAS(ME)^2</p>
<ul>
<li>SAMM Long 数据集有更长的视频，更高的分辨率和帧率</li>
<li>具有更多的表情样本标注</li>
<li>没有标注情感类型</li>
</ul>
<h4 id="官网链接-7"><a href="#官网链接-7" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href="http://www2.docm.mmu.ac.uk/STAFF/M.Yap/dataset.php">MH Yap - Datasets/Software (mmu.ac.uk)</a></p>
<h4 id="相关论文-7"><a href="#相关论文-7" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1a030my0st4h02a0cr7506t09w466465&site=xueshu_se">SAMM Long Videos: A Spontaneous Facial Micro- and Macro-Expressions Dataset - 百度学术 (baidu.com)</a></p>
<hr>
<h3 id="MMEW"><a href="#MMEW" class="headerlink" title="MMEW"></a>MMEW</h3><p>micro-and-macro expression warehouse</p>
<p>2021年发布，同样在实验室环境下，通过观看情感视频诱惑微表情，同时视图保持中性表情。</p>
<h4 id="示例-7"><a href="#示例-7" class="headerlink" title="示例"></a>示例</h4><img src="/21278805/10.jpg" class>

<h4 id="数据集信息-8"><a href="#数据集信息-8" class="headerlink" title="数据集信息"></a>数据集信息</h4><ul>
<li>包含微表情视频样本 300，宏表情视频样本 900</li>
<li>受试者 36，平均年龄22.35，亚洲人</li>
<li>样本标签包含7种情感类型, Happiness (36), Anger (8), Surprise (89), Disgust (72), Fear (16), Sadness (13) and Others (66);</li>
</ul>
<h4 id="视频信息-8"><a href="#视频信息-8" class="headerlink" title="视频信息"></a>视频信息</h4><ul>
<li>分辨率为（resolution）1920*1080</li>
<li>每秒帧数（fps) 200</li>
<li>视频中人脸尺寸 400*400</li>
</ul>
<h4 id="优缺点-8"><a href="#优缺点-8" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li>包含AUs表情并指出Apex帧</li>
<li>同时包含有一组受试人员的微表情和宏表情视频样本</li>
<li>样本数量较多</li>
</ul>
<h4 id="官网链接-8"><a href="#官网链接-8" class="headerlink" title="官网链接"></a>官网链接</h4><p><a href>山大数据智能实验室 (dpailab.com)</a></p>
<h4 id="相关论文-8"><a href="#相关论文-8" class="headerlink" title="相关论文"></a>相关论文</h4><p><a href="https://ieeexplore.ieee.org/document/9382112">Video-based Facial Micro-Expression Analysis: A Survey of Datasets, Features and Algorithms | IEEE Journals &amp; Magazine | IEEE Xplore</a></p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>其按发布时间排序为：</p>
<ul>
<li>CAS(ME)3(2022)</li>
<li>MMEW(2021)</li>
<li>SAMM Long(2020)</li>
<li>CAS(ME)^2(2018)</li>
<li>MEVIEW(2017)</li>
<li>SAMM(2016)</li>
<li>CASMEII(2014)</li>
<li>CASME(2013)</li>
<li>SMIC(2013)</li>
</ul>
<p>CAS(ME)^2和SAMM Long适合微表情检测相关工作；CASMEⅢ、MMEW、SAMM、CASMEII、SMIC适合微表情分类，其中MMEW、CASMEII、CASMEⅢ、受试人员由亚洲人组成；MEVIEW是真实场景下的数据集，这意味着需要更多的处理。</p>
<p>在2019年的The Second Facial Micro-Expression Grand Challenge (MEGC): Spotting and Recognition 比赛中，CASMEII、SAMM、SMIC被组合为一个表情分类表情有3种（positive、negative、surprise）的数据库。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/420094515">https://zhuanlan.zhihu.com/p/420094515</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫微表情</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-解决CNN固有缺陷，CCNN凭借单一架构，实现多项SOTA</title>
    <url>/314096c1.html</url>
    <content><![CDATA[<p><strong>本文提出了迈向通用 CNN 架构：CCNN，可以用于任意分辨率、长度和维度的数据。</strong></p>
<p>选自arXiv，作者：David W. Romero等，机器之心编译。</p>
<p>在 VGG、U-Net、TCN 网络中… CNN 虽然功能强大，但必须针对特定问题、数据类型、长度和分辨率进行定制，才能发挥其作用。我们不禁会问，可以设计出一个在所有这些网络中都运行良好的单一 CNN 吗？</p>
<p>本文中，来自阿姆斯特丹自由大学、阿姆斯特丹大学、斯坦福大学的研究者提出了 CCNN，单个 CNN 就能够在多个数据集（例如 LRA）上实现 SOTA ！</p>
<span id="more"></span>

<img src="/314096c1/1.jpg" class>

<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>1998 年 LeCun 等人提出卷积神经网络 (CNN)，这是一类广泛用于机器学习的深度学习模型。由于 CNN 具有高性能和高效率等特点，使其在跨序列、视觉和高维数据的多个应用程序中实现 SOTA 性能。然而，CNN（以及一般的神经网络）存在一个严重缺陷，这些架构必须针对特定应用进行定制，以便处理不同的数据长度、分辨率和维度。这反过来又导致大量特定于任务的 CNN 架构出现。</p>
<p>数据可以有许多不同的长度，例如图像可以是 32x32 或 1024x1024。标准 CNN 存在的问题是，它们的卷积核是局部的，这需要为每个长度定制一个精心选择的步长和池化层来捕获整个上下文自定义架构。此外，许多数据本质上是连续的，在不同的分辨率下具有相同的语义，例如图像可以在任意分辨率下捕获，并具有相同的语义内容，音频可以在 16kHz 或 44.1kHz 采样，但人耳听起来仍然是相同的。</p>
<p>然而，由于卷积核的离散性，传统的 CNN 不能跨分辨率使用。当考虑具有相同 CNN 的不同维度数据时，这两个问题会进一步加剧，例如序列（1D）、视觉（2D）和高维数据（3D、4D），因为不同的维度以不同的特征长度和分辨率运行，例如一秒音频的长度很容易达到 16000，这与基准数据集中的图像大小形成强烈对比。</p>
<p>在本文中，研究者提出了迈向通用 CNN 架构。其目标是构建一个单一的 CNN 架构，可以用于任意分辨率、长度和维度的数据。标准 CNN 需要特定于任务的架构，因为其卷积核的离散性将内核绑定到特定的数据分辨率，并且由于构建大型离散卷积核所需的大量参数，它们不适合对全局上下文进行建模。</p>
<p>因此，为了构建一个通用的 CNN 架构，关键是开发一个分辨率不可知的卷积层，该卷积层能够以参数有效的方式对远程依赖关系进行建模。该研究入选 ICML 2022 。</p>
<img src="/314096c1/2.jpg" class>

<ul>
<li>论文地址：<a href="https://arxiv.org/pdf/2206.03398.pdf">https://arxiv.org/pdf/2206.03398.pdf</a></li>
<li>代码地址：<a href="https://github.com/david-knigge/ccnn">https://github.com/david-knigge/ccnn</a></li>
</ul>
<hr>
<h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><p>本文的贡献如下：</p>
<ul>
<li>该研究提出 Continuous CNN（CCNN）：一个简单、通用的 CNN，可以跨数据分辨率和维度使用，而不需要结构修改。CCNN 在序列 (1D)、视觉 (2D) 任务、以及不规则采样数据和测试时间分辨率变化的任务上超过 SOTA；</li>
<li>该研究对现有的 CCNN 方法提供了几种改进，使它们能够匹配当前 SOTA 方法，例如 S4。主要改进包括核生成器网络的初始化、卷积层修改以及 CNN 的整体结构。</li>
</ul>
<h4 id="连续核卷积"><a href="#连续核卷积" class="headerlink" title="连续核卷积"></a>连续核卷积</h4><p>连续核卷积将小型神经网络</p>
<img src="/314096c1/3.png" class>

<p>作为核生成器网络，同时将卷积核参数化为连续函数。该网络将坐标</p>
<img src="/314096c1/4.png" class>

<p>映射到该位置的卷积核值：</p>
<img src="/314096c1/5.png" class>

<p>（图 1a）。通过将 K 个坐标</p>
<img src="/314096c1/6.png" class>

<p>的向量通过 G_Kernel，可以构造一个大小相等的卷积核 K，即</p>
<img src="/314096c1/7.png" class>

<p>随后，在输入信号</p>
<img src="/314096c1/8.png" class>

<p>和生成的卷积核</p>
<img src="/314096c1/9.png" class>

<p>之间进行卷积运算，以构造输出特征表示</p>
<img src="/314096c1/10.png" class>

<p>即</p>
<img src="/314096c1/11.png" class>

<img src="/314096c1/12.jpg" class>

<p>任意数据维度的一般操作。通过改变输入坐标 c_i 的维数 D，核生成器网络 G_Kernel 可用于构造任意维数的卷积核。因此可以使用相同的操作来处理序列 D=1、视觉 D=2 和更高维数据 D≥3。</p>
<p>不同输入分辨率的等效响应。如果输入信号 x 有分辨率变化，例如最初在 8KHz 观察到的音频现在在 16KHz 观察到，则与离散卷积核进行卷积以产生不同的响应，因为核将在每个分辨率下覆盖不同的输入子集。另一方面，连续核是分辨率无关的，因此无论输入的分辨率如何，它都能够识别输入。</p>
<p>当以不同的分辨率（例如更高的分辨率）呈现输入时，通过核生成器网络传递更精细的坐标网格就足够了，以便以相应的分辨率构造相同的核。对于以分辨率 r (1) 和 r (2) 采样的信号 x 和连续卷积核 K，两种分辨率下的卷积大约等于与分辨率变化成比例的因子：</p>
<img src="/314096c1/13.png" class>

<hr>
<h4 id="CCNN：在-ND-中建模远程依赖关系"><a href="#CCNN：在-ND-中建模远程依赖关系" class="headerlink" title="CCNN：在 ND 中建模远程依赖关系"></a>CCNN：在 ND 中建模远程依赖关系</h4><p>具有连续核卷积的残差块改进。该研究对 FlexNet 架构进行了修改 ，其残差网络由类似于 S4 网络的块组成。CCNN 架构如下图 2 所示。</p>
<img src="/314096c1/14.jpg" class>

<p>基于这些观察，该研究构建了 FlexConv 的深度（depth-wise）可分离版本，其中通道（channel-wise）卷积是使用核生成器网络</p>
<img src="/314096c1/15.png" class>

<p>生成的核计算的，之后是从 N_in 到 N_out 进行逐点卷积。这种变化允许构建更广泛的 CCNN—— 从 30 到 110 个隐藏通道，而不会增加网络参数或计算复杂度。</p>
<p>正确初始化核生成器网络 G_Kernel。该研究观察到，在以前的研究中核生成器网络没有正确初始化。在初始化前，人们希望卷积层的输入和输出的方差保持相等，以避免梯度爆炸和消失，即 Var (x)=Var (y)。因此，卷积核被初始化为具有方差 Var (K)=gain^2 /(in channels ⋅ kernel size) 的形式，其增益取决于所使用的非线性。</p>
<p>然而，神经网络的初始化使输入的 unitary 方差保留在输出。因此，当用作核生成器网络时，标准初始化方法导致核具有 unitary 方差，即 Var (K)=1。结果，使用神经网络作为核生成器网络的 CNN 经历了与通道⋅内核大小成比例的特征表示方差的逐层增长。例如，研究者观察到 CKCNNs 和 FlexNets 在初始化时的 logits 大约为 1e^19。这是不可取的，这可能导致训练不稳定和需要低学习率。</p>
<p>为了解决这个问题，该研究要求 G_Kernel 输出方差等于 gain^2 / (in_channels⋅kernel_size) 而不是 1。他们通过 gain / sqrt(in_channels⋅kernel_size) 重新加权核生成器网络的最后一层。因此，核生成器网络输出的方差遵循传统卷积核的初始化，而 CCNN 的 logits 在初始化时呈现单一方差。</p>
<hr>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>如下表 1-4 所示，CCNN 模型在所有任务中都表现良好。</p>
<p>首先是 1D 图像分类 CCNN 在多个连续基准上获得 SOTA，例如 Long Range Arena、语音识别、1D 图像分类，所有这些都在单一架构中实现的。CCNN 通常比其他方法模型更小架构更简单。</p>
<p>然后是 2D 图像分类：通过单一架构，CCNN 可以匹配并超越更深的 CNN。</p>
<img src="/314096c1/16.jpg" class>

<p>对 ND 进行远程依赖建模的重要性。原则上可以将所有任务视为不考虑 2D 结构的序列任务，该研究只需改变进入核生成器网络的坐标维数，就可以在多维空间上轻松定义 CCNN。有趣的是，该研究观察到，通过在 LRA 基准测试中考虑图像和 Pathfinder 任务的 2D 特性，可以获得更好的结果（上表 3）。</p>
<p>在具有 2D 图像的 PathFinder 中，最大的 CCNN 获得了 96.00% 的准确率，比之前 SOTA 高出近 10 个点，并在扁平图像上的表现明显优于 CCNN。</p>
<p>此外，在原始 2D 数据上训练的模型显示出比它们的序列对应物更快的收敛（图 3）。具有小卷积核的 2D CNN，例如 ResNet-18，由于中间池化层缺乏细粒度的全局上下文建模，无法解决 Pathfinder。</p>
<img src="/314096c1/17.jpg" class>

<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/544030197">https://zhuanlan.zhihu.com/p/544030197</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>软件硬件-局域网内Windows建立共享硬盘服务器</title>
    <url>/ac4e1c0f.html</url>
    <content><![CDATA[<h3 id="Windows连接Windows的共享硬盘服务器"><a href="#Windows连接Windows的共享硬盘服务器" class="headerlink" title="Windows连接Windows的共享硬盘服务器"></a>Windows连接Windows的共享硬盘服务器</h3><h4 id="打开电脑共享功能"><a href="#打开电脑共享功能" class="headerlink" title="打开电脑共享功能"></a>打开电脑共享功能</h4><p>首先进入网络和共享中心打开共享设置</p>
<img src="/ac4e1c0f/1.png" class>

<span id="more"></span>

<img src="/ac4e1c0f/2.png" class>

<img src="/ac4e1c0f/3.png" class>

<img src="/ac4e1c0f/4.png" class>

<hr>
<h4 id="打开SMB功能支持"><a href="#打开SMB功能支持" class="headerlink" title="打开SMB功能支持"></a>打开SMB功能支持</h4><p>在控制面板/程序功能/启用或关闭Windows功能，找到SMB选项，将所有的SMB功能勾选</p>
<img src="/ac4e1c0f/16.png" class>

<hr>
<h4 id="修改wifi权限"><a href="#修改wifi权限" class="headerlink" title="修改wifi权限"></a>修改wifi权限</h4><p>如果是连的局域网wifi需要改为<strong>专用网络</strong>，直接网线连接应该会自动设置为专用网络，否则你的共享文件夹别人看不见。</p>
<img src="/ac4e1c0f/5.png" class>

<img src="/ac4e1c0f/6.png" class>

<hr>
<h4 id="设置共享文件夹"><a href="#设置共享文件夹" class="headerlink" title="设置共享文件夹"></a>设置共享文件夹</h4><p>首先建立一个文件夹，右击打开属性，配置<strong>共享权限</strong></p>
<img src="/ac4e1c0f/7.png" class>

<p>选择共享权限，一般选择Everyone</p>
<img src="/ac4e1c0f/8.png" class>

<img src="/ac4e1c0f/9.png" class>

<hr>
<h4 id="设置共享磁盘"><a href="#设置共享磁盘" class="headerlink" title="设置共享磁盘"></a>设置共享磁盘</h4><p>操作基本同上，只不过仅需设置高级共享</p>
<img src="/ac4e1c0f/10.png" class>

<hr>
<h4 id="检查是否共享成功"><a href="#检查是否共享成功" class="headerlink" title="检查是否共享成功"></a>检查是否共享成功</h4><p>可以在自己电脑我的电脑主页下的网络中查看是否有自己共享的文件，也可在<strong>同一局域网</strong>下的其他电脑上查看是否能看到共享文件夹。</p>
<img src="/ac4e1c0f/11.png" class>

<p>可以看到共享文件的主机名字，点击后会出现登录界面，只要输入那台电脑的<strong>用户名和密码</strong>（为了保密性，可以在主机上新建一个访问用户）就可看到共享文件夹。</p>
<p>也可以在在服务器上新建用户，以便于登录。在“此电脑”右击并点击管理，根据以下操作，在第3步右击，建立新用户</p>
<img src="/ac4e1c0f/12.png" class>

<p>根据自己的特殊喜好，建立你的用户名和密码，靠此账户可以登录服务器。</p>
<img src="/ac4e1c0f/13.png" class>

<hr>
<h3 id="Ubuntu访问Windows的共享硬盘服务器"><a href="#Ubuntu访问Windows的共享硬盘服务器" class="headerlink" title="Ubuntu访问Windows的共享硬盘服务器"></a>Ubuntu访问Windows的共享硬盘服务器</h3><h4 id="安装samba和smbclient"><a href="#安装samba和smbclient" class="headerlink" title="安装samba和smbclient"></a>安装samba和smbclient</h4><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">sudo apt install samba samba-common smbclient</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>由于windows和ubuntu的文件传输协议不一样所以需要修改以下配置文件。</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/samba/smb.conf</span><br></pre></td></tr></table></figure>

<p>在文件中的[global]下面加入以下两句命令</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">client min protocol = CORE</span><br><span class="line">client max protocol = SMB3</span><br></pre></td></tr></table></figure>

<p>如下图</p>
<img src="/ac4e1c0f/14.png" class>

<p>刷新服务</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">sudo service smbd restart</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="连接服务器"><a href="#连接服务器" class="headerlink" title="连接服务器"></a>连接服务器</h4><p>打开ubantu“文件”，左侧看到“连接服务器”</p>
<img src="/ac4e1c0f/15.png" class>

<p>服务器地址输入：smb://你服务器地址</p>
<p>回车后会让你输入账户和密码，成功登录后就能看到里面的文件和数据了。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/Jolen_xie/article/details/110146783">https://blog.csdn.net/Jolen_xie/article/details/110146783</a><br><a href="https://blog.csdn.net/zbb19/article/details/123638199">https://blog.csdn.net/zbb19/article/details/123638199</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙兴趣杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-CCNN论文精读-《Towards a General Purpose CNN for Long Range Dependencies in ND》</title>
    <url>/ed1ba0e7.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2022-Towards-a-General-Purpose-CNN-for-Long-Range-Dependencies-in-ND.pdf" data-height="500px"></div>

<p>论文地址：<a href="https://arxiv.org/pdf/2206.03398.pdf">https://arxiv.org/pdf/2206.03398.pdf</a><br>代码地址：<a href="https://github.com/david-knigge/ccnn">https://github.com/david-knigge/ccnn</a></p>
<span id="more"></span>

<hr>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>卷积神经网络(CNNs)的使用在深度学习中是广泛的，由于一系列理想的模型属性，这导致了一个高效和有效的机器学习框架。然而，性能CNN架构必须针对特定的任务进行定制，必须考虑诸如输入长度、分辨率和维度等因素。在这项工作中，我们通过我们的连续卷积神经网络(CCNN)克服了CNN架构的缺陷，CCNN是一个配有连续卷积核的单一CNN架构，可以用于对任意分辨率、维度和长度的数据的任务，而不需要结构变化。连续卷积核对每一层的长距离依赖进行建模，消除了当前CNN架构中需要的降采样层和任务依赖深度。通过将相同的CCNN应用于一系列序列(1D)和可视化数据(2D)上的任务，我们展示了我们方法的普遍性。我们的CCNN在所有考虑的任务上都表现得很有竞争力，并且经常超过目前最先进的技术。</p>
<hr>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>卷积神经网络 (CNNs)是一类广泛用于机器学习应用的深度学习模型。它们的流行源于其高性能和高效率，使其在跨序列、视觉和高维数据的多个应用程序中实现l了最好的性能。然而，CNN和一般的神经网络的一个重要限制是，它们的架构必须针对特定的应用进行定制，以处理不同的数据长度、分辨率和维度。这反过来又导致了大量特定于任务的CNN架构。</p>
<p>数据可以有许多不同的长度，例如，图像可以是32x32或1024x1024，音频可以是每秒16000个样本。标准的CNN的问题是，它们的卷积内核是局部的，这需要为每个长度定制一个步长和池化层来捕获整个上下文的自定义架构。此外，许多类型的数据本质上是连续的，在不同的分辨率下具有相同的语义意义，例如，图像可以在任意分辨率下捕获，并具有相同的语义内容，音频可以在16kHz或44.1kHz任意采样，但人耳听起来仍然是相同的。然而，由于卷积核的离散性，传统的CNN被限制在分辨率上，不能跨分辨率使用。当考虑具有相同CNN的不同维数数据时，这两个问题进一步加剧，例如序列(1D)、视觉(2D)和高维数据(3D, 4D)，因为不同维数具有不同的特征长度和分辨率。</p>
<p><strong>迈向通用CNN架构。</strong>在这项工作中，我们的目标是构建一个单一的CNN架构，可以用于任意分辨率、长度和维度的数据。由于其卷积核的离散性质，标准的CNNs需要特定任务的架构，这将核绑定到特定的数据分辨率，并使它们不适合建模全局上下文，因为构造大型离散卷积核需要大量的参数。因此，为了构建一个通用的CNN架构，开发一个分辨率不可知的卷积层是至关重要的，它能够以参数高效的方式建模远程依赖关系。</p>
<p><strong>对连续参数化的需要。</strong>离散卷积核在每个核位置用Nout×Nin独立可学习权值定义。因此，大型卷积核需要大量的参数，而传统的CNN依赖于局部卷积核，结合任务相关的深度值和池化层来建模远程依赖。或者，我们可以通过使用一个小的神经网络来构建连续的卷积核，该网络将位置映射到这些位置的核值(图1a)。这种方法将卷积核的大小与构造它所需的参数数量解耦（解除耦合关系），从而允许以参数高效的方式构造任意长的核。此外，这种参数化克服了标准核的离散性，允许构造分辨率不可知的卷积核，它在任意分辨率的坐标上操作。因此，无论输入长度和分辨率如何，都可以使用相同的内核生成器网络——从而使用相同的CNN。此外，只需改变输入坐标的维度，同样的核生成器网络就可以构造序列D=1(图1b)、视觉D=2(图1c)和高维D≥3(图1d)任务的卷积核。总之，连续卷积核的特性允许构建一个单一的CNN架构，可以跨数据长度、分辨率和维度使用。</p>
<img src="/ed1ba0e7/1.png" class>

<p><strong>本文的贡献如下：</strong></p>
<ul>
<li>我们提出 Continuous CNN（CCNN）：一种简单、通用的 CNN，可以跨数据分辨率和维度使用，而不需要结构修改。CCNN 在序列 (1D)、视觉 (2D) 任务、以及不规则采样数据和测试时间分辨率变化的任务上超过最先进的水平。</li>
<li>我们对现有的 CCNN 方法提供了几种改进，使其能够匹配当前最先进的方法，例如 S4。主要改进包括核生成器网络的初始化、卷积层修改以及 CNN 的整体结构。</li>
</ul>
<hr>
<h3 id="Continuous-Kernel-Convolutions"><a href="#Continuous-Kernel-Convolutions" class="headerlink" title="Continuous Kernel Convolutions"></a>Continuous Kernel Convolutions</h3><img src="/ed1ba0e7/2.png" class>

<h4 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h4><p><strong>对任意数据维度的一般操作。</strong>通过改变输入坐标c_i的维数D，可以使用核生成器网络G_Kernel构造任意维数的卷积核。因此，对于序列D=1、视觉D=2、高维D≥3的数据，可以采用相同的操作进行处理。</p>
<p><strong>每一层的参数和计算高效的远程依赖建模。</strong>我们可以使用核生成器网络G_Kernel来构造与输入信号一样大的卷积核，以便对每一层的长距离依赖进行建模。G_Kernel中参数的数量与卷积核的长度无关，因此可以在固定的参数计数下构造任意大小的核。利用卷积定理可以有效地计算具有大卷积核的卷积，该定理指出，时域的卷积等于频域的点积。</p>
<p><strong>无规律采样的数据。</strong>对于某些应用，输入x可能不在规律的网格上，例如医疗数据。离散卷积核不适合这种应用，因为它们的值只在某些预设位置已知，而不适合任意坐标c_i。相反，连续核在任何地方都被定义，因此可以处理无规律的数据。</p>
<p><strong>不同输入分辨率的等效响应。</strong>如果输入信号x的分辨率发生变化，例如，最初观察到的音频是8KHz，现在观察到的音频是16KHz，与离散卷积核进行卷积将产生不同的响应，因为在每个分辨率下，内核将覆盖不同的输入子集。另一方面，连续内核是分辨率无关的，因此无论输入的分辨率如何，它都能够识别输入。当以不同的分辨率呈现一个输入时，例如，更高的分辨率，通过核生成器网络传递更细的坐标网格就足以构建相应分辨率的相同核。</p>
<p><strong>超参数学习。</strong>连续核的一个性质是，它们可以学习参数，否则必须被视为在带有离散卷积核的CNN里的超参数。</p>
<hr>
<h3 id="The-Continuous-Convolutional-Neural-Network-Modelling-Long-Range-Dependencies-in-ND"><a href="#The-Continuous-Convolutional-Neural-Network-Modelling-Long-Range-Dependencies-in-ND" class="headerlink" title="The Continuous Convolutional Neural Network: Modelling Long Range Dependencies in ND"></a>The Continuous Convolutional Neural Network: Modelling Long Range Dependencies in ND</h3><p><strong>一种改进的连续核卷积残差块。</strong>最近的工作表明，通过改变使用的非线性和归一化层在块内的位置，残差块可以得到强有力的改善。基于这些观察结果，我们修改了FlexNet架构，使用与S4网络类似的块组成的剩余网络。CCNN架构如图2所示。</p>
<img src="/ed1ba0e7/3.png" class>

<p><strong>深度可分连续核卷积。</strong>可分离卷积早已被证明可以提高CNNs的参数和计算效率。最近，它们的使用在CNN中比传统卷积有了改善，这是因为空间和信道维度的分离，降低了卷积的计算和参数复杂性，允许更广泛的网络和更高的性能。</p>
<p>基于这些观察，我们构建了一个深度可分版本的FlexConv ，其中信道卷积由核生成器网络生成的核计算，然后从N_in到N_out进行点卷积。这一变化允许建设一个更大的CCNN，从30到110个隐藏通道而不增加网络的参数或计算复杂性。</p>
<p><strong>正确初始化内核生成器网络G_Kernel。</strong>我们观察到，在之前的工作中，内核生成器网络没有为参数化卷积核而正确初始化。在初始化时，我们希望卷积层的输入和输出方差保持相等，以避免梯度爆炸和梯度消失，即Var(x)=Var(y)。因此，卷积核的方差被初始化为Var(K)=(gain^2)/(inchannels·kernelsize)，gain取决于使用的非线性。然而，神经网络的初始化使输入的单位方差保留在输出。因此，当用作核生成器网络时，标准的初始化方法会导致核存在单位方差，即Var(K)=1。结果表明，使用神经网络作为核生成网络的CNN的特征表示方差逐层增长，与in_channels·kernel_size成正比。例如，我们观察到CKCNNs和FlexNets在初始化时的 logits 大约为 e^19。这是不可取的，因为它会导致不稳定的训练和需要较低的学习率。</p>
<p>为了解决这个问题，我们要求G_Kernel输出的方差等于(gain^2)/(inchannels·kernelsize)，而不是1。为此，我们用gain/sqrt(inchannels·kernelsize)重新加权内核生成器网络的最后一层。因此，核生成器网络输出处的方差跟随传统卷积核的初始化，而CCNN的logits在初始化时呈现单位方差。</p>
<hr>
<h3 id="Experiments-and-discussion"><a href="#Experiments-and-discussion" class="headerlink" title="Experiments and discussion"></a>Experiments and discussion</h3><img src="/ed1ba0e7/4.png" class>

<p>结果如表1-4所示，我们的CCNN模型在所有考虑的任务中都表现良好。事实上，ccnn在多个LRA任务以及语音命令上的1D CIFAR10像素分类和原始语音分类上设置了一个新的艺术状态，而通常比竞争方法(远)小。</p>
<p>对ND进行远程依赖建模的重要性。原则上，我们可以把所有的任务看作一个不考虑二维结构的顺序任务。这是由于在多维空间中定义状态空间的复杂性而实现的。然而，这是以丢弃有关数据性质的重要信息为代价的。相反，只需改变进入内核生成器网络的坐标的维数，就可以很容易地在多维空间上定义CCNN。有趣的是，我们观察到，通过考虑LRA基准中的Image和Pathfinder任务的2D性质，可以获得更好的结果(表3)。在带有2D图像的Pathfinder中，我们最大的CCNN获得了96.00的精度，比之前的技术状态高出近10%的百分点，并且在平坦图像上的CCNN表现得非常好。此外，我们观察到，在原始2D数据上训练的模型比它们的顺序对应的模型显示出更快的收敛速度(图3)。</p>
<p>我们注意到，由于中间池化层导致缺乏细粒度的全局上下文建模，具有小卷积核(如ResNet-18)的2D CNN无法解决Pathfinder。</p>
<p>【细粒度（fine-grained）：粒度似乎根据项目模块划分的细致程度区分的，一个项目模块（或子模块）分得越多，每个模块（或子模块）越小，负责的工作越细，就说是细粒度。】</p>
<hr>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>我们提出了连续卷积神经网络:一个单一的CNN架构能够对任意长度、分辨率和维度的数据进行长距离依赖建模。这一发展的关键是用连续卷积核替换标准CNN中使用的离散卷积核。凭借单一的架构，我们的CCNN在各种序列和视觉任务上的表现具有竞争力，通常优于当前的技术水平。</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://blog.csdn.net/weixin_45922730/article/details/126212332">https://blog.csdn.net/weixin_45922730/article/details/126212332</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-马尔可夫判别器(PatchGAN)</title>
    <url>/12a55a8.html</url>
    <content><![CDATA[<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>马尔可夫判别器是判别模型的一种。</p>
<p>基于CNN的分类模型有很多种，很多网络都是在最后引入了一个全连接层，然后将判别的结果输出（输出结点）。</p>
<p>马尔可夫判别器则是不一样，*<em>直观来看，它完全由卷积层构成，最后输出的是一个 n * n 的矩阵，最后取输出矩阵的均值作为True/False的输出。*</em></p>
<p>事实上，输出矩阵中的每一个输出，代表着原图中一个感受野，对应了原图的一片（patch），而具有这样结构的GAN被称为PatchGAN。</p>
<span id="more"></span>

<hr>
<h3 id="优点和应用"><a href="#优点和应用" class="headerlink" title="优点和应用"></a>优点和应用</h3><p>目前来看，<strong>在图像风格迁移领域中</strong>，我们这里沿用Gatys论文中关于风格迁移的想法，<strong>即风格迁移分为两部分：内容部分和纹理部分。</strong></p>
<ul>
<li>内容部分是指生成图像和原图像在内容（语义）上的相似性</li>
<li>纹理部分是指生成图像和目标图像在纹理上的相似性</li>
</ul>
<p>马尔可夫判别器对于风格迁移中的超高分辨率、图片清晰化有一定的高分辨率、高细节的保持。</p>
<p>目前，马尔可夫判别器用于Pix2Pix和CycleGAN等GAN网络中。</p>
<hr>
<h3 id="感受域计算"><a href="#感受域计算" class="headerlink" title="感受域计算"></a>感受域计算</h3><p><strong>每一层感受域的计算公式为：</strong>input_size = (output_size-1)*k_stride+k_size</p>
<ul>
<li>感受域：输出结点（输出网络中的每个结点）对输入网络的感受野的范围（可以从输出网络大小反推感受野的大小）</li>
<li>input_size：为输出结点感受域的大小</li>
<li>k_stride：卷积核的移动步长</li>
<li>k_size：输入输出之间卷积核的大小</li>
</ul>
<p>以之前分析的CycleGAN代码中的马尔可夫判别器为例：</p>
<img src="/12a55a8/1.webp" class>

<p>last_conv输出（k_stride=1），假设其中一个节点，即output_size=1，计算得到CK4的大小（input_size）为4。同理，假设CK4_size = 4，则CK3_size = (4 - 1) * 2 + 4 = 10，CK2_size = (10 - 1) * 2 + 4 = 22，CK1_size = (22 - 1) * 2 + 4 = 46，input的感受域大小为94</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.likecs.com/show-204955112.html">https://www.likecs.com/show-204955112.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-被数据定义的睡眠——睡眠APP应用现状</title>
    <url>/aedfd9aa.html</url>
    <content><![CDATA[<p>《中国睡眠研究报告（2022）》指出，2021年中国居民睡眠指数为64.78分（百分制），略高于及格水平，可见我国居民的总体睡眠状况一般。其中，睡眠质量指标得分最高（71.51分），其次是睡眠环境指标得分（68.54分），得分最低的是睡眠信念和行为指标，仅为54.73分。我国居民基本睡眠情况的调查结果显示，多数居民在22<del>24点上床睡觉，在6</del>8点间起床，多数居民能在半小时左右入睡。64.75%的居民每天实际睡眠时长不足8个小时，睡眠时长超过8个小时的比例仅为7.97%，每天平均睡眠时长为7.06小时。为了改善睡眠不足的情况，提升睡眠质量，睡眠APP的研究和应用存在其必要性。</p>
<span id="more"></span>

<hr>
<h3 id="什么是睡眠APP"><a href="#什么是睡眠APP" class="headerlink" title="什么是睡眠APP"></a>什么是睡眠APP</h3><p>可以安装在手机或平板等电子设备的工具型APP，能够为使用者提供与辅助睡眠相关的功能。睡眠APP是互联网时代的新生产物，其本质是线上服务，通过播放助眠音乐、记录睡眠数据或培养良好的睡眠习惯达到促进用户快速入睡的目的。睡眠APP的种类主要包括声音助眠类、作息习惯类和监测记录类。</p>
<hr>
<h3 id="常见的睡眠APP"><a href="#常见的睡眠APP" class="headerlink" title="常见的睡眠APP"></a>常见的睡眠APP</h3><img src="/aedfd9aa/1.jpg" class>

<h4 id="小睡眠"><a href="#小睡眠" class="headerlink" title="小睡眠"></a>小睡眠</h4><p>小睡眠提供白噪音、冥想练习、专业ASMR、睡前故事等助眠内容，还支持监测睡眠、记录梦话、智能闹钟和CBT-I数字疗法。在睡眠服务基础上，小睡眠白噪音也是保持专注、减少拖延、冥想静心、看书阅读的好帮手。</p>
<img src="/aedfd9aa/2.jpg" class>

<h4 id="蜗牛睡眠"><a href="#蜗牛睡眠" class="headerlink" title="蜗牛睡眠"></a>蜗牛睡眠</h4><p>蜗牛睡眠自研睡眠算法，每日记录及监测入睡时间、睡眠深度及时长、翻身次数、打鼾/梦话内容等30项数据，并提供记录梦话与呼噜、分析睡眠状态、形成睡眠分析报告、睡眠音乐入睡停止、智能闹钟清晨唤醒、搞笑梦话在线分享等功能。</p>
<img src="/aedfd9aa/3.jpg" class>

<h4 id="SleepTown"><a href="#SleepTown" class="headerlink" title="SleepTown"></a>SleepTown</h4><p>SleepTown是一个帮助使用者培养规律作息的健康APP。每日达成设置的就寝、起床目标，就可以盖出一栋栋精致的房屋。简单3步骤，养成规律作息好习惯：</p>
<ol>
<li>设定一个有挑战性的就寝、起床时间目标</li>
<li>每天在就寝目标时间前开启APP，开始建造房屋</li>
<li>每天在起床目标以前，摇动手机快速清醒，看看昨晚盖出了什么新房屋</li>
</ol>
<hr>
<h3 id="睡眠APP的发展潜力"><a href="#睡眠APP的发展潜力" class="headerlink" title="睡眠APP的发展潜力"></a>睡眠APP的发展潜力</h3><p>2019年6月，来自世界各地的睡眠研究人员在一年一度联合专业睡眠协会的大会上初步展示了他们新发现的睡眠科技。一些研究也证实了睡眠追踪器很难探测到醒来的时间，但一些项目也解决了提高睡眠质量的问题。使用认知行为疗法治疗失眠症的研究人员发现，他们可以利用一款应用程序远程跟踪睡眠，以便在分析进展时减少志愿者亲自探访的负担。在另一项小规模的试点研究中发现，正确的睡眠指导与可穿戴式追踪器一起使用更有助于减少睡眠障碍。</p>
<p>因此，睡眠APP可以成为治疗手段中的一个实用工具。虽然我们需要等到睡眠数据正式发布之后才能得出一个确切的结论，但是了解目前学术界正在研究的睡眠追踪器与睡眠问题之间的相关性也十分有必要。</p>
<p>从目前已有的证据来看，市场上的一些睡眠APP明显是有潜力的。人们广泛且有规律地使用它们意味着研究人员可以更容易从大量人群中采集到有关睡眠质量的真实数据，这可以帮助临床医生更好地理解为什么这么多人有睡眠问题，以及怎样才能更好地改善睡眠。</p>
<p>对于目前在家使用睡眠监测应用的人来说，睡眠监测应用可能会提高人们对不良睡眠习惯的意识，进而激发人们改善睡眠。睡眠对于人类的身体健康很重要，所以鼓励人们关注睡眠产品或许会带来一些好处。但对于那些已经培养良好睡眠习惯的人来说，无论是坚持自己有规律的就寝时间，还是使用其他方法，睡眠监测对于他们的帮助尚未明确。毫无疑问，这项技术将会得到改进，科学界也会支持睡眠监测应用。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.sgpjbg.com/info/27019.html">https://www.sgpjbg.com/info/27019.html</a><br><a href="https://zhuanlan.zhihu.com/p/103645626">https://zhuanlan.zhihu.com/p/103645626</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12387">https://www.scholat.com/teamwork/showPostMessage.html?id=12387</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-TDGAN论文精读-《Facial Expression Recognition With Two-Branch Disentangled Generative Adversarial Network》</title>
    <url>/14139c13.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2021-Facial_Expression_Recognition_With_Two-Branch_Disentangled_Generative_Adversarial_Network.pdf" data-height="500px"></div>

<p>论文：<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9197663">Facial Expression Recognition with Two-branch Disentangled Generative Adversarial Network</a><br>代码：<a href="https://github.com/XsLangley/TDGAN">TDGAN</a></p>
<span id="more"></span>

<hr>
<h3 id="本文贡献"><a href="#本文贡献" class="headerlink" title="本文贡献"></a>本文贡献</h3><ol>
<li><p>提出一种利用双分支的分离GAN(TDGAN)进行表情识别。</p>
</li>
<li><p>面部表情识别任务与人脸检测任务不同。</p>
<p>当前工业上常用的人脸检测模型例如MTCNN，提出利用面部额外的属性信息例如表情、年龄等作为辅助任务，可以增强面部人脸识别(人脸ID)的表征能力，并且通过自监督的方式监督模型的训练过程，提高模型的泛化能力和性能，也取得了很好的效果。</p>
<p>然而，对于表情识别任务来说，核心是为了识别面部的表情，最理想的情况是相同的表情在不同的脸上都能完美识别。与个人信息有强关联的面部特征会对识别模型误导，也就是说，模型需要能够忽略面部与个人身份信息有强关联的特征。</p>
</li>
<li><p>2中的内容也就是提出本文方法的初衷：通过对抗学习的方式，同时学习面部表情特征和面部ID属性特征，通过表情迁移的方式把表情从一个脸上迁移到另一个脸上(图片生成)，让模型能够更好的分离面部ID信息和面部表情信息。</p>
</li>
<li><p>本文提出了自监督方式提升表征学习能力，增强特征分离能力。</p>
</li>
<li><p>本文提出的方法的定性和定量分析在实验室数据集和自然场景数据集上都获得了SOTA的效果。</p>
</li>
</ol>
<hr>
<h3 id="本文内容"><a href="#本文内容" class="headerlink" title="本文内容"></a>本文内容</h3><p>表情只在面部的特定区域内运动，但是全脸作为输入的模型会学习与表情导致的面部运动区域无关的特征，这些学习到的特征不仅是多余的，对于模型的全局识别能力也是有害的。另一方面，观测对象的姿态或者对象的外观变化也会不利于特征提取的质量，最终导致模型学习到的不同面部表情的特征的辨别能力不足。</p>
<p>本文提出的TDGAN模型，具有两个独立的分支：表情分支用于表情信息的处理，面部分支负责其他面部属性信息的编码。如Fig.1所示。模型以一对图片作为输入，图片对包括一个表情图片和一个面部图片(分别来自不同的数据集)。TDGAN的生成器分别学习两张图片的表情表征和面部表征后使用一个解码器融合，然后通过迁移表情图片中表情到面部面部图片的方式生成一张图片。最后，通过两个分支，一个用来判断面部信息，一个同来判断表情信息。</p>
<img src="/14139c13/1.png" class>

<p>TDGAN的框架如下：</p>
<img src="/14139c13/2.png" class>

<p>TDGAN首先通过两个编码器生成表情和面部特征，然后将两个特征融合并引入噪声(三块内容通过信道级拼接合成)。</p>
<p>通过一个嵌入层对融合的特征进行编码，并通过上采样方式生成Ig(模型生成的图片)。最后通过两个分支，对生成的图片进行分辨，两个辨别器分支分别为面部ID辨别器分支和表情辨别器分支。两个辨别器用来评估合成的图像的效果。如果合成的图像能够欺骗辨别器，说明模型学习到的特征已经很好。</p>
<p>另外，表情编码器分支还有一个FC层分支用于判别表情编码器分支学习到的特征。<br>通过对抗学习，生成器中学习到的表情特征可以从其他面部属性中分离出来，用于FER任务。</p>
<hr>
<h3 id="模型学习"><a href="#模型学习" class="headerlink" title="模型学习"></a>模型学习</h3><h4 id="使用对抗学习进行表情迁移"><a href="#使用对抗学习进行表情迁移" class="headerlink" title="使用对抗学习进行表情迁移"></a>使用对抗学习进行表情迁移</h4><p>学习过程中，TDGAN只更新输入面部图片的表情，也就是说生成的图片应该基于输入的面部图片而不是表情图片。额外加的fake class只配置到面部分辨器。生成的图片会作为面部图片输入分支的输入(伪样本)，用于训练输入面部图片分辨器；用于学习面部数据集的分布；</p>
<p>表情迁移分类的loss为LC：</p>
<img src="/14139c13/3.png" class>

<hr>
<h4 id="双图片一致性"><a href="#双图片一致性" class="headerlink" title="双图片一致性"></a>双图片一致性</h4><p>使用图片的ground-truth进行训练。也就是如下图所示，训练过程中，Ig作为模型生成结果，分别与If(输入的面部图片)和Ie(输入的表情图片)编码后融合重建图片，其Loss为LD。</p>
<img src="/14139c13/4.png" class>

<img src="/14139c13/5.png" class>

<hr>
<h4 id="语义内容一致性"><a href="#语义内容一致性" class="headerlink" title="语义内容一致性"></a>语义内容一致性</h4><p>本文采用额外感知loss(additionally perceptual loss)来评估生成面部图片的差距。df是由面部编码器对面部图片编码后生成的高级语义特征，d(g,f)是生成的图片输入到面部编码器生成的高层语义特征。LP用于计算两个图片的差距。</p>
<img src="/14139c13/6.png" class>

<p>因此，本文提出方法的生成器的loss最终计算为：</p>
<img src="/14139c13/7.png" class>

<p>表情识别分支的loss：</p>
<img src="/14139c13/8.png" class>

<p>使用方法：J. Johnson, A. Alahi, and L. Fei-Fei, “Perceptual losses for realtime style transfer and super-resolution,” in European Conference on Computer Vision, ECCV, 2016, pp. 694–711.</p>
<hr>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="实验细节"><a href="#实验细节" class="headerlink" title="实验细节"></a>实验细节</h4><h5 id="表情数据集的处理"><a href="#表情数据集的处理" class="headerlink" title="表情数据集的处理"></a>表情数据集的处理</h5><p>本论文使用数据集分别为CK+、TFEID、RaFD、BAUM-2i，RAF-DB</p>
<p>CK+：选择序列的最后三帧来构建训练集和测试集；序列的第一帧作为平静脸；因此，实验中一共有1236张图片</p>
<p>TFEID：数据集包括8中表情(6种基本表情+neutral+contempt)，本文只选取6种基本表情+neutral，一共选取580张图片</p>
<p>RaFD：数据标签包括表情标签和身份标签。本文只选取7种表情(6种基本表情+neutral）的数据集，共1407张图片</p>
<p>BAUM-2i：选取7种表情(6种基本表情+neutral），共998张图片</p>
<p>RAF-DB:数据集是大尺度面部表情数据集。只选取7种表情(6种基本表情+neutral）的数据集；共计12271个训练样本和3608个测试样本</p>
<hr>
<h5 id="试验设置"><a href="#试验设置" class="headerlink" title="试验设置"></a>试验设置</h5><p>面部数据集使用CASIA-WebFace。CASIA-WebFace只选取20个Subject作为训练数据，共计2894张面部图片。因为本方法是为了学习表情特征，而增加不同面部ID的图片，会干扰模型(让模型学习太多不同面部ID的特征信息，造成干扰)</p>
<p>网络结构如表所示:</p>
<img src="/14139c13/9.png" class>

<p>本实验验证，改变表情的特征会影响生成图片的表情，而不影响面部的其他属性信息。</p>
<ol>
<li>固定面部图片，不同表情插帧</li>
<li>固定表情图片<br>并不同面部插帧通过插帧方法查看生成图片的过程图片。</li>
</ol>
<img src="/14139c13/10.png" class>

<hr>
<h4 id="模型分析"><a href="#模型分析" class="headerlink" title="模型分析"></a>模型分析</h4><p>本文最后讨论了模型性能的问题</p>
<h5 id="识别任务问题"><a href="#识别任务问题" class="headerlink" title="识别任务问题"></a>识别任务问题</h5><ol>
<li>双分支模型，双分支的收敛速度不一致</li>
<li>双分支模型，表情分支学习的效果比面部特征学习效果好</li>
</ol>
<p>作者给出解决方案：面部分支使用更深/更加精细的模型进行训练；或者使用与训练模型</p>
<h5 id="迁移性能问题"><a href="#迁移性能问题" class="headerlink" title="迁移性能问题"></a>迁移性能问题</h5><p>有些图片的迁移效果较差的原因：</p>
<ol>
<li>识别对象极端姿势</li>
<li>识别对象有大面积的遮挡</li>
<li>数据集分布不均匀，例如惊讶表情较少</li>
</ol>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://blog.csdn.net/juan190755422/article/details/115430204">https://blog.csdn.net/juan190755422/article/details/115430204</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>算法分享-一些盛水与接水算法题的分享，leetcode 11.42.407/84</title>
    <url>/77d030e2.html</url>
    <content><![CDATA[<img src="/77d030e2/1.PNG" class>

<span id="more"></span>

<hr>
<img src="/77d030e2/2.PNG" class>

<img src="/77d030e2/3.PNG" class>

<img src="/77d030e2/4.PNG" class>

<img src="/77d030e2/5.PNG" class>

<img src="/77d030e2/6.PNG" class>

<img src="/77d030e2/7.PNG" class>

<hr>
<img src="/77d030e2/8.PNG" class>

<img src="/77d030e2/9.PNG" class>

<img src="/77d030e2/10.PNG" class>

<img src="/77d030e2/11.PNG" class>

<img src="/77d030e2/12.PNG" class>

<img src="/77d030e2/13.PNG" class>

<img src="/77d030e2/14.PNG" class>

<img src="/77d030e2/15.PNG" class>

<img src="/77d030e2/16.PNG" class>

<img src="/77d030e2/17.PNG" class>

<img src="/77d030e2/18.PNG" class>

<img src="/77d030e2/19.PNG" class>

<img src="/77d030e2/20.PNG" class>

<img src="/77d030e2/21.PNG" class>

<img src="/77d030e2/22.PNG" class>

<hr>
<img src="/77d030e2/23.PNG" class>

<img src="/77d030e2/24.PNG" class>

<img src="/77d030e2/25.PNG" class>

<img src="/77d030e2/26.PNG" class>

<img src="/77d030e2/27.PNG" class>

<img src="/77d030e2/28.PNG" class>

<img src="/77d030e2/29.PNG" class>

<hr>
<img src="/77d030e2/30.PNG" class>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐算法设计与分析</category>
      </categories>
  </entry>
  <entry>
    <title>Git-commit代码提交说明规范</title>
    <url>/b1b30ed3.html</url>
    <content><![CDATA[<p>git 是现在市面上最流行的版本控制工具，书写良好的 commit message 能大大提高代码维护的效率。但是在日常开发中由于缺少对于 commit message 的约束，导致填写内容随意、质量参差不齐，可读性低亦难以维护。在项目中引入 commit message 规范已是迫在眉睫。</p>
<h3 id="用什么规范？"><a href="#用什么规范？" class="headerlink" title="用什么规范？"></a>用什么规范？</h3><p>现在市面上比较流行的方案是约定式提交规范（Conventional Commits），它受到了 Angular 提交准则的启发，并在很大程度上以其为依据。约定式提交规范是一种基于提交消息的轻量级约定。它提供了一组用于创建清晰的提交历史的简单规则；这使得编写基于规范的自动化工具变得更容易。这个约定与 SemVer 相吻合，在提交信息中描述新特性、bug 修复和破坏性变更。它的 message 格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 头header</span><br><span class="line">&lt;类型&gt;[可选的作用域]: &lt;描述&gt;</span><br><span class="line">// 空一行</span><br><span class="line">[可选的正文]</span><br><span class="line">// 空一行</span><br><span class="line">[可选的脚注]</span><br></pre></td></tr></table></figure>

<p>即👇</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;type&gt;([scope]): &lt;subject&gt; </span><br><span class="line"></span><br><span class="line">[body]</span><br><span class="line"></span><br><span class="line">[footer]</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<hr>
<h3 id="Commit-message-规范"><a href="#Commit-message-规范" class="headerlink" title="Commit message 规范"></a>Commit message 规范</h3><h4 id="header（关键）"><a href="#header（关键）" class="headerlink" title="header（关键）"></a>header（关键）</h4><p>记录主要的修改类型和内容</p>
<p>由三个部分组合：type（必填）、scope（可选）、subject（必填）</p>
<h5 id="type"><a href="#type" class="headerlink" title="type"></a>type</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 主要type</span><br><span class="line">feat:     增加新功能</span><br><span class="line">fix:      修复bug</span><br><span class="line"></span><br><span class="line"># 特殊type</span><br><span class="line">docs:     只改动了文档相关的内容</span><br><span class="line">style:    不影响代码含义的改动，例如去掉空格、改变缩进、增删分号</span><br><span class="line">build:    构造工具的或者外部依赖的改动，例如webpack，npm</span><br><span class="line">refactor: 代码重构时使用</span><br><span class="line">revert:   执行git revert打印的message</span><br><span class="line"></span><br><span class="line"># 暂不使用type</span><br><span class="line">test:     添加测试或者修改现有测试</span><br><span class="line">perf:     提高性能的改动</span><br><span class="line">ci:       与CI（持续集成服务）有关的改动</span><br><span class="line">chore:    不修改src或者test的其余修改，例如构建过程或辅助工具的变动</span><br></pre></td></tr></table></figure>

<p>当一次改动包括主要type与特殊type时，统一采用主要type。</p>
<p>当然最好是分两次commit，便于了解每次的具体更新内容，方便回滚。</p>
<h5 id="scope"><a href="#scope" class="headerlink" title="scope"></a>scope</h5><p>scope非必填，用于说明此次提交影响的范围，比如数据层、控制层、视图层等。</p>
<p>也可用于描述改动的范围，格式为项目名/模块名，例如：node-pc/common rrd-h5/activity。如果一次commit修改多个模块，建议拆分成多次commit，以便更好追踪和维护。</p>
<p>简单易懂，成规则就好。</p>
<h5 id="subject"><a href="#subject" class="headerlink" title="subject"></a>subject</h5><p>必填，此次提交的简短描述。动词开头，用英文的话用第一人称现在时，比如add，而不用added、adds，第一个字母小写，句尾不加句号（.）</p>
<hr>
<h4 id="body（可省略）"><a href="#body（可省略）" class="headerlink" title="body（可省略）"></a>body（可省略）</h4><p>body填写详细描述，可多行，与header之间空一行，主要描述改动之前的情况及修改动机，对于小的修改不作要求，但是重大需求、更新等必须添加body来作说明。</p>
<hr>
<h4 id="footer（可省略）"><a href="#footer（可省略）" class="headerlink" title="footer（可省略）"></a>footer（可省略）</h4><p>footer只用于以下两种情况：</p>
<h5 id="break-changes"><a href="#break-changes" class="headerlink" title="break changes"></a>break changes</h5><p>break changes（不兼容变动）</p>
<p>break changes指明是否产生了破坏性修改，涉及break changes的改动必须指明该项，类似版本升级、接口参数减少、接口删除、迁移等。要写清楚变动的描述、变动的理由以及迁移的方法，比如用户密码的加密方式发生改变，如果进行了类似的修改，务必也在body中说明！</p>
<h5 id="affect-issues"><a href="#affect-issues" class="headerlink" title="affect issues"></a>affect issues</h5><p>affect issues（关闭issue）</p>
<p>当前提交修改了某个issue，整体的git message如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">feat(数据层): [简短描述]</span><br><span class="line"></span><br><span class="line">[详细描述]</span><br><span class="line"></span><br><span class="line">BREAKING CHANGE: 不兼容变动</span><br><span class="line"></span><br><span class="line">Closes 关闭issue</span><br></pre></td></tr></table></figure>

<p>affect issues 指明是否影响了某个问题。例如我们使用 jira 时，我们在 commit message 中可以填写其影响的 JIRA_ID，若要开启该功能需要先打通 jira 与 gitlab。</p>
<p>（上班时一般会用到，便于统计你的bug情况，影响你的okr和kpi）</p>
<hr>
<h3 id="idea插件"><a href="#idea插件" class="headerlink" title="idea插件"></a>idea插件</h3><p>知道了提交的规范，但是经常记不住格式怎么办？</p>
<p>这时强大的 idea 插件 Git Commit Message Helper，真香</p>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>在 settings-&gt;plugins，搜索 Git Commit Message Helper，点击 install 并重启即可</p>
<img src="/b1b30ed3/1.jpg" class>

<h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>在 git 提交页面，点击 create commit message 按钮，弹出如下窗口，编辑之后，点击 ok</p>
<img src="/b1b30ed3/2.jpg" class>

<p>在以下弹窗输入信息</p>
<img src="/b1b30ed3/3.jpg" class>

<p>提交的message如下</p>
<img src="/b1b30ed3/4.jpg" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.jianshu.com/p/6a6b9698cf06">https://www.jianshu.com/p/6a6b9698cf06</a><br><a href="https://baijiahao.baidu.com/s?id=1711325963965181539">https://baijiahao.baidu.com/s?id=1711325963965181539</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Git</category>
      </categories>
  </entry>
  <entry>
    <title>CCF学生领航计划（SPP）第十六期-《学术研究的基础经验交流》</title>
    <url>/1d27acc4.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=774114428&bvid=BV1z14y1L7Ga&cid=860935752&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<p>2022年10月12日，CCF学生领航计划已举办到第十六期。本期的主角为中山大学计算机学院2022级博士生陈蔓笙同学，主题是面向研一新生的“学术研究的基础经验交流”。</p>
<p>陈曼笙 2018年在华南农业大学获得软件工程学士学位，2021年在中山大学获得计算机科学硕士学位。现是中山大学计算机学院2022级博士研究生，导师为王昌栋副教授。已经在国际期刊和会议上以第一作者身份发表论文十一篇，包括IEEE TKDE、IEEE TCYB、IEEE TNNLS、Information Fusion、KDD、ACM MM、AAAI 和 DASFAA。担任TPAMI, TKDE, TNNLS, Neural Network等学术期刊审稿人。主要研究方向是多视图聚类。</p>
<hr>
<h3 id="学术研究之启蒙篇"><a href="#学术研究之启蒙篇" class="headerlink" title="学术研究之启蒙篇"></a>学术研究之启蒙篇</h3><p>“让我们回到那年的夏天，找回最初的自己”，陈师姐开篇灵魂三问，“什么是学术研究？为什么要做学术研究？怎么开始做学术研究？”</p>
<p>陈师姐着重回答了怎么开始做学术研究这个问题。</p>
<img src="/1d27acc4/1.jpg" class>

<p>极少人能一开始就找对方向，本科阶段能利用的资源有大学课程、大牛讲座、大创项目等等，因此要积极地尝试，根据自己的兴趣最终找到一个合适的研究方向。</p>
<p>在科研的道路上导师的作用至关重要，可以通过个人主页、代表文章、主持项目、所带学生来全面了解和选择启蒙导师。</p>
<p>拜师之后，一定要早进实验室，多混实验室！哪怕研一阶段课程和杂事很多。虽然现在通信和网络很发达，大多可以在线上沟通和工作，但线下可以更加感受实验室的科研氛围，与师兄师姐面对面发问交流，学习和干活的效率也一定更高，还能培养和团队的革命友谊。</p>
<hr>
<h3 id="学术研究之入门篇"><a href="#学术研究之入门篇" class="headerlink" title="学术研究之入门篇"></a>学术研究之入门篇</h3><p>学术的朝阳已在心头冉冉升起，此时的入门阶段就是大量刷论文！选用合适的搜索引擎（如有必要则****），如搜中文论文用中国知网，搜英文论文用Google学术；还有专门针对计算机学科方向的文献网站，如计算机学报、DBLP，还可以是大家耳熟能详的Github，大都能搜到想要看的文献（或代码）。</p>
<img src="/1d27acc4/2.jpg" class>

<p>每个学科就像一棵参天大树，综述论文就是大树的主干，可以帮助了解研究方向的大致分类，该学科的发展脉络和主要方法，未来展望及待解决问题。通过综述介绍的内容及参考文献，我们可以选读感兴趣的细分方向的论文，接着不断细分下去，直至具体的选题落地。这个过程就如同学科大树不断分支，直到属于自己的那片树叶。</p>
<p>经过综述的洗礼后，要优先搜索学科领域的顶会顶刊论文（权威保证），尽量看最近5年发表的论文（知识迭代）。注意，搜会议名可以缩写，但搜期刊名需全称。大体上，读论文分三个步骤：熟悉问题，读懂方法，了解实验。一开始读的比较痛苦很正常（特别是英文文献），要多写写阅读笔记，遇到不懂的多问多沟通，尽可能摆脱对翻译工具的依赖。所谓熟能生巧，论文看的越多，看的效率也越高，精读百篇后只需看个摘要就能判断是否能为我所用。</p>
<img src="/1d27acc4/3.jpg" class>

<hr>
<h3 id="学术研究之选题篇"><a href="#学术研究之选题篇" class="headerlink" title="学术研究之选题篇"></a>学术研究之选题篇</h3><p>选题与谈对象有相似的地方，要先了解再做决定。大部分选题来自导师课题，有的来自团队项目；也可以发挥自主性，依据团队与个人沟通协商后做出抉择。这个过程中要和导师、同门积极交流，充分剖析该课题的发展程度、研究难度及自己可能的突破。</p>
<img src="/1d27acc4/4.jpg" class>

<p>选完题之后就可以开展学术研究了，学术研究大致可以归纳为三生万物：</p>
<ol>
<li>旧问题能否挖掘新方法</li>
<li>新问题能否用旧方法解决</li>
<li>新问题中开创性地使用新方法</li>
</ol>
<p>当然，以上的创新点都建立在牢靠的先验知识上，即之前要积累大量的“旧问题旧方法”才能实现新的点突破。</p>
<img src="/1d27acc4/5.jpg" class>

<p>最后，学术研究不是闭门造车，这个过程中的交流永无止境。周期性面对面交流，分享与讨论有用见解，批判性阅读权威文章。紧跟研究大团队的前沿脚步，主动获取新鲜的第一手资料。有时间有精力甚至可以去各大平台PK辩论，摩擦出思想与智慧的火花，但是一定要避免无效争吵与垃圾输出。</p>
<p>下期CCF学生领航计划的主角仍是陈曼笙师姐，她将继续分享余下的学术研究之实验篇与写作篇，敬请期待！</p>
<hr>
<h3 id="补充资料"><a href="#补充资料" class="headerlink" title="补充资料"></a>补充资料</h3><blockquote>
<p><a href="https://dl.ccf.org.cn/video/videoDetail.html?_ack=1&amp;id=6173674233268224">https://dl.ccf.org.cn/video/videoDetail.html?_ack=1&amp;id=6173674233268224</a><br><a href="https://dl.ccf.org.cn/ppt/pptDetail.html?_ack=1&amp;id=6173675892639744">https://dl.ccf.org.cn/ppt/pptDetail.html?_ack=1&amp;id=6173675892639744</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12438">https://www.scholat.com/teamwork/showPostMessage.html?id=12438</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐讲座</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口-认知控制和执行功能常用的实验范式</title>
    <url>/cfdb438d.html</url>
    <content><![CDATA[<img src="/cfdb438d/1.jpg" class>

<span id="more"></span>

<hr>
<p>实验范式(Experimental Paradigm)：是指在各种心理过程和各个心理学分支的研究中较经典的实验任务。也就是相对固定的实验程序。</p>
<p>认知科学和实验心理学家<strong>陈霖院士</strong>指出：心理学实验范式是认知科学的三大基础之一，另两大基础是心理学变量和脑成像技术。</p>
<p>可见，实验范式是心理学，尤其是认知心理学研究难点和精华之所在！小编也因此为大家整理出认知控制和执行功能研究中一些常用的实验范式。</p>
<hr>
<h3 id="反应抑制和干扰控制任务"><a href="#反应抑制和干扰控制任务" class="headerlink" title="反应抑制和干扰控制任务"></a>反应抑制和干扰控制任务</h3><h4 id="Antisaccade（反向眼跳任务）"><a href="#Antisaccade（反向眼跳任务）" class="headerlink" title="Antisaccade（反向眼跳任务）"></a>Antisaccade（反向眼跳任务）</h4><p>实验中要求被试抑制对外围目标的注视，并注视与它相反的位置。</p>
<img src="/cfdb438d/2.webp" class>

<h4 id="Stop-signal（停止信号任务）"><a href="#Stop-signal（停止信号任务）" class="headerlink" title="Stop-signal（停止信号任务）"></a>Stop-signal（停止信号任务）</h4><p>要求被试看到屏幕上出现刺激 (如“&gt;”或“&lt;”)时，就分别按右键和左键。如果听到作为停止信号的声音“哔”，就停止按任何一个键。</p>
<img src="/cfdb438d/3.webp" class>

<h4 id="Stroop（斯特鲁普范式）"><a href="#Stroop（斯特鲁普范式）" class="headerlink" title="Stroop（斯特鲁普范式）"></a>Stroop（斯特鲁普范式）</h4><p>实验者给被试呈现用不同颜色写成的单词，要求被试尽快且正确地地说出每个词的颜色，而不理会这个词的名称及其所代表的意义。</p>
<img src="/cfdb438d/4.webp" class>

<h4 id="Flanker（侧抑制任务）"><a href="#Flanker（侧抑制任务）" class="headerlink" title="Flanker（侧抑制任务）"></a>Flanker（侧抑制任务）</h4><p>当中心靶刺激与两侧分心刺激同时出现时，两侧分心刺激带来的无关信息会对被试判断中心靶刺激造成干扰。不一致条件下，让被试按“K”键；一致条件下，让被试按“C”键；无分心刺激条件下，让被试按“C”键。</p>
<img src="/cfdb438d/5.webp" class>

<hr>
<h3 id="工作记忆和更新任务"><a href="#工作记忆和更新任务" class="headerlink" title="工作记忆和更新任务"></a>工作记忆和更新任务</h3><h4 id="N-back任务"><a href="#N-back任务" class="headerlink" title="N-back任务"></a>N-back任务</h4><p>要求被试将当前刺激与前面第N个刺激相比较，通过控制当前刺激与目标刺激间隔的刺激个数来操纵负荷。当N=1时，要求被试比较当前刺激和与它相邻的前一个刺激；当N=2时，则比较当前刺激和与它前面隔一个位置上的刺激；当N=3时，要求比较的是当前刺激和它前面隔两个位置上的刺激，依此类推获得不同程度的任务难度。</p>
<img src="/cfdb438d/6.webp" class>

<h4 id="Letter-memory（字母记忆任务又称活动记忆任务）"><a href="#Letter-memory（字母记忆任务又称活动记忆任务）" class="headerlink" title="Letter memory（字母记忆任务又称活动记忆任务）"></a>Letter memory（字母记忆任务又称活动记忆任务）</h4><p>要求被试听或看一系列未知长度的字符串，被试在系列回忆时，有两种回忆方式，一是回忆出尽可能多的字符串，二是只回忆最近呈现的几个字符串。比如，这里就要求被试按顺序大声说出最近的三个字母。如呈现字母L，R，Z，Q，被试就应该依次报告：L，LR，LRZ，RZQ。</p>
<img src="/cfdb438d/7.webp" class>

<h4 id="Backward-digit-span（倒背数字任务）"><a href="#Backward-digit-span（倒背数字任务）" class="headerlink" title="Backward digit span（倒背数字任务）"></a>Backward digit span（倒背数字任务）</h4><p>给被试呈现一系列数字“3658789”，让被试倒背出来。那么，被试报告的正确顺序应该为：“9878563”。</p>
<img src="/cfdb438d/8.webp" class>

<h4 id="Self-ordered-selection-tasks（自定顺序选择任务）"><a href="#Self-ordered-selection-tasks（自定顺序选择任务）" class="headerlink" title="Self-ordered selection tasks（自定顺序选择任务）"></a>Self-ordered selection tasks（自定顺序选择任务）</h4><p>在每个试次的一组刺激图片中选择一个新的刺激，要求被试避免选择上一个试次中所选择的图片刺激。该任务适用于研究儿童的执行功能。首先，让儿童看到一张图片上有2张小图片并任意选择其中一张。接下来，给儿童呈现一张与前面看到的完全一样但位置安排却不同的2张小图片，要求儿童指出刚才没有选过的那张图片。然后，研究者向儿童呈现新的一张图片，这一张在原有2张图片的基础上增加一张新图片，且原有的2张图片的位置与前一张图片的安排又不相同，要求儿童指出哪张图片是没有选过的，以此类推。此研究方法实际上是一种图片记忆广度的测量，以此揭示出工作记忆在整个儿童时期内存在与年龄有关的规律性的增长。</p>
<img src="/cfdb438d/9.webp" class>

<hr>
<h3 id="思维定势转变任务"><a href="#思维定势转变任务" class="headerlink" title="思维定势转变任务"></a>思维定势转变任务</h3><h4 id="Cued-switch-tasks（线索切换任务）"><a href="#Cued-switch-tasks（线索切换任务）" class="headerlink" title="Cued switch tasks（线索切换任务）"></a>Cued switch tasks（线索切换任务）</h4><p>要求被试根据提示对刺激进行分类按键反应，对刺激的颜色和形状进行判断。左键表示圆形或绿色，右键表示红色或三角形。当被试看到当前的字母与前一个试次相同时，则同样对当前刺激进行颜色判断，否则，对当前刺激进行形状判断，依此切换。</p>
<img src="/cfdb438d/10.webp" class>

<hr>
<h3 id="思维灵活性和计划测试"><a href="#思维灵活性和计划测试" class="headerlink" title="思维灵活性和计划测试"></a>思维灵活性和计划测试</h3><h4 id="Wisconsin-Card-Sorting-Test（威斯康星卡片分类测验）"><a href="#Wisconsin-Card-Sorting-Test（威斯康星卡片分类测验）" class="headerlink" title="Wisconsin Card Sorting Test（威斯康星卡片分类测验）"></a>Wisconsin Card Sorting Test（威斯康星卡片分类测验）</h4><p>要求被试根据卡片的颜色、数量或形状进行分类堆放，让对被试对分类堆放后获得的反馈发现规则。在连续进行10次正确分类后，改变分类规则。这个任务是共有4张位于屏幕上方的刺激卡片和128张反应卡片，每张卡片的大小为8cm*8cm，卡片上分别以红、绿、蓝、黄4种颜色，画有1~4个三角形、星形、十字形或圆形。其中4张刺激卡分别画有1个红三角、2个绿星、三个黄十字、4个蓝圆的图片，按上述顺序放于卡片盒上方。分类原则由计算机设定（颜色、数量或形状），需要被试不断尝试、分析、推理找到计算机设定的分类原则。</p>
<img src="/cfdb438d/11.webp" class>

<h4 id="Intra-and-extradimensional-shifting-and-reversal-learning（内-外维度转变和反向学习任务）"><a href="#Intra-and-extradimensional-shifting-and-reversal-learning（内-外维度转变和反向学习任务）" class="headerlink" title="Intra-and extradimensional shifting and reversal learning（内-外维度转变和反向学习任务）"></a>Intra-and extradimensional shifting and reversal learning（内-外维度转变和反向学习任务）</h4><p>给被试呈现有着不同形状和不同线型的图案的目标卡片，接着给被试呈现一系列测试卡片，要求被试在其中一种维度上（如，形状-内维；线型-外维）进行分类，经过6次正确分类后，再让被试在另一维度上进行相等次数的分类。考察被试是否能在两种不相容的规则之间进行灵活的转换。</p>
<img src="/cfdb438d/12.webp" class>

<h4 id="Trail-Making-Test（连线测试）"><a href="#Trail-Making-Test（连线测试）" class="headerlink" title="Trail Making Test（连线测试）"></a>Trail Making Test（连线测试）</h4><p>要求被试交替连接顺序数字和字母（如1-A-2-B-3-C）。该测试通常会有基线条件，即需要与连接连续数字或连续字母（不交替的情况）的条件（基线）相比较。</p>
<img src="/cfdb438d/13.webp" class>

<h4 id="Tower-of-London（伦敦塔）"><a href="#Tower-of-London（伦敦塔）" class="headerlink" title="Tower of London（伦敦塔）"></a>Tower of London（伦敦塔）</h4><p>伦敦塔任务是由河内塔变化而来，Shallice将河内塔任务中的圆盘换成了彩球，要求被试描述如何将彩球的最初排列转变成目标排列。</p>
<img src="/cfdb438d/14.webp" class>

<h4 id="Verbal-fluency（词语流畅性测验）"><a href="#Verbal-fluency（词语流畅性测验）" class="headerlink" title="Verbal fluency（词语流畅性测验）"></a>Verbal fluency（词语流畅性测验）</h4><p>让被试在60秒内尽可能多的回忆以F开头的单词。</p>
<img src="/cfdb438d/15.webp" class>

<hr>
<h3 id="热认知控制和决策测试"><a href="#热认知控制和决策测试" class="headerlink" title="热认知控制和决策测试"></a>热认知控制和决策测试</h3><h4 id="Delay-discounting（延迟折扣任务又称时间贴现）"><a href="#Delay-discounting（延迟折扣任务又称时间贴现）" class="headerlink" title="Delay discounting（延迟折扣任务又称时间贴现）"></a>Delay discounting（延迟折扣任务又称时间贴现）</h4><p>需要被试在较小的即时奖赏和较大的延迟奖赏之间做出选择。</p>
<img src="/cfdb438d/16.webp" class>

<h4 id="Iowa-Gambling-Task（爱荷华赌博任务）"><a href="#Iowa-Gambling-Task（爱荷华赌博任务）" class="headerlink" title="Iowa Gambling Task（爱荷华赌博任务）"></a>Iowa Gambling Task（爱荷华赌博任务）</h4><p>要求被试学会在拥有不同奖励/损失回报的A-D牌组中进行选择。纸牌A：每次给100美元的奖励，但是连续10次中会有5次35～150美元的惩罚；纸牌B：每次给的奖励是100美元，但是连续10次中有一次1250美元的惩罚；纸牌C：每次给50美元的奖励，但连续10次中有5次是25～75美元的惩罚；纸牌D：每次给50美元的奖励，但连续10次中有一次250美元的惩罚。在任务开始前，被试不知道纸牌中奖励惩罚的数量，频率等情况，只是被告知每次任意从4副纸牌中选择1张，以达到选择多次以后赢分尽可能多的目的。</p>
<img src="/cfdb438d/17.webp" class>

<hr>
<h4 id="Emotional-Stroop（情绪Stroop任务）"><a href="#Emotional-Stroop（情绪Stroop任务）" class="headerlink" title="Emotional Stroop（情绪Stroop任务）"></a>Emotional Stroop（情绪Stroop任务）</h4><p>情绪Stroop任务是经典Stroop范式的变式，用情绪词作刺激，让被试对词的颜色进行命名。</p>
<img src="/cfdb438d/18.webp" class>

<h4 id="Emotional-n-back（情绪n-back范式）"><a href="#Emotional-n-back（情绪n-back范式）" class="headerlink" title="Emotional n-back（情绪n-back范式）"></a>Emotional n-back（情绪n-back范式）</h4><p>让被试判断每个情绪图片刺激的效价，例如，下图所示为情绪2-back任务，让被试判断当前情绪图片刺激的效价是否与2-back相匹配，即让被试判断当前情绪图片的效价是否与上上个试次相同。</p>
<img src="/cfdb438d/19.webp" class>

<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/413920863">https://zhuanlan.zhihu.com/p/413920863</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫知识分享</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-触觉刺激实现“云撸猫”：超分辨率可穿戴式点触觉呈现系统</title>
    <url>/5d5d248c.html</url>
    <content><![CDATA[<p>近年来，显示器和扬声器的更新迭代给我们带来了沉浸式的视听享受，但少有能够呈现逼真触觉的设备。</p>
<p>近日，腾讯Robotics X实验室和香港城市大学合作发明了一种超分辨率可穿戴式的电触觉呈现系统。研究人员将这套设备与VR设备结合，开发了一套模拟与猫互动的系统。佩戴者不仅感受到猫毛的纹理变化，还能清楚感觉到被猫舔时，猫舌上的小倒刺所带来的轻微痒痛感。</p>
<span id="more"></span>

<hr>
<h3 id="触觉刺激器的原理"><a href="#触觉刺激器的原理" class="headerlink" title="触觉刺激器的原理"></a>触觉刺激器的原理</h3><p>现阶段，触觉刺激模拟主要分为机械刺激和电刺激两种。机械刺激通过在人体皮肤上施加局部机械力或振动从而产生稳定和连续的触觉刺激。但往往机械刺激器设备较大，难以模拟细微的触觉。而且由于驱动模式的原因，机械刺激器的响应时间也较长。相比之下，电刺激可以模拟更加细微的触觉感受，有着更快的响应速度。</p>
<h4 id="双高频交流电调制低压的触觉刺激"><a href="#双高频交流电调制低压的触觉刺激" class="headerlink" title="双高频交流电调制低压的触觉刺激"></a>双高频交流电调制低压的触觉刺激</h4><p>有别于传统的高压直流脉冲穿透高阻抗角质层的触觉刺激器，本文的电触觉刺激器是通过高频交流电来穿透人体的皮肤，刺激神经。通过提高交流电的频率，可以产生密度更高、渗透皮肤更深的电流，从而激活更多的神经，进而呈现更强的触觉刺激。</p>
<img src="/5d5d248c/1.jpg" class>

<h4 id="通过调整振幅模拟不同质感"><a href="#通过调整振幅模拟不同质感" class="headerlink" title="通过调整振幅模拟不同质感"></a>通过调整振幅模拟不同质感</h4><p>模拟触觉的粗糙程度与刺激的强度和振动频率有关。通过实验，研究人员发现，低频和高电压刺激能够模拟岩石和砂纸等的粗糙纹理，而高频和低电压刺激可以模拟丝绸和玻璃等的光滑纹理。</p>
<img src="/5d5d248c/2.png" class>

<h4 id="控制电流来实现超分率触觉刺激"><a href="#控制电流来实现超分率触觉刺激" class="headerlink" title="控制电流来实现超分率触觉刺激"></a>控制电流来实现超分率触觉刺激</h4><p>设备在指尖位置设置了一个有着25个电极的电极阵列，利用电极阵列的高可重构性，研究人员采用创新性的转向超分辨率策略，即通过控制目标及其周围位置的电极产生的电流，从而实现在两个电极之间的位置产生刺激，实现设备的超分辨率。</p>
<img src="/5d5d248c/3.png" class>

<hr>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><h4 id="模拟现实中的各类场景"><a href="#模拟现实中的各类场景" class="headerlink" title="模拟现实中的各类场景"></a>模拟现实中的各类场景</h4><p>这套设备所带来的高仿真触觉刺激使其可以与VR设备配合来模拟各种场景，例如模拟与猫互动，购物时抚摸不同面料的服饰等等。实验中，佩戴者可以感觉到被猫的舌头舔时，猫舌头上倒刺所带来的轻微痒痛感，以及抚摸猫毛时，随抚摸方向和速度变化带来的的粗糙感变化。</p>
<img src="/5d5d248c/4.jpg" class>

<h4 id="方便视障人士阅读的触觉阅读"><a href="#方便视障人士阅读的触觉阅读" class="headerlink" title="方便视障人士阅读的触觉阅读"></a>方便视障人士阅读的触觉阅读</h4><p>同时，研究人员也通过这套设备开发了一套方便视障人士阅读的盲文呈现系统。系统按照字母或数字的书写顺序呈现笔画，形成连续的触觉刺激来呈现不同的字母或者数字。实验中受试者的分辨准确率能够超过87%，但像”I”和”1”、“S”和“8”以及“O”和“0”等笔画和结构类似的字符依然容易混淆。</p>
<img src="/5d5d248c/5.jpg" class>

<h4 id="隔着手套也能感受到触觉细节"><a href="#隔着手套也能感受到触觉细节" class="headerlink" title="隔着手套也能感受到触觉细节"></a>隔着手套也能感受到触觉细节</h4><p>研究人员还将电触觉呈现系统与灵敏的触觉传感器分别安装在安全手套的内外侧，然后让受试者佩戴安全手套，仅通过触摸确定微型钢圈（半径1mm，厚度0.44m）的位置。但即便隔着厚厚的手套，受试者也能准确找出微型钢圈的位置。</p>
<img src="/5d5d248c/6.jpg" class>

<p>“云撸猫”、4D电影、感受网购物品的材质，触觉的加入颠覆了传统的视听娱乐模式，极大地提高了用户的沉浸感。盲文阅读也能够为视障人士带来更多生活中的便捷。在未来，这套设备还有可能应用于潜水、消防救援、航空航天等需要身着特定厚重服装的应用场景。甚至配合上5G技术以及机械臂，实现远程手术等高精度的作业。这套设备所带来的高仿真，超分辨率的模拟触觉，为这套设备的应用提供了无限可能。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.qbitai.com/2022/10/38347.html">https://www.qbitai.com/2022/10/38347.html</a><br><a href="https://www.science.org/doi/10.1126/sciadv.abp8738">https://www.science.org/doi/10.1126/sciadv.abp8738</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12437">https://www.scholat.com/teamwork/showPostMessage.html?id=12437</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-SOTA微表情数据集：4DME即将发布</title>
    <url>/20f9385.html</url>
    <content><![CDATA[<h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>微表情（ME）是一种不受思维控制的面部表情，具有持续时间短暂、变化顿度微弱、动作区域较少等明显区别于宏表情的特点。当人们出于某些原因试图隐藏自己的真实情感时，可能会出现这种表情。微表情是揭示人们真实情感的重要线索，但由于其非常短暂和微妙，普通人很难或不可能用肉眼捕捉到。</p>
<p>应用潜力：微表情能够真实反映人们内心对外部世界的情感，可以应用在如刑侦、审讯、谈判、心理咨询（面试)、安全（司法)、医疗、教育等领域，有很大的发展潜力。</p>
<span id="more"></span>

<hr>
<h3 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h3><p>随着计算机模式识别技术的发展微表情相关研究取得了很多成果，但作为研究基础的微表情数据库由于微表情挑提困难、采集过程复杂、人工编码费时耗力和图像质量评价标准缺失等原因导致数据库样本数量不足，质量参差不齐，越来越无法满足微表情研究工作。</p>
<img src="/20f9385/1.jpg" class>
<p>经典微表情数据集的发展历程</p>
<p>目前的运动估计数据集不足，且大多只包含单一形式的2D彩色video。虽然针对普通面部表情的四维数据的研究已经很活跃，但目前在微表情研究中还没有四维数据。</p>
<p>为了丰富微表情的数据集，以支持微表情研究的发展，芬兰奥卢大学的李晓白博士及其团队制作了4D的微表情数据集——4DME。该数据集含有56个样本，其中男女比例4:6，且跨人种，含亚裔与欧美裔。数据集提供：</p>
<ol>
<li>286个长片段（平均147.6帧）</li>
<li>267个微表情短片段和123个宏表情断片段</li>
<li>22个AU标签和5种情绪标签。</li>
</ol>
<p>微表情数据集的信息</p>
<img src="/20f9385/2.jpg" class>

<p>诱发情绪的电影片段</p>
<img src="/20f9385/3.png" class>

<p>相比其它数据集，4DME有着更丰富的模态，包括DI4D视频、正面灰度视频、kinect彩色video和kinect深度视频。</p>
<img src="/20f9385/4.png" class>

<p>表中是MEs的情绪和AU统计(各模态)。P、N、S、R和OT分别代表正、负、惊讶、压抑和其他。他们代表了情感。</p>
<img src="/20f9385/5.png" class>

<hr>
<h3 id="4DME评估"><a href="#4DME评估" class="headerlink" title="4DME评估"></a>4DME评估</h3><p>为了比较4DME数据集中不同模态对ME识别任务的有效性，作者进行了单独的实验来评估2D正面灰度视频和重建的4D视频。</p>
<p>针对2D视频数据，作者采用三种方法进行检测分别为LBP-TOP、Res3D和Res3D+SCA。</p>
<p>在AU检测中三种测试方法的准确率和f1值都是Res3D+SCA &gt; Res3D &gt; LBP-TOP。使用Res3D+SCA得到的最佳平均准确率为82.48%，最佳平均f1值为0.6779。研究结果与先前的研究结果一致。</p>
<p>2D数据的AU检测结果</p>
<img src="/20f9385/6.jpg" class>

<p>对于情绪识别两种基于深度学习的方法(Res3D和Res3D+SCA)都优于传统的LBP-TOP方法。Res3D+SCA取得了最好的性能，在5个情感类别上的平均F1-score为0.6481，平均准确率为82.54%。在五种情绪中，如果我们同时考虑准确性和f1 -分数，似乎“惊讶”类别获得了最好的性能，而“压抑”和“其他”类别的评估由于样本量较小，则依赖于指标。</p>
<p>2D数据的情绪识别结果</p>
<img src="/20f9385/7.jpg" class>

<p>针对4D视频数据，作者采用一种基于4D的协同跨域动态图像网络(CCDN)[21]对普通面部表情图像进行识别，并与3种单视角和多视角融合的识别结果进行了比较。</p>
<p>在使用三视图即多视图协同识别AUs时，取得了0.7990的平均F1-score和86.55%的平均准确率，明显高于三个单视图中的任何一个。实验结果与我们的预期相吻合，当显示更多的面部区域(无遮挡)时，即多视角&gt;额部&gt;左、右部&gt;时，AU检测性能会更好。4D数据承载更多信息，提高系统性能。</p>
<p>4D数据的AU检测结果</p>
<img src="/20f9385/8.jpg" class>

<p>对于情绪识别中，3种个体视图中，前视图表现最好，左视图次之，右视图表现最低。多视角优于3个个体视角，取得了0.7908的平均f1值和85.59%的平均准确率，再次证明了4D数据在ME识别任务中的优势。通过融合多视角来使用4D数据的优势在所有五种情感类别中都是一致的。</p>
<p>4D数据的情绪识别结果</p>
<img src="/20f9385/9.jpg" class>

<p>目前4DME数据集的公布正在着手进行中，预计十月份会发布第一版数据集。</p>
<hr>
<h3 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h3><blockquote>
<p><a href="https://doi.org/10.1109/TAFFC.2022.3182342">https://doi.org/10.1109/TAFFC.2022.3182342</a><br><a href="https://www.bilibili.com/video/BV1P8411x71z">https://www.bilibili.com/video/BV1P8411x71z</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12439">https://www.scholat.com/teamwork/showPostMessage.html?id=12439</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-一种Apex帧查找算法-《CapsuleNet for Micro Expression Recognition》</title>
    <url>/19376813.html</url>
    <content><![CDATA[<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2019-CapsuleNet-for-Micro-Expression-Recognition.pdf" data-height="500px"></div>

<span id="more"></span>

<hr>
<h3 id="微表情序列中Apex帧介绍"><a href="#微表情序列中Apex帧介绍" class="headerlink" title="微表情序列中Apex帧介绍"></a>微表情序列中Apex帧介绍</h3><p>一个微表情视频序列以Onset帧开始，以Offset帧结束，通常保持中性的表情；其中Apex帧是在序列中变化强度最大的那一帧。</p>
<p>一个微表情序列的Apex帧，在微表情分类中能提供丰富的特征，可以帮助接下来的光流特征提取、迁移学习等。</p>
<hr>
<h3 id="一种查找Apex帧算法"><a href="#一种查找Apex帧算法" class="headerlink" title="一种查找Apex帧算法"></a>一种查找Apex帧算法</h3><p>下面是一种在微表情序列中提取Apex帧的算法，算法流程如下：</p>
<ol>
<li>根据面部68个特征点，定位10个微表情肌肉移动发生频繁的区域</li>
<li>定义变化强度M，用于衡量序列中每一帧变化大小</li>
<li>遍历序列帧，计算每一帧变化强度Mi，取值最大的那帧作为Apex帧</li>
</ol>
<h4 id="Step-1-定义10个面部区域块"><a href="#Step-1-定义10个面部区域块" class="headerlink" title="Step 1 定义10个面部区域块"></a>Step 1 定义10个面部区域块</h4><p>首先通过一个开源面部工具(ageitgey/face_recognition)[<a href="https://github.com/ageitgey/face_recognition]%E5%AE%9A%E4%BD%8D%E6%AF%8F%E4%B8%80%E5%B8%A768%E4%B8%AA%E9%9D%A2%E9%83%A8%E7%89%B9%E5%BE%81%E7%82%B9%EF%BC%8C%E6%8E%A5%E7%9D%80%E5%9F%BA%E4%BA%8E%E8%BF%99%E4%BA%9B%E7%89%B9%E5%BE%81%E7%82%B9%E5%AE%9A%E4%B9%8910%E4%B8%AA%E9%9D%A2%E9%83%A8%E5%8C%BA%E5%9F%9F%E5%9D%97%E3%80%82%E5%85%B6%E6%95%88%E6%9E%9C%E5%A6%82%E5%9B%BE1%EF%BC%9A">https://github.com/ageitgey/face_recognition]定位每一帧68个面部特征点，接着基于这些特征点定义10个面部区域块。其效果如图1：</a></p>
<img src="/19376813/1.webp" class>

<p>这10个区域分别选取left_lip、right_lip、chin、left_nose、right_nose、left_eye、right_eye、left_eyebrow、right_eyebrow处的特征点作为基准点，形成正方形块。其中，正方形的边长是上嘴唇距离的一半，作者称边长的确定是启发式地（heuristically）。</p>
<p>下面以左嘴唇正方形块区域举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> face_recognition</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取当前frame的人脸特征点，lmks是一个字典，记录了68个特征点坐标</span></span><br><span class="line">lmks = face_recognition.face_landmarks(frame)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正方形宽度的确定</span></span><br><span class="line">cell_width = <span class="built_in">int</span>((lmks[<span class="string">&#x27;top_lip&#x27;</span>][<span class="number">6</span>][<span class="number">0</span>] - lmks[<span class="string">&#x27;top_lip&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]) / <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 最左嘴唇点的坐标</span></span><br><span class="line">leftmost_lip_point=lmks[<span class="string">&#x27;top_lip&#x27;</span>][<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 确定正方形块左上角和右下角坐标，据此确定一个块</span></span><br><span class="line">left_lip_rect=</span><br><span class="line"><span class="built_in">tuple</span>(np.array(leftmost_lip_point) - <span class="built_in">int</span>(cell_width / <span class="number">2</span>)),</span><br><span class="line"><span class="built_in">tuple</span>(np.array(leftmost_lip_point) + <span class="built_in">int</span>(cell_width / <span class="number">2</span>))</span><br></pre></td></tr></table></figure>

<h4 id="Step-2-定义变化强度"><a href="#Step-2-定义变化强度" class="headerlink" title="Step 2 定义变化强度"></a>Step 2 定义变化强度</h4><p>首先分别计算当前帧与Onset帧、Offset帧在这10个区域块的绝对像素差，为了减少环境噪音影响，将差值的除以当前帧与偏差为З的连续帧的绝对像素差。将规化后的像素差求和，表示当前帧的变化强度值，即Mi。（З 表示epsilon,一个变量，并非数字3）</p>
<img src="/19376813/2.webp" class>

<p>下面根据计算脸部某个区域的变化强度函数，理解上述公式。实际上还需要对10个面部区域块分别计算，取其均值作为当前帧的变化强度值Mi。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cell_difference</span>(<span class="params">cell_t: np.ndarray, cell_onset: np.ndarray, cell_offset: np.ndarray, cell_epsilon: <span class="built_in">int</span></span>):</span> </span><br><span class="line">    <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">    计算某块区域的变化强度 </span></span><br><span class="line"><span class="string">    :param cell_t:当前面部区域块 </span></span><br><span class="line"><span class="string">    :param cell_onset:起始帧 </span></span><br><span class="line"><span class="string">    :param cell_offset:末尾帧 </span></span><br><span class="line"><span class="string">    :param cell_epsilon:偏差为epsilon的帧 </span></span><br><span class="line"><span class="string">    :return: 一个float </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span> </span><br><span class="line">    numerator = (np.<span class="built_in">abs</span>(cell_t - cell_onset) + <span class="number">1.0</span>) </span><br><span class="line">    <span class="comment"># 分子分母同时加1的一个原因是防止出现&#x27;inf&#x27;数据 </span></span><br><span class="line">    denominator = (np.<span class="built_in">abs</span>(cell_t - cell_epsilon) + <span class="number">1.0</span>) </span><br><span class="line">    difference = numerator / denominator </span><br><span class="line"></span><br><span class="line">    numerator = (np.<span class="built_in">abs</span>(cell_t - cell_offset) + <span class="number">1.0</span>) </span><br><span class="line">    difference1 = numerator / denominator </span><br><span class="line"> </span><br><span class="line">    difference = difference + difference1 </span><br><span class="line">    <span class="keyword">return</span> difference.mean() </span><br></pre></td></tr></table></figure>

<h4 id="Step-3-遍历查找"><a href="#Step-3-遍历查找" class="headerlink" title="Step 3 遍历查找"></a>Step 3 遍历查找</h4><p>遍历计算对应帧的的变化强度M,取值最大的那帧作为Apex帧。</p>
<p>浅蓝色曲线描述了序列中每帧的变化强度M值的变化。</p>
<img src="/19376813/3.webp" class>

<hr>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>CASMEⅡ 微表情数据集已经对其中的微表情序列Apex帧进行了人工标注，在此数据集上使用上述算法进行自动查找，观察实验结果。</p>
<ol>
<li>准备CASMEⅡ 数据集</li>
<li>运行代码得到预测的Apex 帧序号数组pred_apex_id_list，图3 显示了某个微表情序列的Apex帧标注过程</li>
<li>通过人工标注的Apex帧序号数组groundtruth_apex_id_list 和自动预测的Apex帧序号数组 pred_apex_id_list，得到绝对差值数组absolute_difference_list, 观察其平均值（也即两组数据的<strong>平均绝对误差，MAE</strong>）、无偏标准差(两组数组的<strong>均方根误差, RMSE</strong>)、中位数。</li>
</ol>
<img src="/19376813/4.png" class>

<p>其平均值7.91, 中位数4.0，无偏标准差10.0, 反应了其集中趋势和波动大小。</p>
<img src="/19376813/5.png" class>

<hr>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] N. V. Quang, J. Chun and T. Tokuyama, “CapsuleNet for Micro-Expression Recognition,” 2019 14th IEEE International Conference on Automatic Face &amp; Gesture Recognition (FG 2019), 2019, pp. 1-7, doi: 10.1109/FG.2019.8756544.</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/425412701">https://zhuanlan.zhihu.com/p/425412701</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-深度图像修复的回顾和改进：使用生成对抗网络基于Patch的图像修复</title>
    <url>/607c14e8.html</url>
    <content><![CDATA[<h3 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h3><p>相比于之前，在图像修复网络结构中增加了残差块，并对每个局部区域都进行了真假的判别。</p>
<p>今天，我想给我们到目前为止讨论过的深度图像修复做一个回顾。另外，我想再复习一篇图像修复的论文，巩固深度图像修复的知识。</p>
<span id="more"></span>

<hr>
<h3 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h3><p><strong>Context Encoder (CE)是第一个基于GAN的修复算法。</strong>它强调了在修复任务中理解整个图像的上下文的重要性，并使用(channel-wise)全连接层来实现这一功能。文章链接：(用生成模型来做图像恢复的介绍和回顾：上下文编码器)[<a href="https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg==&amp;chksm=c06a62fef71debe8414ef6d0a5653ec546f1953e3905a7fbdfcf7d1a3bc5720828673ded9dff&amp;idx=1&amp;mid=2247494307&amp;scene=21&amp;sn=6259effaf115c4255be3827beb890fa1#wechat_redirect]">https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg%3D%3D&amp;chksm=c06a62fef71debe8414ef6d0a5653ec546f1953e3905a7fbdfcf7d1a3bc5720828673ded9dff&amp;idx=1&amp;mid=2247494307&amp;scene=21&amp;sn=6259effaf115c4255be3827beb890fa1#wechat_redirect]</a></p>
<p>**Multi-scale Neural Patch Synthesis (MNPS)**可以看作是CE的改进版本。它由两个网络组成，即内容网络和纹理网络。内容网络是CE，纹理网络是预先训练好的用于分类任务的VGG-19。使用纹理网络的想法来自于最近成功的神经风格迁移。简单地说，对于高级视觉任务(如对象分类)，预训练网络的神经响应包含有关图像模式的信息。通过鼓励在缺失区域内外产生相似的神经响应，我们可以进一步增强生成像素的纹理细节，因此完成的图像将更真实。文章链接：(使用多尺度patch合成来做高分辨率的图像复原)[<a href="https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg==&amp;chksm=c06a62e3f71debf50f82afafc8e5739568ce4f11b327c6c09ffdb5c05658c032e02b9b00b371&amp;idx=2&amp;mid=2247494334&amp;scene=21&amp;sn=7954763a1e6b53fe384eb17d97a0ecb8#wechat_redirect]">https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg%3D%3D&amp;chksm=c06a62e3f71debf50f82afafc8e5739568ce4f11b327c6c09ffdb5c05658c032e02b9b00b371&amp;idx=2&amp;mid=2247494334&amp;scene=21&amp;sn=7954763a1e6b53fe384eb17d97a0ecb8#wechat_redirect]</a></p>
<p>**Globally and Locally Consistent Image Completion (GLCIC)**是深度图像修复任务中的一个里程碑。作者采用完全卷积网络(FCN)与扩张卷积(DilatedConv)作为他们提出的模型的框架。FCN允许不同的输入大小和带膨胀的conv来替换通道全连接层，用于理解整个图像上下文。在此基础上，采用两种鉴别器对两种尺度下的完整图像和真实图像进行区分。一个全局判别器着眼于整个图像，而一个局部判别器着眼于局部填充后的图像patch。文章链接：(图像修复中的一个里程碑：全局和局部一致性的图像补全)[<a href="https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg==&amp;chksm=c06a6283f71deb954cee27dd70d6342f783d5712c3ba7668ff28dd9e417af40d33bfcbbf0099&amp;idx=1&amp;mid=2247494366&amp;scene=21&amp;sn=19cb9e7f28898655c0ee604db5112fd3#wechat_redirect]">https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg%3D%3D&amp;chksm=c06a6283f71deb954cee27dd70d6342f783d5712c3ba7668ff28dd9e417af40d33bfcbbf0099&amp;idx=1&amp;mid=2247494366&amp;scene=21&amp;sn=19cb9e7f28898655c0ee604db5112fd3#wechat_redirect]</a></p>
<p>今天，我们将回顾这篇论文，<strong>《Patch-Based Image Inpainting with Generative Adversarial Networks》</strong>。这可以看作是GLCIC的一种变体，因此我们可以对这种典型的网络结构做了一些修改。</p>
<hr>
<h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>本文作者希望利用残差链接和PatchGAN鉴别器的优势，进一步提高其修复效果。图像识别的深度残差学习(Deep Residual Learning for Image Recognition， ResNet)在深度学习方面取得了显著的成就。</p>
<p>通过使用残差块(残差连接)，我们能够训练非常深的网络，许多论文表明残差学习对于获得更好的结果是有用的。</p>
<p>PatchGAN在图像对图像的转换方面也取得了巨大的成功。与典型GAN中的鉴别器相比，PatchGAN鉴别器(参见下面的图1)输出的是一个矩阵(2d-array)，而不是单个值。简单来说，典型GAN鉴别器的输出是0 ~ 1的单个值。这意味着鉴别器会看整个图像，判断这幅图像是真的还是假的。如果图像是真实的，它应该等于1。如果图像是假的(即生成的图像)，它应该给出0。该式子关注的是整个图像，因此可能忽略图像的局部纹理细节。另一方面，PatchGAN判别器的输出是一个矩阵，这个矩阵中的每个元素都在0到1之间。注意，每个元素代表输入图像中的一个局部区域，如图1所示。因此，这一次，判别器需要查看多个局部图像patch，并判断每个patch的真伪。通过这样做，生成的图像的局部纹理细节可以得到增强。这就是为什么PatchGAN被广泛应用于图像生成任务。</p>
<img src="/607c14e8/1.png" class>

<p>图1，PatchGAN 判别器，输出是一个矩阵，矩阵中的每个元素表示输入图像的一个局部区域，如果局部区域是真实的，我们会得到1，否则是0</p>
<hr>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>图像修复可以看作是一种图像生成任务。我们希望填充图像中缺失的区域(即生成缺失的像素)，这样图像就完整了，看起来更真实。</p>
<p>为了生成逼真的图像，GAN通常用于不同的图像生成任务，包括图像修复。典型的GAN鉴别器只通过一个单一的值[0, 1]来判断输入是否为实数。本文将这种GAN鉴别器称为全局GAN (G-GAN)。</p>
<p>另一方面，如前一节所述，PatchGAN会在输入中查看多个局部区域，并独立决定每个局部区域的真实性。研究人员已经表明，使用PatchGAN可以通过关注更多的局部纹理细节，进一步提高生成图像的视觉质量。</p>
<hr>
<h3 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h3><p>生成器采用了具有膨胀卷积的残差块(<strong>膨胀残差块</strong>)。(作者希望通过使用残差学习来提高修复效果)</p>
<p>**Mixture of PatchGAN and G-GAN discriminators (PGGAN)**被提出，以鼓励输出完成的图像应该具有全局和局部真实的外观。(与GLCIC的意图相同，GLCIC使用两个鉴别器，一个全局和一个局部)</p>
<hr>
<h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><p><strong>PatchGAN和G-GAN discriminator (PGGAN)的组合</strong>其中早期的卷积层是共享的。实验结果表明，该方法可以进一步增强生成像素的局部纹理细节。</p>
<p>生成网络中使用了<strong>膨胀和插值卷积</strong>。通过使用<strong>膨胀残差块</strong>，改善了修补效果。</p>
<hr>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><img src="/607c14e8/2.png" class>
<p>图2，提出的ResNet结构的生成网络和PGGAN判别器</p>
<img src="/607c14e8/3.png" class>
<p>图3，提出的GLCIC的结构</p>
<p>图2和3分别给出本文和GLCIC所提出的网络结构。很明显，他们是相似的。两个主要区别是 i) 在生成器中使用了膨胀残差块，ii) 修改了GLCIC中的全局和局部判别器。</p>
<p>在GLCIC中，全局判别器以整个图像作为输入，而局部识别器以填充区域周围的一个子图像作为输入。将两个判别器的输出连接起来，然后返回一个值来显示输入是真还是假(<strong>一个对抗损失</strong>)。从这个角度来看，局部判别器会聚焦在局部填充的图像patch上，从而增强填充的图像patch的局部纹理细节。一个主要缺点是<strong>局部判别器的输入依赖于缺失区域</strong>，作者在训练期间假设一个单一的矩形缺失区域。</p>
<p>对于PGGAN判别器，我们几乎没有<strong>早期共享卷积层</strong>，如图2所示。然后，我们有<strong>两个分支</strong>，一个给出一个输出值(G-GAN)，一个给出一个输出矩阵(PatchGAN)。请注意1×256是16×16矩阵的reshape形式。如上所述，这也是一种让判别器在区分完整图像和真实图像时同时关注全局(整幅图像)和局部(局部图像patch)信息的方法。请注意，在这种情况下，我们有两个对抗损失，因为我们有两个分支。</p>
<hr>
<h4 id="膨胀残差块"><a href="#膨胀残差块" class="headerlink" title="膨胀残差块"></a>膨胀残差块</h4><p>在之前的文章中，我已经介绍过CNN的膨胀卷积。简单回忆一下，<strong>膨胀卷积通过跳过连续的空间位置增加感受野，而不添加额外的参数。</strong></p>
<img src="/607c14e8/4.png" class>
<p>图4，残差块类型，从上到下依次为：标准残差块、扩张卷积在前的残差块、扩张卷积在后的剩余块<br>简单地说，残差块可以写成Y = X + F(X)，其中Y是输出，X是输入，F是几个层次的序列。在图4的基本残差块中，F为conv - norm - relu - conv。这意味着我们将X输入一个卷积层，然后是一个归一化层，一个ReLU激活层，最后是另一个卷积层得到F(X)。一个要点是，输入X是直接添加到输出Y上的，这就是我们称之为跳跃连接的原因。由于在这条路径上没有任何可训练的参数，我们可以确保在反向传播过程中必须有足够的梯度传递到早期的层。因此，我们可以训练一个非常深度的网络而不会遇到梯度消失的问题。</p>
<hr>
<h4 id="为什么要用残差块？"><a href="#为什么要用残差块？" class="headerlink" title="为什么要用残差块？"></a>为什么要用残差块？</h4><p>你可能想知道使用残差块的好处。你们中的一些人可能已经知道答案了。以下是我的看法。让我们比较一下Y = X + F(X)和Y = F(X)，对于Y = X + F(X)，我们学习的实际上是F(X) = Y - X, Y和X的差值。这就是所谓的残差学习，X可以作为残差学习的参考。另一方面，对于Y = F(X)，我们直接学习在没有参考的情况下将输入X映射到输出Y。所以，人们认为残差学习是比较容易的。更重要的是，很多论文已经证明了残差学习可以带来更好的效果！</p>
<p>由于膨胀卷积有助于增加感受野，这对修复任务很重要，作者用膨胀卷积层替换了两个标准卷积层中的一个，如图4所示。膨胀残差块有两种类型，i) 以膨胀卷积在前，ii) 膨胀卷积在后。在本文中，根据膨胀残差块的数量，膨胀率从1开始每次增加2倍，例如，如果有4膨胀残差块，膨胀率为1,2,4,8。</p>
<hr>
<h4 id="插值卷积"><a href="#插值卷积" class="headerlink" title="插值卷积"></a>插值卷积</h4><p>为了解决标准反卷积(即转置卷积)造成的伪影，作者在这项工作中采用了插值卷积。对于插值卷积，首先使用典型的插值方法，如双线性和双三次插值，将输入调整到所需的大小。然后，应用标准卷积。下面的图5显示了转置卷积和插值卷积的区别。</p>
<img src="/607c14e8/5.png" class>
<p>图5，使用转置卷积核插值卷积的可视化比较</p>
<p>在我看来，这两种类型的卷积具有相似的性能。有时转置卷积更好，有时插值插卷积更好。</p>
<hr>
<h4 id="判别网络"><a href="#判别网络" class="headerlink" title="判别网络"></a>判别网络</h4><p>我们讨论了本文使用的PGGAN鉴别器。回想一下，这里的鉴别器有两个分支，一个分支给出一个值，就像global-GAN (G-GAN)一样，另一个分支给出256个值，其中每个值表示输入中局部区域的真实性。</p>
<p><strong>关注输入图像中多个局部区域的真实性，有助于改进完成图像的局部纹理细节。</strong></p>
<hr>
<h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p>实际上，本文中使用的损失函数(即目标函数)与我们之前讨论过的论文或多或少是相同的。</p>
<p><strong>重构损失</strong>：这种损失是为了保证逐像素的重构精度。我们通常使用L1或L2(欧几里得)距离来计算这个损失。本文采用<strong>L1损失</strong>作为它们的重构损耗。</p>
<img src="/607c14e8/6.png" class>

<p>N为训练批中的图像数量。W、H、C分别是训练图像的宽度、高度和通道。x和y分别为ground truth和模型给出的完整图像。</p>
<p><strong>对抗损失</strong>：我想你们大多数人现在都熟悉这种典型的对抗损失。</p>
<img src="/607c14e8/7.png" class>

<p>x是ground truth，所以我们希望D(x)返回1，否则返回0。注意，D只是鉴别器的函数形式。</p>
<p><strong>联合损失</strong>：</p>
<img src="/607c14e8/8.png" class>

<p>式3为其联合损失函数。Lambda 1, 2, 3用来平衡每个损失的重要性。g_adv表示全局分支给出的输出，而p_adv表示PatchGAN分支给出的输出。需要注意的是，在他们的实验中，λ 1,2,3分别设置为0.995,0.0025和0.0025。</p>
<hr>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>在他们的实验中使用了三个数据集。<strong>i) Paris StreetView</strong>包含14900张训练图像和100张测试图像。<strong>ii) 谷歌StreetView</strong>拥有62058张高分辨率图像，分为10个部分。第一部分和第10部分用于测试，第9部分用于验证，其余部分用于训练。总共有46200张训练图像。<strong>iii) Places</strong>包含超过800万的训练图像。该数据集仅用于测试，以显示其通用性。</p>
<p>为了比较典型残差块和膨胀残差块的性能，训练了<strong>PGGAN-Res</strong>和<strong>PGGAN-DRes</strong>两个模型。对于PGGAN-Res，使用基本残差块和3个子采样块。这意味着输入被向下采样了2倍3次。对于PGGAN-DRes，使用膨胀残余块和2个子采样块。这意味着输入被下采样2倍。</p>
<img src="/607c14e8/9.png" class>
<p>图6，用不同的判别器训练同一生成器网络的结果。</p>
<p>图6显示了用不同判别器训练同一生成器网络的修复结果。从图6的最后一列来看，如果只使用G-GAN鉴别器，则会观察到窗口的局部纹理细节很差。与G-GAN相比，PatchGAN提供了更好的窗口局部纹理细节，但窗口的角落看起来与全局结构不一致。总之，PGGAN可以提供最好的视觉效果。</p>
<img src="/607c14e8/10.png" class>
<p>表1，巴黎街景256x256图像的定量比较</p>
<img src="/607c14e8/11.png" class>
<p>表2，来自巴黎街景数据集中512x512图像的定量比较</p>
<p>表1和2给出了在256×256和512×512两种分辨率下，不同方法在Paris StreetView数据集上的定量比较。需要注意的是，CE是Context Encoder， NPS是Multi-scale Neural Patch Synthesis (MNPS) ， GLGAN是global and local Consistent Image Completion (GLCIC)。我们已经在前面的文章中讨论了所有这些方法。</p>
<p>从表1和表2可以明显看出，PGGAN对所有这些措施都有改进。但是，请记住，视觉质量比这些客观的评价指标更重要。</p>
<img src="/607c14e8/12.png" class>
<p>图7，用不同的方法对完整图像进行感知比较。</p>
<p>作者对这些方法进行了感知评估，如图7所示。12名投票者被要求对原始图像的自然程度和各种方法的修复结果进行评分。每个选民从巴黎街景数据集中随机分配了500张图像。注意CE是在128×128图像上训练的，因此它在256×256测试图像上的性能很差。其他方法在这种感知评价上也有类似的表现。</p>
<img src="/607c14e8/13.png" class>
<p>图8，256x256巴黎街景数据集的量化比较</p>
<img src="/607c14e8/14.png" class>
<p>图9，512x512巴黎街景数据集的量化比较</p>
<p>图8和图9分别显示了大小为256×256和512×512的图像的修复结果。我建议读者放大以更好地查看结果。在我看来，PGGAN-DRes和PGGAN-Res通常会给出更好的局部纹理细节，例如，图8中的第4行和图9中的第3行。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>首先，将残差学习的概念以膨胀残差块的形式嵌入生成网络。从他们的实验结果来看，残差学习有助于提高修复性能。</p>
<p>其次，将PatchGAN判别的概念与传统的GAN判别器 (G-GAN)相结合，以鼓励更好的局部纹理细节和全局结构一致性。</p>
<hr>
<h3 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h3><p>实际上，本文的大部分内容与GLCIC相似。在网络结构中嵌入了两个新的概念，即残差块和PatchGAN判别器，进一步增强了修复结果。</p>
<p>希望你能认识到这种典型的图像修复网络架构。后来的图像修复的论文中提出的网络或多或少都是一样的。</p>
<p>你还应该注意到重建损失和对抗损失是图像修复任务的两个基本损失。本文提出的修复论文的方法必须包括L1损失和对抗性损失。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://towardsdatascience.com/revision-for-deep-image-inpainting-and-review-patch-based-image-inpainting-with-generative-4197d29c5468">https://towardsdatascience.com/revision-for-deep-image-inpainting-and-review-patch-based-image-inpainting-with-generative-4197d29c5468</a><br><a href="https://blog.csdn.net/u011984148/article/details/115191575">https://blog.csdn.net/u011984148/article/details/115191575</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-跟读者建立联系【研究的艺术·一】</title>
    <url>/7f719eb.html</url>
    <content><![CDATA[<img src="/7f719eb/1.png" class>

<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=257648884&bvid=BV1hY411T7vy&cid=752569504&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="两件事情"><a href="#两件事情" class="headerlink" title="两件事情"></a>两件事情</h3><ol>
<li>语文或英语成绩好不代表你的论文写作就很好<ul>
<li>如果是30岁左右在国内接受教育的话（跟李沐老师一样背景的话）很有可能你在国内教育的时候，没有接受过系统的专业论文的写作</li>
<li>如果是20岁的话，可能在语文和英语课里面写的作文跟论文所要求的那一种格式不一样</li>
</ul>
</li>
<li>研究做了一些年，甚至发表过一些顶级的会议和期刊的情况下，很有可能论文写作没有你想象的那么好（可能</li>
<li>能够符合发表的标准，写东西比较快，要写得很好、很优美、很清晰，是需要大量的练习的，这还有很多的提升空间的</li>
</ol>
<hr>
<h3 id="好的写作能带来的好处"><a href="#好的写作能带来的好处" class="headerlink" title="好的写作能带来的好处"></a>好的写作能带来的好处</h3><ol>
<li>让你的思考更加的深入，更加的有条理</li>
<li>让更多的人愿意读你的论文，之后论文的影响力</li>
</ol>
<p>参考书名：《The Craft of Research, Fourth Edition (Chicago Guides to Writing, Editing, and Publishing) 》</p>
<ul>
<li>这本书不仅对论文写作有用，对商业的写作也是有用的（总结报告、项目计划等）</li>
<li>如果是英语写作的话，强烈建议读它的英语版本的</li>
<li>当然中文版也是可以去读的（大部分东西是跨语言的）</li>
<li>过一遍可能是不够的，需要再去读几遍</li>
</ul>
<hr>
<img src="/7f719eb/2.png" class>

<h3 id="The-Craft-of-Research-介绍"><a href="#The-Craft-of-Research-介绍" class="headerlink" title="The Craft of Research 介绍"></a>The Craft of Research 介绍</h3><ul>
<li><p>这本书是整个芝加哥 关于写作系列丛书之一</p>
</li>
<li><p>这些丛书中，这几本也是非常有名的：</p>
<ul>
<li>《The Chicago Guide to Grammar, Usage, and Punctuation》：关于语法使用和标点符号的写作指导，是非常基本的 也是权威的一本关于英语写作的书</li>
<li>《A Manual for Writers of Research Papers, Theses, and Dissertations》：关于写研究论文的比较基础的书</li>
</ul>
</li>
<li><p>这本书是教怎么样去讲这个故事，并将这个故事写下来</p>
</li>
<li><p>书的版本不同可能是在找文献这一块不同，可能看前面的版本也问题不大</p>
</li>
<li><p>在作者上面均是大学英语系的，在写作上面应该是比较权威的（用词与写作方法上），但是在举的例子上，比较偏文学和自然科学（写作的想法是相通的，适用范围广）</p>
</li>
<li><p>第一部分，提出了一个核心的观点：在写作的时候，永远要知道你的读者是谁，他们想要知道什么</p>
</li>
<li><p>第二部分，关于是怎么样去问问题，怎么样去找答案</p>
</li>
<li><p>第三部分，是讲怎么样讲一个故事（怎么样提一个论点，怎么样安排论据来支撑你的论点）</p>
</li>
<li><p>第四部分，是讲怎么样把这个故事给你写下来（关于写作主要在这个部分）</p>
</li>
</ul>
<hr>
<h3 id="第一部分-研究、研究者和读者"><a href="#第一部分-研究、研究者和读者" class="headerlink" title="第一部分 研究、研究者和读者"></a>第一部分 研究、研究者和读者</h3><p>本书的受众很广：可以是 正准备做第一个研究项目的本科生，也可以是比较年轻的研究者，本课的受众就缩小了范围（可以是研究项目已经做到一半了或者快要做完了，开始准备想怎么写论文；或已经做过了几个研究写过了几篇论文但想提升论文写作的），所以跳过了前言部分（当然也是可以去读一下的）</p>
<img src="/7f719eb/3.png" class>

<h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>介绍了研究是什么东西（研究就是要去收集信息来回答一个疑问，这个回答完之后呢能解决某一个问题（比较偏社会和自然学科这一块））</p>
<p>对于技术类来说，收集信息可能是提出一个新的解决方案，然后去做一些实验来证实他的有效性；方法是解决某一个问题（不会把 question 和 problem 在两个东西分开），但是这里为了使得我们去想这件事</p>
<h4 id="为什么要去写一篇文章"><a href="#为什么要去写一篇文章" class="headerlink" title="为什么要去写一篇文章"></a>为什么要去写一篇文章</h4><ul>
<li>写文章自己会记得</li>
<li>写的时候会帮助你理解事情</li>
<li>写作可以用来测试我们的想法</li>
</ul>
<img src="/7f719eb/4.png" class>

<p>所以说，写作使我们，记得更加精确，理解更好以及评估我们的想法是不是客观的</p>
<h4 id="为什么要用一个正式的论文格式"><a href="#为什么要用一个正式的论文格式" class="headerlink" title="为什么要用一个正式的论文格式"></a>为什么要用一个正式的论文格式</h4><p>研究就是跟在同一个研究领域的同行之间进行交流，而论文的格式可认为是通讯中的协议，为了方便个体之间相互快速的理解研究的内容</p>
<h4 id="写作也是一种思考"><a href="#写作也是一种思考" class="headerlink" title="写作也是一种思考"></a>写作也是一种思考</h4><img src="/7f719eb/5.png" class>

<ul>
<li>需要为读者思考：去想自己的受众要去怎么样去理解这些东西，他们会怎么去想</li>
<li>写作的核心在于，要找到一个 topic（自己真正关心的问题，并且自己真的想去回答的问题，就是说去找到自己的兴趣点在哪）</li>
<li>作者希望能够告诉我们怎么样去权衡自己对自己项目的价值的信念和老师和同行之间的一个需求</li>
</ul>
<p>李沐老师的想法：</p>
<ul>
<li>对一个人的羡慕，不在乎说你有多少钱、你有多少地位、你有多少什么什么东西，更羡慕的是说能找到自己人生的意义，能做一件事情真的是觉得能够实现人生价值的</li>
<li>为什么呢？是因为人的时间都是一样的，每个人就有那么多的时间，你把你的时间花在你认为值得东西上，可能别人觉得值不值。其实真的不重要，只是说你用你的时间去实现你的人生目标的话，那就是最值得钦佩的。</li>
</ul>
<hr>
<h3 id="第二部分-跟读者建立联系"><a href="#第二部分-跟读者建立联系" class="headerlink" title="第二部分 跟读者建立联系"></a>第二部分 跟读者建立联系</h3><img src="/7f719eb/6.png" class>

<p>摘要：如果一个研究没有人读的话，可能也算不了什么。就算是很有经验的研究员，在有时候也会忘记掉把他们的读者放在自己的脑海里面。在这一节，我们将告诉你怎么样去为你的读者考虑，甚至是在你开始你的项目之前。</p>
<ul>
<li>大部分重要的事情，通常是要跟别人一起来合作完成的，作者反驳了大众对研究人员的刻板印象之后，提出了：读书或读论文时其实是跟作者的无声交流，写作也一样，是将自己的“声音” 写进文字里</li>
</ul>
<h4 id="文章就是跟你的读者的一个对话"><a href="#文章就是跟你的读者的一个对话" class="headerlink" title="文章就是跟你的读者的一个对话"></a>文章就是跟你的读者的一个对话</h4><ul>
<li>在日常生活中，我们离不开沟通，在交流的过程可以根据具体情况（别人的反馈），改变交流的方式（改语速、加背景知识等）</li>
<li>但是，写作是一个想象中的对话，在开始写的时候，就决定了作者是什么样的角色，以及受众是什么样的角色。比如<ul>
<li>作者是作为一个老师，来教学生一些东西，就是教科书的写法</li>
<li>作者给大家分享一些有意思的东西，blog 是怎么写的</li>
</ul>
</li>
<li>而这些角色（读者与作者扮演的角色）从文章的开头到结尾是固定的<ul>
<li>一旦改变的话，会让人觉得这个上下文不一致，文不对头</li>
<li>同时，文本是静态的东西，不可能根据读者现在的情况，来改变下面的文字的输出</li>
</ul>
</li>
<li>在关于读者读a的文章的例子中，应该在开始的时候，就带入读者的身份，思考读者可能会困惑的地方，然后适当的去调整一些论文，以下通过关于快速眼动期的例子，来说明这一点</li>
</ul>
<img src="/7f719eb/7.png" class>

<p>想好自己的受众</p>
<h4 id="理解作者的角色"><a href="#理解作者的角色" class="headerlink" title="理解作者的角色"></a>理解作者的角色</h4><ul>
<li>作为一个作者的角色，通常有三种<ul>
<li>发现了有意思的事，让大伙儿也乐乐（视频作者）</li>
<li>找到了实际问题的解决方案（有点像写博客）</li>
<li>找到了一个重要问题的答案，陈述问题与答案是什么（写论文）</li>
</ul>
</li>
</ul>
<h4 id="想像读者的角色"><a href="#想像读者的角色" class="headerlink" title="想像读者的角色"></a>想像读者的角色</h4><ul>
<li>当作者扮演不同的角色的时候，读者也会得到对应的角色</li>
<li>追求娱乐的人</li>
<li>需要解决实际问题的人</li>
<li>想要更好去理解东西的人</li>
</ul>
<img src="/7f719eb/8.png" class>

<p>作者给出了问题清单，方便我们思考：</p>
<ol>
<li>我们的读者是谁？谁会读我们的文章<ul>
<li>对这一块相当了解的人（评审人）</li>
<li>有一定知识的一般大众</li>
<li>根本不知道这一块的大众</li>
<li>在背景知识的介绍上，根据不同的读者，用词是不一样的</li>
</ul>
</li>
<li>他们希望我来干什么事情<ul>
<li>来娱乐他们吗？</li>
<li>帮他们了解新的东西？</li>
<li>帮他们更好的去了解东西？</li>
<li>帮他们解决实际问题？</li>
</ul>
</li>
<li>理解一下你的读者的知识的储备<ul>
<li>读者是不是理解你这个研究的话题</li>
<li>他其实他们有这个问题，但是他们还没有意识到</li>
<li>这个问题他们根本没有，只是我的问题</li>
<li>他们是不是理解这个问题的严重性</li>
</ul>
</li>
<li>要预测读者对你的回答以及方法做的反馈<ul>
<li>如果观点跟所有人的观点是对立的，那么要非常小心来改变别人的观点</li>
<li>他们会不会做一些标准的问句来反对我们提出的解决方案</li>
<li>他们是不是特别关心我是怎么去解决这个问题的</li>
</ul>
</li>
</ol>
<hr>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><ul>
<li>整个论文的写作，就是跟你的读者的一个无声的交流。</li>
<li>跟正常的交流不一样的是说，他不是互动的，而说你要一开始就想好，整个交流应该是一个什么的过程，要想清楚读者是谁，他们需要什么。</li>
<li>所以你在写文章时，而写的能满足他们的需求，使得他们能信服你写的东西。</li>
</ul>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv17247461">https://www.bilibili.com/read/cv17247461</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫方法技巧</category>
      </categories>
  </entry>
  <entry>
    <title>CCF学生领航计划（SPP）第十七期-《学术研究中实验写作与日常积累》</title>
    <url>/c9152824.html</url>
    <content><![CDATA[<iframe src="//player.bilibili.com/player.html?aid=731625806&bvid=BV1BD4y1C7KN&cid=866458635&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<p>2022年10月19日，CCF学生领航计划已举办到第十七期。本期的主角为中山大学计算机学院2022级博士生陈蔓笙同学，主题是面向研一新生的“学术研究中实验写作与日常积累”，这次主要介绍了学术研究中想法启蒙、实验验证和论文写作三方面的内容。</p>
<p>陈曼笙 2018年在华南农业大学获得软件工程学士学位，2021年在中山大学获得计算机科学硕士学位。现是中山大学计算机学院2022级博士研究生，导师为王昌栋副教授。已经在国际期刊和会议上以第一作者身份发表论文十一篇，包括IEEE TKDE、IEEE TCYB、IEEE TNNLS、Information Fusion、KDD、ACM MM、AAAI 和 DASFAA。担任TPAMI, TKDE, TNNLS, Neural Network等学术期刊审稿人。主要研究方向是多视图聚类。</p>
<hr>
<h3 id="学术研究之想法启蒙"><a href="#学术研究之想法启蒙" class="headerlink" title="学术研究之想法启蒙"></a>学术研究之想法启蒙</h3><p>有同学提问“看了很久文献没有想法很焦虑”，陈师姐回答通过使用一个合理的文献阅读范式来解决这个问题。</p>
<p>文献阅读范式</p>
<ol>
<li>文章<strong>待解决问题</strong>及其<strong>动机</strong>，发现问题的<strong>本质</strong></li>
<li>记录方法模型的大体<strong>技术</strong>及其<strong>思路</strong>和<strong>贡献</strong></li>
<li>与现有方法相比它的<strong>优势</strong>和不明显的<strong>劣势</strong></li>
<li>论文<strong>总结</strong>与个人论文<strong>观后感</strong>，引申出<strong>个人</strong>的想法</li>
<li>阅读论文时的<strong>问题</strong>，便于与导师同学<strong>讨论</strong></li>
</ol>
<p>接着陈师姐以一篇AAAI2018多视图子空间聚类论文为例，讲述了论文摘要、引言、所提方法、实验、总结的阅读思路。</p>
<img src="/c9152824/1.jpg" class>

<p>在精读完一篇论文，要进一步深入思考做到“想作者所想”，即为什么作者能发现这个问题？然后如何想到通过这样一个方法来解决这个问题？从而在阅读论文时，构建自身的思维逻辑。陈师姐以AAAI2018的多视图子空间聚类论文为例，讲述了作者融合使用了两条原则一致性与互补性原则来进行方法上的创新。</p>
<img src="/c9152824/2.jpg" class>

<p><strong>想法的紧迫性</strong>：学术研究是很紧迫的，如果想法上慢了，容易一步慢，步步慢。应当通过合理的方法去进行学术想法的构思</p>
<ol>
<li>紧跟大团队研究，构建研究的逻辑脉络</li>
<li>在已有成果的逻辑脉络中，追记下一个节点脉络</li>
<li>在已有成果的逻辑脉络中国总结问题，助力新想法的诞生</li>
</ol>
<hr>
<h3 id="学术研究之实验篇"><a href="#学术研究之实验篇" class="headerlink" title="学术研究之实验篇"></a>学术研究之实验篇</h3><p>有了新的想法就到了实验验证环节，新想法的验证包括两方面。</p>
<img src="/c9152824/3.jpg" class>

<p>初步确认想法可行性之后，可以进行对比实验来验证想法。</p>
<img src="/c9152824/4.jpg" class>

<p><strong>一般实验思路</strong>：</p>
<ol>
<li>参考类似结构模型的设置</li>
<li>记录实验过程（确保算法收敛），调参过程</li>
<li>分析实验结果</li>
</ol>
<p><strong>实验结果不符合预期</strong>：</p>
<ol>
<li>可以求助导师和同学</li>
<li>分析想法逻辑的完整性和合理性</li>
<li>设定DDL，根据讨论结果进行多次尝试</li>
<li>总结实验的经验</li>
</ol>
<p>如果实验结果符合预期就可以进行整体实验进一步的完善，进行实验设计时可以参考优秀论文的实验设计结构。</p>
<img src="/c9152824/5.jpg" class>

<hr>
<h3 id="学术研究之写作篇"><a href="#学术研究之写作篇" class="headerlink" title="学术研究之写作篇"></a>学术研究之写作篇</h3><p>先介绍论文写作软件工具Overleaf，TeXstudio等Latex写作软件，以及JabRef, Zotero等参考文献管理工具，以及其他一些方便的小工具。</p>
<img src="/c9152824/6.jpg" class>

<p>学术写作是70%思考+30%写作，我们先结合实验进行思考，然后进行写作。</p>
<p><strong>思考内容</strong>：</p>
<ol>
<li>明确你的主要<strong>研究问题</strong></li>
<li>明确该问题涉及的所有<strong>领域</strong>或者学科</li>
<li>明确你研究该问题的<strong>原因</strong></li>
<li>明确解决该问题的<strong>方法</strong></li>
<li>明确<strong>实验结果</strong>的<strong>贡献</strong></li>
</ol>
<img src="/c9152824/7.png" class>

<p><strong>学术论文组成</strong>：</p>
<ol>
<li>标题：核心<strong>问题与创新点</strong>的高度凝练</li>
<li>摘要：<strong>动机</strong>、<strong>亮点</strong>与<strong>效果</strong>的概要介绍</li>
<li>引言：<strong>动机</strong>、<strong>现状</strong>、<strong>方法</strong>和<strong>贡献</strong>介绍</li>
<li>相关工作：引言<strong>现有</strong>工作的详细介绍</li>
<li>研究方法：引言<strong>模型</strong>部分的详细介绍</li>
<li>实验分析：引言模型<strong>效果</strong>的详细介绍</li>
<li>总结展望：经过实验验证后给的<strong>结论</strong></li>
<li>致谢：对作者以外人员/机构的感谢</li>
<li>参考文献：正文出现的按照<strong>格式</strong>引用</li>
</ol>
<p>学术论文的写作时，陈师姐建议先完成我们熟悉的部分即，自己所提的研究方法以及前面所做实验的分析部分。反复修改确认逻辑无误后再开始后续论文的撰写。写作顺序如图所示。</p>
<img src="/c9152824/8.jpg" class>

<h4 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h4><p>首先一篇好的论文都有一个好的标题，下面时标题命名的基本要求以及如何起一个好的标题。</p>
<p><strong>基本要求</strong>：英文形式规范；语言精炼简洁；范围大小适当。</p>
<p><strong>好标题</strong>：反应核心问题；突出技术创新；保护知识产权；易于记忆传播。</p>
<h4 id="研究方法"><a href="#研究方法" class="headerlink" title="研究方法"></a>研究方法</h4><p>然后就可以开始撰写论文的研究方法部分，一般来说先对问题进行建模，然后基于问题进行目标模型设计。</p>
<img src="/c9152824/9.jpg" class>

<p><strong>实验分析</strong>：这部分在前面进行想法验证时，已经大致完成，我们这部分主要包括两大部分：实验介绍和实验分析。</p>
<img src="/c9152824/10.jpg" class>

<h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p><strong>基本要求（关键、难）</strong>：研究背景与挑战；提出问题与原因；相关工作与不足；本文研究思路；本文主要贡献。</p>
<p><strong>问题：有理有据，具体化</strong>：背景阐述聚焦重点；问题提出明确具体；聚焦研究动机，总结现状问题；基于研究动机，概述研究方法；拔高论文贡献。</p>
<h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><p><strong>基本要求</strong>：包括理解本文的所有主题（尽可能）；包括问题相关的所有工作；从不同角度划分主题；总结问题，引出本文区别与贡献</p>
<h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p><strong>基本要求</strong>：引言的概括；涵盖动机、亮点、效果等；逻辑清晰；200词左右（精炼)。</p>
<h4 id="总结展望"><a href="#总结展望" class="headerlink" title="总结展望"></a>总结展望</h4><p><strong>基本要求</strong>：和摘要的区别：经验证后的结论；论文主要发现总结；内容尽量简洁，不过度夸大；介绍未来工作。</p>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p>要不遗漏，使用会议/期刊格式，要统一参考文献格式，推荐使用DBLP搜索文献的BibTeX。</p>
<p><strong>论文写作日程</strong></p>
<img src="/c9152824/11.jpg" class>

<hr>
<h3 id="学术研究之日常积累"><a href="#学术研究之日常积累" class="headerlink" title="学术研究之日常积累"></a>学术研究之日常积累</h3><p>学术研究在与每日点滴积累，可以从下面五个方向积累</p>
<ol>
<li>论文Paper:写作框架，想法逻辑，好词好句</li>
<li>想法Idea:旧问题想法</li>
<li>数学Math:已有论文原理</li>
<li>英语English:以论文为材料，学习语感</li>
<li>代码Code:学习trick,便于调参</li>
</ol>
<p>应当把握好学术研究节奏，保持良好的心态和合理的科研规划。</p>
<img src="/c9152824/12.jpg" class>

<p>陈曼笙师姐的基础学术研究结束，希望大家脚踏实地，仰望星空，道阻且长，行时将至！</p>
<hr>
<h3 id="补充资料"><a href="#补充资料" class="headerlink" title="补充资料"></a>补充资料</h3><blockquote>
<p><a href="https://dl.ccf.org.cn/video/videoDetail.html?_ack=1&amp;id=6183465944074240">https://dl.ccf.org.cn/video/videoDetail.html?_ack=1&amp;id=6183465944074240</a><br><a href="https://dl.ccf.org.cn/ppt/pptDetail.html?_ack=1&amp;id=6183557460723712">https://dl.ccf.org.cn/ppt/pptDetail.html?_ack=1&amp;id=6183557460723712</a></p>
</blockquote>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12477">https://www.scholat.com/teamwork/showPostMessage.html?id=12477</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐讲座</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-明白问题的重要性【研究的艺术·二】</title>
    <url>/2cc05622.html</url>
    <content><![CDATA[<img src="/2cc05622/1.png" class>

<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=727683126&bvid=BV11S4y1v7S2&cid=753356845&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>研究的艺术的第2部分：</p>
<ul>
<li>怎么样去找到你研究的问题</li>
<li>想清楚自己研究问题的重要性是什么</li>
</ul>
<p>找问题去解决 是研究领域一个独有的事情，在做一件事情之前，想清楚这件事情的意义是非常重要的。</p>
<p>这个是具有普适性的，在生活中或工作中都可以用的到。这样既可以将事情做的更好，可以避开无意义的事情从而节省时间。</p>
<hr>
<h3 id="第3章-从话题到问题（topics-to-questions）"><a href="#第3章-从话题到问题（topics-to-questions）" class="headerlink" title="第3章 从话题到问题（topics to questions）"></a>第3章 从话题到问题（topics to questions）</h3><p><strong>摘要</strong></p>
<p>在自己的兴趣之中，找到一个话题然后适度的调整它的大小，使得我们能在这上面做研究。对于这个话题，我们需要提出一些问题，来指导我们做研究。</p>
<p><strong>正文</strong></p>
<ul>
<li>在研究的时候，可以自由的选择话题去做（学术界 相对高；工业界 相对低）</li>
<li>自由也有危害：定不下来具体要做什么事情（进入一个新的行业 或者 刚开始做研究）</li>
<li>一些定义：<ul>
<li>subject：学术领域（气候变换、人工智能、计算机视觉等）</li>
<li>topic：话题，即领域内特别兴趣点（气候变换对鸟的迁移带来的影响、怎么样高效的设计卷积神经网络使得图片的分类精度更高）</li>
</ul>
</li>
<li>为什么要选择话题？【因为很难有一个研究是针对整个研究领域来做的，】所以一定要在自己的领域里面找到一个话题，这样才可以往深挖。</li>
<li>话题是一个使得你可以在里面问一些问题的途径，如果回答这个问题回答得比较好的话呢，整个领域的研究人员都会对它感兴趣，而且好的答案能够在一定程度上推进整个领域往前发展。</li>
<li>话题本身，也可能比较大也可能比较小。<ul>
<li>大就是说，在整个研究领域中很常见的一个话题（心理学中害羞或愿意冒险是人类学来的还是天生的）</li>
<li>小众一点的也可以，但只有某些特定的研究人员感兴趣（把咖啡放在桌上之后留下的印子为什么一定是个圆形）</li>
<li>大家都感兴趣的话题，肯定有更多人参与研究，所以竞争更加激烈一点；</li>
<li>比较小众的话题在里面做出比别人更好的工作的概率更高一点，但是会导致你就算做出来受众没那么广；</li>
</ul>
</li>
<li>最重要还是对这个话题问一些问题，然后你问题的答案，别人可能会觉得重要，甚至这个答案在一定程度上能改变整个研究领域。</li>
</ul>
<img src="/2cc05622/2.png" class>

<p><strong>区分什么是question什么是problem？</strong></p>
<ul>
<li>question，就是疑问，就是说问一个问题，然后需要来做答案的</li>
<li>problem，可认为是一个困难，就是存在一个问题，如果不去解决他的话，可能会带来一些危害</li>
<li>往细的说，一个疑问不一定会带来一个问题，一些问题回答与否，并不都会带来什么后果；但有些问题的回答可以解决很大的问题<ul>
<li>a problem或者一个困难或者一个问题，就是研究界觉得是值得去解决的一件事情</li>
<li>a question或者说一个疑问呢，是找到一个问题的途径，也就是说，针对话题问一些问题使得我们可以找到一些方法来解决某个problem</li>
</ul>
</li>
<li>这两个是可以区分开的，也就是针对一个话题，要问很多这样子的问题，然后找出里面到底谁值得去回答</li>
</ul>
<hr>
<h4 id="怎么样从兴趣到一个话题"><a href="#怎么样从兴趣到一个话题" class="headerlink" title="怎么样从兴趣到一个话题"></a>怎么样从兴趣到一个话题</h4><p>(兴趣到话题再到疑问)</p>
<p>在通过读一些文章之后去发现自己没有发现的兴趣，然后从中找到一个话题，话题主要取决于自己的兴趣</p>
<p>对于技术领域来说，能考虑的就那么几件事情：</p>
<ol>
<li>怎么样把一个东西的效果做出来，就是针对一个问题我们提出个算法，使得之前的算法都不是很行，用了这个算法之后行了</li>
<li>怎么样把它做大，数据更大，整个规模更大</li>
<li>怎么把它做便宜一点</li>
<li>怎么样把它做安全一些</li>
</ol>
<p>看到一个技术点或者一个话题可以带上以上四点来考虑，在这之后看看自己对什么东西感兴趣，然后针对这些兴趣去找到对应的话题</p>
<p>这本书介绍了很多东西可以去看一看，但主要还是偏文科的，跟我们理工科还是有不一样的地方</p>
<hr>
<h4 id="如何将话题变小，并使其能开始做研究？"><a href="#如何将话题变小，并使其能开始做研究？" class="headerlink" title="如何将话题变小，并使其能开始做研究？"></a>如何将话题变小，并使其能开始做研究？</h4><p>怎么使话题促成一个比较好的研究工作？能不能把这个话题换算成一个论点？这个论点看上去是有价值去讨论的。</p>
<p>当找到合适的话题的时候，就要问一些问题了。常见的错误：当找到一个合适的话题的时候，就会迫不及待的把这个所有话题相关的文章、资料都找起来读一读。这样子的效率是比较低的。因为你去读的时候，如果没有带着问题出发的话，你可能读起来就不那么的专注了。</p>
<p>李沐老师对于上面例子的观点：</p>
<ul>
<li>与作者不同的是老师觉得，如果你是真的新进入一个领域或者一个话题的时候，不一定能问出什么样的问题出来，可能干的事情就是把那些文章都找出来读一读然后总结一下。</li>
<li>因为很多第1年第2年的硕士生或者博士生他干的事情，就是找到一个话题之后，就把整个话题的文章拿出来写一个综述文章，这样子能够对整个话题有一个比较全面的认识，当比较熟悉之后就知道哪一些东西是可以问合适的问题。</li>
<li>反过来讲，当你打算去写综述的时候呢你其实也已经问了一个问题：这个话题上有没有很好的综述文章，如果答案是有的话，那么就不要干这个事情了，就读一下综述的文章，在里面有一个比较全面认识，就可以开始想自己的问题；如果没有的话，就变成了一个实际的problem，可以给大家写一个综述的文章，给大家带来价值。在这个时候很有可能就可以问了一个很好的问题。</li>
<li>当开始真正的写综述的时候，再去读文章就会去想这篇文章提出的东西怎么样放进我的综述文章里面，也就是综述里面需要对整个话题、整个子领域给画一个比较大的图，然后把所有的工作放进图里面把他们之间联系起来。</li>
</ul>
<p>更好的是说，在读论文的时候，能带着一些具体的一些问题（能够真的成为最后研究的一些问题）来去读的话，专注度会更好一点。</p>
<hr>
<h4 id="怎么样评估你的问题"><a href="#怎么样评估你的问题" class="headerlink" title="怎么样评估你的问题"></a>怎么样评估你的问题</h4><p><strong>当对某一个问题感兴趣的时候，应该问自己个更难的问题，叫做“so what”。</strong></p>
<ul>
<li>就是说我如果解决了这个问题，又怎么样呢，别人会不会关心，他能给别人带来什么样的好处，是不是能够推动整个领域的发展，或者推动领域在一个小地方的发展，能不能启发别人做更多的工作；</li>
<li>也可以反过来问，假设我不去回答这样个问题，会不会有什么样损失，别人会不会觉得错过了一个亿，是不是整个领域可能会停止向前发展很多年。</li>
<li>如果你的答案是说没有，就是说是因为兴趣而做的也没有关系，这可以使得我们继续往深里面走，但是还得不断的去问SO WHAT这个问题，去想我现在的东西so what，别人care不care。</li>
<li>对自己狠一点，这样子才能比较客观一点。在生活中，时不时很tougher的问一问自己so what 这个问题，能够使得生活变得更加简单，发现很多事情其实没必要做的，会发现一些更有意义的事情</li>
</ul>
<p><strong>怎么样找到我们的问题以及怎么样去问so what这个问题</strong></p>
<ul>
<li>先把话题给列出来（把topic的名字你找出来），句式：我想去 学习/做/研究 _______</li>
<li>有了话题之后再其后加间接的问题，就是加个w词（6w1h）</li>
<li>去想清楚问题的重要性，如果问题是一个开放性的问题的话，那么问题的重要性很有可能就是为了帮助读者更好的了解 怎么样 为什么 或者 是不是 的问题啊</li>
</ul>
<p><strong>在so what 这个问题上继续展开</strong></p>
<ul>
<li>在一开始找问题的时候，很有可能找到的问题就是这个领域关心的一些问题。那么这时候就不那么需要去关心这个东西的意义在什么地方</li>
<li>在技术领域，通常我们去找一个方法来解决某一个痛点，只要你的方法真的能够比较好的解决这个痛点的情况下，一般都是有意义的，最后的意义的大小取决你这个痛点到底是有多痛以及是多少人觉得痛</li>
<li>但是，很多时候其实是并不知道我们的这个东西为什么重要，特别是偏理论点的研究或者是很开放性的问题。在这个情况下一开始是OK的，就是说一开始并不知道为什么要做这个事情，随着研究慢慢深入，我们不断的去问自己说，找出来的这个东西（发现这个东西）到底有没有用，别人到底在不在意</li>
<li>所以不断的去想这个事情，也会指导你的研究的方向。当我们有没有想清楚这个事情的时候，很有可能这个研究是不能停的。只有当我们大概是知道为什么别人觉得这东西有用的时候，我们是可以把研究停下来，开始写论文了</li>
<li>总结一下：这里面是有3步的：我们的话题是什么；在这个话题里面的问题是什么；为什么别人会在意这个事情</li>
</ul>
<hr>
<h4 id="怎么去找话题"><a href="#怎么去找话题" class="headerlink" title="怎么去找话题"></a>怎么去找话题</h4><ul>
<li>当我们去参加一个比如说科研实践这样子的课的话，在你的兴趣点里面找到一些话题来研究</li>
<li>如果已经有了一个研究领域的话要去怎么样找：<ul>
<li>去读一些教科书啊或者去上节课（书和课要比现在学的要再往上一层，因为了解一下自己已经懂得东西，可能也没什么新的想法）</li>
<li>参加一些这个领域的学术报告，参加一下研讨会，跟大家讨论一下、问一些问题，看看大家在讨论什么东西；</li>
<li>问问老师（如果你的老师是一线的研究员的话，他肯定在心中是有一些想法的）</li>
<li>去网上找一找谈论</li>
</ul>
</li>
</ul>
<p>李沐老师的看法：</p>
<ul>
<li>除非是在一个比较大的团队里面，有很多人一起做一个事情，以及说有大的数据或者有比较多的计算资源的话，一般来说尽量不要去碰那种大家都在谈的特别大的领域。因为这里面的人特别多，比如说啊图片分类问题，目标检测问题，以及现在大家都在做的那些特别大的transformer模型。因为就算有一个很好的想法，但是要把文章写出来的话，需要大量的实验以及大量的精力去调这种东西，要做出效果的话，不是一个人很短时间就能做出来的。</li>
<li>反过来讲，可以去关注一些稍微小一点的问题，从小的地方开始，也许可以往大的方向靠。那么怎么样找小的问题，可以在网上找一找（reddit上面很多这样子讨论，大家会分享一下自己的使用的一些经验）</li>
<li>可能比较好的一个办法是说：如果有时间的话，可以去公司里实习，去看一下整个工业界中在应用人工智能的时候，遇到的一些痛点。很多时候工业界的人，他自己可能没这个想法，反正就这么痛，用过去就已经习惯了。但是我们作为一个刚进去的实习生，是个外来者，可以去仔细的观察大家是怎么样用的，遇到了什么问题，去把这些小的事情抽象出来，总结出来就变成了一个研究的问题了。然后只要观察仔细的话，其实是会发现很多这样子的问题，这里面的小问题很有可能是能支撑我们几年的研究的。</li>
</ul>
<hr>
<h4 id="本节的核心思想"><a href="#本节的核心思想" class="headerlink" title="本节的核心思想"></a>本节的核心思想</h4><ul>
<li>怎么样从兴趣点开始去找到一个话题，然后把这个话题缩小到足够小的范围，使得我们能够去驾驭它，也使得它足够大到支撑一个比较好的研究</li>
<li>要在这个话题里面去问很多问题，因为我们的研究都是用来解决问题的，所以一定要有问题</li>
<li>有了问题之后，你要去问，最重要的 so what的问题，就是说解决这个问题要怎么样。在真的动手去解决问题之前，真的就要去想一想，假设半年之后，1年之后我解决了这个问题，那么别人关不关心这个事情</li>
<li>在做任何项目之前，都应该去想想这个东西做出来它的意义在于什么，不要去想说能不能做出来。就假设说有足够的资源，运气足够好，能把它做出来最好的结果以及能做出来情况下，去想一想对别人的影响有多大（这个事情的意义的天花板在什么地方）</li>
</ul>
<hr>
<img src="/2cc05622/3.png" class>

<h3 id="第4章-从疑问到问题"><a href="#第4章-从疑问到问题" class="headerlink" title="第4章 从疑问到问题"></a>第4章 从疑问到问题</h3><p><strong>前言</strong></p>
<ul>
<li>在这一节将解释怎么样去把一个question变成一个problem，而且是一个读者认为值得解决的问题</li>
<li>作者把问的问题question和值得解决问题problem给区分开来，帮助我们去了解这样子的一个思考的过程</li>
<li>这个思考的过程，不仅仅是对新手有用，在以后如果要指导别人做研究的话，也需要了解这一个过程来帮助别人来更好的思考</li>
</ul>
<p><strong>正文</strong></p>
<ul>
<li>回顾一下在上一章所提出了的3步公式来解决问题，首先提出话题：在研究什么，然后问一个问题，然后需要去找出回答问题之后的意义在哪里。这样就找到了一个读者认为是值得解决的问题，也就能创建一个与读者的强联系。</li>
</ul>
<hr>
<h4 id="理解研究问题"><a href="#理解研究问题" class="headerlink" title="理解研究问题"></a>理解研究问题</h4><p>研究的问题有两类：</p>
<ol>
<li>实际问题（practical problem）：比如说一个算法他跑的比较慢，解决他的话会让它跑得更快了；一个任务在某个数据集上的精度不是很高，可以提出一个新的算法解决它；这个领域没有一个很好的数据集能够让大家更好的去评估这个问题，那我提出个数据集；这都是解决一些实际的问题</li>
<li>概念问题（conceptual problem）：这些问题不是要去解决某一个实际的痛点，而是说如果我们回答他的话，会对某一个事情或者这个世界有一个更好的认识。在科学领域，绝大部分问题是这种概念上的一些问题，帮我们更好的理解某一个东西。</li>
</ol>
<p>但是在技术领域，更偏向实际的问题。当然也有很多偏理论的问题，比如说了解batch normalization为什么能够工作，以及说深度学习为什么能工作，甚至机器学习为什么能工作。这里面有很多的理论工作，但是我们只是目前为止，没有太多的去涉及这些的论文，所以导致大家可能觉得这些东西不多。但实际上在整个人工智能领域 特别是机器学习，可能是在深度学习之前啊，可能至少有1/3的论文是关于这样子的一些概念性的问题。</p>
<img src="/2cc05622/4.png" class>

<p><strong>这个问题是怎么样来的：</strong></p>
<ul>
<li>首先是有一些实际的问题（在日常生活中碰到一些东西）</li>
<li>然后就会有动机（motivates）去找到一些研究的问题（值得research的问题，通常是一些开放性的你不可能立马就知道答案的或者别人觉得没有很容易就解决的，其中就一些有价值的问题）</li>
<li>有价值的问题就定义了一些啊研究的实际的或者是概念上的问题</li>
<li>这样子的问题导致说，我们要去研究出他的答案，就是整个研究工作在干的事情</li>
<li>这些研究答案能够去帮助解决这些实际的问题</li>
</ul>
<img src="/2cc05622/5.png" class>

<p><strong>为什么要有问题？</strong></p>
<ul>
<li>如果你没有问题的话，可能你整个论文写出来就是很多数据在里面，很多证据摆在里面，但是别人看上去就没有能找到你的观点（point）在哪里</li>
<li>很多新手写作就是没有把东西聚焦在某一个问题上，使得读者跟不上你的节奏，也不知道到底在问什么问题，所以还是需要有一个问题</li>
</ul>
<hr>
<h4 id="问题的结构"><a href="#问题的结构" class="headerlink" title="问题的结构"></a>问题的结构</h4><p>不管是实际的问题还是概念上的问题都有一个下面的结构：</p>
<ol>
<li>situation condition就是说你的状况</li>
<li>你不想要的一个结果（如果不解决它的话，可能需要去付某一些不想付的代价）</li>
</ol>
<p>需要注意的是所谓的代价，其实是读者关心的，不是我们自己要付的代价而是他们要付的代价</p>
<img src="/2cc05622/6.png" class>

<p><strong>怎么样从读者的角度去找出这样子的代价</strong>：从自己的状况开始不断的问so what</p>
<img src="/2cc05622/7.png" class>

<p><strong>概念性的问题会有什么样的区别：</strong></p>
<ul>
<li>在实际问题上，我们的状况通常是一些状态，导致会付出我们不想要付的代价</li>
<li>但对于这种概念上的问题来讲我们的状态通常是说不知道某或者不了解某一个东西，这就是condition；一般来说不理解某一个东西，不会给我们带来立即的一个代价（除了考试），所以一般不会去谈他的代价</li>
<li>那它的后果是什么：如果不能了解这个问题的话，那么就会无法去理解一个更重要的问题，而这个重要的问题，大家都觉得我们应该去了解的</li>
</ul>
<img src="/2cc05622/8.png" class>

<p><strong>作者画了幅图来说明：</strong>我们去了解我们的第一个问题（研究要去回答的问题）能帮助我们了解一个更大的一个问题，就是从Q1 一直到Q2，只要Q2足够大而且确实是能过去的话，那么这还是有价值的。</p>
<img src="/2cc05622/9.png" class>

<p><strong>如何更好的去找到这样子的一个后果：</strong>可以反问大家，如果我不能回答这个问题的话，会导致我不能回答什么事情。概念性的问题，比实际的问题在问上去觉得更加虚一点，因为看不到一些事实上可见的代价。很多时候这些问题最后也只是满足了人类的一个好奇心。</p>
<p><strong>怎么样去区别纯研究和应用的研究？</strong></p>
<ul>
<li>纯研究就是去回答一个概念上的一个问题，应用的研究就是去解决一个实际上的问题</li>
<li>纯研究通常会出现在比如说自然学科领域，在学术界会多一点。在工业界的话，大部分的研究是应用性的研究，当然在学校也是一样，偏技术类的研究通常都是应用性的研究，就是去回答一些实际的问题</li>
<li>但具体的区别就是说你最后你的重要性也就说 so what 的问题，这个问题是要去回答一个问题，就是满足大家的一个好奇心，就是纯研究，还是说去解决一个实际的问题，降低某一个代价，就是应用的一个研究</li>
<li>同样主题的东西，最后的significance不一样，导致了在纯研究和应用的研究的差异。应用性的研究，大家可能会觉得问题不大，反正因为能看到实际的一些结果。但是对纯研究的话，很多说大家对上面不是那么的理解。如果是做纯研究领域的话，想让大家能够更好的理解你研究价值，也可以往实际的那些应用去靠</li>
</ul>
<hr>
<img src="/2cc05622/10.png" class>

<h4 id="怎么样找到一个好的研究问题"><a href="#怎么样找到一个好的研究问题" class="headerlink" title="怎么样找到一个好的研究问题"></a>怎么样找到一个好的研究问题</h4><ul>
<li>找人帮忙：去跟别人讨论然后不断的去问so what的问题，有人帮你讨论其实会更好一点</li>
<li>在阅读中寻找问题</li>
<li>从自己的总结中选择：在写的时候通常会想的比较全面，所以写的比较客观，然后把它写下的时候也是帮助我们将整个思维想的更全面</li>
<li>找到一个好的问题，是一个研究者可能需要花很多年的一个事情，需要跟可能比我们更善于去找好问题的研究者去合作，从他那里学习不断的去学习怎么样找到这个领域的好的的问题</li>
</ul>
<hr>
<h4 id="问题的解决前提"><a href="#问题的解决前提" class="headerlink" title="问题的解决前提"></a>问题的解决前提</h4><ul>
<li>在真的去解决一个问题之前，不要去想说能不能解决它。能不能解决它其实是后一步的事情，先要问的问题是说读者认不认为这个东西值得解决</li>
<li>作者直接把后果说了出来，假设我们不这么做的话，那么很有可能读者会不在意（care）我们的工作，也就是为什么在做一个问题之前，一定要想说读者会不会觉得这个问题值得解决</li>
</ul>
<img src="/2cc05622/11.png" class>

<p><strong>怎么样摆脱进入一个新的领域时不知道问题重不重要的焦虑：</strong></p>
<ul>
<li>首先要承认这个问题，不可能在一开始就知道问题是不是重要的，很多时候需要写一篇论文然后看一下数据怎么样，所以不是一两天的事情</li>
</ul>
<p><strong>李沐老师的办法：</strong></p>
<ul>
<li>不要等到真的把研究做完论文写完，再去给别人看说这个东西值不值得做。要在一开始的时候，尽量的在有想法的时候，跟别人谈，跟你的同学谈也行，同事谈也行，老师谈也行，甚至是可能针对的用户谈也行，就看看他们关不关心这个事情</li>
<li>不要等到你的研究真的做完，可以是做了中间一半比如说1/3或者1/2的时候，准备一个10分钟、20分钟的小报告，然后在本地的一些研究小组里面给大家讲一讲，看一看大家的一个反馈。（可以在workshop上面投稿，看看大家的想法）</li>
<li>在工作中，在公司的时候，想做任何研究的时候，在做它之前一定要想清楚说哪个产品团队或哪个客户可能会需要这个东西，他们会不会把这个研究工作做进产品里面。在做之前先别急着动手，先想清楚你要做什么样的问题，可能用什么方法，然后你去跟这些未来可能存在的这些啊合作方去聊，告诉他说：我准备做这个问题，你感不感兴趣，你感不感兴趣把这个东西放进你的产品里面</li>
<li>核心是说要在做研究的过程中，要不断的跟潜在的读者（用户）沟通，使得可以根据这个交互来帮助我们改变整个研究的一个方向。也是确保在研究做完之后，最后是有人关心有人买账</li>
</ul>
<hr>
<img src="/2cc05622/12.png" class>

<h3 id="第5章-从问题到学术资源"><a href="#第5章-从问题到学术资源" class="headerlink" title="第5章 从问题到学术资源"></a>第5章 从问题到学术资源</h3><p><strong>在有了问题的时候，怎么样去找资源（文中偏文科）：</strong></p>
<ul>
<li>在技术领域，要去解决某个问题，先去找到跟你这个问题最相关的一两篇论文，然后去看他引用了谁，就是往前走，看看他之前的工作长什么样子</li>
<li>不要去看一篇论文对前面工作总结，要去把那些他真的引用的那些东西真的拿去看一下，完成一个自己的一个总结，然后再看一下谁引用这一篇文章</li>
<li>把这个论文往前走往后走，基本上能找到要的那些资源了</li>
</ul>
<hr>
<img src="/2cc05622/13.png" class>

<h3 id="第6章-使用学术资源"><a href="#第6章-使用学术资源" class="headerlink" title="第6章 使用学术资源"></a>第6章 使用学术资源</h3><p><strong>怎么样评估一篇论文的好坏：</strong></p>
<ul>
<li>看引用，大概就知道这篇文章有多少人读它，多少人关心它，这个方法主要是针对已经发表了几年的文章</li>
<li>对于新的文章是说，至少在计算机领域，不管是杂志也好会议好都是有排名的，虽然排名也不那么可信。假设一篇文章引用的那几篇主文章 就是说我们的方法、做对比的或者基于的那些文章，发表在某一个会议的时候，我们的文章也通常要发表过去</li>
<li>研究也是有圈子的，假设想发一个一流会议的文章的话，那么我们去读的和引用的，和基于的工作最好也是一流会议甚至是更好</li>
</ul>
<hr>
<h3 id="本期总结"><a href="#本期总结" class="headerlink" title="本期总结"></a>本期总结</h3><p><strong>总结：</strong></p>
<ul>
<li>第2部分的标题叫做问问题然后找到答案</li>
<li>核心是说先找到大小合适的话题，然后问一些问题，然后把一个读者认为值得去了解答案的问题抽出来，做成一个研究问题，我们的研究问题可能是实际的，也可能是概念上的</li>
<li>不管是哪类问题都要想清楚：<ul>
<li>它的状况是什么</li>
<li>不解决他的话他的后果是什么</li>
</ul>
</li>
<li>后面两节是说给一个问题怎么样找到资源，就找到前面的工作，然后怎么样读懂别人的工作，以及把自己的工作放在别人的工作之上</li>
<li>核心是说要学懂前面两章讲的东西，就是话题、问题以及他的后果</li>
</ul>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv17357477">https://www.bilibili.com/read/cv17357477</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫方法技巧</category>
      </categories>
  </entry>
  <entry>
    <title>论文写作与学术规范-（第七讲）研究中的实验及数据处理</title>
    <url>/5564d281.html</url>
    <content><![CDATA[<div class="pdfobject-container" data-target="./file/lecture/20221025.pdf" data-height="500px"></div>

<span id="more"></span>

<hr>
<h3 id="Experimentation-实验"><a href="#Experimentation-实验" class="headerlink" title="Experimentation 实验"></a>Experimentation 实验</h3><h4 id="Baseline-基线"><a href="#Baseline-基线" class="headerlink" title="Baseline 基线"></a>Baseline 基线</h4><p>实验是健全的科学的一个重要组成部分。试验应该是公平的。</p>
<ul>
<li>你的结果应该与以前的最佳方法进行比较。</li>
<li>将基线的选择更新为最新的。</li>
<li>如果你以一种新颖的方式解决了一个现有的问题，但由于某种原因无法与以前的工作相比较，怎么办？潜在的比较点：一个合理的人可能提出的第一个可行的方案。</li>
</ul>
<hr>
<h4 id="Persuasive-Data-有说服力的数据"><a href="#Persuasive-Data-有说服力的数据" class="headerlink" title="Persuasive Data 有说服力的数据"></a>Persuasive Data 有说服力的数据</h4><p>把自己放在读者的位置上。</p>
<p>你想被对于某一类问题，有一种算法是现有的最佳选择的说法给说服。</p>
<ul>
<li>什么数据：其特点</li>
<li>机制：需要进行规范化或清理</li>
<li>充分性：较大的数据集提供不同的统计特性。数据量要足够大，以保证实验将能够检测到被假设的效果。</li>
<li>数据集的数量：单个数据集可能不具有说服力</li>
<li>领域知识：问题已被抽象或简化<ul>
<li>例如在生物或医学领域</li>
<li>无效的结果</li>
</ul>
</li>
<li>限制：需要数据方面的知识来帮助评估结果的重要性，然后尽可能地矫正数据。例如这可能涉及到按照明确的指导原则，仔细地手工处理数据。</li>
<li>如果参数是通过调整得出的，那么确定其有效性的唯一方法就是看它们在其他数据上是否有良好的表现。选择参数来适应数据，或者选择数据来适应参数，都有可能使研究无效。</li>
<li>参考数据集：允许机构之间和论文之间直接比较工作。它有风险，即方法可能变得非常专业（低鲁棒性），以至于对其他数据不起作用。</li>
<li>验证你所测试的是你打算测试的东西，只有在假设正确的情况下，实验才应该成功。询问单一的数据集是否足够？</li>
<li>你的主张应该适用于什么量的数据？</li>
</ul>
<hr>
<h4 id="Interpretation-解释"><a href="#Interpretation-解释" class="headerlink" title="Interpretation 解释"></a>Interpretation 解释</h4><ul>
<li>考虑对结果是否有其他可能的解释；如果有，则设计进一步的测试以消除这些可能性。</li>
<li>结论应得到结果的充分支持。特殊情况下的成功并不能证明一般情况下的成功，所以要注意试验中可能使其特殊的因素。</li>
<li>不要得出不适当的结论或推论。例如，如果一种方法在大数据集上比另一种方法快，而它们在中等数据集上的速度相同，这并不意味着第二种方法在小数据集上更快；这只意味着不同的成本在不同的规模上占优势。</li>
<li>不要夸大你的结论。例如，如果一个新的算法比现有的算法差一些，把它们说成是等价的是错误的。如果差异很小，读者可能会推断它们是等价的，但你这样说是不诚实的。</li>
<li>数字测量法允许进行数字操作，但如果应用于我们希望实现的定性目标，这种操作并不总是有意义的。 不能直接解释分数之间的差异程度。</li>
<li>预测性：我们论文中的结论通常是关于系统的属性，而不是我们已经看到的数据上的行为。</li>
</ul>
<hr>
<h4 id="An-“Experimentation”-Checklist-“实验”总结清单"><a href="#An-“Experimentation”-Checklist-“实验”总结清单" class="headerlink" title="An “Experimentation” Checklist “实验”总结清单"></a>An “Experimentation” Checklist “实验”总结清单</h4><h5 id="design-of-the-experiments-实验设计"><a href="#design-of-the-experiments-实验设计" class="headerlink" title="design of the experiments 实验设计"></a>design of the experiments 实验设计</h5><ul>
<li>是否已经确定了适当的基线？是什么让它们变得合适？它们是SOTA吗？</li>
<li>必须收集哪些数据，从哪里收集？</li>
<li>读者将如何为自己收集可比数据？</li>
<li>数据是否真实？它的数量是否足够？人工数据需要什么验证？</li>
<li>是否应在数据中加入实例以检验结果的有效性？</li>
<li>是否有关于这个问题的参考数据，其局限性是什么？</li>
<li>是否需要一个领域专家来解释结果？</li>
<li>结果可能有哪些限制？</li>
<li>实验结果是否应该与模型的预测相符？</li>
<li>报告的结果是全面的还是选择的？选择的结果是否有代表性？</li>
<li>其他试图用不同的硬件、数据和实现方式来验证工作的人可能会观察到哪些持久的特性？</li>
<li>实验是可行的吗？你是否有必要的资源（时间、机器、数据、代码、人力），以合理的标准进行实验？</li>
</ul>
<h5 id="software-to-be-developed-待开发的软件"><a href="#software-to-be-developed-待开发的软件" class="headerlink" title="software to be developed 待开发的软件"></a>software to be developed 待开发的软件</h5><ul>
<li>能否从其他地方获得基线，或者是否需要实施？它们的标准是否与你的系统的实施类似？</li>
<li>需要多少代码工作？哪些现有资源可以使用？也就是说，你的“造轮子”工作是否被有效利用？</li>
<li>代码（或建议的贡献）能否被分解成组件？如何测试各个组件的正确性，并评估其重要性？</li>
<li>你怎么知道这些代码是正确的？</li>
<li>代码是否会被公开？如果不，为什么不？</li>
</ul>
<h5 id="the-use-of-human-subjects-人的“使用”"><a href="#the-use-of-human-subjects-人的“使用”" class="headerlink" title="the use of human subjects 人的“使用”"></a>the use of human subjects 人的“使用”</h5><ul>
<li>在哪些方面可能需要人类？为数据做注释？作为测试对象？你的问题可以在没有人的情况下得到有意义的回答吗？</li>
<li>他们将如何被选中？</li>
<li>将需要多少人，这与你的预算如何对应？如果使用较少的人，或使用较少的时间，会有哪些妥协？</li>
<li>如何保持客观性和独立性？需要采取什么措施来避免引入偏见？</li>
<li>是否需要道德审查？<ul>
<li>伦理审查：1. 参与者为自愿参与并且可以随时退出；2. 已经给参与者提供了关于项目的相关信息；3. 数据进行匿名及保密；4. 对参与者权益的保护</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Statistical-Principles-统计原理"><a href="#Statistical-Principles-统计原理" class="headerlink" title="Statistical Principles 统计原理"></a>Statistical Principles 统计原理</h3><h4 id="Variables-变量"><a href="#Variables-变量" class="headerlink" title="Variables 变量"></a>Variables 变量</h4><ul>
<li>理想的实验是研究一个变量对被研究对象的行为的影响。</li>
<li>消除变量（消融实验）</li>
<li>明确了解相关参数</li>
</ul>
<p>Samples and Populations 样本和总体</p>
<ul>
<li>“新的算法通常比旧的算法快”：声称新的算法平均来说更快。</li>
<li>(这样的声明可以很容易地在无理论分析的基础上和在实验的基础上作出。)</li>
<li>但是是什么的平均值？如果预期的含义只是在实验中进行的运行中，新的比旧的平均快，那么这些运行中的什么东西使它们具有代表性或预测性？</li>
<li>总体：所有可能运行的集合</li>
<li>但在所有的可能性中，总体是无限的，因为它必须包含所有可能的输入数据的组合</li>
<li>有必要采用取样的方式</li>
</ul>
<p>The task may be qualitatively changed. 任务可能会有质的变化。</p>
<ul>
<li>例如，一个搜索引擎在每次运行时，对一个给定的查询和网页集合会取得同样的效果，但对不同的查询或不同的集合会取得不同的分数————这可能是由于新数据改变了任务的性质。在任务发生质变的情况下，谈论总体、样本或平均数可能没有意义，所以解释结果的其他策略可能是合适的。</li>
</ul>
<hr>
<h4 id="Reporting-variability-报告差异性"><a href="#Reporting-variability-报告差异性" class="headerlink" title="Reporting variability 报告差异性"></a>Reporting variability 报告差异性</h4><ul>
<li>平均值提供了对典型行为的宝贵洞察力。</li>
<li>一个描述性的统计数字是<strong>标准差</strong></li>
<li>你可以报告特定的值，如1/4至3/4，与中位数相结合</li>
<li>实验运行次数是<strong>奇数</strong>比偶数要好，因为中间的运行将是中位数。</li>
</ul>
<hr>
<h4 id="Statistical-Tools-统计工具"><a href="#Statistical-Tools-统计工具" class="headerlink" title="Statistical Tools 统计工具"></a>Statistical Tools 统计工具</h4><ul>
<li>相关性用于确定两个变量是否相互依赖。</li>
<li>回归是用来确定两个变量之间的关系。</li>
<li>统计假设检验：假设检验用于调查改进是否有意义。通常的情况是，在对同一任务的两种技术进行的一系列比较中，一种技术在某些时候比另一种技术好，但不是所有的时候。</li>
<li>有一些软件包可以做很多困难的工作。其次，许多统计问题可以用基本概率来表述，然后通过计算来解决。</li>
</ul>
<h5 id="Visualization-of-Results-结果可视化"><a href="#Visualization-of-Results-结果可视化" class="headerlink" title="Visualization of Results 结果可视化"></a>Visualization of Results 结果可视化</h5><img src="/5564d281/1.png" class>

<img src="/5564d281/2.png" class>

<hr>
<h4 id="A-“Statistical-Principles”-Checklist-“统计原则”总结清单"><a href="#A-“Statistical-Principles”-Checklist-“统计原则”总结清单" class="headerlink" title="A “Statistical Principles” Checklist “统计原则”总结清单"></a>A “Statistical Principles” Checklist “统计原则”总结清单</h4><ul>
<li>哪些变量可能影响你的结果？对这些变量的分析是否意味着你需要利用统计学的方法？</li>
<li>你能预测改变每个变量的效果吗？它们是如何互动的？它们是独立的吗？</li>
<li>实验是如何区分变量的影响的？</li>
<li>影响是随机的还是系统的？如何控制它们？</li>
<li>将使用什么方法来调查异常值？</li>
<li>什么是总体？如何抽取样本？证明样本将具有代表性的论据是什么？</li>
<li>各项测量的精确度如何？达到一个特定的精度水平有多重要？</li>
<li>总结你的结果的正确方式是什么–平均数？一个中位数？一个最小值？</li>
<li>什么形式的差异会出现，以及如何在你的结果中捕捉到它？</li>
<li>你希望观察到的效应有多大，需要多少次测量才能可靠地观察到它？</li>
<li>假设检验是否合适，如果合适，是哪一种？</li>
<li>这些结果有意义吗？它们与任何明显的比较点是否一致？</li>
<li>哪些可视化方法可能有助于深入了解结果的模式或行为？</li>
</ul>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐讲座</category>
      </categories>
  </entry>
  <entry>
    <title>脑机接口与混合智能-新闻-科学家首次拍到：人睡着时清洗大脑全过程</title>
    <url>/cf506fa7.html</url>
    <content><![CDATA[<p>你睡着的时候，真的被洗了脑。</p>
<p>这次，波士顿大学的科学家们，史无前例地拍下了清洗过程：</p>
<img src="/cf506fa7/1.gif" class>

<span id="more"></span>

<p>红色是血液，蓝色是脑脊液。厉害的是从前没有发现过，血液会周期性地大量流出大脑。每当血液大量流出，脑脊液就趁机发动一波攻击。</p>
<p>脑脊液进入之后会清除毒素，比如导致阿尔茨海默病的β淀粉样蛋白。</p>
<p>而这样的清洗，只有在睡着后才能做到，让人一觉醒来，拥有一个清爽的大脑；没睡着的时候，脑脊液并没有充分的机会趁虚而入。</p>
<p>另外，研究人员还发现了脑电活动和清洗过程之间的关系，也就是说脑电波指挥了液体运动。</p>
<p>这项成果，刚刚登上了Science。作者兴奋地说：离揭示阿尔茨海默病和睡眠之间的联系，又近了一步。</p>
<p>罗切斯特大学的神经科学家Maiken Nedergaard则不禁赞叹：这篇论文太棒了。完全想不到，有人能够真的证明，脑电活动是可以让液体流动起来的。</p>
<p>所以，多睡一点吧，不要熬夜了。洗脑洗不完，说不定真的会变傻。</p>
<img src="/cf506fa7/2.jpg" class>

<hr>
<p>为何只有睡着才能洗脑？</p>
<p>当你睡着之后，大脑会经历几个不同的阶段：</p>
<p>经过入睡时期，浅睡时期，再到熟睡期和沉睡期，我们就会进入快速眼动 (REM) 睡眠期了，也就是容易做梦的一种状态。</p>
<p>而科学家把前四个阶段合称为“非快速眼动期”。这项新的研究，正是专注在非REM阶段，这是一个对大脑保留记忆 (Memory Retention) 来说非常重要的阶段。<br>其实，2013年已经有研究证明了，在小鼠睡眠的过程中，大脑里像β淀粉样蛋白这样的毒素，是会被清除的。大脑用的清洁剂，叫做脑脊液。</p>
<p>问题是，到底怎么清除的？为什么只有睡觉的时候才能清除？</p>
<p>科学家们做了个实验，让13个人类带上脑电帽，在核磁共振 (MRI) 机器里睡觉。脑电图会显示，一个人处在哪个睡眠状态；而MRI会测量血氧水平，显示有多少脑脊液流进流出。</p>
<p>然后发现了奇妙的现象：</p>
<p>大脑里的血氧浓度，出现了明显的大周期变化。也就是说，血液会大规模、周期性地流出大脑。</p>
<p>这个时候，脑脊液就会趁机冲进大脑，把留给它的空间都填满：</p>
<img src="/cf506fa7/3.jpg" class>

<p>绿色是血液氧合信号，紫色是脑脊液信号</p>
<p>醒来之后，大周期不见了，脑脊液就没办法大量冲进大脑，完成有效的清洗：</p>
<img src="/cf506fa7/4.jpg" class>

<p>论文的通讯作者Laura Lewis (简称“刘易斯”) 认为，这是因为睡眠过程中，大脑里的神经元们会开始同步活动，一起开，一起关。</p>
<p>之所以有这样的推测，是因为脑电图的数据显示，有神经节律出现后，才发生了血液和脑脊液的流转：</p>
<img src="/cf506fa7/5.jpg" class>

<p>当大量神经元一同停止了激发，就不需要那么多血液进去输送氧气，才给了脑脊液涌入的机会。</p>
<p>这样，便有了我们在开头看到的那副景象：</p>
<img src="/cf506fa7/6.gif" class>

<p>这个发现很重要，它告诉我们睡眠是一项非常特殊的功能：</p>
<p>我们醒着的时候，神经元们是不会同开同关的。所以，醒着的时候没有办法让大脑的血量，下降到足够低的水平。</p>
<p>只有睡着之后，大脑里没有那么多血液的时候，脑脊液才能自如地循环开来，清除像β淀粉样蛋白这样的代谢副产物。</p>
<p>所以，如果你经常熬夜，大脑就得不到清洗，那你真的会慢慢“变傻”。</p>
<hr>
<p><strong>原文链接</strong></p>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzk0OTMxNjY2MA==&amp;mid=2247633076&amp;idx=2&amp;sn=8c5a4c9e8e13f0a272bcb62513ce9416&amp;chksm=c356b5eff4213cf93112b52b83751f7d293fde3c6f825a0be60f14622aae3bb1e976648ba979">https://mp.weixin.qq.com/s?__biz=Mzk0OTMxNjY2MA==&amp;mid=2247633076&amp;idx=2&amp;sn=8c5a4c9e8e13f0a272bcb62513ce9416&amp;chksm=c356b5eff4213cf93112b52b83751f7d293fde3c6f825a0be60f14622aae3bb1e976648ba979</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐脑机接口与混合智能</category>
        <category>💫新闻</category>
      </categories>
  </entry>
  <entry>
    <title>开发知识-开发人员需要知道的6种开源协议</title>
    <url>/41f31a63.html</url>
    <content><![CDATA[<h3 id="什么是软件许可协议？"><a href="#什么是软件许可协议？" class="headerlink" title="什么是软件许可协议？"></a>什么是软件许可协议？</h3><p>通俗来讲，许可协议是指用来授权其他人具有某种使用你的作品的权利。</p>
<p>依靠许可协议将你的作品对外开源或者对你的作品的各个方面逐一进行授权，是一个不错的方法(WordPress, Drupal 和许多其它的内容管理系统都是开源软件)。一旦对外开源，你将失去所有对你的作品的版权，别人也没有义务将你标注为作品的原创者或捐献者。</p>
<p><strong>开源许可协议</strong>使人们免去了研究那些专业的许可条款的麻烦，使人们更方便的对开源项目贡献出自己的代码。而且它还能保护你作为作品的原创作者，确保你至少拥有由于贡献参与而带来的署名荣誉。它还能用来阻止其他人企图声明对你的作品拥有所有权的行为。</p>
<p>但是很多的软件作者和设计者都对各种不同的开源许可协议的内容和含义不甚了了。当你选择了某种开源许可协议时，你都放弃了哪些权力？在没有能明白各种开源协议的确切含义前，在不知道它们最适用于什么情况下时，软件开发者不可能在关于哪个许可协议最适合自己的软件的问题上做出准确的抉择。</p>
<img src="/41f31a63/1.png" class>

<span id="more"></span>

<hr>
<h3 id="BSD"><a href="#BSD" class="headerlink" title="BSD"></a>BSD</h3><p>BSD开源协议（original BSD license、FreeBSD license、Original BSD license）。BSD是”Berkeley Software Distribution”的缩写，意思是”伯克利软件发行版”。</p>
<p>BSD开源协议是一个给于使用者很大自由的协议。基本上使用者可以”为所欲为”,可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。</p>
<p>但“为所欲为”的前提当你发布使用了BSD协议的代码，或则以BSD协议代码为基础做二次开发自己的产品时，需要满足三个条件：</p>
<ol>
<li>如果再发布的产品中包含源代码，则在源代码中必须带有原来代码中的BSD协议。</li>
<li>如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。</li>
<li>不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。</li>
</ol>
<p>BSD 代码鼓励代码共享，但需要尊重代码作者的著作权。BSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销售，因此是对商业集成很友好的协议。<strong>而很多的公司企业在选用开源产品的时候都首选BSD协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者二次开发。</strong></p>
<p>相较于GPL许可证和MPL许可证的严格性，BSD许可证就宽松许多了，一样是只需要附上许可证的原文，不过比较有趣的是，它还要求所有进一步开发者将自己的版权资料放上去，所以拿到以BSD许可证发行的软件可能会遇到一个小状况，就是这些版权资料许可证占的空间比程序还大。</p>
<hr>
<h3 id="Apache-Licence"><a href="#Apache-Licence" class="headerlink" title="Apache Licence"></a>Apache Licence</h3><p>Apache Licence 2.0（Apache License, Version 2.0、Apache License, Version 1.1、Apache License, Version 1.0）</p>
<p>Apache License（Apache许可证），是Apache软件基金会发布的一个自由软件许可证。</p>
<p>Apache Licence是著名的非盈利开源组织Apache采用的协议。该协议和BSD类似，同样鼓励代码共享和尊重原作者的著作权，同样允许代码修改，再发布（作为开源或商业软件）。需要满足的条件也和BSD类似：</p>
<ol>
<li>需要给代码的用户一份Apache Licence。（代码可以商用或开源，但是如果开源必须要保留原有的开源声明）</li>
<li>如果你修改了代码，需要再被修改的文件中说明。（代码可以随意修改，如果开源，必须要写明修改的内容）</li>
<li>在延伸的代码中（修改和有源代码衍生的代码中）需要带有原来代码中的协议，商标，专利声明和其他原来作者规定需要包含的说明。</li>
<li>如果再发布的产品中包含一个Notice文件，则在Notice文件中需要带有Apache Licence。你可以在Notice中增加自己的许可，但不可以表现为对Apache Licence构成更改。（修改后开源的，可以加新的协议要求，但是不能与之前的apache协议冲突。）</li>
<li>Apache Licence也是对商业应用友好的许可。使用者也可以再需要的时候修改代码来满足并作为开源或商业产品发布/销售。（代码可以任意使用，原作者不承担任何责任）</li>
</ol>
<p>使用这个协议的好处是：</p>
<ol>
<li>永久权利。<strong>一旦被授权，永久拥有。</strong></li>
<li>全球范围的权利。在一个国家获得授权，<strong>适用于所有国家</strong>。假如你在美国，许可是从印度授权的，也没有问题。</li>
<li>授权免费。无版税， 前期、后期均无任何费用。</li>
<li><strong>授权无排他性。任何人都可以获得授权。</strong></li>
<li>授权不可撤消。一旦获得授权，没有任何人可以取消。比如，你基于该产品代码开发了衍生产品，你不用担心会在某一天被禁止使用该代码。</li>
</ol>
<hr>
<h3 id="GPL"><a href="#GPL" class="headerlink" title="GPL"></a>GPL</h3><p>GPL（GNU General Public License）</p>
<p>GPL协议又分为v1、v2、v3，GPL协议最早由大名鼎鼎的斯托曼创建。</p>
<ul>
<li>v1：已经gpl开源的软件不能修改协议成为闭源，修改的代码必须开源。开源并不免费，如果提供软件维护服务，可以向用户收取服务费。如果把gpl软件作为其中一个独立服务，软件不需要开源。</li>
<li>v2：在v1基础上，加上了一条限制，主要是强调gpl软件如果和自己开发的软件一起发布，自己开发的软件就必须开源，如果分开发布，就可以不开源</li>
<li>v3：在v2的基础上进一步收紧，不管是不是一起发布，只要用到了gpl软件，都必须开源</li>
</ul>
<p><strong>我们很熟悉的Linux就是采用了GPL。</strong>GPL协议和BSD, Apache Licence等鼓励代码重用的许可很不一样。GPL的出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用，但不允许修改后和衍生的代码做为闭源的商业软件发布和销售。这也就是为什么我们能用免费的各种linux，包括商业公司的linux和linux上各种各样的由个人、组织以及商业软件公司开发的免费软件了。</p>
<p>GPL协议的主要内容是只要在一个软件中使用(“使用”指类库引用，修改后的代码或者衍生代码)GPL 协议的产品，则该软件产品必须也采用GPL协议，既必须也是开源和免费。这就是所谓的”传染性”。GPL协议的产品作为一个单独的产品使用没有任何问题，还可以享受免费的优势。</p>
<p>由于GPL严格要求使用了GPL类库的软件产品必须使用GPL协议，对于使用GPL协议的开源代码，商业软件或者对代码有保密要求的部门就不适合集成/采用作为类库和二次开发的基础。</p>
<p>其它细节如再发布的时候需要伴随GPL协议等和BSD/Apache等类似。</p>
<hr>
<h3 id="MPL"><a href="#MPL" class="headerlink" title="MPL"></a>MPL</h3><p>MPL (Mozilla Public License 1.1)</p>
<p>MPL协议允许免费重发布、免费修改，但要求修改后的代码版权归软件的发起者。这种授权维护了商业软件的利益，它要求基于这种软件的修改无偿贡献版权给该软件。这样，围绕该软件的<strong>所有代码的版权都集中在发起开发人的手中</strong>。但MPL是允许修改和无偿使用的。MPL软件对链接没有要求。</p>
<hr>
<h3 id="LGPL"><a href="#LGPL" class="headerlink" title="LGPL"></a>LGPL</h3><p>LGPL（GNU Lesser General Public License）</p>
<p>LGPL是GPL的一个为主要为类库使用设计的开源协议。和GPL要求任何使用/修改/衍生之GPL类库的的软件必须采用GPL协议不同。LGPL 允许商业软件通过类库引用(link)方式使用LGPL类库而不需要开源商业软件的代码。<strong>这使得采用LGPL协议的开源代码可以被商业软件作为类库引用并发布和销售。</strong></p>
<p>但是如果修改LGPL协议的代码或者衍生，则所有修改的代码，涉及修改部分的额外代码和衍生的代码都必须采用LGPL协议。因此LGPL协议的开源代码很适合作为第三方类库被商业软件引用，但不适合希望以LGPL协议代码为基础，通过修改和衍生的方式做二次开发的商业软件采用。</p>
<p>GPL/LGPL都保障原作者的知识产权，避免有人利用开源代码复制并开发类似的产品</p>
<hr>
<h3 id="MIT"><a href="#MIT" class="headerlink" title="MIT"></a>MIT</h3><p>The MIT License</p>
<p>MIT是和BSD一样宽范的许可协议，源自麻省理工学院（Massachusetts Institute of Technology, MIT），又称“X许可协议”（X License）或“X11许可协议”（X11 License）。作者只想保留版权，而无任何其他了限制。MIT与BSD类似，但是比BSD协议更加宽松，是目前最少限制的协议。这个协议唯一的条件就是在修改后的代码或者发行包包含原作者的许可信息。适用商业软件。使用MIT的软件项目有：jquery、Node.js。</p>
<p>MIT与BSD类似，但是比BSD协议更加宽松，是目前最少限制的协议。这个协议唯一的条件就是在修改后的代码或者发行包包含原作者的许可信息，被许可人有权利使用、复制、修改、合并、出版发行、散布、再许可和/或贩售软件及软件的副本，及授予被供应人同等权利，但是在软件和软件的所有副本中都必须包含以上著作权声明和本许可声明。适用商业软件。使用MIT的软件项目有：jquery、Node.js。</p>
<p>MIT 协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><img src="/41f31a63/2.png" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://jokerliang.com/developers-will-know-5-kinds-of-open-source-licenses.html">https://jokerliang.com/developers-will-know-5-kinds-of-open-source-licenses.html</a><br><a href="https://guizimo.blog.csdn.net/article/details/105801442">https://guizimo.blog.csdn.net/article/details/105801442</a><br><a href="https://fuhanghang.blog.csdn.net/article/details/84035846">https://fuhanghang.blog.csdn.net/article/details/84035846</a><br><a href="https://blog.csdn.net/qietingfengsong/article/details/124745148">https://blog.csdn.net/qietingfengsong/article/details/124745148</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Git</category>
      </categories>
  </entry>
  <entry>
    <title>UCB CS61A: Computer Programs [Fall 2020] (PART I)</title>
    <url>/8977a093.html</url>
    <content><![CDATA[<h3 id="Lecture-1-Computer-Science"><a href="#Lecture-1-Computer-Science" class="headerlink" title="Lecture 1. Computer Science"></a>Lecture 1. Computer Science</h3><iframe src="//player.bilibili.com/player.html?aid=427281261&bvid=BV1s3411G7yM&cid=740918799&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<span id="more"></span>

<hr>
<h3 id><a href="#" class="headerlink" title></a></h3>]]></content>
      <categories>
        <category>🌙优秀学习资源</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-ResNet被全面超越了，是Transformer干的：依图科技开源“可大可小”T2T-ViT，轻量版优于MobileNet</title>
    <url>/96cdc0f0.html</url>
    <content><![CDATA[<p>【导读】又一篇Transformer来了！本文在ViT方面进行了一次突破性探索，提出了首次全面超越ResNet，甚至轻量化版本优于MobileNet系列的T2T-ViT。</p>
<img src="/96cdc0f0/4.jpg" class>

<p>本文是依图科技在ViT方面的一次突破性的探索。与之前ViT、Detr、Deit等不同之处在于：本文针对ViT的特征多样性、结构化设计等进行了更深入的思考，提出了一种新颖的Tokens-to-Token机制，用于同时建模图像的局部结构信息与全局相关性，同时还借鉴了CNN架构设计思想引导ViT的骨干设计。最终，<strong>仅仅依赖于ImageNet数据，而无需JFT-300M预训练，所提方案即可取得全面超越ResNet的性能</strong>，且参数量与计算量显著降低；与此同时，在轻量化方面，所提方法<strong>只需简单减少深度与隐含层维度即可取得优于精心设计的MobileNet系列方案的性能</strong>。</p>
<span id="more"></span>

<hr>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>语言模型中主流的Transformer已经开始对CV任务开始了降维打击，比如目标检测中NETR，low-level任务中的IPT，图像分类任务中的ViT与DeiT等等。ViT方案首先将输入图像拆分为定长的tokens序列，然后采用多个Transformer层对其进行全局相关性建模并用于图像分类。但ViT背靠比ImageNet更大的训练取得了优于纯CNN的性能，但如果仅采用ImageNet的话，其性能反而不如CNN方案。</p>
<p>作者通过分析发现：</p>
<ol>
<li>输入图像的简单token化难以很好的建模近邻像素间的重要局部结构(比如边缘、线条等)，这就导致了少量样本时的低效性</li>
<li>在固定计算负载与有限训练样本约束下，ViT中的冗余注意力骨干设计限制了特征的丰富性。</li>
</ol>
<p>可参考下图：</p>
<img src="/96cdc0f0/1.webp" class>

<p><strong>ResNet50可以逐步捕获到期望的局部结构(比如边缘、线条、纹理等)，然而ViT的结构建模信息较差，反而全局相关性被更好的获取。与此同时，可以看到：ViT的特征中存在零值，这导致其不如ResNet高效，限制了其特征丰富性。</strong></p>
<p>为克服上述局限性，作者提出了一种新的<em>Tokens-to-Token Vision Transformer，T2T-ViT</em>，它引入了(1) 层级<em>Tokens-to-Token</em>变换通过递归的集成近邻Tokens为Token将渐进的将图像结构化为tokens，因此局部结构可以更好的建模且tokens长度可以进一步降低；(2) 受CNN架构设计启发，设计一种高效的<em>deep-narrow</em>的骨干结构用于ViT。</p>
<p>相比标准ViT，<strong>所提T2T-ViT的参数量与MACs可以减低200%，并取得2.5%的性能提升</strong>(注仅用ImageNet从头开始训练)；所提T2T-ViT同样取得了优于ResNet的性能，比如，<strong>在ImageNet数据集上，T2T-ViT-ResNet50取得了80.7%的Top1精度</strong>。可参考下图。</p>
<img src="/96cdc0f0/2.webp" class>

<p>总而言之，本文的主要贡献包含以下几个方面：</p>
<ul>
<li><strong>首次</strong>通过精心设计Transformer结构在标准ImageNet数据集上取得了全面超越CNN的性能，而无需在JFT-300M数据进行预训练；</li>
<li>提出一种新颖的渐进式Token化机制用于ViT，并证实了其优越性，所提T2T模块可以更好的协助每个token建模局部重要结构信息；</li>
<li>CNN的架构设计思想有助于ViT的骨干结构设计并提升其特征丰富性、减少信息冗余。通过实验发现：deep-narrow结构设计非常适合于ViT。</li>
</ul>
<hr>
<h3 id="T2TViT方法简介"><a href="#T2TViT方法简介" class="headerlink" title="T2TViT方法简介"></a>T2TViT方法简介</h3><p>前面对ViT存在的问题以及本文的主要改进思路进行了简单的介绍，接下来我们将着重针对本文所提的T2T、deep-narrow骨干设计进行重点介绍与分析。</p>
<h4 id="Tokens-to-Token"><a href="#Tokens-to-Token" class="headerlink" title="Tokens-to-Token"></a>Tokens-to-Token</h4><p>Tokens-to-Token(T2T)模块旨在克服ViT中简单Token化机制的局限性，它采用渐进式方式将图像结构化为token并建模局部结构信息；而Tokens的长度可以通过渐进式迭代降低，每个T2T过程包含两个步骤：Restructurization与SoftSplit，见下图。</p>
<img src="/96cdc0f0/3.webp" class>

<h4 id="Re-structurization"><a href="#Re-structurization" class="headerlink" title="Re-structurization"></a>Re-structurization</h4><p>如上图所示，给定Tokens序列T，将通过自注意力模块对齐进行变换处理，可以描述为：</p>
<img src="/96cdc0f0/5.png" class>

<h4 id="Soft-Split"><a href="#Soft-Split" class="headerlink" title="Soft Split"></a>Soft Split</h4><p>正如上图所示，在得到重结构化图像I后，我们对其进行软拆分操作以建模局部结构信息，降低Tokens长度。为避免图像到tokens过程中的信息损失，我们将图像拆分为重叠块，也就是说：每个块将与近邻块之间构建相关性。每个拆分块内的Token将通过Concat方式变换为一个Token(即Tokens-to-Token)，因此可以更好的建模局部信息。我们假设每个块大小为k×k，重叠尺寸为s，padding为p</p>
<img src="/96cdc0f0/6.png" class>

<h4 id="T2T-module"><a href="#T2T-module" class="headerlink" title="T2T module"></a>T2T module</h4><p>通过交替执行上述Re-structurization与Soft Split操作，T2T模块可以逐渐的减少Token的长度、变换图像的空间结构。T2T模块可以表示为如下形式：</p>
<img src="/96cdc0f0/7.png" class>

<p>对于输入图像I_o，我们采用SoftSplit操作将其拆分为Token：T_1 = SS(I_o)。在完成最后的迭代后，输出Token T_f具有固定IG长度，因此T2T-ViT可以在T_f上建模全局相关性。</p>
<p>另外，由于T2T模块中的Token长度要比常规形式的更大，故而MAC与内存占用会非常大。为克服该局限性，在T2T模块中，我们设置通道维度为32(或者64)以降低MACs。</p>
<h4 id="T2T-ViT-Backbone"><a href="#T2T-ViT-Backbone" class="headerlink" title="T2T-ViT Backbone"></a>T2T-ViT Backbone</h4><p>由于ViT骨干中的不少通道是无效的，故而我们计划设计一种高效骨干以降低冗余提升特征丰富性。我们将CNN架构设计思想引入到ViT骨干设计以提升骨干的高效性、增强所学习特征的丰富性。由于每个Transformer具有类似ResNet的跳过连接，一个最直接的想法是采用类似DenseNet的稠密连接提升特征丰富性；或者采用Wide-ResNet、ResNeXt结构改变通道维度。本文从以下五个角度进行了系统性的比较：</p>
<ul>
<li>Dense Connection，类似于DenseNet</li>
<li>Deep-narrow vs shallow-wide结构，类似于Wide-ResNet一文的讨论</li>
<li>Channel Attention，类似SENet</li>
<li>More Split Head，类似ResNeXt</li>
<li>Ghost操作，类似GhostNet</li>
</ul>
<p>结合上述五种结构设计，我们通过实验发现：(1) Deep-Narrow结构可以在通道层面通过减少通道维度减少冗余，可以通过提升深度提升特征丰富性，可以减少模型大小与MACs并提升性能；(2) 通道注意力可以提升ViT的性能，但不如Deep-Narrow结构高效。</p>
<p>基于上述结构上的探索与发现，我们为T2T-ViT设计了Deep-Narrow形式的骨干结构，也就是说：更少的通道数、更深的层数。对于定长Token T_f，我们将类Token预期Concat融合并添加正弦位置嵌入(Sinusoidal Position Embedding, SPE)，类似于ViT进行最后的分类：</p>
<img src="/96cdc0f0/8.png" class>

<h4 id="T2T-ViT-Architecture"><a href="#T2T-ViT-Architecture" class="headerlink" title="T2T-ViT Architecture"></a>T2T-ViT Architecture</h4><img src="/96cdc0f0/9.webp" class>

<p>上图给出了T2T-ViT的网络结构示意图，它包含T2T模块与T2T骨干两部分。上图给出了n=2的结构示意图(即n+1=3个soft split，n个Re-structurization)。每个Soft Split的块大小分别为[7, 3, 3]，重叠为[3, 1, 1]。</p>
<img src="/96cdc0f0/10.webp" class>

<p>为更好的与常见手动设计CNN进行对比，我们设计了不同复杂度的T2T-ViT模型，见上表。比如对标ResNet50的T2T-ViT-14，对标ResNet101的T2T-ViT-19，对标ResNet152的T2T-ViT-24，对标MobileNetV1、MoblieNetV2的T2T-ViT-7，T2T-ViT-10，T2T-ViT-12。</p>
<hr>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>为更好说明所提方案的有效性，我们将其与ViT进行了对比，结果见下表。从表中数据可以看到：<strong>相比ViT，所提方案具有更少的参数量、MAC，但取得了更高的性能。</strong></p>
<img src="/96cdc0f0/11.webp" class>

<p>下表给出了所提方案与ResNet的对比。从中可以看到：<strong>在相同模型大小与MACs约束下，所提方案能够以1%-2.5%的性能优势超过ResNet。</strong></p>
<img src="/96cdc0f0/12.webp" class>

<p>与此同时，本文还给出了所提方案与轻量化网络MobileNet系列的对比，见下表。可以看到：<strong>在轻量化网络层面，所提方案可以取得比MobileNet系列更好的性能。</strong>注：由于MobileNet系列采用了高效卷积(Depthwise)操作导致其计算量要比T2T-ViT稍低，而T2T-ViT的设计则更为简单，只需要调整深度、隐含层维度即可得到不同计算量的模型。</p>
<img src="/96cdc0f0/13.webp" class>

<p>最后还给出了不同CNN结构设计思想在T2T-ViT的性能对比，见下表。</p>
<img src="/96cdc0f0/14.webp" class>

<p>从上表可以看到：</p>
<ul>
<li><strong>无论是SE还是Deep-Narrow结构有益于T2T-ViT，但Deep-Narrow结构设计更为有效</strong></li>
<li>稠密连接会损害ViT和T2T-ViT的性能</li>
<li>SE有助于提升ViT与T2T-ViT的性能</li>
<li>ResNeXt结构与ViT与T2T-ViT的影响非常小，几乎可以忽略</li>
<li>Ghost可以进一步压缩T2T-ViT的模型大小、降低MACs，但会造成性能的下降</li>
</ul>
<img src="/96cdc0f0/15.webp" class>

<p>最后的最后，本文还对所提T2T模块与Deep-Narrow结构设计进行了消融分析，结果见上表。从中可以看到：(1) <strong>T2T模块比卷积更优</strong>，这是因为它可以同时建模全局相关性与结构信息；(2) <strong>相比Shallow-Wide结构，Deep-Narrow结构可以带来2.9%的性能提升</strong>。</p>
<p>全文到此结束，更多消融实验分析建议好看原文，笔者强烈建议对Transformer感兴趣的同学研究一下该文，文中不少思想值得各位思考与借鉴。</p>
<hr>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>开源的才是好工作，在paper放出来之前先开源的更是好工作。依图科技就将T2T-ViT相关code与预训练模型在github上进行了开源。</p>
<p>上述论文、code以及预训练模型下载： 链接: <a href="https://pan.baidu.com/s/1ddoyH_kFK_7GhATCy9uDuw">https://pan.baidu.com/s/1ddoyH_kFK_7GhATCy9uDuw</a> 提取码: pi7d</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/348046612">https://zhuanlan.zhihu.com/p/348046612</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>“情感脑机接口”线上研讨会-清华大学张丹教授作“基于对比学习的跨个体脑电情绪识别方法”的主题报告</title>
    <url>/e9b82e5e.html</url>
    <content><![CDATA[<p>2022年11月10日，在“情感脑机接口”的线上研讨会上，清华大学张丹教授在研讨会上作“基于对比学习的跨个体脑电情绪识别方法”的主题报告。</p>
<img src="/e9b82e5e/1.jpg" class>

<span id="more"></span>

<p>报告开始，张丹教授对脑电情绪识别的背景做了铺垫，从深度学习在棋类游戏取得的成果引入到脑机接口领域未来在情绪识别上的突破。通过对近年来人们对情绪识别这一领域的关注，点明了脑电情绪识别的重要性。</p>
<img src="/e9b82e5e/2.jpg" class>

<p>在2016年提出的面向未来的20大问题中，“Will we use wearable technologies to detect our emotion?”是其中的一大重点问题。张丹教授从可穿戴设备来检测情绪的可行性角度出发，再次说明了情绪识别的重要性。</p>
<img src="/e9b82e5e/3.jpg" class>

<p>从脑电情绪识别的准确度来看，EEG识别的正确率普遍高于其它单模态检测，张丹教授从这一角度说明了为什么人们关注使用EEG进行情绪识别。</p>
<img src="/e9b82e5e/4.jpg" class>

<p>从脑机接口的发展来看，近年来关于情绪的脑机接口愈受人们关心，成为一个在脑机接口领域细分下来的新兴的、人们越来越重视的发展范式和发展方向。这个方向中，更关注的是情绪的被动识别，而不是传统脑机接口主动的控制。</p>
<img src="/e9b82e5e/5.jpg" class>

<p>在这样的大背景下，传统的做法是将脑电数据打上对应的情绪标签，通过机器学习学到一个分类模型，这样的思路跟其它的分类模型是一致的。但其不像传统的语音识别、图像识别那么有确定性，情绪的标签是很微妙的，有很多个体化的因素在里面。标签体系的构建和诱发素材/诱发方法的建设是脑电情绪分类面临的挑战。</p>
<img src="/e9b82e5e/6.jpg" class>

<p>目前情绪诱导的常用方法是用视频来触发，在研究阶段暂时能满足，但真正走向应用时光用视频是不够的。真实的情况是人在任何自然场景环境下情绪都能发生，不一定需要视频或图片进行诱发，这也是在数据构建阶段遇到的挑战。</p>
<img src="/e9b82e5e/7.jpg" class>

<p>从标签体系来说，关于情绪理论还没有一个统一的标准，不同数据集对于情绪的标注方式并不完全一致，DEAP数据集采用的是唤起度和效价的二维连续标注，SEED数据集采用的是离散的情绪标注方式，其标注的方法皆有其合理性，目前还没有一种盖棺定论的方法，脑电情绪识别领域还正在发展中。</p>
<img src="/e9b82e5e/8.jpg" class>

<p>目前跨个体的情绪识别准确度不高，想提高准确率需要被试的历史数据进行学习，这也限制了目前情绪识别的应用。不过张丹教授对此保持乐观态度，相较于语音识别近年来的发展，相信未来脑机情绪领域也能在跨个体的情绪识别有所突破。</p>
<img src="/e9b82e5e/9.jpg" class>

<p>可以看出不同个体间的特征降维到二维后差异还是很大的，但个体间的差异很好区分，这点从个体内和跨个体的分类正确率区别中也看得出来。</p>
<img src="/e9b82e5e/10.jpg" class>

<p>跨个体间的差异也并不是全无是处，或许能通过这些差异在正常人与病人间找出差异之处，从而更好地辅助其它领域。</p>
<img src="/e9b82e5e/11.jpg" class>

<p>如果想做跨个体的情绪识别，张丹教授分享了两种方法：域适应（Domain Adaptation, DA）、域泛化（Domain Generalization, DG）。域适应方法是根据新数据在历史数据中的相似性，使用历史数据中与之相似性更高的来建立分类模型应用到新的个体。</p>
<img src="/e9b82e5e/12.jpg" class>

<p>域泛化方法能够更好地习得每个人的个体化信息，通过模型的泛化对特征进行更好的建模。</p>
<img src="/e9b82e5e/13.jpg" class>

<img src="/e9b82e5e/14.jpg" class>

<p>另一种角度来看，不单单从脑电强度出发，人们在对同一事件的脑电相应的一致性也能反应情绪的不同。人与人之间脑电强弱不一定相同，但对同一事件的大脑相应区域是类似的，说明这种人的神经活动一致性能够用来描述情绪的状态。这是张丹教授本次报告想要分享的重点。</p>
<img src="/e9b82e5e/15.jpg" class>

<p>人与人之间脑电的相关性有多种计算方式。Hasson等仅计算了多人脑电之间的平均信息，张丹教授分享了其它的一些计算方式，例如计算相位响应和幅度响应、寻找关键成分来反应一致性表达。</p>
<img src="/e9b82e5e/16.jpg" class>

<p>是否能用深度学习方法进行优化？如何更加关注个体间的一致性对情绪的贡献？张丹教授提出了基于对比学习的跨个体脑电情绪识别方法，该模型不再是学习样本到标签的特征，而是每次都是成对的正负样本进行呈现，标签仅作为判断正负样本的参考。这种方式更加接近于人类的学习方法，人去学习时并不是学习具体的标签，而是通过对比的方式总结出一类物体该有的特征。</p>
<img src="/e9b82e5e/17.jpg" class>

<img src="/e9b82e5e/18.jpg" class>

<img src="/e9b82e5e/19.jpg" class>

<p><strong>Contrastive Learning for Inter-Subject Alignment（CLISA）是张丹教授提出的基于对比学习的跨个体脑电情绪识别方法。</strong>该方法的样本的定义较为保守，观看相同的视频时，即感知觉一致时产生的脑电即为正样本，观看不同情绪触发视频为负样本。在模型的构建上引入了时域卷积和空域卷积这些模块，使之更具有生理的可解释性和适配数据的特点。</p>
<img src="/e9b82e5e/20.jpg" class>

<p>在预测模型中，将原始数据压缩编码后提取微分熵（Didderential Entropy, DE）特征，进行进一步特征提取与分类，最后再输出结果。</p>
<img src="/e9b82e5e/21.jpg" class>

<p>在自采数据集中，选择的情绪从积极、中性、消极出发，共有3大类9小类，相较于SEED数据集相比，数据量更加庞大与完善，能够更好地在对比学习上使用。</p>
<img src="/e9b82e5e/22.jpg" class>

<img src="/e9b82e5e/23.jpg" class>

<p>在效果验证上，更好的测试应该是使用诱发相同情绪的不同视频片段，而不是在训练中使用过的视频继续测试，这样能够更泛化地测试出模型的性能。在测试结果中，可以看出对比学习随着被试样本的增多，验证准确率有明显的提升。</p>
<img src="/e9b82e5e/24.jpg" class>

<p>张丹教授最后总结到，通过时域卷积和空域卷积，能够更加可视化地看出大脑是以何种机制支持我们的情绪识别，能够更加符合生理预期形态的描述。在积极、中性、消极的情绪中的最大贡献成分里，空间分布是比较类似的，都集中在前额的不对称表达，不一样的是在时域频域表达上，大脑震荡的节律是在完全不同的频带上。张丹教授表示到，目前并不敢盖棺定论这其中的联系，但可以为以后的研究提供支撑。</p>
<p><strong>张丹，清华大学心理学系副教授、博士生导师，清华大学脑与智能实验室兼职研究员。研究致力于运用脑电、近红外等脑成像技术开展情绪、言语等社会交互关键认知功能的神经机制研究，同时运用脑机接口、穿戴式神经生理测量技术，开展面向情感计算、人机交互、心理健康等领域的智能心理测量方法与应用研究。</strong></p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.scholat.com/teamwork/showPostMessage.html?id=12631">https://www.scholat.com/teamwork/showPostMessage.html?id=12631</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐讲座</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-脑电EEG常用的特征-《A review of EEG features for emotion recognition》</title>
    <url>/8ed6a4ed.html</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>情绪是人对外界事物产生的心理和生理反应。准确地识别情绪在人机交互研究中占据着重要位置，其成果可应用在医学、教育、心理、军事等方向。由于脑电信号具有客观, 不易伪装等特点, 其在情绪识别领域的应用广受关注。从脑电信号中提取与情绪关联大、区分能力强的特征, 有助于后续的分类器更有效地识别不同情绪状态。本文调研了目前常用于情绪识别研究领域的脑电信号特征, 从时域、频域、时频域和空间域 4 个方面介绍其定义、计算方法, 以及与情绪的联系。</p>
<span id="more"></span>

<hr>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>情绪是人对客观事物的态度体验及相应的行为反应 [1]，对于人类的行为和心理健康有着重要影响。如何准确识别情绪，在人机交互研究中占据重要位置，且有实际应用的意义：在医学方面，有助于对有心理疾病或表达障碍的患者进行疏导与诊断；在教育方面，根据听者的情绪施以不同的教学手段，可提高授课效率。在《国家中长期科学和技术发展规划纲要(2006∼2020)》中, 脑科学和人机交互均列为国家重大需求的关键技术, 而情绪识别技术将为其研究提供重要的理论依据。</p>
<p>为了识别情绪，研究人员需要对情绪状态进行量化和建模。目前广泛使用的情绪量化模型主要有离散模型和维度模型两种。在离散模型中，情绪空间由离散而有限的基本情绪构成，例如大多数心理学研究者公认的 6 种基本情绪 —— 高兴 (happiness)、悲伤 (sadness)、惊讶 (surprise)、恐惧 (fear)、愤怒 (anger) 和厌恶 (disgust)，其他情绪都可以由基本情绪组合而成 [2]。维度模型则是基于认知评价将情绪空间划分为效价 – 唤醒度 (valence-arousal, VA) 两个维度 [3]，或效价 – 唤醒度 – 优势度 (valence-arousal-dominance, VAD) 3 个维度 [4]，目前对于 VA 模型的研究比 VAD 模型更广泛。效价表示情绪是积极还是消极的；唤醒度反映情绪的强烈程度；优势度指人能否控制这种情绪。维度模型可将离散情绪映射至坐标空间，图 1 即为用 VA 模型表示高兴、恐惧和悲伤 3 种离散情绪。</p>
<img src="/8ed6a4ed/1.png" class>

<p>面部表情、语音语调、姿势动作和生理信号都可以作为情绪识别的数据来源，其中生理信号难以伪装，包含的信息也更丰富 [5]。使用生理信号识别情绪通常包括以下 6 步: </p>
<ol>
<li>情绪诱发，使用图片、声音或视频等刺激材料诱发被试者产生特定类型的情绪</li>
<li>信号采集，通过设备采集被试产生情绪时的各种生理信号</li>
<li>信号预处理，通常使用滤波去除噪声和伪迹</li>
<li>特征提取，对信号进行变换。从中计算与目标任务相关的特征</li>
<li>用机器学习领域的分类算法进行情绪分类</li>
<li>以图表等形式反馈识别结果。<br>其中，特征提取是至关重要的一步，若能找出与情绪最相关的特征集合，有利于提高后续分类器的识别准确率。</li>
</ol>
<p>在脑电 (electroencephalogram, EEG)、心电 (electrocardiogram, ECG)、肌电 (electromyography, EMG) 和皮肤温度 (skin temperature, SKT) 等生理信号中，使用脑电识别情绪具有操作简单、成本低、效果好的优势，近年来得到了广泛关注 [6]。脑电是记录头皮电位变化的信号，在一定程度上反映大脑皮层的活动。研究表明不同脑区参与不同的感知和认知活动，例如额叶 (frontal lobe) 与思维、意识有关，颞叶 (temporal lobe) 与人脸和场景等复杂刺激信息的处理、嗅觉和听觉有关，顶叶 (parietal lobe) 与多种感官信息的整合和对物体的操作控制有关，枕叶 (occipital lobe) 则与视觉有关 [7].</p>
<hr>
<hr>
<h3 id="现有脑电特征的定义与计算方法"><a href="#现有脑电特征的定义与计算方法" class="headerlink" title="现有脑电特征的定义与计算方法"></a>现有脑电特征的定义与计算方法</h3><p>在情绪识别领域，EEG传统特征主要分为时域(time domain)特征、频域(frequency domain)特征、时频域(time-frequency domain)特征3类。考虑到脑区的不对称性也可以反映情绪信息, 空间域(space domain)特征也因此逐渐用于识别情绪。本节将从时域、频域、时频域、空间域4个角度介绍常用于情绪识别的脑电特征。</p>
<h4 id="时域特征"><a href="#时域特征" class="headerlink" title="时域特征"></a>时域特征</h4><p>大多数脑电设备以时域形式采集 EEG 信号，故时域特征最直观易得，其主要包括：事件相关电位、信号统计量、能量、功率、高阶过零分析、Hjorth参数特征、不稳定指数和分形维数。</p>
<p>脑电设备根据一定的采样频率对原连续信号进行采样, 得到离散序。 我们约定，用 s(n) 表示某个电极上第 n 次采样得到的 EEG 信号值, n = 1, 2, . . . , N , N 表示总采样数。</p>
<h5 id="事件相关电位"><a href="#事件相关电位" class="headerlink" title="事件相关电位"></a>事件相关电位</h5><p>事件相关电位 (event related potential, ERP) 是指由离散刺激事件引发的脑电电压波动，可反映认知加工的过程[8]。与不间断的脑电电压波动幅度相比，大多数 ERP 幅度小，因此通常取多段由相同刺激引发的 EEG 的平均值分析 ERP [9]。</p>
<p>ERP 的波形随时间变化呈现具有不同持续时间、振幅和极性的波峰，因而通常从 3 个方面来衡量：潜伏期 (latency)、振幅 (amplitude)、正负极性 (polarity)。图 2 是在 0 ms 时发生的刺激事件引发的 ERP 波形示意图。</p>
<ol>
<li>潜伏期指大脑皮层从接受刺激到发生反应的延迟时间，通常计算刺激起始到波峰顶点间的时长。潜伏期与神经活动的加工时间有关，加工越久潜伏期越长。</li>
<li>振幅有基线 – 波峰和波峰 – 波峰两种测量方式，反映大脑的兴奋性高低，例如给被试呈现负性刺激材料时，ERP 的振幅会增加 [10]。</li>
<li>极性中的正性电压波动 (positive) 用 P 表示，负性 (negative) 用 N 表示 [11]。</li>
</ol>
<img src="/8ed6a4ed/2.png" class>

<p>ERP 的成分一般遵循两种命名体系, 一种依据潜伏期, 例如 P300 表示电压向正性波动, 且潜伏期为 300 ms 左右; 另一种则依据成分的序列性, 例如刺激诱发的第 1 个显著的负成分为 N1, 第 3 个显著的正成分为 P3。ERP 成分的潜伏期数值往往约为序列位置的 100 倍, 所以第 1 种命名方式中的 P300 等价于第 2 种方式的 P3。</p>
<p>在情绪方面, 潜伏期较短的 ERP 成分与效价有关 [12∼15], 如枕叶的 P100 在产生消极情绪时的振幅大于积极情绪时的振幅 [16, 17]。P300 和潜伏期在 500 ms 以上的皮层慢电位 (slow cortical potential, SCP) 等潜伏期较长的 ERP 成分与唤醒度有关 [6, 18∼20]。由于 P300 的测量更可靠, 且其振幅和潜伏期特征包含的信息更丰富, 故 P300 为神经科学领域研究最多的 ERP 成分 [11]。Nieuwenhuis 等 [21] 的研究表明, P300 在正性或负性情绪下都比中性状态时更显著。</p>
<p>ERP 的瞬时分辨率强, 常用于由离散的视、听和触觉刺激诱发情绪的情况, 例如图片、短音频和振动等, 而不常用于连续的情绪诱发。在实时系统中, 情绪的触发点很难确定和控制, 所以 ERP 难以应用在情绪的实时诱发和检测中 [22]。</p>
<hr>
<h5 id="信号统计量"><a href="#信号统计量" class="headerlink" title="信号统计量"></a>信号统计量</h5><p>电信号通用的时域统计特征也可应用于 EEG 信号, 它们简单易计算, 且可以得到较好的识别效果 [23∼25]。 例如, 平均值 μ_s, 标准差 σ_s, 一阶差分绝对值的平均值:</p>
<img src="/8ed6a4ed/3.png" class>

<p>二阶差分绝对值的平均值:</p>
<img src="/8ed6a4ed/4.png" class>

<p>归一化的一阶差分 (也称为归一化长度密度, 可衡量脑电信号的自相似性 [26]):</p>
<img src="/8ed6a4ed/5.png" class>

<p>和归一化的二阶差分:</p>
<img src="/8ed6a4ed/6.png" class>

<hr>
<h5 id="能量"><a href="#能量" class="headerlink" title="能量"></a>能量</h5><p>大脑皮层的活跃程度影响 EEG 的振幅, 进而反映为能量的波动。信号的能量在时域上表示为幅度的平方, 即</p>
<img src="/8ed6a4ed/7.png" class>

<hr>
<h5 id="功率"><a href="#功率" class="headerlink" title="功率"></a>功率</h5><p>平均功率可用能量除以采样数得到 [27], 在频域上也有能量和功率的计算方法, 将在 2.2 小节进行说明。</p>
<img src="/8ed6a4ed/8.png" class>

<hr>
<h5 id="Hjorth-参数特征"><a href="#Hjorth-参数特征" class="headerlink" title="Hjorth 参数特征"></a>Hjorth 参数特征</h5><p>Hjorth 定义了信号在时域上的 Hjorth 参数特征 [28], Activity 衡量信号波幅的偏离程度:</p>
<img src="/8ed6a4ed/9.png" class>

<p>Mobility 衡量坡度的变化:</p>
<img src="/8ed6a4ed/10.png" class>

<p>Complexity 衡量一个振幅上有多少个标准的坡 (slope):</p>
<img src="/8ed6a4ed/11.png" class>

<p>其中, μ_s 表示信号平均值, s′(n) 表示一阶导数, var 表示方差。</p>
<hr>
<h5 id="高阶过零分析"><a href="#高阶过零分析" class="headerlink" title="高阶过零分析"></a>高阶过零分析</h5><p>Petrantonakis 等 [29] 提出高阶过零分析 (higher order crossings, HOC) 的方法, 用信号通过零点的次数来反映信号的振荡程度。将 EEG 序列 s(n) 转换为均值为 0 的序列 Z(n), n = 1, 2, . . . , N , 将该序列通过 M 个高通滤波器, k 表示滤波器的顺序, k = 1, 2, . . . , M :</p>
<img src="/8ed6a4ed/12.png" class>

<p>再根据 L_k{Z(n)} 构建二值序列</p>
<img src="/8ed6a4ed/13.png" class>

<p>X_n(k) 中符号的变化次数即为 HOC 值:</p>
<img src="/8ed6a4ed/14.png" class>

<p>由于 EEG 在不同情绪下的振荡模式和特性不同, 与谱功率相比, HOC 可以更鲁棒地表征信号的振荡特点 [18]; 与统计特征或基于小波变换的特征相比, 使用 HOC 可以更好地区分第 1 节所述的 6 种基本情绪 [29]。</p>
<hr>
<h5 id="不稳定指数"><a href="#不稳定指数" class="headerlink" title="不稳定指数"></a>不稳定指数</h5><p>不稳定指数 (non-stationary index, NSI) 衡量局部平均值随时间的变化 [26]。将信号分成 n 段并计算各段的均值, NSI 定义为这 n 个平均值的标准差。NSI 越大表示局部平均值振荡越大. Hausdorff 等[30] 发现在不同的分割时长上, 得到的 NSI 值是类似的。</p>
<hr>
<h5 id="分形维数"><a href="#分形维数" class="headerlink" title="分形维数"></a>分形维数</h5><p>分形维数 (fractal dimension, FD) 可用来表示时域信号的复杂程度。Sevcik 方法 [31]、分形布朗运动 (fractal Brownian motion) [32]、计盒法 (box-counting) [33]、Higuchi 算法 [34] 都可用来计算 FD, 而 Higuchi 算法的效果更好 [22], 使用该算法计算 EEG 的分形维数特征 FDs 的过程如下: 首先将时域信号序列 s(n), n = 1, 2, … , N 重写为 {s(m), s(m + k), … , s(m + ⌊ (N−m)/k ⌋ · k)}, 其中, m = 1, … , k 是起始时间, k 是时间间隔。在每个 m 的取值上, 令</p>
<img src="/8ed6a4ed/15.png" class>

<p>用 H(k) 表示 H_m(k) 的平均值, 取 FD_s 为</p>
<img src="/8ed6a4ed/16.png" class>

<hr>
<h4 id="频域特征"><a href="#频域特征" class="headerlink" title="频域特征"></a>频域特征</h4><p>由于时域特征无法展示信号的频率信息, 研究者加入了频域分析 [35]。首先将原始的时域信号转换至频域获得频谱, 之后将频段分解到与人的心理活动联系密切 [36] 的 5 个子频段 δ, θ, α, β, γ, 再从中计算特征。</p>
<p>通常使用傅里叶变换 (Fourier transfer, FT) 进行时–频域转换。将信号投影到固定的正交函数系上, 用一组变换系数 (谱线) 表示时间函数, 各谱线表示某一频率分量的相位、幅度等参数 [37]。</p>
<p>由于采集到的 EEG 信号为离散序列 s(n), 实际操作中多使用离散傅里叶变换法 (discrete Fourier transfer, DFT), 用求和代替积分运算, 使计算机能够处理傅里叶变换 [5]。应用于 EEG 信号可得频谱</p>
<img src="/8ed6a4ed/17.png" class>

<p>其中 k 表示样本点序号, k = 0, 1, … , N − 1。记 WN = e^[−j( 2π/N )] 为变换矩阵。从式中可看出, 每个 S(k) 需要 N − 1 次复数加法和 N 次乘法运算, 整个序列的 DFT 运算需要 N (N − 1) 次复数加法和 N^2 次复数乘法, 运算复杂度高。</p>
<p>快速傅里叶变换 (fast Fourier transfer, FFT) 也称库利 – 图基 (Cooley-Tukey) 算法, 利用 WN 的周期性 W^nk_N = W^[(nk) mod N]_N 和对称性 W^[nk + (N/2)]_N = −W^nk_N , 将 DFT 运算按照奇偶性逐级分解, 第 1 级将 N 个点分为各 N/2 个采样点的两组, 第 2 级再细分为各 N/4 个采样点的四组, 以此类推, 运算流程如图 3 所示, 自图的左端向右运算, 两条线的汇合点表示数值相加, 线旁标注的 W^k 表示与相应的数值相乘。例如</p>
<img src="/8ed6a4ed/18.png" class>

<p>从上式可看出, 单元包含一个复数乘和两个复数加操作。对于 N 个采样点, 共 log N 层, 每层 N/2 个单元, 因而整个 FFT 算法只需要 N/2 * log N 次乘和 N * log N 次加法, 且 N 越大, FFT 的优越性越显著 [37]。</p>
<img src="/8ed6a4ed/19.png" class>

<p>由上述步骤处理后得到的频段经过分解, 得到 5 个子频段 δ (1∼4 Hz), θ (4∼8 Hz), α (8∼12 Hz), β (13∼30 Hz), γ (31∼45 Hz), 在不同实验中, 各频段的边界略有几赫兹的差异。EEG 的不同频段与不同的意识状态有关: δ 波与无意识的状态有关, 常出现于深度无梦的睡眠; θ 波与潜意识有关, 例如有梦境的睡眠或浅度睡眠、困倦, 当诱发积极情绪时, 额中线上的 θ 波功率会增强 [38]; α 波多出现于较为放松的有意识状态, 额叶上 α 波的不对称性可反映情绪的不同效价 [39, 40]; β 波与活跃的意识状态例如注意力集中的活动有关, 在额叶区域较为显著, 可反映情绪的效价 [6, 41, 42]; γ 波则与大脑的过度活跃现象、特定的认知或运动有关 [43∼45]。中性情绪和消极情绪在 β 和 γ 波段有相似的振荡模式, 但其在 α 波段的振荡能量更高 [46]。</p>
<p>分解频段后, 再分别提取功率、功率谱密度、事件相关同步化、事件相关去同步化、高阶谱、微分熵等特征。</p>
<hr>
<h5 id="功率-1"><a href="#功率-1" class="headerlink" title="功率"></a>功率</h5><p>功率在时域上的计算方法如式 (6) 所示。而在频域上, 可通过功率谱密度的积分运算得到。通过将整个频段划分为若干个子频段, 计算各子频段功率的平均值、最值和方差等。此外, β 波段和 α 波段的平均功率之比可以表征脑部的活跃状态, 可用于情绪识别研究 [22]。</p>
<hr>
<h5 id="功率谱密度"><a href="#功率谱密度" class="headerlink" title="功率谱密度"></a>功率谱密度</h5><p>功率谱密度 (power spectral density, PSD) 描述信号的功率随频率的变化情况, 可由直接法或间接法得到。</p>
<p><strong>直接法</strong>。直接法包括周期图法、Welch 法等线性经典谱估计法, 和最大熵法、最大似然法等非线性现代谱估计法。经典谱估计法更适合长序列, 当信号序列较短时, 谱分辨能力较差; 而非线性方法可保证较高的谱分辨率 [5]。</p>
<ol>
<li>周期图法 (periodogram)。功率谱密度由 DFT 后幅频特性的平方除以 EEG 序列的长度得到。由于 DFT 的周期性, 功率谱也有周期性, 故称周期图。因为不同序列长度会产生不同的周期图, 无法得到稳定的估值, 故取各子区间上周期图的均值作为功率谱估值。</li>
<li>Welch 法。在周期图的基础上加入平滑操作。先分成若干子波段, 再用子波段内的信号与窗函数相乘进行平滑, 最后在各子区间上取平均, 以降低周期图的波动程度。</li>
<li>最大熵法。取一组自相关函数与已知信号序列相等, 且自相关函数以外的部分随机性最大的序列, 以所取序列的功率谱作为已知序列功率谱的估值。由于要求随机性最大, 因而熵最大, 称最大熵法。</li>
<li>最大似然谱估计法。也称最小方差谱估计法。让信号通过一个滤波器, 保证所需信号不失真且其他频率信号均方差最小。若将一个确定信号加一个 Gauss 白噪声作为输入, 则滤波器输出此信号的最大似然估值, 故称为最大似然法。若信号只是一个确定信号, 例如脑电信号, 则输出为确定信号最小方差的无偏估值, 即为该信号的功率谱估值。</li>
</ol>
<p><strong>间接法</strong>。由维纳 – 辛钦 (Wiener-Khinchin) 定理可知, 信号的功率谱密度可由时域信号的自相关函数的傅里叶变换得到, 称为间接法。得到功率谱后, 根据给定的某一波段, 计算该波段内功率谱密度的均值、最值、方差等统计量作为特征。</p>
<hr>
<h5 id="事件相关-去-同步化"><a href="#事件相关-去-同步化" class="headerlink" title="事件相关 (去) 同步化"></a>事件相关 (去) 同步化</h5><p>在一个刺激事件之后的若干毫秒内, EEG 信号在某一频段上功率的快速升高称为事件相关同步化 (event related synchronization, ERS); 相反, 功率降低称为事件相关去同步化 (event related desynchronization, ERD) [47]。它们在时域中不明显, 需要在频域上经过带通滤波和平滑后才能观察到。一般认为 ERS 和 ERD 与大脑神经元放电的同步性有关, 当同步性增加时能量叠加变高, 产生 ERS, 同步性下降时能量降低, 产生 ERD。第 n 个采样点上得到的特征 ERDS_n 为</p>
<img src="/8ed6a4ed/20.png" class>

<p>其中, A_n 表示在第 n 个采样点上的功率, R 表示在该采样点前后一段区间上的平均功率 [48]。</p>
<p>效价上, γ 波段上的 ERS 和 ERD 特征可区分正负性情绪 [45]; 产生正性情绪时, 颞叶左侧的 θ 波段上的 ERS 特征会变得显著, 而产生负性情绪时, 右侧 ERS 特征更显著 [41]。唤醒度上, 非中性情绪与中性情绪相比, θ 波段的 ERS 和 ERD 特征在整个右侧脑区都更加显著 [49]。</p>
<hr>
<h5 id="高阶谱"><a href="#高阶谱" class="headerlink" title="高阶谱"></a>高阶谱</h5><p>高阶谱 (higher order spectrum, HOS) 特征通常需要计算双谱 (bispectrum) 和双相干谱 (bicoherence)。双谱是信号三阶矩的傅里叶变换, 可用来量化信号分量之间的二次相位耦合, 即原信号与谐波发生耦合作用, 产生的新频率成分的和频与差频。与功率谱密度相比, 双谱特征涵盖相位信息, 其计算方法为</p>
<img src="/8ed6a4ed/21.png" class>

<p>其中, f_1, f_2 指两个信号各自的频率, F(f) 指傅里叶变换, E[x] 为期望, ∗ 表示共轭复数。双相干谱是双谱的归一化形式</p>
<img src="/8ed6a4ed/22.png" class>

<p>其中, P(f) = E[F(f) F∗(f)] 是功率谱。Bis 与 Bic 各自的模或模的平方都可以作为高阶谱特征 [22]。</p>
<hr>
<h5 id="微分熵"><a href="#微分熵" class="headerlink" title="微分熵"></a>微分熵</h5><p>微分熵 (differential entropy, DE) 是香农 (Shannon) 信息熵 − ∑_x p(x) log(p(x)) 在连续变量上的推广形式</p>
<img src="/8ed6a4ed/23.png" class>

<p>其中, p(x) 表示连续信息的概率密度函数, [a, b] 表示信息取值的区间。对于一段特定长度的近似服从 Gauss 分布 N (μ, σ^2_i ) 的 EEG, 其微分熵为 [46, 50]:</p>
<img src="/8ed6a4ed/24.png" class>

<p>等于其在特定频段上的能量谱的对数 [51]。</p>
<p>Zheng 等 [46] 在识别正性、中性和负性 3 种情绪的实验中, 使用 DE 作为特征获得的识别准确率高于其他特征。</p>
<hr>
<h4 id="时频域特征"><a href="#时频域特征" class="headerlink" title="时频域特征"></a>时频域特征</h4><p>傅里叶变换的作用范围是整个时域, 缺乏局部化能力, 且无法确认非平稳信号各频域成分对应的时刻, 所以引入了时域与频域结合的时频域。通常做法是划分出若干时间窗, 各窗内的子信号近似平稳, 将其变换至频域得到一组频域特征, 滑动时间窗可处理不同时段, 从而同时获取信号的时域和频域信息, 提高对不稳定信号的处理能力, 可粗略计算情绪开始和持续的时间 [52]。通常使用短时傅里叶变换 (short-time Fourier transform, STFT)、小波变换 (wavelet transform, WT) 和小波包变换 (wavelet packet transform, WPT) 或 Hilbert-Huang 方法来进行时频域信号变换。</p>
<hr>
<h5 id="短时傅里叶变换"><a href="#短时傅里叶变换" class="headerlink" title="短时傅里叶变换"></a>短时傅里叶变换</h5><p>STFT 可提高对噪声干扰的鲁棒性 [53]。使用等长的窗函数 w(n − t) 计算窗内信号的傅里叶变换:</p>
<img src="/8ed6a4ed/25.png" class>

<p>再求出各窗函数的时间点及频率成分。常见的窗函数有三角波、方波和 Gauss 函数等, 通常默认使用 Gauss 函数, 此时 STFT 也称 Gabor 转换。</p>
<p>选择合适的窗长度至关重要, 短的时间窗提供的信息量不足, 导致频域分辨率差; 长的时间窗又会导致各窗差异大, 时域分辨率差。目前情绪识别研究中效果好的时间窗长度多为 1 ∼ 2 s [5, 54, 55]。</p>
<hr>
<h5 id="小波变换"><a href="#小波变换" class="headerlink" title="小波变换"></a>小波变换</h5><p>由于 STFT 的时间窗长度对效果有明显影响, 且无法同时在时域和频域获得高分辨率, 故引入小波变换。主要有两种基本类型: 连续小波变换 (continuous wavelet transform, CWT) 和离散小波变换 (discrete wavelet transform, DWT) [56]。</p>
<p>基本小波, 或称小波母函数 φ(t) 应平方可积, 且其傅里叶变换满足 ( |φ(ω)|2 / |ω| ) dω &lt; ∞。平移 τ 可使小波函数在时间轴上移动; α 变大或变小会使其变窄或变宽 [57], 其中, α, τ ∈ R, α &gt; 0。由此得到变换后的函数</p>
<img src="/8ed6a4ed/26.png" class>

<p>称为参数为 α 和 τ 的小波基函数。1/√α 将能量归一化。当参数可连续取值时, 称为连续小波变换; 当参数只能取离散值时, 称为离散小波变换。</p>
<hr>
<h5 id="小波包变换"><a href="#小波包变换" class="headerlink" title="小波包变换"></a>小波包变换</h5><p>小波变换将信号分成低频和高频两个部分, 只分解低频部分, 导致忽略表征信号细节的高频部分, 使高频分辨率差, 丢失细节信息。因此引入 WPT, 仍将信号分解为低频和高频部分, 但两部分都会继续分解, 低频上丢失的信息可以在高频中补充。因此, 小波包变换可以提供更丰富的信号分析, 提高分辨率 [58]。</p>
<hr>
<h5 id="Hilbert-Huang-谱"><a href="#Hilbert-Huang-谱" class="headerlink" title="Hilbert-Huang 谱"></a>Hilbert-Huang 谱</h5><p>Hilbert-Huang 是一种非线性的时频域特征提取方法, 与 STFT 相比, 抵抗噪声干扰的能力更强 [22, 59]。首先用经验模式分解 (empirical mode decomposition, EMD) 得到固有模态函数 (intrinsic mode functions, IMFs) 来表征原 EEG 信号 X(t), 假设共分解出 k 个固有模态函数:</p>
<img src="/8ed6a4ed/27.png" class>

<p>其中, r(t) 表示剩余的单调或常数的部分。再对每个 IMF_i(t) 计算 Hilbert 变换, 解析信号可用振幅 A_i(t) 和瞬时相位 θ_i(t) 来表征, 瞬时频率 f_i(t) = (1/2π) (dθ_i/dt) , 则原信号可表示为</p>
<img src="/8ed6a4ed/28.png" class>

<p>通过上述方法将 EEG 按时间段变换至频域后, 再提取如前所述的频域特征, 例如功率、功率谱密度的均值、最值等。除此之外, 也可根据时间窗提取时频域上的相对能量</p>
<img src="/8ed6a4ed/29.png" class>

<p>和每个时间窗上的熵</p>
<img src="/8ed6a4ed/30.png" class>

<p>其中, Energy_band 表示某个时间窗内信号在某个频段上的能量, Energy_total 为该时间窗内所有频段能量之和 [40]。</p>
<hr>
<h4 id="空间域特征"><a href="#空间域特征" class="headerlink" title="空间域特征"></a>空间域特征</h4><p>脑电信号采自若干个对应大脑皮层不同位置的电极, 如前所述, 左右半球产生的 EEG 信号与情绪效价有关: 消极情绪能激活右侧额叶、颞叶和顶叶, 而积极情绪可以激活左侧区域 [60∼63]。因此形成 EEG 的空间域特征, 主要分为空频域特征和电极组合特征。</p>
<hr>
<h5 id="空频域"><a href="#空频域" class="headerlink" title="空频域"></a>空频域</h5><p>先提取各电极上的频域特征, 再用共同空间模式 (common spatial patterns, CSP) 等算法与空间域结合, 计算空频域特征。</p>
<p><strong>共同空间模式</strong>。CSP 常用于二分类问题, 根据信号所属的类别标签, 设计特殊的空间滤波器, 使两类信号的功率最大, 继而得到区分度高的特征 [64, 65] 以及各电极信号的权重 [66]。</p>
<p>假设 n 段 EEG 信号分为正性和负性效价两类, 每段信号都表示为通道数 × 采样点个数的矩阵形式, 将两种分类下信号的协方差矩阵分别取平均得到 Σ+ 和 Σ−, 并进行特征值分解 Σ+ + Σ− = U (DU)T, U 是特征向量矩阵, D 是特征值构成的对角矩阵, 则白化值矩阵为 P = √D^−1 U T, 白化后的信号的协方差矩阵为</p>
<img src="/8ed6a4ed/31.png" class>

<p>二者特征向量相同, 且特征值加和为 1。I 表示单位矩阵, B 表示特征向量矩阵, Λ 表示特征值构成的对角矩阵, 那么</p>
<img src="/8ed6a4ed/32.png" class>

<p>因此, 称投影矩阵 W = BTP 中的每个行向量 wj 就是一个空间滤波器, 越大的特征值表示 wj 在两类上可以得到差距越大的方差。而 W^(−1) 的每一列称为共同空间模式 [66]。</p>
<p>Koelstra 等 [65] 在效价 (valence)、唤醒度 (arousal) 和喜爱度 (like/dislike) 3 项上, 分别以原始 PSD 和 CSP 作为特征, 用支持向量机 (support vector machine, SVM) 进行二分类, CSP 得到的分类准确率高于 PSD。</p>
<p><strong>共同空间模式的改进</strong>。由于不同个体的脑电信号在各频段上的显著程度不同, 因此当被试较多且差异较大时, 为保证识别效果, 需要大量手动调整 CSP 的频段。为了解决这一问题, Novi 等 [67] 提出子波段共同空间模式 (sub-band common spatial pattern, SBCSP), 用基于傅里叶的 Gabor 滤波器组将信号分成不同频段, 在各波段上提取 CSP 特征, 使用 LDA 算法自动选择显著的频段和相应的 CSP 特征, 最后用分类器对 CSP 特征进行分类。SBCSP 可以实现自动调整且保证识别准确率。</p>
<p>Ang 等 [68] 进一步改进了 SBCSP 算法, 提出了滤波器组共同空间模式 (filter bank common spatial pattern, FBCSP), 其与 SBCSP 的区别在于使用零相位切比雪夫 (Chebyshev) 滤波器组作为滤波器, 克服了 IIR (infinite impulse response) 滤波器造成的非线性相移; 在特征选择和分类中, 可广泛使用现有的特征选择和分类器算法, 具有普适性。</p>
<hr>
<h5 id="电极组合"><a href="#电极组合" class="headerlink" title="电极组合"></a>电极组合</h5><p>计算电极组合特征时, 先对各电极信号计算前述时域、频域或时频域特征作为初步特征值, 再将若干电极组合成对, 进一步计算特征。电极对的组合方式包括对称和不对称两种, 对称方式又分为前后对称和左右对称。为了便于论述, 以 32 导 NeuroScan Quik-cap 脑电帽的电极位置为例。该设备包括 2 个参考电极和 30 个采样电极, 如图 4 所示。</p>
<img src="/8ed6a4ed/33.png" class>

<p><strong>左右位置对称</strong>。以中间的灰色竖线为对称轴, 剩余 24 个电极左右对称, 可得到 12 对电极, 绿色线标识的两列电极互为电极对, 蓝色线标识的两列同理。用 L 列举出所有电极对中的左侧电极, R 为相应的右侧电极: L = {FP1, F3, FC3, C3, CP3, P3, O1, F7, FT7, T7, TP7, P7}, R = {FP2, F4, FC4, C4, CP4, P4, O2, F8, FT8, T8, TP8, P8}。</p>
<ol>
<li>不对称差/不对称商。<br> 不对称差 (differential asymmetry, DASM) 和不对称商 (rational asymmetry, RASM) 分别指左右对称电极上特征的差分和比值 [69] <img src="/8ed6a4ed/34.png" class>
 或者更复杂的计算方法, 用左右特征的差除以和, 此处称为不对称系数 [18]: <img src="/8ed6a4ed/35.png" class>
 其中, X_L 和 X_R 分别表示左侧和右侧电极采集到的 EEG 信号, Feature(X) 表示在信号 X 上提取的初步特征值。</li>
<li>多维度有向信息。<br> Sakata 等 [70] 提出了多维度有向信息 (multidimensional directed information, MDI), 反映从某个电极流向其他电极的信息量, 通常测量左右电极对之间流动的信息量。MDI 的优势在于可以表示各电极之间信号量的绝对量而非相对量 [71]。首先将两个电极上长度为 N 的 EEG 信号平均划分为 n 段, 每段以 xk 和 yk 界定 <img src="/8ed6a4ed/36.png" class>
 那么两序列的互信息为 <img src="/8ed6a4ed/37.png" class>

</li>
</ol>
<p><strong>前后位置对称</strong>。以图 4 中间横向的灰色横线为对称轴, 并舍弃 OZ 电极, 剩余 24 个电极前后对称, 可得到 12 对电极, 紫色线标识的两行电极互为电极对, 红色线、橙色线同理。用 F 列举出所有电极对中的前部电极, P 为相应的后部电极: F = {FP1, FP2, F7, F3, FZ, F4, F8, FT7, FC3, FCZ, FC4, FT8}, P = {O1, O2, P7, P3, PZ, P4, P8, TP7, CP3, CPZ, CP4, TP8}。</p>
<p>DCAU (differential caudality) 可以用来描述前后电极上的不对称性 [46]</p>
<img src="/8ed6a4ed/38.png" class>

<hr>
<hr>
<h3 id="不同脑电特征对于情绪识别结果的影响"><a href="#不同脑电特征对于情绪识别结果的影响" class="headerlink" title="不同脑电特征对于情绪识别结果的影响"></a>不同脑电特征对于情绪识别结果的影响</h3><p>为了测试特征对情绪识别结果的贡献, 本文选择 3 个脑电数据库 SEED, DREAMER 和 CASTHU, 计算各类特征值, 将稀疏线性判别分析 (sparse linear discriminant analysis, SLDA) [72] 选择特征的权重作为评价标准。</p>
<p>需要说明的是, 频域与时频域本质都是将时域信号变换至频域, 且二者计算的特征类型 (如 PSD, 微分熵等) 相同; 但时频域按时间段划分信号, 含有更丰富的特征信息, 也更常用于情绪识别领域。因而本实验对 EEG 加时间窗以提取时频域特征, 不计算整个信号的频域特征。</p>
<hr>
<h4 id="数据库介绍"><a href="#数据库介绍" class="headerlink" title="数据库介绍"></a>数据库介绍</h4><h5 id="SEED"><a href="#SEED" class="headerlink" title="SEED"></a>SEED</h5><p>SEED 数据库 [46, 69] 由上海交通大学发布, 用时长 4 min 左右的华语电影片段诱发正性、中性和负性效价的 3 种情绪。使用 62 导的 ESI NeuroScan 系统采集 15 名被试 (7 名男性, 8 名女性, 年龄平均值为 23.27, 标准差为 2.37) 的脑电数据, 采样率为 1000 Hz。每名被试在不同时间做 3 次实验, 每次观看 15 段电影片段, 即共 45 个试次。对 EEG 信号的预处理包括: 信号下采样至 200 Hz, 去除眼电和肌电噪声, 并使用 0.3 ∼ 50 Hz 的带通滤波器。计算时频域特征时, 使用长度为 1 s 互不重叠的 hanning 窗进行短时傅里叶变换, 并划分 5 个频段 δ (1∼3 Hz), θ (4∼7 Hz), α (8∼13 Hz), β (14∼30 Hz), γ (31∼50 Hz)。</p>
<h5 id="DREAMER"><a href="#DREAMER" class="headerlink" title="DREAMER"></a>DREAMER</h5><p>DREAMER 数据库 [73] 由 University of the West of Scotland 发布, 提供被试对影片在效价、唤醒度和控制度上的评分, 并据此得到相应情绪的正负性或唤醒度、控制度的高低。影片共 18 段, 长度在 65 ∼ 393 s 之间 [73, 74]。实验使用 14 导的 Emotiv EPOC 系统, 采集 23 名被试 (14 名男性, 9 名女性, 年龄平均值为 26.6, 标准差为 2.7) 观看电影时的脑电和心电数据, 采样率为 128 Hz。截取每段信号最后的 60 s, 并用 MATLAB 环境下的 EEGLAB 工具包 [75] 做预处理。用长度为 2 s、相邻窗重叠 1 s 的时间窗进行短时傅里叶变换, 并将信号分为 θ (4∼7 Hz), α (8∼13 Hz), β (14∼30 Hz) 3 个频段。</p>
<h5 id="CAS-THU"><a href="#CAS-THU" class="headerlink" title="CAS-THU"></a>CAS-THU</h5><p>CAS-THU 数据库[76] 由中国科学院心理研究所与清华大学共同提出, 使用 16 段华语影片诱发 8 种离散情绪, 包括搞笑、高兴和温馨 3 种正性情绪, 厌恶、恐惧、愤怒和悲伤 4 种负性情绪以及中性状态。使用 14 导 Emotiv EPOC 系统采集 30 名男性被试 (年龄平均值为 23, 标准差为 1.73) 的脑电数据。预处理时先通过 1 ∼ 45 Hz 的带通滤波器, 再用独立成分分析 (independent component analysis, ICA) 和 MATLAB 环境下的 EEGLAB 工具包 [75] 除去眼电干扰。与 DREAMER 相同, 采用长度 2 s 且相邻重叠 1 s 的时间窗做 STFT, 将信号划分为 5 个频段: δ (1∼4 Hz), θ (4∼8 Hz), α (8∼12 Hz), β (13∼30 Hz), γ (31∼45 Hz) [76]。</p>
<p>综上可知, 3 个数据库都包含情绪的效价信息, 其中 SEED 和 CAS-THU 包含正性、中性和负性 3 类效价, DREAMER 只包含正性和负性两类效价, 所以本实验只衡量各特征在判断效价上的作用。</p>
<hr>
<h4 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h4><p>由于 ERP, ERS 和 ERD 3 项事件相关的特征需要离散材料作为诱发, 而本实验数据库均用视频持续诱发情绪, 更符合实际应用场景。因此在本文的实验中, 不提取这 3 个特征。另外, CSP 适用于二分类任务, 因此只对 DREAMER 数据库计算 CSP 特征。综上, 本文实验在 3 个数据库上共同计算的特征包括:</p>
<ol>
<li>时域。平均值、标准差、一阶差分、归一化的一阶差分、二阶差分、归一化的二阶差分、Hjorth 特征 (activity, mobility, complexity)、能量、功率、高阶过零分析、不稳定指数、Higuchi 分形维数。</li>
<li>时频域。功率谱密度、高阶谱、微分熵。</li>
<li>空间域。DASM、RASM、不对称系数、DCAU、多维度有向信息。</li>
</ol>
<p>对于每个数据库, 按照其描述添加相应时间窗应用 STFT。需要注意的是, 在计算高阶谱 HOS 特征时, 我们使用 MATLAB 上的 HOSA 工具包 [77]; 在提取电极组合特征时, 使用广泛用于情绪识别领域的 PSD 特征。</p>
<p>表 1 列出了 3 个数据集上各类特征的维数, 需要强调的是, 每类特征会有多列, 即 “一类” 特征可能包含 “多维” 特征值。</p>
<img src="/8ed6a4ed/41.png" class>

<hr>
<h4 id="计算特征重要程度"><a href="#计算特征重要程度" class="headerlink" title="计算特征重要程度"></a>计算特征重要程度</h4><p>令 n×p 的矩阵 X 表示提取的 EEG 特征, n 表示样本数, 每一行样本都属于一类效价。属于第 j 类的样本下标为 C_j, 数量为 n_j; p 为特征维数, 即表 1 最后一行的 “总计” 维数, 例如 pSEED = 2423。线性判别分析 (linear discriminant analysis, LDA) 从 Fisher 线性判别法的角度寻找判别向量, 使类间方差相对类内方差最大化, 即</p>
<img src="/8ed6a4ed/39.png" class>

<p>但是, 当所选特征的数量大于观测数量时, 特征的类内协方差矩阵会变得单一。可应用稀疏的 LDA (sparse LDA, SLDA) [72], 添加 l1 罚项对判别向量施加稀疏约束, 以解决这个问题。</p>
<img src="/8ed6a4ed/40.png" class>

<p>在本实验中, 用 MATLAB 上的 SpaSM 工具包 [78] 实现 SLDA 算法, 使用默认参数以保证算法在不同数据库上的统一性。采用准确率较高的被试留一法划分数据, 即, 若数据集中包括 s 名被试, 将其划分为 s 个子集, 各子集包含一个被试的全部样本 [79]。每次取其中的 s − 1 个子集的数据送入SLDA 算法, 计算权重 Wi; 在 s 次上取权重均值并排序, 再计算每一类特征的 “重要程度”, “重要程度” 定义如下：</p>
<p><strong>定义1</strong> (重要程度) 若某特征共有 p_i 维, 其中有 m_i 维排在所有维度的前 x%, 则该特征的重要程度值为</p>
<img src="/8ed6a4ed/42.png" class>

<p>例如, 由表 1 可知, pSEED = 2423, 其中 310 列是功率谱密度 (PSD), 令 x = 10, 则关注权重排在前 2423 × 10% ≈ 242 位的特征, 若 242 列中有 100 列来自 PSD, 则 PSD 特征的重要程度值 d_10 = 100/310 ≈ 0.32。x 值越小, 越可以反映特征的重要程度。</p>
<hr>
<img src="/8ed6a4ed/43.png" class>

<h4 id="结果分析和讨论"><a href="#结果分析和讨论" class="headerlink" title="结果分析和讨论"></a>结果分析和讨论</h4><p>将各类特征按照 x = 10, 30, 50 分别计算重要程度并排序; 统计在 2 个或全部 3 个数据库上都排在前 10 位的特征。需要注意的是, CSP 为 DREAMER 数据集独有的特征, 故不参与排名。最终结果如表 2 所示。可看出时域特征中的一阶差分、二阶差分、Hjorth 特征, 以及不稳定指数的重要程度最高, 其次是归一化的一阶差分、归一化的二阶差分, 以及分形维数; 频域中的微分熵, 空间域中的 DASM 和 RASM 也有较好的表现。时域特征对效价的分辨能力强于时频域和空间域。</p>
<p>对于 CSP 特征, 当 x 取 10 时, 其重要程度排在 DREAMER 所有 23 类特征中的第 16 位; 当 x 取 30 时, 排在第 5 位; x 取 50 时排在第 2 位。说明 CSP 在该数据库上可以较好地表征效价, 但表征能力并不突出。</p>
<p>根据以上结果可知, 时域特征对情绪效价的分辨能力最强, 因而在后续相关研究中, 研究者可考虑加入时域特征来优化情绪识别效果。此外在所有时域特征中, 统计特征的重要程度高, 原因之一在于, 不同数据库中同效价的影片唤醒度可能有异。例如诱发正性情绪的两部影片, 其产生正性情绪的强烈程度可能不同, 即此处效价的分类会受到唤醒度的影响。</p>
<hr>
<hr>
<h3 id="对未来工作的展望"><a href="#对未来工作的展望" class="headerlink" title="对未来工作的展望"></a>对未来工作的展望</h3><h4 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h4><p>需要建立包括脑电信号数据和情绪诱发材料的情绪标准化库, 作为后续情绪理论研究的基础。该库应满足以下要求:</p>
<ol>
<li><strong>采用视听刺激的方式诱发情绪</strong>。相比于单一的视觉或听觉刺激, 视听刺激结合的方式更贴近实际生活, 内容和情节也更丰富, 例如电影片段、音乐视频等, 这种方式下产生的脑电信号具有良好的动态性、不可欺骗性和高生态效度 [80]。</li>
<li><strong>适用于中国社会和文化背景</strong>。由于文化背景的差异, 现有国外标准库难以直接用于我国被试, 因此建立针对我国人群的标准库具有极大的应用价值。</li>
<li><strong>涵盖更多的正性情绪类别及样本数</strong>。近年来有关情绪的最新行为学研究认为, 积极情绪至少可以分为 10 种代表性类型 [81], 包括高兴、感恩、宁静、兴趣、希望、自豪、搞笑、激励、敬畏、爱。在实践应用或社会需求的角度, 积极情绪比消极情绪更重要。积极情绪有助于扩大注意、认知及行为的范围, 促进身体、智力与社交能力的健康发展。但已有情绪库中的正性情绪种类较少, 正负情绪材料和样本数量不平衡, 不利于情绪模型建立和应用, 因此脑电信号数据库应涵盖更多的正性情绪种类及样本数。</li>
<li><strong>尽量排除刺激材料本身对被试的影响</strong>。应尽量排除刺激材料本身内容 (如画面的明暗、声音的强弱等) 产生的影响, 让采集的 EEG 信号直接反映情绪对被试的影响。</li>
</ol>
<hr>
<h4 id="理论研究"><a href="#理论研究" class="headerlink" title="理论研究"></a>理论研究</h4><ol>
<li><strong>从多学科交叉角度分析脑电特征与情绪识别结果的关系</strong>。基于 EEG 信号的情绪识别是多学科交叉的研究问题. 而现有的情绪识别研究中, 特征计算方法多来自电信号处理领域, 对特征的讨论主要停留在实验准确率的层面, 鲜有特征与情绪本身联系的探讨. 如果从生理、心理和神经科学的理论层面分析特征与情绪的关系, 将有助于理解情绪产生的机制, 进而设计出与情绪最相关的脑电特征, 优化识别效果。</li>
<li><strong>多人脑功能影像数据联合分析方法</strong>。通过联合分析多名被试在特定任务状态下大脑活动之间的关系, 研究被试在完成任务时的认知过程, 可提取绝对强度不大, 但持续时间较长、个体间一致性较好的 “微弱” 神经响应. 这一方法可能分析出在传统事件相关分析中被低估的神经响应, 有利于提取更深层次的情绪响应特性。</li>
<li><strong>深度学习方法</strong>。近年来兴起的深度学习 (deep learning) 方法采用分层结构, 先将原空间的特征表示转换到新的空间, 再进行后续分类。与人工构造的特征相比, 利用海量数据学习到的特征更能反映数据的内在本质 [82], 克服特征冗余问题, 提高情绪识别的智能和普适性。</li>
</ol>
<hr>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>情绪识别是人机交互中的重要组成部分, 在医学、教育和军事等方面都具有切实的研究需要和广阔的应用前景, 脑电信号是目前情绪识别领域中识别效果较好的生理指标. 从信号中提取与情绪关联度高、区分度大的特征有助于达到较高的情绪识别准确率。</p>
<p>本文围绕面向情绪识别的脑电特征, 从时域、频域、时频域和空间域 4 个方面介绍了特征的定义、计算方法和与情绪的联系, 在总结已有工作的基础上, 在 SEED, DREAMER 和 CAS-THU 3 个公开的脑电 – 情绪数据集上, 对各类特征的效价区分能力进行评估和比较, 并展望未来可行的研究方向, 为开展进一步研究提供思路。</p>
<hr>
<hr>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Huang X T. Introduction to Psychology. Beijing: Peoples Education Press, 1991 [黄希庭. 心理学导论. 北京: 人民教育出版社, 1991]</p>
<p>[2] van den Broek E L. Ubiquitous emotion-aware computing. Pers Ubiquit Comput, 2013, 17: 53–67</p>
<p>[3] Posner J, Russell J A, Peterson B S. The circumplex model of affect: an integrative approach to affective neuroscience, cognitive development, and psychopathology. Develop Psychopathol, 2005, 17: 715–734</p>
<p>[4] Lang P J. The emotion probe: studies of motivation and attention. Am Psychol, 1995, 50: 372–385</p>
<p>[5] Zhao G Z, Song J J, Ge Y, et al. Advances in emotion recognition based on physiological big data. J Comput Res Dev, 2016, 53: 80–92 [赵国朕, 宋金晶, 葛燕, 等. 基于生理大数据的情绪识别研究进展. 计算机研究与发展, 2016, 53: 80–92]</p>
<p>[6] Alarcao S M, Fonseca M J. Emotions recognition using EEG signals: a survey. IEEE Trans Affect Comput, 2017. doi: 10.1109/TAFFC.2017.2714671</p>
<p>[7] Chanel G, Kierkels J J M, Soleymani M, et al. Short-term emotion assessment in a recall paradigm. Int J HumanComput Stud, 2009, 67: 607–627</p>
<p>[8] Hruby T, Marsalek P. Event-related potentials-the P3 wave. Acta Neurobiol Exp, 2002, 63: 55–63</p>
<p>[9] Luck S J, Kappenman E S. The Oxford Handbook of Event-Related Potential Components. Oxford: Oxford University Press, 2011</p>
<p>[10] Lithari C, Frantzidis C A, Papadelis C, et al. Are females more responsive to emotional stimuli? A neurophysiological study across arousal and valence dimensions. Brain Topogr, 2010, 23: 27–40</p>
<p>[11] Yazdani A, Lee J S, Ebrahimi T. Implicit emotional tagging of multimedia using EEG signals and brain computer interface. In: Proceedings of the 1st SIGMM Workshop on Social Media, Beijing, 2009. 81–88</p>
<p>[12] Codispoti M, Ferrari V, Bradley M M. Repetition and event-related potentials: distinguishing early and late processes in affective picture perception. J Cogn Neurosci, 2007, 19: 577–586</p>
<p>[13] Olofsson J K, Nordin S, Sequeira H, et al. Affective picture processing: an integrative review of ERP findings. Biol Psychol, 2008, 77: 247–265</p>
<p>[14] Olofsson J K, Polich J. Affective visual event-related potentials: arousal, repetition, and time-on-task. Biol Psychol, 2007, 75: 101–108</p>
<p>[15] Gianotti L R R, Faber P L, Schuler M, et al. First valence, then arousal: the temporal dynamics of brain electric activity evoked by emotional stimuli. Brain Topogr, 2008, 20: 143–156</p>
<p>[16] Jiang J F, Zeng Y, Tong L, et al. Single-trial ERP detecting for emotion recognition. In: Proceedings of the 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD), Shanghai, 2016. 105–108</p>
<p>[17] Smith N K, Cacioppo J T, Larsen J T, et al. May I have your attention, please: electrocortical responses to positive and negative stimuli. Neuropsychologia, 2003, 41: 171–183</p>
<p>[18] Kim M K, Kim M, Oh E, et al. A review on the computational methods for emotional state estimation from the human EEG. Comput Math Method Med, 2013, 2013: 13</p>
<p>[19] Bernat E, Bunce S, Shevrin H. Event-related brain potentials differentiate positive and negative mood adjectives during both supraliminal and subliminal visual processing. Int J Psychophysiol, 2001, 42: 11–34</p>
<p>[20] Cuthbert B N, Schupp H T, Bradley M M, et al. Brain potentials in affective picture processing: covariation with autonomic arousal and affective report. Biol Psychol, 2000, 52: 95–111</p>
<p>[21] Nieuwenhuis S, Aston-Jones G, Cohen J D. Decision making, the P3, and the locus coeruleus-norepinephrine system. Psychol Bull, 2005, 131: 510–532</p>
<p>[22] Jenke R, Peer A, Buss M. Feature extraction and selection for emotion recognition from EEG. IEEE Trans Affect Comput, 2014, 5: 327–339</p>
<p>[23] Wang X W, Nie D, Lu B L. EEG-based emotion recognition using frequency domain features and support vector machines. In: Proceedings of International Conference on Neural Information Processing, Berlin, 2011. 734–743</p>
<p>[24] Bastos-Filho T F, Ferreira A, Atencio A C, et al. Evaluation of feature extraction techniques in emotional state recognition. In: Proceedings of the 4th International Conference on Intelligent Human Computer Interaction (IHCI), Kharagpur, 2012</p>
<p>[25] Picard R W, Vyzas E, Healey J. Toward machine emotional intelligence: analysis of affective physiological state. IEEE Trans Pattern Anal Mach Intell, 2001, 23: 1175–1191</p>
<p>[26] Kroupi E, Yazdani A, Ebrahimi T. EEG correlates of different emotional states elicited during watching music videos. In: Proceedings of Affective Computing and Intelligent Interaction, Berlin, 2011. 457–466</p>
<p>[27] Fan C X, Cao L N. Communication Principle. Beijing: National Defense Industrial Press, 2001 [樊昌信, 曹丽娜. 通信原理. 北京: 国防工业出版社, 2001]</p>
<p>[28] Hjorth B. EEG analysis based on time domain properties. Electroencephal Clin Neurophysiol, 1970, 29: 306–310</p>
<p>[29] Petrantonakis P C, Hadjileontiadis L J. Emotion recognition from EEG using higher order crossings. IEEE Trans Inform Technol Biomed, 2010, 14: 186–197</p>
<p>[30] Hausdorff J M, Lertratanakul A, Cudkowicz M E, et al. Dynamic markers of altered gait rhythm in amyotrophic lateral sclerosis. J Appl Physiol, 2000, 88: 2045–2053</p>
<p>[31] Ansari-Asl K, Chanel G, Pun T. A channel selection method for EEG classification in emotion assessment based on synchronization likelihood. In: Proceedings of the 15th European Signal Processing Conference, Poznan, 2007. 1241–1245</p>
<p>[32] Khosrowabadi R, bin Abdul Rahman A W. Classification of EEG correlates on emotion using features from Gaussian mixtures of EEG spectrogram. In: Proceeding of the 3rd International Conference on Information and Communication Technology for the Moslem World (ICT4M), Jakarta, 2010. 102–107</p>
<p>[33] Sourina O, Liu Y S. A fractal-based algorithm of emotion recognition from EEG using arousal-valence model. In: Proceedings of the International Conference on Bio-inspired Systems and Signal Processing (BIOSIGNALS-2011), Rome, 2011. 209–214</p>
<p>[34] Liu Y, Sourina O. Real-time fractal-based valence level recognition from EEG. In: Proceedings of Transactions on Computational Science XVIII, Berlin, 2013. 101–120</p>
<p>[35] Conneau A C, Essid S. Assessment of new spectral features for eeg-based emotion recognition. In: Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Florence, 2014. 4698–4702</p>
<p>[36] Nie D, Wang X W, Duan R N, et al. A survey on EEG based emotion recognition. Chinese J Biomed Eng, 2012, 31: 595–606 [聂聃, 王晓韡, 段若男, 等. 基于脑电的情绪识别研究综述. 中国生物医学工程学报, 2012, 31: 595–606]</p>
<p>[37] Zheng J L, Ying Q H, Yang W L. Signal and System. 2nd ed. Beijing: Higher Education Press, 2000 [郑君里, 应启珩, 杨为理. 信号与系统 (第二版). 北京: 高等教育出版社, 2000]</p>
<p>[38] Sammler D, Grigutsch M, Fritz T, et al. Music and emotion: electrophysiological correlates of the processing of pleasant and unpleasant music. Psychophysiology, 2007, 44: 293–304</p>
<p>[39] Davidson R J. What does the prefrontal cortex “do” in affect: perspectives on frontal EEG asymmetry research. Biol Psychology, 2004, 67: 219–234</p>
<p>[40] Yuvaraj R, Murugappan M, Ibrahim N M, et al. Optimal set of EEG features for emotional state classification and trajectory visualization in Parkinson’s disease. Int J Psychophysiol, 2014, 94: 482–495</p>
<p>[41] Aftanas L I, Varlamov A A, Pavlov S V, et al. Affective picture processing: event-related synchronization within individually defined human theta band is modulated by valence dimension. Neurosci Lett, 2001, 303: 115–118</p>
<p>[42] Yuvaraj R, Murugappan M, Ibrahim N M, et al. Emotion classification in Parkinson’s disease by higher-order spectra and power spectrum features using EEG signals: a comparative study. J Integr Neurosci, 2014, 13: 89–120</p>
<p>[43] Keil A, M ̈ uller M M, Gruber T, et al. Effects of emotional arousal in the cerebral hemispheres: a study of oscillatory brain activity and event-related potentials. Clin Neurophysiol, 2001, 112: 2057–2068</p>
<p>[44] Bos D O. EEG-based emotion recognition-the influence of visual and auditory stimuli. Emotion, 2007, 57: 1798–1806</p>
<p>[45] Balconi M, Lucchiari C. Consciousness and arousal effects on emotional face processing as revealed by brain oscillations. A gamma band analysis. Int J Psychophysiol, 2008, 67: 41–46</p>
<p>[46] Zheng W L, Lu B L. Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks. IEEE Trans Auton Mental Dev, 2015, 7: 162–175</p>
<p>[47] Bekkedal M Y V, Rossi III J, Panksepp J. Human brain EEG indices of emotions: delineating responses to affective vocalizations by measuring frontal theta event-related synchronization. Neurosci Biobehaval Rev, 2011, 35: 1959–1970</p>
<p>[48] Graimann B, Pfurtscheller G. Quantification and visualization of event-related changes in oscillatory brain activity in the time-frequency domain. Progress Brain Res, 2006, 159: 79–97</p>
<p>[49] Balconi M, Lucchiari C. EEG correlates (event-related desynchronization) of emotional face elaboration: a temporal analysis. Neurosci Lett, 2006, 392: 118–123</p>
<p>[50] Duan R N, Zhu J Y, Lu B L. Differential entropy feature for EEG-based emotion classification. In: Proceedings of the 6th International IEEE/EMBS Conference on Neural Engineering (NER), San Diego, 2013. 81–84</p>
<p>[51] Shi L C, Jiao Y Y, Lu B L. Differential entropy feature for EEG-based vigilance estimation. In: Proceedings of the 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Osaka, 2013. 6627–6630</p>
<p>[52] Behnam H, Sheikhani A, Mohammadi M R, et al. Analyses of EEG background activity in Autism disorders with fast Fourier transform and short time Fourier measure. In: Proceedings of International Conference on Intelligent and Advanced Systems, Kuala Lumpur, 2007. 1240–1244</p>
<p>[53] Kıymık M K, Guler I, Dizibuyuk A, et al. Comparison of STFT and wavelet transform methods in determining epileptic seizure activity in EEG signals for real-time application. Comput Biol Med, 2005, 35: 603–616</p>
<p>[54] Yoon H J, Chung S Y. EEG-based emotion estimation using Bayesian weighted-log-posterior function and perceptron convergence algorithm. Comput Biol Med, 2013, 43: 2230–2237</p>
<p>[55] RozgicV, Vitaladevuni S N, Prasad R. Robust EEG emotion classification using segment level decision fusion. In: Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing, Vancouver, 2013. 1286–1290</p>
<p>[56] Akin M. Comparison of wavelet transform and FFT methods in the analysis of EEG signals. J Med Syst, 2002, 26: 241–247</p>
<p>[57] Adeli H, Zhou Z, Dadmehr N. Analysis of EEG records in an epileptic patient using wavelet transform. J Neurosci Method, 2003, 123: 69–87</p>
<p>[58] Sun Z, Chang C C. Structural damage assessment based on wavelet packet transform. J Struct Eng, 2002, 128: 1354–1361</p>
<p>[59] Hadjidimitriou S K, Hadjileontiadis L J. Toward an EEG-based recognition of music liking using time-frequency analysis. IEEE Trans Biomed Eng, 2012, 59: 3498–3510</p>
<p>[60] Davidson R J, Ekman P, Saron C D, et al. Approach-withdrawal and cerebral asymmetry: emotional expression and brain physiology: I. J Personality Soc Psychol, 1990, 58: 330–341</p>
<p>[61] Huang D, Guan C, Ang K K, et al. Asymmetric spatial pattern for EEG-based emotion detection. In: Proceedings of International Joint Conference on Neural Networks (IJCNN), Brisbane, 2012</p>
<p>[62] Takahashi K. Remarks on emotion recognition from bio-potential signals. In: Proceedings of IEEE International Conference on Industrial Technology (IEEE ICIT’04), Hammamet, 2004. 1148–1153</p>
<p>[63] Davidson R, Fox N. Asymmetrical brain activity discriminates between positive and negative affective stimuli in human infants. Science, 1982, 218: 1235–1237</p>
<p>[64] Blankertz B, Tomioka R, Lemm S, et al. Optimizing spatial filters for robust EEG single-trial analysis. IEEE Signal Process Mag, 2008, 25: 41–56</p>
<p>[65] Koelstra S, Yazdani A, Soleymani M, et al. Single trial classification of EEG and peripheral physiological signals for recognition of emotions induced by music videos. In: Proceedings of International Conference on Brain Informatics, Berlin, 2010. 89–100</p>
<p>[66] Winkler I, J ̈ager M, Mihajlovic V, et al. Frontal EEG asymmetry based classification of emotional valence using common spatial patterns. World Acad Sci Eng Technol, 2010, 45: 373–378</p>
<p>[67] Novi Q, Guan C, Dat T H, et al. Sub-band common spatial pattern (SBCSP) for brain-computer interface. In: Proceedings of the 3rd International IEEE/EMBS Conference on Neural Engineering, Kohala Coast, 2007. 204–207</p>
<p>[68] Ang K K, Chin Z Y, Zhang H, et al. Filter bank common spatial pattern (FBCSP) in brain-computer interface. In: Proceedings of IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence), Hong Kong, 2008. 2390–2397</p>
<p>[69] Duan R N, Wang X W, Lu B L. EEG-based emotion recognition in listening music by using support vector machine and linear dynamic system. In: Proceedings of International Conference on Neural Information Processing, Berlin, 2012. 468–475</p>
<p>[70] Sakata O, Shiina T, Saito Y. Multidimensional directed information and its application. Electron Commum Jpn, 2002, 85: 45–55</p>
<p>[71] Petrantonakis P C, Hadjileontiadis L J. A novel emotion elicitation index using frontal brain asymmetry for enhanced EEG-based emotion recognition. IEEE Trans Inform Technol Biomed, 2011, 15: 737–746</p>
<p>[72] Clemmensen L, Hastie T, Witten D, et al. Sparse discriminant analysis. Technometrics, 2011, 53: 406–413</p>
<p>[73] Katsigiannis S, Ramzan N. DREAMER: a database for emotion recognition through EEG and ECG signals from wireless low-cost off-the-shelf devices. IEEE J Biomed Health Inform, 2018, 22: 98–107</p>
<p>[74] Song T F, Zheng W M, Song P, et al. EEG emotion recognition using dynamical graph convolutional neural networks. IEEE Trans Affect Comput, 2018. doi: 10.1109/TAFFC.2018.2817622</p>
<p>[75] Delorme A, Makeig S. EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. J Neurosci Methods, 2004, 134: 9–21</p>
<p>[76] Liu Y J, Yu M, Zhao G, et al. Real-time movie-induced discrete emotion recognition from EEG signals. IEEE Trans Affect Comput, 2018, 9: 550–562</p>
<p>[77] Swami A, Mendel C, Nikias C. Higher-order spectral analysis (HOSA) toolbox. Version, 2000, 2: 3</p>
<p>[78] Sjostrand K, Clemmensen L H, Larsen R, et al. SpaSM: a matlab toolbox for sparse statistical modeling. J Stat Soft, 2018, 84: 37</p>
<p>[79] Zhou Z H. Machine Learning. Beijing: Tsinghua University Press, 2016 [周志华. 机器学习. 北京: 清华大学出版社, 2016]</p>
<p>[80] Gross J J, Levenson R W. Emotion elicitation using films. Cogn Emotion, 1995, 9: 87–108</p>
<p>[81] Fredrickson B L. Positive emotions and upward spirals in organizations. Positive Organ Scholarship, 2003, 3: 163–175</p>
<p>[82] Yu C, Sun K, Zhong M Y, et al. One-dimensional handwriting: inputting letters and words on smart glasses. In: Proceedings of CHI Conference on Human Factors in Computing Systems (CHI’16), San Jose, 2016. 71–82</p>
<hr>
<h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><blockquote>
<p><a href="https://www.sciengine.com/SSI/doi/10.1360/N112018-00337">https://www.sciengine.com/SSI/doi/10.1360/N112018-00337</a></p>
</blockquote>
<hr>
<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2019-A-review-of-EEG-features-for-emotion-recognition.pdf" data-height="500px"></div>

<p>引用：张冠华, 余旻婧, 陈果, 等. 面向情绪识别的脑电特征研究综述. 中国科学: 信息科学, 2019, doi: 10.1360/N112018-00337 Zhang G H, Yu M J, Chen G, et al. A review of EEG features for emotion recognition (in Chinese). Sci Sin Inform, 2019, doi: 10.1360/N112018-00337<br>Reference: Guanhua ZHANG, Minjing YU, Guo CHEN, Yiheng HAN, Dan ZHANG, Guozhen ZHAO, Yong-Jin LIU, A review of EEG features for emotion recognition, In Journal of SCIENTIA SINICA Informationis, Volume 49, Issue 9, 2019, Pages 1097-1118, ISSN 1674-7267, <a href="https://doi.org/10.1360/N112018-00337">https://doi.org/10.1360/N112018-00337</a>.</p>
<hr>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-讲好故事、论点【研究的艺术·三】</title>
    <url>/22b7233e.html</url>
    <content><![CDATA[<img src="/22b7233e/1.png" class>

<p><strong>前情回顾：</strong></p>
<ul>
<li>写文章的时候呢要跟读者建立联系，因为我们写的文章最后是要给读者来读的</li>
<li>在选题的时候要选择有价值的题，读者认为这个问题是值得解决的</li>
</ul>
<p>现在假设我们的研究已经正常的展开了，已经做了一半或者甚至是一大半的时候，这时候就要开始想怎么样来讲故事、写论文了</p>
<p>也就是说，我们选的题已经保证了读者会来读我们的文章，他有兴趣来看，但接下来的任务是要让读者信我写的东西，包括了我们对一个问题提出了一个新的看法，要让大家认同这个看法。或者说提出了一个新的方法，使得大家相信这个新的方法确实能解决某一个问题。</p>
<p><strong>核心是讲一个故事，能让读者信我们讲的东西。</strong></p>
<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=598414840&bvid=BV1WB4y1v7ST&cid=773589171&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="怎么样讲我们的故事"><a href="#怎么样讲我们的故事" class="headerlink" title="怎么样讲我们的故事"></a>怎么样讲我们的故事</h3><p>要讲一个故事（科研写作），是一个有理有据的故事，不像是一些小说或日常对话一样的讲故事</p>
<p>不能等到把所有的信息都收集全的时候，再去考虑故事要怎么写</p>
<ul>
<li>可能很难把所有东西都收集</li>
<li>如果没有一个故事的话，也不知道应该怎么去收集东西</li>
<li>想一个故事和做研究很多时候是一个并行或者是交错进行的一个过程。如果做过研究的话，很有可能一开始想做的东西是做问题a，但是你随着研究的深入，或者提出了新的方法或者是读了更多的文章以及做了更多的实验，会发现其实你更想解决的或更适合解决的是问题b，所以这时候整个研究的一个计划以及要说的故事都会跟着发生改变。</li>
</ul>
<p>实际上，对大部分研究来讲，很难在一开始就能预测到想要怎么样的结果，如果在一开始就知道最后的方案、结果是什么样子的话，这个就不叫研究，一般叫做工程。</p>
<ul>
<li>工程就是我们一开始能想清楚答案，只要我们把它执行好就行</li>
<li>对研究来讲，通常要去探索未知的一些答案</li>
</ul>
<p>需要有一个这样的故事在心中，去指导我们收集信息以及做什么样的实验。这个故事（research argument，学术的论点或论述）就是用来回答所有可以预测的一些读者的问题，这样就知道你的研究还剩了多少可以做。这就是为什么作者一开始就说需要早一点想我们的故事，不要等到所有的研究做完了再去想</p>
<p>所以不能说已经做完了所有研究，剩下一点时间来写论文，写着写着就发现故事讲不通了，要换的时候再改就很麻烦了。而是说一边做实验一边讲故事，把大纲写出来，如果故事要发生变动的话，实验可以跟着变，这样子就是比较好的一个过程，不要等到最后开始写</p>
<p>对于研究来讲，很多时候我们一开始是没有冲突的，只是说大家在信息的获取上面是不一样的，所以我们要干的事情呢，更多是跟读者做一个合作的探索，让读者在读了之后也达到跟我们同样的认知水平上</p>
<p>这里重要的一点是说，不一定需要读者也认同我们的方法是最好的，更多是读者在读了我们的文章之后，他跟我们一起去探索解决一个重要问题，这个问题读者也是关心怎么样去解决它，然后在读者在这个过程中间也去思考，他也许在思考后说：我的结论跟你是差不多的、我觉得你这方法很好，或者也会说：在这过程中我发现一个更好的想法，我可以在你的方法在再做改进，得到一个新的研究，这个都是我们要追求的。</p>
<ul>
<li>我们要找东西来支持我们的一些论点，与足够多的原因和论据，这样子别人才会觉得我们的论点是可信的</li>
<li>这个跟我们之前要去考虑说我们的研究问题为什么有价值，我们不断的问SO WHAT这个问题的时候同样道理</li>
<li>在组织你的故事的时候，要不断的从读者的角度去问这个问题，为什么我应该相信这个事情</li>
<li>如果整个这本书要抽出两个核心的问题的话，其实也就是<strong>So What</strong>和<strong>我为什么要信</strong>这两个问题</li>
<li>所以在研究开始和研究结束的过程中，不断的给自己问这两个问题基本上就可能指导怎么样做研究了</li>
</ul>
<hr>
<h3 id="论证的总览"><a href="#论证的总览" class="headerlink" title="论证的总览"></a>论证的总览</h3><p>整个论证里面几个核心的东西</p>
<ul>
<li>首先要提出一个论点</li>
<li>然后用一些原因和证据来支撑我们的论点</li>
<li>有时候需要承认和回复一些别的观点</li>
<li>最后有时候要提供一下你推理的一些逻辑的原则</li>
</ul>
<p>当理解每一句话他在整个论述中扮演的角色的时候，既能够帮我们去更好的读一篇文章，而且是用批判性的眼光去读一篇文章，也能帮助我们在构造自己的故事的时候，能够让每一句话都在发挥他的用处</p>
<p>所以写作的核心是说，要在脑海中去预测这样子对话，使得在跟人真的对话之前，把所有这种可能性——别人攻击你的地方，以及缺失的理由、论点、论据全部补充起来，这样子就能写出别人相信的故事了</p>
<hr>
<h3 id="几个重要的元素"><a href="#几个重要的元素" class="headerlink" title="几个重要的元素"></a>几个重要的元素</h3><p><strong>论点：</strong>核心的理由是什么东西，很多时候文章最后就是一个核心的论点，当然论点还有别的子论点支撑<br><strong>理由：</strong>为什么我们的论点是对的<br><strong>论据：</strong>一些数据点或者别人的工作<br><strong>承认和回复：</strong>对于别的一个观点的一个说明<br><strong>保证：</strong>这个逻辑是怎么样过来的，如果读者不理解的话，应该把它说出来，解释一下我们的理由为什么能解释我们的结论好</p>
<hr>
<h3 id="核心要干的事情（支撑论点）"><a href="#核心要干的事情（支撑论点）" class="headerlink" title="核心要干的事情（支撑论点）"></a>核心要干的事情（支撑论点）</h3><p><strong>怎么用原因和论据啊来支撑你的论点</strong></p>
<ul>
<li>用原因来支撑的话，一般会有一个因为这一个词在这个地方</li>
<li>在一般的情况下，很少只用一个理由来支撑你的论点，很有可能会用多个理由，而特别的是说，其实理由的本身它也是一个论点</li>
</ul>
<p><strong>什么时候可以结束说明理由</strong></p>
<ul>
<li>理由必须是在论据之上的，结论是基于好的原因，理由又是基于好的论据</li>
<li>所谓的论据就包括了，做实验得出来的一些实验的结果，或者前面的值得信任那些工作里面的一些论点，这个是现实存在；理由很多时候更多是一个思维的逻辑，是存在你脑海中的</li>
<li>一旦我们成功的把论点通过理由和论据支撑住了之后，被大家认可之后，我们的论点也会成为别人工作的一个论据</li>
<li>我们一个论点需要有原因来支持，这些原因又是在基于我们的论据上面的，所以我们要保证说原因能够合理的解释我们的论点，反过来讲每一个原因也需要有他的论据来支撑才是合理存在的</li>
</ul>
<hr>
<h3 id="使用承认和回复"><a href="#使用承认和回复" class="headerlink" title="使用承认和回复"></a>使用承认和回复</h3><p>作者提前预测读者可能会提的一些反对意见，然后把答案写在这里，这样子在读者读的过程中心中产生问题的时候，作者就在下面就把这些问题给回答掉了。</p>
<p>其实回答本身不是最难的问题，最难的是说在写的时候要假设他们这些问题的存在，就是你要想到你的读者可能会提这样子的问题。核心是说我们得尽量的去考虑到很周全，去想象你的读者会问这样子的问题。</p>
<p>我们的论点可能有一些反对的意见，或者不同的解释、不同的看法，这样子我们需要去承认这些东西的存在，并且给予回复。</p>
<p><strong>用理由去支撑论文时，读者可能会看不出它们之间的关系：</strong></p>
<ul>
<li>在读者看不明白的时候，需要补充说明他们之间的联系，不然读者是不会买账的</li>
<li>这个补充说明一般是一些通用的原则，就是一些大家都能接触的东西，然后把它作为一个通用的原则。在这个原则之下，能够特立出我们的推理逻辑</li>
<li>当原因和论点之间隔得比较远的时候，需要给出一些推理的保证，来使得读者能清楚的认识到我们的原因和论点是怎么样联系起来的</li>
</ul>
<p>实际上我们正在写的时候，整个逻辑可能是比较复杂的，可能就想说一个很简单的东西也可以变得比较复杂。想把一个文章写的有理有据、滴水不漏是一件很难的事情。</p>
<hr>
<h3 id="要把argument弄得“厚一点”"><a href="#要把argument弄得“厚一点”" class="headerlink" title="要把argument弄得“厚一点”"></a>要把argument弄得“厚一点”</h3><p>在支撑论点的时候，正正反反都要多讲一点，因为我们的目的是要通过这些比较厚实的论述，让读者能够相信我们所说的内容</p>
<p><strong>常见的错误：</strong></p>
<ul>
<li>当在别的领域做过研究了，然后刚进入一个新的领域的时候，新领域可能在摆道理的方法跟别的领域是不一样的，所以当新进入一个领域或者是换一个领域的时候，要去多读人家的文章去看其他人是怎么样去讲论述的。</li>
<li>如果在一个领域待的时间够久的时候，其实什么都懂了，这时候再去写的时候可能会写的比较简单一点，在写作的时候，还是需要向主流人群来看拢。</li>
</ul>
<hr>
<h3 id="关于声明"><a href="#关于声明" class="headerlink" title="关于声明"></a>关于声明</h3><p>声明就是对研究问题的答案，就是把答案浓缩成一句话变成声明，然后整个文章呢主要是围绕去支撑这个声明</p>
<p>声明要考虑那么下面这3个问题</p>
<ul>
<li>我在做一个什么样类别的声明：因为不同类别的声明，导致可能要支撑他的这些证据是不一样的</li>
<li>声明够不够具体：因为对于比较空洞的声明，大家读起来会觉得比较空洞</li>
<li>声明啊够不够重要：读者觉不觉得有必要去花一篇文章去支撑我这样子的声明</li>
</ul>
<p>我们要解决一个有价值的问题，然后我的解决的方法本身应该也要是有价值的。</p>
<hr>
<h3 id="偏概念性的分类"><a href="#偏概念性的分类" class="headerlink" title="偏概念性的分类"></a>偏概念性的分类</h3><ul>
<li>声明一些什么东西存在，或者什么样的事实</li>
<li>或者说声明一些什么样的定义，什么样的分类</li>
<li>或者说你声明什么样的原因，和他导致的一些后果</li>
<li>还有是说声明一些评论</li>
<li>声明对于解决某一个问题的话，需要采取什么样的行动，或者是什么样的政策</li>
</ul>
<hr>
<h3 id="偏技术的分类"><a href="#偏技术的分类" class="headerlink" title="偏技术的分类"></a>偏技术的分类</h3><ul>
<li>我们的方法是可行的，可以花合理的时间和力气来实现它</li>
<li>实现它的代价要少于你不解决这个问题给你带来的代价</li>
<li>解决这个问题会不会创造一个更大的问题出来</li>
<li>我们的方法为什么要比别的替代的方法更加便宜或更加的快</li>
</ul>
<hr>
<h3 id="什么样的声明是比较好的"><a href="#什么样的声明是比较好的" class="headerlink" title="什么样的声明是比较好的"></a>什么样的声明是比较好的</h3><p>这本书写的比较通用一点，他无法告诉我们说，具体怎么去找到一个特别好的一个声明</p>
<p>声明需要是具体的而且是重要的</p>
<p>有一些领域可能不那么希望特别直白的一个声明，希望有那么一点点转折和一点点的层次</p>
<p>可以用一个 虽然 although 或者 even though 来开始，然后在结论的后面加上一个因为，把你的层次感增强</p>
<hr>
<h3 id="怎么样把声明变得更重要一些"><a href="#怎么样把声明变得更重要一些" class="headerlink" title="怎么样把声明变得更重要一些"></a>怎么样把声明变得更重要一些</h3><p>对一个大家感兴趣的话题提供新的证据</p>
<p>不仅仅把数据展示出来而是要用数据去回答一个大家有争论、不那么确定的问题的答案</p>
<p><strong>怎么样去看现在想到的声明重不重要：</strong>把结论反过来看一下反过来的那个结论是长什么样子</p>
<p><strong>怎么样把论点变得更加可信一点：</strong>如果想让别人信我们说的话，最好不要把话说的特别的满，可以承认一些局限性的条件。要去想的限制条件的时候，是从读者角度来出发的。从他们的角度来讲，去想想我们的理由也好我们的论据也好，在哪些地方更加薄弱一点，把这些薄弱的地方作为限制条件给出来之话，那么对整个的可信度就会增加</p>
<hr>
<h3 id="使用一些降低语气确信度的词，使得论点显得没那么的强硬"><a href="#使用一些降低语气确信度的词，使得论点显得没那么的强硬" class="headerlink" title="使用一些降低语气确信度的词，使得论点显得没那么的强硬"></a>使用一些降低语气确信度的词，使得论点显得没那么的强硬</h3><p>如果讲的特别自信的话，读者会觉得更加的难以置信一些</p>
<p>如果用了大量这样子的不确定的词汇呢，整个文章可能会显得比较弱，别人会觉得你可能自己也不是那么的确信</p>
<p>尽量要避免这些词汇：all、no one、every、always、never</p>
<hr>
<h3 id="第8章总结"><a href="#第8章总结" class="headerlink" title="第8章总结"></a>第8章总结</h3><p>讲的是论文，论点的类型</p>
<p>一个好的论点一定是具体的而且是有价值的</p>
<p>可以通过把论点写的没那么满，使得读者认为你的论点解释出来更加容易一些</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv17586472">https://www.bilibili.com/read/cv17586472</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫方法技巧</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-深入浅出Yolov1-v7，全系列Tricks解析汇总</title>
    <url>/39c38ef8.html</url>
    <content><![CDATA[<p>【导读】目标检测Yolo算法是非常经典且应用广泛的算法，而在Yolo中，又分成了输入端、网络推理、输出层，每个部分都可以延伸出很多的优化方式，本文主要从Yolov1~v7各个版本的Tricks进行了讲解，希望对大家有帮助。</p>
<p>近年来YOLO系列层出不穷，更新不断，已经到v7版本。本人认为不能简单用版本高低来评判一个系列的效果好坏，YOLOv1-v7不同版本各有特色，<strong>在不同场景，不同上下游环境，不同资源支持的情况下，如何从容选择使用哪个版本，甚至使用哪个特定部分，都需要我们对YOLOv1-v7有一个全面的认识。</strong></p>
<span id="more"></span>

<p>故将YOLO系列每个版本都表示成下图中的五个部分，逐一进行解析，并将每个部分带入业务向，竞赛向，研究向进行延伸思考，探索更多可能性。</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg4NDYwOTUwNA==&mid=2247485146&idx=1&sn=f925d3509585c6cbe094e6a19cea35e2">【Make YOLO Great Again】YOLOv1-v7全系列大解析（Neck篇）</a>，<a href="https://mp.weixin.qq.com/s?__biz=Mzg4NDYwOTUwNA==&mid=2247485573&idx=1&sn=def0aff4f9fc9b7336881e51c8db2292">【Make YOLO Great Again】YOLOv1-v7全系列大解析（Head篇）</a>,<a href="https://mp.weixin.qq.com/s?__biz=Mzg4NDYwOTUwNA==&mid=2247485731&idx=1&sn=899893914caf18be49680a6ef712c1ea">【Make YOLO Great Again】YOLOv1-v7全系列大解析（输入侧篇）</a>以及<a href="https://mp.weixin.qq.com/s?__biz=Mzg4NDYwOTUwNA==&mid=2247485832&idx=1&sn=9a7cd6b5ffaaecea9586ce0744f2e807">【Make YOLO Great Again】YOLOv1-v7全系列大解析（Backbone篇）</a>已经发布，大家可按需取用～</p>
<p>而本文将聚焦于YOLO系列Tricks知识的分享，希望能让江湖中的英雄豪杰获益。</p>
<img src="/39c38ef8/1.png" class>

<hr>
<h3 id="YOLOv1-v7论文-amp-amp-项目名称"><a href="#YOLOv1-v7论文-amp-amp-项目名称" class="headerlink" title="YOLOv1-v7论文&amp;&amp;项目名称"></a>YOLOv1-v7论文&amp;&amp;项目名称</h3><p>YOLOv1论文名：You Only Look Once: Unified, Real-Time Object Detection<br>YOLOv2论文名：YOLO9000: Better, Faster, Stronger<br>YOLOv3论文名：YOLOv3: An Incremental Improvement<br>YOLOv4论文名：YOLOv4: Optimal Speed and Accuracy of Object Detection<br>YOLOv5论文名：无<br>YOLOx论文名：YOLOX: Exceeding YOLO Series in 2021<br>YOLOv6论文名：YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications<br>YOLOv7论文名：YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</p>
<p>YOLOv1开源代码：YOLOv1-Darkent<br>YOLOv2开源代码：YOLOv2-Darkent<br>YOLOv3开源代码：YOLOv3-PyTorch<br>YOLOv4开源代码：YOLOv4-Darkent<br>YOLOv5开源代码：YOLOv5-PyTorch<br>YOLOx开源代码：YOLOx-PyTorch<br>YOLOv6开源代码：YOLOv6-PyTorch<br>YOLOv7开源代码：Official YOLOv7-PyTorch</p>
<hr>
<h3 id="YOLO系列中Tricks的特点"><a href="#YOLO系列中Tricks的特点" class="headerlink" title="YOLO系列中Tricks的特点"></a>YOLO系列中Tricks的特点</h3><p>YOLO系列中使用的Tricks，<strong>从横向角度来看，基本算是当时的最优Trcks；从纵向角度来看，其大部分都具备了可迁移性，强适应性，能够跟随着我们一起进入2020年代，并且依旧发挥余热。</strong></p>
<p>YOLO系列中使用的Tricks和Backbone以及输入侧一样，是通用性非常强的一个部分，具备很强的向目标检测其他模型，图像分类，图像分割，目标跟踪等方向迁移应用的价值。</p>
<p>从业务向，竞赛向，研究向等角度观察，Tricks部分也能在这些方面比较好的融入，从容。</p>
<hr>
<h3 id="YOLOv1-v3-Tricks解析"><a href="#YOLOv1-v3-Tricks解析" class="headerlink" title="YOLOv1-v3 Tricks解析"></a>YOLOv1-v3 Tricks解析</h3><p>作为YOLO系列的开山之作，YOLOv1中并未用太多的Tricks，但是设计出YOLO的架构，已经足够伟大。</p>
<img src="/39c38ef8/2.png" class>
<p>YOLOv1整体结构</p>
<p>等到YOLOv2发布时，引入了当时来说比较有创造性的Tricks，<strong>即设计了分类与检测的联合训练方法，使得YOLO能够实时检测多达9000种目标，在这种方法下输出的模型称为YOLO9000。</strong></p>
<img src="/39c38ef8/3.png" class>
<p>YOLO9000联合训练逻辑</p>
<p>YOLO9000主要在COCO和ImageNet数据集上进行训练，<strong>首先在检测数据集上训练一定的epoch来让模型学习定位和检测目标的能力；再使用分类数据集进行训练，从而扩展模型对目标的识别能力。</strong></p>
<p>在训练的过程中，混合目标检测和分类的数据集。当输入是检测数据集时，对整个Loss函数计算Loss；当输入是分类数据集时，Loss函数只计算分类Loss，其余部分Loss设为零。</p>
<p><strong>YOLO9000使用的联合训练不同于将Backbone在ImageNet上进行预训练</strong>，联合训练可以扩充检测识别的目标类别。例如，当模型检测出车的位置后，更进一步将其细分类别轿车、卡车、客车、自行车、三轮车等。</p>
<img src="/39c38ef8/4.png" class>
<p>Darknet-19网络结构</p>
<p>等到YOLOv3发布时，YOLO系列的整体架构算是基本确定，<strong>Adam优化器也开始逐渐流行起来。</strong></p>
<img src="/39c38ef8/5.png" class>
<p>YOLOv3网络结构图</p>
<p>Adam优化器结合了AdaGrad和RMSProp两种优化算法的优点。对梯度的一阶矩估计（First Moment Estimation，即梯度的均值）和二阶矩估计（Second Moment Estimation，即梯度的未中心化的方差）进行综合考虑，计算出更新步长。</p>
<p><strong>Adam的优势：</strong></p>
<ol>
<li>实现简单，计算高效，对内存需求少。</li>
<li>参数的更新不受梯度的伸缩变换影响。</li>
<li>超参数具有很好的解释性，且通常无需调整或仅需很少的微调。</li>
<li>更新的步长能够被限制在大致的范围内（初始学习率）。</li>
<li>能自然地实现步长退火过程（自动调整学习率）。</li>
<li>很适合应用于大规模的数据及参数的场景。</li>
<li>适用于不稳定目标函数。</li>
<li>适用于梯度稀疏或梯度存在很大噪声的问题。</li>
</ol>
<p><strong>Adam的实现原理：</strong></p>
<img src="/39c38ef8/6.png" class>

<p>【延伸思考】</p>
<ol>
<li>YOLOv1-v3中使用的Tricks无论是在业务向，竞赛向还是研究向，都可以作为入场Baseline。</li>
</ol>
<hr>
<h3 id="YOLOv4-Tricks解析"><a href="#YOLOv4-Tricks解析" class="headerlink" title="YOLOv4 Tricks解析"></a>YOLOv4 Tricks解析</h3><p>YOLOv4在YOLOv3的基础上，<strong>设计使用了SAT，CmBN和Label Smoothing等Tricks。</strong></p>
<img src="/39c38ef8/7.png" class>
<p>YOLOv4网络结构图</p>
<p>YOLOv4中的<strong>SAT（self adversarial training）</strong>使用基于FGSM原理的梯度攻击技术，生成对抗样本进行对抗训练。</p>
<img src="/39c38ef8/8.png" class>

<p>首先，什么是对抗样本呢？对抗样本是在原图像中增加扰动噪声生成，如上图所示。对抗样本容易使得模型输出错误判断，这给模型的鲁棒性造成了重大挑战。</p>
<p>打不过，就加入它。秉持着这个原则，我们在训练时将对抗样本加入训练集一起训练，即为对抗训练。进行对抗训练能扩充训练集的可能性，使得数据集逼近我们想要的数据分布，训练后的模型鲁棒性和泛化性能也大大增强。</p>
<p>生成对抗样本的方法主要分为三种，具体逻辑如下图所示。</p>
<img src="/39c38ef8/9.png" class>

<p><strong>CmBN（Cross mini-Batch Normalization）</strong>是CBN的修改版。</p>
<p>CBN主要用来解决在Batch-Size较小时，BN的效果不佳问题。CBN连续利用多个迭代的数据来变相扩大Batch-Size从而改进模型的效果。（每次迭代时计算包括本次迭代的前四个迭代后统一计算整体BN）</p>
<p>而CmBN是独立利用多个mini-batch内的数据进行BN操作。（每四个迭代后统一计算一次整体BN）</p>
<img src="/39c38ef8/10.png" class>

<p><strong>Label Smooth</strong>可以看作是一种防止过拟合的正则化方法。</p>
<p>其主要是在One-Hot标签中加入噪声，减少训练时GroundTruth在计算损失函数的权重，来达到防止过拟合的作用，增强模型的泛化能力。</p>
<p>通常参数设置如下图中的比例即可。</p>
<img src="/39c38ef8/11.png" class>

<p>【延伸思考】</p>
<ol>
<li>YOLOv4中的Tricks具备在业务，竞赛以及研究中进行实验的价值。</li>
</ol>
<hr>
<h3 id="YOLOv5-Tricks解析"><a href="#YOLOv5-Tricks解析" class="headerlink" title="YOLOv5 Tricks解析"></a>YOLOv5 Tricks解析</h3><p>YOLOv5中使用的Tricks基本上和YOLOv4一致，并在此基础上引入了更多的<strong>工程优化逻辑。</strong></p>
<img src="/39c38ef8/12.png" class>
<p>YOLOv5网络结构图</p>
<p>YOLOv5通过不同的训练参数配置，用来获得不同复杂度的模型。</p>
<img src="/39c38ef8/13.png" class>
<p>YOLOv5模型家族</p>
<p>除此之外，YOLOv5还尝试了<strong>混合精度训练和模型EMA（Exponential Moving Average）策略。</strong></p>
<p>混合精度训练<strong>能在尽可能减少精度损失的情况下利用FP16加速训练，并使用FP16存储模型权重，在减少占用内存的同时起到了加速训练的效果。</strong></p>
<p>模型EMA（Exponential Moving Average）策略<strong>将模型近期不同epoch的参数做平均，提高模型整体检测性能以及鲁棒性。</strong></p>
<p>【延伸思考】</p>
<ol>
<li>YOLOv5 Backbone的易用性使得其不管在业务向，竞赛向还是研究向都非常友好。</li>
</ol>
<hr>
<h3 id="YOLOx-Tricks解析"><a href="#YOLOx-Tricks解析" class="headerlink" title="YOLOx Tricks解析"></a>YOLOx Tricks解析</h3><p>YOLOx使用了YOLOv5中提到的模型EMA（Exponential Moving Average）策略，<strong>并且使用余弦退火学习率优化训练过程。</strong></p>
<img src="/39c38ef8/14.png" class>
<p>YOLOx网络结构图</p>
<p>余弦退火学习率衰策略(CosineAnnealingLR)使得学习率呈周期性变化，但我们通常取它的一个余弦周期来完成整个训练过程。</p>
<p>另外，固定步长衰减(StepLR)，多步长衰减(MultiStepLR)，指数衰减(ExponentialLR)等都是经典实用的学习率衰减策略。</p>
<p>固定步长衰减在每隔一定的步长或者epoch对学习率进行一定衰减，而多步长衰减策略比起固定步长衰减则更加灵活，它可以在不同阶段使用不同强度和频率的衰减策略。指数衰减策略是使用指数逻辑对学习率进行衰减。</p>
<img src="/39c38ef8/15.png" class>

<hr>
<h3 id="YOLOv6-v7-Tricks解析"><a href="#YOLOv6-v7-Tricks解析" class="headerlink" title="YOLOv6-v7 Tricks解析"></a>YOLOv6-v7 Tricks解析</h3><p>YOLOv6<strong>进行了很多蒸馏方向上的尝试。</strong></p>
<img src="/39c38ef8/16.png" class>
<p>YOLOv6网络结构图</p>
<p>比如<strong>Self-distillation，Reparameterizing Optimizer，使用 Channel-wise Distillation进行量化感知训练等方法</strong>，进一步加强模型的整体性能。</p>
<p>YOLOv7也使用了YOLOv5中提到的模型EMA（Exponential Moving Average）策略，<strong>并引入了YOLOR中使用的隐性知识。</strong></p>
<img src="/39c38ef8/17.png" class>
<p>YOLOv7网络结构图</p>
<p>YOLOR中的隐式知识可以在推理阶段将计算值简化为向量。这个向量可以与前一层或后一层卷积层的偏差和权重相结合。</p>
<p>由于篇幅原因，在这里就不展开讲了，后续将专门对蒸馏技术撰写一篇总结文章，大家敬请期待！</p>
<p>【延伸思考】</p>
<ol>
<li>蒸馏技术在业务，竞赛以及研究中的应用落地，以及蒸馏技术自身的发展，都是值得我们关注的地方。</li>
</ol>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg5NzgyNTU2Mg==&amp;mid=2247502986&amp;idx=1&amp;sn=b68828e099a04e2bc04d2a46a2231502">https://mp.weixin.qq.com/s?__biz=Mzg5NzgyNTU2Mg==&amp;mid=2247502986&amp;idx=1&amp;sn=b68828e099a04e2bc04d2a46a2231502</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-理由、论据和担保【研究的艺术·四】</title>
    <url>/b09e4572.html</url>
    <content><![CDATA[<img src="/b09e4572/1.png" class>

<span id="more"></span>

<iframe src="//player.bilibili.com/player.html?aid=601089966&bvid=BV1SB4y1a75c&cid=778243309&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h3 id="第九章"><a href="#第九章" class="headerlink" title="第九章"></a>第九章</h3><h4 id="怎么准备我们的理由和一些论据"><a href="#怎么准备我们的理由和一些论据" class="headerlink" title="怎么准备我们的理由和一些论据"></a>怎么准备我们的理由和一些论据</h4><ul>
<li>支撑一个论点的两种东西：原因、论据</li>
<li>怎么样去区别这两个以及怎么样去用理由来组织你的这个论述</li>
<li>怎么样去评价你的这些论据的一个好坏</li>
</ul>
<hr>
<h4 id="读者是怎么样去看理由和论证"><a href="#读者是怎么样去看理由和论证" class="headerlink" title="读者是怎么样去看理由和论证"></a>读者是怎么样去看理由和论证</h4><p>读者首先会去看我们论述的核心（论点和它的一些支撑的论据）</p>
<p>对于支撑来说，读者会先去看我们提过的那一些理由，然后去看一下它是不是有道理</p>
<p>如果理由靠谱的话，读者会去看它的整个逻辑，然后把它排好序，读者会顺着这个思路往下看，看看这个逻辑是不是过得去</p>
<p>如果这些理由看上去还不错的话，那么接下来他去会去看论据，论据是整个论述的一个基石，论据理应是不容质疑的，但是如果读者不相信你的论据的话，那么他也就不会相信我们的理由</p>
<p>核心是说，我们有一个论点，然后通过理由，这个是能够架在我们的论据上面，理由是能够撑住你的论点的，如果中间任何一个部分没有做好的话，那么导致我们的论点是支撑不起来，就会导致大家不会信你</p>
<hr>
<h4 id="如果要去收集整个论述要怎么办"><a href="#如果要去收集整个论述要怎么办" class="headerlink" title="如果要去收集整个论述要怎么办"></a>如果要去收集整个论述要怎么办</h4><ul>
<li>首先应该给读者提供一些合理的理由</li>
<li>然后这些理由需要在一个清晰的有逻辑的顺序之下</li>
<li>最后所有这些理由必须要是基于论据的，而且读者是可以接受这些论据的</li>
</ul>
<hr>
<h4 id="怎么样用理由来计划整个论述"><a href="#怎么样用理由来计划整个论述" class="headerlink" title="怎么样用理由来计划整个论述"></a>怎么样用理由来计划整个论述</h4><p>得找到一些合适的、说得过去的理由，要对这些理由排序</p>
<p>作者给出的通用方法：</p>
<ul>
<li>一开始的是说对我们的这个论点的介绍</li>
<li>然后引出我们的论点</li>
<li>最后是结论（对我们的论点的肯定或者是对论点的升华）</li>
<li>从引出论点就第一句话跳到结尾的最后一句话的话，中间需要提过很多的理由，每个理由可以直接支撑论点，也可以支撑上一个理由。对每一个理由，我们要提供论据来支撑这个理由</li>
</ul>
<p>在构思的时候要怎么办：</p>
<ul>
<li>在每一个方块里面，写上论点、写上理由、写上论据，然后你不用去管具体是怎么写，不要写的特别完整的一句话，只是把一些要点写在这个地方</li>
<li>把它写出来之后，可以对着它来去仔细的去看，论点是不是有漏洞，然后从读者的角度来想说，是不是有什么虚的地方是可以被攻击的</li>
<li>或者说可以把整个这个故事给同学给老师看一看，让大家也用挑剔的目光来看一看，这个东西是不是充分</li>
<li>通常会要求写的质量没那么好得同学，把整个故事的骨架写下来，这样子的话可以叫有经验的同学过来一起来看。因为对整个这样子骨架去看去发表评论的时候，远远的好于最后看到已经成稿的文章了，因为成稿的文章，可能会关心这个句子怎么写，这个句子有没联通。在这个地方，主要还是关心的整个故事的逻辑，这个东西一定要想清楚的，故事的逻辑是不可能通过后面的写作来弥补的，所以可以花多点时间在怎么样构思故事上。</li>
</ul>
<h4 id="怎么样去区分论据和理由"><a href="#怎么样去区分论据和理由" class="headerlink" title="怎么样去区分论据和理由"></a>怎么样去区分论据和理由</h4><p>不是由我们来决定什么是理由什么是论据，而是读者来决定的，需要把整个论据写的非常的脚踏实地</p>
<p>对一个证据通常我们不是真正的把这个证据拿出来，而是用的是这个证据的一个报道，要确定对证据的描述的本身是可以值得信的</p>
<p>证据比如说数据可能是来自于别人的工作，在别人的工作里面，他用他的证据也是用来支撑自己的一个论点。所以，在别人工作里面，这些数字已经把它换了个形式，能够更好得支撑他的一个需求。所以在搬过来的时候要知道，前面的工作其实已经为了他的一个需求做过一次改动了，所以他也不真正的是一个很原始的一个面貌，再把数据搬过来的时候，同样要把整个数据变成一个更适合支撑论点的形式。</p>
<p>在这个地方是要比较小心的，不能给读者一个对证据做过一些主观上改动的印象。而是说，要给读者 整个证据是一个比较客观的描述的印象。</p>
<p>在文章中间所用的证据只是对一个证据的描述，要确保两件事情：</p>
<ul>
<li>证据的本身是能站得住脚的</li>
<li>对证据的描述是客观的</li>
</ul>
<hr>
<h4 id="怎么样评估论据的好坏"><a href="#怎么样评估论据的好坏" class="headerlink" title="怎么样评估论据的好坏"></a>怎么样评估论据的好坏</h4><p>一个好的证据必须是准确的、精确的、足够的、有代表性的和权威的</p>
<p>必须要很准确的来报告证据，作为证据来讲一般来自于两种可能性：从自己收集而来的（比如说做实验采集到了证据），来自于前面人的一个工作</p>
<p>所以不管是哪一种都要很准确的报告你的数据怎么来的：对第一种来讲，要说整个实验是怎么做的，流程是什么样子，然后这数据是怎么样采集的，这需要我们能够准确的描述这个流程，而且大家是认可我们的这个方法的；如果论据是来自于别人方法的话，那么把证据从别人的报告搬到我们这里来的时候，要足够准确，至少是ctrl C + ctrl V过来的，不要把一些数字搞错了</p>
<hr>
<h4 id="要有合理的精度"><a href="#要有合理的精度" class="headerlink" title="要有合理的精度"></a>要有合理的精度</h4><p>精确就说不要使用这种很模棱两可的词，而要使用一些比较精确的语言</p>
<p>所谓的模棱两可的词就包括了 some most many almost often usually frequently generally 这都是一些比较模糊的词，我们要尽量得避免它。</p>
<hr>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>对于论点怎么样用理由和论据来支撑</li>
<li>理由通常有多个而且是要合理的，而且需要用合适的顺序把它组织起来</li>
<li>证据是要需要强有力的而且是读者要认可的，包括你的报告是准确的</li>
<li>然后这数据的精度是合适的，全面的有代表性的以及是权威的</li>
</ul>
<hr>
<h3 id="第十章"><a href="#第十章" class="headerlink" title="第十章"></a>第十章</h3><h4 id="承认和回应"><a href="#承认和回应" class="headerlink" title="承认和回应"></a>承认和回应</h4><p>需要去回应读者心中的那些不同的看法。写文章的时候要去预测、承认、回应这些读者在读你文章过程中间产生出来的一些问题、反对意见和一些另外的解决方法</p>
<p>难点是说，我们的写作是一个假想的对话，我们并不知道读者在真的看到我们这么写的时候的反馈，所以在这个时候，我们需要去想象读者的情况和我们要怎么样回应</p>
<p>在本章节作者会告诉我们，可以从两个方法来想象读者可能会怎么样提供一些不一样的看法，然后也告诉大家怎么样去承认和回复这样子的看法</p>
<p>读者通常有两种方法去挑战我们说的东西：</p>
<ul>
<li><strong>内在的完备性。</strong>也就是说他们会挑战论点是不是讲的很清楚，然后理由是不是相关的，以及说论据的质量是怎么样的；</li>
<li><strong>外部的完备性。</strong>包括了是不是有一个别的方法来重新来讲我们的问题，或者是说是不是有一些我们自己没有注意到论据，还有是说是不是有别人的工作也写过相似的一些话题，但是他们提供了不一样的意见，我们并没有引用他们</li>
</ul>
<hr>
<h4 id="怎么把这样子的看法挖掘出来"><a href="#怎么把这样子的看法挖掘出来" class="headerlink" title="怎么把这样子的看法挖掘出来"></a>怎么把这样子的看法挖掘出来</h4><p>这是一个很难的事情，比如已经花了很多时间去想象各种理由、各种证据的好坏，如果读者还是有一些不一样的问题的话，那肯定是没有想到的，当时如果已经花了很长时间的话，那再花更多时间可能也不一定能想到</p>
<p>所以要去找别人来看一看，因为别人看的话，反正他也不知道你怎么想的，所以他没有先验的偏见，也许他可以提供一些不一样的看法</p>
<p>所以在做研究的时候，时不时找人（不管是同学、师兄师姐、师弟师妹或者是导师或者是同事）能够让他们来帮忙看一看现在有的东西也是非常有用的</p>
<p>如果还是找不到怎么办，作者给大家提供了一些问题可以去问自己，就当自己是读者，从这些方向去看，看看是不是能够找出什么漏洞出来：</p>
<ul>
<li>这为什么是一个问题（问题应该是指我们所研究的东西）？因为有时候问题可能不是真正存在，只是我们构造出来的或者你想象出来的啊</li>
<li>问题是不是已经很好地定义</li>
</ul>
<p>看看自己的解决方案：</p>
<ul>
<li>如果解决方式是实用的话，你必须要提供一个更好的更实用的方法</li>
<li>如果你解决方式是概念上的，就不应该要仅仅指出这个东西存在，要提供一个不一样的看法</li>
<li>声明是不是太强了，所有的东西是不是能支撑那么强的声明，能不能想出一些反例或者局限性出来</li>
<li>为什么我们的方法要比别人的好，通过什么的论据来证明 或为什么这些概念上的一个新的看法比别人要好</li>
</ul>
<hr>
<h4 id="看一下自己这些原因和论据"><a href="#看一下自己这些原因和论据" class="headerlink" title="看一下自己这些原因和论据"></a>看一下自己这些原因和论据</h4><p>能不能提供一些别的种类的论据，有很多数字但可能希望一些关于真实案例的情况，或者说只有一些真实的案例但是并没有统计上的一些数字</p>
<p>所有的论据可以去看它的一个质量（是否准确、精度是不是高、是不是有代表性、是不是权威的），最难的是说，需要更多的证据</p>
<p>我们可以用这些问题来客观的去看你现在有的所有的东西，从而发现你的论述中间薄弱的一些地方，在找到论述里面的薄弱点之后，接下来要去决定我们应该把哪一些拿出来写</p>
<p>如果你承认了太多不一样的观点的话，会导致你的文章很长，别人会觉得说你说了那么多有的没的，那么你的自己的方案在哪里；如果你承认太少，别人会觉得说你可能想地不够深入，你的置信度就没那么高，所以我们需要有一个合适的一个平衡点</p>
<hr>
<h4 id="如何找到平衡"><a href="#如何找到平衡" class="headerlink" title="如何找到平衡"></a>如何找到平衡</h4><p>按照以下优先级来选：</p>
<ul>
<li>指控（charge）论述中可能的一些弱点而且这些指控是合理的、能够反驳的</li>
<li>如果我们的答案是用的某一个方法，但是在整个领域里面可能还有一些别的方法的话，也可以去说别的方法是什么样子（通常出现在相关工作那一章节里面）</li>
<li>提供多个解决方案，给出自己的看法，剩下的由读者选择</li>
<li>从读者可能会知道的另外的证据出发</li>
<li>必须解决的一些重要的反例</li>
</ul>
<p>承认这些不一样的看法可能会使得读者开心，当且仅当我们没有用一个很轻蔑的态度</p>
<hr>
<h4 id="可能会遇到一些问题是无法回答的"><a href="#可能会遇到一些问题是无法回答的" class="headerlink" title="可能会遇到一些问题是无法回答的"></a>可能会遇到一些问题是无法回答的</h4><p>要纠正一个思想是说我们的文章解决了某一个问题的所有，在绝大部分的情况下，我们的研究工作，只是回答了一个小的问题的一部分，所以肯定会漏想了一些别的部分，以及说跟这个问题更大的一些问题的东西，可能是无法回答的</p>
<p>有时候承认自己无法回答别的问题也很正常了，大家也是这么理解的。对于无知来讲，知道自己无知的无知和不知道自己无知的无知，后者当然更加无知一点，所以宁可自己做前者。</p>
<hr>
<h4 id="怎么样把这个东西给写下来"><a href="#怎么样把这个东西给写下来" class="headerlink" title="怎么样把这个东西给写下来"></a>怎么样把这个东西给写下来</h4><p>可以把回应当做一个主论点</p>
<p>然后用前面介绍过的理由和论据来支撑它</p>
<hr>
<h4 id="一些例句与词汇"><a href="#一些例句与词汇" class="headerlink" title="一些例句与词汇"></a>一些例句与词汇</h4><img src="/b09e4572/2.png" class>
<img src="/b09e4572/3.png" class>
<img src="/b09e4572/4.png" class>
<img src="/b09e4572/5.png" class>

<hr>
<h4 id="三种常见的不一样的意见"><a href="#三种常见的不一样的意见" class="headerlink" title="三种常见的不一样的意见"></a>三种常见的不一样的意见</h4><ul>
<li>声称a引起了b但别人可能会觉得还有CDEF</li>
<li>如果把一个论点弄得比较大的时候，出现反例的概率就更大了</li>
<li>我不同意你对X的一个定义，这个是很容易出现在一些比较新的问题上面</li>
</ul>
<hr>
<h4 id="本节核心"><a href="#本节核心" class="headerlink" title="本节核心"></a>本节核心</h4><p>我们不管怎么样去支撑我们的论点、用原因、用论据，读者总会有一些不同的想法，我们要能够预测出读者的不同想法，把它写下来，把它承认出来然后回复他，远远的好过了我们没有找出来。</p>
<hr>
<h3 id="第十一章"><a href="#第十一章" class="headerlink" title="第十一章"></a>第十一章</h3><h4 id="推理的保证"><a href="#推理的保证" class="headerlink" title="推理的保证"></a>推理的保证</h4><p>这是一个通用的原则，能够把你的原因和你的论点连起来，尤其是当原因和论点隔得比较远的时候</p>
<hr>
<h4 id="让我们看看准则或者公理是不是合适的"><a href="#让我们看看准则或者公理是不是合适的" class="headerlink" title="让我们看看准则或者公理是不是合适的"></a>让我们看看准则或者公理是不是合适的</h4><p>它是不是<strong>有道理的</strong>，因为我们对一个这样的担保，通常不会用原因去证明它是合理的，所以你至少让读者觉得他是一个合理的</p>
<p>这个是不是它<strong>覆盖面不用特别广</strong>，因为如果一个担保想覆盖更多通用的情况下，就会显得它更加的薄一点，可能反例就更多一点。很多时候我们只要这个担保，能够足够覆盖到论点和原因就行了</p>
<p>有没有别的一些<strong>更好的担保</strong>，有时候我们在数学里面做公理的时候，当我们要选一个最好的一个公理而不是选一些公理下面的一些东西</p>
<p>对于我们的这个领域（大家的研究文章都是发在某个领域上面）是不是<strong>合适的</strong>，就这个领域的人能不能接受这样子的观点</p>
<p>我们得覆盖住论点和原因</p>
<hr>
<h4 id="什么时候需要用到担保"><a href="#什么时候需要用到担保" class="headerlink" title="什么时候需要用到担保"></a>什么时候需要用到担保</h4><p>读者是在领域之外的时候（写教科书的时候经常会用它），大量的新来读者不清楚里面的一些隐藏逻辑，把它给大家讲出来是非常有用的，不然读者可能会看不懂。如果说发一篇文章，必须要是自然杂志的话，它的读者相对来说比较广的时候，也尽量要把这个领域相关的一些东西给大家写出来，让大家明白我们的这一个逻辑</p>
<p>如果我们使用的原则对这个领域的读者来说，比较新或者是有争议的时候，也应该把它讲一讲</p>
<p>当我们的论点特别有争议性可能读者觉得很难接受的时候，那么在大家都会接受的情况下在前面说一些准则（如果他接受第一句，然后再过渡到第二句的时候）就显得没那么难接受一些</p>
<p>我们选择去把这样子担保说出来时候，意味着是说我们其实关心读者，生怕他不懂我在说什么，所以把前面这一些逻辑给他们交代的更清楚</p>
<hr>
<h4 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h4><p>关于怎么样去讲一个故事，故事也就是对你这个研究问题的一个回答</p>
<p>我们的追求的终极目标是让读者信我们讲的故事，在这个故事里面有以下元素：</p>
<ul>
<li>论点，也就是我们对研究问题的一个答案</li>
<li>我们需要用很多原因来支撑我们的论点</li>
<li>然后所有这些原因都应该架在读者能够信的这些论据上面的；</li>
<li>当原因和论点隔得比较远的时候，需要提供一些这样子的担保，来把整个逻辑说的更通一些</li>
<li>不管我们提供多少原因去证明我们的论点，在读者读的时候总会有一些别的一些想法，这时候我们如果能够提前预测出来读者的想法，然后承认他们并回复他们的话能够使得整个故事更加可信</li>
</ul>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.bilibili.com/read/cv17695445">https://www.bilibili.com/read/cv17695445</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫方法技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Android-confluence-代码重构总结</title>
    <url>/9d43e8ed.html</url>
    <content><![CDATA[<p>⭐此confluence系列纪念大三大四TCL实习时在confluence中学习到的一些额外的知识⭐</p>
<h3 id="为什么要重构"><a href="#为什么要重构" class="headerlink" title="为什么要重构"></a>为什么要重构</h3><p>接收新项目时，有时候会感觉项目很难理解，或者说代码很混乱。一接受的时候，不能盲目的认为别人的代码不好，需要认真的分析。因为每个人的代码风格都不一样，每个人的擅长的领域也不一样，所有有时候并不是说代码写的不好，也有可能是使用了一种新的技术，或者新的模式框架，需要我们去深入了解后，才能评估一个项目的好坏。</p>
<p>不能因为我们不熟悉或者不习惯就重构代码，而是应该提升自己的能力，需要学习更多更先进的技术来丰富自己。毕竟重构一个项目是<strong>非常耗时</strong>的。</p>
<span id="more"></span>

<p>哪些情况下是应该重构代码的呢? </p>
<ol>
<li>框架混乱。这种混乱体现在很多方面, 比如:<ul>
<li>文件路径随意。所有Java文件随意新建文件夹。</li>
<li>mvp、mvvm模型随意使用。有些功能非常简单的界面，比如显示关于界面。像这种那么简单的界面，根本就需要使用复杂的模式，直接一个activity就可以搞定的。</li>
<li>复杂界面，功能和数据混合在一起。有些虽然使用一个mvp或者mvvm模型，但是还是能看到在activity上来处理数据的情况，或者说根本没有框架来分离，都在一个类里面实现了。</li>
<li>公用的功能没整合。比如一些功能是很多地方都会调用的，比如存储、访问API这种，哪里使用就哪里写是不方便管理的，这种应该整合到统一的模块中，方便管理和修改。</li>
</ul>
</li>
<li>补丁多。修改bug有很多方法，有的时候为了修改方便，经常能看到直接打补丁的，而不是完善原来的方案的，这种补丁多了就容易出问题。<ul>
<li>举个例子：在一个项目中，有一个接收广播会启动悬浮窗的功能，这种功能因为并没有把应用提升到前台来展示，也就是没启动activity的，所有进程的优先级在系统中是很低的。此时是很容易被系统杀死的，所以为了解决这个问题，就需要提升进程的优先级。</li>
<li>正常的修改，肯定是在接受到广播之后，启用进程优先级更高的控件来提升优先级的，比如前台服务。但是因为悬浮窗显示这块比较麻烦，就看到一种打补丁的方式，就是在启动悬浮窗的同时，再起一个空的前台服务。</li>
<li>以上这种补丁方式，都是有隐患的，如果整个应用里面这种补丁比较多的话呢，整体性能和稳定性是很差的，经常有一个奇奇怪怪的bug。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="重构哪些部分"><a href="#重构哪些部分" class="headerlink" title="重构哪些部分"></a>重构哪些部分</h3><p>重构就是在之前的基础上进行部分的优化, 所以优化哪些部分就是关键。在我看来, UI或者算法之类的, 没有很严重的问题, 是没必要去动的, UI这部分大同小异, 就算重构, 也是UI出图, 代码本身改动有限。算法是核心, 除非你是专业人才, 否则不一定比之前的做的好。</p>
<p>重构的核心我觉得不是创作, 而是整合。整个应用的功能都是开发好的, 只不过还有一些瑕疵, 所以我们只需要把所有的功能重新梳理, 并整合好就可以。</p>
<p>可以从以下部分入手:</p>
<ol>
<li>框架设计: 框架说大点就是整个APP的结构, 说小点呢, 就是activity的模型。<ul>
<li>APP结构的部分呢, 多进程的一定要代码分离。同一进程的需要把基础组件, UI界面和功能模块进行统一管理。最好就是文件夹名称让人一看就明白里面放的是什么。</li>
<li>activity模型部分, 我建议是根据实际情况和个人喜好来规划, 功能简单的不建议使用复杂的模型, 功能复杂的建议选择自己熟悉的模型来操作。比如在mvp模型中, 我就会采用UI界面在activity处理, 数据操作在presenter中处理, 还会再定义一个接口层方便ui-数据之间来相互调用。</li>
<li>比如一个在一个功能很复杂的界面中, 所有的数据和UI交互都整合在一个activity里面, 我想这样的类是很难维护的, 因为代码复杂。这个时候, 对整个activity进行重构就很有必要, 把其中的数据处理和UI进行分离, 统一的模块也需要功能分类, 也就是下一个部分了。</li>
</ul>
</li>
<li>功能分类: 什么样的功能需要提炼出来, 作为一个功能模块呢<ul>
<li>其实很简单, 就是哪些不依赖界面, 不依赖acitivity数据的, 或者是那种通用的方法都是可以提出来作为一个统一的功能模块。这样就能减轻activity的代码量, 只需要一个调用接口就可以实现功能了。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="重构的误区"><a href="#重构的误区" class="headerlink" title="重构的误区"></a>重构的误区</h3><ol>
<li>为了重构而重构<ul>
<li>需要理解哪些部分重构, 在项目中也遇到过, 明明很简单的东西, 为了体现代码的能力, 使用了很复杂的控件或者框架, 我觉得代码首先是性能, 其次就是可阅读性, 在性能相差不大的情况下, 选择简单易懂的才是最好的, 有利用公司内部代码的共享和共同维护。</li>
</ul>
</li>
<li>数据和界面的完全分离<ul>
<li>整体思路应该是分离的, 但是很多情况需要根据使用场景来判断, 不能盲目的所有的照搬照做。比如在视频通话界面, 成员数据和成员界面之间就需要进行同一模块来处理, 为什么要放在一起呢, 因为成员界面是需要改变的, 如果同一界面的移动, 小窗口的布局切换。</li>
</ul>
</li>
</ol>
<p>这些方案都是界面和数据一起移动的, 在这种情况, 不是一味的数据改变来刷新界面, 还需要界面改变来查找数据。这种情况建议就是一个成员的界面和数据做成一个模块来处理。</p>
<hr>
<h3 id="原文信息"><a href="#原文信息" class="headerlink" title="原文信息"></a>原文信息</h3><font style="color:white">
代码重构总结
由 宋杰 创建, 最后修改于2021-04-09
</font>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>Android-confluence-Android常用命令</title>
    <url>/cee21a4b.html</url>
    <content><![CDATA[<p>⭐此confluence系列纪念大三大四TCL实习时在confluence中学习到的一些额外的知识⭐</p>
<h3 id="linux常用命令"><a href="#linux常用命令" class="headerlink" title="linux常用命令"></a>linux常用命令</h3><h4 id="top"><a href="#top" class="headerlink" title="top"></a>top</h4><p>选项说明：<br>-b：以批处理模式操作；<br>-c：显示完整的治命令；<br>-d：屏幕刷新间隔时间；<br>-I：忽略失效过程；<br>-s：保密模式；<br>-S：累积模式；<br>-i&lt;时间&gt;：设置间隔时间；<br>-u&lt;用户名&gt;：指定用户名；<br>-p&lt;进程号&gt;：指定进程；<br>-n&lt;次数&gt;：循环显示的次数。</p>
<span id="more"></span>

<hr>
<h4 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h4><p>解释<br>USER：该进程属于那个使用者账号。<br>PID ：该进程的进程ID号。<br>%CPU：该进程使用掉的 CPU 资源百分比；<br>%MEM：该进程所占用的物理内存百分比；<br>VSZ ：该进程使用掉的虚拟内存量 (Kbytes)<br>RSS ：该进程占用的固定的内存量 (Kbytes)<br>TTY ：该进程是在那个终端机上面运作，若与终端机无关，则显示 ?。另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。<br>STAT：该程序目前的状态，主要的状态有：<br>    R ：该程序目前正在运作，或者是可被运作；<br>    S ：该程序目前正在睡眠当中，但可被某些讯号(signal) 唤醒。<br>    T ：该程序目前正在侦测或者是停止了；<br>    Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态<br>START：该进程被触发启动的时间；<br>TIME ：该进程实际使用 CPU 运作的时间。<br>COMMAND：该程序的实际指令。</p>
<hr>
<h3 id="Android常用命令"><a href="#Android常用命令" class="headerlink" title="Android常用命令"></a>Android常用命令</h3><h4 id="am命令"><a href="#am命令" class="headerlink" title="am命令"></a>am命令</h4><h5 id="am-start"><a href="#am-start" class="headerlink" title="am start"></a>am start</h5><p>选项说明<br>[-a <ACTION>] [-d <DATA_URI>] [-t <MIME_TYPE>]<br>[-c <CATEGORY> [-c <CATEGORY>] …]<br>[-e|–es <EXTRA_KEY> <EXTRA_STRING_VALUE> …]<br>[–ez <EXTRA_KEY> <EXTRA_BOOLEAN_VALUE> …]<br>[-e|–ei <EXTRA_KEY> <EXTRA_INT_VALUE> …]<br>[-n <COMPONENT>] [-f <FLAGS>] [<URI>]</URI></FLAGS></COMPONENT></EXTRA_INT_VALUE></EXTRA_KEY></EXTRA_BOOLEAN_VALUE></EXTRA_KEY></EXTRA_STRING_VALUE></EXTRA_KEY></CATEGORY></CATEGORY></MIME_TYPE></DATA_URI></ACTION></p>
<p>举例<br>am start -n com.android.music/com.android.music.MusicBrowserActivity<br>am start -a android.intent.action.VIEW -d <a href="http://www.google.cn/">http://www.google.cn/</a><br>am start -n com.xxx.tmotion/.activitys.MainActivity –es webUrl “<a href="https://xxxxxxx.api.my7v.com/728page/index.html?debug=true&quot;">https://xxxxxxx.api.my7v.com/728page/index.html?debug=true&quot;</a></p>
<hr>
<h4 id="pm命令"><a href="#pm命令" class="headerlink" title="pm命令"></a>pm命令</h4><h5 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h5><p>用法<br>pm install [-lrtsfd] [-i PACKAGE] [PATH]</p>
<p>参数说明<br>-l    锁定应用程序<br>-r    重新安装应用，且保留应用数据<br>-t    允许测试apk被安装<br>-i <INSTALLER_PACKAGE_NAME>    指定安装包的包名<br>-s    安装到sd卡<br>-f    安装到系统内置存储中（默认安装位置）<br>-d    允许降级安装（同一应用低级换高级）<br>-g    授予应用程序清单中列出的所有权限（只有6.0系统可用）</INSTALLER_PACKAGE_NAME></p>
<p>举例<br>adb shell pm install -r /data/local/tmp/test.apk</p>
<hr>
<h5 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h5><p>用法<br>pm uninstall [options] <PACKAGE></PACKAGE></p>
<p>举例<br>pm uninstall com.xxx.tshop</p>
<hr>
<h5 id="清除应用数据"><a href="#清除应用数据" class="headerlink" title="清除应用数据"></a>清除应用数据</h5><p>用法<br>pm clear [options] <PACKAGE></PACKAGE></p>
<p>举例<br>pm clear com.xxx.tshop</p>
<hr>
<h5 id="禁用-amp-恢复应用"><a href="#禁用-amp-恢复应用" class="headerlink" title="禁用&amp;恢复应用"></a>禁用&amp;恢复应用</h5><p>被禁用应用在应用管理中变得不可见，桌面图标也会消失禁用应用<br>pm disenable com.xxxx.tshop</p>
<hr>
<h4 id="dumpsys命令"><a href="#dumpsys命令" class="headerlink" title="dumpsys命令"></a>dumpsys命令</h4><h5 id="包信息查询"><a href="#包信息查询" class="headerlink" title="包信息查询"></a>包信息查询</h5><p>dumpsys package [-h] [-f] [—checkin] [cmd]…</p>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">-h</td>
<td align="left">打印帮助信息</td>
</tr>
<tr>
<td align="left">-f</td>
<td align="left">打印intent filter的信息</td>
</tr>
<tr>
<td align="left">–checkin</td>
<td align="left">打印出已经登记的库、系统功能、安装包</td>
</tr>
<tr>
<td align="left">cmd</td>
<td align="left">子命令（可以在-h帮助文档中查看有哪些子命令）</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">cmd子命令</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">prov[iders]</td>
<td align="left">获取content providers</td>
</tr>
<tr>
<td align="left">p[ackages]</td>
<td align="left">获取安装包基本信息</td>
</tr>
<tr>
<td align="left">s[hared-user]</td>
<td align="left">获取共享用户ID的应用</td>
</tr>
<tr>
<td align="left">m[essages]</td>
<td align="left">打印运行时收集的信息</td>
</tr>
<tr>
<td align="left">v[erifiers]</td>
<td align="left">打印包校验信息</td>
</tr>
<tr>
<td align="left">version</td>
<td align="left">打印数据库版本信息</td>
</tr>
<tr>
<td align="left">write</td>
<td align="left">写当前位置</td>
</tr>
<tr>
<td align="left">&lt;package.name&gt;</td>
<td align="left">输出给定包的信息</td>
</tr>
<tr>
<td align="left">installs</td>
<td align="left">安装会话的详细信息</td>
</tr>
<tr>
<td align="left">l[ibraries]</td>
<td align="left">列出已知的共享库</td>
</tr>
<tr>
<td align="left">f[ibraries]</td>
<td align="left">列出手机的功能</td>
</tr>
<tr>
<td align="left">k[eysets]</td>
<td align="left">列出各个包的Signing KeySets</td>
</tr>
<tr>
<td align="left">r[esolvers]</td>
<td align="left">获取intent filter</td>
</tr>
<tr>
<td align="left">perm[issions]</td>
<td align="left">获取权限</td>
</tr>
<tr>
<td align="left">pref[erred]</td>
<td align="left">打印包首选项</td>
</tr>
<tr>
<td align="left">preferred-xml [—full]</td>
<td align="left">打印包首选项，xml格式打印</td>
</tr>
</tbody></table>
<hr>
<h5 id="activity信息查询"><a href="#activity信息查询" class="headerlink" title="activity信息查询"></a>activity信息查询</h5><p>adb shell dumpsys activity [-a] [-c]…</p>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">-a</td>
<td align="left">包括所有可用的服务器状态</td>
</tr>
<tr>
<td align="left">-c</td>
<td align="left">包括客户端状态</td>
</tr>
<tr>
<td align="left">-p</td>
<td align="left">限制输出为给定的包，例如： adb shell dumpsys activity -p com.android.browser</td>
</tr>
<tr>
<td align="left">-h</td>
<td align="left">打印帮助信息</td>
</tr>
<tr>
<td align="left">cmd</td>
<td align="left">子命令</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">cmd子命令</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">a[ctivities]</td>
<td align="left">activity堆栈状态</td>
</tr>
<tr>
<td align="left">r[recents]</td>
<td align="left">最近activity的状态</td>
</tr>
<tr>
<td align="left">b[rodacasts] [package_name] [histpry [-s]]</td>
<td align="left">广播状态</td>
</tr>
<tr>
<td align="left">i[ntents] [package_name]</td>
<td align="left">挂起的intent状态</td>
</tr>
<tr>
<td align="left">p[rocesses] [package_name]</td>
<td align="left">进程状态</td>
</tr>
<tr>
<td align="left">o[om]</td>
<td align="left">oom管理</td>
</tr>
<tr>
<td align="left">perm[issions]</td>
<td align="left">url权限授权状态</td>
</tr>
<tr>
<td align="left">prov[iders] [comp_spec…]</td>
<td align="left">content provider状态</td>
</tr>
<tr>
<td align="left">provider [comp_spec]</td>
<td align="left">provider客户端状态</td>
</tr>
<tr>
<td align="left">s[ervices] [comp_spec…]</td>
<td align="left">服务状态</td>
</tr>
<tr>
<td align="left">as[sociations]</td>
<td align="left">跟踪应用程序的关联</td>
</tr>
<tr>
<td align="left">service [comp_spec]</td>
<td align="left">服务客户端状态</td>
</tr>
<tr>
<td align="left">package [package_name]</td>
<td align="left">给的包的所有状态</td>
</tr>
<tr>
<td align="left">all</td>
<td align="left">转储所有的activityes</td>
</tr>
<tr>
<td align="left">top</td>
<td align="left">转储栈顶的activity</td>
</tr>
<tr>
<td align="left">write</td>
<td align="left">写入所有挂起状态存储</td>
</tr>
<tr>
<td align="left">track-associations</td>
<td align="left">允许会话跟踪</td>
</tr>
<tr>
<td align="left">untrack-associations</td>
<td align="left">禁用和明确会话跟踪，命令参数可能也是一个comp_spec 转储的activity</td>
</tr>
</tbody></table>
<hr>
<h5 id="网络信息查询"><a href="#网络信息查询" class="headerlink" title="网络信息查询"></a>网络信息查询</h5><table>
<thead>
<tr>
<th align="left">cmd子命令</th>
<th align="left">说明</th>
<th align="left">命令格式</th>
</tr>
</thead>
<tbody><tr>
<td align="left">connectivity</td>
<td align="left">网络连接</td>
<td align="left">dumpsys connectivity</td>
</tr>
<tr>
<td align="left">netpolicy</td>
<td align="left">网络策略</td>
<td align="left">dumpsys netpolicy</td>
</tr>
<tr>
<td align="left">netstats</td>
<td align="left">网络状态</td>
<td align="left">dumpsys netstats</td>
</tr>
<tr>
<td align="left">network_management</td>
<td align="left">网络管理</td>
<td align="left">dumpsys network_management</td>
</tr>
</tbody></table>
<hr>
<h5 id="其他常用服务信息查询"><a href="#其他常用服务信息查询" class="headerlink" title="其他常用服务信息查询"></a>其他常用服务信息查询</h5><table>
<thead>
<tr>
<th align="left">cmd子命令</th>
<th align="left">说明</th>
<th align="left">命令格式</th>
</tr>
</thead>
<tbody><tr>
<td align="left">meminfo</td>
<td align="left">内存</td>
<td align="left">dumpsys meminfo</td>
</tr>
<tr>
<td align="left">cpuinfo</td>
<td align="left">CPU</td>
<td align="left">dumpsys cpuinfo</td>
</tr>
<tr>
<td align="left">gfxinfo</td>
<td align="left">帧率</td>
<td align="left">dumpsys gfxinfo</td>
</tr>
<tr>
<td align="left">display</td>
<td align="left">显示</td>
<td align="left">dumpsys display</td>
</tr>
<tr>
<td align="left">power</td>
<td align="left">电源</td>
<td align="left">dumpsys power</td>
</tr>
<tr>
<td align="left">batterystats</td>
<td align="left">电池状态</td>
<td align="left">dumpsys batterystats</td>
</tr>
<tr>
<td align="left">battery</td>
<td align="left">电池</td>
<td align="left">dumpsys battery</td>
</tr>
<tr>
<td align="left">alarm</td>
<td align="left">闹钟</td>
<td align="left">dumpsys alarm</td>
</tr>
<tr>
<td align="left">location</td>
<td align="left">位置</td>
<td align="left">dumpsys location</td>
</tr>
</tbody></table>
<hr>
<h4 id="允许应用安装"><a href="#允许应用安装" class="headerlink" title="允许应用安装"></a>允许应用安装</h4><p>setprop persist.xxx.installapk.enable 1<br>setprop persist.xxx.debug.installapk 1</p>
<hr>
<h4 id="关闭系统日志"><a href="#关闭系统日志" class="headerlink" title="关闭系统日志"></a>关闭系统日志</h4><p>echo 0 &gt; /proc/sys/kernel/printk</p>
<hr>
<h4 id="挂载获取system目录写权限"><a href="#挂载获取system目录写权限" class="headerlink" title="挂载获取system目录写权限"></a>挂载获取system目录写权限</h4><p>mount -o rw,remount /system</p>
<hr>
<h4 id="开发者选项"><a href="#开发者选项" class="headerlink" title="开发者选项"></a>开发者选项</h4><p>setprop debug.hwui.overdraw show            //显示过渡绘制<br>setprop debug.hwui.profile visual_bars      //显示帧率</p>
<hr>
<h3 id="原文信息"><a href="#原文信息" class="headerlink" title="原文信息"></a>原文信息</h3><font style="color:white">
Android常用命令
由 王世昌 创建, 最后修改于2020-03-30
</font>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Android</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-ProGAN、StyleGAN、Diffusion GAN…你都掌握了吗？一文总结图像生成必备经典模型（一）</title>
    <url>/f9495119.html</url>
    <content><![CDATA[<p>本文将分 2 期进行连载，共介绍 <strong>16 个在图像生成</strong>任务上曾取得 SOTA 的经典模型。</p>
<ul>
<li>第 1 期：ProGAN、StyleGAN、StyleGAN2、StyleGAN3、VDVAE、NCP-VAE、StyleGAN-xl、Diffusion GAN</li>
<li>第 2 期：WGAN、SAGAN、BIG-GAN、CSGAN、LOGAN、UNet-GAN、IC-GAN、ADC-GAN</li>
</ul>
<p>现在正在阅读的是其中的第 1 期。前往 SOTA！模型资源站（sota.jiqizhixin.com）即可获取本文中包含的模型实现代码、预训练模型及 API 等资源。</p>
<span id="more"></span>

<p>本期收录模型速览</p>
<table>
<thead>
<tr>
<th align="left">模型</th>
<th align="left">SOTA！模型资源站收录情况</th>
<th align="left">模型来源论文</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ProGAN</td>
<td align="left"><a href="https://sota.jiqizhixin.com/project/0190e1fa-5643-4043-8b75-9b863a6d20db">https://sota.jiqizhixin.com/project/0190e1fa-5643-4043-8b75-9b863a6d20db</a></td>
<td align="left">Progressive Growing of GANs for Improved Quality, Stability, and Variation</td>
</tr>
<tr>
<td align="left">StyleGAN</td>
<td align="left"><a href="https://sota.jiqizhixin.com/project/e072cfc0-26c3-40e7-a979-60df61170c7a">https://sota.jiqizhixin.com/project/e072cfc0-26c3-40e7-a979-60df61170c7a</a></td>
<td align="left">A Style-Based Generator Architecture for Generative Adversarial Networks</td>
</tr>
<tr>
<td align="left">StyleGAN2</td>
<td align="left"><a href="https://sota.jiqizhixin.com/project/a07f5a80-bf97-4a33-a2a8-4ff938b1b82f">https://sota.jiqizhixin.com/project/a07f5a80-bf97-4a33-a2a8-4ff938b1b82f</a></td>
<td align="left">Analyzing and Improving the Image Quality of StyleGAN</td>
</tr>
<tr>
<td align="left">StyleGAN3</td>
<td align="left"><a href="https://sota.jiqizhixin.com/project/6f7d3d51-762a-4d23-a572-3ea79ab49b4f">https://sota.jiqizhixin.com/project/6f7d3d51-762a-4d23-a572-3ea79ab49b4f</a></td>
<td align="left">Alias-Free Generative Adversarial Networks</td>
</tr>
<tr>
<td align="left">VDVAE</td>
<td align="left"><a href="https://sota.jiqizhixin.com/project/0ed2229c-722b-47fb-b6aa-d22dedf87f1b">https://sota.jiqizhixin.com/project/0ed2229c-722b-47fb-b6aa-d22dedf87f1b</a></td>
<td align="left">Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images</td>
</tr>
<tr>
<td align="left">NCP-VAE</td>
<td align="left"><a href="https://sota.jiqizhixin.com/project/74d15cbe-7f75-434a-a1cf-a69ae303eec6">https://sota.jiqizhixin.com/project/74d15cbe-7f75-434a-a1cf-a69ae303eec6</a></td>
<td align="left">A Contrastive Learning Approach for Training Variational Autoencoder Priors</td>
</tr>
<tr>
<td align="left">StyleGAN-xl</td>
<td align="left"><a href="https://sota.jiqizhixin.com/project/01d16b00-e79f-4527-a7e3-08354b5d9b47">https://sota.jiqizhixin.com/project/01d16b00-e79f-4527-a7e3-08354b5d9b47</a></td>
<td align="left">StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets</td>
</tr>
<tr>
<td align="left">Diffusion GAN</td>
<td align="left"><a href="https://sota.jiqizhixin.com/project/9aa9b499-adec-46a3-aef9-4cd73e1c13ec">https://sota.jiqizhixin.com/project/9aa9b499-adec-46a3-aef9-4cd73e1c13ec</a></td>
<td align="left">Diffusion-GAN: Training GANs with Diffusion</td>
</tr>
</tbody></table>
<p>生成模型是一种训练模型进行无监督学习的模型，即，给模型一组数据，希望从数据中学习到信息后的模型能够生成一组和训练集尽可能相近的数据。图像生成（Image generation，IG）则是指从现有数据集生成新的图像的任务。图像生成模型包括无条件生成和条件性生成两类，其中，无条件生成是指从数据集中无条件地生成样本，即p(y)；条件性图像生成是指根据标签有条件地从数据集中生成样本，即p(y|x)。</p>
<p>图像生成也是深度学习模型应用比较广泛、研究程度比较深的一个主题，大量的图像库也为SOTA模型的训练和公布奠定了良好的基础。在几个著名的图像生成库中，例如CIFAR-10、ImageNet64、ImageNet32、STL-10、CelebA 256、CelebA64等等，目前公布出的最好的无条件生成模型有StyleGAN-XL、Diffusion ProjectedGAN；在ImageNet128、TinyImageNet、CIFAR10、CIFAR100等库中，效果最好的条件性生成模型则是LOGAN、ADC-GAN、StyleGAN2等。</p>
<img src="/f9495119/1.png" class>

<p>我们在这篇文章中介绍图像生成必备的TOP模型，从无条件生成模型和条件性生成模型两个类别分别介绍。图像生成模型的发展非常快，所以与其它几个topic不同，图像生成中必备的TOP模型介绍主要以近两年的SOTA模型为主。</p>
<hr>
<h3 id="无条件生成模型"><a href="#无条件生成模型" class="headerlink" title="无条件生成模型"></a>无条件生成模型</h3><h4 id="ProGAN"><a href="#ProGAN" class="headerlink" title="ProGAN"></a>ProGAN</h4><p>生成性对抗网络（GAN）是机器学习中一个相对较新的概念，于2014年首次引入。GAN的目标是合成与真实图像无法区分的人工样本，如图像。GAN的基本组成部分是两个神经网络：一个新样本的生成器（G），一个从训练数据和生成器输出中提取样本并预测它们是“真”还是“假”的鉴别器（D）。生成器的输入是一个随机向量（噪声），因此其初始输出也是噪声。随着训练的进行，当它收到鉴别器的反馈时，会学习合成更“真实”的图像。鉴别器还通过将生成的样本与真实样本进行比较，随着训练的进行不断改进，使得生成器更难欺骗它。</p>
<p>ProGAN是NVIDIA投稿ICLR 2018的一篇文章，ProGAN关键创新在于渐进式训练，它在经典GAN的基础上首先通过学习在低分辨率图像中也可以显示的基本特征，来创建图像的基本部分，并且随着分辨率的提高和时间的推移，学习越来越多的细节。低分辨率图像的训练不仅简单、快速，而且有助于更高级别的训练，因此，整体的训练也就更快。ProGAN被认为是后来大热的StyleGAN的前身。</p>
<img src="/f9495119/2.png" class>
<p>图1 ProGAN架构</p>
<p>ProGAN的训练部分，从低分辨率的图像开始，通过向网络添加层来逐步提高分辨率，如图2所示。这种递增的性质允许训练首先发现图像分布的大规模结构，然后将注意力转移到越来越精细的细节上，而不是同时学习所有的尺度。使用生成器和鉴别器网络，它们是彼此的镜像，并且总是同步增长。在整个训练过程中，两个网络中的所有现有层都是可训练的。当新的层被添加到网络中时，平稳地将它们淡化，如图3所示。这就避免了对已经训练好的小分辨率层的突然冲击。</p>
<img src="/f9495119/3.png" class>
<p>图2 训练开始时，生成器（G）和鉴别器（D）的空间分辨率都很低，只有4×4像素。随着训练的进行，逐步增加G和D的层数，从而提高生成图像的空间分辨率</p>
<img src="/f9495119/4.png" class>
<p>图3  当生成器（G）和鉴别器（D）的分辨率翻倍时，顺利地淡化新层。这个例子说明了从16×16图像（a）到32×32图像（c）的过渡。在过渡期间（b），把在更高的分辨率上操作的层当作一个残差块，其权重α从0到1线性增加</p>
<p>GAN还有一个问题是只捕捉训练数据中发现的变化的一个子集，mini-batch就是为了解决这个问题提出的，它是通过在鉴别器的末尾添加一个minibatch层来实现的，该层学习一个大的张量，将输入激活投射到一个统计数组。mini-batch中的每个样本都会产生一组单独的统计数据，并将其串联到该层的输出中，这样鉴别器就可以在内部使用这些统计数据。</p>
<p>ProGAN的简化方案既没有可学习的参数，也没有新的超参数，而是引入了特征的标准差作为衡量标准。首先计算每个特征在每个空间位置上的标准偏差。然后，在所有特征和空间位置上平均这些估计值，得到一个单一的值。复制这个值并将其连接到所有的空间位置和minibatch上，产生一个额外的（恒定）特征图。这一层可以插入鉴别器的任何地方，将其在最后插入效果最好。这个特征图中包含了不同样本之间的差异性信息，送入鉴别器后，经过训练，生成样本的差异性也会与训练样本的相似。</p>
<p>此外，ProGAN还对生成器和鉴别器进行了归一化处理，归一化主要是用来控制信号幅度，从而减少G与D之间的不正常竞争，沿channel维度对每个像素的特征长度归一化。minibatch statistic layer沿着batch维度求标准差，而它沿着channel维度求norm。</p>
<p>当前 SOTA！平台收录ProGAN共 1 个模型实现资源。</p>
<img src="/f9495119/5.png" class>

<table>
<thead>
<tr>
<th align="left">项目</th>
<th align="left">SOTA！平台项目详情页</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ProGAN</td>
<td align="left">前往SOTA！模型平台获取实现资源：<a href="https://sota.jiqizhixin.com/project/0190e1fa-5643-4043-8b75-9b863a6d20db">https://sota.jiqizhixin.com/project/0190e1fa-5643-4043-8b75-9b863a6d20db</a></td>
</tr>
</tbody></table>
<hr>
<h4 id="StyleGAN"><a href="#StyleGAN" class="headerlink" title="StyleGAN"></a>StyleGAN</h4><p>StyleGAN是一种开创性的工作，不仅可以生成高质量和逼真的图像，还可以对生成的图像进行更好的控制和理解，从而比以前更容易生成可信的假图像。StyleGAN是ProGAN图像生成器的升级版本，重点关注生成器网络（G）。</p>
<p>StyleGAN的重点就是“Style”，在提出StyleGAN的论文中具体是指人脸的风格，包括人脸表情、人脸朝向、发型等等，还包括纹理细节上的人脸肤色、人脸光照等。进一步对这些Style进行细分为：1）粗-分辨率高达8 * 8-影响姿势、一般发型、人脸形状等；2）中等-分辨率16 * 16到32 * 32-影响更精细的人脸特征、发型、睁眼/闭眼等；3）精细-分辨率为64 * 64到1024 * 1024-影响配色方案（眼睛、头发和皮肤）和微观特征。</p>
<img src="/f9495119/6.png" class>
<p>图4 StyleGAN结构</p>
<p>StyleGAN 的网络结构包含两个部分，第一个是Mapping network，即图 4(b)的左部分，由潜在变量 z 生成中间潜在变量 w的过程，w用来控制生成图像的style。第二个是Synthesis network，它的作用是生成图像，创新之处在于给每一层子网络都输入A 和 B，A 是由 w 转换得到的仿射变换，用于控制生成图像的style，B 是转换后的随机噪声，用于丰富生成图像的细节，即每个卷积层都能根据输入的A来调整”style”。整个网络结构还是保持了 ProGAN 的结构。经典GAN的随机变量或者潜在变量 z是通过输入层，即前馈网络的第一层提供给生成器的（图4a）。而StyleGAN完全省略了输入层，直接从一个学习的常数开始（图4b，右），即将 z 单独用 mapping网络变换成w，再将w输入给 Synthesis network的每一层。</p>
<p>Mapping network 要做的事就是对潜在空间（latent space）进行解耦，Mapping network由8个全连接层组成，其输出与输入层的大小相同。通过一系列仿射变换，由 z 得到 w，这个 w 转换成风格y=(ys,yb) ，结合 AdaIN (adaptive instance normalization) 风格变换方法：</p>
<img src="/f9495119/7.png" class>

<p>使用输入向量控制视觉特征的能力是有限的，因为它必须遵循训练数据的概率密度。例如，如果黑发人的图像在数据集中更常见，则更多输入值将映射到该特征。因此，该模型无法将部分输入（向量中的元素）映射到特征，这种现象称为特征纠缠。然而，Mapping network通过使用另一个神经网络，可以生成一个不必遵循训练数据分布的向量，并且可以减少特征之间的相关性。</p>
<p>具体到AdaIN（也称为Style模块），该模块被添加到生成网络的每个分辨率级别，并定义该级别中特征的视觉表达：首先对卷积层输出的每个通道进行正则归一化，以确保缩放和移位达到预期效果；然后，使用另一个全连接层转换为每个通道的比例和偏差；最后，将尺度变化和偏置移动作用于卷积输出的每个通道，从而定义卷积中每个滤波器的重要性。利用AdaIN实现了将信息从潜在变量转化为一种视觉表现。在StyleGAN中，可以省略初始随机噪声输入，用常量值替换。这种操作减少了特征纠缠，因为网络不再依赖于互相纠缠的输入向量。AdaIN 层的含义同BN层类似，其目的是对网络中间层的输出结果进行scale和shift，以增加网络的学习效果，避免梯度消失。相对于BN是学习当前batch数据的mean和variance，Instance Norm则是采用了单张图片。AdaIN则是使用learnable的scale和shift参数去对齐特征图中的不同位置。</p>
<p>具体到人脸图像生成任务，人脸有很多的特征都很小且可以看作是随机的，例如雀斑、头发的精确位置、皱纹等，这些可以使图像更逼真，并增加输出的多样性。将这些小特征插入GAN图像的常用方法是向输入向量添加随机噪声。然而，在许多情况下，由于上述特征纠缠现象，很难控制噪声效果，这会导致图像的其他特征受到影响。StyleGAN中的噪声以与AdaIN机制类似的方式添加，即在AdaIN模块之前向每个通道添加控制缩放的噪声，并稍微改变其操作分辨率级别特征的视觉表达。</p>
<p>为了进一步定位Style，引入混合正则化的处理方式，即在训练过程中，一定比例的图像是使用两个随机潜在变量而不是一个潜在变量生成的。在生成这样的图像时，只需在生成网络中随机选择一个点，从一个潜在变量切换到另一个潜在变量即Style mix。具体的，通过mapping network运行两个潜在变量z1、z2，并让相应的w1、w2控制style，使w1在crossover point之前适用，w2在crossover point之后适用。这种正则化技术可以防止网络假设相邻的风格是相关的。</p>
<p>最后，针对特征解纠缠（disentanglement）问题，对于disentanglement各种定义的共同的目标是由线性子空间组成的隐藏空间，每个子空间控制一个变化因素。然而，Z中每个因素组合的采样概率需要与训练数据中的相应密度相匹配。如图5所示，因素无法与典型的数据集和输入的潜在分布完全分离。</p>
<img src="/f9495119/8.png" class>
<p>图5. 有两个变化因素（图像特征，如男性化和头发长度）的说明性示例。(a) 一个样本训练集，其中一些组合（如长发男性）是缺失的。(b) 这迫使从Z到图像特征的映射变得弯曲，以便被禁止的组合在Z中消失，以防止无效组合的采样。(c) 从Z到W的学习映射能够 “撤销 “大部分的弯曲</p>
<p>为了量化特征分离的表现，本文提出了量化两种特征分离的新方法：</p>
<ol>
<li>感知路径长度：在两个随机输入之间插值时，测量连续图像之间的差异。剧烈的变化意味着多个功能一起发生了变化，它们可能会相互纠缠。</li>
<li>线性可分性：将输入分类为二元类的能力，如男性和女性。分类越好，特征越可分离。</li>
</ol>
<p>当前 SOTA！平台收录StyleGAN共 75 个模型实现资源。</p>
<img src="/f9495119/9.png" class>

<table>
<thead>
<tr>
<th align="left">项目</th>
<th align="left">SOTA！平台项目详情页</th>
</tr>
</thead>
<tbody><tr>
<td align="left">StyleGAN</td>
<td align="left">前往SOTA！模型平台获取实现资源：<a href="https://sota.jiqizhixin.com/project/e072cfc0-26c3-40e7-a979-60df61170c7a">https://sota.jiqizhixin.com/project/e072cfc0-26c3-40e7-a979-60df61170c7a</a></td>
</tr>
</tbody></table>
<hr>
<h4 id="StyleGAN2"><a href="#StyleGAN2" class="headerlink" title="StyleGAN2"></a>StyleGAN2</h4><p>StyleGAN2是为了应对StyleGAN的问题而提出的：少量生成的图片有明显的水珠（water-droplet artifacts），这个水珠也存在于feature map上。导致水珠的原因是 AdaIN，AdaIN对每个feature map进行归一化，因此有可能会破坏掉feature之间的信息。作者认为出现droplet artifact的原因是生成器有意将信号强度信息隐藏再实例归一化后的结果中：通过创建一个强大的、局部的尖峰来控制统计数据，生成器可以有效地缩放信号。</p>
<img src="/f9495119/10.png" class>
<p>图6 StyleGAN存在的水珠问题</p>
<img src="/f9495119/11.png" class>
<p>图7 重新设计StyleGAN synthesis network 。(a) StyleGAN，A表征生成style的学习映射变换，B为噪声广播操作；(b) StyleGAN的详细表述，其中，将AdaIN拆分以更加明确归一化操作，两者均基于每个特征图的平均值和标准偏差；(c)StyleGAN2架构，在开始时删除了一些冗余操作，将b和B的添加移动到style的活动区域之外，并仅调整每个特征映射的标准偏差；(d) 将实例归一化替换为“demodulation”操作，将其应用于与每个卷积层相关联的权重</p>
<p>修改StyleGAN的生成器。首先，StyleGAN2将AdaIN重构为Weight Demodulation。如图7（d）所示，modulation根据传入的style对卷积的每个输入特征图进行缩放，也可以通过缩放卷积权重来实现：</p>
<img src="/f9495119/12.png" class>

<p>其中，w和w’分别表征原始的和modulated的权重，s_i为对应第i个输入特征图的尺度，j和k分别表示生成输出特征图和卷积的空间分布图。接着对卷积层的权重进行demod：</p>
<img src="/f9495119/13.png" class>

<p>从而得到新的卷积层权重为：</p>
<img src="/f9495119/14.png" class>

<p>加一个小的ϵ是为了避免分母为0，保证数值稳定性。尽管这种方式与Instance Norm并非在数学上完全等价，但是weight demodulation同其它normalization 方法一样，使得输出特征图有着standard的unit和deviation。此外，将scaling参数挪为卷积层的权重使得计算路径可以更好的并行化。这种方式使得训练加速了约40%。</p>
<p>第二，虽然诸如FID或精确率和召回率（Precision and Recall，P&amp;R）等GAN指标成功地捕获了生成器的许多方面，但它们在图像质量方面仍然有一些盲点。感知图像质量和感知路径长度（perceptual path length，PPL）之间的相关性指标最初是用来量化从潜在空间到输出图像的映射的平滑度，通过测量潜在空间的小扰动下生成的图像之间的平均LPIPS距离来实现。更小的PPL（更平滑的发生器映射）似乎与更高的整体图像质量相关，而其他指标则对此并不敏感。为什么低PPL会与图像质量相关，这一点尚不明确。作者假设，在训练过程中，由于鉴别器对broken image进行惩罚，则改进生成器的最直接方式是有效地拉伸能够产生良好图像的潜在空间区域。</p>
<p>作者通过引入regularization的方式实现上述目标。StyleGAN2使用lazy regularization的策略，即对数据分布开始跑偏的时候才使用R1 regularization，其它时候不使用。Path Length Regularization的意义是使得latent space的插值变得更加平滑和线性。简单来说，当在latent space中对latent vector进行插值操作时，我们希望对latent vector的等比例的变化直接反映到图像中去。即：“在latent space和image space应该有同样的变化幅度（线性的latent space）”（比如说，当你对某一组latent vector进行了5个degree的偏移，那么反映在最后的生成图像中，应该是同样的效果）。</p>
<p>最后，与StyleGAN第一代使用progressive growing的策略不同，StyleGAN2开始寻求其它的设计以便于让网络更深，并有着更好的训练稳定性。progressive growing的关键问题是，逐渐演进的生成器会对细节有着强烈的位置偏好；当像牙齿或眼睛这样的特征应该在图像上平滑移动时，它们反而可能在跳到下一个首选位置之前停留在原地。如图8所示。</p>
<img src="/f9495119/15.png" class>
<p>图8. progressive growing会导致 “相位 “伪影。在这个例子中，牙齿没有跟随姿势，而是与相机保持一致，如蓝线所示</p>
<p>为此，作者重新评估了StyleGAN的网络设计，并寻找一种能生成高质量图像而又不会逐渐增长的架构。如图9所示，作者对比了MSG-GAN、对不同分辨率的RGB输出的贡献进行上采样和求和、残差连接。StyleGAN2采用了类似ResNet的残差连接结构(residual block)，使用双线性滤波对前一层进行上/下采样，并尝试学习下一层的残差值(residual value)。通过一个resnet风格的skip connection在低分辨率的特征映射到最终生成的图像（图9（c）的绿色block）。</p>
<img src="/f9495119/16.png" class>
<p>图9. 三个生成器（虚线以上）和鉴别器的结构。上面和下面分别表示双线性上采样和下采样。在残差网络中，这些还包括一个1×1的卷积，以调整特征图的数量</p>
<p>当前 SOTA！平台收录 StyleGAN2 共 1 个模型实现资源。</p>
<img src="/f9495119/17.png" class>

<table>
<thead>
<tr>
<th align="left">项目</th>
<th align="left">SOTA！平台项目详情页</th>
</tr>
</thead>
<tbody><tr>
<td align="left">StyleGAN2</td>
<td align="left">前往SOTA！模型平台获取实现资源：<a href="https://sota.jiqizhixin.com/project/a07f5a80-bf97-4a33-a2a8-4ff938b1b82f">https://sota.jiqizhixin.com/project/a07f5a80-bf97-4a33-a2a8-4ff938b1b82f</a></td>
</tr>
</tbody></table>
<hr>
<h4 id="StyleGAN3"><a href="#StyleGAN3" class="headerlink" title="StyleGAN3"></a>StyleGAN3</h4><p>对于StyleGAN系列来说，生成网络是整体训练的，深层网络特征的空间位置并不是由浅层网络特征很强的控制，而是还受到监督信息（如对抗损失、重构损失等）的决定性的影响，粗糙特征（GAN的浅层网络的输出特征）主要控制了精细特征（GAN的深层网络的输出特征）的存在与否，没有严格控制他们出现的精确位置。按照作者所说：“画面上的细节似乎被粘在了图像坐标上，而不是被描述的物体表面。”作者认为，其根本原因是信号处理导致了生成网络的aliasing。StyleGAN3主要是为了解决这一问题提出的，即实现高质量的 Equivariance（等变性）。所以，StyleGAN3的标题为 Alias-Free GAN。</p>
<p>StyleGAN2生成器由两部分组成。首先，一个映射网络将初始的、正常分布的latent转换为 intermediate latent code w∼W。然后，一个synthesis网络G从学习的4×4×512常数Z0开始，应用N层处理—包括卷积、非线性、上采样和per-pixel噪声—以生成输出图像Z_N＝G(Z0；w)。intermediate latent code w控制G中卷积核的调制。各层遵循严格的2×上采样，在每个分辨率下执行两个层，每次上采样后特征图的数量减半。此外，StyleGAN2采用了skip connection、 mixing regularization和 path length regularization 。StyleGAN3目标是使G的每一层对连续信号都是Equivariance的，这样所有较细的细节就会与局部邻域的较粗的特征一起转化。如果这成功了，整个网络也会变得类似于Equivariance。换句话说，目标是使synthesis网络的连续操作g对应用于连续输入z0的变换t（平移和旋转）具有Equivariance：</p>
<img src="/f9495119/18.png" class>

<p>其中 t 是一种变换（平移或旋转），上式表明生成器对特征信号的连续运算应该对于平移和旋转操作是等变的。改进后的生成器网络结构图见图10。</p>
<img src="/f9495119/19.png" class>
<p>图10 (a) 2×上采样滤波器的一维例子，n = 6, s = 2, fc = 1, fh = 0.4（蓝色）。设置fh=0.6使得过渡带更宽（绿色），这减少了不需要的阻带纹波，从而导致更强的衰减。(b) alias-free生成器，对应于配置T和R。主要的数据路径包括傅里叶特征和归一化，调制卷积和过滤非线性。(c) Flexible layer specification（配置T），N=14，sN=1024。截止点fc（蓝色）和最小可接受的阻带频率ft（橙色）服从各层的几何级数；采样率s（红色）和实际阻带fc+fh（绿色）是根据设计约束计算出来的</p>
<p>首先是将StyleGAN2的生成器的常数输入替换为Fourier特征，删除噪声输入，降低映射网络深度并禁用 mixing regularization 和 path length regularization， 在每次卷积前使用简单的归一化。（B，C，D改进步骤）。</p>
<p>通过在目标空间周围保持一个固定大小的边界来进行近似，在每一层之后都要crop到这个扩展的空间上。用理想低通滤波器的一个更好的近似来代替双线性上采样：带有较大Kaiser窗口（n=6）的 sinc 滤波器，Kaiser窗口的好处是提供了对过渡带和衰减的明确控制。改进的边界和上采样得到了更好的平移Equivariance，但是FID变差了。（E改进步骤）。</p>
<p>由于信号是有带限的，所以可以切换上采样和卷积的顺序，允许将常规的2×上采样和随后与非线性相关的m×上采样融合到一个2m×上采样中，并将整个upsample-LReLU-downsample过程写到一个自定义的CUDA内核中。（F改进步骤）。</p>
<p>为了抑制aliasing，可以简单地将截止频率降低到fc = s/2 - fh，这样可以确保所有的alias频率（高于s/2）都在阻带中。作者又额外加了一些trick使得FID低于了StyleGAN2。（G改进步骤）。</p>
<p>引入一个学习型仿射层，为输入的傅里叶特征输出全局平移和旋转参数。该层被初始化为 identity transformation 。但随着时间的推移，在有利的情况下会学习使用该机制。(H改进步骤）。</p>
<p>作者还设计了新的层规范化操作再次提高平移的Equivariance，目的是增强衰减来完全消除alias。（T改进步骤）。</p>
<p>生成一个有两个变体的rotated equivalence网络。首先，将所有层的3×3卷积改为1×1，并通过将特征图的数量增加一倍来弥补容量的减少。在这个配置中，只有上采样和下采样操作在像素之间传播信息。其次，用一个径向对称的jinc-based的滤波器取代sinc-based的下采样滤波器，用同样的Kaiser方案来构建这个滤波器。对所有的层都是这样做的，除了两个关键的采样层。这两个采样层最重要的是要与训练数据的potential non-radiometric spectrum相匹配。（R改进步骤）。</p>
<p>当前 SOTA！平台收录 StyleGAN3 共 2 个模型实现资源。</p>
<img src="/f9495119/20.png" class>

<table>
<thead>
<tr>
<th align="left">项目</th>
<th align="left">SOTA！平台项目详情页</th>
</tr>
</thead>
<tbody><tr>
<td align="left">StyleGAN3</td>
<td align="left">前往SOTA！模型平台获取实现资源：<a href="https://sota.jiqizhixin.com/project/6f7d3d51-762a-4d23-a572-3ea79ab49b4f">https://sota.jiqizhixin.com/project/6f7d3d51-762a-4d23-a572-3ea79ab49b4f</a></td>
</tr>
</tbody></table>
<hr>
<h4 id="VDVAE"><a href="#VDVAE" class="headerlink" title="VDVAE"></a>VDVAE</h4><p>VDVAE是一个层次化的VAE，它能快速生成样本，并在所有自然图像基准上的 log-likelihood 方面优于PixelCNN。文章论证了增加 VAE 的层数能够在保证生成速度的情况下，实现超过自回归模型 (AR) 的 NLL (negative log-likelihood)。VDVAE的基本假设就是：我们可以通过增加 VAE 的层数获得更好的 VAE。首先，本文采用类似 LVAE 的并行化生成，示意图如下：</p>
<img src="/f9495119/21.png" class>
<p>图11 在VAE中可能学到的不同生成模型。左图：一个层次化的VAE可以通过使用确定性的identity functions作为编码器来学习自回归模型，并在先验中学习自回归。右图：学习编码器可以导致潜在变量的有效分层（黑色）。如果最下面的三组潜在变量是有条件地独立于第一组潜在变量的，那么它们可以在一个单层内平行生成，可能会导致更快的采样</p>
<p>当然了，只是单纯的增加VAE的层数并不可行，作者对VAE进行了一些改进，包括减少 residual block 的维度，将残差乘以一个常数，去掉 weight normalization, 使用 nearest-neighbour upsampling, skip 较大的 gradient 等。如图12所示。它类似于ResNet VAE，但有bottleneck ResNet块。对于每个随机层，先验和后验是对角线高斯分布。作为权重归一化和依赖数据的初始化的替代方案，采用默认的PyTorch权重归一化。唯一的例外是对每个剩余bottleneck ResNet块中的最后一个卷积层，将其按1/sqrt(N)进行扩展，其中N是深度。此外，对 “unpool “层使用了最近邻的上采样，当与ResNet架构配对时，可以完全消除相关工作中出现的 “free bits “和KL “warming up “。当上采样通过转置卷积层进行时，网络可能会忽略低分辨率的层（例如，1x1或4x4层）。</p>
<img src="/f9495119/22.png" class>
<p>图12. 自上而下的VAE架构的图示。残差块类似于bottleneck ResNet块。q_φ(.)和p_θ(.)是对角线高斯分布。使用平均池化和最近邻上采样来进行池化和非池化层的处理</p>
<p>当前 SOTA！平台收录 VDVAE 共1个模型实现资源。</p>
<img src="/f9495119/23.png" class>

<table>
<thead>
<tr>
<th align="left">项目</th>
<th align="left">SOTA！平台项目详情页</th>
</tr>
</thead>
<tbody><tr>
<td align="left">VDVAE</td>
<td align="left">前往SOTA！模型平台获取实现资源：<a href="https://sota.jiqizhixin.com/project/0ed2229c-722b-47fb-b6aa-d22dedf87f1b">https://sota.jiqizhixin.com/project/0ed2229c-722b-47fb-b6aa-d22dedf87f1b</a></td>
</tr>
</tbody></table>
<hr>
<h4 id="NCP-VAE"><a href="#NCP-VAE" class="headerlink" title="NCP-VAE"></a>NCP-VAE</h4><p>VAE是强大的基于似然的生成模型之一，在许多领域的应用都取得了很好的效果。然而，它们很难生成高质量的图像，特别是当从先验中获得的样本没有任何调节时。对VAEs生成质量差的一个解释是 prior hole 问题：先验分布不能与总的近似后验相匹配。由于这种不匹配，潜在空间中存在着在先验下具有高密度的区域，而这些区域并不对应于任何编码的图像。来自这些区域的样本被解码为损坏的图像。为了解决这个问题，作者提出了一个基于能量的先验，其定义是基数先验分布与reweighting factor的乘积，目的是使基数更接近总后验。通过噪声对比估计来训练reweighting factor，并将其推广到具有许多潜在变量组的分层VAEs。</p>
<p>这项工作的关键点在于，作为训练VAE的结果，可训练的先验被尽可能地接近 aggregate posterior。先验和 aggregate posterior 之间的不匹配可以通过重新加权来减少，在与 aggregate posterior 不匹配的地方重新调整其可能性。为了表示这种加权机制，使用EBM（ Energy-based Models ）来确定先验，EBM是由一个 reweighting factor 和一个基础可训练先验的乘积来定义的，如图13所示。用神经网络表示 reweighting factor ，用正态分布表示基本先验。</p>
<img src="/f9495119/24.png" class>
<p>图13 提出了一种EBM先验，使用基础先验p(z)和 reweighting factor r(z)的乘积，旨在使p(z)更接近aggregate posterior q(z)</p>
<p>基于EBM，引入NCP（ the noise contrastive prior ）计算基础先验：</p>
<img src="/f9495119/25.png" class>

<img src="/f9495119/26.png" class>

<p>使用两阶段训练方法训练NCP，如图14。在第一阶段，使用原始VAE目标训练VAE。在第二阶段，使用噪声对比估计（noise contrast estimation，NCE）来训练重新加权因子r(z)。NCE训练一个分类器来区分来自先验的样本和来自aggregate posterior的样本。NCP是由基础先验和reweighting factor的乘积构建的，通过分类器形成。在测试时，使用采样-重要性-采样（ sampling-importance-resampling ，SIR）或LD（Langevin dynamics ）从NCP中采样。然后，这些样本被传递给解码器以产生输出样本。</p>
<img src="/f9495119/27.png" class>
<p>图14. NCP-VAE的训练分为两个阶段</p>
<p>最后，作者还将NCP-VAE扩展到了Hierarchical VAEs</p>
<img src="/f9495119/28.png" class>

<p>其中，每个因子都是EBM。pNCP(z)类似于具有自回归结构的组间EBM。在第一阶段，以先验的方式训练HVAE：</p>
<img src="/f9495119/29.png" class>

<p>在第二阶段，我们使用K个二进制分类器，每个分类器用于一个分层组。通过以下方式训练每个分类器</p>
<img src="/f9495119/30.png" class>

<img src="/f9495119/31.png" class>

<table>
<thead>
<tr>
<th align="left">项目</th>
<th align="left">SOTA！平台项目详情页</th>
</tr>
</thead>
<tbody><tr>
<td align="left">NCP-VAE</td>
<td align="left">前往SOTA！模型平台获取实现资源：<a href="https://sota.jiqizhixin.com/project/74d15cbe-7f75-434a-a1cf-a69ae303eec6">https://sota.jiqizhixin.com/project/74d15cbe-7f75-434a-a1cf-a69ae303eec6</a></td>
</tr>
</tbody></table>
<hr>
<h4 id="StyleGAN-xl"><a href="#StyleGAN-xl" class="headerlink" title="StyleGAN-xl"></a>StyleGAN-xl</h4><p>StyleGAN-XL 是第一个在 ImageNet-scale 上演示 1024^2 分辨率图像合成的模型。实验表明，即使是最新的 StyleGAN3 也不能很好地扩展到 ImageNet 上，特别是在高分辨率时，训练会变得不稳定。StyleGAN为关于图像质量和可控性的生成建模设定了一种标杆方法。但StyleGAN在 ImageNet 等大型非结构化数据集上表现不好，它更适合人脸数据方面的生成。</p>
<p>研究者首先修改了StyleGAN的生成器及其正则化损失，调整了潜在空间以适应 Projected GAN (Config-B) 和类条件设置 (Config-C)；然后重新讨论了渐进式增长，以提高训练速度和性能 (Config-D)；接下来研究了用于 Projected GAN 训练的特征网络，以找到一个非常适合的配置 (Config-E)；最后，提出了分类器引导，以便 GAN 通过一个预训练的分类器 (Config-F) 提供类别信息。这样一来，就能够训练一个比以前大得多的模型，同时需要比现有技术更少的计算量。StyleGAN-XL 在深度和参数计数方面比标准的 StyleGAN3 大三倍。</p>
<img src="/f9495119/32.png" class>
<p>图15. StyleGAN-XL训练。将潜在编码z和类别标签c送入预训练的嵌入和映射网络G𝑚，以生成 style code w，这些code调制synthesis网络G𝑠的卷积。在训练过程中，逐渐增加层数，使渐进式增长的每个阶段的输出分辨率增加一倍。只训练最新的层，而保持其他层的固定。G𝑚只在最初的162阶段进行训练，在更高的分辨率阶段保持固定。合成的图像在小于2242时被放大，并通过一个CNN和一个ViT（ Vision Transformer）以及各自的特征混合块（CCM+CSM）。在更高的分辨率下，CNN接收未经修改的图像，而ViT接收降频输入，以保持低内存要求，但仍利用其全局反馈。最后，在得到的多尺度特征图上应用八个独立的鉴别器。图像也被送入分类器CLF，用于分类器指导</p>
<p>此外，还可以进一步细化所得到的重构结果，StyleGAN-xl可以在肖像或特定对象类的应用领域完成逆映射、编辑等扩展任务，将 PTI 和 StyleGAN-XL 相结合，几乎可以精确地反演域内 (ImageNet 验证集) 和域外图像。同时生成器的输出保持平滑。</p>
<p>当前 SOTA！平台收录 StyleGAN-XL 共 1 个模型实现资源。</p>
<img src="/f9495119/33.png" class>

<table>
<thead>
<tr>
<th align="left">项目</th>
<th align="left">SOTA！平台项目详情页</th>
</tr>
</thead>
<tbody><tr>
<td align="left">StyleGAN-XL</td>
<td align="left">前往SOTA！模型平台获取实现资源：<a href="https://sota.jiqizhixin.com/project/01d16b00-e79f-4527-a7e3-08354b5d9b47">https://sota.jiqizhixin.com/project/01d16b00-e79f-4527-a7e3-08354b5d9b47</a></td>
</tr>
</tbody></table>
<hr>
<h4 id="Diffusion-GAN"><a href="#Diffusion-GAN" class="headerlink" title="Diffusion GAN"></a>Diffusion GAN</h4><p>Diffusion-GAN主要关注的是 stabilize GAN training 的问题。为了实现GAN的稳定训练，将实例噪声注入鉴别器的输入理论上可行但缺少实践的验证。本文介绍了Diffusion-GAN，它采用了高斯混合分布，在前向扩散链条中的所有扩散步骤中引入实例噪声。将观察到的或生成的数据中扩散出的混合物的随机样本作为输入送入鉴别器。生成器通过前向扩散链反向传播其梯度进行更新，其长度是自适应调整的，以控制每个训练步骤中允许的最大噪声与数据比率。</p>
<img src="/f9495119/34.png" class>
<p>图16. Diffusion-GAN的流程图。上排图像代表真实图像的前向扩散过程，而下排图像代表生成的假图像的前向扩散过程。鉴别器学会在所有扩散步骤中区分扩散的真图像和扩散的假图像</p>
<p>Diffusion-GAN的对应目标是vanilla GAN的最小-最大目标，定义为</p>
<img src="/f9495119/35.png" class>

<p>鉴别器D学习区分扩散的生成样本y_g和扩散的真实观测值y，时间为∀t∈{1, . . . , T}，具体的优先级由π_t的值决定。生成器G学习将潜在变量z映射到它的输出x_g=G_θ(z)，它可以在扩散链的任何一步骗过鉴别器。y_g∼q(y | G_θ(z), t)可以被重新参数化为</p>
<img src="/f9495119/36.png" class>

<p>梯度可以直接反向传播到生成器。随着t的增加，y和y_g中的噪声与数据之比也在增加，从而使鉴别器D的任务越来越难。作者设计了一个扩散强度的自适应控制，以便更好地训练鉴别器。作者通过适应性地修改T来实现这一目标。我们为T设计了一个基于度量r_d的 self-paced schedule，这个schedule评估了鉴别器的过拟合度</p>
<img src="/f9495119/37.png" class>

<p>为了更好地防止鉴别器过拟合，定义t作为一个不对称的离散分布，鼓励鉴别器在T增加时观察新增加的扩散样本。</p>
<img src="/f9495119/38.png" class>

<p>当T开始增加时，鉴别器对所看到的样本已经很有信心，所以我们希望它探索更多的新样本，以抵消鉴别器的过度拟合。</p>
<p>当前 SOTA！平台收录 Diffusion-GAN 共 1 个模型实现资源。</p>
<img src="/f9495119/39.png" class>

<table>
<thead>
<tr>
<th align="left">项目</th>
<th align="left">SOTA！平台项目详情页</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Diffusion-GAN</td>
<td align="left">前往SOTA！模型平台获取实现资源：<a href="https://sota.jiqizhixin.com/project/9aa9b499-adec-46a3-aef9-4cd73e1c13ec">https://sota.jiqizhixin.com/project/9aa9b499-adec-46a3-aef9-4cd73e1c13ec</a></td>
</tr>
</tbody></table>
<hr>
<p>前往 SOTA！模型资源站（sota.jiqizhixin.com）即可获取本文中包含的模型实现代码、预训练模型及API等资源。 </p>
<p><strong>网页端访问：</strong>在浏览器地址栏输入新版站点地址 <strong>sota.jiqizhixin.com</strong> ，即可前往「SOTA！模型」平台，查看关注的模型是否有新资源收录。 </p>
<p><strong>移动端访问：</strong>在微信移动端中搜索服务号名称「<strong>机器之心SOTA模型</strong>」或 ID 「<strong>sotaai</strong>」，关注 SOTA！模型服务号，即可通过服务号底部菜单栏使用平台功能，更有最新AI技术、开发资源及社区动态定期推送。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650859439&amp;idx=2&amp;sn=c45f2b2767a027c77348545a783c21a5">https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650859439&amp;idx=2&amp;sn=c45f2b2767a027c77348545a783c21a5</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-WGAN、CSGAN、ADC-GAN…你都掌握了吗？一文总结图像生成必备经典模型（二）</title>
    <url>/20702606.html</url>
    <content><![CDATA[<h3 id="本期收录模型速览"><a href="#本期收录模型速览" class="headerlink" title="本期收录模型速览"></a>本期收录模型速览</h3><p>生成模型是一种训练模型进行无监督学习的模型，即，给模型一组数据，希望从数据中学习到信息后的模型能够生成一组和训练集尽可能相近的数据。图像生成（Image generation，IG）则是指从现有数据集生成新的图像的任务。图像生成模型包括无条件生成和条件性生成两类，其中，无条件生成是指从数据集中无条件地生成样本，即p(y)；条件性图像生成是指根据标签有条件地从数据集中生成样本，即p(y|x)。</p>
<p>图像生成也是深度学习模型应用比较广泛、研究程度比较深的一个主题，大量的图像库也为SOTA模型的训练和公布奠定了良好的基础。在几个著名的图像生成库中，例如CIFAR-10、ImageNet64、ImageNet32、STL-10、CelebA 256、CelebA64等等，目前公布出的最好的无条件生成模型有StyleGAN-XL、Diffusion ProjectedGAN；在ImageNet128、TinyImageNet、CIFAR10、CIFAR100等库中，效果最好的条件性生成模型则是LOGAN、ADC-GAN、StyleGAN2等。</p>
<img src="/20702606/1.webp" class>

<p>我们在这篇文章中介绍图像生成必备的TOP模型，从无条件生成模型和条件性生成模型两个类别分别介绍。图像生成模型的发展非常快，所以与其它几个topic不同，图像生成中必备的TOP模型介绍主要以近两年的SOTA模型为主。</p>
<span id="more"></span>

<hr>
<h3 id="条件性生成模型"><a href="#条件性生成模型" class="headerlink" title="条件性生成模型"></a>条件性生成模型</h3><h4 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h4><p>WGAN即Wasserstein GAN。GAN网络训练的重点在于均衡生成器G与鉴别器D：若鉴别器太好，loss不再下降，则生成器就学不到东西，也就无法继续提升生成图像的质量。所以在原始GAN的（近似）最优判别器下，生成器loss面临着梯度消失、梯度不稳定、对多样性与准确性惩罚不平衡导致的mode collapse等一系列问题。问题的根源是：</p>
<ol>
<li>等价优化的距离衡量（JS散度）不合理；</li>
<li>生成器随机初始化后的生成分布很难与真实分布重叠。</li>
</ol>
<p>WGAN就是为解决上述两个GAN的问题而提出的，即，引入Wasserstein距离衡量两个分布之间的Wasserstein距离，从而实现即使两个分布没有任何重叠，也可以反应他们之间的距离。由于Wasserstein距离相对KL散度与JS 散度具有优越的平滑特性，理论上可以解决梯度消失问题。WGAN最小化一个合理而有效的EM（ Earth Mover）距离的近似值。</p>
<p>WGAN与原始GAN第一种形式相比，只改了四点：</p>
<ol>
<li>鉴别器的最后一层中去掉了sigmoid，鉴别器要拟合的是Wasserstein距离，所以不是一个0或1的分类问题，而是回归问题，取值不限于0到1；</li>
<li>生成器和鉴别器的loss不取log；</li>
<li>每次更新鉴别器的参数之后把它们的值截断到不超过一个固定常数c，即令鉴别器的函数是一个Lipschitz函数，函数的导数小于某个固定的c值；</li>
<li>不使用基于动量的优化算法（包括momentum和Adam），推荐RMSProp。</li>
</ol>
<p>与原始的GAN相比，WGAN的鉴别器D的作用是一个EM距离的计量器，因此鉴别器越准确，对生成器越有利，可以在训练一个Step时训练D多次，训练G一次，从而获得较为准确的EM距离估计。WGAN的算法流程如下述Algorithm 1。</p>
<img src="/20702606/2.webp" class>

<p>当前 SOTA！平台收录 WGAN 共 96 个模型实现资源。</p>
<img src="/20702606/3.webp" class>

<hr>
<h4 id="SAGAN"><a href="#SAGAN" class="headerlink" title="SAGAN"></a>SAGAN</h4><p>跟踪图像中复杂的几何轮廓需要long-range dependencies(长距离依赖)，但是，卷积的特点就是局部性，受到感受野大小的限制，卷积的操作很难提取到图像中的这些长距离依赖。虽然可以通过加深网络或者扩大卷积核的尺寸的方法在一定程度上解决该问题，但是这会使卷积网络丧失了其参数和计算的效率优势。SAGAN聚焦的问题就是：如何找到一种能够利用全局信息的方法，具体的，SAGAN把 Attention 机制引入到 GANs 的图像生成当中。</p>
<img src="/20702606/4.webp" class>
<p>图1 SAGAN的自注意力模块。⊗表示矩阵乘法，对每一行进行softmax操作</p>
<p>SAGAN的架构如图1所示，其核心就是用带有自注意力的特征图去代替传统的卷积特征图，建模像素间的远距离关系，即在一层获取远距离的依赖关系而非多层卷积操作获得依赖关系。首先，图17中的f(x)、g(x)和 h(x)都是普通的 1x1 卷积，差别只在于输出通道大小不同（这是1x1 卷积的特性，可以通过控制1x1 卷积的通道数来实现特征通道的升维和降维。然后，将 f(x)的输出转置，并和 g(x)的输出相乘，再经过 softmax 归一化得到一个 attention map。最后，将得到的 attention map 和 h(x)逐像素点相乘，得到自适应注意力的特征图：</p>
<img src="/20702606/5.webp" class>

<p>其中，γ是一个可学习的标量，初始化为0。γ允许网络首先依赖局部附近的线索，然后逐渐学会为非局部线索分配更大的权重。在SAGAN中，将自适应注意力模块同时应用于生成器和鉴别器，通过最小化 hinge version of the adversarial loss 以交替的方式进行训练。</p>
<img src="/20702606/6.webp" class>

<p>SAGAN当中提出了两种优化方式以实现稳定训练的 GANs，分别是Spectral Normalization与TTUR（Two Timescale Update Rule），前者稳定了训练和生成过程，后者平衡了D与G的训练速度。</p>
<ol>
<li>Spectral Normalization。SAGAN为D和G加入了谱范数归一化的方式，让D满足了1-lipschitz限制，同时也避免了G的参数过多导致梯度异常，使得整套训练较为平稳和高效。</li>
<li>TTUR。在以前的工作中，鉴别器的正则化通常会减慢GAN学习过程。实际上，使用正则化鉴别器的方法通常在训练期间每个生成器需要多个更新步骤。本文建议专门使用TTUR来补偿正则化鉴别器中慢学习的问题，使得对于每个鉴别器步骤使用更少的生成器步骤成为可能。 </li>
</ol>
<p>当前 SOTA！平台收录SAGAN共 43 个模型实现资源。</p>
<img src="/20702606/7.webp" class>

<hr>
<h4 id="BIG-GAN"><a href="#BIG-GAN" class="headerlink" title="BIG-GAN"></a>BIG-GAN</h4><p>BIG-GAN希望应对的是从像ImageNet这样的复杂数据集成功生成高分辨率、多样化的样本的问题。BIG-GAN的基线方法是SAGAN，它使用hinge损失，类别条件BatchNorm向G提供类别信息，用投影向D提供类别信息，通过调整网络提高GAN模型生成图像的真实性和多样性，同时，保证GAN模型的稳定性。</p>
<p>BIG-GAN的很多参数都是在SAGAN上调整的，batch size的大小为原来的8倍，将隐藏层的变量数量扩充到4倍以后，进行训练获得了很好的图片生成的效果。优化设置遵循SAGAN(特别是在G中使用谱范数)的修改，BIG-GAN将学习速率减半，在训练一个Step时训练D两次，训练G一次。</p>
<img src="/20702606/8.webp" class>
<p>图2. (a) BigGAN的典型架构；(b) G中的残差块（ResBlock up）；c）D中的残差块（ResBlock down）</p>
<p>由图2，在G中使用单一的共享类别嵌入，并跳过潜在向量z的连接（skip-z）。特别是，采用分层的潜在空间，使潜在向量z沿着其通道维度被分割成大小相等的块（图18的示例中是20-D），每个块被连接到共享类别嵌入，并作为调节向量传递给相应的残差块。每个块的调节被线性投影，以产生块的BatchNorm层的每个样本的增益和偏置。偏置投影以零为中心，而增益投影以1为中心。由于残差块的数量取决于图像分辨率，128×128图像的z全维度为120，256×256为140，而512×512的图像为160。</p>
<img src="/20702606/9.webp" class>
<img src="/20702606/10.webp" class>
<p>图3. (a) BigGAN-deep的典型架构。(b) G中的一个残差块（ResBlock up）。(c)D中的一个残差块（ResBlock down）</p>
<p>BigGAN-deep模型（图3）在几个方面与BigGAN不同。它使用了一个更简单的skip-z conditioning的变体：不是先将z分割成块，而是将整个z与类别的嵌入相连接，并通过skip connection将得到的向量传递给每个残差块。BigGAN-deep基于带有瓶颈的剩差块，其中包含两个额外的1×1卷积：第一个在3×3卷积之前将通道的数量减少了4倍；第二个产生所需的输出通道数量。在BigGAN中，每当需要改变通道数量时，都会在skip connection中使用1×1的卷积，而在BigGAN-deep中，使用了一种不同的策略，旨在保持整个skip connection的特性。在G中，如果需要减少通道的数量，只需保留第一组通道，并放弃其余的通道以产生所需的通道数量。在应该增加通道数量的D区，将输入通道不加扰动地通过，并与1×1卷积产生的剩余通道串联起来。就网络配置而言，鉴别器是发生器的精确反映。每个分辨率有两个块（BigGAN使用一个），因此BigGAN-deep比BigGAN深四倍。</p>
<p>当前 SOTA！平台收录 BIG-GAN 共 29 个模型实现资源。</p>
<img src="/20702606/11.webp" class>

<hr>
<h4 id="CSGAN"><a href="#CSGAN" class="headerlink" title="CSGAN"></a>CSGAN</h4><p>CSGAN是一种新的周期合成生成对抗网络，主要服务的目标是image-to-image transformation，在一个域合成图像和另一个域循环图像之间使用了一种新的目标函数循环合成损失(CS)。</p>
<img src="/20702606/12.webp" class>
<p>图4. CSGAN的网络结构，用于图像-图像转换。本文提出的循环-合成损失是为了利用两个图像域中合成图像和循环图像之间的关系。因此，除了对抗性损失和循环一致性损失之外，还使用了循环合成损失来训练网络。对抗性损失用蓝色的矩形表示，它是在1）生成器G_AB和鉴别器D_B，以及2）生成器G_BA和鉴别器D_A之间计算的。循环一致性损失用黑色表示，为真实图像和循环图像之间的L1损失。循环-合成损失以红色显示，为合成图像和循环图像之间的L1损失</p>
<p>如图4所示，CSGAN方法的总体工作是将图像R_A从域A转化为B，并将其交给生成器网络G_AB，从而得到合成的图像S_ynB。将合成的图像S_ynB从域B转化为原域A，并将其交给生成器网络G_BA，得到循环的图像C_ycA。以同样的方式，来自B域的真实图像R_B首先被转换到A域作为合成图像S_ynA，然后通过使用生成器网络G_BA和G_AB分别转换回B域作为循环图像C_ycB。鉴别器网络D_A用于区分真实图像R_A和合成图像S_ynA。同样地，鉴别器网络D_B用于区分真实图像R_B和合成图像S_ynB。为了生成最接近真实图像的合成图像，它们之间的损失要最小化。这就意味着需要有高效的损失函数。CSGAN引入了一种新的损失函数循环合成损失(CS loss)，它可以在降低伪影的情况下提高结果的质量：</p>
<img src="/20702606/13.webp" class>
<img src="/20702606/14.webp" class>

<p>其中，L_CSA是A域（即S_ynA和C_ycA之间）的循环合成损失，L_CSB是B域（即S_ynB和C_ycB之间）的循环合成损失。CSGAN方法的目标函数（L）结合了所提出的Cyclic-Synthesized损失与现有的Adversarial损失和Cycle-consistency损失，如下所示：</p>
<img src="/20702606/15.webp" class>
<img src="/20702606/16.webp" class>
<img src="/20702606/17.webp" class>
<img src="/20702606/18.webp" class>
<img src="/20702606/19.webp" class>

<p>CSGAN的生成器网络由3个卷积层、9个残差块和3个去卷积层组成，使用实例归一化，而不是批量归一化。源域中256×256维的输入图像输入到网络。该网络通过一系列的下卷积和上卷积，将256×256的图像保留在另一个域中。鉴别器网络是一个70×70的PatchGAN，由4个卷积层组成，每个卷积层都是convolution-instance-norm-swing-ReLU的序列，然后是1个卷积层，产生1维的输出。鉴别器网络采用256×256维度的图像，输出为表征图像真假的概率（即0代表假，1代表真）。斜率为0.2的Leaky ReLUs被用作鉴别器网络的激活函数。</p>
<p>当前 SOTA！平台收录 CSGAN 共 1 个模型实现资源。</p>
<img src="/20702606/20.webp" class>

<hr>
<h4 id="LOGAN"><a href="#LOGAN" class="headerlink" title="LOGAN"></a>LOGAN</h4><p>LOGAN是一种受CSGAN启发的潜在优化（latent optimisation），核心思想是加强鉴别器和生成器之间的交互来改善对抗性。如图5，首先，令潜在变量z通过生成器和鉴别器进行前向传播。然后，用生成器损失（红色虚线箭头）的梯度来计算改进的z’。在第二次前向传播中，使用优化后的z’。其后，引入潜在优化计算鉴别器的梯度。最后，用这些梯度来更新模型。</p>
<img src="/20702606/21.webp" class>
<p>图5. LOGAN示意图。首先计算一个通过G和D的前向传递，有一个 sampled latent z，然后，使用来自生成器损失的梯度（红色虚线箭头）来计算一个改进的latent z’。在第二次正向传递中使用这个改进的latent后，通过latent优化计算出鉴别器的梯度，返回到模型参数θ_D、θ_G中</p>
<p>LOGAN的完整计算过程见下述Algorithm 1：</p>
<img src="/20702606/22.webp" class>

<p>当前 SOTA！平台收录 LOGAN 共 2 个模型实现资源。</p>
<img src="/20702606/23.webp" class>

<hr>
<h4 id="UNet-GAN"><a href="#UNet-GAN" class="headerlink" title="UNet-GAN"></a>UNet-GAN</h4><p>GANs面临的主要挑战之一是：生成全局和局部一致的图像，使得其物体形状和纹理与真实图像无法区分。UNet-GAN是一个致力于解决这一问题的基于U-Net的替代性鉴别器架构。基于U-Net的架构允许向生成器提供 per-pixel反馈，同时通过提供全局图像反馈，保持生成图像的全局一致性。在鉴别器的per-pixel 响应支持下，进一步提出了一种基于CutMix数据增强的per-pixel 一致性正则化技术，鼓励U-Net鉴别器更加关注真实和虚假图像之间的语义和结构变化。</p>
<img src="/20702606/24.webp" class>
<p>图6. U-Net GAN。U-Net鉴别器在全局和局部per-pixel层面对输入图像进行分类。由于编码器和解码器之间的skip connections（虚线），输出层的通道既包含高层次信息也包含低层次信息。解码器输出中较亮的颜色表征鉴别器对像素是真实的信任程度（颜色越暗表征越怀疑是假的）</p>
<p>Unet-GAN通过重复使用原鉴别器分类网络的构件作为编码器部分，以及生成器网络的构件作为解码器部分，来扩展鉴别器形成一个U-Net，即，鉴别器现在由原来的下采样网络和一个新的上采样网络组成。这两个模块通过一个瓶颈连接，以及，从编码器和解码器模块复制和串联特征图的skip connections。将分类器表征为D^U。原始的D(x)将输入的图像x分类为真实和虚假，而U-Net鉴别器D^U(x)则在per-pixel层面额外执行这种分类处理，将图像x分割为真实和虚假区域，同时还有来自编码器的x的原始图像分类。这使鉴别器能够学习真实和虚假图像之间的全局和局部差异。把鉴别器的原始编码器模块称为(D^U)_enc，把引入的解码器模块称为(D^U)_dec。现在，新的鉴别器损失可以通过从(D^U)_enc和(D^U)_dec中获取决策来计算：</p>
<img src="/20702606/25.webp" class>
<img src="/20702606/26.webp" class>
<img src="/20702606/27.webp" class>

<p>(D^U)_dec的这些per-pixel输出是基于来自高级特征的全局信息，通过瓶颈的上采样过程实现的，以及来自低级特征的更多局部信息，由编码器网络中间层的skip-connection介导的。最终生成器的目标函数为：</p>
<img src="/20702606/28.webp" class>

<p>进一步，提出了D^U鉴别器的一致性正则化，鼓励解码器模块(D^U)_dec在真实和虚假样本的CutMix转换下输出等值预测值。图7中展示了CutMix的增强策略和D^U的预测。</p>
<img src="/20702606/29.webp" class>
<p>图7. CutMix增强和U-Net鉴别器对CutMix图像的预测的可视化。第一行：真实和虚假的样本。第二行和第三行：采样的真/假CutMix比率r和相应的二进制掩码M（颜色代码：白色为真，黑色为假）。第四行：从真实和虚假样本中生成的CutMix图像。第5行和第6行：相应的真/假D^U的分割图及其预测的分类分数</p>
<p>具体的，通过将x和G(z)∈RW×H×C与掩码M混合，为鉴别器D^U合成一个新的训练样本x˜</p>
<img src="/20702606/30.webp" class>

<p>鉴于CutMix操作，训练鉴别器通过在鉴别器目标中引入一致性正则化损失项，以提供一致的per-pixel预测：</p>
<img src="/20702606/31.webp" class>
<img src="/20702606/32.webp" class>

<p>最终生成器的目标函数为：</p>
<img src="/20702606/33.webp" class>

<p>当前 SOTA！平台收录UNet-GAN共 1 个模型实现资源。</p>
<img src="/20702606/34.png" class>

<hr>
<h4 id="IC-GAN"><a href="#IC-GAN" class="headerlink" title="IC-GAN"></a>IC-GAN</h4><p>GAN 有着神经网络模型所共有的致命缺点，就是具有局限性，通常只能生成与训练数据集密切相关的物体或场景的图像。Facebook AI Research 为了解决这个问题，提出了IC-GAN，可以生成逼真的、没有见过的图像组合。研究人员从核密度估计（kernel density estimation, KDE）技术中得到启发，引入了一种非参数化方法来建模复杂数据集的分布。KDE是一种非参数密度估计器，以参数化核的混合形式对每个训练数据点周围的密度进行建模。IC-GAN可以看作是一种混合密度估计器，其中每个分量都是通过对训练实例进行条件化得到的。</p>
<p>IC-GAN 将数据流形划分为由数据点及其最近邻描述的重叠邻域的混合物，IC-GAN模型能够学习每个数据点周围的分布。通过在条件实例周围选择一个足够大的邻域，可以避免将数据过度划分为小的聚类簇。当给定一个具有M个数据样本的未标记数据集的嵌入函数f，首先使用无监督或自监督训练得到f来提取实例特征（instance features）。然后使用余弦相似度为每个数据样本定义k个最近邻的集合。使用生成器隐式模拟条件分布p(x | h_i) 时，生成器从单位高斯先验z~N(0, 1)变换样本从条件分布中抽取样本x，其中h_i是从训练数据中抽取的实例x_i的特征向量。</p>
<img src="/20702606/35.webp" class>
<p>图8.  IC-GAN。(a) 生成器的目标是生成与h_i的邻域相似的现实图像，在嵌入空间中使用余弦相似度定义。图中显示了七个邻居中的五个。请注意，同一邻域的图像可能属于不同的类别（被描述为不同的形状）。(b) 以实例特征h_i和噪声z为条件，生成器产生一个合成样本x_g。生成的样本和真实样本（h_i的邻居）被送入鉴别器，鉴别器以相同的h_i为条件</p>
<p>在IC-GAN中，采用对抗式方法来训练生成器，因此可以联合训练生成器和鉴别器，鉴别器用来区分h_i的真实相邻节点和生成的相邻点。对于每个h_i，真实邻居都从A_i中均匀采样。生成器 G和鉴别器 D都参与了一个两人最小-最大博弈，在博弈中，二者试图找到目标的纳什均衡的等式。</p>
<img src="/20702606/36.webp" class>

<p>在训练IC-GAN时，使用所有可用的训练数据点来微调模型。在推理时，与KDE等非参数密度估计方法一样，IC-GAN的生成器也需要实例特征，这些特征可能来自于训练分布或不同的分布。</p>
<p>并且这种方法可以扩展到具有类别条件（class condition）的生成上。通过在类别标签y上添加一个额外的生成器和鉴别器，可以让IC-GAN 用于有类别条件的生成。IC-GAN 通过向生成器和鉴别器提供实例的表示作为额外的输入，并通过使用实例的邻居作为鉴别器的真实样本，学习对数据点（也称为实例）的邻域的分布建模。与对离散簇索引进行条件处理不同，对实例表示进行条件处理自然会导致生成器为相似实例生成相似样本。并且一旦训练完成，IC-GAN可以通过在推理时简单地交换条件实例，轻松地迁移到训练期间未看到的其他数据集。</p>
<p>作者在文章中是基于BigGAN和StyleGAN2实现的IC-GAN，同时扩展了它们的架构来处理引入的实例条件。当使用BigGAN作为基础架构时，IC-GAN用全连接层来替换生成器和鉴别器中的类别嵌入层。生成器中的全连接层的输入大小为2,048(对应于特征提取器f_θ的维数)和一个可以调整的输出大小o_dim。鉴别器中的全连接层具有一个可变的输出大小n_dim来匹配中间无条件鉴别器特征向量的维数。对于类别条件的IC-GAN，同时使用类别嵌入层以及与实例条件反射相关联的全连接层。将类别嵌入(维度c_dim=128)和实例嵌入(维度o_dim=512)连接起来。</p>
<p>当使用StyleGAN2作为基础架构时，将生成器中的输出维数512的全连接层替换类别嵌入层。替换鉴别器中的类别嵌入的全连接层是大小可变的。在这种情况下，实例特征与StyleGAN2的映射网络输入处的噪声向量连接起来，为生成器创建一个style vector。当涉及到鉴别器时，映射网络只输入提取的实例特征，以获得一个modulating vector，该向量乘以每个块上的内部鉴别器表示。所有实例特征向量h_i在计算邻域和用作GAN的条件反射之前都用l2范数进行归一化处理。</p>
<p>当前 SOTA！平台收录IC-GAN 共 1 个模型实现资源。</p>
<img src="/20702606/37.png" class>

<hr>
<h4 id="ADC-GAN"><a href="#ADC-GAN" class="headerlink" title="ADC-GAN"></a>ADC-GAN</h4><p>条件生成模型（Conditional generative models ）学习数据和标签的基本联合分布，以实现条件数据的生成。其中，辅助分类器生成式对抗网络（auxiliary classifier generative adversarial network ，AC-GAN）已被广泛使用，但存在着生成样本的类内多样性低的问题。原因是AC-GAN的分类器与生成器无关，因此不能为生成器提供接近联合分布的信息指导，导致条件熵的最小化降低了类内多样性。ADC-GAN的目标是解决上述问题，具体来说，所提出的辅助判别分类器通过辨别真实数据和生成的数据的类别标签而具备生成器感知特性（ generator-aware ）。</p>
<img src="/20702606/38.webp" class>
<p>图9 cGAN、AC-GAN、TAC-GAN和ADC-GAN的鉴别器/分类器的说明。符号+/-表示GAN标签（真实或虚假），y是数据x的类别标签。ADC-GAN与cGAN不同，它明确预测了标签，与AC-GAN和TAC-GAN不同的是，分类器C_d也区分真实和生成，就像鉴别器一样</p>
<p>使分类器能够对具有不同类别标签的真实数据和生成的数据进行分类，建立一个鉴别性分类器Cd : X → Y+ ∪ Y- (Y+代表真实数据，Y-代表生成的数据)，以鉴别性地识别真实和生成样本的标签。鼓励生成器产生可分类的真实数据，而不是可分类的虚假数据。ADC-GAN的鉴别器、鉴别分类器和生成器的目标函数被定义为：</p>
<img src="/20702606/39.webp" class>
<img src="/20702606/40.webp" class>
<img src="/20702606/41.webp" class>

<p>其中，C_d表示数据x被判别性分类器同时归类为标签y和真假的概率。φ : X → Rd是一个特征提取器，与原始鉴别器共享（D = σ ◦ ψ ◦ φ，具有线性映射ψ : Rd → R和sigmoid函数σ : R → [0, 1]），ϕ+ : Y → Rd和ϕ- : Y → Rd捕获负责真实和生成数据的标签的可学习嵌入。log C_d(y+|x)的最大化鼓励生成器只生成少数标签一致的数据，促进了保真度，但失去了生成样本的多样性。另一方面，log C_d(y-|x)的最小化鼓励生成器不合成典型的标签一致的数据，增加多样性，但可能降低生成样本的保真度。</p>
<p>当前 SOTA！平台收录 ADC-GAN 共 1个模型实现资源。</p>
<img src="/20702606/42.webp" class>

<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://new.qq.com/rain/a/20221030A02NZ000">https://new.qq.com/rain/a/20221030A02NZ000</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-图像处理特征融合相关延伸</title>
    <url>/3b4d60e3.html</url>
    <content><![CDATA[<h3 id="特征融合"><a href="#特征融合" class="headerlink" title="特征融合"></a>特征融合</h3><p><a href="https://blog.csdn.net/MengYa_Dream/article/details/124728120">【学习资源】图像处理-特征融合：相加、拼接、Attention</a></p>
<h4 id="底层特征-高层特征"><a href="#底层特征-高层特征" class="headerlink" title="底层特征/高层特征"></a>底层特征/高层特征</h4><ul>
<li><strong>低层特征：</strong>低层特征分辨率更高，包含更多位置、细节信息，但是由于经过的卷积更少，其语义性更低，噪声更多。</li>
<li><strong>高层特征：</strong>高层特征具有更强的语义信息，但是分辨率很低，对细节的感知能力较差。</li>
</ul>
<span id="more"></span>

<hr>
<h4 id="早融合-高融合-Attention融合"><a href="#早融合-高融合-Attention融合" class="headerlink" title="早融合/高融合/Attention融合"></a>早融合/高融合/Attention融合</h4><ul>
<li><strong>早融合(Early fusion)：</strong>先融合多层的特征，然后<strong>在融合后的特征上训练</strong>预测器（只在完全融合之后，才统一进行检测）。这类方法也被称为<strong>skip connection</strong>，即采用<strong>concat、add</strong>操作。</li>
<li><strong>晚融合(Late fusion)：</strong>通过<strong>结合不同层的检测结果</strong>改进检测性能（尚未完成最终的融合之前，在部分融合的层上就开始进行检测，会有多层的检测，<strong>最终将多个检测结果进行融合</strong>）。</li>
<li><strong>Attention融合：</strong>学习权重分布：输入数据或特征图上的不同部分对应的专注度不同，加权。</li>
</ul>
<hr>
<h3 id="欠拟合-过拟合"><a href="#欠拟合-过拟合" class="headerlink" title="欠拟合/过拟合"></a>欠拟合/过拟合</h3><p><a href="https://blog.csdn.net/qq_18254385/article/details/78428887">【学习资源】 大白话给你说清楚什么是过拟合、欠拟合以及对应措施</a></p>
<h4 id="过拟合（over-fitting）"><a href="#过拟合（over-fitting）" class="headerlink" title="过拟合（over-fitting）"></a>过拟合（over-fitting）</h4><ul>
<li><strong>概念：</strong>所建模型在训练样本中表现得过于优越，在验证数据集以及测试数据集中表现不佳。 </li>
<li><strong>原因：</strong>参数过多，对于transformer的层数的增加，相对来说会出现特征冗余？</li>
</ul>
<hr>
<h4 id="欠拟合（under-fitting）"><a href="#欠拟合（under-fitting）" class="headerlink" title="欠拟合（under-fitting）"></a>欠拟合（under-fitting）</h4><ul>
<li><strong>概念：</strong>所建模型在训练样本中提取的特征比较少，导致训练出来的模型不能很好地匹配，表现得很差。</li>
<li><strong>原因：</strong>参数不够，现阶段这种情况很少出现！</li>
</ul>
<p>例子：<br>比如是识别一只狗狗的模型，需要对这个模型进行训练。恰好，训练样本中的所有训练图片都是二哈，那么经过多次迭代训练之后，模型训练好了，并且在训练集中表现得很好。基本上二哈身上的所有特点都涵括进去！<br><strong>那么问题来了！假如我的测试样本是一只金毛呢？</strong><br>将一只金毛的测试样本放进这个识别狗狗的模型中，很有可能模型最后输出的结果就是金毛不是一条狗（因为这个模型基本上是按照二哈的特征去打造的）。<br><strong>所以这样就造成了模型过拟合</strong>，虽然在训练集上表现得很好，但是在测试集中表现得恰好相反，在性能的角度上讲就是<strong>协方差过大（variance is large）</strong>，同样在测试集上的<strong>损失函数（cost function）</strong>会表现得很大。<br><strong>欠拟合则可能二哈被提取的特征比较少</strong>，导致训练出来的模型不能很好地匹配，表现得很差，甚至二哈都无法识别。</p>
<hr>
<h3 id="特征冗余"><a href="#特征冗余" class="headerlink" title="特征冗余"></a>特征冗余</h3><p><a href="https://blog.csdn.net/qq_36782366/article/details/89044131">【学习资源】机器学习第十五章——降维</a><br><a href="https://blog.csdn.net/moxibingdao/article/details/109685497">【学习资源】重读GhostNet：使用轻量操作代替部分传统卷积层生成冗余特征以减少计算量</a></p>
<h4 id="降低神经网络计算量"><a href="#降低神经网络计算量" class="headerlink" title="降低神经网络计算量"></a>降低神经网络计算量</h4><p>随着卷积神经网络部署在终端的需求越来越强烈，很多研究者们开始研究如何<strong>降低神经网络的计算量</strong>。</p>
<ul>
<li>在一个已经训练好的网络基础上做一些裁剪和量化，比如模型剪枝、低比特量化、知识蒸馏；</li>
<li>另外一种方法是设计高效的神经网络架构，比如MobileNetv1-v3系列、ShuffleNet等等。</li>
</ul>
<p><strong>特征冗余性是卷积神经网络的重要特性之一</strong>，一些轻量化网络的工作恰恰是利用特征的冗余性，通过裁掉部分冗余特征达到模型轻量化的效果。</p>
<h4 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h4><p>在图像处理过程中，高维特征是在所难免的，但随之而来的问题也显而易见：</p>
<ul>
<li>学习性能下降，知识越多，吸收知识（输入），并且精通知识（学习）的速度就越慢。</li>
<li>过多的特征难于分辨，很难第一时间认识某个特征代表的意义。</li>
<li>特征冗余，厘米和英尺就是一对冗余特征，其本身代表的意义是一样的，并且能够相互转换。</li>
</ul>
<p><strong>特征降维的一般手段就是将高维特征投影到低维空间。</strong></p>
<p>降维的动机有两个：</p>
<ul>
<li>压缩数据</li>
<li>数据可视化，100个特征可能难以表示，但是两个三个特征就可以用图表的形式把他画出来可视化，更加形象。</li>
</ul>
<hr>
<h3 id="局部融合"><a href="#局部融合" class="headerlink" title="局部融合"></a>局部融合</h3><p><a href="https://blog.csdn.net/silence2015/article/details/79748812">【学习资源】局部特征融合为全局特征笔记__全局特征融合</a><br><a href="https://blog.csdn.net/TTdreamloong/article/details/79798817">【学习资源】图像检索研究进展：浅层、深层特征及特征融合_深层特征是什么</a></p>
<p>图像特征分为全局特征和局部特征两种：</p>
<ul>
<li>全局特征代表了图像的整体表现特性，比如颜色直方图；</li>
<li>局部特征代表了图像的局部特性，往往能够从一幅图片中提取出若干个数量不等的局部特征，这些局部特征组合起来代表了整幅图像的特征分布。</li>
</ul>
<p><strong>每一张图片提取出的局部特征数可能是不同的</strong>，需要将这些不同数目的描述子融合成一个特征向量（假设维度为n）来表征整个图像，这样一张图片就可以用一个1*k的向量来表征。这样做后就可以方便的实现图片检索，分类任务。其中将局部特征融合为图片全局特征表示需要一个模型来转化。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://blog.csdn.net/MengYa_Dream/article/details/124904632">https://blog.csdn.net/MengYa_Dream/article/details/124904632</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>Python-JC1001 Assessment 2</title>
    <url>/3e62d3a3.html</url>
    <content><![CDATA[<h3 id="Part-1"><a href="#Part-1" class="headerlink" title="Part 1"></a>Part 1</h3><h4 id="Question-1"><a href="#Question-1" class="headerlink" title="Question 1"></a>Question 1</h4><p>Write a function named <strong>stringToNum</strong> that receives a string parameter of numbers separated with commas and returns a list of integers based on the string parameter e.g. <strong>stringToNum(“5, 6, 7, 8”)</strong> would return [5, 6, 7, 8].<br>(0.5 mark)</p>
<span id="more"></span>

<p><strong>题目翻译：</strong></p>
<p>编写一个名为<strong>stringToNum</strong>的函数，该函数接收一个由逗号分隔的数字组成的字符串参数，并根据字符串参数返回一个整数列表，例如 <strong>stringToNum(“5, 6, 7, 8”)</strong> 将返回[5, 6, 7, 8]。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>字符串的split()函数，split()默认用空格作为分隔符，即split(‘ ‘)。str1.split(‘,’)的意思是将str1这个string字符串按照逗号分隔开，并将分割后的结果返回一个列表</li>
<li>使用for循环将列表里的string元素挨个取出并转为int类型</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：stringToNum，输入1个参数，类型为string</li>
<li>接受字符串转化为列表</li>
<li>将列表里的string元素转化为int</li>
<li>返回整数列表list</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stringToNum</span>(<span class="params">str1</span>):</span>                  <span class="comment"># 1. stringToNum，输入1个参数，类型为string</span></span><br><span class="line">    temp = str1.split(<span class="string">&#x27;,&#x27;</span>)              <span class="comment"># 2. 接受字符串转化为列表</span></span><br><span class="line">    temp = [<span class="built_in">int</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> temp]   <span class="comment"># 3. 将列表里的string元素转化为int</span></span><br><span class="line">    <span class="keyword">return</span> temp                         <span class="comment"># 4. 返回类型list</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(stringToNum(<span class="string">&quot;5,6,7,8&quot;</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-2"><a href="#Question-2" class="headerlink" title="Question 2"></a>Question 2</h4><p>Write a function named <strong>n_w_h_input</strong> that receives a string followed by two floats. The function should return a tuple containing the string argument in upper case and the two floats rounded to 1 decimal place.<br>(0.5 mark)</p>
<p><strong>题目翻译：</strong></p>
<p>编写一个名为<strong>n_w_h_input</strong>的函数，接收一个字符串和两个浮点数。该函数应返回一个元组，其中包含大写的字符串参数，并且两个浮点数四舍五入到小数点后一位。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>字符串的upper()函数，str1.upper()即可将str1这个字符串里的英文字母都变成大写</li>
<li>round()函数，接受两个参数，第一个参数是要四舍五入的数字，第二个参数是要保留的小数位数。round(num1, 1)即把num1这个浮点数四舍五入保留1位小数</li>
<li>tuple()函数输入一个数字、字符串、列表或者元组（只需要一个参数，不可以是多个数据用逗号隔开），将这个数据变成元组类型返回</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：n_w_h_input，输入3个参数，类型为string、float、float</li>
<li>把字符串里的字母都变成大写</li>
<li>把浮点数四舍五入到小数点后一位</li>
<li>把3个参数整合为一个元组</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">n_w_h_input</span>(<span class="params">str1, num1, num2</span>):</span>      <span class="comment"># 1. n_w_h_input，输入3个参数，类型为string、float、float</span></span><br><span class="line">    str1 = str1.upper()                 <span class="comment"># 2. 把字符串里的字母都变成大写</span></span><br><span class="line">    num1 = <span class="built_in">round</span>(num1, <span class="number">1</span>)               <span class="comment"># 3. 把浮点数四舍五入到小数点后一位</span></span><br><span class="line">    num2 = <span class="built_in">round</span>(num2, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">tuple</span>([str1, num1, num2])    <span class="comment"># 4. 把3个参数整合为一个元组</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(n_w_h_input(<span class="string">&#x27;yy&#x27;</span>, <span class="number">1.11</span>, <span class="number">2.22</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-3"><a href="#Question-3" class="headerlink" title="Question 3"></a>Question 3</h4><p>Write a function named <strong>n_w_h_output</strong> that receives a string followed by two floats. The function should print out these parameters using the format below e.g. if the function is called with the values, <strong>Sam, 69.7, 1.9</strong> the function should print:<br><strong>“Sam’s weight is 69.7 and his/her height is 1.9”</strong><br>(0.5 mark)</p>
<p><strong>题目翻译：</strong></p>
<p>编写一个名为<strong>n_w_h_output</strong>的函数，该函数接收一个字符串和两个浮点数。函数应该使用下面的格式打印出这些参数，例如，如果函数输入<strong>Sam, 69.7, 1.9</strong>，函数应该打印:<br><strong>“Sam’s weight is 69.7 and his/her height is 1.9”</strong></p>
<p><strong>本题考点：</strong></p>
<ul>
<li>字符串间的拼接可以使用加号</li>
<li>非字符串数据要用加号和字符串拼接的时候，需要用str()函数先转为字符串。str(num1)表示将num1这个数字（可以是int，也可以是float，其他类型也可以）转化为string类型</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：n_w_h_output，输入3个参数，类型为string、float、float</li>
<li>把字符串拼接起来</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">n_w_h_output</span>(<span class="params">str1, num1, num2</span>):</span>         <span class="comment"># 1. n_w_h_output，输入3个参数，类型为string、float、float</span></span><br><span class="line">    <span class="built_in">print</span>(str1 + <span class="string">&quot;&#x27;s weight is &quot;</span> + <span class="built_in">str</span>(num1) + <span class="string">&quot; and his/her height is &quot;</span> + <span class="built_in">str</span>(num2))       <span class="comment"># 2. 把字符串拼接起来</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    n_w_h_output(<span class="string">&#x27;Sam&#x27;</span>, <span class="number">69.7</span>, <span class="number">1.9</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-4"><a href="#Question-4" class="headerlink" title="Question 4"></a>Question 4</h4><p>Write a function named <strong>calcBMI</strong> which receives two floats representing weight and height and then calculates body mass index (BMI). Your function should use the following formula:<br>BMI is calculated as: weight / height / height * 10,000<br>The number should be rounded to 1 decimal place.<br>(0.5 mark)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>calcBMI</strong>的函数，该函数接收代表体重和身高的两个浮点数，然后计算身体质量指数(BMI)。你的函数应该使用以下公式:<br>BMI的计算公式为: 体重 / 身高 / 身高 * 10000<br>这个数字应该四舍五入到小数点后一位。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>还是round()函数</li>
<li>乘法与除法这种同级运算直接连着写、连着计算就可以</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：calcBMI，输入2个参数，类型为float、float</li>
<li>round()保留一位小数，按公式计算BMI</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcBMI</span>(<span class="params">num1, num2</span>):</span>                            <span class="comment"># 1. calcBMI，输入2个参数，类型为float、float</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(num1 / num2 / num2 * <span class="number">10000</span>, <span class="number">1</span>)     <span class="comment"># 2. round()保留一位小数，按公式计算BMI</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(calcBMI(<span class="number">64.5</span>, <span class="number">179.5</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-5"><a href="#Question-5" class="headerlink" title="Question 5"></a>Question 5</h4><p>Write a function named <strong>bmiCat</strong> which receives a float representing BMI and then returns a weight category based on the following criteria:</p>
<ul>
<li>BMI categories are as follows:<ul>
<li>Lower than 18.5, Underweight</li>
<li>Between 18.5 and 24.9, Healthy</li>
<li>Between 25 and 29.9, Overweight</li>
<li>Between 30 and 39.9, Obese</li>
<li>More than 40, Severely obese<br>(2.5 marks)</li>
</ul>
</li>
</ul>
<p><strong>题目翻译：</strong><br>写一个名为<strong>bmiCat</strong>的函数，它接收一个表示BMI的浮点数，然后根据以下标准返回一个权重类别:</p>
<ul>
<li>BMI分类如下:<ul>
<li>低于 18.5，体重过轻</li>
<li>18.5 到 24.9之间，健康</li>
<li>25 到 29.9之间，超重</li>
<li>30 至 39.9，肥胖</li>
<li>40 以上，严重肥胖</li>
</ul>
</li>
</ul>
<p><strong>本题考点：</strong></p>
<ul>
<li>使用if、elif、else等判断来进行类别分类</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：bmiCat，输入1个参数，类型为float</li>
<li>使用if、elif、else等判断来进行类别分类</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bmiCat</span>(<span class="params">num1</span>):</span>                   <span class="comment"># 1. bmiCat，输入1个参数，类型为float</span></span><br><span class="line">    <span class="keyword">if</span> num1 &lt; <span class="number">18.5</span>:                 <span class="comment"># 2. 使用if、elif、else等判断来进行类别分类</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Underweight&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">18.5</span> &lt;= num1 &lt;= <span class="number">24.9</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Healthy&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">25</span> &lt;= num1 &lt;= <span class="number">29.9</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Overweight&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">30</span> &lt;= num1 &lt;= <span class="number">39.9</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Obese&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="number">40</span> &lt;= num1:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Severely obese&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(bmiCat(<span class="number">20</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-6"><a href="#Question-6" class="headerlink" title="Question 6"></a>Question 6</h4><p>Write a function named <strong>bmiReport</strong> which receives a name, weight, height, bmi and weight category. The function should return a nested dictionary. The outer dictionary should contain a single key, that is the name passed as a parameter. The inner dictionary should contain keys for each of the remaining parameters, weight, height, BMI, weight category and each key should be assigned the value passed when the function is called.<br>(0.5 mark)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>bmiReport</strong>的函数，该函数接收一个名称、体重、身高、bmi和体重类别。函数应该返回一个嵌套的字典。外部字典应该包含一个键，即作为参数传递的名称。内部字典应该包含每个剩余参数的键，体重，身高，BMI，体重类别，每个键都应该被赋值为函数调用时传递的值。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>字典和嵌套字典的使用。（具体初始化和使用方法百度一下）</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：bmiReport，输入5个参数，类型为string、float、float、float、string</li>
<li>先构造内部字典，表示weight, height, bmi, category</li>
<li>用另一个字典进行嵌套，用名字来找到内部字典</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bmiReport</span>(<span class="params">name1, weight1, height1, bmi1, category1</span>):</span>                                        <span class="comment"># 1. bmiReport，输入5个参数，类型为string、float、float、float、string</span></span><br><span class="line">    dic1 = &#123;<span class="string">&#x27;weight&#x27;</span>: weight1, <span class="string">&#x27;height&#x27;</span>: height1, <span class="string">&#x27;BMI&#x27;</span>: bmi1, <span class="string">&#x27;weight category&#x27;</span>: category1&#125;    <span class="comment"># 2. 先构造内部字典，表示weight, height, bmi, category</span></span><br><span class="line">    <span class="keyword">return</span> &#123;name1: dic1&#125;                                                                        <span class="comment"># 3. 用另一个字典进行嵌套，用名字来找到内部字典</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    bmiReport(<span class="string">&#x27;Sam&#x27;</span>, <span class="number">65</span>, <span class="number">180</span>, <span class="number">20</span>, <span class="string">&#x27;Healthy&#x27;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Part-2"><a href="#Part-2" class="headerlink" title="Part 2"></a>Part 2</h3><h4 id="Question-7"><a href="#Question-7" class="headerlink" title="Question 7"></a>Question 7</h4><p>Write a function named <strong>oddList</strong>, which receives two integers and returns a list of all odd numbers between the first and second integer parameters. The returned list should include the second integer, if it is an odd number.<br>(1 mark)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>oddList</strong>的函数，该函数接收两个整数，并返回第一个和第二个整数参数之间的所有奇数的列表。返回的列表应该包括第二个整数，如果它是一个奇数。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>使用for in range进行区间内遍历</li>
<li>range(a, b)表示从a到b（包括a但不包括b，即左闭右开区间，[a, b)）</li>
<li>奇数的判断方法之一：i % 2 == 1</li>
<li>使用列表的append()函数将元素添加到列表中</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：oddList，输入2个参数，类型为int、int</li>
<li>创建一个空列表</li>
<li>在区间内循环，因为最后如果是奇数也需要包含，所以要加一</li>
<li>是否为奇数的判断</li>
<li>是奇数，则添加进要返回的列表中</li>
<li>返回列表</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">oddList</span>(<span class="params">num1, num2</span>):</span>            <span class="comment"># 1. oddList，输入2个参数，类型为int、int</span></span><br><span class="line">    temp = []                       <span class="comment"># 2. 创建一个空列表</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num1, num2+<span class="number">1</span>):   <span class="comment"># 3. 在区间内循环，因为最后如果是奇数也需要包含，所以要加一</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">1</span>:              <span class="comment"># 4. 是否为奇数的判断</span></span><br><span class="line">            temp.append(i)          <span class="comment"># 5. 是奇数，则添加进要返回的列表中</span></span><br><span class="line">    <span class="keyword">return</span> temp                     <span class="comment"># 6. 返回列表</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(oddList(<span class="number">1</span>, <span class="number">7</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-8"><a href="#Question-8" class="headerlink" title="Question 8"></a>Question 8</h4><p>Write a function named <strong>reverseString</strong>, which receives a string and returns the string with all characters reversed e.g. if the function is called with the parameter <strong>PJ</strong> it will return <strong>JP</strong>.<br>(0.5 mark)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>reverseString</strong>的函数，该函数接收一个字符串并返回所有反转字符的字符串，例如，如果使用参数<strong>PJ</strong>调用该函数，它将返回<strong>JP</strong>。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>字符串快速反转。[::-1]即[参数1：参数2：-1]，前两个为空表示访问范围等为默认，第三个参数-1表示倒着数</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：reverseString，输入1个参数，类型为string</li>
<li>将字符串反转</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reverseString</span>(<span class="params">str1</span>):</span>    <span class="comment"># 1. reverseString，输入1个参数，类型为string</span></span><br><span class="line">    <span class="keyword">return</span> str1[::-<span class="number">1</span>]       <span class="comment"># 2. 将字符串反转</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(reverseString(<span class="string">&#x27;abc&#x27;</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-9"><a href="#Question-9" class="headerlink" title="Question 9"></a>Question 9</h4><p>Write a function named <strong>startAndEnd</strong>, which receives a list and returns True if the start and end of the list are the same e.g. if the function is called with the parameter <strong>[1, 2, 1]</strong> it will return true but if the function is called with the parameter <strong>[1, 2, 3]</strong> it will return False.<br>(1 Mark)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>startAndEnd</strong>的函数，它接收一个列表，如果列表的开头和结尾相同，则返回True，例如，如果函数使用参数 <strong>[1, 2, 1]</strong> 调用，则返回True，但如果函数使用参数 <strong>[1, 2, 3]</strong> 调用，则返回False。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>列表的访问。从0开始访问直到列表长度-1，即0到len(list1)-1</li>
<li>访问第一个则为list1[0]。</li>
<li>最后一个为list1[len(list1)-1]，因为len(list1)表示list的长度，可以省去简写成-1，即list1[-1]</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：startAndEnd，输入1个参数，类型为list</li>
<li>判断列表第一个和列表最后一个是否一致</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startAndEnd</span>(<span class="params">list1</span>):</span>         <span class="comment"># 1. startAndEnd，输入1个参数，类型为list</span></span><br><span class="line">    <span class="keyword">if</span> list1[<span class="number">0</span>] == list1[-<span class="number">1</span>]:   <span class="comment"># 2. 判断列表第一个和列表最后一个是否一致</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(startAndEnd([<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>]))</span><br><span class="line">    <span class="built_in">print</span>(startAndEnd([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Part-3"><a href="#Part-3" class="headerlink" title="Part 3"></a>Part 3</h3><h4 id="Question-10"><a href="#Question-10" class="headerlink" title="Question 10"></a>Question 10</h4><p>Write a function called <strong>createBoard</strong>. The function receives no parameters but will return a list containing 3 separate individual lists that represent the noughts and crosses board. Within each list, there should be 3 items containing the string “ “.<br>E.g. a single list will contain <strong>[“ “, “ “, “ “]</strong> and there should be 3 to represent all 9 squares of the noughts and crosses board.<br>(0.5 mark)<br>(本博客中文字部分无法显示下划线，用空格代替)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>createBoard</strong>的函数。该函数不接收任何参数，但将返回一个包含3个单独列表的列表，这些列表表示零和叉。在每个列表中，应该有3个包含字符串“ ”的项。<br>例如，一个列表将包含 <strong>[“ “, “ “, “ “]</strong> ，并且应该有3个来代表棋盘上的所有9个零和叉。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>二维列表的创建</li>
<li>一维列表就是[]，然后用逗号分割放进去的元素，例如放进3个” “就是[“ “, “ “, “ “]</li>
<li>二维列表就是再用一个[]把多个一维列表框起来，不同的一维列表也是用逗号隔开</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：createBoard，没有输入的参数</li>
<li>创建二维列表并返回</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createBoard</span>():</span>          <span class="comment"># 1. createBoard，没有输入的参数</span></span><br><span class="line">    <span class="keyword">return</span> [                <span class="comment"># 2. 创建二维列表并返回</span></span><br><span class="line">        [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">        [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">        [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(createBoard())</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-11"><a href="#Question-11" class="headerlink" title="Question 11"></a>Question 11</h4><p>Write a function named <strong>displayBoard</strong>. The function should receive a single parameter, that is a list containing 3 lists, as described in (10). Your function should display the each of the 3 lists on a single line.<br>E.g.<br>[“ ”, “ ”, “ ”]<br>[“ ”, “ ”, “ ”]<br>[“ ”, “ ”, “ ”]<br>(0.5 mark)<br>(本博客中文字部分无法显示下划线，用空格代替)</p>
<p><strong>题目翻译：</strong><br>写一个名为<strong>displayBoard</strong>的函数。函数应该接收一个参数，即包含3个列表的列表，如(10)所述。你的函数应该在一行中显示这三个列表。<br>如：<br>[“ ”, “ ”, “ ”]<br>[“ ”, “ ”, “ ”]<br>[“ ”, “ ”, “ ”]</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>for循环的使用</li>
<li>print()默认调用一次就输出为同一行，并且下次调用print()会在下一行</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：displayBoard，输入1个参数，类型为list，是一个二维列表</li>
<li>用for循环遍历<strong>二维列表</strong>里面的<strong>一维列表</strong></li>
<li>输出一维列表</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">displayBoard</span>(<span class="params">list1</span>):</span>    <span class="comment"># 1. displayBoard，输入1个参数，类型为list，是一个二维列表</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list1:         <span class="comment"># 2. 用for循环遍历二维列表里面的一维列表</span></span><br><span class="line">        <span class="built_in">print</span>(i)            <span class="comment"># 3. 输出一维列表</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    displayBoard([</span><br><span class="line">        [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">        [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">        [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-12"><a href="#Question-12" class="headerlink" title="Question 12"></a>Question 12</h4><p>Write a function named <strong>getMove</strong>. This function receives no parameters but prompts the user to enter a number between 1 to 9. The function should return the number entered by the user or if the user does not enter a number between 1 to 9, the function should return False.<br>(1 mark)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>getMove</strong>的函数。此函数不接收参数，但提示用户输入1到9之间的数字。函数应该返回用户输入的数字，或者如果用户没有输入1到9之间的数字，函数应该返回False。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>input()函数来接受用户的输入，可以在参数添加要提示的字符串</li>
<li>input()输入的值都会被存为string，不能因为输入了数字就当作int或者float，需要进行类型转换</li>
<li>使用if else对变量进行判断</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：getMove，没有输入的参数</li>
<li>使用input()接收输入</li>
<li>将遍历的类型强制转换为int</li>
<li>对输入进行判断</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getMove</span>():</span>              <span class="comment"># 1. getMove，没有输入的参数</span></span><br><span class="line">    num = <span class="built_in">input</span>(<span class="string">&#x27;please input a number between 1 to 9: &#x27;</span>)   <span class="comment"># 2. 使用input()接收输入</span></span><br><span class="line">    num = <span class="built_in">int</span>(num)          <span class="comment"># 3. 将遍历的类型强制转换为int</span></span><br><span class="line">    <span class="keyword">if</span> <span class="number">1</span> &lt;= num &lt;= <span class="number">9</span>:       <span class="comment"># 4. 对输入进行判断</span></span><br><span class="line">        <span class="keyword">return</span> num</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(getMove())</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-13"><a href="#Question-13" class="headerlink" title="Question 13"></a>Question 13</h4><p>Write a function named <strong>intToBoard</strong>. The function should receive a single integer and then return a tuple that contains two integers that represent the coordinates of a single square from the noughts and crosses board.</p>
<p>E.g. Each square on the board may be numbered as follows:<br>1, 2, 3<br>4, 5, 6<br>7, 8, 9</p>
<p>Square 1 may be accessed using (0,0). Therefore, if <strong>intToBoard</strong> receives 1 as a parameter, it should return the tuple (0,0). Note, consider the number of squares (9) and use of the floor and modulo operators.<br>(4.5 marks)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>intToBoard</strong>的函数。该函数应该接收一个整数，然后返回一个元组，该元组包含两个整数，表示一个正方形的坐标。</p>
<p>例:棋盘上的每个方格可以编号如下:<br>1 2 3<br>4 5 6<br>7 8 9</p>
<p>可以使用(0,0)访问方格1。因此，如果<strong>intToBoard</strong>接收到1作为参数，它应该返回元组(0,0)。注意，考虑平方的数量(9)以及地板运算符和模运算符的使用。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>使用地板除法 // 计算行数，即除法后忽略小数部分，因为有3行，将默认的编号地板除以3后会得到<br>  1 2 3 -&gt; 0 0 1<br>  4 5 6 -&gt; 1 1 2<br>  7 8 9 -&gt; 2 2 3<br>  因为第一行是0， 第二行是1， 第三行是2，干脆就把坐标减去1，再地板除法以3<br>  0 1 2 -&gt; 0 0 0<br>  3 4 5 -&gt; 1 1 1<br>  6 7 8 -&gt; 2 2 2<br>  这样就能正确表示行数</li>
<li>使用取余 % 计算列数，即不做小数的除法后保留最后的整数余数，因为有3列，将默认的编号对3取余后会得到<br>  1 2 3 -&gt; 1 2 0<br>  4 5 6 -&gt; 1 2 0<br>  7 8 9 -&gt; 1 2 0<br>  因为第一列是0， 第二列是1， 第三列是2，干脆就把坐标加上2，再对3取余<br>  3  4  5 -&gt; 0 1 2<br>  6  7  8 -&gt; 0 1 2<br>  9 10 11 -&gt; 0 1 2</li>
<li>同Q2，tuple()函数的使用</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：intToBoard，输入1个参数，类型为int</li>
<li>计算这个数字表示处在第几行</li>
<li>计算这个数字表示处在第几列</li>
<li>返回坐标元组</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">intToBoard</span>(<span class="params">num1</span>):</span>               <span class="comment"># 1. intToBoard，输入1个参数，类型为int</span></span><br><span class="line">    temp1 = (num1 - <span class="number">1</span>) // <span class="number">3</span>         <span class="comment"># 2. 计算这个数字表示处在第几行</span></span><br><span class="line">    temp2 = (num1 + <span class="number">2</span>) % <span class="number">3</span>          <span class="comment"># 3. 计算这个数字表示处在第几列</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">tuple</span>([temp1, temp2])    <span class="comment"># 4. 返回坐标元组</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(intToBoard(<span class="number">6</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-14"><a href="#Question-14" class="headerlink" title="Question 14"></a>Question 14</h4><p>Write a function named <strong>insertToBoard</strong>. This function should receive 3 parameters; the first parameter should be a Tuple, similar to that returned from intToBoard. The second parameter should be a list of 3 lists i.e. the board and the final parameter should be a Boolean value (either True or False). The <strong>insertToBoard</strong> function should as name implies, insert a players move on the board. If the Boolean parameter is True, then the function<br>should insert an <strong>“X”</strong> into the position of the board, provided by the Tuple of the first parameter. The function should also return a tuple with the value True and the board (list of 3 lists). If the Boolean parameter is False, then the function should insert an <strong>“O”</strong> in the board and return a tuple with the value True and the board. The board should only be updated with valid moves, that is areas on the board which do not contain a <strong>“X”</strong> or <strong>“O”</strong>. If the position specified by the first parameter contains a previous move i.e. an <strong>“X”</strong> or <strong>“O”</strong> then the function should return False and the board.</p>
<p>Remember, a tuple’s items may be accessed similarly to a list:<br>i.e. consider the Tuple named t, which contains 3 elements: <strong>t = (1,2,3)</strong>. To access the first element, we would use <strong>t[0]</strong><br>(1.5 marks)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>insertToBoard</strong>的函数。这个函数应该接收3个参数；第一个参数应该是一个元组，类似于从intToBoard返回的元组。第二个参数应该是3个列表的列表即棋盘，最后一个参数应该是一个布尔值(True或False)。<strong>insertToBoard</strong>函数顾名思义，应该在棋盘上插入一个玩家移动。如果布尔参数为True，则函数<br>应插入一个 <strong>“X”</strong> 到板的位置，由第一个参数的元组提供。该函数还应该返回一个值为True的元组和board(由3个列表组成的列表)。如果布尔参数为False，则函数应该在板子中插入一个 <strong>“O”</strong> ，并返回一个值为True和板子的元组。棋盘应该只更新有效的移动，即棋盘上不包含 <strong>“X”</strong> 或 <strong>“O”</strong> 的区域。如果第一个参数指定的位置包含之前的移动，即 <strong>“X”</strong> 或 <strong>“O”</strong> ，则该函数应返回False和board。</p>
<p>记住，元组的项可以类似于列表的访问方式:<br>例如，考虑名为t的元组，它包含3个元素: <strong>t = (1,2,3)**。要访问第一个元素，可以使用 **t[0]</strong></p>
<p><strong>本题考点：</strong></p>
<ul>
<li>元组的访问，跟列表是一样的，题目有说明</li>
<li>根据题目要求使用if elif else进行组合，对下棋的逻辑进行整理，像一棵树一样展开决策的枝桠</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：insertToBoard，输入3个参数，类型为tuple、list、bool</li>
<li>类似于数组的访问得到行row和列col的值</li>
<li>如果没下过，则可以下棋</li>
<li>按照要求下’X’或者’O’</li>
<li>返回成功下棋的True和下过之后的棋盘list</li>
<li>已经下过了，就返回这次没下棋的False和原本的棋盘list</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertToBoard</span>(<span class="params">tuple1, list1, bool1</span>):</span>    <span class="comment"># 1. insertToBoard，输入3个参数，类型为tuple、list、bool</span></span><br><span class="line">    row = tuple1[<span class="number">0</span>]                         <span class="comment"># 2. 类似于数组的访问得到行row和列col的值</span></span><br><span class="line">    col = tuple1[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> list1[row][col] == <span class="string">&#x27;_&#x27;</span>:              <span class="comment"># 3. 如果没下过，则可以下棋    </span></span><br><span class="line">        <span class="keyword">if</span> bool1:</span><br><span class="line">            list1[row][col] = <span class="string">&#x27;X&#x27;</span>           <span class="comment"># 4. 按照要求下&#x27;X&#x27;或者&#x27;O&#x27;</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">tuple</span>([<span class="literal">True</span>, list1])     <span class="comment"># 5. 返回成功下棋的True和下过之后的棋盘list</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> bool1:</span><br><span class="line">            list1[row][col] = <span class="string">&#x27;O&#x27;</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">tuple</span>([<span class="literal">True</span>, list1])</span><br><span class="line">    <span class="keyword">else</span>:                                   <span class="comment"># 6. 已经下过了，就返回这次没下棋的False和原本的棋盘list</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>([<span class="literal">False</span>, list1])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(insertToBoard(</span><br><span class="line">        (<span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">        [</span><br><span class="line">            [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">        ],</span><br><span class="line">        <span class="literal">True</span></span><br><span class="line">    ))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-15"><a href="#Question-15" class="headerlink" title="Question 15"></a>Question 15</h4><p>Write a function named <strong>checkDraw</strong>. The function receives a single parameter, the board (list of 3 lists). The function should check whether there are any free squares left on the board i.e. a square containing “ ”. If there are squares on the board containing free spaces, then the function should return False, otherwise it should return True.<br>(2.5 marks)<br>(本博客中文字部分无法显示下划线，用空格代替)</p>
<p><strong>题目翻译：</strong><br>编写一个名为<strong>checkDraw</strong>的函数。该函数接收一个参数，即board(由3个列表组成的列表)。该函数检查棋盘上是否有剩余的方格，即包含” “的方格。如果棋盘上有包含空闲空间的正方形，则函数应返回False，否则应返回True。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>二维数组的访问。先通过一次遍历得到二维数组里面的一维数组，再第二次遍历得到一维数组里面的元素值。就是先定好按行访问（按顺序访问一维数组），再定好按列访问（按顺序访问单个元素）</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：checkDraw，输入1个参数，类型为list，二维列表</li>
<li>遍历二维数组bigList，得到里面的一维数组smallList</li>
<li>遍历一维数组smallList，得到里面的单个元素str1</li>
<li>判断单个元素是不是没下过</li>
<li>有一个没下过就False</li>
<li>两层for循环所有判断完都没有False，说明都下过了，为True</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkDraw</span>(<span class="params">bigList</span>):</span>         <span class="comment"># 1. checkDraw，输入1个参数，类型为list，二维列表</span></span><br><span class="line">    <span class="keyword">for</span> smallList <span class="keyword">in</span> bigList:   <span class="comment"># 2. 遍历二维数组bigList，得到里面的一维数组smallList</span></span><br><span class="line">        <span class="keyword">for</span> str1 <span class="keyword">in</span> smallList:  <span class="comment"># 3. 遍历一维数组smallList，得到里面的单个元素str1</span></span><br><span class="line">            <span class="keyword">if</span> str1 == <span class="string">&#x27;_&#x27;</span>:     <span class="comment"># 4. 判断单个元素是不是没下过</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span>    <span class="comment"># 5. 有一个没下过就False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span>                 <span class="comment"># 6. 两层for循环所有判断完都没有False，说明都下过了，为True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(checkDraw([</span><br><span class="line">            [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">        ]))</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Question-16"><a href="#Question-16" class="headerlink" title="Question 16"></a>Question 16</h4><p>Write a function named <strong>checkWin</strong>. The function receives a single parameter, the board (list of 3 lists). The function should check whether any one of the 8 possible winning conditions are present. The winning conditions are when a horizontal, vertical or diagonal line of 3 squares on the board contain the same symbol (<strong>“X”</strong> or <strong>“O”</strong>). If either of these conditions are met, the function should return True, otherwise it should return False.<br>(4 marks)</p>
<p><strong>题目翻译：</strong></p>
<p>编写一个名为<strong>checkWin</strong>的函数。该函数接收一个参数，即board(由3个列表组成的列表)。该函数应检查8个可能获胜条件中的任何一个是否存在。获胜条件是棋盘上由3个方格组成的水平、垂直或对角线包含相同符号( <strong>“X”</strong> 或 <strong>“O”</strong> )。如果满足其中任何一个条件，函数应返回True，否则应返回False。</p>
<p><strong>本题考点：</strong></p>
<ul>
<li>判断胜利就行，不管是X还是O，所以只要三个一样连在一起就是胜利，返回True，8种胜利条件都不满足就是False</li>
<li>按行访问数组可以轻松得到同一行的三个元素，不同行同一列的三个元素要么转置变成行，要么用坐标访问</li>
<li>8种胜利条件如下：<br>  按行有3种<br>  X X X   /   ~ ~ ~   /   ~ ~ ~<br>  ~ ~ ~   /   X X X   /   ~ ~ ~<br>  ~ ~ ~   /   ~ ~ ~   /   X X X<br>  按列有3种<br>  X ~ ~   /   ~ X ~   /   ~ ~ X<br>  X ~ ~   /   ~ X ~   /   ~ ~ X<br>  X ~ ~   /   ~ X ~   /   ~ ~ X<br>  按对角线有2种<br>  X ~ ~   /   ~ ~ X<br>  ~ X ~   /   ~ X ~<br>  ~ ~ X   /   X ~ ~</li>
</ul>
<p><strong>题目分析：</strong></p>
<ol>
<li>函数名：checkWin，输入1个参数，类型为list，二维列表</li>
<li>按行访问，如果同一行三个一样就获胜</li>
<li>对二维列表进行转置，使得同一列列也能在一次循环中访问到</li>
<li>对角线进行判断</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkWin</span>(<span class="params">list1</span>):</span>                        <span class="comment"># 1. checkWin，输入1个参数，类型为list，二维列表</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list1:                         <span class="comment"># 2. 按行访问，如果同一行三个一样就获胜</span></span><br><span class="line">        <span class="keyword">if</span> i[<span class="number">0</span>] == i[<span class="number">1</span>] == i[<span class="number">2</span>]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    list2 = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">list</span>, <span class="built_in">zip</span>(*list1)))    <span class="comment"># 3. 对二维列表进行转置，使得同一列列也能在一次循环中访问到</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list2:</span><br><span class="line">        <span class="keyword">if</span> i[<span class="number">0</span>] == i[<span class="number">1</span>] == i[<span class="number">2</span>]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> list1[<span class="number">0</span>][<span class="number">0</span>] == list1[<span class="number">1</span>][<span class="number">1</span>] == list1[<span class="number">2</span>][<span class="number">2</span>]:   <span class="comment"># 4. 对角线进行判断</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">elif</span> list1[<span class="number">0</span>][<span class="number">2</span>] == list1[<span class="number">1</span>][<span class="number">1</span>] == list1[<span class="number">2</span>][<span class="number">0</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(checkWin([</span><br><span class="line">        [<span class="string">&#x27;X&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">        [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;X&#x27;</span>, <span class="string">&#x27;_&#x27;</span>],</span><br><span class="line">        [<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;X&#x27;</span>],</span><br><span class="line">    ]))</span><br></pre></td></tr></table></figure>

<hr>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐Python</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-变分自编码器VAE(Variational Autoencoder)的原理</title>
    <url>/4bb99d46.html</url>
    <content><![CDATA[<p>Kingma, Diederik P., and Max Welling. “Auto-encoding variational bayes.” arXiv preprint arXiv:1312.6114 (2013).</p>
<p>论文的理论推导见：<a href="https://zhuanlan.zhihu.com/p/25401928">https://zhuanlan.zhihu.com/p/25401928</a></p>
<p>中文翻译为：变分自动编码器</p>
<p>下面是VAE的直观解释，不需要太多的数学知识。</p>
<span id="more"></span>

<hr>
<h3 id="什么是变分自动编码器？"><a href="#什么是变分自动编码器？" class="headerlink" title="什么是变分自动编码器？"></a>什么是变分自动编码器？</h3><p>为了理解VAE，我们首先从最简单的网络说起，然后再一步一步添加额外的部分。</p>
<p>一个描述神经网络的常见方法是近似一些我们想建模的函数。然而神经网络也可以被看做是携带信息的数据结构。</p>
<p>假如我们有一个带有解卷积层的网络，我们设置输入为值全为1的向量，输出为一张图像。然后，我们可以训练这个网络去减小重构图像和原始图像的平均平方误差。那么训练完后，这个图像的信息就被保留在了网络的参数中。</p>
<img src="/4bb99d46/1.png" class>

<p>现在，我们尝试使用更多的图片。这次我们用one-hot向量而不是全1向量。我们用[1, 0, 0, 0]代表猫，用[0, 1, 0, 0]代表狗。虽然这要没什么问题，但是我们最多只能储存4张图片。当然，我们也可以增加向量的长度和网络的参数，那么我们可以获得更多的图片。</p>
<p>但是，这样的向量很稀疏。为了解决这个问题，我们想使用实数值向量而不是0，1向量。我们可认为这种实数值向量是原图片的一种编码，这也就引出了编码/解码的概念。举个例子，[3.3, 4.5, 2.1, 9.8]代表猫，[3.4, 2.1, 6.7, 4.2] 代表狗。这个已知的初始向量可以作为我们的潜在变量。</p>
<p>如果像我上面一样，随机初始化一些向量去代表图片的编码，这不是一个很好的办法，我们更希望计算机能帮我们自动编码。在autoencoder模型中，我们加入一个编码器，它能帮我们把图片编码成向量。然后解码器能够把这些向量恢复成图片。</p>
<img src="/4bb99d46/2.png" class>

<p>我们现在获得了一个有点实际用处的网络了。而且我们现在能训练任意多的图片了。如果我们把这些图片的编码向量存在来，那以后我们就能通过这些编码向量来重构我们的图像。我们称之为标准自编码器。</p>
<p>但是，我们想建一个产生式模型，而不是一个只是储存图片的网络。现在我们还不能产生任何未知的东西，因为我们不能随意产生合理的潜在变量。因为合理的潜在变量都是编码器从原始图片中产生的。</p>
<p>这里有个简单的解决办法。我们可以对编码器添加约束，就是强迫它产生服从单位高斯分布的潜在变量。正式这种约束，把VAE和标准自编码器给区分开来了。</p>
<p>现在，产生新的图片也变得容易：我们只要从单位高斯分布中进行采样，然后把它传给解码器就可以了。</p>
<p>事实上，我们还需要在重构图片的精确度和单位高斯分布的拟合度上进行权衡。</p>
<p>我们可以让网络自己去决定这种权衡。对于我们的损失函数，我们可以把这两方面进行加和。一方面，是图片的重构误差，我们可以用平均平方误差来度量，另一方面。我们可以用KL散度（KL散度介绍）来度量我们潜在变量的分布和单位高斯分布的差异。</p>
<img src="/4bb99d46/3.png" class>

<p>为了优化KL散度，我们需要应用一个简单的参数重构技巧：不像标准自编码器那样产生实数值向量，VAE的编码器会产生两个向量：一个是均值向量，一个是标准差向量。</p>
<img src="/4bb99d46/4.png" class>

<p>我们可以这样来计算KL散度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># z_mean and z_stddev are two vectors generated by encoder network</span></span><br><span class="line">latent_loss = <span class="number">0.5</span> * tf.reduce_sum(tf.square(z_mean) + tf.square(z_stddev) - tf.log(tf.square(z_stddev)) - <span class="number">1</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>当我们计算解码器的loss时，我们就可以从标准差向量中采样，然后加到我们的均值向量上，就得到了编码去需要的潜在变量。</p>
<img src="/4bb99d46/5.png" class>

<p>VAE除了能让我们能够自己产生随机的潜在变量，这种约束也能提高网络的产生图片的能力。</p>
<p>为了更加形象，我们可以认为潜在变量是一种数据的转换。</p>
<p>我们假设我们有一堆实数在区间[0, 10]上，每个实数对应一个物体名字。比如，5.43对应着苹果，5.44对应着香蕉。当有个人给你个5.43，你就知道这是代表着苹果。我们能用这种方法够编码无穷多的物体，因为[0, 10]之间的实数有无穷多个。</p>
<p>但是，如果某人给你一个实数的时候其实是加了高斯噪声的呢？比如你接受到了5.43，原始的数值可能是 [4.4 ~ 6.4]之间的任意一个数，真实值可能是5.44(香蕉)。</p>
<p>如果给的方差越大，那么这个平均值向量所携带的可用信息就越少。</p>
<p>现在，我们可以把这种逻辑用在编码器和解码器上。编码越有效，那么标准差向量就越能趋近于标准高斯分布的单位标准差。</p>
<p>这种约束迫使编码器更加高效，并能够产生信息丰富的潜在变量。这也提高了产生图片的性能。而且我们的潜变量不仅可以随机产生，也能从未经过训练的图片输入编码器后产生。</p>
<hr>
<h3 id="VAE的效果"><a href="#VAE的效果" class="headerlink" title="VAE的效果"></a>VAE的效果</h3><p>我做了一些小实验来测试VAE在MNIST手写数字数据集上的表现：</p>
<img src="/4bb99d46/6.png" class>

<p>这里有一些使用VAE好处，就是我们可以通过编码解码的步骤，直接比较重建图片和原始图片的差异，但是GAN做不到。</p>
<p>另外，VAE的一个劣势就是没有使用对抗网络，所以会更趋向于产生模糊的图片。</p>
<p>这里也有一些结合VAE和GAN的工作：使用基本的VAE框架，但是用对抗网络去训练解码器。更多细节参考：<a href="https://arxiv.org/pdf/1512.09300.pdf">https://arxiv.org/pdf/1512.09300.pdf</a>和<a href="http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/">http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/</a></p>
<p>你可以从这里获得一些这篇博客的代码：<a href="https://github.com/kvfrans/variational-autoencoder">https://github.com/kvfrans/variational-autoencoder</a>和一个整理好的版本：<a href="https://jmetzen.github.io/2015-11-27/vae.html">https://jmetzen.github.io/2015-11-27/vae.html</a></p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="http://kvfrans.com/variational-autoencoders-explained/">http://kvfrans.com/variational-autoencoders-explained/</a><br><a href="https://www.cnblogs.com/huangshiyu13/p/6209016.html">https://www.cnblogs.com/huangshiyu13/p/6209016.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-解析Variational AutoEncoder（VAE）</title>
    <url>/64e0fbea.html</url>
    <content><![CDATA[<h3 id="模型总览"><a href="#模型总览" class="headerlink" title="模型总览"></a>模型总览</h3><h4 id="AutoEncoder"><a href="#AutoEncoder" class="headerlink" title="AutoEncoder"></a>AutoEncoder</h4><p>在说VAE之前，先来看一下它的前身AutoEncoder(AE)。</p>
<p>AE是非常知名的自编码器，它通过自监督的训练方式，能够从原始特征获得一个潜在的特征编码，实现了自动化的特征工程，并且达到了降维和泛化的目的。</p>
<p>它的网络结构很简单，有编码和解码两个部分组成：</p>
<img src="/64e0fbea/1.webp" class>

<span id="more"></span>

<p>容易看出，之所以是自监督就是因为网络的target即是input本身，因此不需要额外的标签工作，虽然它由编码器和解码器两个部分组成，但是，显然从自编码器这个名字就可以看出，AE的重点在于编码，即得到这个隐藏层的向量，作为input的潜在特征，这是常见的一种embedding的一种方式。而解码的结果，基于训练目标，如果损失足够小的话，将会与input相同，从这一点上看解码的值没有任何实际意义，除了通过增加误差来补充平滑一些初始的零值或有些许用处。因为，从输入到输出的整个过程，都是基于已有的训练数据的映射，尽管隐藏层的维度通常比输入层小很多，但隐藏层的概率分布依然只取决于训练数据的分布，这就导致隐藏状态空间的分布并不是连续的，于是如果我们随机生成隐藏层的状态，那么它经过解码将很可能不再具备输入特征的特点，因此想通过解码器来生成数据就有点强模型所难了。</p>
<hr>
<h4 id="Variational-AutoEncoder"><a href="#Variational-AutoEncoder" class="headerlink" title="Variational AutoEncoder"></a>Variational AutoEncoder</h4><p>正是因为以上的这些原因，有大佬就对AE的隐藏层做了些改动，得到了VAE。</p>
<img src="/64e0fbea/2.webp" class>

<p>VAE将经过神经网络编码后的隐藏层假设为一个标准的高斯分布，然后再从这个分布中采样一个特征，再用这个特征进行解码，期望得到与原始输入相同的结果，损失和AE几乎一样，只是增加编码推断分布与标准高斯分布的KL散度的正则项，显然增加这个正则项的目的就是防止模型退化成普通的AE，因为网络训练时为了尽量减小重构误差，必然使得方差逐渐被降到0，这样便不再会有随机采样噪声，也就变成了普通的AE。</p>
<p>没错，我们先抛开变分，它就是这么简单的一个假设… 仔细想一下，就会觉得妙不可言。</p>
<p>它妙就妙在它为每个输入x，生成了一个潜在概率分布 p(z|x)，然后再从分布中进行随机采样，从而得到了连续完整的潜在空间，解决了AE中无法用于生成的问题。</p>
<p>《论语》有言：“举一隅，不以三隅反，则不复也。” 给我的启发就是看事物应该不能只看表面，而应该了解其本质规律，从而可以灵活迁移到很多类似场景。聪明人学习当举一反三，那么聪明的神经网络，自然也不能只会怼训练数据。如果我们把原始输入看作是一个表面特征，而其潜在特征便是表面经过抽象之后的类特征，它将比表面特征更具备区分事物的能力，而VAE直接基于拟合了基于已知的潜在概率分布，可以说是进一步的掌握了事物的本质。</p>
<p>就拿一个人的某个行为来说，我们不能单纯看行为本身，因为这个行为往往代表了他的综合特性，他从出生开始，因为遗传，后天教育和环境，决定了他在面对某种情形的情况下，高概率会产生这个行为，也就是说掌握了概率分布，就掌控了一切。</p>
<p>这就好比..某个骚年A说他喜欢姑娘B，经过AE的编码得到的是A喜欢B类型的姑娘的特征，但是VAE编码之后就得到了更深入的特征：A馋B类型姑娘的身子。透过现象看本质，我想这便是VAE更胜一筹的原因。</p>
<hr>
<h3 id="变分自编码是怎么炼成的"><a href="#变分自编码是怎么炼成的" class="headerlink" title="变分自编码是怎么炼成的"></a>变分自编码是怎么炼成的</h3><p>读了上面的内容之后，你应该对VAE模型有了一个较为直观和感性的认知，但是可能会疑惑所谓的变分到底在哪里？</p>
<p>放心，变分并没有被作者吃掉，接下来，我们就从变分推断的角度，对VAE进行一个理性的推导。有了上面的基础，再读下面的内容时就会轻松愉快很多。</p>
<h4 id="变分推断"><a href="#变分推断" class="headerlink" title="变分推断"></a>变分推断</h4><p>变分自编码器（VAE）的想法和名字的由来便是变分推断了，那么什么是变分推断呢？</p>
<p>变分推断是 MCMC 搞不定场景的一种替代算法，它考虑一个贝叶斯推断问题，给定观测变量 x∈R^k 和潜变量 z∈R^d，其联合概率分布为 p(z, x) = p(z)p(x|z)，目标是计算后验分布 p(z|x)。然后我们可以假设一个变分分布 q(z) 来自分布族 Q，通过最小化 KL 散度来近似后验分布 p(z|x)：</p>
<img src="/64e0fbea/3.svg" class>

<p>这么一来，就成功的将一个贝叶斯推断问题转化为了一个优化问题~</p>
<hr>
<h4 id="变分推导过程"><a href="#变分推导过程" class="headerlink" title="变分推导过程"></a>变分推导过程</h4><p>有了变分推断的认知，我们再回过头去看一下VAE模型的整体框架，VAE就是将AE的编码和解码过程转化为了一个贝叶斯概率模型：</p>
<p>我们的训练数据即为观测变量 x，假设它由不能直接观测到的潜变量 z 生成， 于是，生成观测变量过程便是似然分布：p(x|z)，也就是解码器，因而编码器自然就是后验分布：p(z|x)。</p>
<p>根据贝叶斯公式，建立先验、后验和似然的关系：</p>
<img src="/64e0fbea/4.svg" class>

<p>接下来，基于上面变分推断的思想，我们假设变分分布 q_x(z)，通过最小化 KL 散度来近似后验分布 p(z|x) ，于是，最佳的 q_x^* 便是：</p>
<img src="/64e0fbea/5.svg" class>

<p>因为训练数据 x 是确定的，因此 log~p(x) 是一个常数，于是上面的优化问题等价于：</p>
<img src="/64e0fbea/6.svg" class>

<p>此时，观察一下优化方程的形式…已经是我们前面所说的 VAE 的损失函数了</p>
<p>显然，跟我们希望解码准确的目标是一致的。要解码的准，则 p(z|x) 应该尽可能的小，编码特征 z 的分布 q_x(z) 同 p(z) 尽可能的接近，此时恰好 -log~p(x|z) 和 KL(q_x(z)||p(z)) 都尽可能的小，与损失的优化的目标也一致。</p>
<hr>
<h3 id="如何计算极值"><a href="#如何计算极值" class="headerlink" title="如何计算极值"></a>如何计算极值</h3><p>正如前面所提到的AE潜变量的局限性，我们希望VAE的潜变量分布 p(z) 应该能满足海量的输入数据 x 并且相互独立，基于中心极限定理，以及为了方便采样，我们有理由直接假设 p(z) 是一个标准的高斯分布 N(0,1)。</p>
<h4 id="编码部分"><a href="#编码部分" class="headerlink" title="编码部分"></a>编码部分</h4><p>我们先来看一下编码部分，我们希望拟合一个分布 q_x(z) = N(μ, σ) 尽可能接近 p(z) = N(0, 1)，关键就在于基于输入 x 计算 μ 和 σ，直接算有点困难，于是就使用两个神经网络 f(x) 和 g(x) 来无脑拟合 μ 和 σ。</p>
<p>值得一提的是，很多地方实际使用的 f(x)、g(x) 两部分神经网络并不是独立的，而是有一部分交集，即他们都先通过一个 h(x) 映射到一个中间层 h，然后分别对 h 计算 f(h) 和 g(h)。这样做的好处的话一方面是可以减少参数数量，另外这样算应该会导致拟合的效果差一些，算是防止过拟合吧。</p>
<hr>
<h4 id="解码部分"><a href="#解码部分" class="headerlink" title="解码部分"></a>解码部分</h4><p>解码，即从潜变量 z 生成数据 x 的过程，在于最大化似然 p(x|z)，那这应该是个什么分布呢？通常我们假设它是一个伯努利分布或是高斯分布。伯努利分布十分简单，熟悉的人也多，高斯分布接近大自然了，用起来又方便。</p>
<p>知道了分布类型，那计算 -log~p(x|z) 最小值其实只要把分布公式带进去算就可以了</p>
<ul>
<li><p>高斯分布</p>
  <img src="/64e0fbea/7.svg" class>

<p>  和预期一样，演变为了均方误差。</p>
</li>
<li><p>伯努利分布</p>
<p>  假设伯努利的二元分布是 P 和 1-P (注意这里是输出没一维组成的向量)</p>
  <img src="/64e0fbea/8.svg" class>

<p>  很对，正好就是交叉熵的损失。</p>
</li>
</ul>
<p>然后，将编码和解码部分组合到一起，就形成了完整的VAE网络。</p>
<hr>
<h3 id="一点微不足道的技巧"><a href="#一点微不足道的技巧" class="headerlink" title="一点微不足道的技巧"></a>一点微不足道的技巧</h3><p>训练的时候似乎出了点问题。从编码得到的分布 N(μ, σ) 随机采样 z 的这个过程没法求导，没法进行误差反向传播…</p>
<p>好在这里可以使用一个叫做<strong>重参数（reparametrisation trick）</strong>的技巧：</p>
<img src="/64e0fbea/9.svg" class>

<p>这样一来将采样变成了一个数值变换，整个过程便可导了</p>
<p>这样，训练好模型之后，我们可以直接将解码部分拿出来，通过标准高斯分布随机采样源源不断的生成数据了。</p>
<hr>
<h3 id="延伸的一些思考"><a href="#延伸的一些思考" class="headerlink" title="延伸的一些思考"></a>延伸的一些思考</h3><p>VAE中使用神经网络来拟合高斯分布的想法独树一帜，对很多任务能带来启发。神经网络在特征化训练数据的过程无异于海量数据的管中窥豹，但是想要让模型超脱于豹，而像人一样产生对相似的猫、老虎…之类的概念，VAE的这种思想颇有一些意味。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.jianshu.com/p/ffd493e10751">https://www.jianshu.com/p/ffd493e10751</a><br><a href="https://arxiv.org/pdf/1312.6114.pdf">Auto-Encoding Variational Bayes</a><br><a href="https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73">Understanding Variational Autoencoders</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-VAE变分自编码机详解 原理篇</title>
    <url>/430f6451.html</url>
    <content><![CDATA[<p>这篇文章介绍变分自编码机(Variational AutoEncoder, VAE)，VAE作为可以和GAN比肩的生成模型，融合了贝叶斯方法和深度学习的优势，拥有优雅的数学基础和简单易懂的架构以及令人满意的性能，其能提取disentangled latent variable的特性也使得它比一般的生成模型具有更广泛的意义。这次会深入VAE的数学原理和实现方法，让大家对VAE有更详细的了解。</p>
<p>这篇文章的大部分内容都来自<a href="https://arxiv.org/abs/1606.05908">Tutorial on Variational AutoEncoder</a>，有兴趣的同学可以直接看英文原版。</p>
<span id="more"></span>

<hr>
<h3 id="Latent-Variable-Model"><a href="#Latent-Variable-Model" class="headerlink" title="Latent Variable Model"></a>Latent Variable Model</h3><p>生成模型一般会生成多个种类的数据，比如说在手写数字生成中，我们总共有10个类别的数字要生成，这个时候latent variable model就是一个很好的选择。</p>
<p>为什么呢？举例来说，我们很容易能注意到相同类别的数据在不同维度之间是有依赖存在的，比如生成数字5的时候，如果左边已经生成了数字5的左半部分，那么右半部分就几乎可以确定是5的另一半了。</p>
<p>因此一个好的想法是，生成模型在生成数字的时候有两个步骤，即(1)决定要生成什么数字，这个数字用一个被称为latent variable的向量z来表示，(2)然后再根据z来直接生成相应的数字。用数学表达式来表示就是：</p>
<img src="/430f6451/1.jpg" class>

<p>这就是所谓的latent variable model。</p>
<p>我们要介绍的VAE就是latent variable model的一种，我们将会看到，VAE可以利用BP算法来快速训练，且不需要对latent code的prior有任何知识，所有你需要的只是一个简单的encoder-decoder模型。也正是因为吸收了深度学习时代的众多技术优势，才使VAE变成了一个广受欢迎的生成模型。</p>
<hr>
<h3 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h3><h4 id="latent-variable"><a href="#latent-variable" class="headerlink" title="latent variable"></a>latent variable</h4><p>要解式(1)，就必须决定P(z)，然而latent variable z的prior是很难决定的，尤其是在深度学习背景下的生成模型，其生成的数据动辄上百维度，因此数据中就会存在大量依赖。</p>
<p>VAE是怎么解决这个问题的呢？它没有对z做出任何假设，而是说任何z的sample都可以从一个最简单的高斯分布来得到，即均值为0，协方差为单位矩阵的高斯分布。</p>
<p>你可能会觉得很奇怪，这是为什么呢？其实这里最关键的是注意到任何d维分布都可以从一个d维高斯分布+一个足够复杂的函数映射得到，比如我们可以把一个二维高斯分布映射成环型：</p>
<img src="/430f6451/2.jpg" class>

<p>因此，只要有足够强力的函数估计器，我们就可以获得任何分布的latent variable z。很容易就可以想到用神经网络来构建这个函数估计器。</p>
<p>接下来的问题是，如何最大化(1)式？</p>
<hr>
<h4 id="The-objective"><a href="#The-objective" class="headerlink" title="The objective"></a>The objective</h4><p>有了z的prior，我们很容易想到利用多次采样的方式来最大化likelihood：</p>
<img src="/430f6451/3.jpg" class>

<p>然而这种方法非常低效，特别是当z在高维空间的时候。</p>
<p>那么VAE是怎么解决这个问题的呢？</p>
<p>首先我们需要注意到，几乎所有的P(X|z)都是接近于0的，因为既然X是只有有限个类数据，那么z就应该有特定的值，因此我们要做的就是只用那些最有可能生成X的z来训练。这个时候我们就需要一个新的函数用来生成X对应的latent variable distribution：</p>
<img src="/430f6451/4.jpg" class>

<p>这个Q让我们可以计算</p>
<img src="/430f6451/5.jpg" class>

<p>而不是z是高斯分布时候的期望，这就减少了计算量。然而，虽然这样很好，但是上式和P(X)又有什么关系呢？别忘了我们最终的目的是最大化P(X)，因此这里我们就需要把这两个式子联系起来。</p>
<p>这里KL散度是一个比较好的选择，因为它刻画了两个分布之间的距离：</p>
<img src="/430f6451/6.jpg" class>

<p>我们用贝叶斯公式来分解右边的P(z|X)：</p>
<img src="/430f6451/7.jpg" class>

<p>移项，两边乘-1就得到：</p>
<img src="/430f6451/8.jpg" class>

<p>上式把Q(z)换成Q(z|X)就得到了VAE的objective：</p>
<img src="/430f6451/9.jpg" class>

<p>我们看到上式左边正是我们<strong>想优化</strong>的两项，即P(X)的likelihood和Q(z|X)估计P(z|X)的error。而右边也正好是我们<strong>可以计算</strong>的两项，第一项相当于一个decoder，第二项就相当于一个encoder。</p>
<p>上式右边一般被称为Evidence Lower Bound(ELBO)，一般在讨论VAE的时候我们用ELBO来指代它的cost function。</p>
<hr>
<h4 id="Optimization-和-reparameterization-trick"><a href="#Optimization-和-reparameterization-trick" class="headerlink" title="Optimization 和 reparameterization trick"></a>Optimization 和 reparameterization trick</h4><p>得到objective我们就需要做优化，这里我们首先需要得到Q(z|X)，一般假设它满足一个高斯分布：</p>
<img src="/430f6451/10.jpg" class>

<p>这里μ和Σ是任意的函数，一般用神经网络来拟合。</p>
<p>为了计算简便，我们一般假设Σ是对角矩阵，它的好处是让KL散度更好计算，两个多元高斯分布的KL散度是：</p>
<img src="/430f6451/11.jpg" class>

<p>如果Σ是对角矩阵，则上式可化简为：</p>
<img src="/430f6451/12.jpg" class>

<p>最终的cost function就是：</p>
<img src="/430f6451/13.jpg" class>

<p>理论上来说我们需要sample多个z来估计上式，然而实际操作的时候我们用一次sample来作为估计值：</p>
<img src="/430f6451/14.jpg" class>

<p>到这里你可能会觉得万事俱备只差代码了，然而等等，上式还有一个很致命的问题，即在sample z的时候，我们实际上做了一个不可导的计算，这会导致encoder和decoder之间无法传递梯度，但是在我们的假设中，z必须依赖于encoder Q，怎么解决这个问题呢？</p>
<p>这里解决的关键在于，我们不直接从Q编码得到的分布来sample z，而是先从一个标准正态分布采样一个值ε，然后通过Q得到的μ和Σ把这个值变换到Q得到的分布上：</p>
<img src="/430f6451/15.jpg" class>

<p>这样整个网络就是可导的，我们实际上的计算表达式是：</p>
<img src="/430f6451/16.jpg" class>

<p>如下图所示：</p>
<img src="/430f6451/17.webp" class>

<p>上述技巧被称为reparameterization trick，是一种非常有用的技巧。</p>
<hr>
<h4 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h4><p>当你训练好模型，想要生成一个新的数据的时候，你只需要保留decoder就可以，如下图所示：</p>
<img src="/430f6451/18.jpg" class>

<hr>
<h3 id="Conditional-VAE"><a href="#Conditional-VAE" class="headerlink" title="Conditional VAE"></a>Conditional VAE</h3><p>有的时候我们希望整个生成过程是基于某个条件的，这就是所谓的conditional VAE，其训练和测试图示如下图所示：</p>
<img src="/430f6451/19.webp" class>

<p>其objective的推导和VAE类似，只需要加上额外的条件即可：</p>
<img src="/430f6451/20.jpg" class>

<p>CVAE的一个典型应用是填补有缺失的图片，这时候缺失图片就是条件。</p>
<hr>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>在这篇文章中介绍了VAE的数学原理和实现机制，研究者在之后也提出了性能更为优异的beta-VAE和beta-TCVAE等，有兴趣的同学可以了解一下。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/108262170">https://zhuanlan.zhihu.com/p/108262170</a><br><a href="https://arxiv.org/abs/1606.05908">https://arxiv.org/abs/1606.05908</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>论文阅读-将面部微表情与脑电图和生理信号结合起来进行情绪识别-《Using Facial Micro-Expressions in Combination With EEG and Physiological Signals for Emotion Recognition》</title>
    <url>/a4775ace.html</url>
    <content><![CDATA[<h3 id="Abstract-摘要"><a href="#Abstract-摘要" class="headerlink" title="Abstract 摘要"></a>Abstract 摘要</h3><p>情绪是多通道的过程扮演着重要的角色在我们的日常生活。识别情绪变得越来越重要在广泛的应用领域，如医疗、教育、人机交互、虚拟现实、智能代理、娱乐等等。</p>
<p>面部宏表情macro-expressions或强烈的面部表情识别情绪状态是最常见的形式。然而，由于面部表情可以主动控制，它们可能不会准确地代表情绪状态。早些时候的研究表明，面部微表情比面部宏表情揭示情绪更可靠。它们是微妙的，无意识的运动响应外界刺激，无法控制。</p>
<p>本文提出了使用面部微表情结合大脑和更可靠的检测潜在的情感生理信号。模型测量唤醒和效价水平从面部表情、脑电图(EEG)信号、皮肤电反应(GSR)和光谱分析(PPG)信号。然后评估模型使用DEAP数据集和基于subject-independent方法自采数据集。最后讨论结果、工作的局限性，如何克服这些限制，还讨论未来的发展方向使用面部表情和情感生理信号识别。</p>
<span id="more"></span>

<hr>
<h3 id="Introduction-介绍"><a href="#Introduction-介绍" class="headerlink" title="Introduction 介绍"></a>Introduction 介绍</h3><p>人类的情绪涉及众多的外部和内部活动，在我们的日常生活中起着至关重要的作用。面部表情、语言和身体姿态是受情绪影响的一些外部活动。</p>
<table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Verma and Tiwary (2014)</td>
<td align="left">大脑活动、心率、血压、呼吸频率、体温和皮肤传导的变化是内部情绪影响的例子*。</td>
</tr>
<tr>
<td align="left">Zheng et al. (2018)</td>
<td align="left">如今，在现代社会中，我们被数字字符、智能设备和计算机所包围。有必要与这些系统进行更好的互动，在许多人与人、人与计算机的互动中，识别情感变得越来越重要*。</td>
</tr>
<tr>
<td align="left">Khalfallah和Slama (2015)</td>
<td align="left">如果我们的远程互动、治疗、咨询或培训课程配备了情绪识别系统，其效果就会得到改善。例如，在远程电子学习中识别情绪*可以提高学习的绩效。</td>
</tr>
<tr>
<td align="left">Piumsomboon et al. (2017)</td>
<td align="left">在移情计算的应用中，目标是测量一起举行远程会议的人的情绪，并利用结果来改善远程通信*。</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Huang et al. (2016)</td>
<td align="left">创建具有情感识别能力的智能代理可能对医疗保健、教育、娱乐、犯罪调查和其他领域有帮助*。</td>
</tr>
<tr>
<td align="left">Marcos-Pablos et al. (2016)</td>
<td align="left">它可以有利于智能助手*测量用户的情感。</td>
</tr>
<tr>
<td align="left">Bartlett et al. (2003)</td>
<td align="left">它可以有利于人形机器人*能够测量用户的情感。</td>
</tr>
<tr>
<td align="left">Zepf et al. (2020)</td>
<td align="left">*讨论emotion-aware系统在汽车上的重要性。</td>
</tr>
<tr>
<td align="left">Hu et al. (2021)</td>
<td align="left">*提出了一个对话代理，它可以根据语音的声学特征来识别情绪。</td>
</tr>
<tr>
<td align="left">Chin et al. (2020)</td>
<td align="left">*对话代理和人之间的移情可以改善攻击性行为。</td>
</tr>
<tr>
<td align="left">Schachner et al. (2020)</td>
<td align="left">讨论了为健康护理开发智能对话代理，特别是针对慢性病。</td>
</tr>
<tr>
<td align="left">Aranha et al. (2019)</td>
<td align="left">*回顾了在健康、教育、安全和艺术等不同领域中能够识别情绪的智能用户界面的软件。根据他们的评论，情绪识别经常被用于根据用户的情绪来调整声音、用户界面、图形和内容。</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Sun et al. (2020)</td>
<td align="left">面部表情是最常用的输入模式之一，被分析用来识别情绪状态*。</td>
</tr>
<tr>
<td align="left">Samadiani et al. (2019)</td>
<td align="left">面部表情被用于许多人机交互应用中*。</td>
</tr>
<tr>
<td align="left">Li and Deng (2020)</td>
<td align="left">虽然研究表明，从面部表情中识别情绪的效果很好*。</td>
</tr>
<tr>
<td align="left">Hossain and Gedeon (2019)</td>
<td align="left">但在日常生活中使用这些方法面临一些挑战，因为它们可以被人类控制或伪造*。</td>
</tr>
<tr>
<td align="left">Weber et al. (2018); Li and Deng (2020)</td>
<td align="left">许多从面部表情中识别情绪的方法都是基于非自发的面部表情或夸张的面部表情的数据集，这并不能正确反映真实的情绪*。</td>
</tr>
<tr>
<td align="left">Zeng et al. (2008)</td>
<td align="left">在现实世界中，人们通常会表现出微妙的不自主的表情*或根据刺激的类型表现出强度较低的表情。</td>
</tr>
</tbody></table>
<p>这些研究表明了开发和改进识别自发情绪的有效方法的重要性。</p>
<hr>
<h4 id="Recognizing-Spontaneous-Emotions-识别自发的情绪"><a href="#Recognizing-Spontaneous-Emotions-识别自发的情绪" class="headerlink" title="Recognizing Spontaneous Emotions 识别自发的情绪"></a>Recognizing Spontaneous Emotions 识别自发的情绪</h4><p>文献中提出了三种主要的方法来识别现实世界中微妙的、自发的情绪：</p>
<ul>
<li>从脸部提取不自主的表情</li>
<li>使用无法伪造的生理信号</li>
<li>使用各种输入模式的组合</li>
</ul>
<hr>
<h5 id="Extracting-Facial-Micro-Expressions-From-Faces-从脸部提取面部微表情"><a href="#Extracting-Facial-Micro-Expressions-From-Faces-从脸部提取面部微表情" class="headerlink" title="Extracting Facial Micro-Expressions From Faces 从脸部提取面部微表情"></a>Extracting Facial Micro-Expressions From Faces 从脸部提取面部微表情</h5><p>在这种方法中，重点是提取面部微表情而不是面部宏观表情。</p>
<table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Ekman and Rosenberg (1997)</td>
<td align="left">面部宏观表情或强烈的面部表情是指面部的自愿性肌肉运动，这些运动是可以区分的，覆盖了面部的大部分区域，其持续时间在0.5到4秒之间*。</td>
</tr>
<tr>
<td align="left">Yan et al. (2013)</td>
<td align="left">相比之下，面部微表情指的是短暂的、非自愿的面部变化，如眉毛内侧的上扬或鼻子的皱褶，这些变化是对外部刺激的自发反应，通常在65至500毫秒的短时间内发生*。</td>
</tr>
<tr>
<td align="left">Takalkar et al. (2018)</td>
<td align="left">面部微表情很难伪造，可以用来检测真实的情绪*。</td>
</tr>
<tr>
<td align="left">Qu et al. (2016)</td>
<td align="left">这些表情持续时间短，动作细微，人类很难识别它们*。</td>
</tr>
</tbody></table>
<p>图1显示了一些与面部宏观表情相比的面部微表情的例子</p>
<img src="/a4775ace/1.png" class>

<hr>
<h5 id="Using-Physiological-Signals-That-Cannot-Be-Faked-使用无法伪造的生理信号"><a href="#Using-Physiological-Signals-That-Cannot-Be-Faked-使用无法伪造的生理信号" class="headerlink" title="Using Physiological Signals That Cannot Be Faked 使用无法伪造的生理信号"></a>Using Physiological Signals That Cannot Be Faked 使用无法伪造的生理信号</h5><p>这种方法依赖于难以伪造的生理反应，并提供对潜在情绪的更好理解。</p>
<table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Kreibig, 2010</td>
<td align="left">这些反应来自中枢（大脑和脊髓）和自主神经系统（调节身体功能，如心率）*。</td>
</tr>
<tr>
<td align="left">Alarcao and Fonseca, 2017</td>
<td align="left">脑电图（EEG）是测量大脑活动的方法之一，通常用于情绪研究*。</td>
</tr>
<tr>
<td align="left">Perez-Rosero et al., 2017; Setyohadi et al., 2018; Shu et al., 2018</td>
<td align="left">皮肤电泳反应（GSR）和心率变异（HRV）也可以用来可靠地测量情绪状态，并被广泛用于情绪识别研究*。</td>
</tr>
<tr>
<td align="left">Wioleta, 2013</td>
<td align="left">虽然EEG和生理信号更可靠，不能被人类控制或伪造*。</td>
</tr>
<tr>
<td align="left">Jiang et al., 2020</td>
<td align="left">这些信号可能非常弱，容易被噪音污染*。</td>
</tr>
</tbody></table>
<p>所以，只用生理信号来识别情绪是相当有挑战性的。</p>
<hr>
<h5 id="Using-a-Combination-of-Various-Input-Modalities-使用各种输入模式的组合"><a href="#Using-a-Combination-of-Various-Input-Modalities-使用各种输入模式的组合" class="headerlink" title="Using a Combination of Various Input Modalities 使用各种输入模式的组合"></a>Using a Combination of Various Input Modalities 使用各种输入模式的组合</h5><p>在这种方法中，各种模式被结合起来以克服每个单独模式的弱点。</p>
<table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Yazdani et al., 2012; Shu et al., 2018</td>
<td align="left">结合不同的生理信号进行情感识别*。</td>
</tr>
<tr>
<td align="left">Busso et al., 2008; McKeown et al., 2011</td>
<td align="left">只融合行为模式的方法已经被广泛探索*。</td>
</tr>
<tr>
<td align="left">Zheng et al., 2018; Huang et al., 2019; Zhu et al., 2020</td>
<td align="left">最近一些研究试图通过利用生理和行为技术来改进情绪识别方法*。</td>
</tr>
<tr>
<td align="left">Koelstra and Patras, 2013; Huang et al., 2017; Zhu et al., 2020</td>
<td align="left">许多研究使用面部表情和EEG信号的组合来实现这种改进*。</td>
</tr>
<tr>
<td align="left">Koelstra et al., 2011; Soleymani et al., 2011</td>
<td align="left">通常，这些研究人员的工作是在受试者观看视频或看静态图像时收集的数据*。然而，人们在这些任务中往往不会表现出很多面部表情。因此，常规的面部表情策略可能无法准确识别情绪。</td>
</tr>
<tr>
<td align="left">Huang et al., 2016</td>
<td align="left">有限的研究使用了面部微表情来代替面部宏观表情*，但这个领域仍然需要更多的研究和探索。</td>
</tr>
</tbody></table>
<p>此外，根据Doma和Pirouz（2020）的研究，真正的情绪何时开始并不清楚。他们假设，在观看视频刺激的前几秒，参与者可能还处于之前的情绪状态。而在最后几秒钟，他们可能更沉浸在视频中，感受到真正的情感。这是因为他们在最后几秒钟更好地理解视频。他们发现，最后几秒钟的脑电图数据信息量更大，显示出更好的情绪预测结果。感受情绪最强烈的峰值时间受到许多因素的影响，如刺激流、参与者的个性或以前的经验。</p>
<hr>
<h4 id="Goals-Overview-and-Contributions-目的、总览与贡献"><a href="#Goals-Overview-and-Contributions-目的、总览与贡献" class="headerlink" title="Goals, Overview, and Contributions 目的、总览与贡献"></a>Goals, Overview, and Contributions 目的、总览与贡献</h4><p><strong>本文假设：</strong>通过识别和分析每个刺激物中最情绪化的部分或出现情绪的时间，可以更好地理解身体对情绪的反应，并创建更强大的模型来识别情绪。</p>
<p><strong>研究目的：</strong>通过将面部微表情策略与脑电图和生理信号相结合来改善情绪识别。</p>
<p><strong>本文方法：</strong>首先对每个面部视频进行扫描，寻找大致表明出现情绪刺激的微表情。微表情窗口被用来大致确定情绪产生的时间。然后，分析每次试验中微表情出现前后的脑电和生理数据，与整个试验的分析进行比较。最后比较了这两种策略，并基于独立于主体的方法评估的方法。文章还使用DEAP数据集作为基准来评估的方法。作者进行了一项用户研究，在观看与DEAP数据集类似的视频任务时收集面部视频、EEG、PPG和GSR数据，但使用不同的传感器。</p>
<p><strong>主要贡献：</strong></p>
<ul>
<li>将面部微表情与脑电图和生理信号相融合以识别情绪。</li>
<li>利用面部微表情来识别情绪刺激或更多信息期的数据，以提高识别精度。</li>
<li>使用低成本和开源的EEG采集设备创建一个新的多模态数据集用于情感识别。</li>
</ul>
<hr>
<h3 id="Conclusions-结论"><a href="#Conclusions-结论" class="headerlink" title="Conclusions 结论"></a>Conclusions 结论</h3><p>本文展示了如何将面部微表情与EEG和生理信号一起有效地用于识别情绪状态。</p>
<p><strong>本文方法：</strong></p>
<ul>
<li>使用了面部微表情的情感识别，而不是结合生理模式的面部宏观表情的情感识别，这在识别真实情感方面更加可靠。</li>
<li>使用了面部微表情识别策略来大致确定数据中最具情感和信息的部分。</li>
<li>使用基于地标的发现策略来检测微表情，确定了每个试验的兴趣区域（ROI）。提取了微表情周围的几个帧，并将其输入到一个三维卷积网络。</li>
<li>从脑电图和生理数据中提取了一连串的特征向量，这些数据被划分为1秒的窗口。</li>
<li>为了从生理信号和EEG信号中提取时间特征，采用了LSTM。评估了用LSTM、SVM、KNN和RF分类器对ROI的分类与对所有数据的分类的比较。</li>
<li>本文的方法是基于独立于主体的方法进行评估的（subject-independent）。</li>
</ul>
<p><strong>本文效果：</strong></p>
<ul>
<li>根据结果与所有数据相比，可以通过使用一小部分数据获得类似甚至更好的准确性。</li>
<li>根据研究结果，面部微表情可以识别出具有足够信息和低噪音的数据中更多的情感部分。</li>
<li>本文使用一个低成本、开源的EEG采集设备来收集多模态的情绪数据。</li>
<li>根据DEAP数据集和自采数据评估了本文的方法。最后结合了多种模式，并发现融合它们的输出可以改善情绪识别。- 本文发现面部微表情比面部宏观表情方法更有效地检测出真实情绪。</li>
</ul>
<p><strong>未来工作：</strong></p>
<ul>
<li>由于OpenBCI硬件的高数据质量和易用性，文章希望在后续的研究中用OpenBCI的各种设置收集更多的数据。收集到的数据将被用于预训练即将到来的模型，以创建一个强大的模型来识别EEG数据中的情绪。</li>
<li>在获得发布数据集的伦理批准后，作者希望公开EEG和生理学数据。这将有助于研究人员训练更强大的情感识别模型。</li>
<li>想在未来研究更多的特征，看看改变特征集或使用更复杂的特征是否会改善LSTM方法的性能。</li>
<li>还想使用更复杂的融合策略来有效利用多模态传感器。</li>
<li>探索如何从更自然的头部运动中提取面部微表情（例如，不要求人们保持严肃）。</li>
<li>此外，在常规面部表情存在的情况下识别面部微表情，并探索如何将两者结合起来用于识别情绪，这将是非常有趣的。</li>
<li>希望可以将这种情绪识别方法纳入到医疗保健的应用中，如远程治疗课程，识别病人的情绪障碍，或创建智能助手来帮助病人或老人。</li>
<li>这种情感模型还可以用于我们与人类的日常互动中，比如加强远程会议，使远程互动更具有沉浸感</li>
<li>改善我们与虚拟代理和其他我们经常使用的互动设备的互动，让它们有能力识别和回应我们的情绪。</li>
</ul>
<hr>
<h3 id="Preliminaries-前言"><a href="#Preliminaries-前言" class="headerlink" title="Preliminaries 前言"></a>Preliminaries 前言</h3><h4 id="Emotion-Models-情绪模型"><a href="#Emotion-Models-情绪模型" class="headerlink" title="Emotion Models 情绪模型"></a>Emotion Models 情绪模型</h4><p>一些研究人员认为，存在一些适用于所有年龄和文化的普遍情绪（Maria等人，2019）。为了避免在情感识别中犯错并设计一个可靠的系统，有必要对情感建模进行更深入的了解。研究人员以两种方式表示情绪：</p>
<ul>
<li>第一种观点是Ekman和Friesen（1971）提出的著名的离散情绪模型，它将情绪分为六种基本类型；快乐、悲伤、惊讶、愤怒、厌恶和恐惧。</li>
<li>第二种观点认为情绪是三个心理维度的组合：唤醒和效价以及支配或强度之一。早期的研究已经证明，唤醒和效价这两个维度足以解释基本的情绪，这些情绪主要是由神经生理因素驱动的（Eerola和Vuoskoski，2011）。</li>
</ul>
<p>文献中最常用的维度模型是Russel的Circumplex模型（Posner等人，2005），它只用效价和唤醒来代表情绪，其中价值代表从消极到积极的情绪范围。相比之下，唤醒代表一种从被动到主动的情绪。</p>
<p>根据罗素的圆环模型，将情绪状态归类为不连续的情绪是不正确的，因为人类的情绪状态总是几种情绪的混合物。因此，当人们报告恐惧是他们的情绪时，可能是兴奋、快乐和恐惧的混合，或者是负面情绪和恐惧的混合。所以，在积极和消极的恐惧情况下，大脑和生理信号的模式是不一样的，把它们归为一类会导致错误的识别。</p>
<table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Maria et al. (2019)</td>
<td align="left">基于经验、文化、年龄和许多其他因素，对情绪的感知也有很大的不同，这使得评估变得困难*。</td>
</tr>
<tr>
<td align="left">Lichtenstein et al. (2008)</td>
<td align="left">*的研究表明，维度方法对自我评估更准确。</td>
</tr>
<tr>
<td align="left">Eerola and Vuoskoski (2011)</td>
<td align="left">在对复杂的情绪刺激进行评分时，离散情绪模型不如维度模型可靠*。他们还观察到离散模型和维度模型之间有很高的对应关系。</td>
</tr>
</tbody></table>
<p><strong>本文情绪模型：</strong><br>面部宏表情和面部微表情通常用离散情绪来表达，以前的研究使用离散情绪模型来评估他们的策略。然而，大多数关于神经生理学情绪识别的研究和本文使用的基准数据集，都使用了环状模式（唤醒和效价）来评估他们的方法。由于本文研究的重点是揭示潜在的情绪，并且除了面部微表情外还使用了三种神经生理线索，因此使用二维环状模型来评估本文在基准数据集和自采数据集上的方法。</p>
<hr>
<h4 id="Emotion-Stimulation-Methods-情绪刺激方法"><a href="#Emotion-Stimulation-Methods-情绪刺激方法" class="headerlink" title="Emotion Stimulation Methods 情绪刺激方法"></a>Emotion Stimulation Methods 情绪刺激方法</h4><p>情绪有不同的诱导情绪的方法。然而，所有情绪诱导方法的效果是不一样的。Siedlecka和Denson（2019）将情绪刺激分为五种策略：</p>
<ol>
<li>观看图像和视频等视觉刺激；</li>
<li>听音乐；</li>
<li>回忆个人情绪记忆；</li>
<li>完成心理程序；</li>
<li>想象情绪场景。</li>
</ol>
<p>他们展示了不同类型的刺激如何对各种生理变量产生不同的影响。根据他们的研究，视觉刺激是文献中使用较多的最有效的诱导方法。另外：</p>
<ul>
<li>Roberts等人（2007）发现，双人互动可以被认为是一种情感诱导方法。</li>
<li>Quigley等人（2014）增加了言语、身体运动、生理操纵器如咖啡因和虚拟现实（VR）。</li>
</ul>
<hr>
<h4 id="Facial-Micro-Expressions-面部微表情"><a href="#Facial-Micro-Expressions-面部微表情" class="headerlink" title="Facial Micro Expressions 面部微表情"></a>Facial Micro Expressions 面部微表情</h4><table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Ekman, 2003</td>
<td align="left">面部微表情是对情绪刺激的简短面部动作，它揭示了隐藏的情绪*。</td>
</tr>
<tr>
<td align="left">Yan et al., 2013</td>
<td align="left">微表情已被用于测谎、安全系统以及临床和心理领域，以揭示潜在的情绪*。</td>
</tr>
<tr>
<td align="left">Liong et al., 2015</td>
<td align="left">与宏观表情相比，较少的动作和较短的持续时间是面部微表情的主要特征*。</td>
</tr>
<tr>
<td align="left">Yan et al., 2013</td>
<td align="left">*研究了微表情的持续时间，结果显示其持续时间在65至500毫秒之间。</td>
</tr>
<tr>
<td align="left">Li et al., 2013; Yan et al., 2014</td>
<td align="left">由于视频情节是动态的、持续时间长的情感刺激，它们被用于微表情研究，并创造了大多数微表情数据集*。</td>
</tr>
<tr>
<td align="left">Li et al., 2013; Yan et al., 2013, 2014</td>
<td align="left">为了防止微表情记录中的面部宏观表情污染，在许多研究中，参与者被要求在观看视频时抑制任何面部动作并保持扑克脸*。</td>
</tr>
<tr>
<td align="left">Yan et al., 2013</td>
<td align="left">然而，在应对情绪化的视频刺激时，抑制是很难实现的。</td>
</tr>
</tbody></table>
<p>一个微表情有三个阶段；开始阶段、顶点阶段和抵消阶段。在对情绪刺激的反应中，快速的肌肉运动发生在开始阶段，这是非自愿的，显示出真正的情绪泄漏。有时这些反应会持续片刻，作为顶点阶段。最后，情绪反应在偏移期消失，面部恢复到放松状态。</p>
<table>
<thead>
<tr>
<th align="left">Author</th>
<th align="left">Effects</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Yan et al., 2013</td>
<td align="left">由于皮肤的自然紧张，恢复到放松状态对某些人来说可能需要更长的时间，或者因为与随后的情绪刺激合并而没有发生*。</td>
</tr>
<tr>
<td align="left">Goh et al., 2020</td>
<td align="left">在录制的视频中，开始阶段的第一帧表示开始帧，而表情最丰富的那一帧是顶点帧。偏移帧是表情消失的时候*。</td>
</tr>
</tbody></table>
<p>利用面部微表情识别情绪有两个主要步骤：</p>
<ul>
<li>第一步是在视频序列中发现或定位有微表情的帧或帧。</li>
<li>第二步是识别微表情的情绪状态（Oh等人，2018；Tran等人，2020）。</li>
</ul>
<p>一些工作使用<strong>手工特征</strong>的策略，如：</p>
<ul>
<li>三正交平面的局部二进制模式（LBP-TOP）（Pfister等人，2011）</li>
<li>定向梯度直方图（HOG）（Davison等人，2015）从帧中提取特征，以发现和识别情绪。</li>
<li>(Guermazi等人，2021）提出了一种基于LBP的微表情识别方法，以创建面部视频的低维高相关表示，并使用随机森林分类器对微表情进行分类。</li>
</ul>
<p><strong>深度学习</strong>提取深度特征：</p>
<ul>
<li>深度学习技术被用来提取深度特征，并利用面部微表情进行情绪分类（Van Quang等人，2019；Tran等人，2020）。</li>
<li>Hashmi等人（2021）提出了一个无损注意力残差网络（LARNet），用于编码特定关键位置的面部空间和时间特征，并对面部微表情进行分类。虽然他们在实时识别情绪方面取得了可喜的成绩，但他们的模型只有在帧率超过200帧时才有效。</li>
<li>Xia等人（2019）提出了一个递归卷积神经网络（RCN）来提取面部微表情的时空变形。他们使用基于外观和基于几何的方法将面部序列转化为矩阵并提取面部运动的几何特征。他们对他们的策略进行了评估，基于留下一个视频（LOVO）和留下一个主体（LOSO）的方法，并取得了令人满意的结果。</li>
<li>Xia等人（2020）提出了一个RCN网络来识别多个数据集的微表情。他们还讨论了输入和模型复杂性对深度学习模型性能的影响。他们表明，在组合数据集上运行模型时，低分辨率的输入数据和较浅的模型是有益的。</li>
</ul>
<p><strong>数据集</strong>方面：</p>
<ul>
<li>Ben等人（2021）回顾了现有的面部微表情数据集，并讨论了用于识别面部微表情的不同特征提取方法。在这项研究中，他们引入了一个新的微表情数据集，并讨论了微表情研究的未来方向。</li>
<li>Pan等人（2021）总结和比较了现有的发现和微表情策略，并讨论了该领域的局限性和挑战。</li>
<li>检测面部微表情已受到越来越多的关注。许多数据集已经被创建，发现和识别方法也有了很大发展。然而，识别面部微表情仍然面临许多挑战（Weber等人，2018；Zhao和Li，2019；Tran等人，2020）。</li>
<li>Oh等人（2018）讨论了数据集、发现和识别领域的各种挑战。他们表明，处理面部宏观运动，开发更强大的发现策略，以及忽略不相关的面部信息，如头部运动和跨数据集的评估，仍然需要更多的关注和研究。</li>
</ul>
<hr>
<h4 id="Electroencephalography-EEG-Signals-脑电图信号"><a href="#Electroencephalography-EEG-Signals-脑电图信号" class="headerlink" title="Electroencephalography (EEG) Signals 脑电图信号"></a>Electroencephalography (EEG) Signals 脑电图信号</h4><p>最近，许多神经心理学研究调查了情绪和大脑信号之间的相关性。脑电图（EEG）是神经成像技术之一，通过安装在头皮上的电极读取大脑电活动。</p>
<ul>
<li>脑电图设备根据电极的类型和数量、电极的位置（灵活或固定位置）、连接类型（无线或有线）、放大器和过滤步骤的类型、设置和可佩戴性而有所不同（Teplan等，2002）。</li>
<li>像g.tec1或Biosemi2或EGI3这样具有较高数据质量的脑电图设备通常是昂贵和笨重的，需要耗时的设置。另外，还有一些数据质量较低的EEG设备，如Emotiv Epoc4或MindWave5。这些脑电图设备价格低廉，是无线设备，需要的设置时间较短（Alarcao和Fonseca，2017）。</li>
<li>OpenBCI6提供了一个轻量级和开源（硬件和软件）的脑电图耳机，它的定位在这两个产品类别之间。它可以捕获高质量的数据，同时成本低，易于设置。如今，由于EEG设备的可穿戴性提高和价格降低，利用EEG信号识别情绪已经吸引了许多研究人员（Alarcao和Fonseca，2017）。</li>
</ul>
<p><strong>基于EEG的情绪识别</strong>是一个令人兴奋和快速增长的研究领域。</p>
<ul>
<li>由于EEG信号的振幅较弱，使用EEG识别情绪具有挑战性（Islam等人，2021）。</li>
<li>一些研究专注于提取手工制作的特征，并使用浅层机器学习方法对健康护理等不同应用领域的情绪进行分类（Aydın等人，2018；Bazgir等人，2018；Pandey和Seeja，2019a；Huang等人，2021）。</li>
</ul>
<p>一些综述研究讨论了各种<strong>手工特征</strong>的效果，如脑波段功率，以及使用各种分类器，如支持向量机（SVM）或随机森林（RF）来识别情绪。</p>
<ul>
<li>Alarcao和Fonseca（2017）回顾了EEG情绪识别研究。他们讨论了文献中用于情绪识别的最常见的数据清理和特征提取。根据他们的回顾，大脑波段功率，包括α、β、θ、γ和δ波段，是情绪识别的有效特征。</li>
<li>Wagh和Vasanth（2019）对基于脑机接口和机器学习算法的人类情绪分析中涉及的各种技术进行了详细调查。</li>
</ul>
<p><strong>深度学习</strong>方法：</p>
<ul>
<li>许多研究人员使用原始EEG信号并应用深度学习方法来提取深度特征并识别情绪（Keelawat等人，2019；Aydın，2020）。</li>
<li>Sharma等人（2020）使用基于LSTM的深度学习方法，根据EEG信号对情绪状态进行分类。</li>
<li>Topic和Russo（2021）使用深度学习来提取EEG信号的地形和全息表征，并对情绪状态进行分类。</li>
<li>Islam等人（2021）对基于EEG的情绪识别方法进行了全面的回顾。他们讨论了各种特征提取方法以及用于识别情绪的浅层和深层学习方法。</li>
</ul>
<p>近年来，研究人员专注于<strong>更先进的网络架构</strong>以提高性能。</p>
<ul>
<li>Li等人（2021）提出了一个基于强化学习（RL）的神经架构搜索（NAS）框架。他们用RL训练了一个循环神经网络（RNN）控制器，以使验证集上生成的模型性能最大化。在DEAP数据集上，他们用一种依赖主体的方法，对唤醒和情感取得了约98%的高平均准确性。</li>
<li>在另一项研究中（Li等人，2022），他们提出了一个多任务学习机制，同时进行唤醒、价值和支配力的学习步骤。他们还使用了一个胶囊网络来寻找通道之间的关系。最后，他们使用注意力机制来寻找通道的最佳权重，以便从数据中提取最重要的信息。他们在依赖主体的方法中，对唤醒和价值的平均准确率达到了97.25％，97.41％。</li>
<li>同样，Deng等人（2021）使用注意力机制为通道分配权重，然后用胶囊网络和LSTM来提取空间和时间特征。他们对唤醒和情绪水平的平均准确率达到了97.17%，97.34%。</li>
</ul>
<hr>
<h4 id="Galvanic-Skin-Responses-GSR-Signals-皮肤电反应信号"><a href="#Galvanic-Skin-Responses-GSR-Signals-皮肤电反应信号" class="headerlink" title="Galvanic Skin Responses (GSR) Signals 皮肤电反应信号"></a>Galvanic Skin Responses (GSR) Signals 皮肤电反应信号</h4><p>研究表明，神经系统和人类皮肤上的汗腺之间存在联系。因为情绪亢奋而导致的汗液分泌水平的变化导致了皮肤电阻的变化（Tarnowski等人，2018；Kołodziej等人，2019），这被称为皮肤电活动（EDA）或皮肤电反应（GSR）。</p>
<p>当皮肤接收到大脑由情绪唤醒引起的兴奋信号时，人体的出汗就会发生变化，GSR信号也会上升。</p>
<ul>
<li>Kreibig（2010）表明，虽然EDA信号显示了情绪唤醒的变化，但还需要更多的研究来利用EDA信号识别情绪的类型。</li>
<li>Tarnowski等人（2018）使用GSR局部最小值作为EEG的情绪纪元的指标。他们表明，GSR是情绪唤醒的一个很好的指标。</li>
<li>在许多研究中，GSR信号的统计特征被用作情绪分类的特征（Udovicic等人，2017；Yang等人，2018）。</li>
<li>Kołodziej等人（2019）计算了一些峰值（局部最大值）和原始GSR信号的统计数据，作为信号的特征。他们使用了不同的分类器，并表明SVM在使用这些统计特征识别情绪唤醒方面比其他分类器效果更好。</li>
</ul>
<p>一些研究使用了<strong>时间序列或平均信号</strong>作为特征向量。</p>
<ul>
<li>Setyohadi等人（2018）收集了每一秒的平均信号并应用了特征缩放。他们用这个数据对积极、中性和消极的情绪状态进行分类。他们使用了不同的分类器，带有Radial Based Kernel的SVM显示出最好的准确性。</li>
<li>Kanjo等人（2019）使用GSR时间序列和深度学习分析来了解在城市中间行走时的情绪水平。</li>
<li>Ganapathy等人（2021）表明，多尺度卷积神经网络（MSCNN）在提取GSR信号的深层特征和分类情绪方面是有效的。</li>
</ul>
<p>在许多研究中，GSR信号已被独立用于识别情绪。但是，它们主要被用作补充信号或与其他生理信号相结合来识别情绪（Das等人，2016；Udovicic等人，2017；Wei等人，2018；Yang等人，2018；Maia和Furtado，2019）。</p>
<hr>
<h4 id="Photoplethysmography-PPG-Signals-光谱分析信号"><a href="#Photoplethysmography-PPG-Signals-光谱分析信号" class="headerlink" title="Photoplethysmography (PPG) Signals 光谱分析信号"></a>Photoplethysmography (PPG) Signals 光谱分析信号</h4><ul>
<li>光密度计（PPG）是一种利用红外线测量血容量脉冲（BVP）的新方法（Elgendi，2012）。</li>
<li>事实证明，PPG可以测量心率变异性（HRV）。HRV是对心率的时间变化的测量，以揭示医疗或精神状态（Maria等人，2019）。</li>
</ul>
<p>由于像智能手表这样可以传输PPG信号的可穿戴设备的出现，利用PPG信号的研究受到更多关注。</p>
<ul>
<li>Kreibig（2010）已经显示了不同情绪状态下心率变异和心率的变化。</li>
<li>最近，有限的研究使用深度学习策略来提取PPG信号的深度特征。Lee等人（2019）使用一维卷积神经网络（1D CNN）来提取PPG信号的深层特征并对情绪状态进行分类。与GSR信号类似，PPG数据通常与其他生理信号一起使用来识别情绪状态。</li>
</ul>
<hr>
<h3 id="Related-Works-相关工作"><a href="#Related-Works-相关工作" class="headerlink" title="Related Works 相关工作"></a>Related Works 相关工作</h3><h4 id="Multimodal-Datasets-for-Emotion-Recognition-情绪识别多模态数据集"><a href="#Multimodal-Datasets-for-Emotion-Recognition-情绪识别多模态数据集" class="headerlink" title="Multimodal Datasets for Emotion Recognition 情绪识别多模态数据集"></a>Multimodal Datasets for Emotion Recognition 情绪识别多模态数据集</h4><p>多模态情感识别已经吸引了许多研究者的注意。数量有限的包含面部视频、EEG和生理信号的多模态数据集可供下载，用于情绪识别。</p>
<ul>
<li>DEAP数据集（Koelstra等人，2011）</li>
<li>MAHNOB-HCI数据集（Soleymani等人，2011）</li>
</ul>
<p>由于EEG信号对肌肉伪影很敏感（Jiang等人，2019年），这类数据集使用了看视频或听音乐等被动任务，以尽量减少主体运动。</p>
<hr>
<h5 id="DEAP-Dataset-DEAP数据集"><a href="#DEAP-Dataset-DEAP数据集" class="headerlink" title="DEAP Dataset DEAP数据集"></a>DEAP Dataset DEAP数据集</h5><p>DEAP数据集包含32名参与者的EEG数据、面部视频、GSR、血容量压力（BVP）、温度和呼吸数据。它使用了40个音乐视频来刺激情绪，而EEG数据是使用Biosemi ActiveTwo EEG headset7收集的，它有32个通道。参与者使用自我评估人体模型（SAM）调查表（Bradley和Lang，1994）报告他们的唤醒、价值、支配和喜欢程度。然而，在这个数据集中，只有22名参与者有视频数据，其中4人的一些试验被遗漏。面部视频的照度很低，面部的一些传感器覆盖了部分面部表情。</p>
<hr>
<h5 id="MAHNOB-HCI-Dataset-MAHNOB-HCI数据集"><a href="#MAHNOB-HCI-Dataset-MAHNOB-HCI数据集" class="headerlink" title="MAHNOB-HCI Dataset MAHNOB-HCI数据集"></a>MAHNOB-HCI Dataset MAHNOB-HCI数据集</h5><p>在MAHNOB-HCI数据集中，眼球运动、声音、EEG数据和呼吸模式已被收集，用于图像和视频内容的标记。在观看视频片段后，参与者使用价值-唤醒模型报告他们的情绪状态。招募了30名参与者来创建这个数据集。使用了具有32个通道的Biosemi active II headset8来收集脑电图数据。</p>
<hr>
<h4 id="Exploring-the-Relationship-Between-Modalities-探讨各种模式之间的关系"><a href="#Exploring-the-Relationship-Between-Modalities-探讨各种模式之间的关系" class="headerlink" title="Exploring the Relationship Between Modalities 探讨各种模式之间的关系"></a>Exploring the Relationship Between Modalities 探讨各种模式之间的关系</h4><p>一些研究专注于多模态情感识别中行为反应和生理变化之间的关系：</p>
<ul>
<li>Benlamine等人（2016）和Raheel等人（2019）使用EEG信号来识别面部微表情。</li>
<li>Hassouneh等人（2020年）使用单模态策略，使用脑电图和面部数据识别身体残疾者或自闭症患者的情绪。虽然他们没有使用多模态策略，但他们表明，使用每个面部表情或EEG信号可以成功识别情绪。在他们的实验数据集中，EEG的准确率达到87.3%，面部微表情的准确率达到99.8%。</li>
<li>Sun等人（2020年）研究了自发面部表情与脑电图和近红外光谱（fNIRS）测量的大脑活动之间在情绪价值上的强烈关联。</li>
<li>Soleymani等人（2015）认为，虽然EEG信号对基于面部表情的情绪识别有一些补充信息，但它们不能提高面部表情系统的准确性。然而，后来的研究表明，通过结合脑电图和面部表情，可以改善。</li>
</ul>
<hr>
<h4 id="Fusing-Behavioral-and-Physiological-Modalities-融合行为和生理模式"><a href="#Fusing-Behavioral-and-Physiological-Modalities-融合行为和生理模式" class="headerlink" title="Fusing Behavioral and Physiological Modalities 融合行为和生理模式"></a>Fusing Behavioral and Physiological Modalities 融合行为和生理模式</h4><p>在许多研究中，研究人员表明情绪刺激对生理变化的影响，如心率、体温、皮肤传导、呼吸模式等。然而，他们无法确定哪些情绪被激发了。一些研究表明，将生理情绪识别和行为模式结合起来可以提高识别结果。将面部表情与生理模式相结合吸引了该领域一些研究人员的关注。这些研究大多集中在传统的面部表情方法上，并使用所有录制的视频帧来识别情绪。</p>
<ul>
<li>Koelstra和Patras（2013）使用EEG和面部表情的组合来生成视频的情感标签。他们提取了14个左右对的功率谱密度和横向化，并提取了230个EEG数据的特征。他们试图逐帧识别动作单元的激活，最后为每段视频提取了三个特征。他们使用了特征级和决策级的融合策略。根据他们的结果，与单一模式相比，融合策略提高了标签的性能。通过融合EEG和人脸数据，唤醒的准确性从EEG的64.7%和人脸的63.8%提高到70.9%。通过融合情绪值，这一改进从EEG的70.9%和脸部的62.8%提高到73%。</li>
<li>Huang等人（2017）研究了融合面部宏观表情和EEG信号在决策层面上的情绪识别。他们使用一个前馈网络对每一帧视频中提取的面部的基本情绪进行分类。他们在这项研究中使用了他们的实验数据，在融合EEG和面部表情时，在依赖主体的策略中取得了82.8%的准确性。</li>
<li>后来，他们通过使用CNN模型改进面部表情识别来扩展他们的工作（Huang等人，2019）。他们使用FER2013数据集（Goodfellow等人，2013）预训练了一个模型，并使用小波提取功率带和SVM对EEG数据进行分类。他们在DEAP数据集上使用多模态方法中的主体依赖策略，对情绪和唤醒的准确率分别达到80%和74%。</li>
<li>在一项类似的研究中，Zhu等人（2020年）使用加权决策水平融合策略，结合脑电图、外周生理信号和面部表情来识别唤醒-情绪状态。他们使用三维卷积神经网络（CNN）来提取面部特征并进行分类，他们还使用一维CNN来提取EEG特征并进行分类。当将面部表情与EEG和生理信号相结合时，他们取得了更高的准确性。</li>
<li>Chaparro等人（2018年）还提出了一种特征级融合策略，用于结合EEG和面部特征（使用70个地标坐标）来提高识别结果。</li>
</ul>
<p>在大多数多模态情感数据集的记录视频中，在许多帧中无法观察到任何表情。这些数据集使用被动的任务，如观看视频来刺激情绪，所以情绪化的面孔只能在一小部分的帧中看到。因此，在数据分析中考虑所有的帧，或者在不考虑这个问题的情况下使用帧之间的多数票，都不能产生一个好的情感识别结果。然而，在应对这些被动任务时，可以观察到许多微表情。</p>
<ul>
<li>只有Huang等人（2016）考虑了中性脸和微妙表情的存在。他们基于局部二进制模式（LBP）策略提取了所有帧的空间-时间特征。然后，他们使用这些特征训练了一个线性核SVM来计算表情百分比特征，并使用这个特征向量进行情绪分类。他们提取了所有的频率和频段，然后使用ANOVA测试来选择这些特征的子集用于EEG。对于面部分类，他们使用K-Nearest-Neighbor（KNN）分类器进行EEG和支持向量机（SVM）。他们表明，决策层的融合策略比单一模式或特征的融合效果更好。他们对情绪和唤醒的准确率分别达到了62.1%和61.8%。</li>
</ul>
<img src="/a4775ace/2.png" class>

<p>表1总结了最新的相关工作。可以看出，数量有限的研究将面部表情与EEG数据结合起来。当训练和测试集中有一些所有参与者的试验时，大多数以前的工作都会评估他们的方法是依赖主体或跨主体的。尽管设计识别未见过的参与者的情绪的一般模型在日常生活中是非常有用的，但只有少数研究使用了独立于主体的方法来设计和评估他们的方法。与依赖主体和跨主体的评价相比，独立于主体的方法的准确性较低，需要更多的研究和探索。另外，尽管一些研究集中于将面部表情与生理信号相结合，但大多数都是基于强烈的面部表情来设计和训练的。而在大多数使用的多模态数据集中，人们不允许表现出激烈的表情。</p>
<p>这项研究通过研究使用面部微表情策略与EEG和生理信号相结合进行多模态情感识别的最佳方式来解决这一问题，还探讨了如何利用面部微表情来识别面部视频、EEG和生理数据中最具情感的部分。此外，创建了一个新的面部视频、生理信号和EEG信号的数据集，这有助于开发情感识别的稳健模型。还探索了从OpenBCI EEG headset收集的数据的性能和质量，这是一个用于识别情绪的低成本EEG headset。此外，提出了使用多模态数据进行情感识别的策略，并最终对其进行了评估。</p>
<p>总的来说，这项研究的<strong>主要创新之处</strong>在于<strong>将面部微表情识别与EEG和生理信号相融合</strong>。这项工作的另一个重要贡献是<strong>利用面部微表情来识别中性状态和情绪状态，以提高使用EEG和生理信号的情绪识别</strong>。</p>
<hr>
<h3 id="Experimental-Setup-实验设置"><a href="#Experimental-Setup-实验设置" class="headerlink" title="Experimental Setup 实验设置"></a>Experimental Setup 实验设置</h3><p>创建了一个新的多模态数据集，用于使用轻型可穿戴设备和网络摄像头进行情感识别。从大学生和工作人员中招募了23名志愿者（12名女性和11名男性），年龄在21至44岁之间（μ=30，σ=6）。只针对六种基本情绪中的四种，包括快乐、悲伤、愤怒和恐惧，外加一个中性状态。在观看视频的任务中收集了面部视频、EEG、PPG和GSR信号。使用唤醒-价值模型来测量情绪，自我报告数据也被用作基础真实值。</p>
<p>（其它详见原文）</p>
<hr>
<h3 id="Methodology-方法"><a href="#Methodology-方法" class="headerlink" title="Methodology 方法"></a>Methodology 方法</h3><h4 id="Ground-Truth-Labeling-正确标签"><a href="#Ground-Truth-Labeling-正确标签" class="headerlink" title="Ground Truth Labeling 正确标签"></a>Ground Truth Labeling 正确标签</h4><p>使用来自SAM调查问卷的自我报告数据进行基础真实标记。只使用DEAP和自采数据集的报告的唤醒和价值。为了对唤醒和情感水平进行分类，尽管在SAM问卷中有九个级别的唤醒和情感，但与以前的研究类似，使用二进制分类。认为五个是创建二进制标签的阈值，对应于高和低的唤醒和价值。</p>
<img src="/a4775ace/3.png" class>

<p>表3显示了当评分值在1到9之间时，自我报告的唤醒评分和数值的平均值。该表还显示了每个视频片段中报告每种情绪的参与者的百分比。例如，78.9%的参与者对《追求幸福》视频片段报告了幸福，而对这个视频片段只有4.3%报告了恐惧，7.8%报告了中性，8.7%报告了悲伤。可以看出，大多数参与者对所有刺激物都报告了目标情绪。尽管在自我报告问卷中包括了所有的基本情绪，但除了目标情绪列表中的情绪，没有一个参与者报告其他的情绪。因此，没有在本表和评价结果中包括其他情绪。</p>
<hr>
<h4 id="Imbalanced-Data-不平衡的数据"><a href="#Imbalanced-Data-不平衡的数据" class="headerlink" title="Imbalanced Data 不平衡的数据"></a>Imbalanced Data 不平衡的数据</h4><p>在DEAP数据集中，所有参与者的低级和高级试验的总数量为339和381，而唤醒的数量为279和444。在数据集中，这些值对于价值类来说是100和130，对于唤醒类来说是94和136，分别是低级和高级。可以看出，这两个数据集在类别之间是不平衡的。另外，使用了一个离开一些对象的策略来分割训练和测试数据。因此，每一组的训练和测试集之间的不平衡状态取决于参与者的评分。使用成本敏感学习（Ling and Sheng, 2008）来处理不平衡的数据。成本敏感型学习在模型训练过程中使用了预测错误的成本。它采用了一种惩罚性的学习算法，提高了少数类的分类错误的成本。使用Scikit-learn库来测量类权重，并在训练模型时使用估计的权重。还使用成本敏感的SVM和RF来处理不平衡的数据。</p>
<hr>
<h4 id="Video-Emotion-Recognition-视频情绪识别"><a href="#Video-Emotion-Recognition-视频情绪识别" class="headerlink" title="Video Emotion Recognition 视频情绪识别"></a>Video Emotion Recognition 视频情绪识别</h4><p>在DEAP数据集和自采数据集中，由于EEG信号对肌肉伪影的敏感性，要求参与者在观看视频时保持扑克脸。这个条件与微表情数据集完全相同。在微表情数据集中，参与者被要求在观看视频时抑制他们的表情并保持一张扑克脸，以防止宏观表情污染（Goh等人，2020）。这个条件导致几乎所有的帧都是中性脸，只有真正的情绪会作为微表情泄露出来。</p>
<p>图4显示了来自DEAP数据集、自采数据集、SMIC数据集（Li等人，2013）和FER2013数据集（Goodfellow等人，2013）的一些试验帧。SMIC数据集是专门为面部微表情的情感识别研究而收集的。正如在所有这些数据集中所看到的，情绪几乎不能被注意到，大多看到的是一张中立的脸。相比之下，在FER2013（Goodfellow等人，2013）和CK+（Lucey等人，2010）等面部宏观表情数据集中，有几组表情强烈的脸（图4）。</p>
<img src="/a4775ace/4.png" class>

<p>使用FER2013数据集训练了一个深度卷积神经网络，在所有试验的框架上进行了测试，主要从面部表情识别中得到了中性情绪。该模型有五个卷积层和池化层块，其结构类似于VGG-16（Simonyan和Zisserman，2014），每个块中有一些额外的层。图5显示了模型的结构。FER2013是一个由谷歌图像搜索API自动收集的大规模数据集，已被广泛用于面部情绪识别研究。它包含28,709张训练图像、3,589张验证图像和3,589张测试图像，有七个表情标签：愤怒、厌恶、恐惧、快乐、悲伤、惊讶和中性。对数据进行了预处理，将图像转换为灰度图像，使用Dlib库中的人脸检测模块提取人脸区域，对其进行标准化和大小调整，最后，将其送入深度卷积网络。将未检测到的人脸从训练和测试集中移除，在FER2013测试集数据上达到了85%的准确率。使用训练好的模型从DEAP数据集和自采数据集的每一帧记录的视频中检测情绪。使用训练好的模型，应用同样的预处理步骤，预测每一帧的情绪。</p>
<img src="/a4775ace/5.png" class>

<p>表4显示了DEAP和自采数据集的预测结果。可以看出，基于对所有框架情绪的多数投票策略，在DEAP的试验中100%检测到的情绪是中性的，在实验的试验中89.1%是中性的。对于有限的参与者，在所有的试验中，中性脸被错误地预测为悲伤的情绪。</p>
<img src="/a4775ace/6.png" class>

<p>这一结果表明，中性脸或有细微或微表情的脸不容易用面部宏观表情方法识别。由于DEAP和自采数据集中录制视频的条件与微表情数据集相同，使用微表情方法来检测这两个数据集中的面部视频表情，并研究其性能。因此，将DEAP和自采数据集中的面部数据视为具有微表情的面部数据，并使用面部微表情策略进行视频-情绪识别。</p>
<p>使用了一个两步的面部微表情识别策略。首先，使用了一个自动发现策略，根据与试验的第一和最后一帧相比，最大的面部组件的运动，自动找到顶点帧。然后，提取了顶点帧周围的一组帧，并考虑这些帧而不是整个视频进行分类。最后，将提取的序列输入一个三维卷积神经网络。</p>
<p>为了准备发现微表情的框架，首先，在WIDER FACE数据集（Yang等人，2016）上采用了预训练的YOLO v3网络（Redmon和Farhadi，2018）进行人脸检测。选择WIDER FACE数据集是因为它包含了不同程度的比例、遮挡和姿势的图像，增强了模型学习的特征空间，在任何条件下都有更好的实时性能。然后，按照Van Quang等人（2019）介绍的定点方法来识别每个视频中的顶点帧（有微表情的帧）。在这个定点方法中，首先提取了面部组件周围的十个区域，这些区域的肌肉运动发生得非常频繁。下一步，将视频序列的第一帧视为起始帧，最后一帧视为偏移帧，并计算出这十个区域中每一帧与起始帧和偏移帧之间的绝对像素差异。最后，计算了每一帧的每个像素的平均值。认为具有较高强度差异的帧为顶点帧。认为顶点帧周围的窗口是感兴趣的区域（ROI），在分类步骤中只使用这些帧（图6A）。</p>
<img src="/a4775ace/7.png" class>

<p>虽然自采数据集和DEAP数据集的录制视频较长，而且可能包含比面部微表情数据集更多的中性帧，但面部微表情的发现方法仍然可以找到顶点帧。因此，仍然有起始、顶点和偏移帧。在实际起始帧之前和偏移帧之后可能有几个中性帧，但所有这些帧都是一样的，不会影响发现算法的结果。这是因为实际起始帧和第一帧或实际偏移帧和最后一帧几乎相同。因此，顶点帧和实际起始或偏移帧之间测量的绝对像素差异将与顶点帧和第一或最后一帧之间的绝对像素差异实际上是一样的。虽然视频中可能有更多的面部表情和顶点帧，但实际的偏移帧，和最后一帧几乎是相同的，因为这两个帧都描述了面部的中性状态。</p>
<p>考虑了ROI的不同窗口大小，并在结果部分进行了讨论。图4说明了DEAP和自采数据集的顶点框架周围提取的六帧序列，此外还有SMIC数据集的一个序列。使用三维卷积神经网络（3D CNN）来对微表情序列进行分类。它是微表情情感识别领域最先进的模型之一（Reddy等人，2019），在两个流行的微表情数据集CASME II（Yan等人，2014）和SMIC（Li等人，2013）上取得了良好的表现。该方法在CASME II数据集上取得了87.8%的准确性，在SMIC数据集上取得了68.75%的准确性。用这个模型来提取深度特征并对DEAP和自采数据集中的微表情进行分类。由于这两个数据集的基础事实标签都是基于唤醒和情感水平的，所以没有根据基本的情绪对微表情进行分类，而是根据唤醒和情感水平对微表情进行分类。为了对基于唤醒或价值的情绪状态进行分类，对数据应用了两次模型，一次是对唤醒水平进行分类，一次是对价值水平进行分类。在这个模型中，没有用6作为最后一个密集层的输出形状，而是用2来对基于低和高的唤醒或价值的微表情进行分类。</p>
<p>首先，使用YOLO人脸检测算法来检测ROI中每一帧的人脸，然后将其转换为灰度图像，归一化，并调整其大小。最后，将预处理过的序列送入Reddy等人（2019）介绍的两个三维CNN模型，用于分别对唤醒和价值进行分类。图6B说明了三维CNN模型的结构。</p>
<hr>
<h4 id="EEG-and-Physiological-Emotion-Recognition-脑电图生理情感的识别"><a href="#EEG-and-Physiological-Emotion-Recognition-脑电图生理情感的识别" class="headerlink" title="EEG and Physiological Emotion Recognition 脑电图生理情感的识别"></a>EEG and Physiological Emotion Recognition 脑电图生理情感的识别</h4><p>微表情是识别每个试验中最有情绪的时间的一个指标。然后使用一个基于ROI的策略，使用EEG和生理数据来识别唤醒和价值。顶点框架的时间是每次试验中最有情绪的时间。然后，在脑电图和生理学数据中找到这个时间段的相应样本。由于脑电图、生理数据和视频帧之间的采样率不同，将此时每个信号的采样率相乘来确定ROI。最后，在其周围提取了几秒钟的数据，将提取的部分视为ROI，并只对提取的数据进行分析。考虑了不同的窗口大小来提取ROI，并在结果部分进行了讨论。</p>
<p>为了分析EEG和生理数据，遵循情绪识别的主要步骤：预处理、特征提取和分类。首先，清理了数据，然后提取了ROI部分，并且只使用ROI数据作为特征提取步骤的输入。为了对数据进行分类，使用了两种方法对EEG和生理学数据进行分类。在第一种方法中，从整个数据或ROI部分提取了一些特征————在下面的章节中描述。用这些特征作为支持向量机（SVM）、K-近邻（KNN）（Bressan和Vitria，2003）和随机森林（RF）（Criminisi等人，2011）分类器的输入。在第二种方法中，首先，将每个试验划分为不重叠的窗口。然后从每个窗口中提取与前一种方法相同的特征，并制成一个后果特征向量的序列。用这些序列作为堆叠的长短期记忆（LSTM）网络（Staudemeyer和Morris，2019）的输入，用两层LSTM提取时间特征。最后，用一个带有Adam优化器的密集层（Kingma和Ba，2014）来分别对数据进行唤醒和价值标签分类。图6C显示了EEG和生理数据分析的整体结构。</p>
<hr>
<h4 id="Data-Cleaning-数据清洗"><a href="#Data-Cleaning-数据清洗" class="headerlink" title="Data Cleaning 数据清洗"></a>Data Cleaning 数据清洗</h4><h5 id="EEG"><a href="#EEG" class="headerlink" title="EEG"></a>EEG</h5><p>使用DEAP数据集中的预处理过的EEG数据，去除前8s的数据，包括3s的基线，并将5s作为参与时间，最后将数据归一化。参与时间是通过观察选择的，是参与者沉浸在视频中的平均时间。对于自采数据集，使用带通滤波器，提取1到45赫兹之间的频率，这是脑波的频率范围（Huang等人，2016）。然后应用一个共同的平均参考，最后，将数据归一化。图7A,B显示了数据清理前后的脑电图通道的频率。</p>
<hr>
<h5 id="PPG-and-GSR"><a href="#PPG-and-GSR" class="headerlink" title="PPG and GSR"></a>PPG and GSR</h5><p>一个低切频率为0.7赫兹、高切频率为2.5赫兹的带通滤波器被用来去除PPG信号的噪声。同样地，用0.1的低切频率和15赫兹的高切频率来清除GSR信号。还使用了一个中值滤波器来去除GSR信号中的快速瞬态伪影。最后，将这些GSR和PPG信号归一化。图7C-F显示了数据清理前后的GSR和PPG信号的一个样本的振幅。</p>
<hr>
<h4 id="Feature-Extraction-特征提取"><a href="#Feature-Extraction-特征提取" class="headerlink" title="Feature Extraction 特征提取"></a>Feature Extraction 特征提取</h4><h5 id="EEG-1"><a href="#EEG-1" class="headerlink" title="EEG"></a>EEG</h5><p>为了提取脑电特征，对每个数据窗口应用快速傅里叶变换（FFT）来提取脑电波段功率。通过从每个窗口中提取脑电功率波段，并将每个波段的平均值视为一个特征向量，从而形成五个特征。提取了Delta（1-4 HZ）、Theta（4-8 HZ）、Alpha（8-12 HZ）、Beta（12-30 HZ）和Gamma（30-45）带。这些特征通常在以前的研究中使用（Wagh和Vasanth，2019）。</p>
<hr>
<h5 id="PPG-and-GSR-1"><a href="#PPG-and-GSR-1" class="headerlink" title="PPG and GSR"></a>PPG and GSR</h5><p>计算了GSR和PPG信号的一些统计特征。GSR信号的平均值和标准差以及GSR信号的一阶和二阶离散差构成了GSR特征向量。为了建立PPG特征向量，考虑了PPG信号的平均和标准偏差。PPG和GSR特征向量具有相似的特征，因此将这两个特征向量串联起来，并将其称为生理数据。</p>
<hr>
<h4 id="Fusion-Strategy-融合策略"><a href="#Fusion-Strategy-融合策略" class="headerlink" title="Fusion Strategy 融合策略"></a>Fusion Strategy 融合策略</h4><p>有几种方法来融合来自不同来源的数据。融合数据主要有两种方式：（1）特征级或早期融合；（2）决策级融合或后期融合（Shu等人，2018）。</p>
<p>在特征层面上融合了PPG和GSR信号，将创建的特征作为生理特征处理，并对其进行分类。在决策层使用了两种不同的策略来融合面部微表情、EEG和生理学分类结果。第一个策略是基于多数投票，在脑电图、面部和生理预测中选择得票最多的预测作为最终预测。在第二种策略中，使用所有概率的加权和作为决策层的融合策略（Koelstra和Patras，2013；Huang等人，2017）。给这三个分类器在[0，1]的范围内以0.01的步长赋予各种权重，在训练数据上测量最佳权重，并在融合步骤中使用这些权重。方程（1）中，px模态表示每个类别使用特定模态的概率，a、b、c是权重。</p>
<img src="/a4775ace/8.png" class>

<hr>
<h3 id="Result-and-Discussion-结果和讨论"><a href="#Result-and-Discussion-结果和讨论" class="headerlink" title="Result and Discussion 结果和讨论"></a>Result and Discussion 结果和讨论</h3><h4 id="Evaluation-Strategy-评估策略"><a href="#Evaluation-Strategy-评估策略" class="headerlink" title="Evaluation Strategy 评估策略"></a>Evaluation Strategy 评估策略</h4><p>使用了独立于主体的策略来评估本文方法，并找到一个通用的模型。使用了离开部分主体的策略交叉验证。由于本文模型并不复杂，而且数据集的大小也不明显，所以没有使用GPU来训练模型。所有的模型都是在一台装有Gnu-Linux Ubuntu 18.04、英特尔（R）酷睿（TM）i7-8700K CPU（3.70 GHz）的电脑上训练的，有六个内核。将参与者随机洗牌成六个组，并对所有组的模型进行并行训练。对于DEAP数据集，每个折叠中的测试集都有3个参与者。在自采数据集中，有4个参与者被考虑到测试集中。报告的结果是所有组结果的平均值。</p>
<p>评估模型的四个主要指标是准确性、精确性、召回率和F-Score或F1。它们使用方程（2）来衡量二进制分类。在本节中，所有的结果都是基于F-Score的。在这些公式中，TP是真阳性，指的是正确的阳性类预测的数量。真阴性（TN）衡量有多少正确的阴性预测。假阳性是指错误预测的阳性类的数量。FN代表假阴性，即错误的阴性类预测的数量。使用二元分类法对唤醒和情绪分别进行分类，并选择F-Score来评估本文方法，这适合于不平衡数据。(Sun et al., 2009)。</p>
<img src="/a4775ace/9.png" class>

<hr>
<h4 id="Hyper-Parameter-Tuning-超参数调优"><a href="#Hyper-Parameter-Tuning-超参数调优" class="headerlink" title="Hyper-Parameter Tuning 超参数调优"></a>Hyper-Parameter Tuning 超参数调优</h4><p>为了衡量SVM、RF和KNN的最佳超参数，使用了网格搜索交叉验证的参数调整（Claesen和De Moor，2015）。当基于离开部分受试者策略分割数据时，使用六倍交叉验证法调整超参数。当考虑Radial Basis Function（RBF）核时，得到了最好的结果，200作为SVM的调节参数，KNN的五个邻居，RF的500个估计值。对于微观面部表情的三维卷积模型，使用的参数与源研究（Reddy等人，2019）相同。只将epochs的数量设置为50。还根据经验发现，当第一个LSTM有80个神经元，第二个有30个神经元时，使用两个堆叠的LSTM会产生更好的结果。考虑将128、32和64作为脑电图、GSR和PPG分类器的LSTM模型训练中的批次大小，并将它们的历时数设置为100。没有调整学习率。相反，在0.0010.0001的范围内使用了一个降低的学习率，当验证损失不发生变化时，学习率以0.5的速度递减。</p>
<hr>
<h4 id="Identifying-ROI-Size-确定ROI大小"><a href="#Identifying-ROI-Size-确定ROI大小" class="headerlink" title="Identifying ROI Size 确定ROI大小"></a>Identifying ROI Size 确定ROI大小</h4><p>微表情的持续时间在65到500毫秒之间变化。当情绪持续一段时间后，这个时间可能会增加，也可能与下一个微表情合并，而这个微表情是后续情绪刺激的反应（Yan等人，2013）。DEAP数据集以每秒50帧的速度记录面部数据。这意味着，如果认为一个微表情的长度为半秒，当帧率为50赫兹时，一个微表情会出现在25帧中。在自采数据集中，帧率是每秒30帧，所以一个微表情的长度是15帧。考虑了两种不同的窗口大小，包括20和60帧，围绕着顶点帧，以涵盖短的微表情或长的微表情。考虑了更大的窗口尺寸，以覆盖保持较长时间或与下一个微表情重叠的微表情。表5比较了这两种窗口大小对预测结果的影响，当想根据唤醒和价值水平对情绪进行分类。可以看出，对于两个数据集，60帧的结果都比较好。由于增加窗口大小会增加包括其他头部运动的概率，在序列中增加非信息数据，并增加计算成本，没有考虑更大的窗口大小。表5显示了来自DEAP和自采数据集的3D CNN模型在这两种不同窗口大小下的f-score。使用面部微表情分类的预测结果与决策层面的其他模式相结合，对唤醒和价值水平进行分类。</p>
<p>考虑了从EEG和生理数据中提取ROI的各种尺寸，并比较了ROI尺寸对分类结果的影响。图8显示了使用LSTM方法时各种ROI大小对分类结果的影响。报告的数值是所有折叠的F-Score值的平均值。如图8所示，对于两个数据集，使用多数融合时，15的窗口大小几乎创造了最高的F-Score。对于DEAP数据集，当考虑所有的数据时，加权融合创造了预测唤醒的最佳结果。尽管在这里显示的两个不同的数据集中没有看到任何一致的模式，但假设在最情绪化的部分的一小部分数据可以产生一个类似或比使用所有数据更好的结果。这表明，如果准确地确定数据中最情绪化的部分，可以准确地研究大脑和身体对情绪刺激的反应。</p>
<p>还使用SVM、KNN和RF分类器对窗口大小为15和考虑整个数据时的ROI部分进行分类。在表6中比较了这些分类器与LSTM方法在所有数据或只考虑ROI部分进行分类时的F-Score。表5中报告的窗口大小为60的面部微表情的F-Score已被考虑在融合策略中。将面部微表情方法的预测结果与使用的所有分类器进行了融合。从这些表格中可以看出，LSTM方法在两个数据集的唤醒和价值方面都取得了最佳结果。这表明，利用时间和空间特征可以帮助检测情绪。同时，融合策略的结果也大大优于单一模式。在自采数据集中，大多数人对唤醒和情感的融合进行投票，而在DEAP中只有情感的融合优于加权的融合。当应用于ROI数据时，结合PPG和GSR只提高了LSTM方法在价值水平分类中的性能。另外，基于ROI的LSTM的FScore相对接近于或有时优于在整个数据上使用LSTM。这表明，使用一小部分数据可以像使用全部数据一样具有信息量。</p>
<p>虽然其他分类器在其中一个数据集中的唤醒或情感的某些模式产生了良好的结果，但与LSTM方法相比，他们的预测在与其他模式融合后并没有改善。当预测精度低于或接近随机预测或二元分类的50%时，它无法在数据中找到任何特定的模式。因此，单模态预测之间的不匹配性增加，导致融合策略的f-score下降。根据表6，SVM、KNN或RFC对某些模式的f-scores低于或接近50%。因此，这导致了无效的融合。</p>
<hr>
<h4 id="Computation-Cost-计算成本"><a href="#Computation-Cost-计算成本" class="headerlink" title="Computation Cost 计算成本"></a>Computation Cost 计算成本</h4><p>没有使用所有的帧作为3D卷积模型的输入，而是只使用了每个视频的60个帧作为模型的输入。DEAP数据集在每个视频中有3,000帧，而自采数据集在每个视频中有2,400帧。通过提取微表情的ROI，减少了DEAP的输入大小，比率为（60/3000），自采数据集为（60/2400）。输入规模的下降导致了计算成本的大幅下降。自采数据集有230（23 * 10）次试验，而DEAP的数据集有720（18 * 40）次试验，适用于所有参与者。两个数据集的人脸模型的输入都是（60 * 64 * 64），其中60是每个试验的帧数，64 * 64是人脸区域灰度的帧的尺寸。对DEAP数据集的六折人脸模型进行并行训练花了1小时37分钟（每个历时235秒）。由于每个参与者的试验次数较少，自采数据集的训练时间为33分钟（每个震荡期为79秒）。</p>
<p>此外，尽管以前的研究使用LSTM网络对EEG信号进行分类，并将原始信号作为网络的输入（Ma等人，2019年），但从每秒钟的数据中提取了有限的特征，以减少输入规模。创建了一个新的数据序列，该序列比原始数据小得多，同时仍然具有信息量。例如，对于EEG数据，每个试验的大小是（持续时间（秒） * 采样率 * 通道）。将这一大小减少到（持续时间（秒） * 五个功率段）。这种减少对生理学数据也是一样的。脑电图、PPG和GSR的LSTM模型的训练是以六倍的方式平行进行的。为DEAP数据集训练所有这些模型需要12分钟和14秒，而每个历时大约需要1-3秒。自采数据集的训练时间为5分钟，每个历时的运行时间在25到100ms之间。</p>
<hr>
<h4 id="Final-Result-最终结果"><a href="#Final-Result-最终结果" class="headerlink" title="Final Result 最终结果"></a>Final Result 最终结果</h4><p>表7显示了当ROI窗口大小为15秒时，单一模式或融合策略对ROI部分进行分类的最终结果。可以看出，在两个数据集中，将微表情与EEG和生理信号融合，比使用单一模式有更高的准确性和F-Score。与使用独立于主体的策略的相关作品相比，在识别唤醒和情绪水平方面取得了类似或更好的准确性。</p>
<img src="/a4775ace/10.png" class>

<p>没有任何标准的基准来评估各种情感识别研究。有多个数据集，在数据收集方面有不同的场景，使用不同的模式和传感器记录情感数据。数据集、情感模型、分割数据的方式、评估策略和评估指标的多样性会影响最终的情感识别结果。出于这个原因，应该考虑所有这些因素来比较各种研究。与表1中报告的前人工作相比，在考虑独立于主体的方法时，所提出的方法的准确性相当高，这是最具挑战性的评价条件。</p>
<p>虽然检测面部微表情在文献中仍是一个很大的挑战，需要更多的探索，但已经证明，它可以大大降低视频情感识别的计算成本。检测微表情存在一些影响情绪识别性能的挑战，包括与其他面部动作的污染、姿势变化、光照不足，以及伪造或摆放微表情的可能性（Zhao and Li, 2019）。在DEAP数据集和自采数据集中，由于扑克脸的条件，伪造微表情的机会很低。然而，有一些不必要的动作会影响检测微表情和识别感兴趣区域的结果。</p>
<p>低成本的OpenBCI脑电图帽可以达到与DEAP数据集中使用的Biosemi Active II帽类似的性能。结果表明，虽然这个工具成本很低，但它可以作为一个可靠的工具，用于收集大脑信号进行情感识别。</p>
<p>与之前的研究类似，结果显示结合各种模式会带来更好的识别结果，融合后的识别率提高了38%。在DEAP数据集中，对唤醒的准确率达到65.1%，对情感的准确率达到69.2%，这比单一模式要好。在自采数据集中，这些相应的数值为70.8％和69.2％的唤醒和情感。表7显示了这些改进。虽然采用多模态数据有一些缺点，如增加计算成本和数据分析的复杂性，但提高预测性能的好处超过了它们。现在，大多数处理系统都有多个核心，使并行处理变得容易。可以在几乎与单模态分析相同的时间内利用并行处理进行多模态数据分析。</p>
<hr>
<h3 id="Limitations-局限性"><a href="#Limitations-局限性" class="headerlink" title="Limitations 局限性"></a>Limitations 局限性</h3><p>尽管显示面部微表情可以有效地识别情绪，但仍面临着一些挑战，应该在未来解决。由于不自主的面部运动，如眨眼、头部运动或常规的面部表情，微表情可能被错误地检测到（Tran等人，2020）。这些运动会导致对顶点框架的错误检测。在未来，可以通过引入新的面部微表情数据集和使用深度学习方法来大大改善发现策略的结果。在本文中，使用了一个简单的传统微表情识别策略来检测顶点框架。在情感识别中，面部微表情可以与其他模式相结合。在未来，希望使用更强大的定点策略来提高识别质量。</p>
<p>此外，面部微表情方法面临着与面部宏观表情类似的挑战，包括光照条件、文化多样性、性别和年龄。这些限制可以通过使用新的数据集和更强大的深度学习方法来克服。此外，将面部微表情与生理信号相结合，将改善识别结果。对于大多数人来说，脑电图headset和生理传感器并不像相机那样容易获得。现在比以往任何时候都更接近开发情感识别的稳健模型，因为越来越多价格低廉的可穿戴设备，如智能手表、活动追踪器和VR头盔都配备了生理传感器。可以通过引入更准确、可穿戴和可负担的EEG传感器，以及开发更稳健的生理情绪识别算法来实现这一目标。</p>
<p>在研究中，使用了一个定点策略来检测顶点框架。由于定点方法仍然需要更多的探索，是一个开放的挑战（Oh等人，2018），可以在未来通过手动注释DEAP和自采数据集来改善结果。手动注释这些数据集是一项劳动密集型和耗时的活动。尽管如此，由于它们是在类似于微表达数据集的条件下收集的，可以将它们作为微表达数据集，用于制作更强大的微表达模型。</p>
<hr>
<h3 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h3><div class="pdfobject-container" data-target="./file/paper/2022-Using-Facial-Micro-Expressions-in-Combination-With-EEG-and-Physiological-Signals-for-Emotion-Recognition.pdf" data-height="500px"></div>

<hr>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐论文阅读</category>
        <category>💫自我提升</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GAN与VAE</title>
    <url>/a4030801.html</url>
    <content><![CDATA[<h3 id="Generative-Adversarial-Networks-及其变体"><a href="#Generative-Adversarial-Networks-及其变体" class="headerlink" title="Generative Adversarial Networks 及其变体"></a>Generative Adversarial Networks 及其变体</h3><p>生成对抗网络是近几年最为经典的生成模型的代表工作，Goodfellow的经典工作。通过两个神经网络结构之间的最大最小的博弈游戏然后生成模型。下面是原始GAN与一些GAN的变体。</p>
<h4 id="GAN（Generative-Adversarial-Nets）"><a href="#GAN（Generative-Adversarial-Nets）" class="headerlink" title="GAN（Generative Adversarial Nets）"></a>GAN（Generative Adversarial Nets）</h4><p>模型判别模块与生成模块的损失的定义：</p>
<img src="/a4030801/1.webp" class>

<span id="more"></span>

<p>网络结构是：</p>
<img src="/a4030801/2.webp" class>

<p>该结构的最大的问题有两个：一个是难以训练，一个是模型输出图片单调（model collapse）。</p>
<hr>
<h4 id="CGAN（Conditional-Generative-Adversarial-Nets）"><a href="#CGAN（Conditional-Generative-Adversarial-Nets）" class="headerlink" title="CGAN（Conditional Generative Adversarial Nets）"></a>CGAN（Conditional Generative Adversarial Nets）</h4><p>模型判别模块与生成模块的损失的定义：</p>
<img src="/a4030801/3.webp" class>

<p>该模型结构如下图所示。与原始的网络结构的最大的变化便是增加了条件向量。</p>
<img src="/a4030801/4.webp" class>

<hr>
<h4 id="WGAN（Wasserstein-GAN）"><a href="#WGAN（Wasserstein-GAN）" class="headerlink" title="WGAN（Wasserstein GAN）"></a>WGAN（Wasserstein GAN）</h4><p>该论文是对GAN之前提到的问题的分析，结构上并没有具体的变化。通过调整损失函数来实现训练稳定与抑制model collapse。</p>
<img src="/a4030801/5.jpg" class>

<p>其中对参数的截断操作是因为Wasserstein距离中的近似计算中的条件约束导致的。</p>
<hr>
<h4 id="EBGAN（Energy-based-Generative-Adversarial-Network）"><a href="#EBGAN（Energy-based-Generative-Adversarial-Network）" class="headerlink" title="EBGAN（Energy-based Generative Adversarial Network）"></a>EBGAN（Energy-based Generative Adversarial Network）</h4><p>原始的GAN的辨别模块是简单的神经网络。这里使用基于能量的神经网络进行真实样本与虚假样本分布的距离衡量。EBGAN的判别器是一个自编码器。那么EBGAN就是将判别器的输入输出求一个重构误差（rescontruction error），也就是判别器的输出，也即所说的能量（energy）。</p>
<img src="/a4030801/6.jpg" class>

<p>我们希望对于真实样本的重建误差小，同时希望由生成器生成的图片的能量小。那么D的损失函数中要最小化 -D(G(z)），就是最大化D(G(z))， 也就是要抬高下图中的蓝色点对应的曲线，但是如果没有margin的约束，可以无限制的抬高，所以我们需要一个m，即margin，就是当抬高到m这个距离后就没有惩罚了，所以此时loss就将不再忙着抬高，而是去将real对应的曲线也即D(x)拉小。generator做的事情就很好理解了，因为real对应的energy是小的，所以希望生成的图片的energy也是小的。</p>
<img src="/a4030801/7.jpg" class>

<img src="/a4030801/8.webp" class>

<p>其中PT是编码后的结果的余弦相似度。网络结构如下图：</p>
<img src="/a4030801/9.webp" class>

<hr>
<h4 id="ACGAN（Auxiliary-Classifier-GANs）"><a href="#ACGAN（Auxiliary-Classifier-GANs）" class="headerlink" title="ACGAN（Auxiliary Classifier GANs）"></a>ACGAN（Auxiliary Classifier GANs）</h4><p>ACGAN模型与CGAN类似。生成器都是输入类标签c和噪声e。在判别模块中不再输入类标签，另外在输入样本是否为真的同时，利用另一个分类器来判断输入样本的所属类别。</p>
<img src="/a4030801/10.webp" class>

<p>网络结构就是在条件GAN上加入了类别标签。</p>
<img src="/a4030801/11.webp" class>

<hr>
<h4 id="InfoGAN（Information-Maximizing-Generative-Adversarial-Nets）"><a href="#InfoGAN（Information-Maximizing-Generative-Adversarial-Nets）" class="headerlink" title="InfoGAN（Information Maximizing Generative Adversarial Nets）"></a>InfoGAN（Information Maximizing Generative Adversarial Nets）</h4><p>模型将噪声拆分成两个部分，一部分是噪声信号，另一部分就是潜在信息。</p>
<img src="/a4030801/12.jpg" class>

<p>网络结构如图：</p>
<img src="/a4030801/13.webp" class>

<hr>
<h3 id="Variational-Auto-Encoders-及其变体"><a href="#Variational-Auto-Encoders-及其变体" class="headerlink" title="Variational Auto-Encoders 及其变体"></a>Variational Auto-Encoders 及其变体</h3><p>通过编码过程生成目标分布的均值与方差，然后通过采样的技巧来复原目标样本分布，并且使用复原的分布和真实分布的距离来进行参数的调节。</p>
<h4 id="VAE（Variational-Auto-Encoders）"><a href="#VAE（Variational-Auto-Encoders）" class="headerlink" title="VAE（Variational Auto-Encoders）"></a>VAE（Variational Auto-Encoders）</h4><p>变分自编码器的经典形式与网络结构：</p>
<img src="/a4030801/14.webp" class>
<img src="/a4030801/15.webp" class>

<hr>
<h4 id="Conditional-Variational-Auto-Encoders（CVAE）"><a href="#Conditional-Variational-Auto-Encoders（CVAE）" class="headerlink" title="Conditional Variational Auto-Encoders（CVAE）"></a>Conditional Variational Auto-Encoders（CVAE）</h4><p>条件自编码器的构建和CGAN的构建是类似的。</p>
<img src="/a4030801/16.png" class>
<img src="/a4030801/17.webp" class>

<hr>
<h3 id="GAN与VAE的异同"><a href="#GAN与VAE的异同" class="headerlink" title="GAN与VAE的异同"></a>GAN与VAE的异同</h3><ol>
<li>GAN与VAE两个生成模型的Loss推导都可以放在联合概率密度的KL散度的统一框架下进行讨论，而且都得到了与原始推导相同的结果。</li>
<li>GAN与VAE所设计的隐变量不同，结构不同，导致了近似处理的方法不同，但它们的出发点是相同的（上述第一点）。</li>
<li>GAN最后的Loss反映的是生成样本与真实样本的概率流型之间的距离，而VAE最后的Loss反映的是Auto-Encoder的输出x’与原来数据点x两点之间的距离。因而导致了生成效果的不同，以及训练难度的不同。</li>
</ol>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/51476125">https://zhuanlan.zhihu.com/p/51476125</a><br><a href="https://www.jianshu.com/p/41f3eb963346">VAE 原理</a><br><a href="https://github.com/hwalsuklee/tensorflow-generative-model-collections/blob/master/README.md">hwalsuklee/tensorflow-generative-model-collections</a><br><a href="https://zhuanlan.zhihu.com/p/26663985">summer：《Conditional Image Synthesis with Auxiliary Classifier GANs》阅读笔记</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-【生成式模型】GAN 与 VAE —— 隐变量学习的两种不同思路</title>
    <url>/a574ce96.html</url>
    <content><![CDATA[<p>在图像处理中，比较常见的任务有识别、检测、追踪等，这些任务的模型通常在训练阶段通过参数估计学得如何提取输入图像的特征，并建立输入图像与输出之间的映射，在应用阶段之间提取输入图像的特征，以得到相应的结果。</p>
<p>但有这样一类特殊的模型，其参数估计的目的不是通过提取特征来建立输入输出之间的映射，而是学习训练数据的分布，从而模型在应用阶段能够生成与训练数据相似的图像，通常这些图像与真实图像极为相似，我愿称之为“以假乱真”的哲学，这类模型就是<strong>生成式模型</strong>。</p>
<p>基于特定分布进行数据生成，是近年来机器学习领域研究和落地，通常由模型通过学习一组数据的分布，然后生成类似的数据。在机器学习领域，主流的生成模型共有几类：</p>
<ul>
<li>生成式对抗网络（Generative adversarial net, GAN）</li>
<li>变分自编码器（Variational autoencoder, VAE）</li>
<li>流模型（Flow-based model）</li>
</ul>
<p>这 4 类模型是基于不同的原理构建的，在本文中，我将介绍最常被用到的两类模型—— GAN 和 VAE。 GAN 和 VAE 分别是对抗学习和变分推断运用在深度学习的先例，此后学习隐变量的生成式模型很大一部分是基于这两种思路构建。</p>
<span id="more"></span>

<hr>
<h3 id="生成对抗网络（GAN）"><a href="#生成对抗网络（GAN）" class="headerlink" title="生成对抗网络（GAN）"></a>生成对抗网络（GAN）</h3><p>生成式对抗网络（Generative adversarial net, GAN）是一种基于对抗学习的深度生成模型，最早由 Ian Goodfellow 在 《Generative Adversarial Nets》 提出，一经提出就成为了学术界研究的热点，Ian Goodfellow 也因此被人称为“GANs 之父”。</p>
<hr>
<h4 id="GAN-的基本思想"><a href="#GAN-的基本思想" class="headerlink" title="GAN 的基本思想"></a>GAN 的基本思想</h4><p>想必看过金庸小说的同学们都知道，“老顽童”周伯通有一样异于常人的本领——左右互博，有了这样一门武功，一来只有自己一个人也能玩得不亦乐乎，二来自己一个人就能切磋武艺。那是不是神经网络也可以通过这种方式来“修炼功夫”？ 对抗学习就是基于这样的思想。</p>
<p>GAN 的思想很简单，总结起来就是<strong>以假乱真、相互对抗</strong>，而它的做法也是非常之简单粗暴，同时（或者说交替）训练两个网络，通过两个网络之间的博弈，从而达到互相促进的作用。</p>
<p>在 GAN 的整体框架中，用于训练的模型由两个网络组成，一个网络是<strong>生成器 G</strong>（generator），用于数据的生成；另一个网络是<strong>判别器 D</strong>（discriminator），用于对生成器生成的数据和训练数据进行真假判别。就拿图像生成为例，在图像生成模型的训练过程中：</p>
<ul>
<li><strong>G</strong>是生成图像的网络，它接受一个随机的噪声z，并根据噪声生成图像，生成的图像记作G(z)</li>
<li><strong>D</strong>是一个判别网络，判别一张图像是不是“真实的”。它的输入参数是x，x代表一张图像，输出D(x)代表x为真实图片的概率，如果为1，就代表100%是真实的图片，而输出为0，就代表不可能是真实的图像。</li>
</ul>
<p>在训练过程中，生成器和判别器就像是两个相互博弈的人，生成网络 <strong>G</strong> 的目标就是尽量生成真实的图像去欺骗判别网络 <strong>D</strong>，而 <strong>D</strong> 的目标就是尽量把 <strong>G</strong> 生成的图片和真实的图片分别开来。通过相互对抗，生成网络的生成能力和判别网络的判别能力将越来越强，最终当模型收敛时，我们将得到一个生成效果较好的生成器。</p>
<hr>
<h4 id="GAN-的具体实现和训练过程"><a href="#GAN-的具体实现和训练过程" class="headerlink" title="GAN 的具体实现和训练过程"></a>GAN 的具体实现和训练过程</h4><p>为了描述 GAN 如何完成这个博弈过程，我们先定义 GAN 目标函数：</p>
<img src="/a574ce96/1.png" class>

<p>让我来解释一下这个公式：</p>
<ul>
<li>这个式子由两部分构成。第一部分判别网络在真实图像上的对数似然（衡量“将真实图片判定为真”的能力），第二部分是判别网络在生成网络生成的图像上的对数似然的（衡量“将生成图片判定为假”的能力）。</li>
<li>在第一部分中，x 表示真实图像，D(x) 表示 <strong>D</strong> 判断真实图像是否真实的概率；在第二部分中，z 表示输入 <strong>G</strong> 的噪声，G(z) 表示 <strong>G</strong> 网络生成的图像，而 D(G(z)) 是 <strong>D</strong> 网络判断 <strong>G</strong> 生成的图片的是否真实的概率。</li>
<li>对于判别网络 <strong>D</strong>​ 来说，它的目的是能够区分生成图像和真实图像，这需要它对目标函数进行最大化。</li>
<li>对于生成网络 <strong>G</strong>​ 来说，它需要生成能够“骗”过 <strong>D</strong> 的数据，这就意味着它需要最小化第二项似然，由于在 <strong>G</strong> 进行参数更新时，不会对第一项的值造成影响，所以相当于生成网络在最小化似然函数。</li>
</ul>
<p>借用论文里的一张图来说明这个过程，如下图：</p>
<img src="/a574ce96/2.webp" class>

<p>在实际实现中，两个网络的更新是交替进行的，这导致在超参数调节不合适时，会出现参数更新不平衡的问题，不过这个问题不是这篇博客讨论的重点，暂且挂起不谈。</p>
<p>其训练过程如下图所示（来自原论文）：</p>
<img src="/a574ce96/3.webp" class>

<p>可以看到，在每一轮迭代中：</p>
<ul>
<li>先更新由生成器生成数据，并由判别器对生成数据和训练数据进行判别，并利用梯度下降法对判别器的参数进行更新，这样对判别器的更新每次迭代要重复多次。</li>
<li>再利用生成器生成数据，并利用梯度下降法进行生成器的参数更新，每次迭代只需要更新一次</li>
</ul>
<hr>
<h3 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h3><p>GAN 依然存在一些缺点，比如说训练不稳定，生成过程不可控，不具备可解释性等，于是后来出现了若干改进的版本。</p>
<p>当卷积神经网络再视觉领域大放光彩后，有人尝试将卷积操作融合到 GAN 中，也就是接下来要讲的深度卷积对抗生成网络（DCGAN）。</p>
<p>DCGAN 在《UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS》被首次提出，是基于 GAN 的基本框架构建的生成模型，相比于 GAN ，它有了如下的改进：</p>
<ul>
<li>取消所有 pooling 层。G 网络中使用转置卷积（transposed convolutional layer）进行上采样，D 网络中用加入 stride 的卷积代替 pooling；</li>
<li>在 D 和 G 中均使用 batch normalization；</li>
<li>去掉 FC 层，使网络变为全卷积网络；</li>
<li>G 网络中使用 ReLU 作为激活函数，最后一层使用 tanh；</li>
<li>D 网络中使用 LeakyReLU 作为激活函数；</li>
</ul>
<p>DCGAN 的网络结构如下图：</p>
<img src="/a574ce96/4.webp" class>

<p>DCGAN的训练过程与 GAN 相同，不过由于网络结构的改变，相比于 GAN ，DCGAN 的训练相对平衡，并且对局部特征的提取和还原能力较 GAN 强。但由于 DCGAN 属于早期的 GANs ，所以依然存在部分 GAN 的问题，在 DCGAN 后 GAN 又有了若干改进版，由于数量较多、有的比较水，这里就暂且挂起，不多叙述。</p>
<hr>
<h3 id="变分自编码器（VAE）"><a href="#变分自编码器（VAE）" class="headerlink" title="变分自编码器（VAE）"></a>变分自编码器（VAE）</h3><p>如果说 GAN 在数据生成模型领域为我们选择了一条简单粗暴的道路，那接下来要讲的模型则为我们提供了更加巧妙的办法。</p>
<p>变分自编码器（variational autoencoder, VAE）采用变分推断的方式来构建，与其他自编码器类似，变分自编码器也是由编码器和解码器组成，其本质是对一个含隐变量的函数进行密度估计。在训练过程中， VAE 的主要目的是进行极大似然估计，为了使得隐变量服从某一分布，在参数估计的过程中采用了变分推断的思想。</p>
<hr>
<h4 id="KL-散度"><a href="#KL-散度" class="headerlink" title="KL 散度"></a>KL 散度</h4><p>针对这一问题，在变分推断中，我们希望望找到一个相对简单好算的概率分布 q(z) ，使它尽可能地近似我们待分析地后验概率 p(z|x) ，以求我们能够用 q(z) 来近似 p(z|x) 。所以，为了度量两个概率分布 q(z) 和 p(z|x) 之间的距离，我们需要用到的一个工具就是 <strong>KL 散度</strong>。</p>
<p><strong>KL 散度（Kullback-Leibler divergence）即相对熵</strong>，两个概率分布间差异的非对称性度量。如果两个分布越接近，那么 KL 散度越小，如果越远，KL 散度就会越大。对于两个分布 p 和 q ，其 KL 散度的公式为：</p>
<img src="/a574ce96/5.png" class>

<hr>
<h4 id="VAE-的基本思想"><a href="#VAE-的基本思想" class="headerlink" title="VAE 的基本思想"></a>VAE 的基本思想</h4><p>假设我们有一个判别任务，现有一个等待判别的事物 X ，这个事物有一个类别 y ，我们需要建立一个模型 y = f(x; w) 使得 p(y|X) 的概率尽可能大，即让 f(x; w) 尽可能地接近 y 。</p>
<p>如果我们使用生成式模型去解决这一问题，就需要用贝叶斯公式将这个问题转换成：</p>
<img src="/a574ce96/6.png" class>

<p>让我们再考虑一下数据生成问题，则问题可以转换成：当我们有式子左边的 p(z|X) ，应该如何生成一个符合某种 z 的 X（其中 z 为符合某种分布的隐变量）？</p>
<p>一个解决方式是：每次随机生成一个 X ，用 p(z|X) 计算概率，如果概率满足，则结束，如果不满足，则继续随机生成。但这种方式在某些情况下是不现实的，特别是右部的公式难以直接计算得到，所以，我们需要采用其他可行的方法来解决这一问题。这时就可以用到变分推断的思想结合自编码器，假设隐变量 z 服从某种分布来解决这一问题。</p>
<p>由于公式（2）中，右部的积分公式难以计算，我们可以用一个变分函数 q(z|X) 去代替 p(z|X) 。在 VAE 中，这个函数将采用编码器实现），当编码器能够将数据能够完美地将真实数据编码成服从一定分布的隐变量时，那解码器就能将服从这一分布的隐变量解码成接近真实数据的生成数据，从而解码器将能作为生成器使用，这便是 <strong>VAE 的基本思想</strong>。</p>
<p>为了能采用 q(z|X) 去代替 q(z|X) ，我们需要使得两个分布布尽可能地相近，于是乎我们选择了 KL 散度这个指标用来衡量两者的相近程度，于是有：</p>
<img src="/a574ce96/7.png" class>

<p>左右整理一下，我们可以得到：</p>
<img src="/a574ce96/8.png" class>

<p>我们知道在 X 给定的情况下，p(X) 是个固定值，而我们的目的是最大化 KL(q(z)||p(z|X))，所以我们需要让等号右边那部分尽量大，所以，为了找到一个好的 q(z|X)，使得它和 p(z|X) 尽可能地相近，我们需要：</p>
<ul>
<li>右边第一项的对数似然的期望最大化</li>
<li>右边第二项的 KL 散度最小化</li>
</ul>
<hr>
<h4 id="VAE-的实现"><a href="#VAE-的实现" class="headerlink" title="VAE 的实现"></a>VAE 的实现</h4><p>为了将数据编码到隐变量，我们需要假设隐变量 z 服从某种分布。通常我们假设 z 服从高斯分布，则计算公式为：</p>
<img src="/a574ce96/9.png" class>

<p>为了计算方便，我们再进行一个比较强的假设，假设隐变量服从标准正态分布，即服从均值为 0 ，方差为单位矩阵的高斯分布，则：</p>
<img src="/a574ce96/10.png" class>

<p>接下来，我们就能通过构建编码器，得到一个由输入 X 求解隐变量 z 的函数，利用梯度下降法，可根据公式（6）对网络参数进行优化，使得编码器近似接近我们想要拟合的函数。</p>
<p>而对于公式（4）的第一项，我们可以通过构建一个从 z 再变回 X 的解码器，通过梯度下降法进行解码器参数优化，从而实现对 p(X|z) 的极大似然估计，我们将得到一个将符合高斯分布的隐变量变成生成数据的生成器。</p>
<hr>
<h3 id="CVAE"><a href="#CVAE" class="headerlink" title="CVAE"></a>CVAE</h3><p>条件变分自编码器（CVAE） 是 VAE 的变种。VAE 是无监督学习，但是当我们需要网络能够根据我们的需要生成特定的图片，需要加入标签 y 辅组训练，这就是 CVAE。</p>
<p>CVAE 可以看作是有监督学习的 VAE 。将公式（4）的右部变为：</p>
<img src="/a574ce96/11.png" class>

<p>在这里，自编码器需要重构的是 y|X 而不是 X, 所以最终的生成器能够根据标签进行采样而生成对应的数据。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/424045862">https://zhuanlan.zhihu.com/p/424045862</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-VAE与GAN的关系</title>
    <url>/f675461a.html</url>
    <content><![CDATA[<h3 id="VAE-与-GAN-的关系"><a href="#VAE-与-GAN-的关系" class="headerlink" title="VAE 与 GAN 的关系"></a>VAE 与 GAN 的关系</h3><p>VAE（Variational Auto-Encoder）和 GAN（Ganerative Adversarial Networks）都是生成模型（Generative model）。</p>
<p>所谓生成模型，即能生成样本的模型。我们可以将训练集中的数据点看作是某个随机分布抽样出来的样本，比如：MNIST 手写体样本，我们就可将每一幅图像看作是一个随机分布 p(x) 的抽样（实例）。</p>
<p>如果我们能够得到这样的一个随机模型，我们就可以无限制地生成样本，再无采集样本的烦恼。但这个随机分布 p(x) 我们并不知道，需要通过对训练集的学习来得到它，或者逼近它。</p>
<p>要逼近一个随机分布，其基本思想是：将一个已知的，可控的随机分布 q(z) 映射到目标随机分布 p(x) 上。在深度学习领域中，有两个典型的生成模型：VAE，变分自编码器；GAN，生成对抗性网络。它们的结构如图 1、图 2：</p>
<img src="/f675461a/1.png" class>
<p style="text-align:center">图 1 VAE 结构图</p>

<span id="more"></span>

<img src="/f675461a/2.jpg" class>
<p style="text-align:center">图 2 GAN 结构图</p>

<p>VAE 的工作流程是：</p>
<ol>
<li>在训练集（Dataset）中抽样，得到样本x_i，x_i经过神经网络编码器（NN Encoder）得到一个正态分布（N(μ_i, (σ_i)^2)）的充分统计量：均值（以图 1 为例进行解释，μ_i = (m1, m2, m3)）和方差（σ_i = (σ1, σ2, σ3)）</li>
<li>由 N(μ_i, (σ_i)^2) 抽样得到 z_i， 已知 z_i 的分布是标准正态分布 N(0, 1)</li>
<li>z_i 经过 NN_Decoder 得到输出x_i</li>
<li>Loss = ‖x^i−xi‖，训练过程就是让 Loss 取得最小值</li>
<li>训练好的模型，我们可以利用 Decoder 生成样本，即将已知分布 q(z) 的样本通过 Decoder 映射成目标 p(x) 分布的样本</li>
</ol>
<p>以上过程可以用图 3 进行概括。</p>
<img src="/f675461a/3.png" class>
<p style="text-align:center">图 3 VAE 原理图</p>

<p>为比较 VAE 和 GAN 的差异，参考图 4，简述 GAN 的工作原理如下：</p>
<ol>
<li>在一个已知的、可控的随机分布 q(z) (e.g.: 多维正态分布 q(z)=N(μ,σ^2))采样，得到z_i</li>
<li>zi 经过生成器映射 G(z_i) 得到在样本空间（高维空间）的一个数据点 x^g_i，有 x^g_i = G * (z_i)</li>
<li>x^g_i 与样本流型（Manifolds）之间的距离在图中表示为 D = ‖x^g_i−x^^g_i‖，其中 x^^g_i 表示 x^g_i 在流型上的投影，生成器的目标是减少此距离，可以将此距离定义为生成器的损失（Loss）</li>
<li>因为不能直接得到样本的流型，因而需要借助判别器 (Discriminator) 间接地告诉生成器（Generator）它生成的样本距样本流型是 “远了” 还是“近了”，即判别真（real）和假（fake）正确的概率，一方面要判别器提高判别准确性，一方面又要提高生成器的以假乱真的能力，由此形成了竞争导致的均衡，使判别器和生成器两者性能同时提高，最后我们可获得最优的生成器</li>
<li>理想的最优生成器，能将生成的 x^g_i 映射到样本分布的流型中（即图中阴影部分）</li>
</ol>
<img src="/f675461a/4.png" class>
<p style="text-align:center">图 4 GAN 原理</p>

<p>由 GAN 的生成过程，我们可以很直观地得到两个 GAN 缺陷的解释（详细分析可见《Wasserstein GAN》）：</p>
<ol>
<li>模型坍塌（Model collapse）<br> GAN 只要求将 x^g_i 映射至离样本分布流型尽可能近的地方，却不管是不是同一个点，于是生成器有将所有 z_i 都映射为一点的倾向，于是模型坍塌就发生了。</li>
<li>不收敛 由于生成器的 Loss 依赖于判别器 Loss 后向传递，而不是直接来自距离 D = ‖x^g_i−x^^g_i‖ ，因而若判别器总是能准确地判别出真假，则向后传递的信息就非常少（体现为梯度为 0），则生成器便无法形成自己的 Loss，因而便无法有效地训练生成器。正是因为这个原因，《Wasserstein GAN》才提出了一个新的距离定义（Wasserstein Distance）应用于判别器，而不是原型中简单粗暴的<strong>对真伪样本的分辨正确的概率</strong>。Wasserstein Distance 所针对的就是找一个方法来度量 D = ‖x^g_i−x^^g_i‖</li>
</ol>
<p>比较 VAE 与 GAN 的效果，我们可以得到以下两点：</p>
<ul>
<li>GAN 生成的效果要优于 VAE<br>  我认为GAN和VAE的一个本质区别就是loss的区别<br>  VAE是pointwise loss，一个典型的特征就是pointwise loss常常会脱离数据流形面，因此看起来生成的图片会模糊<br>  GAN是分布匹配的loss，更能贴近流行面，看起来就会清晰<br>  但分布匹配的难度较大，一个例子就是经常发生mode collapse问题，小分布丢失，而pointwise loss就没有这个问题，可以用于做初始化或做纠正，因此发展了一系列GAN+VAE的工作<br>  VAE 是一个在数学上具有完美证明的模型，其优化目标和过程都是显式的。由于 VAE 设计的强预设性，其优化过程强制性地把数据拟合到有限维度的混合高斯或者其他分布上，这导致两个结果：<ol>
<li>映射过程中必然导致信息损失，特别是次要信息的损失</li>
<li>不符合预设分布的信息的编码和恢复效果差，如果强制性的把这样的分布投射到高斯分布上，就必然导致模糊<br>对应地，GAN 的训练中没有这样的强预设，它是通过判别器网络来进行优化的，让生成器产生数据的分布直接拟合训练数据的分布，而对具体的分布没有特别的要求。</li>
</ol>
</li>
<li>GAN 比 VAE 要难于训练<br>  文章：Variational Inference: A Unified Framework of Generative Models and Some Revelations，为两个生成模型建立了统一的框架，并提出一种为训练 Generator 而设计的正则项原理，它可以作为《Wasserstein GAN》的一个补充，因为 WGAN 给出的是 GAN 判别器 Loss 的改进意见，而该文却是对生成器下手，提出生成器的一个正则项原则。</li>
</ul>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.cnblogs.com/jiading/articles/13174298.html">https://www.cnblogs.com/jiading/articles/13174298.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-KL散度(Kullback-Leibler divergence)</title>
    <url>/15cccb2.html</url>
    <content><![CDATA[<h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h3><h4 id="KL散度简介"><a href="#KL散度简介" class="headerlink" title="KL散度简介"></a>KL散度简介</h4><p>KL散度的概念来源于概率论和信息论中。KL散度又被称为：相对熵、互熵、鉴别信息、Kullback熵、Kullback-Leible散度(即KL散度的简写)。在机器学习、深度学习领域中，KL散度被广泛运用于变分自编码器中(Variational AutoEncoder,简称VAE)、EM算法、GAN网络中。</p>
<p>KL散度是非对称的，这意味着 D(P||Q) ≠ D(Q||P)。</p>
<span id="more"></span>

<hr>
<h4 id="KL散度定义"><a href="#KL散度定义" class="headerlink" title="KL散度定义"></a>KL散度定义</h4><p>KL散度的定义是建立在熵(Entropy)的基础上的。此处以离散随机变量为例，先给出熵的定义，再给定KL散度定义。</p>
<p>一个离散随机变量X的可能取值为X=x1,x2,…,xn，而对应的概率为pi=p(X=xi)，则随机变量的熵定义为：</p>
<img src="/15cccb2/1.png" class>

<p>规定当p(xi)=0时，p(xi)log(p(xi))=0</p>
<p>如果是两个随机变量P,Q，且其概率分布分别为p(x),q(x)，则p相对q的相对熵为：</p>
<img src="/15cccb2/2.png" class>

<p>针对上述离散变量的概率分布p(x)、q(x)而言，其交叉熵定义为：</p>
<img src="/15cccb2/3.png" class>

<p>因此，KL散度或相对熵可通过下式得出：</p>
<img src="/15cccb2/4.png" class>

<p>同样，当P,Q为连续变量的时候，KL散度的定义为：</p>
<img src="/15cccb2/5.png" class>

<hr>
<h4 id="标准正态分布KL散度计算：N-μ-σ-2-与N-0-1"><a href="#标准正态分布KL散度计算：N-μ-σ-2-与N-0-1" class="headerlink" title="标准正态分布KL散度计算：N(μ, σ^2)与N(0, 1)"></a>标准正态分布KL散度计算：N(μ, σ^2)与N(0, 1)</h4><p>正态分布X~N(μ, σ^2)的概率密度函数为：</p>
<img src="/15cccb2/6.png" class>

<p>标准正态分布X~N(0, 1)的概率密度函数为：</p>
<img src="/15cccb2/7.png" class>

<p>KL散度计算：</p>
<img src="/15cccb2/8.png" class>

<p>整个结果分为三项积分，第一项实际上就是 -log σ^2 乘以概率密度的积分（也就是 1），所以结果是 -log σ^2；第二项实际是正态分布的二阶矩，熟悉正态分布的朋友应该都清楚正态分布的二阶矩为 μ^2 + σ^2 ；而根据定义，第三项实际上就是“-方差除以方差=-1”。所以总结果就：</p>
<img src="/15cccb2/9.png" class>

<hr>
<h3 id="正态分布KL散度计算：N-μ-1-σ-1-2-与N-0-1"><a href="#正态分布KL散度计算：N-μ-1-σ-1-2-与N-0-1" class="headerlink" title="正态分布KL散度计算：N(μ_1, (σ_1)^2)与N(0, 1)"></a>正态分布KL散度计算：N(μ_1, (σ_1)^2)与N(0, 1)</h3><p>正态分布X~N(μ_1, (σ_1)^2)的概率密度函数为：</p>
<img src="/15cccb2/10.png" class>

<p>正态分布X~N(μ_2, (σ_2)^2)的概率密度函数为：</p>
<img src="/15cccb2/11.png" class>

<p>KL散度计算：</p>
<img src="/15cccb2/12.png" class>

<p>整个结果分为四项积分，第一项实际上就是 log (σ_2)^2 乘以概率密度的积分（也就是 1），所以结果是 log (σ_2)^2；第二项实际上就是 -log (σ_1)^2 乘以概率密度的积分（也就是 1），所以结果是 -log (σ_1)^2；第三项实际是异正态分布的二阶矩，熟悉正态分布的朋友应该都清楚异正态分布的二阶矩为 [(σ_1)^2+(μ_1-μ_2)^2]/[(σ_2)^2]；而根据定义，第四项实际上就是“-方差除以方差=-1”。所以总结果就是：</p>
<img src="/15cccb2/13.png" class>

<hr>
<h3 id="KL散度的意义"><a href="#KL散度的意义" class="headerlink" title="KL散度的意义"></a>KL散度的意义</h3><p>在统计学意义上来说，KL散度可以用来衡量两个分布之间的差异程度。若两者差异越小，KL散度越小，反之亦反。当两分布一致时，其KL散度为0。正是因为其可以衡量两个分布之间的差异，所以在VAE、EM、GAN中均有使用到KL散度。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/">https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/</a><br><a href="https://zhuanlan.zhihu.com/p/365400000">https://zhuanlan.zhihu.com/p/365400000</a><br><a href="https://zhuanlan.zhihu.com/p/521804938">https://zhuanlan.zhihu.com/p/521804938</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-解读KL散度：从定义到优化方法</title>
    <url>/499acef4.html</url>
    <content><![CDATA[<p>Kullback-Leibler 散度是计算机科学领域内的一个重要概念。数据科学家 Will Kurt 通过一篇博客文章对这一概念进行了介绍，机器之心技术分析师在此基础上进行了解读和扩充。本文为该解读文章的译文。</p>
<p>原博文：<a href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained">https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained</a></p>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>这篇博文将介绍 KL 散度，即相对熵。这篇博文给出了一个理解相对熵的简单例子，因此这里不会试图重写原作者的内容。除了阅读原博客文章之外，这里还会根据我的知识给出一些基于原博文的额外信息。</p>
<span id="more"></span>

<hr>
<h3 id="定义：熵（Entropy）"><a href="#定义：熵（Entropy）" class="headerlink" title="定义：熵（Entropy）"></a>定义：熵（Entropy）</h3><p>这篇博文介绍了与“概率分布”有关的熵。我想说的是，理解熵的更好方式是将其看作是随机变量的“不确定度”的度量，而不是其概率分布。原博文本身也给出了原因：我们可以将熵看作是“编码我们的信息所需的最小比特数”。概率并不包含信息，原博文解释称被编码的概率的信息必须来自某个字母表（在这里即是一个随机变量），其概率分布根据 p(x_i) 确定。包含信息的是这个随机变量，而非概率分布。</p>
<p>此外，根据原博文，熵能为我们提供“编码我们的信息所需的最小比特数”。我认为有一点需要提及，即实际上这里说的是以<strong>无损</strong>的方式编码我们的信息所需的最小比特数。</p>
<hr>
<h3 id="定义：相对熵（Relative-Entropy）"><a href="#定义：相对熵（Relative-Entropy）" class="headerlink" title="定义：相对熵（Relative Entropy）"></a>定义：相对熵（Relative Entropy）</h3><p>相对熵是两个分布之间的“距离”的度量。从统计学上看，即为似然比的期望对数。相对熵 D(p||q) 衡量了假设当前分布为 q，而真实分布是 p 时的非效率（inefficiency）。</p>
<p>这不是两个分布之间的真实“距离”度量，因为它不是对称的，即 D(p||q) ≠ D(q||p)，而且它也不满足三角不等式。原博文没有提到三角不等式，尽管这可能与理解该博文没有直接关联。在这里，三角不等式即意味着 D(p||q) ≤ D(p||u) + D(u||q)。而实际上这并不总是成立。</p>
<p>相对熵的一个重要性质是非负性，即 D(p||q) ≥ 0。下面给出了证明：</p>
<img src="/499acef4/1.png" class>

<p>其中 (2) 到 (3) 遵循 Jensen 不等式。</p>
<hr>
<h3 id="为什么要优化-KL-散度？"><a href="#为什么要优化-KL-散度？" class="headerlink" title="为什么要优化 KL 散度？"></a>为什么要优化 KL 散度？</h3><p>除了原博文中给出的优化二项分布匹配的案例，我会给出另一个可能需要散度优化的案例。先简单介绍一下原博文的内容，其中本质上是想求解以下问题：</p>
<p>p_optimal = argmin_{p} D(q||p)</p>
<p>其中 q 是根据观察得到的分布，p 是二项分布。从下图可以看到，当 D(q||p) 取最小值时，你应该得到你应该近似求取的二项分布的 p。</p>
<img src="/499acef4/2.jpg" class>

<ul>
<li>原博文是想用一个二项分布来近似观察数据，所以使用了 D(q||p)。</li>
<li>这不是使用散度的传统方式，因为原博文基本上是把观察数据看作是“真实”分布，这显然不对。作者在此的意图是使用一个更简单、更容易理解的分布来近似观察数据，因此按这种方式使用 KL 散度可能是合理的。</li>
<li>在这个 (q,p) 对中，散度是凸的，因此在执行优化时会有很好的图形。</li>
</ul>
<p>从信息论的角度看，散度是无损地编码信息所需的额外比特。让我用以下例子说明一下：</p>
<p>假设问题定义如下：</p>
<ul>
<li>X 是采样自某个有限集 X = x1,x2,…,xn 的一个随机变量</li>
<li>p 是 X 的真实分布，其中 p(x_i) 是 x_i ∈ X, i = 1,…,N 的概率，且 0 ≤ p(x_i) ≤ 1, ∀i</li>
<li><img src="/499acef4/3.png" class> 上式是随机变量 X 的熵，是无损编码信息所需的最小比特数</li>
<li>l_i 是用于编码 x_i 时使用的比特数或比特长度，而 x_i 则是随机变量 X 的一个实例</li>
<li>所有对数的基数都假定为 2</li>
</ul>
<p>为了得到编码给定概率分布 p 的最优 H(p) 比特数，我们必须将每个码字的长度 l_i 设计成与 log 1/p(x) 成正比。因此，我们按以下方式计算编码 X 的期望长度：</p>
<img src="/499acef4/4.png" class>

<p>这里的 ceiling 函数负责处理不是 2 的幂的码字长度。这是因为我们只能为任意码字的比特数分配一个整数值。</p>
<p>现在，让我们假设我们之前不正确地假设了分布 p 为 q，然后看看会怎样。类似地，我们按以下方式计算期望：</p>
<img src="/499acef4/5.png" class>

<p>可以看到，只要执行减法操作 (15)-(9)，就能得到两个期望长度之间的差为 D(p||q)。因为散度是非负的，所以这就是编码该信息平均所需的额外比特。</p>
<hr>
<h3 id="在机器学习相关应用上的应用"><a href="#在机器学习相关应用上的应用" class="headerlink" title="在机器学习相关应用上的应用"></a>在机器学习相关应用上的应用</h3><p>原博文提到两个优化散度的应用：<strong>变分自动编码器（VAE）</strong>和<strong>变分贝叶斯方法</strong>。原博文没有解释这些应用，但提供了扩展阅读链接：</p>
<ul>
<li>变分自动编码器：<a href="https://arxiv.org/pdf/1606.05908.pdf">https://arxiv.org/pdf/1606.05908.pdf</a></li>
<li>变分贝叶斯方法：<a href="https://www.countbayesie.com/blog/2015/3/3/6-amazing-trick-with-monte-carlo-simulations">https://www.countbayesie.com/blog/2015/3/3/6-amazing-trick-with-monte-carlo-simulations</a></li>
</ul>
<p>我将简要描述最小化<strong>机器学习</strong>应用中散度的直观理解。<strong>机器学习</strong>领域中的<strong>生成模型</strong>往往涉及到生成尽可能反映真实情况的分布模型。比如，<strong>生成对抗网络（GAN）</strong>在图片上的应用往往执行的是类似基于黑白图片生成看起来尽量真实的彩色图片这样的任务。在这类似的应用中，输入往往是图像或像素。网络会学习这些像素之间的依赖关系（比如临近像素通常有相似的颜色），然后使用它来创建看起来尽量真实的图像。因此，生成器的目标就是最小化所学到的像素分布于真实图像像素分布之间的散度。</p>
<p>最后，我想说的是，KL 散度最小化可被看作是似然比最大化，这出现在了很多应用中。下面给出了一个看待这一问题的简单方法：</p>
<img src="/499acef4/6.png" class>

<p>从 (18) 到 (19)，我们丢弃了 -H(p)，因为这是一个常数。可以看到，如果我们最小化等式左侧，我们就是在分布 p 上最大化 log q(x) 的期望。因此，最小化 LHS 即是最大化 RHS，即最大化数据的对数似然。</p>
<hr>
<h3 id="总结和扩展阅读"><a href="#总结和扩展阅读" class="headerlink" title="总结和扩展阅读"></a>总结和扩展阅读</h3><p>在本文中，在原博文的基础上，我提供了一些有关 KL 散度（相对熵）的补充材料。我认为 KL 散度的重要性在于其量化你的分布估计与真实分布的可能距离的能力。在这篇博文的案例中，如果我们假设观察数据取自根据某个参数集参数化的分布，那么这些参数应该怎样取值才最能代表观察数据。</p>
<p>最后，如果你还有兴趣了解 KL 散度的变体，我推荐你了解 Jesen-Shannon 散度，这是一种对称的散度，衡量的是两个分布的相似性。另外还有 Renyi 散度，这是 KL 散度的推广，主要用在量子物理学应用中。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://www.jiqizhixin.com/articles/2018-07-24-10">https://www.jiqizhixin.com/articles/2018-07-24-10</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-KL散度与交叉熵概念辨析</title>
    <url>/1ec6e007.html</url>
    <content><![CDATA[<h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h3><p>深度学习中，常用<strong>KL散度衡量两个数据分布之间的差异</strong>，KL散度越小，则表示两个数据分布之间的差异越小。一般以 P(x) 表示样本的真实分布，Q(x)作为模型预测的分布。例如，在一个三分类任务中，x1，x2，x3分别表示猫、狗和马。若一张猫的图片的真实分布P(x)=[1,0,0]，而预测分布为Q(x)=[0.7,0.2,0.1]，则对应的KL散度计算如下：</p>
<img src="/1ec6e007/1.gif" class>

<img src="/1ec6e007/2.gif" class>

<span id="more"></span>

<hr>
<h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><p>在介绍交叉熵之前，首先补充一下以下重要概念：</p>
<h4 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h4><p>设某一事件发生的概率为P(x)，则其信息量表示为：</p>
<img src="/1ec6e007/3.gif" class>

<p>信息量是衡量一个事件发生的不确定性，大小与事件发生的概率呈反比，一个事件发生的概率越大，那么其不确定也就越小，即信息量越小。</p>
<h4 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h4><p><strong>信息量的期望叫做熵。</strong>熵在化学中也是描述混乱程度(不确定性)的一个指标，在计算机领域含义依旧相似。熵的计算公式如下：</p>
<img src="/1ec6e007/4.gif" class>

<p>对于0-1分布，设事件发生的概率为P(x)，不发生的概率为1-P(x)，则熵的计算公式可简化为：</p>
<img src="/1ec6e007/5.gif" class>

<p>这里就引出了交叉熵的概念，交叉熵的计算公式如下：</p>
<img src="/1ec6e007/6.gif" class>

<p>其中p(x)为真实样本的分布(或概率)，q(x)为模型输出的分布(或概率)，因为同时包含了真实数据分布信息和模型预测分布信息，故得名交叉熵。所以说了一大堆，交叉熵和KL散度到底啥关系？</p>
<p>简单来说：<strong>KL散度 = 交叉熵 - 信息熵(常数)</strong></p>
<p>因为信息熵可以看作是个已知的常数，并且交叉熵的计算公式相对而言更简单，所以实际运用中常常用交叉熵的计算代替KL散度而实现一样的效果，即使得模型预测的分布Q(x)更接近于实际样本分布P(x)。下面请看公式推导过程(不想看公式的建议可以直接跳到代码实现部分)：</p>
<img src="/1ec6e007/7.gif" class>
<img src="/1ec6e007/8.gif" class>
<img src="/1ec6e007/9.gif" class>

<p>其中，H(p(x))被称为信息熵，因为真实的样本分布一般是已知的，所以p(x)可以看作是常数，故H(p(x))也为常数，因此就得出了这篇文章最核心的东西：<strong>KL散度 = 交叉熵 - 信息熵(常数)</strong></p>
<hr>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line">loss_f = nn.CrossEntropyLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">True</span>, reduce=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">pred1 = torch.from_numpy(np.array([</span><br><span class="line">                      [<span class="number">0.7</span>, <span class="number">0.2</span>, <span class="number">0.1</span>],</span><br><span class="line">                      [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>],</span><br><span class="line">                      [<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.6</span>]])</span><br><span class="line">                    )</span><br><span class="line">pred2 = torch.Tensor(np.array([</span><br><span class="line">                      [<span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>],</span><br><span class="line">                      [<span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.5</span>],</span><br><span class="line">                      [<span class="number">0.6</span>, <span class="number">0.2</span>, <span class="number">0.2</span>]])</span><br><span class="line">                    )</span><br><span class="line">target = torch.Tensor(np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])).<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line"> </span><br><span class="line">loss1 = loss_f(pred1, target)</span><br><span class="line">loss2 = loss_f(pred2, target)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;loss1:&quot;</span>, loss1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;loss2:&quot;</span>, loss2)</span><br></pre></td></tr></table></figure>

<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">loss1: tensor(0.8527, dtype=torch.float64)</span><br><span class="line">loss2: tensor(1.2527)</span><br></pre></td></tr></table></figure>

<p>值得注意的是上述代码等价于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">nll_loss = nn.NLLLoss(reduce=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">pred1 = torch.from_numpy(np.array([</span><br><span class="line">                      [<span class="number">0.7</span>, <span class="number">0.2</span>, <span class="number">0.1</span>],</span><br><span class="line">                      [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>],</span><br><span class="line">                      [<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.6</span>]])</span><br><span class="line">                    )</span><br><span class="line">pred2 = torch.Tensor(np.array([</span><br><span class="line">                      [<span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>],</span><br><span class="line">                      [<span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.5</span>],</span><br><span class="line">                      [<span class="number">0.6</span>, <span class="number">0.2</span>, <span class="number">0.2</span>]])</span><br><span class="line">                    )</span><br><span class="line">target = torch.Tensor(np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])).<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line"> </span><br><span class="line">loss1 = nll_loss(torch.log(softmax(pred1)),target)</span><br><span class="line">loss2 = nll_loss(torch.log(softmax(pred2)),target)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;loss1:&quot;</span>, loss1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;loss2:&quot;</span>, loss2)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">loss1: tensor(0.8527, dtype=torch.float64)</span><br><span class="line">loss2: tensor(1.2527)</span><br></pre></td></tr></table></figure>

<p>可以看出效果是一样的，这是因为在pytorch的代码实现中，交叉熵的计算公式为：</p>
<img src="/1ec6e007/10.png" class>

<p>也就是先计算Softmax</p>
<img src="/1ec6e007/11.png" class>

<p>在Softmax的输出结果上取Log值之后再计算NLLLoss(直接取target（下面公式中为y）对应的模型的输出再加个负号)</p>
<img src="/1ec6e007/12.gif" class>

<p>例如上述代码实现中，target=[0, 1, 2]分别表示预测的正确类别分别是0,1,2，对应到模型的输出pred1中就是0.7,0.5和0.6。对应的NLLLoss就分别是-0.7,-0.5和-0.6。因此，<strong>在pytorch的代码实现中 CrossEntropy 的作用效果等价于 Softmax 与 Log 以及 NLLLoss 作用的叠加。</strong></p>
<p>注意：CrossEntropy公式中使用Softmax和Log就相当于是把原本模型直接输出的预测值变成了取了log之后的概率值，而NLLLoss的作用就是把对应于正确标签的那个概率值选出来再添个负号从而去Minimize这个值(也就是最大化这个概率值)</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">CrossEntropyLoss — PyTorch 1.10.1 documentation</a><br><a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html">Softmax — PyTorch 1.10.1 documentation</a><br><a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#NLLLoss">torch.nn.modules.loss — PyTorch 1.10.1 documentation</a><br><a href="https://blog.csdn.net/daimashiren/article/details/122625664">KL散度与交叉熵概念辨析</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙进阶学习</category>
        <category>⭐人工智能</category>
        <category>💫机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>数学基础-KKT条件，原来如此简单 | 理论+算例实践</title>
    <url>/9dca7274.html</url>
    <content><![CDATA[<h3 id="什么是KKT"><a href="#什么是KKT" class="headerlink" title="什么是KKT"></a>什么是KKT</h3><p><strong>KKT条件（Karush Kuhn Tucker conditions）</strong>是最优化（特别是<strong>非线性规划</strong>）领域最重要的成果之一，是<strong>判断某点是极值点</strong>的必要条件。</p>
<p>可理解好它需要用到<strong>梯度、松弛变量、对偶理论等</strong>知识，想讲好<strong>KKT条件</strong>是具有一定难度的。</p>
<p>本文第一部分侧重于<strong>理论部分</strong>，第二部分给出<strong>运用KKT条件</strong>进行<strong>数值和符号运算的Matlab代码</strong>。基于此，大家可以非常方便地应用于自己的<strong>论文写作</strong>。</p>
<p>在介绍KKT条件之前，先补充些<strong>基础知识</strong>。</p>
<span id="more"></span>

<hr>
<h4 id="何谓最优化问题"><a href="#何谓最优化问题" class="headerlink" title="何谓最优化问题"></a>何谓最优化问题</h4><blockquote>
<p><strong>要选择一组参数（变量），在满足一定的限制条件（约束）下，使设计指标（目标）达到最优值。</strong></p>
</blockquote>
<p>根据定义，<a href="https://mp.weixin.qq.com/s?__biz=MzIxMDY1OTk1OA==&mid=2247483878&idx=1&sn=9c862202b8dbb9ce9baa953bfcd838ef">古诺模型</a>和<a href="https://mp.weixin.qq.com/s?__biz=MzIxMDY1OTk1OA==&mid=2247483899&idx=1&sn=0f37e20c05a6fe0aecb4d24b440a3f19">Stackelberg模型</a>是最优化问题，只不过它们<strong>均没有约束</strong>，直接对<strong>决策变量求导</strong>便能得到<strong>最优值</strong>。</p>
<p>进一步，根据<strong>有无约束</strong>以及<strong>约束特征</strong>，可以将最优化问题<strong>分为以下三类</strong>，每类问题的<strong>求解方法</strong>也紧跟着列出。</p>
<hr>
<h4 id="最优化问题分类"><a href="#最优化问题分类" class="headerlink" title="最优化问题分类"></a>最优化问题分类</h4><blockquote>
<p><strong>无约束</strong>优化问题：直接求导、最速下降法、共轭梯度法、牛顿法等；<br><strong>等式约束</strong>优化问题：拉格朗日(Lagrange)乘数法；<br><strong>不等式约束</strong>优化问题：KKT条件。</p>
</blockquote>
<p><strong>大家做科研时也要分清楚自己的问题属于哪一类，然后运用对应的求解方法。</strong></p>
<p>以上知识点在本科的《运筹学》和《高等数学》课程中均学过。<strong>前两类</strong>相对简单，至于<strong>KKT条件</strong>，大家会被课本上复杂的数学公式<strong>劝退</strong>，即使考前重温，过段时间又会忘。</p>
<p>所以，本文不先从那些复杂公式入手，而是以我的理解，带大家一起探索下<strong>Karush–Kuhn–Tucker</strong>这三个人，是<strong>如何发现并总结出KKT条件</strong>的。</p>
<hr>
<hr>
<h3 id="KKT条件理论部分"><a href="#KKT条件理论部分" class="headerlink" title="KKT条件理论部分"></a>KKT条件理论部分</h3><p>该部分先介绍KKT条件的<strong>核心思想</strong>，即<strong>λg(X*)=0</strong>公式的由来；再解释为什么课本上的<strong>数学公式长那样</strong>，最后再针对性地给出一些<strong>补充说明</strong>和<strong>数学证明</strong>。</p>
<hr>
<h4 id="KKT条件核心思想"><a href="#KKT条件核心思想" class="headerlink" title="KKT条件核心思想"></a>KKT条件核心思想</h4><p>时光倒流，假设你是还没提出KKT条件的Karush本人，面对不等式约束优化问题，会如何思考呢？</p>
<p>先观察下仅含有一个不等式约束的优化问题：</p>
<img src="/9dca7274/1.png" class>

<blockquote>
<p>注：如果是最大化问题，即maxf(X)，约束改写为<strong>g(X*)≥0</strong>的形式（原因后文会解释）。</p>
</blockquote>
<p>既然默认<strong>还不知道KKT条件</strong>，所以目前咱们还不会解决该问题。但不急，想想咱们会啥？会<strong>求求导数</strong>，同时也会等式约束下的<strong>拉格朗日乘数法</strong>啊。</p>
<p>一步步来，先对f(X)函数求导吧（<strong>若X多维则是求梯度</strong>），即<strong>先不考虑g(X)≤0这个约束</strong>。</p>
<p>毕竟求导或求梯度，Karush和你都是<strong>会的</strong>。此时会得到“使f(X)取最小值时的<strong>最优X</strong>”，进一步，如果将其值X*带入约束g(X)，无非就以下三种情况。</p>
<blockquote>
<p>（1）g(X*)&lt;0</p>
</blockquote>
<p>那正好满足约束，<strong>X</strong>就是我们要找的<strong>最优解</strong>。</p>
<p>猛然发现，此时该约束完全<strong>不起作用</strong>啊(称为<strong>不起作用约束</strong>)，毕竟我们计算X*时压根都没考虑它。</p>
<blockquote>
<p>（2）g(X*)=0</p>
</blockquote>
<p>也就是最优解X*正好也让约束<strong>取了等号</strong>。</p>
<p>这咱们也熟啊，这不转化为含有<strong>等式约束</strong>的优化问题了嘛。如何求解？<strong>拉格朗日乘数法</strong>啊，安排~</p>
<blockquote>
<p>（3）g(X*)&gt;0</p>
</blockquote>
<p>显然此时的X*不满足约束，应<strong>舍弃</strong>。</p>
<p>但这并没有结束，我们需要<strong>给出一个解</strong>，那此时大家觉得X*会在哪？很简单，无非又变回了情形（1）或（2）。</p>
<p>综上，我们只需要分情况讨论清楚<strong>若g(X*)&lt;0和若g(X*)=0时，应该如何求解即可</strong>。</p>
<p>一通分析下来，大家或许此时感觉自己好像<strong>已经会了</strong>，不就是：</p>
<blockquote>
<p><strong>若g(X*)&lt;0</strong>，约束不起作用，该问题转化为<strong>无约束优化问题</strong>求解；<br><strong>若g(X*)=0</strong>，引入拉格朗日乘子λ，采用<strong>拉格朗日乘数法</strong>求解嘛，其间，构造的<strong>拉格朗日函数</strong>如下(这是拉格朗日乘数法的知识，不了解的同学可以自行简单重温下）。</p>
</blockquote>
<img src="/9dca7274/2.png" class>

<p>理确实这么个理，但人家数学家追求的是<strong>能否有个统一的形式来求解？</strong>这样<strong>分类讨论</strong>可不那么高大上啊。</p>
<p>既然都已经引进<strong>拉格朗日乘子λ</strong>了，那也得想办法使得在<strong>g(X*)&lt;0</strong>情形下，也要与<strong>λ</strong>有点关系。</p>
<p>考虑到<strong>若g(X*)&lt;0</strong>，此时该约束不起作用，而已经构造好的<strong>拉格朗日函数</strong>中又有<strong>λ</strong>，怎么办？</p>
<p>很简单，<strong>让拉格朗日函数中的λ=0即可！</strong>此时<strong>拉格朗日函数</strong>可不就简化为L(x, λ)=f(X)了嘛。此时对L(x, λ)求导（等价于对f(X)求导）时既不用管<strong>约束</strong>，也没有<strong>λ的干扰</strong>，简直完美。</p>
<p>汇总一下就是：</p>
<blockquote>
<p>（1）<strong>若g(X*)=0，引入拉格朗日乘子λ，并要求λ≥0；</strong><br>（2）<strong>若g(X*)&lt;0，要求λ=0。</strong></p>
</blockquote>
<p>那怎么统一呢？数学家灵魂附体！脑袋一拍，<strong>含泪发现</strong>，这不就可以采用<strong>λg(X*)=0</strong>的形式统一了嘛。</p>
<p>恭喜你，你代替<strong>Karush本人提出了λg(X*)=0！</strong>而这，就是KKT条件的<strong>精髓</strong>。</p>
<p>是不是有点难以置信，但确实，KKT条件的<strong>核心思想和公式</strong>其实已经<strong>讲完了</strong>。</p>
<p>不复杂吧，基础思想确实是很简单的，毕竟早在1939年，Karush在其<strong>硕士学位论文</strong>里就已经给出了KKT条件。硕士生啊，哎，差距。</p>
<hr>
<h4 id="KKT条件的数学公式"><a href="#KKT条件的数学公式" class="headerlink" title="KKT条件的数学公式"></a>KKT条件的数学公式</h4><p><strong>掌握了思想</strong>，便可以更好地看懂课本上的公式了。</p>
<p>还是由简到难，先给出仅含有<strong>一个不等式约束</strong>的<strong>KKT条件</strong>。</p>
<img src="/9dca7274/3.jpg" class>

<p>这里还需要<strong>借助</strong>上一部分给出的<strong>拉格朗日函数</strong>来理解。</p>
<img src="/9dca7274/4.png" class>

<p>简单分析**公式(1)-(4)**可知：</p>
<blockquote>
<p>式(1)：对拉格朗日函数求梯度(若X一维就是求导)，其中，下三角表示梯度；<br>式(2)：核心公式，要么λ=0，要么g(X*)=0（此处要求两者不能同时为0）；<br>式(3)：拉格朗日乘子λ必须是正的（下一部分的图示法有证明）；<br>式(4)：原问题自己的约束。</p>
</blockquote>
<p>可见，式(1)和(2)都是<strong>等式</strong>，可以帮助我们求<strong>最优X*和λ</strong>，因为式(2)要<strong>分类讨论</strong>，所以可能存在<strong>多个X*和λ</strong>；式(3)和(4)主要起<strong>验证作用</strong>，帮助我们排除掉一些<strong>不满足</strong>式(3)和(4)的<strong>X*和λ</strong>。</p>
<p>具体地，在<strong>应用KKT条件计算</strong>时，通常也是<strong>分类讨论</strong>后先求解<strong>X*和λ</strong>，再<strong>验证</strong>其是否满足式(3)和(4)，从而排除一些解。</p>
<p>像上述仅含有<strong>一个约束</strong>的例子，只需要<strong>分两类</strong>，通常是以<strong>拉格朗日乘子λ是否为0</strong>进行分类：</p>
<blockquote>
<p>(1) 当 λ=0 时，<strong>计算</strong>X*的值，并验证g(X*)≤0是否成立；<br>(2) 当 λ≠0 时，<strong>计算</strong>X*和λ的值，并验证g(X*)≤0和λ≥0是否成立。</p>
</blockquote>
<p>下面，将KKT条件推广至含有多个等式约束和不等式约束的情况。也是课本上给初次学习KKT条件的同学提供的公式，劝退了好多人。</p>
<p>考虑的最优化问题为：</p>
<img src="/9dca7274/5.jpg" class>

<p>此时定义的<strong>拉格朗日函数</strong>为：</p>
<img src="/9dca7274/6.png" class>

<p>其中，**{λi}<strong>指的是一系列的λ（有m个），同理</strong>{μj}**也是。由于是多个约束，因此引入求和号∑。</p>
<p>其对应的<strong>KKT条件</strong>为：</p>
<img src="/9dca7274/7.webp" class>

<p>不要被上述形式吓到了，解题思路与之前叙述<strong>类似</strong>，就是用<strong>几个等式计算</strong>最优值，用<strong>不等式验证</strong>这些值，不满足则排除。</p>
<p>即，<strong>利用式(1)(2)(3)求最优X*和λi</strong>，然后<strong>通过式(4)和(5)验证这些解是否可行</strong>，“可行”指的是这些解是否能让(4)和(5)的不等号成立，不成立则<strong>排除</strong>。注意，μj是可以取任意值的，不受限制。因为它们是<strong>等式约束</strong>的拉格朗日乘子，不是不等式的乘子。</p>
<p>由于该问题有<strong>m个不等式约束</strong>，每个<strong>约束</strong>对应的<strong>拉格朗日/KKT乘子λi</strong>都可以<strong>“=0”或“≠0”</strong>。因此，需要分类讨论的情况有<strong>2^m</strong>种。</p>
<p>分类详情如下：(1) 当λ1=0，λ2≠0，……，λm≠0时；(2) 当λ1=0，λ2=0，……，λm≠0时；……在此，不再展开，<strong>本文第四部分</strong>会给出<strong>算例</strong>来做具体说明。</p>
<p>至此，从特殊到一般的KKT条件讲解完毕，总结一下，当我们<strong>应用KKT条件求解算例</strong>时，可以采用如下思路：</p>
<blockquote>
<p>能解出最优解的一定是等式，故式(1)(2)(3)帮我们求最优解；<br>式(4)和式(5)是不等式，帮我们排除一些解，或者得到最优解的适用范围。</p>
</blockquote>
<p>这里有必要解释下<strong>“得到最优解的适用范围”</strong>这句话。其主要针对<strong>符号运算</strong>的情形，看完<strong>第四部分的算例</strong>，会有更深的理解，这里仅作为引子简单提一下：</p>
<blockquote>
<p>大家在写论文时，建立的数学模型多是用<strong>参数和变量</strong>表示的，不同情形下的最优解也是<strong>符号表达式</strong>，因此<strong>很难比较大小</strong>。<br>此时，只能通过式(4)和(5)，来得到<strong>在什么条件（某符号表达式满足某条件）下，最优解X*和对应的f(X*)值为多少</strong>，即需要<strong>分类讨论</strong>。</p>
</blockquote>
<p>具体如何应用上述理论<strong>求解具体的算例</strong>，并撰写Matlab代码，放在第四部分讲解，本部分着重讲解<strong>理论</strong>。</p>
<hr>
<hr>
<h3 id="KKT条件补充说明"><a href="#KKT条件补充说明" class="headerlink" title="KKT条件补充说明"></a>KKT条件补充说明</h3><p>该部分主要强调KKT条件的<strong>适用范围</strong>和<strong>部分理论的数学证明</strong>。</p>
<hr>
<h4 id="充分性、必要性说明"><a href="#充分性、必要性说明" class="headerlink" title="充分性、必要性说明"></a>充分性、必要性说明</h4><p>首先强调的是，KKT条件是判断某点是极值点的<strong>必要条件，不是充分条件</strong>。换句话说，<strong>最优解一定满足KKT条件，但KKT条件的解不一定是最优解</strong>。</p>
<p>对于<strong>凸规划</strong>，KKT条件就是<strong>充要条件</strong>了，只要满足KKT条件，则一定是极值点，且得到的一定还是<strong>全局最优解</strong>。</p>
<blockquote>
<p><strong>凸规划</strong>指的是：目标函数为<strong>凸函数</strong>，不等式约束函数也为<strong>凸函数</strong>，等式约束函数是<strong>仿射</strong>的（理解成是<strong>线性的</strong>也行）。这牵扯到另一个领域了，本文不再展开陈述。</p>
</blockquote>
<p><strong>补充：</strong>我知道很多同学会问，目标函数是凹函数就不能解了？并不是的，凸规划/凸优化只研究<strong>凸函数的最小化问题</strong>，并且认为凹函数的最大化问题是与它<strong>等价的</strong>。毕竟凹函数只需加个负号就是凸函数了，所以在研究问题中，就不再提凹函数了。</p>
<hr>
<h4 id="Min-Max与“≤0”和“≥0”的规定"><a href="#Min-Max与“≤0”和“≥0”的规定" class="headerlink" title="Min/Max与“≤0”和“≥0”的规定"></a>Min/Max与“≤0”和“≥0”的规定</h4><p>这里指的是（<strong>该部分也是本文的重点部分，划重点</strong>）：</p>
<blockquote>
<p>（1）如果目标为最小化（Min）问题，那么不等式约束需要整理成“≤0”的形式；<br>（2）如果目标为最大化（Max）问题，那么不等式约束需要整理成“≥0”的形式；</p>
</blockquote>
<p>以仅含有<strong>一个不等式约束</strong>的情形为例，<strong>最小化和最大化</strong>的优化问题要整理成如下<strong>形式</strong>：</p>
<img src="/9dca7274/8.png" class>

<p><strong>该形式</strong>可以死记硬背，但时间一长，大家可能会<strong>忘记或记混</strong>了，下面，采用<strong>图示法</strong>逐步展示为什么会有这个要求，该分析过程也展现了KTT条件的<strong>几何思想</strong>。</p>
<img src="/9dca7274/9.webp" class>

<p>上图画出了3条f(X)函数的<strong>等值线(图中虚线)**，以及右下角为</strong>可行域S<strong>（即约束条件规定的区域）和</strong>g(X)=0<strong>的曲线，最优解为</strong>X***。基于此，具体分析如下：</p>
<blockquote>
<p><strong>（1）f(X)函数值下降方向为左上方：</strong><br>目标是<strong>最小化问题</strong>，若下降方向为右下方，则最优解（图中X*）一定不是在g(X)=0上，而是在可行域S内部</p>
</blockquote>
<p>由于KKT条件中第一条就需要计算f(X)和g(X)函数的<strong>梯度</strong>，所以，这里补充一个基础知识：<strong>梯度方向垂直于函数等值线，指向函数值增长的方向</strong>。</p>
<p>基于此，我们尝试画出<strong>f(X)和g(X)函数的梯度方向</strong>：</p>
<blockquote>
<p><strong>（2）画出f(X)的梯度方向（下图红色方向）：</strong><br>梯度方向是函数值增长的方向，因此指向右下方；负梯度方向是函数值下降的方向，指向左上方；<br><strong>（3）画出g(X)的梯度方向（下图蓝色方向）：</strong><br>由于曲线是g(X)=0，右下方是g(X)&lt;0，是在下降，因此，g(X)函数值增长的方向就是左上方了。</p>
</blockquote>
<img src="/9dca7274/10.jpg" class>

<p>由上述分析和上图可知，在最优解X*处，<strong>f(X*)和g(X*)的梯度方向</strong>共线且方向相反。<strong>向量共线且方向相反</strong>在数学上的写法就是：</p>
<p><strong>负梯度向量是另一个梯度向量的λ倍。</strong>移项后发现，这不就是<strong>KKT条件的第一个等式</strong>嘛！</p>
<img src="/9dca7274/11.png" class>

<p>同时可知，λ的值只能取<strong>正值</strong>，因为<strong>g(X)的梯度方向与f(X)负梯度方向</strong>相同。这也是KKT条件要求 <strong>λ≥0</strong> 的原因。</p>
<blockquote>
<p><strong>基于以上分析可知：最小化问题的约束条件应该整理成“≤0”的形式，且λ≥0。</strong></p>
</blockquote>
<p>同理，最大化的分析不再展开，仅给出分析图，有兴趣的同学可以自己动手分析一下。</p>
<img src="/9dca7274/12.webp" class>

<p>补充一点，对于<strong>最大化问题</strong>，如果可行域也<strong>非要写成g(X)≤0</strong>的形式，<strong>能行吗？</strong>先别忙着否定，我们分析一下。</p>
<p>此时g(X*)的梯度方向就不再是右下方了（不是上图了），而是<strong>f(X*)与g(X*)的梯度方向相同</strong>，有：</p>
<img src="/9dca7274/13.png" class>

<p>此时如上图，<strong>要么</strong>KKT条件第一项改为<strong>“作差”</strong>，<strong>要么</strong>让<strong>λ&lt;0</strong>。无论哪一个，其实都是<strong>徒增烦恼</strong>。不如上来就规定约束写成<strong>g(X)≥0</strong>来的方便。</p>
<blockquote>
<p><strong>因此，最大化问题的约束条件应该整理成“≥0”的形式，且λ≥0。</strong></p>
</blockquote>
<p>下面推广到<strong>多约束条件</strong>的情形，仅是把<strong>梯度的共线</strong>变为<strong>梯度的线性组合</strong>，若不好理解，可跳过。</p>
<p>假设有<strong>起作用约束g1(X)和起作用约束g2(X)**共同影响</strong>目标函数f(X)的梯度**，又是怎么样的图形呢？</p>
<img src="/9dca7274/14.webp" class>

<p>我们分别画出g1(X)函数在X*处的梯度，如图中<strong>蓝色向量</strong>，其垂直于曲线g1(X*)=0；同理，画出g2(X)函数在X*处的梯度，是另一个<strong>蓝色向量</strong>。</p>
<p>至于f(X)函数的梯度，图中画出<strong>负梯度方向</strong>（函数值下降的方向），这样画的好处是可以直观地看出三个梯度向量间的关系：</p>
<blockquote>
<p><strong>f函数的负梯度可以表示成g1函数和g2函数梯度的线性组合。则有如下公式：</strong></p>
</blockquote>
<img src="/9dca7274/15.jpg" class>

<p>简单移项后，又发现了我们的老朋友：<strong>KKT条件的第一个等式</strong>。从图中也可以看出，梯度向量之间的夹角为<strong>锐角</strong>，因此也有<strong>λ1≥0，λ2≥0</strong>的要求。</p>
<p>看完这部分内容，相信大家对于课本上关于KKT条件的的<strong>数学公式和图形</strong>，能记忆也能自己推导了。</p>
<hr>
<h4 id="正则性条件-约束规范说明"><a href="#正则性条件-约束规范说明" class="headerlink" title="正则性条件/约束规范说明"></a>正则性条件/约束规范说明</h4><p>KKT条件对于<strong>目标函数</strong>和<strong>约束函数</strong>也是有<strong>要求</strong>的。该部分数学性较强，不好理解可跳过。</p>
<p><strong>目标函数和约束函数（f、g1、… 、gm、h1、… 、hn函数）均为连续可微函数。</strong></p>
<p>上述是我们熟知的要求，事实上，并<strong>不完全正确（严谨）</strong>，还缺少一个<strong>regularity条件</strong>（也被成为<strong>正则性条件</strong>或者<strong>约束规范</strong>（constraint qualification））。</p>
<p>其含义指：<strong>以下方程组是线性独立的。</strong></p>
<img src="/9dca7274/16.png" class>

<p>其中，I(X*)指的是<strong>起作用约束</strong>的集合。</p>
<p>这里不再深入展开，具体算例可参见B站视频<a href="https://www.bilibili.com/video/BV1LF411i768/">《KKT条件为什么用不了了》</a>：</p>
<iframe src="//player.bilibili.com/player.html?aid=295196252&bvid=BV1LF411i768&cid=470437975&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<hr>
<h4 id="几类非光滑函数的转化"><a href="#几类非光滑函数的转化" class="headerlink" title="几类非光滑函数的转化"></a>几类非光滑函数的转化</h4><p>上一节指出，运用KKT条件时，要求函数<strong>连续可微</strong>。可有些函数很常见，但却存在不可微的点，此时就可以想办法转化下。</p>
<blockquote>
<p><strong>（1）目标函数：f(x) = max(x, x^2)</strong></p>
</blockquote>
<p><strong>即目标函数f(x)存在不可微点</strong>：简单画图可知，该函数在 (0, 0) 点和 (1, 1) 点处不可微。此时可以引入变量y，进行如下转化。</p>
<img src="/9dca7274/17.png" class>

<p>强调一下，虽然这个看着简单，但其实应用挺广，比如对如下k个线性函数求最大。</p>
<img src="/9dca7274/18.png" class>

<blockquote>
<p><strong>（2）约束条件：g(x) = |x1| + |x2| ≤ 1</strong></p>
</blockquote>
<p><strong>即约束条件g(x)存在不可微点</strong>：我们知道，绝对值函数的含义为 |x| = max(x, -x)。而g(x)中有两个绝对值，故可以如下转化。</p>
<img src="/9dca7274/19.jpg" class>

<p>可见，g(x)函数转化成了四个约束，<strong>四个约束都是线性</strong>，就可以用KKT条件了。当然，对于这种简单的形式，画图求解也许会更方便。</p>
<p>总的来说，绝对值函数的线性化较为简单，而更多的<strong>线性化方法/技巧</strong>，可以参见<a href="https://mp.weixin.qq.com/s?__biz=MzIxMDY1OTk1OA==&mid=2247483794&idx=1&sn=670cdfa59d9b07c2e64f2bbc77057b91">常见的线性化方法/技巧（上）</a>和<a href="https://mp.weixin.qq.com/s?__biz=MzIxMDY1OTk1OA==&mid=2247483819&idx=1&sn=606e949de5efea55eb310ef997379cb5">常见的线性化方法/技巧（下）</a>或者<a href="https://zhuanlan.zhihu.com/p/552076713">令人拍案叫绝的线性化方法/技巧</a>。</p>
<hr>
<h4 id="KKT条件与KT条件"><a href="#KKT条件与KT条件" class="headerlink" title="KKT条件与KT条件"></a>KKT条件与KT条件</h4><p>1951年，Kuhn和Tucker发现了KKT条件并撰写了论文将其正式发表出来，当然，此时他们不知道另一个K是谁，故命名为Kuhn-Tucker（库恩塔克）条件，也就是KT条件。</p>
<p>很快，他们的成果引起了很多很多学者的重视。树大招风，其中一些学者发现早在1939年，Karush在其<strong>硕士学位论文</strong>里边已经给出了KKT条件，只是当时没有引起广泛关注而已。</p>
<p>不过，后来大家都承认Kuhn，Tucker，Karush三位都是<strong>独立发现KKT条件</strong>的学者。故此后命名多加了个K。</p>
<hr>
<hr>
<h3 id="数值与符号运算（重点）"><a href="#数值与符号运算（重点）" class="headerlink" title="数值与符号运算（重点）"></a>数值与符号运算（重点）</h3><p>简单回顾下KKT条件：</p>
<img src="/9dca7274/20.webp" class>

<p>还记得解题思路吗？</p>
<blockquote>
<p>能解出最优解的一定是等式，故式(1-3)帮我们求最优解；<br>式(4-5)是不等式，帮我们排除一些解，或者得到最优解的适用范围。</p>
</blockquote>
<p>这也是口诀<strong>“等式求最优，不等式验证”</strong>的由来。</p>
<p>下面，我们来看下<strong>数值/符号运算</strong>中，KKT条件是如何求解最优化问题的。数值计算例子为求解<strong>最小化问题</strong>，符号运算例子为求解<strong>最大化问题</strong>。</p>
<p>先看下课本上的例题，是如何应用KKT条件进行<strong>数值计算</strong>的。</p>
<hr>
<h4 id="数值计算实操"><a href="#数值计算实操" class="headerlink" title="数值计算实操"></a>数值计算实操</h4><p>我们想用<strong>KKT条件</strong>求解如下<strong>非线性最优化问题</strong>：</p>
<img src="/9dca7274/21.jpg" class>

<p>观察约束，发现有<strong>“≥0”</strong>的形式，由本文第二三部分可知，需要统一转化为<strong>“≤0”</strong>的形式，故上述问题的<strong>标准形式</strong>为：</p>
<img src="/9dca7274/22.jpg" class>

<p>基于该标准形式，构造的<strong>拉格朗日函数</strong>为：</p>
<img src="/9dca7274/23.png" class>

<p>对其中的x1和x2分别求导，得到如下<strong>两等式</strong>：</p>
<img src="/9dca7274/24.png" class>

<p>有些同学习惯用<strong>梯度</strong>表示，也可以，<strong>两种方法一致</strong>，看大家熟悉哪种了：</p>
<img src="/9dca7274/25.png" class>

<p>数一下，有<strong>四个未知数</strong>，但求导后只有<strong>两个等式方程</strong>，显然还<strong>无法求解</strong>，此时KKT条件的核心公式**λigi=0(i=1,2)**就派上用场了。</p>
<p><strong>λigi=0（两者不同时为0）+ KKT条件中的不等式</strong>，具体含义为：</p>
<blockquote>
<p>（1）若λ1=λ2=0，则g1&lt;0，g2&lt;0；<br>（2）若λ1=0，λ2&gt;0，则g1&lt;0，g2=0；<br>（3）若λ1&gt;0，λ2=0，则g1=0，g2&lt;0；<br>（4）若λ1&gt;0，λ2&gt;0，则g1=0，g2=0；</p>
</blockquote>
<p>仔细观察上述每一种情形，均包含了<strong>两个等式方程</strong>，加上之前求导得到的<strong>两个方程</strong>，总共<strong>四个方程</strong>，这回就可以求解<strong>四个未知数</strong>了。</p>
<p>那还等啥，直接求解吧。</p>
<p><strong>（i）若λ1=λ2=0，则g1&lt;0, g2&lt;0</strong></p>
<p>无论哪种情形，主要是求解上面写的<strong>求导后的/梯度方程</strong>，即：</p>
<img src="/9dca7274/26.png" class>

<p>若λ1=λ2=0，则只需要求解x1，x2即可：</p>
<img src="/9dca7274/27.jpg" class>

<p>那x1=2，x2=1就是其中的一个解了吗？</p>
<p>赶紧背下口诀<strong>“等式求最优，不等式验证”</strong>！奥，原来还得验证下该解是否满足<strong>不等式g1&lt;0和g2&lt;0</strong>。</p>
<p>将x1=2, x2=1带入g1和g2，有：</p>
<img src="/9dca7274/28.png" class>

<p>很遗憾，两个式子都无法使得 <strong>g1&lt;0 和 g2&lt;0</strong>，故只能舍弃该解。</p>
<p><strong>此情形其实已经变为无约束问题</strong>（直接对f(X)求导后得到的解），然而它并不满足约束，只能舍弃。</p>
<p>同时也说明，最优解一定会在<strong>某个约束的边界上</strong>。那就继续吧，看看是在g1=0，还是g2=0，还是g1=g2=0的边界上。</p>
<p><strong>（ii）若λ1=0, λ2&gt;0，则g1＜0, g2=0</strong></p>
<p>除了两个求导后的方程，此情形多的两个方程分别为λ1=0和g2=0，故累计又有四个方程，求解有：</p>
<img src="/9dca7274/29.jpg" class>

<p>此时显然已经有λ2&gt;0，故仅还需验证<strong>“g1＜0”</strong>。</p>
<img src="/9dca7274/30.png" class>

<p>很可惜，不满足g1＜0，故此解还是需要<strong>舍弃</strong>。</p>
<p><strong>（iii）若λ1&gt;0, λ2=0，则g1=0, g2&lt;0</strong></p>
<p>同2，也是<strong>四个方程，求解四个未知数</strong>，有：</p>
<img src="/9dca7274/31.jpg" class>

<p>发现此解与情形1的解一样（仅是这个例子一样，一般不会一样），但带入g2函数时，有：</p>
<img src="/9dca7274/32.png" class>

<p>很可惜，依然不能使得g2&lt;0，故该解还是需要<strong>舍弃</strong>。</p>
<p><strong>（iv）若λ1&gt;0, λ2&gt;0，则g1=0, g2=0</strong></p>
<p>此时，最优解在g1和g2函数的边界上，联立的四个方程为：</p>
<img src="/9dca7274/33.jpg" class>

<p>非常好，此时的λ1&gt;0，λ2&gt;0，满足KKT条件，故x1=1, x2=2是本题的<strong>最优解</strong>。</p>
<p><strong>补充：</strong>一般四个方程，我是不会去手算的，编个简单的Matlab代码，就能快速求解：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">syms x1 x2 t1 t2  <span class="comment">% t1,t2分别指λ1,λ2</span></span><br><span class="line">equ1 = <span class="number">2</span>*x1 - <span class="number">4</span> + t1 - t2;  <span class="comment">% 将上述四个方程对照着抄一下</span></span><br><span class="line">equ2 = <span class="number">4</span>*x2 - <span class="number">4</span> + t1 - <span class="number">2</span>*t2;  <span class="comment">% 注意打上*，新手特别容易忘记</span></span><br><span class="line">equ3 = x1 + x2 - <span class="number">3</span>;</span><br><span class="line">equ4 = <span class="number">5</span> - x1 - <span class="number">2</span>*x2;</span><br><span class="line">[x1,x2,t1,t2] = solve([equ1 equ2 equ3 equ4], [x1 x2 t1 t2])</span><br></pre></td></tr></table></figure>

<p>其中，因为Matlab中不方便打λ，所以我一般用t来代替，同时解四个方程用“[]”框起来，四个变量也用“[]”框起来。“[]”在Matlab中一般用来表示<strong>数组或矩阵</strong>。solve函数就是<strong>解方程</strong>用的。</p>
<p>综上，<strong>x1=1, x2=2</strong>是本题的<strong>最优解</strong>。</p>
<hr>
<h4 id="符号运算实操"><a href="#符号运算实操" class="headerlink" title="符号运算实操"></a>符号运算实操</h4><p>下面，实操下科研中遇到<strong>有不等式约束的极值问题</strong>时，该如何<strong>利用KKT条件</strong>，并采用Matlab来<strong>编码求解</strong>。算例如下：</p>
<blockquote>
<p><strong>无约束定价问题：</strong><br>若企业生产成本为c的产品，市场<strong>需求函数为D = a - bp (a, b 是参数，p为价格)**，那企业的最优定价</strong>p**为多少？</p>
</blockquote>
<p>上面这个算例是无约束的，简单地再编两个约束吧，变为有不等式约束的问题：</p>
<blockquote>
<p><strong>有不等式约束的定价问题：</strong><br><strong>约束1（针对需求）：</strong>假定需求量小于外生变量S；<br><strong>约束2（针对价格）：</strong>企业规定价格不能低于m*c（m&gt;1）；</p>
</blockquote>
<p>则在这两个约束下，企业<strong>如何定价</strong>才能使<strong>利润最大</strong>？</p>
<p>先给出<strong>无约束问题</strong>下的解，决策最优定价p；再给出<strong>含有两个不等式约束</strong>的最优定价决策。</p>
<p><strong>（i）无约束定价问题</strong></p>
<p>此种情形较为简单，就是对利润函数（为<strong>二次函数</strong>）求最优值：</p>
<img src="/9dca7274/34.jpg" class>

<p>具体的Matlab计算代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear</span><br><span class="line">syms a b c p</span><br><span class="line">Pi = (p - c)*(a - b*p);</span><br><span class="line">equ = diff(Pi, p);  <span class="comment">% 对利润函数Pi中的p求导</span></span><br><span class="line">Op_p = solve(equ, p);  <span class="comment">% 求解方程equ=0中的p，命名为Op_p</span></span><br><span class="line">Op_D = simplify(a - b*Op_p);  <span class="comment">% 反代回需求函数，并化简</span></span><br></pre></td></tr></table></figure>

<p>其中牵扯到的<strong>diff()、solve()、simplify()以及后面会提及的subs()函数</strong>，含义分别为<strong>求导、解方程、化简、替换</strong>。</p>
<p><strong>（ii）有不等式约束的定价问题</strong></p>
<p>这里新增了两个约束：<br><strong>约束1(针对需求)：</strong>假定需求量小于外生变量S：</p>
<img src="/9dca7274/35.png" class>
<p><strong>约束2(针对价格)：</strong>企业规定价格不能低于m*c（m&gt;1）：</p>
<img src="/9dca7274/36.png" class>

<p>综上，我们有如下优化问题（<strong>写成最大化问题的标准形式</strong>）：</p>
<img src="/9dca7274/37.jpg" class>

<p><strong>注意</strong>，这里与<strong>数值算例的最小化问题</strong>不同，该问题是<strong>最大化问题</strong>，因此需将约束全部转化为<strong>“≥0”</strong>的形式，并命名为<strong>g1、g2</strong>。</p>
<p>还记得第一步是什么吗？基于<strong>标准形式</strong>，构造<strong>拉格朗日函数</strong>：</p>
<img src="/9dca7274/38.png" class>

<p>决策变量只有<strong>p</strong>，故仅<strong>对p求导</strong>即可：</p>
<img src="/9dca7274/39.png" class>

<p>显然，这里仅有<strong>一个方程</strong>，要解出p、λ1、λ2<strong>三个未知数</strong>是不可能的，还需要<strong>两个等式方程</strong>。而<strong>KKT条件</strong>就是用来给出<strong>剩下的两个等式方程</strong>的。</p>
<p>这里附上上述过程的Matlab代码（为方便敲代码，依旧用t来代替λ）：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear</span><br><span class="line">syms a b c m p S t1 t2  <span class="comment">% 定义需要用到的所有参数/变量</span></span><br><span class="line"><span class="comment">% 构造拉格朗日函数</span></span><br><span class="line">L = (p-c)*(a-b*p) + t1*(S-a+b*p) + t2*(p-m*c);</span><br><span class="line"><span class="comment">% 对L中的决策变量p求导，命名为Equ</span></span><br><span class="line">Equ = diff(L, p);</span><br><span class="line"><span class="comment">% 记录一下Equ的表达式，后面要用</span></span><br><span class="line">Equ = a + t2 - <span class="number">2</span>*b*p + b*t1 + b*c;</span><br></pre></td></tr></table></figure>

<p>为方便后续计算，这里汇总下<strong>后面分类讨论时</strong>，会反复用到的几个表达式：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear</span><br><span class="line">syms a b c m p S t1 t2</span><br><span class="line"><span class="comment">% 1：利润函数表达式</span></span><br><span class="line">Pi = (p - c)*(a - b*p);</span><br><span class="line"><span class="comment">% 2：求导后的拉格朗日函数表达式</span></span><br><span class="line">Equ = a + t2 - <span class="number">2</span>*b*p + b*t1 + b*c;</span><br><span class="line"><span class="comment">% 3：两个约束条件的表达式</span></span><br><span class="line">g1 = S - a + b*p;</span><br><span class="line">g2 = p - m*c;</span><br></pre></td></tr></table></figure>

<p><strong>综上，求导后的拉格朗日函数（Equ）含有p、λ1、λ2三个未知数，接下来分类讨论的目的，就是利用KKT条件，解这三个未知数。</strong>已经有<strong>Equ=0方程</strong>了，剩下的<strong>两个等式方程</strong>，分以下<strong>四种情况</strong>讨论吧。</p>
<blockquote>
<p><strong>情形1：若λ1=λ2=0，则g1&gt;0，g2&gt;0</strong></p>
</blockquote>
<p>注意，这里与第一部分数值算例中的“g1&lt;0, g2&lt;0”不同，这里是<strong>最大化问题</strong>。也许有同学已经发现了，这其实就是<strong>无约束问题</strong>（两个约束均没有起作用），得到的最优解即为之前的<strong>p*=(a+bc)/2b</strong>。</p>
<p>还记得口诀吗？<strong>等式求最优，不等式验证</strong>。所以，剩下的就是检验该解是否满足g1&gt;0，g2&gt;0。</p>
<p>因此，Matlab代码编写也分两步。先给出此种情形下如何计算<strong>最优p和最大利润</strong>，再计算得到该解<strong>需满足的条件</strong>。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">%% 情形1：当t1=t2=0时，g1&gt;0, g2&gt;0</span></span><br><span class="line">equ = subs(Equ, [t1, t2], [<span class="number">0</span>, <span class="number">0</span>]);  <span class="comment">% 将t1=0, t2=0代入Equ函数</span></span><br><span class="line">Op_p = solve(equ, p)  <span class="comment">% 求最优p</span></span><br><span class="line">Pi = simplify(subs(Pi, p, Op_p))  <span class="comment">% 求最优利润并化简</span></span><br></pre></td></tr></table></figure>

<p>时刻记住：<strong>在做符号运算时，求得的每一个解，都是有条件的。</strong>那么该解的条件是什么呢，就是g1&gt;0，g2&gt;0。既然<strong>S</strong>和<strong>m</strong>是我们新引进的<strong>参数</strong>，那么我们就来看看它俩<strong>需满足什么条件</strong>。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 将上述最优解代入g1，g2函数</span></span><br><span class="line">g1 = subs(g1, p, Op_p)  <span class="comment">% 将g1函数中的p，用Op_p的表达式代替</span></span><br><span class="line">g2 = subs(g2, p, Op_p)</span><br><span class="line"><span class="comment">% 解出g1&lt;0和g2&lt;0时，S和m需要满足的条件</span></span><br><span class="line">solve(g1, S)</span><br><span class="line">solve(g2, m)</span><br></pre></td></tr></table></figure>

<p>代码中solve函数解出来的解，就是S和m需要满足的条件。</p>
<p>汇总下，就是只有<strong>当S和m满足如下条件时，才会得到如下最优解</strong>：</p>
<img src="/9dca7274/40.jpg" class>

<blockquote>
<p><strong>情形2：若λ1=0，λ2&gt;0，则g1&gt;0，g2=0</strong></p>
</blockquote>
<p>此时由于g2=p-mc=0，故最优解就是<strong>p*=mc</strong>；将其带入利润函数，便得到<strong>最优利润表达式</strong>。</p>
<p>当然，还需要看下想得到这个解，需要<strong>满足的条件</strong>，即：λ2&gt;0，且g1&gt;0。将λ1=0，p*=mc带入<strong>求导后的拉格朗日函数函数Equ</strong>，可以计算得到<strong>λ2</strong>的值，令其<strong>&gt;0</strong>，加上<strong>g1&lt;0</strong>的约束，便能最终该最优解<strong>适用范围</strong>。代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">%% 情形2：当t1=0，t2&gt;0时，g1&gt;0, g2=0</span></span><br><span class="line"><span class="comment">% 先记录下需要用到几个函数表达式</span></span><br><span class="line">clear</span><br><span class="line">syms a b c m p S t1 t2</span><br><span class="line">Pi = (p - c)*(a - b*p);</span><br><span class="line">Equ = a + t2 - <span class="number">2</span>*b*p + b*t1 + b*c;</span><br><span class="line">g1 = S - a + b*p;</span><br><span class="line">​</span><br><span class="line">equ1 = subs(Equ, [t1 p], [<span class="number">0</span>, m*c]);  <span class="comment">% 将t1=0，p=mc带入Equ</span></span><br><span class="line">equ2 = subs(g1, p, m*c);  <span class="comment">% 将p=mc带入g1约束</span></span><br><span class="line">Pi = simplify(subs(Pi, p, m*c));  <span class="comment">% 将p=mc带入利润函数并化简</span></span><br><span class="line">​</span><br><span class="line"><span class="comment">% 解出t2&gt;0和g1&gt;0时，S和m的范围</span></span><br><span class="line">t2 = solve(equ1, t2);  <span class="comment">% 通过equ1=0解出t2表达式</span></span><br><span class="line">solve(t2, m)  <span class="comment">% 令t2=0，用m来表示</span></span><br><span class="line">solve(equ2, S)  <span class="comment">% 令equ2=0, 用S来表示</span></span><br></pre></td></tr></table></figure>

<p>最后两行代码得到的解，就是为得到情形2下的最优解，需要满足的条件，汇总有：</p>
<img src="/9dca7274/41.png" class>

<blockquote>
<p><strong>情形3：若λ1&gt;0，λ2=0，则g1=0，g2&gt;0</strong></p>
</blockquote>
<p>此时由于g1 = S-a+bp = 0，故最优解就是<strong>p* = (a-S)/b</strong>；将其带入利润函数，便得到<strong>最优利润表达式</strong>。</p>
<p>再次回忆口诀：<strong>不等式验证</strong>。该情形还需要<strong>满足的条件</strong>，为：<strong>λ1&gt;0，且g2&gt;0</strong>。</p>
<p>将λ2=0，p* = (a-S)/b带入Equ，可以计算得到<strong>λ1</strong>的值，令其<strong>&gt;0</strong>，加上<strong>g2&gt;0</strong>的约束，便能最终该最优解<strong>适用范围</strong>。代码如下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">%% 情形3：当t1&gt;0，t2=0时，g1=0, g2&gt;0</span></span><br><span class="line"><span class="comment">% 先记录下需要用到几个函数表达式</span></span><br><span class="line">clear</span><br><span class="line">syms a b c m p S t1 t2</span><br><span class="line">Pi = (p - c)*(a - b*p);</span><br><span class="line">Equ = a + t2 - <span class="number">2</span>*b*p + b*t1 + b*c;</span><br><span class="line">g2 = p - m*c;</span><br><span class="line">​</span><br><span class="line">equ1 = subs(Equ, [t2 p], [<span class="number">0</span>, (a-S)/b]);  <span class="comment">% 将t2=0，p=(a-S)/b带入Equ</span></span><br><span class="line">equ2 = subs(g2, p, (a-S)/b);  <span class="comment">% 将p=(a-S)/b带入g2约束</span></span><br><span class="line">Pi = simplify(subs(Pi, p, (a-S)/b));  <span class="comment">% 将p=(a-S)/b带入利润函数</span></span><br><span class="line">​</span><br><span class="line"><span class="comment">% 解出t1&gt;0和g2&gt;0时，S和m的范围</span></span><br><span class="line">t1 = solve(equ1, t1);  <span class="comment">% 通过equ1=0解出t1表达式</span></span><br><span class="line">solve(t1, S)  <span class="comment">% 令t2=0，用S来表示</span></span><br><span class="line">solve(equ2, m)  <span class="comment">% 令equ2=0, 用S来表示</span></span><br></pre></td></tr></table></figure>

<p>汇总代码计算结果，有：</p>
<img src="/9dca7274/42.jpg" class>

<blockquote>
<p><strong>情形4：若λ1&gt;0，λ2&gt;0，则g1=0，g2=0</strong></p>
</blockquote>
<p>该情形下的最优解就是求解三方程Equ=0，g1=0，g2=0下的p、λ1、λ2值。</p>
<p>由于两个约束都是关于p的一次函数，因此会得到<strong>矛盾的结论</strong>，故此种情形舍弃。</p>
<img src="/9dca7274/43.jpg" class>

<p>需要说明的是，科研中的很多问题会<strong>同时决策两个变量</strong>，或者有<strong>非线性的约束</strong>等，此时两个约束均取“=”是<strong>有解</strong>的。我这个算例编的简单了，造成该种情形无解。</p>
<p><strong>（iii）最优值间的相互比较</strong></p>
<p>上述4种情形，3种情形均有最优解。很显然，工作还没做完，我们真正想得到的是<strong>哪些参数条件下，最优定价和最大利润是多少？</strong></p>
<p>如果是<strong>数值算例</strong>，很简单直观，拿着每种情形下的最大利润比较下即可。</p>
<p>但<strong>符号运算</strong>就不得不<strong>分类讨论</strong>，很多时候，我们甚至连<strong>某个表达式的正负号</strong>都无法确定。</p>
<p>但大家也不用太担心相互比较会很麻烦。因为，<strong>只看利润的话，真正需要比较的，其实只有情形2和情形3下的利润大小</strong>。聪明的你知道这是为什么吗？</p>
<blockquote>
<p><strong>答案揭晓：</strong><br>情形1是无约束极值问题，相当于<strong>全域搜索最优解</strong>，其利润一定是<strong>最大的</strong>；情形2和3下的最优解，均受到了<strong>一个</strong>约束g=0的<strong>硬性限制</strong>，利润一定会小一点；而情形4限制更强，要求<strong>两个约束均为0</strong>，这样再去求利润，一定是最小的。</p>
</blockquote>
<p>因此，在情形1的参数范围内，它就是老大，没必要跟它比了。所以，重点还是落在情形2和情形3的参数范围内，到底谁利润更大。</p>
<p>为方便阅读，避免前后翻看，情形2和情形3的结论汇总如下。</p>
<img src="/9dca7274/44.webp" class>

<p>上述一通分析下来，其实也很简单嘛，将两利润做差，即Pi2 - Pi3，再看看正负号呗。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 比较情形2和情形3下的利润</span></span><br><span class="line">clear</span><br><span class="line">syms a b c m S</span><br><span class="line">Pi2 = c*(a - b*c*m)*(m<span class="number">-1</span>);  <span class="comment">% 情形2下的最优利润</span></span><br><span class="line">Pi3 = -S*(c+(S-a)/b);  <span class="comment">% 情形3下的最优利润</span></span><br><span class="line">​</span><br><span class="line">del_Pi = collect(Pi2 - Pi3, S)  <span class="comment">% 将两式作差，并以S的降序排列</span></span><br><span class="line">del_Pi = S^<span class="number">2</span>/b + (c-a/b)*S + c*(a-b*c*m)*(m<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>

<p>这里用到了<strong>collect()函数</strong>，真的非常好用，大家一定要记住这个函数。</p>
<p>官方说collect是<strong>合并同类项函数</strong>，但我建议大家这样记忆：<strong>collect(f, x)就是将f函数以x的从高到低次项依次展开</strong>。如上述代码最后一行，就是以<strong>S的二次项，S的一次项，S的常数项</strong>依次展开。</p>
<p>这样有什么好处？那可太有用了，我们做科研时，一旦发现表达式是关于某参数的，<strong>3次甚至4次项</strong>后，建议换个参数或者换条思路求解吧。</p>
<p>因为求解三次函数的<strong>卡丹公式</strong>非常长，不适用于论文。而求解二次函数，<strong>韦达定理</strong>大家都是会的。</p>
<p>回到正文，观察差值<strong>del_Pi</strong>函数，是关于S的<strong>二次函数</strong>，开头向上，截距、对称轴均为正，且有两个解，分别为：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">solve(del_Pi, S);  <span class="comment">% 求解方程del=0的两个解</span></span><br><span class="line">S1 = b*c*m - b*c;  S2 = a - b*c*m</span><br></pre></td></tr></table></figure>

<p>紧接着，这两个解谁大呢？再做差呗。看看和m的关系。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">del_S = S1 - S2;</span><br><span class="line">solve(del_S, m)</span><br><span class="line"><span class="comment">% 求解得到 m &gt; (a + b*c)/(2*b*c)</span></span><br></pre></td></tr></table></figure>

<p>而 m &gt; (a+b*c)/(2*b*c)，恰好就是情形2下m的取值范围，故 S1 &gt; S2。那基于此，我们可以画出del_Pi = Pi2 - Pi3的图像如下。</p>
<img src="/9dca7274/45.jpg" class>

<blockquote>
<p>当0 &lt; S &lt; bcm-bc时，Pi2 &lt; Pi3；<br>当bcm-bc &lt; S &lt; (a-bc)/2时，Pi2 &gt; Pi3;<br>当(a-bc)/2 &lt; S时，不用算了，Pi1最大。</p>
</blockquote>
<p>细心的小伙伴也许会说，上面的第一个范围有问题。当 0 &lt; S &lt; a - bcm 时，不应该是 Pi2 &gt; Pi3 吗？从图像上看，确实是的，但是别忘了，情形2中的 S 取值，是要<strong>“&gt; a - bcm”</strong>的。所以当 0 &lt; S &lt; a - bcm 时，Pi2压根就没有图像。</p>
<p>至此，所有的问题就都分析完了。如果上述有错误，望大家批评指正。核心思想是<strong>会用KKT条件分类讨论</strong>，并会<strong>比较不同情形间的最优利润</strong>。</p>
<hr>
<hr>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>总结下本文的核心：</p>
<ol>
<li>KKT条件是拉格朗日乘数法的推广，理解引入λi的原因及作用；</li>
<li>理解λg(X*)=0，就理解了KKT条件的精髓；</li>
<li>掌握采用图示法分析f(X)和g(X)的梯度关系。</li>
<li>数值算例中，在运用KKT条件时，很容易发现矛盾（不满足条件）的解，也很容易比较多个解的大小；</li>
<li>符号运算时，若不考虑参数范围，四种情形下的利润大小关系一定有：情形1 &gt; 情形2、3 &gt; 情形4；</li>
<li>比较利润大小时，最好寻求其关于某个参数的一次或二次函数关系，切忌使用高次项参数。</li>
</ol>
<p>为了方便大家记忆KKT条件的求解步骤，编了个口诀，希望能对大家有所帮助：</p>
<blockquote>
<p>大大小小<br>等式求最优，不等式验证</p>
</blockquote>
<p><strong>“大大小小”含义：</strong>在建立拉格朗日函数前，需要整理成<strong>标准形式</strong>。对于<strong>最大化问题</strong>，约束整理成<strong>“≥0”</strong>形式；对于<strong>最小化问题</strong>，约束整理成<strong>“≤0”</strong>形式。</p>
<p>别看写了不少，其实就记住这<strong>两行口诀</strong>就行。怎么样，是不是感觉KKT条件也不难嘛。</p>
<p>其实，还有拉格朗日乘子的敏感性分析没讲，这和<strong>对偶理论</strong>有关，篇幅有限，也较难，不再展开。</p>
<hr>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/556832103">https://zhuanlan.zhihu.com/p/556832103</a></p>
</blockquote>
]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐最优化理论</category>
      </categories>
  </entry>
  <entry>
    <title>算法作业-SoCodingOJ研一上算法课</title>
    <url>/f0fd6226.html</url>
    <content><![CDATA[<h3 id="Problem-P01-算法课分治-最大二叉树"><a href="#Problem-P01-算法课分治-最大二叉树" class="headerlink" title="Problem P01. [算法课分治] 最大二叉树"></a>Problem P01. [算法课分治] 最大二叉树</h3><p>给定一个<strong>不含重复元素</strong>的整数数组 nums。以此数组直接递归构建的最大二叉树。最大二叉树定义如下：</p>
<ul>
<li>二叉树的根是数组 nums 中的最大元素。</li>
<li>左子树是通过数组中最大值左边部分递归构造出的最大二叉树。</li>
<li>右子树是通过数组中最大值右边部分递归构造出的最大二叉树。</li>
</ul>
<p>返回有给定数组 nums 构建的最大二叉树。</p>
<h4 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h4><p>输入一行多个数字代表数组 nums。数字与数字之间用空格隔开。</p>
<p>以 EOF 作为结束输入（请参考 SCNUOJ 1001 题题解了解如何处理输入）。</p>
<ul>
<li>1 ≤ nums.length ≤ 1000</li>
<li>0 ≤ nums[i] ≤ 1000</li>
<li>nums中的所有整数互不相同</li>
</ul>
<span id="more"></span>

<h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><p>输出一行字符代表二叉树的构造结果（前序遍历），具体请参考样例</p>
<h4 id="样例"><a href="#样例" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">3 2 1 6 0 5</span><br><span class="line">标准输出：</span><br><span class="line">6 3 null 2 null 1 5 0 null </span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">3 2 1</span><br><span class="line">标准输出：</span><br><span class="line">3 null 2 null 1</span><br></pre></td></tr></table></figure>

<h4 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_max</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)):</span><br><span class="line">        <span class="keyword">if</span> a[i] == <span class="built_in">max</span>(a):</span><br><span class="line">            <span class="keyword">return</span> i, a[i]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>(<span class="params">a</span>):</span></span><br><span class="line">    i, Max = find_max(a)</span><br><span class="line">    res.append(Max)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(a) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        res.append(<span class="string">&quot;null&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        func(a[:i])</span><br><span class="line">    <span class="keyword">if</span> i == <span class="built_in">len</span>(a) - <span class="number">1</span>:</span><br><span class="line">        res.append(<span class="string">&quot;null&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        func(a[i + <span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num)):</span><br><span class="line">    num[i] = <span class="built_in">int</span>(num[i])</span><br><span class="line"></span><br><span class="line">res = []</span><br><span class="line">func(num)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(res)):</span><br><span class="line">    res[i] = <span class="built_in">str</span>(res[i])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(res))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P02-算法课分治-寻找多数"><a href="#Problem-P02-算法课分治-寻找多数" class="headerlink" title="Problem P02. [算法课分治] 寻找多数"></a>Problem P02. [算法课分治] 寻找多数</h3><p>给定一个大小为 n 的整型数组 a，找到其中的多数元素，多数元素是指在数组中出现次数大于 ⌊n/2⌋ 的元素。</p>
<h4 id="输入-1"><a href="#输入-1" class="headerlink" title="输入"></a>输入</h4><p>第一行输入一个整数 n (1 ≤ n ≤ 10^4) 代表数组的长度。</p>
<p>第二行输入一行数字代表数组 a (1 ≤ a_i ≤ 10^4)，数字与数字之间用空格间开。</p>
<p>保证给定的数组总是存在多数元素。</p>
<h4 id="输出-1"><a href="#输出-1" class="headerlink" title="输出"></a>输出</h4><p>输出一个整数代表数组的多数元素。</p>
<h4 id="样例-1"><a href="#样例-1" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">3</span><br><span class="line">1 1 1</span><br><span class="line">标准输出：</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">7</span><br><span class="line">4 1 2 3 3 3 3</span><br><span class="line">标准输出：</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">9</span><br><span class="line">4 2 2 2 2 21 23 23 2</span><br><span class="line">标准输出：</span><br><span class="line">2</span><br></pre></td></tr></table></figure>

<h4 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h4><p>如果数 a 是数组 n 的众数，如果我们将 n 分成两部分，那么 a 必定是至少一部分的众数。</p>
<h4 id="解答-1"><a href="#解答-1" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = <span class="built_in">input</span>()</span><br><span class="line">num = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num)):</span><br><span class="line">    num[i] = <span class="built_in">int</span>(num[i])</span><br><span class="line"></span><br><span class="line">num.sort()</span><br><span class="line"><span class="built_in">print</span>(num[<span class="built_in">len</span>(num) // <span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P03-算法课分治-找到最大子序和"><a href="#Problem-P03-算法课分治-找到最大子序和" class="headerlink" title="Problem P03. [算法课分治] 找到最大子序和"></a>Problem P03. [算法课分治] 找到最大子序和</h3><p>给定一个整数数组 nums，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。</p>
<h4 id="输入-2"><a href="#输入-2" class="headerlink" title="输入"></a>输入</h4><p>第一行输入一个整数 nums.length 代表数组的长度</p>
<p>第二行输入一行数字代表数组 nums，数字与数字之间用空格间开</p>
<ul>
<li>1 ≤ nums.length ≤ 3 × 10^4</li>
<li>-100000 ≤ nums[i] ≤ 100000</li>
</ul>
<h4 id="输出-2"><a href="#输出-2" class="headerlink" title="输出"></a>输出</h4><p>输出一个整数代表子序列最大和</p>
<h4 id="样例-2"><a href="#样例-2" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">9</span><br><span class="line">-2 1 -3 4 -1 2 1 -5 4</span><br><span class="line">标准输出：</span><br><span class="line">6</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1</span><br><span class="line">1</span><br><span class="line">标准输出：</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1</span><br><span class="line">0</span><br><span class="line">标准输出：</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<h4 id="提示-1"><a href="#提示-1" class="headerlink" title="提示"></a>提示</h4><p>第一个样例解释：连续子数组 [4, -1, 2, 1] 的和最大，为 6。</p>
<h4 id="解答-2"><a href="#解答-2" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = <span class="built_in">input</span>()</span><br><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">pre = <span class="number">0</span></span><br><span class="line">maxAns = arr[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">    pre = <span class="built_in">max</span>(pre + i, i)</span><br><span class="line">    maxAns = <span class="built_in">max</span>(maxAns, pre)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(maxAns)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P04-算法课分治-找到-k-个最小数"><a href="#Problem-P04-算法课分治-找到-k-个最小数" class="headerlink" title="Problem P04. [算法课分治] 找到 k 个最小数"></a>Problem P04. [算法课分治] 找到 k 个最小数</h3><p>输入整数数组 arr，找出其中最小的 k 个数。</p>
<h4 id="输入-3"><a href="#输入-3" class="headerlink" title="输入"></a>输入</h4><p>第一行输入两个整数，第一个代表数组的长度，第二个代表 k，数字与数字之间用空格间开</p>
<p>第二行输入一行数字代表数组 arr。数字与数字之间用空格间开</p>
<ul>
<li>0 ≤ k ≤ arr.length ≤ 10000</li>
<li>0 ≤ arr[i] ≤ 10000</li>
</ul>
<h4 id="输出-3"><a href="#输出-3" class="headerlink" title="输出"></a>输出</h4><p>输出一行整数，表示最小的 k 个数。数字与数字之间用空格间开</p>
<h4 id="样例-3"><a href="#样例-3" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">3 2</span><br><span class="line">3 2 1</span><br><span class="line">标准输出：</span><br><span class="line">1 2</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">4 1</span><br><span class="line">0 0 1 1</span><br><span class="line">标准输出：</span><br><span class="line">0</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">4 2</span><br><span class="line">1 1 3 4</span><br><span class="line">标准输出：</span><br><span class="line">1 1</span><br></pre></td></tr></table></figure>

<h4 id="解答-3"><a href="#解答-3" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = <span class="built_in">input</span>().split()</span><br><span class="line">k = <span class="built_in">int</span>(temp[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">arr.sort()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    <span class="keyword">if</span> i &gt;= k:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="built_in">print</span>(arr[i], end=<span class="string">&quot; &quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P05-算法课分治-寻找第-k-个最大元素"><a href="#Problem-P05-算法课分治-寻找第-k-个最大元素" class="headerlink" title="Problem P05. [算法课分治] 寻找第 k 个最大元素"></a>Problem P05. [算法课分治] 寻找第 k 个最大元素</h3><p>给定整数数组 nums 和整数 k，请找到数组中第 k 个最大的元素。</p>
<h4 id="输入-4"><a href="#输入-4" class="headerlink" title="输入"></a>输入</h4><p>第一行输入两个整数，第一个代表数组的长度，第二个代表 k，数字与数字之间用空格间开</p>
<p>第二行输入一行数字代表数组 nums。数字与数字之间用空格间开</p>
<ul>
<li>1 ≤ k ≤ nums.length ≤ 1000</li>
<li>-1000 ≤ nums[i] ≤ 1000</li>
</ul>
<h4 id="输出-4"><a href="#输出-4" class="headerlink" title="输出"></a>输出</h4><p>输出一个整数代表第 k 个最大元素</p>
<h4 id="样例-4"><a href="#样例-4" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">6 2</span><br><span class="line">3 2 1 5 6 4</span><br><span class="line">标准输出：</span><br><span class="line">5</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">9 4</span><br><span class="line">3 2 3 1 2 4 5 5 6</span><br><span class="line">标准输出：</span><br><span class="line">4</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="解答-4"><a href="#解答-4" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = <span class="built_in">input</span>().split()</span><br><span class="line">k = <span class="built_in">int</span>(temp[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">arr.sort()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(arr[-k])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P06-算法课分治-找到-k-个最长重复字符串"><a href="#Problem-P06-算法课分治-找到-k-个最长重复字符串" class="headerlink" title="Problem P06. [算法课分治] 找到 k 个最长重复字符串"></a>Problem P06. [算法课分治] 找到 k 个最长重复字符串</h3><p>在一个字符串 s 中找出 s 中的最长子串，且该字符串的每一个字符出现次数都不少于 k。输出该子串的长度。</p>
<h4 id="输入-5"><a href="#输入-5" class="headerlink" title="输入"></a>输入</h4><p>第一行有两个输入，第一个输入一串字符串 s，第二个输入整数代表 k，两个输入之间用空格隔开</p>
<ul>
<li>1 ≤ s.length ≤ 10000</li>
<li>s 仅由小写英文字母组成</li>
<li>0 ≤ k ≤ 1000</li>
</ul>
<h4 id="输出-5"><a href="#输出-5" class="headerlink" title="输出"></a>输出</h4><p>输出一个整数，表示该子串的长度</p>
<h4 id="样例-5"><a href="#样例-5" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">aaabb 3</span><br><span class="line">标准输出：</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">ababbc 2</span><br><span class="line">标准输出：</span><br><span class="line">5</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">abcde 2</span><br><span class="line">标准输出：</span><br><span class="line">0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="提示-2"><a href="#提示-2" class="headerlink" title="提示"></a>提示</h4><p>第一个样例解释：最长子串为 aaa，其中 a 重复了 3 次。</p>
<h4 id="解答-5"><a href="#解答-5" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = <span class="built_in">input</span>().split()</span><br><span class="line">arr = temp[<span class="number">0</span>]</span><br><span class="line">k = <span class="built_in">int</span>(temp[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">longestSubstring</span>(<span class="params">arr, k</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> arr:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">set</span>(arr):</span><br><span class="line">        <span class="keyword">if</span> arr.count(c) &lt; k:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(longestSubstring(t, k) <span class="keyword">for</span> t <span class="keyword">in</span> arr.split(c))</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(arr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(longestSubstring(arr, k))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P07-算法课分治-链表排序"><a href="#Problem-P07-算法课分治-链表排序" class="headerlink" title="Problem P07. [算法课分治] 链表排序"></a>Problem P07. [算法课分治] 链表排序</h3><p>请将链表按<strong>升序</strong>排列并返回排序后的链表。测试用例的链表不为空。 其中 ListNode 的数据结构</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> val;</span><br><span class="line">    ListNode *next;</span><br><span class="line">    <span class="built_in">ListNode</span>() : <span class="built_in">val</span>(<span class="number">0</span>), <span class="built_in">next</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">    <span class="built_in">ListNode</span>(<span class="keyword">int</span> x) : <span class="built_in">val</span>(x), <span class="built_in">next</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">    <span class="built_in">ListNode</span>(<span class="keyword">int</span> x, ListNode *next) : <span class="built_in">val</span>(x), <span class="built_in">next</span>(next) &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="输入-6"><a href="#输入-6" class="headerlink" title="输入"></a>输入</h4><p>输入一行数字表示链表数据，数字与数字之间空格隔开。</p>
<p>以 EOF 作为结束输入（请参考 SCNUOJ 1001 题题解了解如何处理输入）。</p>
<ul>
<li>链表中节点的数目在范围 [0, 5×10^4] 内</li>
<li>−10000 ≤ Node.val ≤ 10000</li>
</ul>
<h4 id="输出-6"><a href="#输出-6" class="headerlink" title="输出"></a>输出</h4><p>输出一行数字代表排序后的链表，数字与数字之间空格隔开</p>
<h4 id="样例-6"><a href="#样例-6" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">4 2 1 3</span><br><span class="line">标准输出：</span><br><span class="line">1 2 3 4</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">-1 5 3 4 0</span><br><span class="line">标准输出：</span><br><span class="line">-1 0 3 4 5</span><br></pre></td></tr></table></figure>

<h4 id="解答-6"><a href="#解答-6" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">arr.sort()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">str</span>(arr[i])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(arr))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P08-算法课蛮力法-柠檬水找零"><a href="#Problem-P08-算法课蛮力法-柠檬水找零" class="headerlink" title="Problem P08. [算法课蛮力法] 柠檬水找零"></a>Problem P08. [算法课蛮力法] 柠檬水找零</h3><p>在柠檬水摊上，每一杯柠檬水的售价为 5 美元。顾客排队购买你的产品，（按账单 bills 支付的顺序）一次购买一杯。</p>
<p>每位顾客只买一杯柠檬水，然后向你付 5 美元、10 美元或 20 美元。你必须给每个顾客正确找零，也就是说净交易是每位顾客向你支付 5 美元。</p>
<p>注意，一开始你手头没有任何零钱。</p>
<p>给你一个整数数组 bills，其中 bills[i] 是第 i 位顾客付的账。如果你能给每位顾客正确找零，输出 true，否则输出 false。</p>
<h4 id="输入-7"><a href="#输入-7" class="headerlink" title="输入"></a>输入</h4><p>输入一行数字表示链表数据，数字与数字之间空格隔开。</p>
<p>以 EOF 作为结束输入（请参考 SCNUOJ 1001 题题解了解如何处理输入）。</p>
<ul>
<li>1 ≤ bills.length ≤ 10^5</li>
<li>bills[i] 不是 5 就是 10 或是 20</li>
</ul>
<h4 id="输出-7"><a href="#输出-7" class="headerlink" title="输出"></a>输出</h4><p>如果你能给每位顾客正确找零，输出 true，否则输出 false</p>
<h4 id="样例-7"><a href="#样例-7" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">5 5 5 10 20</span><br><span class="line">标准输出：</span><br><span class="line">true</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">5 5 10 10 20</span><br><span class="line">标准输出：</span><br><span class="line">false</span><br></pre></td></tr></table></figure>

<h4 id="解答-7"><a href="#解答-7" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">earn = <span class="number">0</span></span><br><span class="line">boolean = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">    earn -= i - <span class="number">5</span></span><br><span class="line">    <span class="keyword">if</span> earn &lt; <span class="number">0</span>:</span><br><span class="line">        boolean = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    earn += <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> boolean:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;true&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;false&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P09-算法课动态规划-换硬币"><a href="#Problem-P09-算法课动态规划-换硬币" class="headerlink" title="Problem P09. [算法课动态规划] 换硬币"></a>Problem P09. [算法课动态规划] 换硬币</h3><p>给定面值分别为2，5，7的硬币，每种硬币有无限个，给定一个N，求组成N最少需要的硬币的数量，若无法组成则返回-1.</p>
<h4 id="输入-8"><a href="#输入-8" class="headerlink" title="输入"></a>输入</h4><p>输入N (1 &lt;= N &lt;= 100)</p>
<h4 id="输出-8"><a href="#输出-8" class="headerlink" title="输出"></a>输出</h4><p>输出需要的最少硬币个数</p>
<h4 id="样例-8"><a href="#样例-8" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">5</span><br><span class="line">标准输出：</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">11</span><br><span class="line">标准输出：</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">27</span><br><span class="line">标准输出：</span><br><span class="line">5</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="提示-3"><a href="#提示-3" class="headerlink" title="提示"></a>提示</h4><p>由后往前推理判断更加容易</p>
<h4 id="解答-8"><a href="#解答-8" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">coins = [<span class="number">2</span>, <span class="number">5</span>, <span class="number">7</span>]</span><br><span class="line">num = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"></span><br><span class="line">dp = [<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)] * (num + <span class="number">1</span>)</span><br><span class="line">dp[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> coin <span class="keyword">in</span> coins:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(coin, num + <span class="number">1</span>):</span><br><span class="line">        dp[i] = <span class="built_in">min</span>(dp[i], dp[i-coin] + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dp[num] <span class="keyword">if</span> dp[num] != <span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>) <span class="keyword">else</span> -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P10-算法课动态规划-走网格"><a href="#Problem-P10-算法课动态规划-走网格" class="headerlink" title="Problem P10. [算法课动态规划]走网格"></a>Problem P10. [算法课动态规划]走网格</h3><p>m行n列的网格，从左上角（1，1）出发，每一步只能向下或者向右，问共有多少种方法可以走到右下角（m,n);</p>
<h4 id="输入-9"><a href="#输入-9" class="headerlink" title="输入"></a>输入</h4><p>输入参数 m n (1&lt;=m&lt;=10 1&lt;=n&lt;=10)</p>
<h4 id="输出-9"><a href="#输出-9" class="headerlink" title="输出"></a>输出</h4><p>输出多少种走法</p>
<h4 id="样例-9"><a href="#样例-9" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">2 3</span><br><span class="line">标准输出：</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">5 5</span><br><span class="line">标准输出：</span><br><span class="line">70</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="解答-9"><a href="#解答-9" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">m = arr[<span class="number">0</span>]</span><br><span class="line">n = arr[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">dp = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">    dp.append([<span class="number">1</span>] * n)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        dp[i][j] = dp[i - <span class="number">1</span>][j] + dp[i][j - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dp[m - <span class="number">1</span>][n - <span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P11-算法课动态规划-爬楼梯"><a href="#Problem-P11-算法课动态规划-爬楼梯" class="headerlink" title="Problem P11. [算法课动态规划]爬楼梯"></a>Problem P11. [算法课动态规划]爬楼梯</h3><p>假设你正在爬楼梯。需要 n 阶你才能到达楼顶。(n是正整数)每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？</p>
<h4 id="输入-10"><a href="#输入-10" class="headerlink" title="输入"></a>输入</h4><p>第一行输入阶数n (1 &lt;= n &lt;= 20)</p>
<h4 id="输出-10"><a href="#输出-10" class="headerlink" title="输出"></a>输出</h4><p>输出总共多少种走法</p>
<h4 id="样例-10"><a href="#样例-10" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">3</span><br><span class="line">标准输出：</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">5</span><br><span class="line">标准输出：</span><br><span class="line">8</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">15</span><br><span class="line">标准输出：</span><br><span class="line">987</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="提示-4"><a href="#提示-4" class="headerlink" title="提示"></a>提示</h4><p>斐波那契数列</p>
<h4 id="解答-10"><a href="#解答-10" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> num == <span class="number">1</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">elif</span> num == <span class="number">2</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">elif</span> num == <span class="number">3</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    a = <span class="number">1</span></span><br><span class="line">    b = <span class="number">2</span></span><br><span class="line">    c = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num - <span class="number">1</span>):</span><br><span class="line">        a = b</span><br><span class="line">        b = c</span><br><span class="line">        c = a + b</span><br><span class="line">    <span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P12-算法课动态规划-背包问题"><a href="#Problem-P12-算法课动态规划-背包问题" class="headerlink" title="Problem P12. [算法课动态规划]背包问题"></a>Problem P12. [算法课动态规划]背包问题</h3><p>一个背包有一定的承重 W，有 N 件物品，每件物品都有自己的价值，记录在数组 V 中，也都有自己的重量，记录在数组 W 中，每件物品只能选择要装入还是不装入背包，要求在不超过背包承重的前提下，选出的物品总价值最大。 假设物品数量为 4 背包承重为 10 每个商品重量为 7, 3, 4, 5 价值为 42, 12, 40, 25</p>
<h4 id="输入-11"><a href="#输入-11" class="headerlink" title="输入"></a>输入</h4><p>输入物品数量 n = 4 承重 cap = 10</p>
<h4 id="输出-11"><a href="#输出-11" class="headerlink" title="输出"></a>输出</h4><p>输出最大总价值为多少</p>
<h4 id="样例-11"><a href="#样例-11" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">4 10</span><br><span class="line">标准输出：</span><br><span class="line">65</span><br></pre></td></tr></table></figure>

<h4 id="提示-5"><a href="#提示-5" class="headerlink" title="提示"></a>提示</h4><p>可以动态规划方法求解。 分析两种情况：</p>
<ol>
<li>第i个物品放不进去背包：W[i] &gt; j;</li>
<li>可以放进去，但是可以选择放进去或者不放：W[i] =&lt; j;</li>
</ol>
<h4 id="解答-11"><a href="#解答-11" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">heavy = [<span class="number">7</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">value = [<span class="number">42</span>, <span class="number">12</span>, <span class="number">40</span>, <span class="number">25</span>]</span><br><span class="line"></span><br><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">n = arr[<span class="number">0</span>]</span><br><span class="line">cap = arr[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">dp = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>):</span><br><span class="line">    dp.append([<span class="number">0</span>] * (cap + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">1</span> + n):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">1</span> + cap):</span><br><span class="line">        <span class="keyword">if</span> j &lt; heavy[i - <span class="number">1</span>]:</span><br><span class="line">            dp[i][j] = dp[i-<span class="number">1</span>][j]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dp[i][j] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][j], value[i-<span class="number">1</span>] + dp[i-<span class="number">1</span>][j-heavy[i-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dp[n][cap])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P13-算法课动态规划-最长回文子串"><a href="#Problem-P13-算法课动态规划-最长回文子串" class="headerlink" title="Problem P13. [算法课动态规划]最长回文子串"></a>Problem P13. [算法课动态规划]最长回文子串</h3><p>求一个字符串中的最长的回文子串</p>
<h4 id="输入-12"><a href="#输入-12" class="headerlink" title="输入"></a>输入</h4><p>输入字符串 s (1 &lt;= s.length &lt;= 1000) s 仅由数字和英文字母（大写和/或小写）组成</p>
<h4 id="输出-12"><a href="#输出-12" class="headerlink" title="输出"></a>输出</h4><p>输出最长的回文子串</p>
<h4 id="样例-12"><a href="#样例-12" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">babad</span><br><span class="line">标准输出：</span><br><span class="line">bab</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">a</span><br><span class="line">标准输出：</span><br><span class="line">a</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">ac</span><br><span class="line">标准输出：</span><br><span class="line">a</span><br></pre></td></tr></table></figure>

<h4 id="解答-12"><a href="#解答-12" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = <span class="built_in">input</span>()</span><br><span class="line">n = <span class="built_in">len</span>(s)</span><br><span class="line"><span class="keyword">if</span> n &lt; <span class="number">2</span>:</span><br><span class="line">    <span class="built_in">print</span>(s)</span><br><span class="line"></span><br><span class="line">maxLen = <span class="number">1</span></span><br><span class="line">begin = <span class="number">0</span></span><br><span class="line">dp = [[<span class="literal">False</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    dp[i][i] = <span class="literal">True</span></span><br><span class="line"><span class="keyword">for</span> L <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        j = L + i - <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> j &gt;= n:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> s[i] != s[j]:</span><br><span class="line">            dp[i][j] = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> j - i &lt; <span class="number">3</span>:</span><br><span class="line">                dp[i][j] = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = dp[i + <span class="number">1</span>][j - <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> dp[i][j] <span class="keyword">and</span> j - i + <span class="number">1</span> &gt; maxLen:</span><br><span class="line">            maxLen = j - i + <span class="number">1</span></span><br><span class="line">            begin = i</span><br><span class="line"><span class="built_in">print</span>(s[begin:begin + maxLen])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P14-算法课动态规划-连续数组最大和"><a href="#Problem-P14-算法课动态规划-连续数组最大和" class="headerlink" title="Problem P14. [算法课动态规划]连续数组最大和"></a>Problem P14. [算法课动态规划]连续数组最大和</h3><p>输入一个整型数组，数组中的一个或连续多个整数组成一个子数组。求所有子数组的和的最大值。</p>
<h4 id="输入-13"><a href="#输入-13" class="headerlink" title="输入"></a>输入</h4><p>输入数组长度n (1 &lt;= n &lt;= 50) 依次给数组的元素赋值</p>
<h4 id="输出-13"><a href="#输出-13" class="headerlink" title="输出"></a>输出</h4><p>输出所有子数组的和的最大值</p>
<h4 id="样例-13"><a href="#样例-13" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">9</span><br><span class="line">-2 1 -3 4 -1 2 1 -5 4</span><br><span class="line">标准输出：</span><br><span class="line">6</span><br></pre></td></tr></table></figure>

<h4 id="解答-13"><a href="#解答-13" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = <span class="built_in">input</span>()</span><br><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">dp = [<span class="number">0</span>] * (<span class="built_in">len</span>(arr) + <span class="number">1</span>)</span><br><span class="line">maxAns = arr[<span class="number">0</span>]</span><br><span class="line">pre = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">    pre = <span class="built_in">max</span>(pre + i, i)</span><br><span class="line">    maxAns = <span class="built_in">max</span>(maxAns, pre)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(maxAns)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P15-算法课动态规划-最长公共子序列"><a href="#Problem-P15-算法课动态规划-最长公共子序列" class="headerlink" title="Problem P15. [算法课动态规划]最长公共子序列"></a>Problem P15. [算法课动态规划]最长公共子序列</h3><p>给定两个字符串 text1 和 text2，返回这两个字符串的最长 公共子序列 的长度。如果不存在 公共子序列 ，返回 0</p>
<h4 id="输入-14"><a href="#输入-14" class="headerlink" title="输入"></a>输入</h4><p>输入字符串s1和s2</p>
<h4 id="输出-14"><a href="#输出-14" class="headerlink" title="输出"></a>输出</h4><p>输出最长公共子序列的长度</p>
<h4 id="样例-14"><a href="#样例-14" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">abcde ace</span><br><span class="line">标准输出：</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">asdfg azxcd</span><br><span class="line">标准输出：</span><br><span class="line">2</span><br></pre></td></tr></table></figure>

<h4 id="提示-6"><a href="#提示-6" class="headerlink" title="提示"></a>提示</h4><p>区分两个概念：子序列可以是不连续的；子数组（子字符串）需要是连续的</p>
<h4 id="解答-14"><a href="#解答-14" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"></span><br><span class="line">m = <span class="built_in">len</span>(arr[<span class="number">0</span>])</span><br><span class="line">n = <span class="built_in">len</span>(arr[<span class="number">1</span>])</span><br><span class="line">dp = [[<span class="number">0</span>] * (n + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m + <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m + <span class="number">1</span>):</span><br><span class="line">    c1 = arr[<span class="number">0</span>][i - <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">        c2 = arr[<span class="number">1</span>][j - <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> c1 == c2:</span><br><span class="line">            dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dp[m][n])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P16-算法课贪婪-最长回文串"><a href="#Problem-P16-算法课贪婪-最长回文串" class="headerlink" title="Problem P16. [算法课贪婪]最长回文串"></a>Problem P16. [算法课贪婪]最长回文串</h3><p>给定一个包含大写字母和小写字母的字符串，找到通过这些字母构造成的最长的回文串。在构造过程中，请注意区分大小写。比如 “Aa” 不能当做一个回文字符串。解释：第一个例子可以构成”dccaccd”, 它的长度是 7。字符串的长度不会超过 1010</p>
<h4 id="输入-15"><a href="#输入-15" class="headerlink" title="输入"></a>输入</h4><p>第一行输入一串字符</p>
<h4 id="输出-15"><a href="#输出-15" class="headerlink" title="输出"></a>输出</h4><p>第一行输出数字代表能构成的最大回文串的长度。</p>
<h4 id="样例-15"><a href="#样例-15" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">abccccdd</span><br><span class="line">标准输出：</span><br><span class="line">7</span><br></pre></td></tr></table></figure>

<h4 id="解答-15"><a href="#解答-15" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line">arr = <span class="built_in">input</span>()</span><br><span class="line"></span><br><span class="line">ans = <span class="number">0</span></span><br><span class="line">count = collections.Counter(arr)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> count.values():</span><br><span class="line">    ans += v // <span class="number">2</span> * <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> ans % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">and</span> v % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">        ans += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ans)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P17-算法课贪婪-分发饼干"><a href="#Problem-P17-算法课贪婪-分发饼干" class="headerlink" title="Problem P17. [算法课贪婪]分发饼干"></a>Problem P17. [算法课贪婪]分发饼干</h3><p>假设你是一位很棒的家长，想要给你的孩子们一些小饼干。但是，每个孩子最多只能给一块饼干。</p>
<p>对每个孩子 i，都有一个胃口值 g[i]，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 j，都有一个尺寸 s[j] 。如果 s[j] &gt;= g[i]，我们可以将这个饼干 j 分配给孩子 i ，这个孩子会得到满足。你的目标是尽可能满足越多数量的孩子，并输出这个最大数值。</p>
<p>1 &lt;= g.length &lt;= 3 * 10^5</p>
<p>0 &lt;= s.length &lt;= 3 * 10^5</p>
<p>1 &lt;= g[i], s[j] &lt;= 5*10^4</p>
<h4 id="输入-16"><a href="#输入-16" class="headerlink" title="输入"></a>输入</h4><p>输入孩子的胃口值与饼干尺寸</p>
<h4 id="输出-16"><a href="#输出-16" class="headerlink" title="输出"></a>输出</h4><p>输出能够满足孩子的最大数</p>
<h4 id="样例-16"><a href="#样例-16" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1 2 3</span><br><span class="line">1 1</span><br><span class="line">标准输出：</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1 2 </span><br><span class="line">1 2 3</span><br><span class="line">标准输出：</span><br><span class="line">2</span><br></pre></td></tr></table></figure>

<h4 id="解答-16"><a href="#解答-16" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = <span class="built_in">input</span>().split()</span><br><span class="line">s = <span class="built_in">input</span>().split()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(g)):</span><br><span class="line">    g[i] = <span class="built_in">int</span>(g[i])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">    s[i] = <span class="built_in">int</span>(s[i])</span><br><span class="line"></span><br><span class="line">g.sort()</span><br><span class="line">s.sort()</span><br><span class="line">m = <span class="built_in">len</span>(g)</span><br><span class="line">n = <span class="built_in">len</span>(s)</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line">j = <span class="number">0</span></span><br><span class="line">flag = <span class="literal">True</span></span><br><span class="line"><span class="keyword">while</span> i &lt; m <span class="keyword">and</span> j &lt; n:</span><br><span class="line">    <span class="keyword">while</span> j &lt; n <span class="keyword">and</span> g[i] &gt; s[j]:</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> j &lt; n:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    j += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P18-算法课贪婪-6和9组成的最大数字"><a href="#Problem-P18-算法课贪婪-6和9组成的最大数字" class="headerlink" title="Problem P18. [算法课贪婪]6和9组成的最大数字"></a>Problem P18. [算法课贪婪]6和9组成的最大数字</h3><p>给你一个仅由数字6和9组成的正整数 num。</p>
<p>你最多只能翻转一位数字，将 6 变成 9，或者把 9 变成 6 。</p>
<p>请返回你可以得到的最大数字。</p>
<ul>
<li>1 &lt;= num &lt;= 10000，即最多4位数</li>
<li>num 每一位上的数字都是 6 或者 9 。</li>
</ul>
<h4 id="输入-17"><a href="#输入-17" class="headerlink" title="输入"></a>输入</h4><p>第一行输入一个整数。</p>
<h4 id="输出-17"><a href="#输出-17" class="headerlink" title="输出"></a>输出</h4><p>第一行输出一个整数代表最大值</p>
<h4 id="样例-17"><a href="#样例-17" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">9669</span><br><span class="line">标准输出：</span><br><span class="line">9969</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">9996</span><br><span class="line">标准输出：</span><br><span class="line">9999</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">69</span><br><span class="line">标准输出：</span><br><span class="line">99</span><br></pre></td></tr></table></figure>

<h4 id="解答-17"><a href="#解答-17" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = <span class="built_in">input</span>()</span><br><span class="line">ans = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> num:</span><br><span class="line">    ans.append(i)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ans)):</span><br><span class="line">    <span class="keyword">if</span> ans[i] == <span class="string">&quot;6&quot;</span>:</span><br><span class="line">        ans[i] = <span class="string">&quot;9&quot;</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>.join(ans))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P19-算法课贪婪-三角形的最大周长"><a href="#Problem-P19-算法课贪婪-三角形的最大周长" class="headerlink" title="Problem P19. [算法课贪婪]三角形的最大周长"></a>Problem P19. [算法课贪婪]三角形的最大周长</h3><p>给定由一些正数（代表长度）组成的数组 A，返回由其中三个长度组成的、面积不为零的三角形的最大周长。如果不能形成任何面积不为零的三角形，返回 0。</p>
<ul>
<li>3 &lt;= A.length &lt;= 1000</li>
<li>1 &lt;= A[i] &lt;= 1000</li>
</ul>
<h4 id="输入-18"><a href="#输入-18" class="headerlink" title="输入"></a>输入</h4><p>第一行输入一行数字代表长度，数字与数字之间空格隔开。</p>
<h4 id="输出-18"><a href="#输出-18" class="headerlink" title="输出"></a>输出</h4><p>输出一个整数代表最大周长</p>
<h4 id="样例-18"><a href="#样例-18" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">2 1 2</span><br><span class="line">标准输出：</span><br><span class="line">5</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1 2 1</span><br><span class="line">标准输出：</span><br><span class="line">0</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">3 2 3 4</span><br><span class="line">标准输出：</span><br><span class="line">10</span><br></pre></td></tr></table></figure>

<h4 id="解答-18"><a href="#解答-18" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num)):</span><br><span class="line">    num[i] = <span class="built_in">int</span>(num[i])</span><br><span class="line">num.sort(reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">boolean = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num) - <span class="number">2</span>):</span><br><span class="line">    <span class="keyword">if</span> num[i + <span class="number">2</span>] + num[i + <span class="number">1</span>] &gt; num[i]:</span><br><span class="line">        <span class="built_in">print</span>(num[i + <span class="number">2</span>] + num[i + <span class="number">1</span>] + num[i])</span><br><span class="line">        boolean = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> boolean:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P20-算法课蛮力法-种花问题"><a href="#Problem-P20-算法课蛮力法-种花问题" class="headerlink" title="Problem P20. [算法课蛮力法]种花问题"></a>Problem P20. [算法课蛮力法]种花问题</h3><p>假设有一个很长的花坛，一部分地块种植了花，另一部分却没有。可是，花不能种植在相邻的地块上，它们会争夺水源，两者都会死去。</p>
<p>给你一个整数数组  flowerbed 表示花坛，由若干 0 和 1 组成，其中 0 表示没种植花，1 表示种植了花。另有一个数 n ，能否在不打破种植规则的情况下种入 n 朵花？能则返回 true ，不能则返回 false。</p>
<ul>
<li>1 &lt;= flowerbed.length &lt;= 2 * 10^4</li>
<li>flowerbed[i] 为 0 或 1</li>
<li>flowerbed 中不存在相邻的两朵花</li>
<li>0 &lt;= n &lt;= flowerbed.length</li>
</ul>
<h4 id="输入-19"><a href="#输入-19" class="headerlink" title="输入"></a>输入</h4><p>输入一行数组flower与需要插入的花数目</p>
<h4 id="输出-19"><a href="#输出-19" class="headerlink" title="输出"></a>输出</h4><p>输出是否插入成功</p>
<h4 id="样例-19"><a href="#样例-19" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1 0 0 0 1</span><br><span class="line">2</span><br><span class="line">标准输出：</span><br><span class="line">false</span><br></pre></td></tr></table></figure>

<h4 id="解答-19"><a href="#解答-19" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num)):</span><br><span class="line">    num[i] = <span class="built_in">int</span>(num[i])</span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"></span><br><span class="line">flowerbed = [<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> num:</span><br><span class="line">    flowerbed.append(i)</span><br><span class="line">flowerbed.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(flowerbed) - <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">if</span> flowerbed[i] == <span class="number">0</span> <span class="keyword">and</span> flowerbed[i - <span class="number">1</span>] == <span class="number">0</span> <span class="keyword">and</span> flowerbed[i + <span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        flowerbed[i] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> count &gt;= n:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;true&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;false&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P21-算法课贪婪-移掉-K-位数字"><a href="#Problem-P21-算法课贪婪-移掉-K-位数字" class="headerlink" title="Problem P21. [算法课贪婪]移掉 K 位数字"></a>Problem P21. [算法课贪婪]移掉 K 位数字</h3><p>给你一个以字符串表示的非负整数 num 和一个整数 k ，移除这个数中的 k 位数字，使得剩下的数字最小。请你以字符串形式返回这个最小的数字。</p>
<ul>
<li>1 &lt;= k &lt;= num.length &lt;= 1000</li>
<li>num 仅由若干位数字（0 - 9）组成</li>
<li>除了 0 本身之外，num 不含任何前导零</li>
</ul>
<h4 id="输入-20"><a href="#输入-20" class="headerlink" title="输入"></a>输入</h4><p>输入一串字符串表示非负整数和一个整数k。字符串和k之间空格隔开。</p>
<h4 id="输出-20"><a href="#输出-20" class="headerlink" title="输出"></a>输出</h4><p>输出一串字符串表示结果。</p>
<h4 id="样例-20"><a href="#样例-20" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1432219 3</span><br><span class="line">标准输出：</span><br><span class="line">1219</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">10200 1</span><br><span class="line">标准输出：</span><br><span class="line">200</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">10 2</span><br><span class="line">标准输出：</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<h4 id="解答-20"><a href="#解答-20" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line">temp = arr[<span class="number">0</span>]</span><br><span class="line">num = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> temp:</span><br><span class="line">    num.append(<span class="built_in">int</span>(i))</span><br><span class="line">k = <span class="built_in">int</span>(arr[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">ans = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num)):</span><br><span class="line">    <span class="keyword">while</span> k &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="built_in">len</span>(ans) &gt; <span class="number">0</span> <span class="keyword">and</span> ans[-<span class="number">1</span>] &gt; num[i]:</span><br><span class="line">        k -= <span class="number">1</span></span><br><span class="line">        ans.pop(-<span class="number">1</span>)</span><br><span class="line">    ans.append(num[i])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> k &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        ans.pop(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> ans <span class="keyword">and</span> ans[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">    ans.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> ans:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> ans:</span><br><span class="line">        <span class="built_in">print</span>(i, end=<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P22-算法课贪婪-盛最多的水"><a href="#Problem-P22-算法课贪婪-盛最多的水" class="headerlink" title="Problem P22. [算法课贪婪]盛最多的水"></a>Problem P22. [算法课贪婪]盛最多的水</h3><p>给你 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0) 。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。</p>
<p>说明：你不能倾斜容器。</p>
<img src="/f0fd6226/1.jpg" class>

<p>输入：1 8 6 2 5 4 8 3 7 输出：49 解释：图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49。</p>
<p>n == height.length</p>
<p>2 &lt;= n &lt;= 10^4</p>
<p>0 &lt;= height[i] &lt;= 10^4</p>
<h4 id="输入-21"><a href="#输入-21" class="headerlink" title="输入"></a>输入</h4><p>输入一行整数</p>
<h4 id="输出-21"><a href="#输出-21" class="headerlink" title="输出"></a>输出</h4><p>输出最大的面积数</p>
<h4 id="样例-21"><a href="#样例-21" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">4 3 2 1 4</span><br><span class="line">标准输出：</span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1 2 1 </span><br><span class="line">标准输出：</span><br><span class="line">2</span><br></pre></td></tr></table></figure>

<h4 id="解答-21"><a href="#解答-21" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">    arr[i] = <span class="built_in">int</span>(arr[i])</span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line">j = <span class="built_in">len</span>(arr) - <span class="number">1</span></span><br><span class="line">ans = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> i &lt; j:</span><br><span class="line">    minH = <span class="built_in">min</span>(arr[i], arr[j])</span><br><span class="line">    area = (j - i) * minH</span><br><span class="line">    ans = <span class="built_in">max</span>(ans, area)</span><br><span class="line">    <span class="keyword">while</span> arr[i] &lt;= minH <span class="keyword">and</span> i &lt; j:</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> arr[j] &lt;= minH <span class="keyword">and</span> i &lt; j:</span><br><span class="line">        j -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ans)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P23-算法课回溯-括号生成"><a href="#Problem-P23-算法课回溯-括号生成" class="headerlink" title="Problem P23. [算法课回溯]括号生成"></a>Problem P23. [算法课回溯]括号生成</h3><p>数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。</p>
<p>有效括号组合需满足：左括号必须以正确的顺序闭合。</p>
<p>1 &lt;= n &lt;= 8<br>请按照括号生成的层数有大到小排序，如输入3时，先生成((()))，最后再生成 ()()()</p>
<h4 id="输入-22"><a href="#输入-22" class="headerlink" title="输入"></a>输入</h4><p>输入数字n</p>
<h4 id="输出-22"><a href="#输出-22" class="headerlink" title="输出"></a>输出</h4><p>生成所有可能的并且 有效的 括号组合</p>
<h4 id="样例-22"><a href="#样例-22" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">3</span><br><span class="line">标准输出：</span><br><span class="line">[((())), (()()), (())(), ()(()), ()()()]</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1</span><br><span class="line">标准输出：</span><br><span class="line">[()]</span><br></pre></td></tr></table></figure>

<h4 id="解答-22"><a href="#解答-22" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">ans = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen</span>(<span class="params">left, right, temp</span>):</span></span><br><span class="line">    <span class="keyword">if</span> left == <span class="number">0</span> <span class="keyword">and</span> right == <span class="number">0</span>:</span><br><span class="line">        ans.append(temp.copy())</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> left &gt; <span class="number">0</span>:</span><br><span class="line">        temp.append(<span class="string">&quot;(&quot;</span>)</span><br><span class="line">        gen(left - <span class="number">1</span>, right, temp)</span><br><span class="line">        temp.pop(-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> left &lt; right:</span><br><span class="line">        temp.append(<span class="string">&quot;)&quot;</span>)</span><br><span class="line">        gen(left, right - <span class="number">1</span>, temp)</span><br><span class="line">        temp.pop(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">gen(num, num, [])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>.join(ans[<span class="number">0</span>]), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(ans)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;, &quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>.join(ans[i]), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;]&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P24-算法课回溯-组合问题"><a href="#Problem-P24-算法课回溯-组合问题" class="headerlink" title="Problem P24. [算法课回溯]组合问题"></a>Problem P24. [算法课回溯]组合问题</h3><p>给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。</p>
<p>你需要按顺序返回答案。</p>
<ul>
<li>1 &lt;= n &lt;= 20</li>
<li>1 &lt;= k &lt;= n</li>
</ul>
<h4 id="输入-23"><a href="#输入-23" class="headerlink" title="输入"></a>输入</h4><p>两个整数 n 和 k</p>
<h4 id="输出-23"><a href="#输出-23" class="headerlink" title="输出"></a>输出</h4><p>范围 [1, n] 中所有可能的 k 个数的组合</p>
<h4 id="样例-23"><a href="#样例-23" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">4 2</span><br><span class="line">标准输出：</span><br><span class="line">[[1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4]]</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">5 3</span><br><span class="line">标准输出：</span><br><span class="line">[[1, 2, 3], [1, 2, 4], [1, 2, 5], [1, 3, 4], [1, 3, 5], [1, 4, 5], [2, 3, 4], [2, 3, 5], [2, 4, 5], [3, 4, 5]]</span><br></pre></td></tr></table></figure>

<h4 id="提示-7"><a href="#提示-7" class="headerlink" title="提示"></a>提示</h4><p>可以用回溯法求解。</p>
<h4 id="解答-23"><a href="#解答-23" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = <span class="built_in">input</span>().split()</span><br><span class="line">n = <span class="built_in">int</span>(num[<span class="number">0</span>])</span><br><span class="line">k = <span class="built_in">int</span>(num[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">ans = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen</span>(<span class="params">cur, n, k, temp</span>):</span></span><br><span class="line">    <span class="keyword">if</span> cur &gt; n + <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(temp) == k:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(temp)):</span><br><span class="line">            temp[i] = <span class="built_in">str</span>(temp[i])</span><br><span class="line">        ans.append(temp.copy())</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    temp.append(cur)</span><br><span class="line">    gen(cur + <span class="number">1</span>, n, k, temp)</span><br><span class="line">    temp.pop(-<span class="number">1</span>)</span><br><span class="line">    gen(cur + <span class="number">1</span>, n, k, temp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">gen(<span class="number">1</span>, n, k, [])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;, &quot;</span>.join(ans[<span class="number">0</span>]), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;]&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(ans)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;, &quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;, &quot;</span>.join(ans[i]), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;]&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;]&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P25-算法课回溯-找出所有子集的异或总和再求和"><a href="#Problem-P25-算法课回溯-找出所有子集的异或总和再求和" class="headerlink" title="Problem P25. [算法课回溯]找出所有子集的异或总和再求和"></a>Problem P25. [算法课回溯]找出所有子集的异或总和再求和</h3><p>一个数组的 异或总和 定义为数组中所有元素按位 XOR 的结果；如果数组为 空 ，则异或总和为 0 。</p>
<p>例如，数组 [2,5,6] 的 异或总和 为 2 XOR 5 XOR 6 = 1 。 给你一个数组 nums ，请你求出 nums 中每个 子集 的 异或总和 ，计算并返回这些值相加之 和 。</p>
<p>注意：在本题中，元素 相同 的不同子集应 多次 计数。</p>
<p>数组 a 是数组 b 的一个 子集 的前提条件是：从 b 删除几个（也可能不删除）元素能够得到 a 。</p>
<ul>
<li>1 &lt;= nums.length &lt;= 12</li>
<li>1 &lt;= nums[i] &lt;= 20</li>
</ul>
<h4 id="输入-24"><a href="#输入-24" class="headerlink" title="输入"></a>输入</h4><p>输入：nums = [1,3]</p>
<p>解释：[1,3] 共有 4 个子集：</p>
<ul>
<li>空子集的异或总和是 0 。</li>
<li>[1] 的异或总和为 1 。</li>
<li>[3] 的异或总和为 3 。</li>
<li>[1,3] 的异或总和为 1 XOR 3 = 2 。 0 + 1 + 3 + 2 = 6</li>
</ul>
<h4 id="输出-24"><a href="#输出-24" class="headerlink" title="输出"></a>输出</h4><p>输出：6</p>
<h4 id="样例-24"><a href="#样例-24" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1 3</span><br><span class="line">标准输出：</span><br><span class="line">6</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">5 10 11 12 13 14</span><br><span class="line">标准输出：</span><br><span class="line">480</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">3 13 8 18 8 14 8 15 14</span><br><span class="line">标准输出：</span><br><span class="line">7936</span><br></pre></td></tr></table></figure>

<h4 id="解答-24"><a href="#解答-24" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num)):</span><br><span class="line">    num[i] = <span class="built_in">int</span>(num[i])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">CountXOR</span>(<span class="params">l</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(l) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(l) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> l[<span class="number">0</span>]</span><br><span class="line">    xor = l[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(l) - <span class="number">1</span>):</span><br><span class="line">        xor ^= l[i + <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> xor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countSum</span>(<span class="params">res</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(res) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> res[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(res)):</span><br><span class="line">        <span class="built_in">sum</span> += CountXOR(res[i])</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findSubset</span>(<span class="params">num</span>):</span></span><br><span class="line">    res = []</span><br><span class="line">    n = <span class="built_in">len</span>(num)</span><br><span class="line">    temp = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** n):</span><br><span class="line">        binary = <span class="built_in">bin</span>(i)</span><br><span class="line">        <span class="built_in">str</span> = <span class="built_in">list</span>(binary[<span class="number">2</span>:])</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(<span class="built_in">str</span>) &lt; n:</span><br><span class="line">            <span class="built_in">str</span>.insert(<span class="number">0</span>, <span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="built_in">str</span>)):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">str</span>[j] == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                temp.append(num[j])</span><br><span class="line">        res.append(temp)</span><br><span class="line">        temp = []</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">res = findSubset(num)</span><br><span class="line"><span class="built_in">sum</span> = countSum(res)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P26-算法课回溯-分割回文串"><a href="#Problem-P26-算法课回溯-分割回文串" class="headerlink" title="Problem P26. [算法课回溯]分割回文串"></a>Problem P26. [算法课回溯]分割回文串</h3><p>给你一个字符串 s，请你将 s 分割成一些子串，使每个子串都是 回文串 。返回 s 所有可能的分割方案。</p>
<p>回文串 是正着读和反着读都一样的字符串。</p>
<h4 id="输入-25"><a href="#输入-25" class="headerlink" title="输入"></a>输入</h4><p>字符串 s (∣s∣≤ 12)</p>
<h4 id="输出-25"><a href="#输出-25" class="headerlink" title="输出"></a>输出</h4><p>输出所有分割方案，按照分割位置序列的字典序输出</p>
<h4 id="样例-25"><a href="#样例-25" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">aab</span><br><span class="line">标准输出：</span><br><span class="line">[[a, a, b], [aa, b]]</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">thjgxlm</span><br><span class="line">标准输出：</span><br><span class="line">[[t, h, j, g, x, l, m]]</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">abbca</span><br><span class="line">标准输出：</span><br><span class="line">[[a, b, b, c, a], [a, bb, c, a]]</span><br></pre></td></tr></table></figure>

<h4 id="解答-25"><a href="#解答-25" class="headerlink" title="解答"></a>解答</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line">vector&lt;string&gt; ans;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">judge</span><span class="params">(string str)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(str.<span class="built_in">size</span>()==<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">int</span> i=<span class="number">0</span>, j=str.<span class="built_in">size</span>()<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;=j)&#123;</span><br><span class="line">        <span class="keyword">if</span>(str[i]!=str[j])&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        i++;</span><br><span class="line">        j--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(string str, <span class="keyword">int</span> idx, string S)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(idx == S.<span class="built_in">size</span>())&#123;</span><br><span class="line">            <span class="keyword">if</span>(str.<span class="built_in">back</span>()==<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">        vector&lt;string&gt; tmp;</span><br><span class="line">        string s=<span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;str.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(str[i]==<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span>(str[i]==<span class="string">&#x27;,&#x27;</span>)&#123;</span><br><span class="line">                tmp.<span class="built_in">push_back</span>(s);</span><br><span class="line">                s=<span class="string">&quot;&quot;</span>;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            s.<span class="built_in">push_back</span>(str[i]);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        tmp.<span class="built_in">push_back</span>(s);</span><br><span class="line">        <span class="keyword">bool</span> flag = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; tmp.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">judge</span>(tmp[i]) == <span class="literal">false</span>)&#123;</span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(flag)&#123;</span><br><span class="line">            ans.<span class="built_in">push_back</span>(str);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">dfs</span>(str+S[idx]+<span class="string">&quot;, &quot;</span>, idx+<span class="number">1</span>, S);</span><br><span class="line">    <span class="built_in">dfs</span>(str+S[idx], idx+<span class="number">1</span>, S);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    string S;</span><br><span class="line">    string str=<span class="string">&quot;&quot;</span>;</span><br><span class="line">    cin &gt;&gt; S;</span><br><span class="line">    <span class="built_in">dfs</span>(str, <span class="number">0</span>, S);</span><br><span class="line">    <span class="comment">// cout &lt;&lt; ans.size() &lt;&lt; endl;</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&#x27;[&#x27;</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;ans.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&#x27;[&#x27;</span> &lt;&lt; ans[i];</span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span> == ans.<span class="built_in">size</span>())&#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&#x27;]&#x27;</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;], &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; <span class="string">&#x27;]&#x27;</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P27-算法课回溯-目标和"><a href="#Problem-P27-算法课回溯-目标和" class="headerlink" title="Problem P27. [算法课回溯]目标和"></a>Problem P27. [算法课回溯]目标和</h3><p>给你一个整数数组 nums 和一个整数 target 。</p>
<p>向数组中的每个整数前添加 ‘+’ 或 ‘-‘ ，然后串联起所有整数，可以构造一个 表达式 ：</p>
<p>例如，nums = [2, 1] ，可以在 2 之前添加 ‘+’ ，在 1 之前添加 ‘-‘ ，然后串联起来得到表达式 “+2-1” 。 返回可以通过上述方法构造的、运算结果等于 target 的不同 表达式 的数目。</p>
<ul>
<li>1 &lt;= nums.length &lt;= 20</li>
<li>0 &lt;= nums[i] &lt;= 1000</li>
<li>0 &lt;= sum(nums[i]) &lt;= 1000</li>
<li>-1000 &lt;= target &lt;= 1000</li>
</ul>
<h4 id="输入-26"><a href="#输入-26" class="headerlink" title="输入"></a>输入</h4><p>第一行为若干整数代表 nums</p>
<p>第二行为整数 target</p>
<h4 id="输出-26"><a href="#输出-26" class="headerlink" title="输出"></a>输出</h4><p>一行一个整数代表答案</p>
<h4 id="样例-26"><a href="#样例-26" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1 1 1 1 1</span><br><span class="line">3</span><br><span class="line">标准输出：</span><br><span class="line">5</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">3 4 5 3 3</span><br><span class="line">12</span><br><span class="line">标准输出：</span><br><span class="line">3</span><br></pre></td></tr></table></figure>

<h4 id="提示-8"><a href="#提示-8" class="headerlink" title="提示"></a>提示</h4><p>输出：5 样例一解释：一共有 5 种方法让最终目标和为3<br>-1 + 1 + 1 + 1 + 1 = 3<br>+1 - 1 + 1 + 1 + 1 = 3<br>+1 + 1 - 1 + 1 + 1 = 3<br>+1 + 1 + 1 - 1 + 1 = 3<br>+1 + 1 + 1 + 1 - 1 = 3</p>
<h4 id="解答-26"><a href="#解答-26" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">    nums[i] = <span class="built_in">int</span>(nums[i])</span><br><span class="line">num = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findSubset</span>(<span class="params">nums, num</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(nums)</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** n):</span><br><span class="line">        binary = <span class="built_in">bin</span>(i)</span><br><span class="line">        <span class="built_in">str</span> = <span class="built_in">list</span>(binary[<span class="number">2</span>:])</span><br><span class="line">        <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(<span class="built_in">str</span>) &lt; n:</span><br><span class="line">            <span class="built_in">str</span>.insert(<span class="number">0</span>, <span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="built_in">str</span>)):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">str</span>[t] == <span class="string">&#x27;0&#x27;</span>:</span><br><span class="line">                <span class="built_in">sum</span> -= nums[t]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">sum</span> += nums[t]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sum</span> == num:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">res = findSubset(nums, num)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P28-算法课回溯-电话号码的字母组合"><a href="#Problem-P28-算法课回溯-电话号码的字母组合" class="headerlink" title="Problem P28. [算法课回溯] 电话号码的字母组合"></a>Problem P28. [算法课回溯] 电话号码的字母组合</h3><p>给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案按字母顺序返回。</p>
<p>给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。</p>
<img src="/f0fd6226/2.png" class>

<p>提示：</p>
<ul>
<li>0 &lt;= digits.length &lt;= 4</li>
<li>digits[i] 是范围 [‘2’, ‘9’] 的一个数字。</li>
</ul>
<h4 id="输入-27"><a href="#输入-27" class="headerlink" title="输入"></a>输入</h4><p>给定一个仅包含数字 2-9 的字符串</p>
<h4 id="输出-27"><a href="#输出-27" class="headerlink" title="输出"></a>输出</h4><p>所有它能表示的字母组合</p>
<h4 id="样例-27"><a href="#样例-27" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">456</span><br><span class="line">标准输出：</span><br><span class="line">[gjm, gjn, gjo, gkm, gkn, gko, glm, gln, glo, hjm, hjn, hjo, hkm, hkn, hko, hlm, hln, hlo, ijm, ijn, ijo, ikm, ikn, iko, ilm, iln, ilo]</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">23</span><br><span class="line">标准输出：</span><br><span class="line">[ad, ae, af, bd, be, bf, cd, ce, cf]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="解答-27"><a href="#解答-27" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = <span class="built_in">input</span>()</span><br><span class="line">ans = []</span><br><span class="line"></span><br><span class="line">let = [[<span class="string">&quot;&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;d&quot;</span>, <span class="string">&quot;e&quot;</span>, <span class="string">&quot;f&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;g&quot;</span>, <span class="string">&quot;h&quot;</span>, <span class="string">&quot;i&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;j&quot;</span>, <span class="string">&quot;k&quot;</span>, <span class="string">&quot;l&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;m&quot;</span>, <span class="string">&quot;n&quot;</span>, <span class="string">&quot;o&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;p&quot;</span>, <span class="string">&quot;q&quot;</span>, <span class="string">&quot;r&quot;</span>, <span class="string">&quot;s&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;t&quot;</span>, <span class="string">&quot;u&quot;</span>, <span class="string">&quot;v&quot;</span>],</span><br><span class="line">       [<span class="string">&quot;w&quot;</span>, <span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;z&quot;</span>]]</span><br><span class="line"></span><br><span class="line">letter = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">    letter.append(let[<span class="built_in">int</span>(nums[i])])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">temp, idx</span>):</span></span><br><span class="line">    <span class="keyword">if</span> idx == <span class="built_in">len</span>(nums):</span><br><span class="line">        ans.append(temp)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    fun(temp + letter[idx][<span class="number">0</span>], idx + <span class="number">1</span>)</span><br><span class="line">    fun(temp + letter[idx][<span class="number">1</span>], idx + <span class="number">1</span>)</span><br><span class="line">    fun(temp + letter[idx][<span class="number">2</span>], idx + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(letter[idx]) == <span class="number">4</span>:</span><br><span class="line">        fun(temp + letter[idx][<span class="number">3</span>], idx + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fun(<span class="string">&quot;&quot;</span>, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>.join(ans[<span class="number">0</span>]), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(ans) &gt; <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(ans)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;, &quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>.join(ans[i]), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;]&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P29-算法课回溯-优美的排列"><a href="#Problem-P29-算法课回溯-优美的排列" class="headerlink" title="Problem P29. [算法课回溯]优美的排列"></a>Problem P29. [算法课回溯]优美的排列</h3><p>假设有从 1 到 n 的 n 个整数。用这些整数构造一个数组 perm（下标从 1 开始），只要满足下述条件 之一 ，该数组就是一个 优美的排列 ：</p>
<ul>
<li>perm[i] 能够被 i 整除</li>
<li>i 能够被 perm[i] 整除</li>
</ul>
<p>给你一个整数 n ，返回可以构造的 优美排列 的 数量 。</p>
<p>提示：</p>
<ul>
<li>1 &lt;= n &lt;= 15</li>
</ul>
<h4 id="输入-28"><a href="#输入-28" class="headerlink" title="输入"></a>输入</h4><p>1 到 n 的 n 个整数</p>
<p>示例 1：</p>
<p>输入：n = 2</p>
<p>输出：2</p>
<p>解释：</p>
<p>第 1 个优美的排列是 [1,2]：<br>perm[1] = 1 能被 i = 1 整除<br>perm[2] = 2 能被 i = 2 整除</p>
<p>第 2 个优美的排列是 [2,1]:<br>perm[1] = 2 能被 i = 1 整除<br>i = 2 能被 perm[2] = 1 整除</p>
<h4 id="输出-28"><a href="#输出-28" class="headerlink" title="输出"></a>输出</h4><p>优美排列 的 数量</p>
<h4 id="样例-28"><a href="#样例-28" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">2</span><br><span class="line">标准输出：</span><br><span class="line">2</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1</span><br><span class="line">标准输出：</span><br><span class="line">1</span><br></pre></td></tr></table></figure>

<h4 id="解答-28"><a href="#解答-28" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line">num = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">countArrangement</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">		match = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">			<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">				<span class="keyword">if</span> i % j == <span class="number">0</span> <span class="keyword">or</span> j % i == <span class="number">0</span>:</span><br><span class="line">					match[i].append(j)</span><br><span class="line">		num = <span class="number">0</span></span><br><span class="line">		vis = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">		<span class="function"><span class="keyword">def</span> <span class="title">backtrack</span>(<span class="params">index: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">			<span class="keyword">if</span> index == n + <span class="number">1</span>:</span><br><span class="line">				<span class="keyword">nonlocal</span> num</span><br><span class="line">				num += <span class="number">1</span></span><br><span class="line">				<span class="keyword">return</span></span><br><span class="line">			<span class="keyword">for</span> x <span class="keyword">in</span> match[index]:</span><br><span class="line">				<span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> vis:</span><br><span class="line">					vis.add(x)</span><br><span class="line">					backtrack(index + <span class="number">1</span>)</span><br><span class="line">					vis.discard(x)</span><br><span class="line"></span><br><span class="line">		backtrack(<span class="number">1</span>)</span><br><span class="line">		<span class="keyword">return</span> num</span><br><span class="line"></span><br><span class="line">s = Solution()</span><br><span class="line"><span class="built_in">print</span>(s.countArrangement(num))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P30-算法课分支限界法-组合"><a href="#Problem-P30-算法课分支限界法-组合" class="headerlink" title="Problem P30. [算法课分支限界法]组合"></a>Problem P30. [算法课分支限界法]组合</h3><p>给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。</p>
<h4 id="输入-29"><a href="#输入-29" class="headerlink" title="输入"></a>输入</h4><p>4 2</p>
<h4 id="输出-29"><a href="#输出-29" class="headerlink" title="输出"></a>输出</h4><p>1 2</p>
<p>1 3</p>
<p>1 4</p>
<p>2 3</p>
<p>2 4</p>
<p>3 4</p>
<h4 id="样例-29"><a href="#样例-29" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1 1</span><br><span class="line">标准输出：</span><br><span class="line">1</span><br></pre></td></tr></table></figure>

<h4 id="提示-9"><a href="#提示-9" class="headerlink" title="提示"></a>提示</h4><p>1 &lt;= n &lt;= 20<br>1 &lt;= k &lt;= n</p>
<h4 id="解答-29"><a href="#解答-29" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = <span class="built_in">input</span>().split()</span><br><span class="line">n = <span class="built_in">int</span>(nums[<span class="number">0</span>])</span><br><span class="line">k = <span class="built_in">int</span>(nums[<span class="number">1</span>])</span><br><span class="line">res = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">helper</span>(<span class="params">startindex,path</span>):</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(path) == k:</span><br><span class="line">		res.append(path.copy())</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	i = startindex</span><br><span class="line">	<span class="keyword">while</span>(i&lt;=n-(k-<span class="built_in">len</span>(path))+<span class="number">1</span>):</span><br><span class="line">		path.append(i)</span><br><span class="line">		helper(i+<span class="number">1</span>,path)</span><br><span class="line">		path.pop()</span><br><span class="line">		i += <span class="number">1</span></span><br><span class="line">helper(<span class="number">1</span>,[])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> res:</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">		i[j] = <span class="built_in">str</span>(i[j])</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>.join(i))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P31-算法课分支限界法-大礼包"><a href="#Problem-P31-算法课分支限界法-大礼包" class="headerlink" title="Problem P31. [算法课分支限界法]大礼包"></a>Problem P31. [算法课分支限界法]大礼包</h3><p>在商店中， 有 n 件在售的物品。每件物品都有对应的价格。然而，也有一些大礼包，每个大礼包以优惠的价格捆绑销售一组物品。</p>
<p>给你一个整数数组 price 表示物品价格，其中 price[i] 是第 i 件物品的价格。另有一个整数数组 needs 表示购物清单，其中 needs[i] 是需要购买第 i 件物品的数量。</p>
<p>还有一个数组 special 表示大礼包，special[i] 的长度为 n + 1 ，其中 special[i][j] 表示第 i 个大礼包中内含第 j 件物品的数量，且 special[i][n] （也就是数组中的最后一个整数）为第 i 个大礼包的价格。</p>
<p>返回 确切 满足购物清单所需花费的最低价格，你可以充分利用大礼包的优惠活动。你不能购买超出购物清单指定数量的物品，即使那样会降低整体价格。任意大礼包可无限次购买。</p>
<h4 id="输入-30"><a href="#输入-30" class="headerlink" title="输入"></a>输入</h4><p>2 5 2 解释：前两个是price数组的值 最后一个是special数组的长度，即2代表下面的两行都是special数组的值</p>
<p>3 0 5 解释：代表special[0]的值</p>
<p>1 2 10 解释：代表special[1]的值</p>
<p>3 2 解释：need数组的值</p>
<h4 id="输出-30"><a href="#输出-30" class="headerlink" title="输出"></a>输出</h4><p>14</p>
<p>解释：有 A 和 B 两种物品，价格分别为 ¥2 和 ¥5 。</p>
<p>大礼包 1 ，你可以以 ¥5 的价格购买 3A 和 0B 。</p>
<p>大礼包 2 ，你可以以 ¥10 的价格购买 1A 和 2B 。</p>
<p>需要购买 3 个 A 和 2 个 B ， 所以付 ¥10 购买 1A 和 2B（大礼包 2），以及 ¥4 购买 2A 。</p>
<h4 id="提示-10"><a href="#提示-10" class="headerlink" title="提示"></a>提示</h4><p>n == price.length</p>
<p>n == needs.length</p>
<p>1 &lt;= n &lt;= 6</p>
<p>0 &lt;= price[i] &lt;= 10</p>
<p>0 &lt;= needs[i] &lt;= 10</p>
<p>1 &lt;= special.length &lt;= 100</p>
<p>special[i].length == n + 1</p>
<p>0 &lt;= special[i][j] &lt;= 50</p>
<h4 id="解答-30"><a href="#解答-30" class="headerlink" title="解答"></a>解答</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line">vector&lt;<span class="keyword">int</span>&gt; price_and_special_num;</span><br><span class="line">vector&lt;vector&lt;<span class="keyword">int</span>&gt; &gt; specials;</span><br><span class="line">vector&lt;<span class="keyword">int</span>&gt; needs;</span><br><span class="line">map&lt;vector&lt;<span class="keyword">int</span>&gt;, <span class="keyword">int</span>&gt; needs_with_price;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_one_line_array</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; &amp;tmp)</span></span>&#123;</span><br><span class="line">    string str;</span><br><span class="line">    <span class="built_in">getline</span>(cin, str);</span><br><span class="line">    <span class="function">istringstream <span class="title">is</span><span class="params">(str)</span></span>;</span><br><span class="line">    string s;</span><br><span class="line">    <span class="keyword">while</span>(is &gt;&gt; s)&#123;</span><br><span class="line">        tmp.<span class="built_in">push_back</span>(<span class="built_in">stoi</span>(s));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; needs)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(needs_with_price.<span class="built_in">count</span>(needs) != <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> needs_with_price[needs];</span><br><span class="line">    <span class="keyword">int</span> MIN=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; needs.<span class="built_in">size</span>(); i++)</span><br><span class="line">        MIN += needs[i] * price_and_special_num[i];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; specials.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; tmp_needs = needs; </span><br><span class="line">        <span class="keyword">bool</span> flag=<span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j &lt; needs.<span class="built_in">size</span>(); j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(specials[i][j] &gt; needs[j])&#123; </span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            tmp_needs[j] -= specials[i][j];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(flag == <span class="literal">false</span>)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        MIN = <span class="built_in">min</span>(MIN, <span class="built_in">dfs</span>(tmp_needs) + specials[i][needs.<span class="built_in">size</span>()]);</span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> needs_with_price[needs] = MIN;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">get_one_line_array</span>(price_and_special_num);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> special_num = price_and_special_num.<span class="built_in">back</span>();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;special_num; i++)&#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; tmp;</span><br><span class="line">        <span class="built_in">get_one_line_array</span>(tmp);</span><br><span class="line">        specials.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">get_one_line_array</span>(needs);</span><br><span class="line">    </span><br><span class="line">    cout &lt;&lt; <span class="built_in">dfs</span>(needs) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P32-算法课分支限界法-Partition-to-K-Equal-Sum-Subsets"><a href="#Problem-P32-算法课分支限界法-Partition-to-K-Equal-Sum-Subsets" class="headerlink" title="Problem P32. [算法课分支限界法]Partition to K Equal Sum Subsets"></a>Problem P32. [算法课分支限界法]Partition to K Equal Sum Subsets</h3><p>Given an integer array nums and an integer k, return true if it is possible to divide this array into k non-empty subsets whose sums are all equal.</p>
<h4 id="输入-31"><a href="#输入-31" class="headerlink" title="输入"></a>输入</h4><p>4 3 2 5 1</p>
<p>3</p>
<h4 id="输出-31"><a href="#输出-31" class="headerlink" title="输出"></a>输出</h4><p>true</p>
<p>Explanation: It’s possible to divide it into 3 subsets (5), (1, 4), (2,3) with equal sums.</p>
<h4 id="提示-11"><a href="#提示-11" class="headerlink" title="提示"></a>提示</h4><p>1 &lt;= k &lt;= nums.length &lt;= 16</p>
<p>1 &lt;= nums[i] &lt;= 10</p>
<p>The frequency of each element is in the range [1, 4].</p>
<h4 id="解答-31"><a href="#解答-31" class="headerlink" title="解答"></a>解答</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sum</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; &amp;tmp, <span class="keyword">int</span> begin, <span class="keyword">int</span> end)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> val=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=begin; i&lt;=end; i++)&#123;</span><br><span class="line">        val += tmp[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_one_line</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; &amp;tmp)</span></span>&#123;</span><br><span class="line">    string str;</span><br><span class="line">    vector&lt;<span class="keyword">int</span>&gt; data;</span><br><span class="line">    <span class="built_in">getline</span>(cin, str);</span><br><span class="line">    <span class="function">istringstream <span class="title">is</span><span class="params">(str)</span></span>;</span><br><span class="line">    string s;</span><br><span class="line">    <span class="keyword">while</span>(is&gt;&gt;s)&#123;</span><br><span class="line">        tmp.<span class="built_in">push_back</span>(<span class="built_in">stoi</span>(s));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    vector&lt;<span class="keyword">int</span>&gt; nums;</span><br><span class="line">    <span class="built_in">get_one_line</span>(nums);</span><br><span class="line">    <span class="keyword">int</span> k;</span><br><span class="line">    cin &gt;&gt; k;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> temp = <span class="built_in">sum</span>(nums, <span class="number">0</span>, nums.<span class="built_in">size</span>()<span class="number">-1</span>) % k;</span><br><span class="line">    <span class="keyword">if</span>(temp != <span class="number">0</span>)&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;false&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;true&quot;</span> &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P33-算法课分支限界法-分割等和子集"><a href="#Problem-P33-算法课分支限界法-分割等和子集" class="headerlink" title="Problem P33. [算法课分支限界法]分割等和子集"></a>Problem P33. [算法课分支限界法]分割等和子集</h3><p>给定一个非空的正整数数组 nums(nums.length &lt; 5) ，请判断能否将这些数字分成元素和相等的两部分。</p>
<h4 id="输入-32"><a href="#输入-32" class="headerlink" title="输入"></a>输入</h4><p>1 5 11 5</p>
<h4 id="输出-32"><a href="#输出-32" class="headerlink" title="输出"></a>输出</h4><p>true</p>
<p>解释：nums 可以分割成 [1, 5, 5] 和 [11] 。</p>
<h4 id="解答-32"><a href="#解答-32" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P34-算法课分支限界法-硬币问题"><a href="#Problem-P34-算法课分支限界法-硬币问题" class="headerlink" title="Problem P34. [算法课分支限界法]硬币问题"></a>Problem P34. [算法课分支限界法]硬币问题</h3><p>给定不同面额的硬币和一个总金额(面额、硬币数、总金额均不超过 10)。写出函数来计算可以凑成总金额的硬币组合数。假设每一种面额的硬币有无限个。</p>
<h4 id="输入-33"><a href="#输入-33" class="headerlink" title="输入"></a>输入</h4><p>5</p>
<p>1 2 5</p>
<h4 id="输出-33"><a href="#输出-33" class="headerlink" title="输出"></a>输出</h4><p>4</p>
<p>解释: 有四种方式可以凑成总金额:</p>
<p>5=5</p>
<p>5=2+2+1</p>
<p>5=2+1+1+1</p>
<p>5=1+1+1+1+1</p>
<h4 id="解答-33"><a href="#解答-33" class="headerlink" title="解答"></a>解答</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_one_line</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; &amp;tmp)</span></span>&#123;</span><br><span class="line">    string str;</span><br><span class="line">    vector&lt;<span class="keyword">int</span>&gt; data;</span><br><span class="line">    <span class="built_in">getline</span>(cin, str);</span><br><span class="line">    <span class="function">istringstream <span class="title">is</span><span class="params">(str)</span></span>;</span><br><span class="line">    string s;</span><br><span class="line">    <span class="keyword">while</span>(is&gt;&gt;s)&#123;</span><br><span class="line">        tmp.<span class="built_in">push_back</span>(<span class="built_in">stoi</span>(s));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    vector&lt;<span class="keyword">int</span>&gt; nums;</span><br><span class="line">    <span class="built_in">get_one_line</span>(nums);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">sort</span>(nums.<span class="built_in">begin</span>(), nums.<span class="built_in">end</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(nums.<span class="built_in">size</span>()==<span class="number">1</span>)&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;false&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(nums.<span class="built_in">size</span>()==<span class="number">2</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums[<span class="number">0</span>]==nums[<span class="number">1</span>])&#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;true&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;false&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(nums.<span class="built_in">size</span>()==<span class="number">3</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums[<span class="number">0</span>]+nums[<span class="number">1</span>] == nums[<span class="number">2</span>] || nums[<span class="number">1</span>]+nums[<span class="number">2</span>] == nums[<span class="number">0</span>])&#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;true&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;false&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(nums.<span class="built_in">size</span>()==<span class="number">4</span>)&#123;</span><br><span class="line">        <span class="keyword">bool</span> flag1 = nums[<span class="number">0</span>] == nums[<span class="number">1</span>]+nums[<span class="number">2</span>]+nums[<span class="number">3</span>];</span><br><span class="line">        <span class="keyword">bool</span> flag2 = nums[<span class="number">0</span>]+nums[<span class="number">1</span>] == nums[<span class="number">2</span>]+nums[<span class="number">3</span>];</span><br><span class="line">        <span class="keyword">bool</span> flag3 = nums[<span class="number">0</span>]+nums[<span class="number">1</span>]+nums[<span class="number">2</span>] == nums[<span class="number">3</span>];</span><br><span class="line">        <span class="keyword">if</span>(flag1 || flag2 || flag3)&#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;true&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;false&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P35-整数拆分"><a href="#Problem-P35-整数拆分" class="headerlink" title="Problem P35. 整数拆分"></a>Problem P35. 整数拆分</h3><p>给定一个正整数 n ，将其拆分为 k 个 正整数 的和（ k &gt;= 2 ），并使这些整数的乘积最大化。 返回 你可以获得的最大乘积。</p>
<p>提示:</p>
<ul>
<li>2 &lt;= n &lt;= 58</li>
<li>题目数据保证运算过程不超过 int 所能表示的范围</li>
</ul>
<h4 id="输入-34"><a href="#输入-34" class="headerlink" title="输入"></a>输入</h4><p>输入正整数n</p>
<h4 id="输出-34"><a href="#输出-34" class="headerlink" title="输出"></a>输出</h4><p>可以获得的最大乘积</p>
<h4 id="样例-30"><a href="#样例-30" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">2</span><br><span class="line">标准输出：</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">10</span><br><span class="line">标准输出：</span><br><span class="line">36</span><br></pre></td></tr></table></figure>

<h4 id="解答-34"><a href="#解答-34" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="keyword">if</span> n &lt;= <span class="number">3</span>:</span><br><span class="line">    <span class="built_in">print</span>(n-<span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    a = n // <span class="number">3</span></span><br><span class="line">    b = n % <span class="number">3</span></span><br><span class="line">    <span class="keyword">if</span> b == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">int</span>(math.<span class="built_in">pow</span>(<span class="number">3</span>, a)))</span><br><span class="line">    <span class="keyword">elif</span> b == <span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">int</span>(math.<span class="built_in">pow</span>(<span class="number">3</span>, a - <span class="number">1</span>) * <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">int</span>(math.<span class="built_in">pow</span>(<span class="number">3</span>, a) * <span class="number">2</span>))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P36-打家劫舍"><a href="#Problem-P36-打家劫舍" class="headerlink" title="Problem P36. 打家劫舍"></a>Problem P36. 打家劫舍</h3><p>你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。</p>
<p>给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。</p>
<h4 id="输入-35"><a href="#输入-35" class="headerlink" title="输入"></a>输入</h4><p>输入每个房屋存放金额的非负整数数组</p>
<h4 id="输出-35"><a href="#输出-35" class="headerlink" title="输出"></a>输出</h4><p>输出一夜之内能够偷窃到的最高金额</p>
<h4 id="样例-31"><a href="#样例-31" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1 2 3 1</span><br><span class="line">标准输出：</span><br><span class="line">4</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">2 7 9 3 1</span><br><span class="line">标准输出：</span><br><span class="line">12</span><br></pre></td></tr></table></figure>

<h4 id="解答-35"><a href="#解答-35" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)):</span><br><span class="line">    n[i] = <span class="built_in">int</span>(n[i])</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(n) == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    N = <span class="built_in">len</span>(n)</span><br><span class="line">    dp = [<span class="number">0</span>] * (N + <span class="number">1</span>)</span><br><span class="line">    dp[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    dp[<span class="number">1</span>] = n[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, N+<span class="number">1</span>):</span><br><span class="line">        dp[i] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>], n[i-<span class="number">1</span>] + dp[i-<span class="number">2</span>])</span><br><span class="line">    <span class="built_in">print</span>(dp[N])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P37-戳气球"><a href="#Problem-P37-戳气球" class="headerlink" title="Problem P37. 戳气球"></a>Problem P37. 戳气球</h3><p>有 n 个气球，编号为0 到 n - 1，每个气球上都标有一个数字，这些数字存在数组 nums 中。</p>
<p>现在要求你戳破所有的气球。戳破第 i 个气球，你可以获得 nums[i−1] × nums[i] × nums[i+1] 枚硬币。 这里的 i - 1 和 i + 1 代表和 i 相邻的两个气球的序号。如果 i - 1 或 i + 1 超出了数组的边界，那么就当它是一个数字为 1 的气球。</p>
<p>求所能获得硬币的最大数量</p>
<p>提示：</p>
<ul>
<li>n == nums.length</li>
<li>1 &lt;= n &lt;= 300</li>
<li>0 &lt;= nums[i] &lt;= 100</li>
<li>题目数据保证运算过程不超过 int 所能表示的范围</li>
</ul>
<h4 id="输入-36"><a href="#输入-36" class="headerlink" title="输入"></a>输入</h4><p>输入一行数组num</p>
<h4 id="输出-36"><a href="#输出-36" class="headerlink" title="输出"></a>输出</h4><p>输出所能获得硬币的最大数量</p>
<h4 id="样例-32"><a href="#样例-32" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">3 1 5 8</span><br><span class="line">标准输出：</span><br><span class="line">167</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1 5</span><br><span class="line">标准输出：</span><br><span class="line">10</span><br></pre></td></tr></table></figure>

<h4 id="解答-36"><a href="#解答-36" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)):</span><br><span class="line">    n[i] = <span class="built_in">int</span>(n[i])</span><br><span class="line">n.insert(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">n.insert(<span class="built_in">len</span>(n), <span class="number">1</span>)</span><br><span class="line">store = [[<span class="number">0</span>]*(<span class="built_in">len</span>(n)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n))]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="built_in">len</span>(n)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(n) - i):</span><br><span class="line">        m = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(j+<span class="number">1</span>, i+j):</span><br><span class="line">            left = store[j][k]</span><br><span class="line">            right = store[k][i+j]</span><br><span class="line">            a = left + right + n[j] * n[i+j] * n[k]</span><br><span class="line">            <span class="keyword">if</span> a &gt; m:</span><br><span class="line">                m = a</span><br><span class="line">        store[j][i+j] = m</span><br><span class="line"><span class="built_in">print</span>(store[<span class="number">0</span>][<span class="built_in">len</span>(n)-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P38-分发糖果"><a href="#Problem-P38-分发糖果" class="headerlink" title="Problem P38. 分发糖果"></a>Problem P38. 分发糖果</h3><p>n 个孩子站成一排。给你一个整数数组 ratings 表示每个孩子的评分。 你需要按照以下要求，给这些孩子分发糖果：</p>
<ul>
<li>每个孩子至少分配到 1 个糖果。</li>
<li>相邻的孩子中，评分高的孩子必须获得更多的糖果。</li>
</ul>
<p>请你给每个孩子分发糖果，计算并返回需要准备的最少糖果数目。</p>
<p>提示：</p>
<ul>
<li>n == ratings.length</li>
<li>1 ≤ n ≤ 2×10^4</li>
<li>0 ≤ ratings_i ≤ 2×10^4</li>
</ul>
<h4 id="输入-37"><a href="#输入-37" class="headerlink" title="输入"></a>输入</h4><p>输入一行整数数组ratings</p>
<h4 id="输出-37"><a href="#输出-37" class="headerlink" title="输出"></a>输出</h4><p>输出需要准备的最少糖果数目</p>
<h4 id="样例-33"><a href="#样例-33" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1 0 2</span><br><span class="line">标准输出：</span><br><span class="line">5</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1 2 2</span><br><span class="line">标准输出：</span><br><span class="line">4</span><br></pre></td></tr></table></figure>

<h4 id="解答-37"><a href="#解答-37" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)):</span><br><span class="line">    n[i] = <span class="built_in">int</span>(n[i])</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(n) == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    candy = [<span class="number">1</span>] * <span class="built_in">len</span>(n)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(n)):</span><br><span class="line">        <span class="keyword">if</span> n[i] &gt; n[i-<span class="number">1</span>]:</span><br><span class="line">            candy[i] = candy[i-<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)-<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> n[i-<span class="number">1</span>] &gt; n[i]:</span><br><span class="line">            candy[i-<span class="number">1</span>] = <span class="built_in">max</span>(candy[i-<span class="number">1</span>], candy[i] + <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">sum</span>(candy))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P39-水壶问题"><a href="#Problem-P39-水壶问题" class="headerlink" title="Problem P39. 水壶问题"></a>Problem P39. 水壶问题</h3><p>有两个水壶，容量分别为 jug1Capacity 和 jug2Capacity 升。水的供应是无限的。确定是否有可能使用这两个壶准确得到 targetCapacity 升。</p>
<p>如果可以得到 targetCapacity 升水，最后请用以上水壶中的一或两个来盛放取得的 targetCapacity 升水。</p>
<p>你可以：</p>
<ul>
<li>装满任意一个水壶</li>
<li>清空任意一个水壶</li>
<li>从一个水壶向另外一个水壶倒水，直到装满或者倒空</li>
</ul>
<p>提示:</p>
<p>0 &lt;= jug1Capacity, jug2Capacity, targetCapacity &lt;= 10^6</p>
<h4 id="输入-38"><a href="#输入-38" class="headerlink" title="输入"></a>输入</h4><p>输入三个数 jug1Capacity jug2Capacity targetCapacity</p>
<h4 id="输出-38"><a href="#输出-38" class="headerlink" title="输出"></a>输出</h4><p>输出 true / false</p>
<h4 id="样例-34"><a href="#样例-34" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">3 5 4</span><br><span class="line">标准输出：</span><br><span class="line">true</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">2 6 5</span><br><span class="line">标准输出：</span><br><span class="line">false</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1 2 3</span><br><span class="line">标准输出：</span><br><span class="line">true</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="解答-38"><a href="#解答-38" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">n = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)):</span><br><span class="line">    n[i] = <span class="built_in">int</span>(n[i])</span><br><span class="line">a = n[<span class="number">0</span>]</span><br><span class="line">b = n[<span class="number">1</span>]</span><br><span class="line">c = n[<span class="number">2</span>]</span><br><span class="line"><span class="keyword">if</span> a + b &lt; c:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;false&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> a == <span class="number">0</span> <span class="keyword">or</span> b == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">if</span> c == <span class="number">0</span> <span class="keyword">or</span> a + c == c:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;false&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> c % math.gcd(a, b) == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;false&#x27;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P40-摆动序列"><a href="#Problem-P40-摆动序列" class="headerlink" title="Problem P40. 摆动序列"></a>Problem P40. 摆动序列</h3><p>如果连续数字之间的差严格地在正数和负数之间交替，则数字序列称为 摆动序列 。第一个差（如果存在的话）可能是正数或负数。仅有一个元素或者含两个不等元素的序列也视作摆动序列。</p>
<ul>
<li>例如， [1, 7, 4, 9, 2, 5] 是一个 摆动序列 ，因为差值 (6, -3, 5, -7, 3) 是正负交替出现的。</li>
<li>相反，[1, 4, 7, 2, 5] 和 [1, 7, 4, 5, 5] 不是摆动序列，第一个序列是因为它的前两个差值都是正数，第二个序列是因为它的最后一个差值为零。 子序列 可以通过从原始序列中删除一些（也可以不删除）元素来获得，剩下的元素保持其原始顺序。</li>
</ul>
<p>给你一个整数数组 nums ，返回 nums 中作为 摆动序列 的 最长子序列的长度 。</p>
<p>提示：</p>
<ul>
<li>1 &lt;= nums.length &lt;= 1000</li>
<li>0 &lt;= nums[i] &lt;= 1000</li>
</ul>
<h4 id="输入-39"><a href="#输入-39" class="headerlink" title="输入"></a>输入</h4><p>输入一行整数数组nums</p>
<h4 id="输出-39"><a href="#输出-39" class="headerlink" title="输出"></a>输出</h4><p>输出 nums 中作为 摆动序列 的 最长子序列的长度</p>
<h4 id="样例-35"><a href="#样例-35" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">1 7 4 9 2 5</span><br><span class="line">标准输出：</span><br><span class="line">6</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1 17 5 10 13 15 10 5 16 8</span><br><span class="line">标准输出：</span><br><span class="line">7</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">1 2 3 4 5 6 7 8 9</span><br><span class="line">标准输出：</span><br><span class="line">2</span><br></pre></td></tr></table></figure>

<h4 id="解答-39"><a href="#解答-39" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)):</span><br><span class="line">    n[i] = <span class="built_in">int</span>(n[i])</span><br><span class="line">down = <span class="number">1</span></span><br><span class="line">up = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(n)):</span><br><span class="line">    <span class="keyword">if</span> n[i] &gt; n[i-<span class="number">1</span>]:</span><br><span class="line">        up = down + <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> n[i] &lt; n[i-<span class="number">1</span>]:</span><br><span class="line">        down = up + <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(n) == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">max</span>(up, down))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Problem-P41-跳跃游戏"><a href="#Problem-P41-跳跃游戏" class="headerlink" title="Problem P41. 跳跃游戏"></a>Problem P41. 跳跃游戏</h3><p>给定一个非负整数数组 nums ，你最初位于数组的 第一个下标 。</p>
<p>数组中的每个元素代表你在该位置可以跳跃的最大长度</p>
<p>判断你是否能够到达最后一个下标。</p>
<p>提示：</p>
<ul>
<li>1 ≤ nums.length ≤ 3×10_4</li>
<li>0 ≤ nums_i ≤ 10^5</li>
</ul>
<h4 id="输入-40"><a href="#输入-40" class="headerlink" title="输入"></a>输入</h4><p>输入一行数组nums</p>
<h4 id="输出-40"><a href="#输出-40" class="headerlink" title="输出"></a>输出</h4><p>输出true/fasle</p>
<h4 id="样例-36"><a href="#样例-36" class="headerlink" title="样例"></a>样例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">标准输入：</span><br><span class="line">2 3 1 1 4</span><br><span class="line">标准输出：</span><br><span class="line">true</span><br><span class="line"></span><br><span class="line">标准输入：</span><br><span class="line">3 2 1 0 4</span><br><span class="line">标准输出：</span><br><span class="line">false</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="解答-40"><a href="#解答-40" class="headerlink" title="解答"></a>解答</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)):</span><br><span class="line">    n[i] = <span class="built_in">int</span>(n[i])</span><br><span class="line">k = <span class="number">0</span></span><br><span class="line">reach = <span class="number">0</span></span><br><span class="line">rightmost = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)):</span><br><span class="line">    <span class="keyword">if</span> i &lt;= rightmost:</span><br><span class="line">        rightmost = <span class="built_in">max</span>(rightmost, i + n[i])</span><br><span class="line">        <span class="keyword">if</span> rightmost &gt;= <span class="built_in">len</span>(n) - <span class="number">1</span>:</span><br><span class="line">            reach = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> reach == <span class="number">1</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;false&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>🌙基础学习</category>
        <category>⭐算法设计与分析</category>
      </categories>
  </entry>
</search>
