---
title: 人脸识别-人脸识别合集 | 4 DeepID2+解析(港中文 2014)
categories:
  - 🌙进阶学习
  - ⭐人工智能 Artificial Intelligence
  - 💫研究领域 Research Area
  - 🛰️计算机视觉 Computer Vision
  - ☄️人脸识别 Face Recognition
abbrlink: a97689db
date: 2023-06-11 06:07:47
tags:
---

DeepID2+是Yi Sun,Xiaogang Wang,Xiaoou Tang于2014.12发表，改进了网络结构，增加了隐藏表示的维度和对早期卷积层的监督，展示了深度网络的3个特性，[Deeply learned face representations are sparse, selective, and robust](https://arxiv.org/abs/1412.1265)

<!--more-->

***

### 主要思想

- DeepID2+的改进（相比于DeepID2）：
    - DeepID层从160维提高到512维。
    - 训练集将CelebFaces+和WDRef数据集融合，共有12000人，290000张图片。
    - 将DeepID层不仅和第四层和第三层的max-pooling层连接，还连接了第一层和第二层的max-pooling层，并且用识别和验证信号监督这四个全连接层。
- 高性能深度网络的的三个特性： 稀疏性、选择性和稳健性
    - 神经元适度的稀疏性最大化了深度网络的判别力以及图像之间的距离，甚至在神经反应被二值化后，DeepID2+仍然可以实现高识别准确度。
    - 高层神经元对身份和身份相关属性具有高度选择性，比较敏感。可以识别不同的神经元子集，当存在不同的身份或属性时，这些子集总是被激发或总是被抑制。虽然DeepID2+没有被教导在训练期间区分属性，但它隐含地学习了这样的高级概念。
    - 对遮挡更有稳健性，尽管在训练集中没有针对遮挡情况进行训练
- 依旧用identification+verification supervisory signal来学习特征
- 人脸验证：组合贝叶斯
- LWF上99.47%，YTF上93.2%

***

### 网络结构

- 监督信号不仅作用于最后一层全连接层，还作用于中间第1、2、3全连接层（池化后）。
- 用红框中的特征提取层进行人脸识别，是512维特征向量，
- 也用到了识别和验证监督信号。如图黄色箭头表示监督信号，Id和Ve分别表示identification和verification监督信号。
- 如给出一对不同的训练图像，输入到左侧和右侧的相同DeepID2+网络。通过对两幅图像在深度id2网络上的前向传播，得到两个DeepID2特征向量(fi和fj)。然后每个特征向量都被分类到8192个身份中（训练样本共8192个人）的一个，进而生成分类(识别)误差。用的也是基于L2范数的损失函数，类似对比损失。若两张图属同一人，则验证误差为：

{% asset_img 1.webp %}

否则为：

{% asset_img 2.webp %}

***

### DeepID2+的改进（相比于DeepID2）

- 它在四个卷积层的每一个中具有128个特征图，最终的特征表示从160维增加到了512维。
- 通过合并CelebFaces+和WDRef数据集，并添加了LFW中的一些新数据。DeepID2+网络训练集有来自12,000个身份的大约290,000张人脸图像，而用于训练DeepID2网络只有8,000个身份的160,000张图像。
- DeepID2+通过将512维全连接层连接到四个卷积层中的每一个（在最大池化之后）来加强监督，对于n=1,2,3,4表示为FC-n， 并且用识别和验证信号监督这四个全连接层。这样，监督信号变得“更接近”早期卷积层从而更有效。
    - 而在DeepID2网络中，监督信号仅被添加到连接到第3和第4卷积层的一个全连接层，而较低卷积层只能通过从较高层反向传播的梯度来监督。

{% asset_img 3.webp %}
{% asset_img 4.webp %}

***

### 神经元激活的中等稀疏性

- 稀疏性体现在两个方面：
    1. 每个图像大约有一半的神经元是被激活的。神经元的中等稀疏性，使得他们能够有最大的判别能力。
    2. 每个神经元在大约一半的图像上是被激活的。图像的中等稀疏性，使得不同身份的人脸图像具有最大的可区分性。

如直方图，左图计算了验证集中每张图被激活的神经元数在292个左右（共512个）；右图计算了每个神经元被激活的图像数在26565张左右（共46594张）。

{% asset_img 5.webp %}

***

### 验证激活模式

- 验证神经元是否需要精确的激活值，通过阈值化将神经活动转化为二进制编码。结果可知将神经元输出二值化，发现性能下降不大。

如表，在LFW上对原始的DeepID2+特征及其二值化表示进行了比较。real comb表示25个网络的原始FC-4层表示的精度，用联合贝叶斯作为相似性度量。后两行是二进制表示形式的精度，分别以联合贝叶斯和汉明距离作为相似性度量。

{% asset_img 6.webp %}

***

### 对身份和属性的选择性

作者通过以下三个方面进行分析：

- 神经元在身份和属性上都比LBP好。

Fig.8：属性分类的精确性，单个DeepID2+与水平翻转图像的特征和不同维度的LBP特征比较。
Fig.9：身份分类的准确性比较，单个DeepID2+和LBP特征比较，使用身份名称的首字母。

{% asset_img 7.webp %}

（2）神经元的兴奋与抑制

- 对身份和面部特征的识别是由神经元对某些身份或属性的兴奋和抑制模式决定的。例如，当一个神经元看到乔治·布什时可能会兴奋，而当它看到科林·鲍威尔时就会变得抑制。对于给定的特征和剩余的图像，LBP特征的范围是重叠的。与深度id2 +神经激活相比，LBP特征的分类精度要低得多，大部分特征都是在50%的随机猜测线上积累起来的。

如下图为DeepID2+的神经元和LBP特征的激活情况，以及单个神经元（特征）的分类准确率。左列是对于单个身份的所有图像中神经元（特征）的激活情况的均值和标准差，均值由红线表示，标准差表示为由(均值-标准差)到(均值+标准差)的纵向小线段；中列是对于所有剩下图像的均值和标准差，与左列较为接近；右列是单个神经元（特征）的分类准确率，红点表示神经元处于激活状态，蓝点为抑制状态。

{% asset_img 8.webp %}
{% asset_img 9.webp %}

（3）神经元激活值的分布

- 通过一些神经元值分布的例子，表明在某个身份或属性上兴奋的神经元，在其他的身份或属性上是抑制的。

Fig.14图中显示了兴奋性神经元和抑制性神经元的柱状图，它们能很好地将每个属性与其余图像区分开来的那些带有神经ID和分类精度。其他直方图用黑色框起来，上面只有神经ID。
Fig.13是每个人的五个兴奋性神经元(偶数行)和五个抑制性神经元(奇数行)的直方图，显示了区分给定身份和剩余图像的最高二分类精度。

{% asset_img 10.webp %}
{% asset_img 11.webp %}

***

### 特征对遮挡的稳健性

一般遮挡率越高，性能越低。用两种手工遮挡方式，对比其他方法，DeepID2+鲁棒性较好。当使用所有四个监督时最鲁棒。尽管特征是在没有人为遮挡的图像上训练的net上提取的，但是却自动地学习到了对遮挡鲁棒的特征。

{% asset_img 12.webp %}

图18和19还给出了遮挡情况下每个神经元被激活的情况，对于两种类型的遮挡，激活模式基本保持不变，直到很大程度的遮挡。

{% asset_img 13.webp %}

- 某32个神经元中，同一个人中无论遮挡有些神经元总是处于激活态。不同的人对应的神经元激活不一样。在大约一半的面部图像上，神经元通常会被激活。但是，对于属于特定个人或属性的所有图像，它可能会不断地激活(或不激活)。从这个意义上说，神经元是稀疏的，并且对身份和属性具有选择性，对遮挡有稳健性。

左：DeepID2+神经元对布什和鲍威尔图像的反应。
右：选取少数神经元对所有LFW人脸图像(作为背景)、所有属于Bush的图像、所有属性为男性的图像、所有属性为女性的图像进行神经元1~4激活直方图显示。

{% asset_img 14.webp %}

***

### 性能测试结果

测试时，做法，训练25个网络去提取与DeepID2相同的25个人脸图像块，与25个人脸区域进行水平翻转联合，然后使用联合贝叶斯进行联合预测。LWF上99.47%，YTF上93.2%。
校正LFW和YouTubeFaces中一些错误的测试脸对后，人脸验证精度提高到在LFW上99.52%，YouTubeFaces上93.8% 。

{% asset_img 15.webp %}
{% asset_img 16.webp %}

分别比较DeepID2+网络与没有逐层监督信号(layer-wise supervision)、较少的训练集、较少的feature map情况的性能，结果可知缺任何一项性能都会降低。

{% asset_img 17.webp %}

***

### 参考资料

> <https://zhuanlan.zhihu.com/p/76535349>
> <https://blog.csdn.net/yuanchheneducn/article/details/51034463>
> <https://cjmcv.github.io/deeplearning-paper-notes/freg/2015/10/02/DeepID2+.html>
> <https://www.weibo.com/1402400261/DeCUv2Wmh?type=comment>
