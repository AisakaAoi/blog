---
title: 学习报告：基于几何放大的注意力图卷积网络用于基于骨架的微手势识别
categories:
  - 🌙进阶学习
  - ⭐脑机接口与混合智能研究团队（BCI团队）
  - 💫学习报告
abbrlink: 95a52ba
date: 2024-02-02 11:05:24
tags:
---

### 论文概要

微姿势（MG）识别是一项新兴且具有挑战性的任务，由于关节的持续时间短且幅度小所以比常规手势更难识别。为了解决上述问题，针对微姿势骨架数据建模，该论文提出了一种基于几何放大的注意力图卷积网络（MA-GCN）来放大和选择特征。该网络主要由两个模块组成：几何放大模块（GM模块）控制不同关节的放大倍数，空间时间注意力图卷积模块（STA模块）通过对不同关节和帧进行加权选择有效信息，以专注于微妙的运动。作者在两个MG数据集上进行了大量实验证明，其提出的方法取得了显著的性能。

该论文被2023 IEEE International Conference on Image Processing (ICIP)接收，题目为《Geometric Magnification-based Attention Graph Convolutional Network for Skeleton-based Micro-Gesture Recognition》，东南大学的Haolin Jiang为此文的第一作者，东南大学的Wenming Zheng为此文的通讯作者。

<!--more-->

***

### 作者贡献及创新点

设计了几何放大模块（GM模块）：为了应对MG幅度较小的特点，作者设计了GM模块，根据运动方向自适应地放大输入关节坐标的运动幅度，以提高MG识别的准确性。

提出了空间时间注意力图卷积模块（STA模块）：为了减少冗余的关节和帧信息，并提取最相关的关节特征和帧序列用于MG分类，作者提出了STA模块，分别考虑了不同关节和帧在空间和时间维度上的重要性。

提出了基于几何放大的注意力图卷积网络（MA-GCN）：将GM模块和STA模块结合起来，构建了MA-GCN模型，在两个MG数据集上取得了显著的性能，超过了现有方法。

***

### 总体框架

模型的总体框架如图1所示，该架构包含了GM和STA模块。GM模块用于自适应放大运动图像，而STA模块用于提取有效的联合特征和时序信息。

{% asset_img 1.webp %}
<div align='center'>图 1 MA-GCN框架图</div>

视频运动放大技术可以放大人眼无法察觉的微小运动。然后，可以通过设计合适的滤波器来提取和放大运动特征。但是骨骼数据主要包含人体关节的2D或3D坐标，并不包含无关的背景信息。因此，GM的目标是放大骨骼数据。通过几何放大方法将输入的关节坐标进行放大。

STA模块利用了图结构来对骨骼数据进行建模。空间时间注意力图卷积包含了空间注意力图卷积和时间注意力图卷积两个分支：

空间注意力图卷积通过图卷积操作，包含了特征提取分支和注意力分支。其具体实现细节由图2所示，特征提取分支使用基于人体关节自然连接的空间图 A 来进行图卷积操作。注意力分支使用自注意力机制来计算关节之间的相似度从而构建关节邻接图。然后利用图卷积提取图邻接特征，并通过线性变换得到空间注意力向量。

{% asset_img 2.webp %}
<div align='center'>图 2 空间注意力图卷积</div>

时间注意力图卷积也包含了特征提取分支和注意力分支，其具体实现细节由图2所示。在特征提取分支中，利用一维卷积对连续帧之间的相同关节进行时序图卷积操作。在注意力分支中，首先使用平均池化聚集输入特征的空间信息，然后利用时序图卷积计算得到时间注意力向量。最后将时间注意力向量与特征提取分支的输出特征进行加权得到经过时间注意力加权的特征。

{% asset_img 3.webp %}
<div align='center'>图 3 时间注意力图卷积</div>

***

### 实验结果

作者在两个MG数据集上评估了其方法：SMG 和iMiGUE 。

MG数据集共有来自40个参与者的3692个MG样本，分为17个类别，其中骨骼坐标是由Kinect V2传感器记录的，包括25个关节。iMiGUE数据集共有18,499个MG样本，分为32个类别。。

对于SMG数据集，样本的平均长度为51.3帧。为了方便起见，作者将所有样本填充到150帧，即重复样本序列直到达到150帧。采用了跨主体的协议对模型进行90个epochs的训练和验证。批量大小为8，学习率设为0.002，每30个epochs除以2。

作者将在iMiGUE数据集和SMG数据集上进行动作识别的最先进方法进行了比较，相应的结果如图4和图5所示.

{% asset_img 3.webp %}
<div align='center'>图 4 在IMiGUE数据集上实验对比</div>

{% asset_img 3.webp %}
<div align='center'>图 5 在SMG数据集上实验对比</div>

***

### 结论

在本文中，作者提出了一种基于几何放大的注意力图卷积网络（Geometric Magnification-Based Attention Graph Convolutional Network），用于微手势识别中的特征放大和过滤。MA-GCN主要由两个模块组成：一个是几何放大模块，用于放大关节的振幅；另一个是时空注意力图卷积模块，用于选择有效的关节和时序信息。对两个微手势数据集进行了大量实验证明，我们的方法表现优于其他最先进的方法。

***

### 原文链接

> <https://www.scholat.com/teamwork/showPostMessage.html?id=15114>
