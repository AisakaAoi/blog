---
title: 人脸识别-基于深度学习的人脸识别发展历史
categories:
  - 🌙进阶学习
  - ⭐人工智能 Artificial Intelligence
  - 💫研究领域 Research Area
  - 🛰️计算机视觉 Computer Vision
  - ☄️人脸识别 Face Recognition
abbrlink: 2fb60bd8
date: 2023-06-07 03:08:12
tags:
---

{% asset_img 1.webp %}

从2014年DeepFace开始到2019年的算法，还有一些用于人脸识别的损失函数：基于欧几里得距离的损失函数（Contrastive Loss、Triplet Loss、Center Loss）；基于Angular Margin相关的损失函数（L-Softmax Loss、A-Softmax Loss、COCO Loss、CosFace Loss、ArcFace Loss）等。

<!--more-->

***

### 基于深度学习的人脸识别发展历史

- 2014年DeepFace和DeepID系列都是主要先训练Softmax多分类器人脸识别框架；然后抽取特征层，用特征再训练另一个神经网络、孪生网络或组合贝叶斯等人脸验证框架。想同时拥有人脸验证和人脸识别系统，需要分开训练两个神经网络。但线性变换矩阵W的大小随着身份数量n的增加而线性增大。
    - DeepFace、DeepID框架为 CNN+Softmax，网络在第一个FC层形成判别力很强的人脸特征，用于人脸识别。
    - DeepID2、DeepID2+、DeepID3都采用 CNN+Softmax+Contrastive Loss，使得同类特征的L2距离尽可能小，不同类特征的L2距离大于某个间隔。
- 2015年FaceNet提出了一个绝大部分人脸问题的统一解决框架，直接学习嵌入特征，然后人脸识别、人脸验证和人脸聚类等都基于这个特征来做。FaceNet在 DeepID2 的基础上，抛弃了分类层，再将 Contrastive Loss 改进为 Triplet Loss，获得类内紧凑和类间差异。但人脸三元组的数量出现爆炸式增长，特别是对于大型数据集，导致迭代次数显著增加；样本挖掘策略造成很难有效的进行模型的训练。
    - 2017年《In Defense of the Triplet Loss for Person Re-Identification》提出了 Soft-Margin 损失公式替代原始的 Triplet Loss 表达式，并引进了 Batch Hard Sampling。
    - 2017年Wu, C等从导函数角度解释了为什么 Non-squared Distance 比 Squared-distance 好，并在这个 insight 基础上提出了 Margin Based Loss。此外，他们还提出了 Distance Weighted Sampling。文章认为 FaceNet 中的 Semi-hard Sampling，Deep Face Recognition 中的 Random Hard 和 Batch Hard 都不能轻易取到会产生大梯度（大loss，即对模型训练有帮助的 triplets）。
- 2015年VGGNet为了加速 Triplet Loss 的训练，先用传统的 softmax 训练人脸识别模型，因为 Classficiation 信号的强监督特性，模型会很快拟合；之后移除Classificiation Layer，用 Triplet Loss 对模型进行特征层 finetune。
- 2016年Center Loss为每个类别学习一个中心，并将每个类别的所有特征向量拉向对应类别中心，根据每个特征向量与其类别中心之间的欧几里得距离，以获得类内紧度；而类间分散则由Softmax loss 的联合惩罚来保证。然而，在训练期间更新实际类别中心非常困难，因为可供训练的人脸类别数量最近急剧增加。
- 2017年COCO Loss，归一化了权值c，归一化了特征f，并乘尺度因子，在LFW上达到99.86%；
- 2017年SphereFace提出A-Softmax，是L-Softmax的改进，提出了角度间隔惩罚，又归一化了权值W，让训练更加集中在优化深度特征映射和特征向量角度上，降低样本数量不均衡问题。
    - 《Learning towards minimum hyperspherical energy》又说了它的损失函数需要一系列近似才能计算出来，从而导致网络训练不稳定。为了稳定训练，他们提出混合Softmax loss损失函数，经验上，softmax loss 在训练过程中占主导地位，因为基于整数的乘性角度间隔使得目标逻辑曲线非常陡峭，从而阻碍了收敛。
- 2018年CosFace直接将cosine间隔惩罚添加到目标逻辑回归中，采用加法余弦间隔，cos(θ)-m，归一化特征向量和权重。与SphereFace相比，它获得了更好的性能，更容易的实现，减少了softmax loss联合监督的需要。
- 2018年ArcFace提出加性角度间隔损失，θ+m，还归一化特征向量和权重，几何上有恒定的线性角度margen。直接优化弧度，为了性能的稳定，ArcFace不需要与其他loss函数实现联合监督。
- 2018年MobileFaceNets，MobileNetV2+ArcFace Loss，轻量化模型。

***

DeepFace、DeepID、DeepID2、DeepID2+、DeepID3、FaceNet、VGGFace、SphereFace、CosFace、ArcFace

***

### 参考资料

> <https://zhuanlan.zhihu.com/p/76511732>
