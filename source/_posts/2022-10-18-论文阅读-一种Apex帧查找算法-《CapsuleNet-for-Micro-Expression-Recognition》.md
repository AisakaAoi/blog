---
title: è®ºæ–‡é˜…è¯»-ä¸€ç§Apexå¸§æŸ¥æ‰¾ç®—æ³•-ã€ŠCapsuleNet for Micro Expression Recognitionã€‹
categories:
  - ğŸŒ™è¿›é˜¶å­¦ä¹ 
  - â­äººå·¥æ™ºèƒ½ Artificial Intelligence
  - ğŸ’«è®¡ç®—æœºè§†è§‰ Computer Vision
  - ğŸ›°ï¸æƒ…ç»ªè¯†åˆ« Emotion Recognition
abbrlink: '19376813'
date: 2022-10-18 11:19:54
tags:
---

### åŸæ–‡

{% pdf ./file/paper/2019-CapsuleNet-for-Micro-Expression-Recognition.pdf %}

<!--more-->

***

### å¾®è¡¨æƒ…åºåˆ—ä¸­Apexå¸§ä»‹ç»

ä¸€ä¸ªå¾®è¡¨æƒ…è§†é¢‘åºåˆ—ä»¥Onsetå¸§å¼€å§‹ï¼Œä»¥Offsetå¸§ç»“æŸï¼Œé€šå¸¸ä¿æŒä¸­æ€§çš„è¡¨æƒ…ï¼›å…¶ä¸­Apexå¸§æ˜¯åœ¨åºåˆ—ä¸­å˜åŒ–å¼ºåº¦æœ€å¤§çš„é‚£ä¸€å¸§ã€‚

ä¸€ä¸ªå¾®è¡¨æƒ…åºåˆ—çš„Apexå¸§ï¼Œåœ¨å¾®è¡¨æƒ…åˆ†ç±»ä¸­èƒ½æä¾›ä¸°å¯Œçš„ç‰¹å¾ï¼Œå¯ä»¥å¸®åŠ©æ¥ä¸‹æ¥çš„å…‰æµç‰¹å¾æå–ã€è¿ç§»å­¦ä¹ ç­‰ã€‚

***

### ä¸€ç§æŸ¥æ‰¾Apexå¸§ç®—æ³•

ä¸‹é¢æ˜¯ä¸€ç§åœ¨å¾®è¡¨æƒ…åºåˆ—ä¸­æå–Apexå¸§çš„ç®—æ³•ï¼Œç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š
1. æ ¹æ®é¢éƒ¨68ä¸ªç‰¹å¾ç‚¹ï¼Œå®šä½10ä¸ªå¾®è¡¨æƒ…è‚Œè‚‰ç§»åŠ¨å‘ç”Ÿé¢‘ç¹çš„åŒºåŸŸ
2. å®šä¹‰å˜åŒ–å¼ºåº¦Mï¼Œç”¨äºè¡¡é‡åºåˆ—ä¸­æ¯ä¸€å¸§å˜åŒ–å¤§å°
3. éå†åºåˆ—å¸§ï¼Œè®¡ç®—æ¯ä¸€å¸§å˜åŒ–å¼ºåº¦Miï¼Œå–å€¼æœ€å¤§çš„é‚£å¸§ä½œä¸ºApexå¸§

#### Step 1 å®šä¹‰10ä¸ªé¢éƒ¨åŒºåŸŸå—

é¦–å…ˆé€šè¿‡ä¸€ä¸ªå¼€æºé¢éƒ¨å·¥å…·(ageitgey/face_recognition)[https://github.com/ageitgey/face_recognition]å®šä½æ¯ä¸€å¸§68ä¸ªé¢éƒ¨ç‰¹å¾ç‚¹ï¼Œæ¥ç€åŸºäºè¿™äº›ç‰¹å¾ç‚¹å®šä¹‰10ä¸ªé¢éƒ¨åŒºåŸŸå—ã€‚å…¶æ•ˆæœå¦‚å›¾1ï¼š

{% asset_img 1.webp %}

è¿™10ä¸ªåŒºåŸŸåˆ†åˆ«é€‰å–left_lipã€right_lipã€chinã€left_noseã€right_noseã€left_eyeã€right_eyeã€left_eyebrowã€right_eyebrowå¤„çš„ç‰¹å¾ç‚¹ä½œä¸ºåŸºå‡†ç‚¹ï¼Œå½¢æˆæ­£æ–¹å½¢å—ã€‚å…¶ä¸­ï¼Œæ­£æ–¹å½¢çš„è¾¹é•¿æ˜¯ä¸Šå˜´å”‡è·ç¦»çš„ä¸€åŠï¼Œä½œè€…ç§°è¾¹é•¿çš„ç¡®å®šæ˜¯å¯å‘å¼åœ°ï¼ˆheuristicallyï¼‰ã€‚

ä¸‹é¢ä»¥å·¦å˜´å”‡æ­£æ–¹å½¢å—åŒºåŸŸä¸¾ä¾‹ï¼š

``` python
import face_recognition
import numpy as np

# è·å–å½“å‰frameçš„äººè„¸ç‰¹å¾ç‚¹ï¼Œlmksæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œè®°å½•äº†68ä¸ªç‰¹å¾ç‚¹åæ ‡
lmks = face_recognition.face_landmarks(frame)[0]

# æ­£æ–¹å½¢å®½åº¦çš„ç¡®å®š
cell_width = int((lmks['top_lip'][6][0] - lmks['top_lip'][0][0]) / 2)
# æœ€å·¦å˜´å”‡ç‚¹çš„åæ ‡
leftmost_lip_point=lmks['top_lip'][0]
# ç¡®å®šæ­£æ–¹å½¢å—å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡ï¼Œæ®æ­¤ç¡®å®šä¸€ä¸ªå—
left_lip_rect=
tuple(np.array(leftmost_lip_point) - int(cell_width / 2)),
tuple(np.array(leftmost_lip_point) + int(cell_width / 2))
```

#### Step 2 å®šä¹‰å˜åŒ–å¼ºåº¦

é¦–å…ˆåˆ†åˆ«è®¡ç®—å½“å‰å¸§ä¸Onsetå¸§ã€Offsetå¸§åœ¨è¿™10ä¸ªåŒºåŸŸå—çš„ç»å¯¹åƒç´ å·®ï¼Œä¸ºäº†å‡å°‘ç¯å¢ƒå™ªéŸ³å½±å“ï¼Œå°†å·®å€¼çš„é™¤ä»¥å½“å‰å¸§ä¸åå·®ä¸ºĞ—çš„è¿ç»­å¸§çš„ç»å¯¹åƒç´ å·®ã€‚å°†è§„åŒ–åçš„åƒç´ å·®æ±‚å’Œï¼Œè¡¨ç¤ºå½“å‰å¸§çš„å˜åŒ–å¼ºåº¦å€¼ï¼Œå³Miã€‚ï¼ˆĞ— è¡¨ç¤ºepsilon,ä¸€ä¸ªå˜é‡ï¼Œå¹¶éæ•°å­—3ï¼‰

{% asset_img 2.webp %}

ä¸‹é¢æ ¹æ®è®¡ç®—è„¸éƒ¨æŸä¸ªåŒºåŸŸçš„å˜åŒ–å¼ºåº¦å‡½æ•°ï¼Œç†è§£ä¸Šè¿°å…¬å¼ã€‚å®é™…ä¸Šè¿˜éœ€è¦å¯¹10ä¸ªé¢éƒ¨åŒºåŸŸå—åˆ†åˆ«è®¡ç®—ï¼Œå–å…¶å‡å€¼ä½œä¸ºå½“å‰å¸§çš„å˜åŒ–å¼ºåº¦å€¼Miã€‚

``` python
def compute_cell_difference(cell_t: np.ndarray, cell_onset: np.ndarray, cell_offset: np.ndarray, cell_epsilon: int): 
    """ 
    è®¡ç®—æŸå—åŒºåŸŸçš„å˜åŒ–å¼ºåº¦ 
    :param cell_t:å½“å‰é¢éƒ¨åŒºåŸŸå— 
    :param cell_onset:èµ·å§‹å¸§ 
    :param cell_offset:æœ«å°¾å¸§ 
    :param cell_epsilon:åå·®ä¸ºepsilonçš„å¸§ 
    :return: ä¸€ä¸ªfloat 
    """ 
    numerator = (np.abs(cell_t - cell_onset) + 1.0) 
    # åˆ†å­åˆ†æ¯åŒæ—¶åŠ 1çš„ä¸€ä¸ªåŸå› æ˜¯é˜²æ­¢å‡ºç°'inf'æ•°æ® 
    denominator = (np.abs(cell_t - cell_epsilon) + 1.0) 
    difference = numerator / denominator 

    numerator = (np.abs(cell_t - cell_offset) + 1.0) 
    difference1 = numerator / denominator 
 
    difference = difference + difference1 
    return difference.mean() 
```

#### Step 3 éå†æŸ¥æ‰¾

éå†è®¡ç®—å¯¹åº”å¸§çš„çš„å˜åŒ–å¼ºåº¦M,å–å€¼æœ€å¤§çš„é‚£å¸§ä½œä¸ºApexå¸§ã€‚

æµ…è“è‰²æ›²çº¿æè¿°äº†åºåˆ—ä¸­æ¯å¸§çš„å˜åŒ–å¼ºåº¦Må€¼çš„å˜åŒ–ã€‚

{% asset_img 3.webp %}

***

### å®éªŒ

CASMEâ…¡ å¾®è¡¨æƒ…æ•°æ®é›†å·²ç»å¯¹å…¶ä¸­çš„å¾®è¡¨æƒ…åºåˆ—Apexå¸§è¿›è¡Œäº†äººå·¥æ ‡æ³¨ï¼Œåœ¨æ­¤æ•°æ®é›†ä¸Šä½¿ç”¨ä¸Šè¿°ç®—æ³•è¿›è¡Œè‡ªåŠ¨æŸ¥æ‰¾ï¼Œè§‚å¯Ÿå®éªŒç»“æœã€‚

1. å‡†å¤‡CASMEâ…¡ æ•°æ®é›†
2. è¿è¡Œä»£ç å¾—åˆ°é¢„æµ‹çš„Apex å¸§åºå·æ•°ç»„pred_apex_id_listï¼Œå›¾3 æ˜¾ç¤ºäº†æŸä¸ªå¾®è¡¨æƒ…åºåˆ—çš„Apexå¸§æ ‡æ³¨è¿‡ç¨‹
3. é€šè¿‡äººå·¥æ ‡æ³¨çš„Apexå¸§åºå·æ•°ç»„groundtruth_apex_id_list å’Œè‡ªåŠ¨é¢„æµ‹çš„Apexå¸§åºå·æ•°ç»„ pred_apex_id_listï¼Œå¾—åˆ°ç»å¯¹å·®å€¼æ•°ç»„absolute_difference_list, è§‚å¯Ÿå…¶å¹³å‡å€¼ï¼ˆä¹Ÿå³ä¸¤ç»„æ•°æ®çš„**å¹³å‡ç»å¯¹è¯¯å·®ï¼ŒMAE**ï¼‰ã€æ— åæ ‡å‡†å·®(ä¸¤ç»„æ•°ç»„çš„**å‡æ–¹æ ¹è¯¯å·®, RMSE**)ã€ä¸­ä½æ•°ã€‚

{% asset_img 4.png %}

å…¶å¹³å‡å€¼7.91, ä¸­ä½æ•°4.0ï¼Œæ— åæ ‡å‡†å·®10.0, ååº”äº†å…¶é›†ä¸­è¶‹åŠ¿å’Œæ³¢åŠ¨å¤§å°ã€‚

{% asset_img 5.png %}

***

### å‚è€ƒæ–‡çŒ®

[1] N. V. Quang, J. Chun and T. Tokuyama, "CapsuleNet for Micro-Expression Recognition," 2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019), 2019, pp. 1-7, doi: 10.1109/FG.2019.8756544.

***

### åŸæ–‡é“¾æ¥

> <https://zhuanlan.zhihu.com/p/425412701>
