---
title: SFFAI 101 | 多模态预训练专题《甘哲：多模态预训练的最新进展》
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: 8edf647a
date: 2021-04-03 22:03:23
tags:
---

<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=891461827&bvid=BV1VP4y1j7ah&cid=436050801&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>

<!--more-->

关注公众号：【人工智能前沿讲习】，回复【SFFAI101】入交流群，推荐论文下载。

随着OpenAI CLIP和DALL-E等模型的相继出现，多模态预训练成为一个日益热门的研究方向。在本次的talk中，我将分享我们组在这个领域上最近发表在ECCV 2020和NeurIPS 2020的几个工作。我将具体讨论如下主题。第一，如何实现多模态预训练？第二，如何理解预训练模型学到了什么？第三，如何提高预训练模型的效果？对抗训练能否达到这样的目的？第四，如何评测和提高预训练模型的鲁棒性？

***

### 讲者介绍

**甘哲：**微软高级研究员，主要研究方向为多模态预训练，2010年和2013年获得北京大学本科和硕士学位，2018年获得杜克大学博士学位。曾担任，或正在担任NeurIPS 2021/2020/2019, ICML 2021, ICLR 2021, AAAI 2021/2020，以及ACL 2021的领域主席。

**报告题目：**多模态预训练的最新进展

**报告摘要：**随着OpenAI CLIP和DALL-E等模型的相继出现，多模态预训练成为一个日益热门的研究方向。在本次的talk中，我将分享我们组在这个领域上最近发表在ECCV 2020和NeurIPS 2020的几个工作。我将具体讨论如下主题。第一，如何实现多模态预训练？第二，如何理解预训练模型学到了什么？第三，如何提高预训练模型的效果？对抗训练能否达到这样的目的？第四，如何评测和提高预训练模型的鲁棒性？

**Spotlight：**
1. UNITER：如何实现多模态预训练？ECCV 2020；
2. VALUE：如何理解预训练模型学到了什么？ECCV 2020 Spotlight；
3. VILLA：如何提高预训练模型的效果？NeurIPS 2020 Spotlight；
4. MANGO：如果评测预训练模型的鲁棒性？Ongoing work (arXiv preprint) 。

***

### 论文推荐

1. ViLBERT Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks

2. LXMERT Learning Cross-Modality Encoder Representations from Transformers

    **推荐理由：**这两篇论文都是第一批关于多模态预训练模型的工作。

3. UNITER UNiversal Image-TExt Representation Learning

    **推荐理由：**比较经典的关于多模态预训练的工作，截至论文发表，在13个多模态数据集和任务上取得state-of-the-art的结果。

4. Behind the Scene Revealing the Secrets of Pre-trained Vision-and-Language Models

    **推荐理由：**ECCV 2020 Spotlight论文，详细分析了多模态预训练模型学到了什么。

5. Large-Scale Adversarial Training for Vision-and-Language Representation Learning

    **推荐理由：**NeurIPS 2020 Spotlight论文，使用对抗训练的方法提高预训练模型的效果。

6. A Closer Look at the Robustness of Vision-and-Language Pre-trained Models

    **推荐理由：**如何评测和提高多模态预训练模型的鲁棒性，在7个关于VQA鲁棒性的任务中取得state-of-the-art的结果。

***

### 参考资料

> <https://www.bilibili.com/video/BV1VP4y1j7ah/>
