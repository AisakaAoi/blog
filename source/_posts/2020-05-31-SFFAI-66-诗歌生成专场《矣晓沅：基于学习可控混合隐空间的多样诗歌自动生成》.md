---
title: SFFAI 66 | 诗歌生成专场《矣晓沅：基于学习可控混合隐空间的多样诗歌自动生成》
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: fe66a8d5
date: 2020-05-31 05:03:29
tags:
---

<iframe src="//player.bilibili.com/player.html?aid=583575381&bvid=BV1Sz4y1Q7WM&cid=202540513&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<!--more-->

关注微信公众号：【人工智能前沿讲习】，回复【SFFAI66】获取讲者PPT资料，入交流群，推荐论文下载。

清华大学自然语言处理与社会人文计算实验室（THUNLP）开发的人工智能诗歌写作系统“九歌”在2017年上线后立即就产生了巨大的轰动。九歌能够产生集句诗、近体诗、藏头诗等不同体裁的诗歌，融合了现代技术和中国古典文化，在推动自然语言处理技术发展，弘扬中华优秀传统文化等方面都有所帮助。SFFAI 66—诗歌生成专场，我们邀请到了九歌系统的主要研发成员矣晓沅，为大家介绍他的最新研究成果。

***

### 讲者介绍

**矣晓沅：**清华大学计算机系博士生，主要研究方向为文本自动生成，目前以一作(含共同一作)身份于ACL，EMNLP，CoNLL，IJCAI，AAAI等会议发表论文6篇，作为主要成员研发了清华中文古典诗歌自动生成系统“九歌”，师从THUNLP实验室孙茂松教授。

**报告题目：**基于学习可控混合隐空间的多样诗歌自动生成

**报告摘要：**诗歌的自动生成是构建可计算性创新的重要一步，在商业娱乐、智能文化教育、数字人文研究等领域有广泛的应用价值。目前的神经诗歌生成模型在诗歌质量上取得了较大的提升，然而这些生成的诗歌往往缺乏多样性，即使给定不同的输入(关键词或者标题)，生成的内容也多有雷同。相关的文学理论研究表明，诗人的人生经历，所处的时代背景，所属的文学流派等因素能够影响他们的写作风格，进而使得人类创作出来的诗歌丰富多样。基于此，我们提出了MixPoet模型。该模型直接建模这些影响因素，进而构建出多种不同的风格，从而提升生成诗歌的多样性。基于半监督变分自动编码器，我们的模型使用对抗训练将风格隐空间解耦为多个子空间，每个子空间条件依赖到一个影响因素。通过混合不同因素对应的子空间，我们的模型能够构建多样的风格并以此区分生成的诗歌。实验结果表明，我们的模型生成的诗歌在保证质量的同时，成多样性能够超过大部分现有模型。

**Spotlight：**
1. 本文第一次将文学作品的风格解释为不同因素的组合，并在隐空间进行建模，以提升生成诗歌的多样性；
2. 本文提出了一个半监督的框架进行风格空间的解耦和学习，仅需要少量的标注数据训练，模型就能在一定程度上控制风格因素的组合；
3. 在中文古典诗歌生成任务上的实验结果表明，本文提出的MixPoet模型能够同时提升诗歌的质量和多样性。

***

### 论文推荐

#### 领域基础

1. Generating Chinese Couplets using a Statistical MT Approach. [Jiang and Zhou, 2008].

    **推荐理由：**这是篇论文第一次将统计机器翻译模型用于中文对联的自动生成。文中定义了多个统计翻译的feature，部分feature在后续的一些工作中也可以用于后处理，作为神经网络模型的补足。此外，该篇model比较了人工评分和BLEU值的相关性，表明BLEU在一定程度上也可以用于自动评价文学文本的生成。

2. Generating Chinese Classical Poems with Statistical Machine Translation Models.[He et al., 2012].

    **推荐理由：**这篇论文是上一篇的延续，同样是MSRA周明老师组当年的工作。在对联之后，他们将统计机器翻译模型进一步应用到了绝句生成上。该文确定了诗歌生成line to line的生成模式，并且提出了利用古籍《诗学含英》来自动构建多个BLEU reference的方法。

3. Chinese Poetry Generation with Recurrent Neural Networks. [Zhang and Lapata, 2014].

    **推荐理由：**这篇论文是将循环神经网络(RNN)应用到中文诗歌生成的第一篇工作，在诗歌自动生成领域具有奠基性的意义。文中提出的很多方法，如上下文的建模思路等，都直接启发了后续的一系列相关工作。对诗歌生成有兴趣的朋友建议优先读一下这篇文论。

#### 领域前沿

4. Stylistic Chinese Poetry Generation via Unsupervised Style Disentanglement. [Yang et al., 2018]

    **推荐理由：**这是我们九歌团队的另一篇工作。该篇论文中我们提出了一种无监督的风格诗歌生成方法。通过最大化互信息的方式，我们直接将诗歌空间，而非隐空间，解耦为任意设定的K个风格空间。该模型完全基于无监督的方法进行训练，在风格的区分度和诗歌的多样性上，效果要略差于MixPoet。但是该模型的优势在于，无需标注语料，简单易用并且可以任意设置风格的数量。有兴趣的朋友可以阅读一下并和MixPoet作对比。

5. Stochastic Beams and Where to Find Them The Gumbel-Top-k Trick for Sampling Sequences Without Replacement Wouter. [Kool et al., 2019]

    **推荐理由：**文学文本的生成往往对多样性有较高的要求。一般我们使用beam search进行解码，然而beam search容易产生雷同乏味的生成结果。这篇论文是Max welling组的工作。该方法利用Gumbel分布定义了新的Beam Score，从而将随机性自然地引入到Beam Search算法中，并在数学上证明了所提出的Stochastic Beam Search算法能够和原Beam Search一样搜索到局部最优解。该方法比较适合于对多样性和创新性有要求的文本生成任务。

6. An Iterative Polishing Framework based on Quality Aware Masked Language Model for Chinese Poetry Generation. [Deng et al., 2020]

    **推荐理由：**这篇论文同样发表于AAAI，其首次将预训练的Masked Language Model (MLM)用在了中文诗歌生成任务上。该论文先用一个基础的sequence-to-sequence模型生成诗歌的草稿，然后利用BERT对草稿诗中质量较差的字进行mask，而后重新生成，不断迭代，以达到润色的效果。虽然对诗歌进行Iterative Polishing的思路最早应该是I, Poet 模型 (Yan, IJCAI 2016)中提出的，但该篇论文设计了更为有效的mask和prediction的方法，同时也整合了目前强大的BERT模型，值得认真阅读。

***

### 参考资料

> <https://www.bilibili.com/video/BV1Sz4y1Q7WM/>
