---
title: 学术人生-吴恩达：告别大数据，AI需要高质量小数据！
categories:
  - 🌙逢坂杂谈
  - ⭐学术区
abbrlink: 8391ed08
date: 2023-03-30 02:14:05
tags:
---

吴恩达是人工智能（AI）和机器学习领域国际最权威的学者之一，最近一年里，他一直在提“以数据为中心的AI”，希望将大家的目光从以模型为中心转向以数据为中心。

最近，在接受IEEE Spectrum的采访中，他谈到了对基础模型、大数据、小数据以及数据工程的一些感悟，并给出了发起“以数据为中心的AI”运动的原因。

“过去十年，代码—神经网络的架构已经非常成熟。保持神经网络架构固定，寻找改进数据的方法，才会更有效率。”

吴恩达表示，他这种以数据为中心的思想受到了很多的批评，就和当年他发起Google brain项目，支持构建大型神经网络行动，时候受到的批评时一样：想法不新鲜，方向错误。据吴教授介绍，批评者中不乏行业资深人士。

{% asset_img 1.webp %}

<!--more-->

关于小数据，吴教授认为，它同样能够有威力：“只要拥有50个好数据（examples），就足以向神经网络解释你想让它学习什么。”

以下是采访原文，我们做了不改变原意的编译。

{% asset_img 2.webp %}

***

**IEEE：过去十年，深度学习的成功来源于大数据和大模型，但有人认为这是一条不可持续的路径，您同意这个观点么？**

**吴恩达:** 好问题。

我们已经在自然语言处理（NLP）领域看到了基础模型（foundation models）的威力。说实话，我对更大的NLP模型，以及在计算机视觉（CV）中构建基础模型感到兴奋。视频数据中有很多信息可以利用，但由于计算性能以及视频数据处理成本的限制，还无法建立相关的基础模型。

大数据与大模型作为深度学习引擎已经成功运行了15年，它仍然具有活力。话虽如此，但在某些场景下，我们也看到，大数据并不适用，“小数据”才是更好的解决方案。

***

**IEEE：您提到的CV基础模型是什么意思？**

**吴恩达:** 是指规模非常大，并在大数据上训练的模型，使用的时候可以为特定的应用进行微调。是我和斯坦福的朋友创建的术语，例如GPT-3就是NLP领域的基础模型。基础模型为开发机器学习应用提供了新的范式，有很大的前景，但同时也面临挑战：如何确保合理、公平、无偏？这些挑战随着越来越多的人在基础模型上构建应用，会越来越明显。

***

**IEEE：为CV创建基础模型的契机在哪？**

**吴恩达：**目前还是存在可扩展性难题。相比NLP，CV需要的计算能力更强大。如果能生产出比现在高10倍性能的处理器，就能够非常轻松建立包含10倍视频数据的基础视觉模型。目前，已经出现了在CV中开发基础模型的迹象。

说到这，我提一嘴：过去十年，深度学习的成功更多的发生在面向消费的公司，这些公司特点是拥有庞大的用户数据。因此，在其他行业，深度学习的“规模范式”并不适用。

***

**IEEE：您这么一说我想起来了，您早期是在一家面向消费者的公司，拥有数百万用户。**

**吴恩达：**十年前，当我发起 Google Brain 项目，并使用 Google的计算基础设施构建“大”神经网络的时候，引起了很多争议。当时有位行业资深人士，“悄悄”告诉我：启动Google Brain 项目不利于我的职业生涯，我不应该只关注大规模，而应该专注于架构创新。

到现在我还记着，我和我的学生发表的第一篇NeurIPS  workshop论文，提倡使用CUDA。但另一位行业资深人劝我：CUDA 编程太复杂了，将它作为一种编程范式，工作量太大了。我想办法说服他，但我失败了。

***

**IEEE：我想现在他们都被说服了。**

**吴恩达：**我想是的。

在过去一年，我一直在讨论以数据为中心的AI，我遇到了和10年前一样的评价：“没有新意”，“这是个错误的方向”。

***

**IEEE：您如何定义“以数据为中心的AI”，为什么会称它为一场运动？**

**吴恩达：**“以数据为中心的AI”是一个系统的学科，旨在将关注点放在构建AI系统所需的数据上。对于AI系统，用代码实现算法，然后在数据集上训练是非常必要的。过去十年，人们一直在遵循“下载数据集，改进代码”这一范式，多亏了这种范式，深度学习获得了巨大的成功。
但对许多应用程序来说，代码—神经网络架构，已经基本解决，不会成为大的难点。因此保持神经网络架构固定，寻找改进数据的方法，才会更有效率。

当我最开始提这件事的时候，也有许多人举手赞成：我们已经按照“套路”做了20年，一直在凭直觉做事情，是时候把它变成一门系统的工程学科了。

“以数据为中心的AI”远比一家公司或一群研究人员要大得多。当我和朋友在NeurIPS上组织了一个“以数据为中心的AI”研讨会时候，我对出席的作者和演讲者的数量感到非常高兴。

***

**IEEE：大多数公司只要少量数据，那么“以数据为中心的AI”如何帮助他们？**

**吴恩达：**我曾用3.5亿张图像构建了一个人脸识别系统，你或许也经常听到用数百万张图像构建视觉系统的故事。但这些规模产物下的架构，是无法只用50张图片构建系统的。事实证明。如果你只有50张高质量的图片，仍然可以产生非常有价值的东西，例如缺陷系统检测。在许多行业，大数据集并不存在，因此，我认为目前必须将重点“从大数据转移到高质量数据”。其实，只要拥有50个好数据（examples），就足以向神经网络解释你想让它学习什么。

***

**IEEE：使用50张图片训练什么样的模型？是微调大模型，还是全新的模型？**

**吴恩达：**让我讲一下Landing AI的工作。在为制造商做视觉检查时，我们经常使用训练模型，RetinaNet，而预训练只是其中的一小部分。其中更难的问题是提供工具，使制造商能够挑选并以相同的方式标记出正确的用于微调的图像集。这是一个非常实际的问题，无论是在视觉、NLP，还是语音领域，甚至连标记人员也不愿意手动标记。在使用大数据时，如果数据参差不齐，常见的处理方式是获取大量的数据，然后用算法进行平均处理。但是，如果能够开发出一些工具标记数据的不同之处，并提供非常具有针对性的方法改善数据的一致性，这将是一个获得高性能系统的更有效的方法。

例如，如果你有10,000张图片，其中每30张图片一组，这30张图片的标记是不一致的。我们所要做的事情之一就是建立工具，能够让你关注到这些不一致的地方。然后，你就可以非常迅速地重新标记这些图像，使其更加一致，这样就可以使性能得到提高。

***

**IEEE：您认为如果能够在训练前更好地设计数据，那这种对高质量数据的关注是否能帮助解决数据集的偏差问题？**

**吴恩达：**很有可能。有很多研究人员已经指出，有偏差的数据是导致系统出现偏差的众多因素之一。其实，在设计数据方面也已经有了很多努力。NeurIPS研讨会上，Olga Russakovsky就这个问题做了一个很棒的演讲。我也非常喜欢Mary Gray在会上的演讲，其中提到了“以数据为中心的AI”是解决方案的一部分，但并不是解决方案的全部。像Datasheets for Datasets这样的新工具似乎也是其中的重要部分。

“以数据为中心的AI”赋予我们的强大工具之一是：对数据的单个子集进行工程化的能力。想象一下，一个经过训练的机器学习系统在大部分数据集上的表现还不错，却只在数据的一个子集上产生了偏差。这时候，如果要为了提高该子集的性能，而改变整个神经网络架构，这是相当困难的。但是，如果能仅对数据的一个子集进行设计，那么就可以更有针对性的解决这个问题。

***

**IEEE：您说的数据工程具体来讲是什么意思？**

**吴恩达：**在人工智能领域，数据清洗很重要，但数据清洗的方式往往需要人工手动解决。在计算机视觉中，有人可能会通过Jupyter notebook将图像可视化，来发现并修复问题。

但我对那些可以处理很大数据集的工具感兴趣。即使在标记很嘈杂的情况下，这些工具也能快速有效地将你的注意力吸引到数据的单个子集上，或者快速将你的注意力引向100个分组中的一个组中，在那里收集更多数据会更有帮助。收集更多的数据往往是有帮助的，但如果所有工作都要收集大量数据，可能会非常昂贵。

例如，我有次发现，当背景中有汽车噪音时，有一个语音识别系统的表现会很差。了解了这一点，我就可以在汽车噪音的背景下收集更多的数据。而不是所有的工作都要收集更多的数据，那样处理起来会非常昂贵且费时。

***

**IEEE：那使用合成数据会是一个好的解决方案吗？**

**吴恩达：**我认为合成数据是“以数据为中心的AI”工具箱中的一个重要工具。在NeurIPS研讨会上，Anima Anandkumar做了一个关于合成数据的精彩演讲。我认为合成数据的重要用途，不仅仅表现在预处理中增加学习算法数据集。我希望看到更多的工具，让开发者使用合成数据生成成为机器学习迭代开发闭环中的一部分。

***

**IEEE：您的意思是合成数据可以让你在更多的数据集上尝试模型吗？**

**吴恩达：**并非如此。比方说，智能手机上有许多不同类型的缺陷，如果要检测智能手机外壳的缺陷，那可能会是划痕、凹痕、坑痕、材料变色或者其它类型的瑕疵。若你训练了模型，然后通过误差分析发现总体上它的表现很好，但在坑痕上表现得很差，那么合成数据的生成就可以让你以更有针对性地解决这个问题。你可以只为坑痕类别生成更多的数据。

***

**IEEE：您可以举例具体说明吗？若一家公司找到Landing AI，并说他们在视觉检查方面有问题时，您将如何说服他们？您又将给出怎样的解决方案呢？**

**吴恩达：**合成数据生成是一个非常强大的工具，但我通常会先尝试许多更简单的工具。比如说用数据增强来改善标签的一致性，或者只是要求厂家收集更多的数据。

当客户找到我们时，我们通常会先就他们的检测问题进行交谈，并查看一些图像，以验证该问题在计算机视觉方面是否可行。假若可行，我们会要求他们将数据上传到LandingLens平台。我们通常根据“以数据为中心的AI”方法向他们提供建议，并帮助他们对数据进行标记。

Landing AI关注的重点之一是让制造企业自己做机器学习的工作。我们的很多工作都是为了软件的便捷使用。通过对机器学习的开发迭代，我们为客户提供了如何在平台上训练模型，以及如何改进数据标记问题来提高模型的性能等很多建议。我们的训练和软件在此过程中会一直发挥作用，直到将训练好的模型部署到工厂的边缘设备上。

***

**IEEE：那您如何应对不断变化的需求？如果产品发生变化或是工厂的照明条件发生变化，在这样的情况下，模型能适应吗？**

**吴恩达：**这要因制造商而异。在很多情况下都有数据偏移，但也有一些制造商已经在同一生产线上运行了20年，几乎没有什么变化，所以在未来5年内他们也不期望发生变化，环境稳定事情就变得更容易了。对于其他制造商，在出现很大的数据偏移问题时我们也会提供工具进行标记。我发现使制造业的客户能够自主纠正数据、重新训练和更新模型真的很重要。比如现在是美国的凌晨3点，一旦出现变化，我希望他们能够自行立即调整学习算法，以维持运营。

在消费类软件互联网中，我们可以训练少数机器学习模型来为10亿用户服务。而在制造业，你可能有10,000 制造商定制10,000 个人工智能模型。所面临的挑战是，Landing AI 在不雇用10,000名机器学习专家的情况下，如何做到这一点？

***

**IEEE：所以为了提高质量，必须授权用户自己进行模型训练？**

**吴恩达：**是的，完全正确！这是一个全行业的AI问题，不仅仅是在制造业。例如在医疗领域，每家医院电子病历的格式略有不同，如何训练定制自己的AI模型？期望每家医院的IT人员重新发明神经网络架构是不现实的。因此，必须构建工具，通过为用户提供工具来设计数据和表达他们的领域知识，从而使他们能够构建自己的模型。

***

**IEEE：您还有什么需要读者了解的么？**

**吴恩达：**过去十年，人工智能最大的转变是深度学习，而接下来的十年，我认为会转向以数据为中心。随着神经网络架构的成熟，对于许多实际应用来说，瓶颈将会存在于“如何获取、开发所需要的数据”。以数据为中心的AI在社区拥有巨大的能量和潜力，我希望能有更多的研究人员加入！

***

### 参考资料

> <https://www.bilibili.com/read/cv22742694/>
