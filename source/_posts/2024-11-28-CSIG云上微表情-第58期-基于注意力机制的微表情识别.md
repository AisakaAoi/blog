---
title: CSIG云上微表情-第58期-基于注意力机制的微表情识别
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: ebde5a2
date: 2024-11-28 06:05:08
tags:
---

<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=113566602560512&bvid=BV1W2zrYcEEJ&cid=27095140558&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>

<!--more-->

微表情是一种短暂的、微弱的、无意识的面部微表情，持续时间往往在0.5s内，能够揭示人类试图隐藏的真实情绪。微表情识别的研究旨在让机器有足够的智能，能够从人脸视频序列中识别人类的真实情绪。然而由于微表情持续时间短、面部肌肉运动强度低，对其进行准确的表征与识别是一项极具挑战性的任务。为了促进心理学领域和计算机视觉领域针对微表情的进一步研究，由中国图象图形学学会（CSIG）和中国科学院心理研究所举办、CSIG机器视觉专业委员会、CSIG情感计算与理解专业委员会和中科院青促会心理所小组联合承办，中国科学院心理研究所的王甦菁博士组织一系列云上微表情的学术活动。
第五十八期云上微表情于2024年11月28日晚7点半进行，由中国科学院心理研究所王甦菁老师团队的李婧婷博士主持。此次讲座主题为基于注意力机制的微表情识别，邀请到重庆邮电大学甘臣权教授和青岛大学硕士研究生蔡文浩同学分享相关工作，欢迎大家关注！

第一位讲者介绍：
甘臣权，男，博士，博导，重庆邮电大学文峰教授、文峰青年百人，汽车金融智能与安全联合实验室副主任，连续两年（2023，2024）入选全球前2%顶尖科学家榜单。澳大利亚迪肯大学访问学者、四川大学访问学者，重庆市科技青年联合会第七次会员代表，四川省计算机学会自然语言处理专业委员会常务委员，计算机学会会员，重庆市公路学会静态交通专业委员会技术专家、教育部学科评估评审专家、教育部学位论文评审专家。主要从事网络传播与控制、情感分析、区块链、异常检测等方面研究工作，先后承担国家自然科学基金、广西重点研发计划、重庆市自然科学基金面上、重庆市教委重点、企业横向等科研项目16项、教学教改项目6项、教学工程项目6项，在IEEE Transactions on Intelligent Transportation Systems、Pattern Recognition、Knowledge-Based Systems、Information Processing and Management、计算机研究与发展、电子与信息学报等国内外期刊会议发表学术论文100篇（高被引5篇、中科院SCI 1区TOP 21篇、中科院SCI 2区及以上52篇），申请国家发明专利49件（授权25件，转让4件），出版专著1部（科学出版社）、教材1部（电子工业出版社），获第12届亚洲膜计算和情感计算会议主题报告优秀奖，担任SCI期刊CMC-Computers, Materials & Continua编委。所指导学生多次获得重庆市、重庆邮电大学优秀硕士、本科学位论文以及在互联网+、挑战杯等竞赛中获奖。

第一位讲者：
报告题目： Transfer-learning enabled micro-expression recognition using dense connections and mixed attention

报告摘要：
微表情识别（MER）是计算机视觉领域中的一项具有挑战性的问题，其中有限的可用训练数据量以及表情强度不足是对现有识别模型性能造成不利影响的主要问题之一。为了解决这些挑战，本文提出了一种基于迁移学习的微表情识别模型，该模型结合了密集连接的特征提取模块和混合注意机制。与以往利用迁移学习来辅助MER并提取局部面部表情信息的工作不同，我们的模型通过在三个多样化的宏表情数据集上进行预训练，从而能够：（1）克服样本量不足和训练数据有限的问题；（2）利用来自多个特征各异的数据集的领域相关信息；（3）提高模型对复杂场景的适应性。
此外，为了增强微表情的表情强度并提高提取特征的可分辨性，在预处理阶段引入了欧拉视频放大（Euler Video Magnification, EVM）方法，并将其与密集连接的特征提取模块和混合注意机制结合使用，以生成具有高表达性的特征表示，用于分类过程。所提出的特征提取机制不仅保证了提取特征的完整性，还通过聚合生成特征图中最显著的信息，有效捕捉局部纹理线索，这对MER任务至关重要。多数据集上的实验结果表明，与当前最先进的方法相比，我们的模型具有鲁棒性和高效性。

参考文献：Gan, C., Xiao, J., Zhu, Q., Jain, D. K., & Štruc, V. (2024). Transfer-learning enabled micro-expression recognition using dense connections and mixed attention. Knowledge-Based Systems, 305, 112640.

第二位讲者：
蔡文浩，青岛大学计算机科学技术学院研究生三年级在读，导师赵俊莉教授。主要研究方向：计算机视觉，情感识别。主要研究兴趣为微表情分析与识别，4D微表情分析。

报告题目： MFDAN: Multi-Level Flow-Driven Attention Network for Micro-Expression Recognition

报告摘要：面部表情是人类情感交流的重要组成部分，而微表情作为一种短暂的、难以察觉的非语言信号，可以潜在地揭示人类真实的情感。然而，细微的运动变化，有限的和不平衡的样本使微表情识别任务（MER）具有挑战性。本文设计了一种新的基于多层次流驱动注意力的微表情识别双分支学习框架（MFDAN），该框架在图像编码分支中创新性地引入了光流引导注意力学习，使得模型能够针对细微的运动模式聚焦于最具辨别力的面部区域。首先，通过光流编码模块提取光流信息。然后在图像编码模块中，我们构建了一个包含光流驱动注意机制的Transformer结构，该结构能够根据光流的位置信息有效定位图像中微表情的兴趣区域，捕捉到更敏感、更细粒度的微表情。通过将先验知识与数据学习进行互操作，并引入Dropkey操作和Focal Loss，我们的方法可以处理小型不平衡数据集上的微表情特征。通过对SMIC-HS、SAMM和CASME II等三个独立数据集和一个复合数据库的实验，稳健的leave-one-subject-out（LOSO）评价结果表明，该方法在复合数据库上的性能优于现有方法.

参考文献： Cai, W., Zhao, J., Yi, R., Yu, M., Duan, F., Pan, Z., & Liu, Y. J. (2024). MFDAN: Multi-level Flow-Driven Attention Network for Micro-Expression Recognition. IEEE Transactions on Circuits and Systems for Video Technology.
