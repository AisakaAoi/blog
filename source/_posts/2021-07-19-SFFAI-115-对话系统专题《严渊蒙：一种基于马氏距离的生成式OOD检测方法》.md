---
title: SFFAI 115 | 对话系统专题《严渊蒙：一种基于马氏距离的生成式OOD检测方法》
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: 93f403cb
date: 2021-07-19 00:43:02
tags:
---

<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=210588357&bvid=BV1qa411q7k9&cid=482550059&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>

<!--more-->

SFFAI论坛已开放注册，详情点击查看：https://bbs.sffai.com/d/312

关注公众号：【人工智能前沿讲习】，回复【SFFAI115】获取讲者PPT资料，入交流群，推荐论文下载。

在任务型对话系统中，域外（Out-of-domain, OOD）意图检测是相当重要的一个模块。它能够防止模型将这类意图错误分类为某个域内意图，从而发生预期外的系统行为。例如对于一个智能音乐软件里的对话系统，用户给出例如“购买某本图书”的对话请求即为域外意图。本期我们邀请到来自北京邮电大学的严渊蒙，分享他如何在无监督设置下基于马氏距离的生成式分类器来检测OOD样本。

***

### 讲者介绍

**严渊蒙：**北京邮电大学模式识别实验室硕士生，自然语言处理方向，导师为徐蔚然老师。其主要研究方向为对话系统中的口语理解，特别是少样本情况下的迁移学习、自监督学习等技术，目前已在ACL、EMNLP等会议上发表多篇论文。

**报告题目：**一种基于马氏距离的生成式OOD检测方法

**报告摘要：**本文中我们主要探索无监督设置下的OOD意图检测方法，即训练过程中只有有监督的域内语料是可获取的，而无法获取到域外的标注语料。我们提出了一个简单但强大的基于马氏距离的生成式分类器来检测OOD样本。具体来说，我们使用高斯判别分析（Gaussian Discriminant Analysis, GDA）对编码器导出的域内样本的特征进行建模以避免基于softmax的分类器过度自信的问题；同时我们比较了在特征空间中使用欧氏距离和马氏距离进行OOD意图判别的性能，显示了使用马氏距离进行OOD意图判别的优势。我们在四个基准数据集上进行实验，结果证明我们的方法显著优于若干基线。

**论文题目：**A Deep Generative Distance-Based Classifier for Out-of-Domain Detection with Mahalanobis Space

**分享亮点：**
1. 我们提出了一种基于距离函数的生成式OOD检测方法，用于无监督的OOD意图检测任务；
2. 我们在传统欧氏距离的基础上，引入马氏距离，并且比较了欧氏距离和马氏距离的性能优劣，结果显示马氏距离相比欧氏距离能够更好地处理特征之间的相关性，从而在OOD意图检测任务上获得更好的效果；
3. 在四个公开数据集上的实验证明了我们的方法显著优于此前的基线。

***

### 论文推荐

1. A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS

    **推荐理由：**本文提出了用于一般性OOD样本检测的基线方法：即基于最大Softmax概率（MSP）的OOD检测方法，并且在图像分类、文本分类、情感分类、词性标注、语音识别等诸多任务上进行了实验。我们将其选作我们的基线之一。
 
2. DOC Deep Open Classification of Text Documents

    **推荐理由：**本文提出了文档级的OOD检测方法（作者将其称为开放世界分类，Open-world Classification），叫作DOC。方法上，作者采用基于CNN的编码器，然后将分类任务转换为对每个类别的一个二分类任务（每个类别都使用一个sigmoid的激活函数）。在预测时，当所有类别的得分低于某阈值时，则认为其为OOD样本。我们将其选作我们的基线之一。
 
3. Deep Unknown Intent Detection with Margin Loss

    **推荐理由：**本文通过在训练阶段（仅包含域内样本）优化特征表示空间，以在OOD意图分类时获得更好的OOD检测性能。具体来说，本文使用Large-margin Cosine Loss (LMCL)，在训练时最小化样本间的类内距离同时最大化类间距离，这样训练出来的表示空间能够最大程度分开域内样本和域外随机分布的样本之间的界限。在预测时本文使用LOF算法进行OOD检测。我们将其选作我们的基线之一。
 
4. Likelihood Ratios and Generative Classifiers for Unsupervised Out-of-Domain Detection in Task Oriented Dialog

    **推荐理由：**本文同样基于生成式方法，它们通过为每个类别训练语言模型（最大化该句子的似然分数），然后使用训练好的语言模型评价预测样本的似然分数，并且基于预设的阈值进行OOD样本检测。为了消除无关的背景信息的影响，本文进一步引入似然比的概念，通过训练一个公共的语言模型（可以认为编码了公共的、类别无关的背景知识）作为分值的归一化，以消除类别公共（背景）信息的影响。
 
5. A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks

    **推荐理由：**本文提出了一个基于高斯判别分析的框架，用于检测分布外的、对抗攻击生成的样本。本文主要使用高斯判别分析代替Softmax分类器，以解决模型过度自信的问题。我们的方法也是主要受到这篇文章的启发。与其不同的是，我们关注于对话系统中的意图分类任务上，同时比较了欧氏距离和马氏距离之间的性能差异。
 
6. Contrastive Training for Improved Out-of-Distribution Detection

    **推荐理由：**本文提出了一种用对比学习进行OOD检测的新方法。该方法避免了显式地在输入空间中建模域内和域外样本的概率密度，易于融入现有框架，并且不需要额外的OOD样本参与训练。此外，作者还提出了一种用于评估OOD数据集的指标。

***

### 参考资料

> <https://www.bilibili.com/video/BV1qa411q7k9/>
