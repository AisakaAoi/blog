---
title: SFFAI 83 | 对抗样本专题《曾捷航：基于对抗样本的依存句法模型鲁棒性分析》
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: 59d7bd19
date: 2020-10-18 05:31:33
tags:
---

<iframe src="//player.bilibili.com/player.html?aid=718046601&bvid=BV1nQ4y1k7TP&cid=409575289&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<!--more-->

关注公众号：【人工智能前沿讲习】，回复【SFFAI83】获取讲者PPT资料，入交流群，推荐论文下载。

神经网络模型虽然在许多自然语言处理任务上取得了卓越的性能，但容易受到对抗样本的干扰。关于文本对抗样本的研究主要集中在语义任务上，例如情感分析，文本分类和阅读理解。本期论坛我们邀请到了来自复旦大学的曾捷航同学在ACL2020发表的工作证明了自然语言处理的句法任务也同样存在对抗样本问题。

***

### 讲者介绍

**曾捷航：**复旦大学计算机学院研究生，导师为郑骁庆教授，主要研究方向为文本对抗样本的攻防等。

**报告题目：**基于对抗样本的依存句法模型鲁棒性分析

**报告摘要：**我们提出了黑盒和白盒两种攻击方法来攻击现有的性能最好的句法分析模型。在英文数据集PTB上的实验表明，这种攻击的成功率高达77％；并且我们还表明，通过精心设计对抗样本并将对抗样本用于训练阶段，可以提高句法分析模型的鲁棒性，同时保证原始干净输入样本的性能几乎没有出现很大下降。

**Spotlight：**
1. 本文探讨了在不更改原始句子句法结构的情况下，通过生成对抗样本使依存句法模型犯错误的可行性；
2. 本文提出了黑盒、白盒两种攻击方法用于攻击多种粒度 (字符级别、词级别等) 的依存句法模型；
3. 通过使用精心设计的对抗样本增强训练模型，可以提高依存句法模型的鲁棒性。

***

### 论文推荐

#### 经典论文

1. Intriguing properties of neural networks

    **推荐理由：**2013年，首次提出神经网络的“对抗样本“：对输入做一些细小的、人难以察觉的扰动，神经网络模型容易犯错误。

2. EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES

    **推荐理由：**2014年，提出FGSM方法用于攻击神经网络模型，经典的“熊猫“、”长臂猿“对抗样本例子就出自于这篇论文。

3. Crafting Adversarial Input Sequences for Recurrent Neural Networks

    **推荐理由：**2016年，为循环神经网络设计对抗样本，对抗样本问题首次用于文本领域。

#### 前沿论文

4. FREELB ENHANCED ADVERSARIAL TRAINING FOR NATURAL LANGUAGE UNDERSTANDING

    **推荐理由：**一篇对抗训练文章，提出FreeLB方法对抗训练方法用于提高模型性能与鲁棒性。

5. Word-level Textual Adversarial Attacking as Combinatorial Optimization

    **推荐理由：**基于提出粒子群算法和词义原的攻击方法。

6. BERT-ATTACK Adversarial Attack Against BERT Using BERT

    **推荐理由：**2020年，通过BERT产生上下文相关的、语意连贯的对抗样本。

***

### 参考资料

> <https://www.bilibili.com/video/BV1nQ4y1k7TP/>
