---
title: 学习报告：基于动作理解的统一多模态无监督表示学习
categories:
  - 🌙进阶学习
  - ⭐脑机接口与混合智能研究团队（BCI团队）
  - 💫学习报告
abbrlink: 4f9a7f5
date: 2024-02-02 11:01:04
tags:
---

### 论文概要

近年来，无监督预训练在基于骨架的动作识别中取得了巨大的成功。现有的研究通常都是采用训练单独的模态特定模型（如关节、骨骼和运动），然后通过后期融合策略集成多模态信息的方法进行动作识别。然而这样的方法在模型设计方面存在复杂冗余的问题，并且受限于固定的骨架输入模态。这篇论文提出了一个统一的多模态无监督表示学习框架，称为UmURL，通过利用高效的早期融合策略联合编码多模态特征以降低模型复杂性，并且进一步提出了模态内一致性学习和模态间一致性学习，以确保多模态特征包含每个模态的完整语义。为了评估所提出的方法的性能，在三个大规模数据集（NTU-60、NTU-120和PKU-MMD II）上进行了广泛的实验，证明了UmURL不仅和单模态方法复杂度相当，而且在骨架动作表示学习的各种下游任务场景中取得了新的最先进性能。

该论文被第 31 届国际多媒体会议（ACM International Conference on Multimedia，ACMMM）接收，题目为《Unified Multi-modal Unsupervised Representation Learning for Skeleton-based Action Understanding》，浙江工商大学的Shengkai Sun和北京大学的Daizong Liu为此文的共同第一作者，浙江工商大学的Jianfeng Dong为此文的通讯作者。

<!--more-->

***

### 作者贡献 / 创新点

作者构建了一个简单但有效的早期融合管道，利用单流的方式处理多模态输入。为确保提取的多模态特征包含每个模态的完整语义，作者又进一步将特征分解到每个单模态域，以进行模态内和模态间语义一致性学习，如图1所示。所学习的多模态表示与其包含的单个模态特征相统一，共享相同的模态内语义，同时补充模态间上下文以实现鲁棒的动作识别。通过这种统一多模态表示，该框架还可以灵活处理不同类型的模态输入。

{% asset_img 1.webp %}
<div align='center'>图1 联合学习单模态和多模态输入的特征来学习统一的多模态表示</div>

***

### 模型总体框架

模型总体框架如图2所示。通常，一个输入的骨骼序列表示为，其中T，C，V分别表示帧数、通道数和关节点数。其他骨骼模态，如骨骼和运动信息，可以通过对原始3D坐标的线性变换进行提取，以补充原始关节点模态的时空信息。基于此，一个多模态动作的输入可以形式化表示为，其中包含来自k种不同模态的信息。

首先将每种异构模态数据映射到相同维度的嵌入空间中，通过简单的平均操作和线性变换在早期阶段对它们进行融合，然后进一步在融合表示上使用多模态编码器从而得到最终的多模态表示。这种方法不仅在一定程度上保留了每个模态的独特语义，而且与对所有模态采用完全独立的编码结构相比还降低了模型复杂度。

作者使用一个无关模态编码器来提取所有模态的原始模态特定特征，然后利用k个模态感知投影器将多模态表示分解成不同的模态领域。通过模态内一致性学习和模态间一致性学习，促进分解的模态特征与原始单模态特征保持一致以及不同模态之间特征保持一致。并且加入了VC正则化以防止模型崩溃。

{% asset_img 2.webp %}
<div align='center'>图2 UmURL框架</div>

***

### 实验结果

为了评估所提出方法的有效性，作者在三个广泛使用的骨架动作识别数据集上进行实验。

NTU-60是一个大规模的动作识别数据集，包含从40个受试者中收集的56,880个动作样本，共60个类别。推荐的标准评估方案有两种：x-sub根据受试者划分数据，其中一半受试者的样本用作训练数据，其余受试者用于测试；x-view根据摄像机视图来分割数据，其中摄像机2和3捕获的样本用于训练，摄像机1捕获的样本用于测试。NTU-120是NTU-60的扩展版本，包含120个动作类别和114,480个样本。同样有两个推荐的标准评估方案：x-sub类似于NTU-60；x-setup具有偶数setup ID的样本用于训练，而具有奇数setup ID的样本用于测试。PKU-MMD II 它包含41个动作类别，有5,339个骨架样本用于训练，1,613个用于测试。PKU-MMD II由于其较大的视图变化而具有挑战性，同样遵循x-sub评估方案。

在NTU-60、NTU-120和PKU-MMD II数据集上基于骨架的动作识别任务的最先进方法进行比较，见表1。

<div align='center'>表1 基于骨架的动作识别</div>
{% asset_img 3.webp %}

在NTU-60和NTU-120数据集上基于骨架的动作检索最先进方法进行比较，见表2。

<div align='center'>表2 基于骨架的动作检索</div>
{% asset_img 4.webp %}

模态内和模态间一致性学习的消融研究，见表3。

<div align='center'>表3 消融实验</div>
{% asset_img 5.webp %}

作者通过实验证明了模态内和模态间一致性学习的有效性，实验在NTU-60数据集上进行，实验结果表明在每个模态上使用模态内一致性学习是有效的，模态间一致性学习模块能够进一步提高性能，还证明了还证明了模态内和模态间模块之间的互补性。

***

### 总结

本文提出了一种新颖的统一多模态表示学习框架，即UmURL，用于基于骨架的动作理解。与传统的通过后期融合策略的多模态方法相比，UmURL在预训练和下游任务中需要的计算开销更少，并且对输入模态的处理也更加灵活。比先前的基于多模态的动作识别解决方案更为高效，在多个下游任务中实现了新的最先进性能。

***

### 原文链接

> <https://www.scholat.com/teamwork/showPostMessage.html?id=15113>
