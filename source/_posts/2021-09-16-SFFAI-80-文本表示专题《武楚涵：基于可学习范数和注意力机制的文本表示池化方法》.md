---
title: SFFAI 80 | 文本表示专题《武楚涵：基于可学习范数和注意力机制的文本表示池化方法》
categories:
  - 🌙进阶学习
  - ⭐讲座
abbrlink: 28417e7d
date: 2021-09-16 05:27:22
tags:
---

<iframe src="//player.bilibili.com/player.html?aid=293036982&bvid=BV1Wf4y1n71k&cid=409037731&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<!--more-->

关注公众号：【人工智能前沿讲习】，回复【SFFAI80】获取讲者PPT资料，入交流群，推荐论文下载。

池化是许多基于深度学习的NLP模型用来学习文本表示的重要技术。在已有的池化方法中（例如平均池化，最大池化和基于注意力机制的池化），输出的文本表示是输入特征的L1或L∞范数的加权和。但是，这些方法的池化范数是固定的，对于在不同任务中学习文本表示可能并非最优。另外，如最大池化和基于注意力机制的池化等许多常用的方法可能会过分强调某些特征，导致其他有用的信息没有被充分利用。

***

### 参考资料

> <https://www.bilibili.com/video/BV1Wf4y1n71k/>
