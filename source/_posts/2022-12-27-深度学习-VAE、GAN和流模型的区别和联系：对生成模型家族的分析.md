---
title: 深度学习-VAE、GAN和流模型的区别和联系：对生成模型家族的分析
categories:
  - 🌙进阶学习
  - ⭐人工智能 Artificial Intelligence
  - 💫网络模型 Networks Model
abbrlink: e3e50e02
date: 2022-12-27 02:28:21
tags:
---

一种常见的分类方法可以将机器学习模型分为「判别式」和「生成式」两种。判别式模型如KNN、SVM、决策树等，强调直接从数据中学习决策函数；而生成式模型如HMM、Bayes等，则强调学习数据生成的规律（分布）从而更好地对数据进行表征建模。生成式模型由于能够学习数据的隐含特征表示，因此在近些年得到了长足的发展，在机器学习领域愈来愈重要。本文主要介绍常见的生成模型，并着重分析VAE、GAN和流模型这三者的区别和联系。

{% asset_img 1.webp %}

<!--more-->

***

目前主流的生成模型主要有4大类：
- 基于自回归（autogressive）的模型，如翻译模型、语言模型
- 变分自编码器（variational autoencoder, VAE）[1]
- 生成对抗网络（Generative adversarial net, GAN）[2]
- 流模型（Flow-based model）[3]

其中除了自回归比较容易理解外，VAE、GAN和流模型这三大类方法有很明显的区别，也有着千丝万缕的联系。

首先，三者都是生成模型，就是说从训练数据来建模真实的数据分布，然后反过来再用学到的这个模型和分布去生成、建模新的数据。

***

### 相同点

- 生成数据的模式都是用了随机噪声（如常用的就是高斯分布）。
- 在建模分布时，都需要度量噪声和训练数据的分布差异。

***

### 不同点

#### 建模的方式（理念）不同

VAE里面z到x的depencence是随机的，而GAN里是确定性的。这使得VAE的inference相对来说是well-defined的而GAN的inferernce相对来说是病态的。

这个建模上的区别也是来自于两者建模目的的不同。GAN就是为了生成新图片，而VAE除此之外，更想做的事情是建模数据的分布以及学到数据的隐含表示。

对于建模数据的分布，通常来说也就是density estimation，虽然VAE和GAN都有在x的空间上定义概率密度，但GAN定义的密度更难计算。density estimation可以用来做比如anomaly/outlier detection进而做分类什么的。

流模型则直接从原始问题出发，建立训练数据和生成数据之间的概率关系（这种概率关系是量化的、准确的），然后用可逆的神经网络来训练。它在建模上的最大特点是z和x之间的关系是确定性的而且是一对一的关系

***

#### 训练方式不同

训练上的区别在于loss不同。

VAE最大化ELBO，其目的是要做最大似然估计，最大似然估计等价于最小化KL，但这个KL不是数据和噪声的KL，而是model给出的p(x)和数据所展示的p(x)之间的KL。

GAN则最小化Jensen-Shannon Divergence，这个JS也是model给出的p(x)和数据所展示的p(x)之间的。

流模型训练也非常直接，也是最大似然估计。只不过因为流模型用的是可逆神经网络，因此，相比于其他两者，学习inference即学习隐含表示非常容易，直接把x用逆函数过一遍就好了不需要额外train一个inference model，而且能直接计算p(x)，所以方便了density estimation，也方便了training因为可以直接用MLE来train（ELBO只是likelihood的lower bound，而且需要一个inference model，但VAE没法直接MLE）。代价就是模型设计比较麻烦，因为要保证可逆而且逆函数可以算，还要有足够的灵活度/表示能力。

从效果上三类方法殊途同归，经过了多年发展，都取得了不错的进展。

最后说一下比较有意思的事：

VAE、GAN、Flow (NICE)三种模型都是2013-2014年提出来的（VAE是13年放到arXiv上的，后来中了NIPS；GAN也同时中了NIPS，而NICE最早是14年的一个ICLR workshop）。最后的发展情况是：GAN最火，VAE次之，Flow模型似乎总是要火不火。但是从理论上来看，分明是Flow模型最接近问题的本质。也许是因为flow太难了，计算资源太大了？

***

### 参考资料

> <https://zhuanlan.zhihu.com/p/116775904>
> [1] VAE原始论文: https://arxiv.org/abs/1312.6114
> [2] GAN原始论文: https://papers.nips.cc/paper/5423-generative-adversarial-nets
> [3] 流模型原始论文: https://arxiv.org/abs/1410.8516
