---
title: 前沿改进-CVPR 2023 | HPM：在掩码学习中挖掘困难样本，带来稳固性能提升！
categories:
  - 🌙进阶学习
  - ⭐人工智能 Artificial Intelligence
  - 💫前沿改进 Frontier Improvement
abbrlink: bf832548
date: 2023-05-02 02:54:05
tags:
---

本文介绍了一篇在自监督掩码学习（Masked Image Modeling）领域的原创工作 HPM (Hard Patches Mining for Masked Image Modeling)。 

各种自监督掩码学习方法的性能强烈依赖于人工定义的掩码策略，而我们提出一种新的困难样本挖掘策略，让模型自主地掩码困难样本，提升代理任务的难度，从而获得强大的表征提取能力。目前 HPM 已被 CVPR 2023 接收，相关代码已开源。

{% asset_img 1.webp %}

- 论文标题：Hard Patches Mining for Masked Image Modeling
- 录用信息：CVPR 2023, https://arxiv.org/abs/2304.05919
- 代码开源：https://github.com/Haochen-Wang409/HPM

<!--more-->

***

### Introduction

{% asset_img 2.webp %}
<p style="text-align:center">Figure 1. Comparison between conventional MIM pre-training paradigm and our proposed HPM.</p>

在典型的 MIM 方法中，模型通常专注于预测 masked patches 的某一形式的 target (例如 BEiT[1]的离散 token，MAE[2] 的 pixel RGB)。而由于 CV 信号的稠密性，MIM 方法通常需要预先定义的掩盖策略，以构造具有挑战性的自监督代理任务。否则，一个简单的插值就能完成对于 masked patches 的重建。总的来说，整个 MIM 的过程可以被认为是训练一个学生（模型），解决给定的问题（重建 masked patches），如上图 (a) 所示。

然而，我们认为，模型不应该只专注于解决给定的问题，还应该站在老师的立场上，具备自己出具挑战性问题的能力。通过创造具有挑战性的问题并解决这些问题，模型可以同时站在学生和老师的立场上，对图像内容有一个更全面的理解，从而通过产生一个高难度的代理任务来引导自己提取更加可扩展的表征。为此，我们提出了Hard Patches Mining（HPM），一个全新的MIM预训练框架，如上图 (b) 所示。

具体来说，给定一个输入图像，我们不是在人工设计的标准下生成一个 binary mask，而是首先让模型作为一个老师，自主产生掩码；然后像传统方法一样，让模型作为一个学生，让它重建 masked patches。

接下来，该问题就转化为了如何评判某一个 patch 是否为困难样本。我们自然地想到：「如果某一 patch 难以重建，即重建 loss 较大，则它为困难样本」。

{% asset_img 3.webp %}
<p style="text-align:center">Figure 2. For each tuple, we show the (a) input image, (b) patch-wise reconstruction loss averaged over 10 different masks, (c) predicted loss, and (d) masked images generated by the predicted loss.</p>

如上图所示，我们发现一张图片中 discriminative 的区域（前景）往往是难以重建的。因此，只要让模型「预测每个 patch 的重建损失」，进而 mask 掉那些高重建损失的 patch，就得到了更加具有挑战性的代理任务。

因此，我们引入了一个辅助的 loss predictor，用以预测每个 patch 的重建损失。

***

### Method

{% asset_img 4.webp %}
<p style="text-align:center">Figure 3. Illustration of our proposed HPM.</p>

{% asset_img 5.webp %}

***

### 图像重建

{% asset_img 6.webp %}

***

### 重建损失预测

#### 绝对损失

{% asset_img 7.webp %}

#### 相对损失

{% asset_img 8.webp %}

***

### 掩码产生：easy-to-hard

{% asset_img 9.webp %}

整个训练过程的伪代码为：

{% asset_img 10.webp %}
{% asset_img 11.webp %}

***

### Experiments

#### 消融实验

这一部分，我们以 ViT-B/16 为 backbone，以 ImageNet-1K 上 pre-train 200 epochs 为默认配置。

重建目标的消融。我们发现，不管以什么为重建目标，加入 L_pred 作为额外的损失，并基于此进一步产生更难的代理任务均能获得性能提升。值得注意的是，仅仅引入一个额外的 objective 也能够带来 consistent 的性能提升，表明挖掘困难样本的能力本身，就能够促使习得更好的特征表示。这一点不仅在分类任务上得到体现，下游任务（检测分割）也有相应的体现。

{% asset_img 12.webp %}
{% asset_img 13.webp %}

**掩码策略的消融。**我们发现，难度大的代理任务确实能够带来性能提升，但保留一定的随机性也是同样必要的。这些结论是非常直观的。直接掩盖那些预测损失最高的 patch 虽然带来了最难的问题，但图像 discriminative parts 几乎被掩盖了，这意味着 visible patches 几乎都是背景（见图2）。在没有任何提示的情况下，强迫模型只根据这些背景来重建前景是没有意义的。

{% asset_img 14.webp %}

进一步地，我们探究「难」的代理任务对于 MIM 是否有帮助。其中，argmin 表示这个任务甚至简单于 random masking，会导致性能退化。类似的，hard-to-easy 也会导致性能退化。

{% asset_img 15.webp %}

**预测损失的 formulation**。MSE 相较于 baseline 能够有提升，但 BCE 是一个更好的选择。

{% asset_img 16.webp %}

**Comparison with state-of-the-art methods**

{% asset_img 17.webp %}

下面，给出了一些预测损失的可视化。可以看出，预测损失很好的反应了物体的前景部分。

{% asset_img 18.webp %}
{% asset_img 19.webp %}

***

### 参考资料

> <https://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&mid=2247601717&idx=2&sn=6907577602ce8b491e59186f6f4704c0>
> [1] Hangbo Bao, Li Dong, and Furu Wei. Beit: Bert pre-training of image transformers. In International Conference on Learning Representations (ICLR), 2022
> [2] Kaiming He,Xinlei Chen,Saining Xie,Yanghao Li, Piotr Dollár, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022
> [3] Kaiming He,Xinlei Chen,Saining Xie,Yanghao Li, Piotr Dollár, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022
