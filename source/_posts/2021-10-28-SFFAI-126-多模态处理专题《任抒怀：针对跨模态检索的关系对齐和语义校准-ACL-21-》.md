---
title: SFFAI 126 | 多模态处理专题《任抒怀：针对跨模态检索的关系对齐和语义校准(ACL 21)》
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: 2cee30f4
date: 2021-10-28 02:04:35
tags:
---

<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=594018870&bvid=BV19q4y147M8&cid=509252661&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>

<!--more-->

SFFAI论坛网站已开放注册，详情点击查看：https://bbs.sffai.com/d/312

关注公众号：【人工智能前沿讲习】，回复【SFFAI126】获取讲者PPT资料，入交流群，推荐论文下载。

跨模态检索，如图文检索，是一项极具挑战性的任务，其难点在于实现视觉和语言两种模态间的语义对齐。以往研究中的语义对齐主要集中在实体（object）层面，即让文本中的单词和图片的对应区域互相匹配。本期论坛我们邀请到了来自北京大学的任抒怀同学，提出了“关系一致性”假设，即给定一个匹配的图文对，其词之间的语言关系和区域之间的视觉关系需保持一致。

***

### 讲者介绍

**任抒怀：**北京大学信息科学技术学院计算语言学研究所二年级博士生。主要研究方向为多模态学习、大规模预训练和高效NLP，目前已在 ACL 与 EMNLP 等会议上发表多篇论文。

**报告题目：**针对跨模态检索的关系对齐和语义校准(ACL 21)

**报告摘要：**我们将语义对齐推广到了关系层面，并提出了“关系一致性”假设，这样能学到更好的上下文表示，提高模型的性能和可解释性。对此，我们提出了一种新指标，通过计算语言自注意力分布和视觉自注意力分布间的语义距离，衡量语言关系和视觉关系间的一致性。进一步地，我们提出了一种正则化训练方法，通过约束两种关系的一致性，加强两个模态的语义校准和对齐。在Flickr30k和MS COCO数据集上的实验结果表明，这种方法显著提高了多模态预训练模型在图文检索任务上的性能。

**论文题目：**Learning Relation Alignment for Calibrated Cross-modal Retrieval
 
**分享亮点：**
1. 本文提出一种“关系一致性”假设，即给定一个匹配的图文对，其文本中的语言关系需和图片中的视觉关系需保持一致；
2. 本文提出了一种新指标，通过计算语言自注意力分布和视觉自注意力分布间的语义距离，来衡量语言关系和视觉关系间的一致性；
3. 本文提出了一种正则化训练方法，通过约束语言自注意力分布和视觉自注意力分布间的语义距离，实现两个模态的语义校准和对齐，进而改善图文对的特征表示，提高跨模态检索的效果。

***

### 论文推荐

1. UNITER UNiversal Image-TExt Representation Learning

    **推荐理由：**单流多模态预训练的经典之作。
 
2. ViLBERT Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks

    **推荐理由：**双流多模态预训练的经典之作。
 
3. Multimodal Pretraining Unmasked A Meta-Analysis and a Unified Framework of Vision-and-Language BERTs

    **推荐理由：**提出了统一单流、双流多模态预训练的框架。对单、双流架构中的注意力机制进行了详细分析。
 
4. Oscar Object-Semantics Aligned Pre-training for Vision-Language Tasks

    **推荐理由：**提出在多模态预训练中加入实体标签，以加强语言和视觉中的实体语义对齐。

5. ViLT Vision-and-Language Transformer Without Convolution or Region Supervision

    **推荐理由：**使用基于patch的ViT而非基于object的Faster RCNN进行图片特征编码，取得60倍的提速。

6. Learning Transferable Visual Models From Natural Language Supervision

    **推荐理由：**OpenAI的CLIP。将图片分类任务建模为匹配形式，把图片标签换成对应的文本描述，并利用对比学习进行大规模预训练，取得了良好的zero-shot效果。

***

### 参考资料

> <https://www.bilibili.com/video/BV19q4y147M8/>
