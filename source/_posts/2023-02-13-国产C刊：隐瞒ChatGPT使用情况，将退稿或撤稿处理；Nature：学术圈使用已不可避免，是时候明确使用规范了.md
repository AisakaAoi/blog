---
title: 国产C刊：隐瞒ChatGPT使用情况，将退稿或撤稿处理；Nature：学术圈使用已不可避免，是时候明确使用规范了
categories:
  - 🌙逢坂杂谈
  - ⭐学术区
abbrlink: 2a93c848
date: 2023-02-13 04:59:53
tags:
---

### 导言

近日，国内部分C刊发表有关人工智能辅助论文写作的相关规定。

暨南学报哲学社会科学版官方公众号发布《关于使用人工智能写作工具的说明》译文。

《说明》中提到，**暂不接受任何大型语言模型工具（例如：ChatGPT）单独或联合署名的文章。**在论文创作中使用过相关工具，需单独提出，并在文章中详细解释如何使用以及论证作者自身的创作性。**如有隐瞒使用情况，将对文章直接退稿或撤稿处理。**对于引用人工智能写作工具的文章作为参考文献的，需请作者提供详细的引用论证。

{% asset_img 1.webp %}

<!--more-->

此外，天津师范大学学报基础教育版也发布相关声明，倡导合理使用新工具、新技术，**建议作者在参考文献、致谢等文字中对使用人工智能写作工具（如：ChatGPT等）的情况予以说明。**

{% asset_img 2.webp %}

> Nature一周连发两文探讨ChatGPT：学术圈使用已不可避免，是时候明确使用规范了

在科技巨头为了ChatGPT大打出手的另一边，学术圈对于ChatGPT的关注也在升高。

一周时间内，Nature**连发两篇**文章探讨ChatGPT及生成式AI。

{% asset_img 3.webp %}

{% asset_img 4.webp %}

毕竟ChatGPT最早还是在学术圈内掀起风浪，先后有学者拿它写论文摘要、改论文。

Nature为此专门颁布禁令：ChatGPT不能当论文作者。Science则直接禁止投稿使用ChatGPT生成文本。

但趋势已摆在眼前。

现在更应该做的，或许是**明确ChatGPT对于科学界的意义**以及应当处于怎样的身位。

正如Nature所言：

> 生成式AI及背后的技术发展如此之快，每个月都有创新出现。研究人员如何使用它们，将决定着技术和学界的未来。

***

### ChatGPT改变学术圈规则

在《ChatGPT：五大优先研究问题》一文中，研究人员提出：

> 无法阻止ChatGPT杀入学术圈，当务之急应该是研究探讨它会带来哪些潜在影响。

如果后续ChatGPT被拿来设计实验、进行同行审议、辅助出版、帮编辑决定是否要接收文章……这些应用应该注意哪些问题？现在人类需要明确哪些边界？

研究人员认为，有5个方面需要优先考虑，并解释了原因。

#### 坚持人类审查

ChatGPT等对话式AI的一大特点，就是回答内容的准确性无法保证。而且编出来的瞎话都还很自然，容易对人产生误导。

比如，研究人员让ChatGPT对一篇关于认知行为疗法（CBT）治疗焦虑等症状是否有效的论文进行总结概述。

ChatGPT给出的回答中，存在很多事实性错误。如它说这项评估是基于**46项**研究，但实际上是**69项**，而且夸大了CBT的有效性。

{% asset_img 5.webp %}

研究人员认为如果有学者使用了ChatGPT帮忙做研究，很可能被错误信息误导。甚至会导致学者在不知情的情况下，**剽窃他人成果**。

因此，研究人员认为在评审论文过程中，人类不能过度依赖于自动化系统，最终还是要由人类自己为科学实践负责。

#### 制定问责规则

为了应对生成式AI的滥用，很多鉴别AI文本工具陆续诞生，它们能很好分辨出一段文字是不是人类自己写的。

不过，**研究人员认为这种“军备赛”大可不必**，真正要做的是让学术圈、出版商能更加公开透明地使用AI工具。

{% asset_img 6.webp %}

论文作者应该明确标注哪些工作是AI承担的，期刊如果使用AI审稿，也应该公开说明。

尤其是目前生成式AI已经引发了关于专利问题的讨论，AI生成的图像版权究竟该怎么算？

那么对于AI生成的问题，著作权应该属于为AI提供训练数据的人？AI背后的制作公司？还是用AI写文章的学者？作者身份的问题，也需要严谨定义。

#### 投资真正开放的LLM

目前，几乎所有先进的对话式AI，都是科技巨头们带来的。

关于AI工具背后算法的工作原理，很多都还不得而知。

这也引发了社会各界的担忧，因为巨头们的垄断行为，严重违背了科学界开放的原则。

这将会影响学术圈探寻对话式AI的缺点和底层原理，进一步影响科技的进步。

为了克服这种不透明性，研究人员认为当下应该**优先考虑开源AI算法的开发和应用**。比如开源大模型BLOOM，就是由1000位科学家联合发起的，性能方面可以匹敌GPT-3。

{% asset_img 7.webp %}

#### 拥抱AI的优点

虽然有很多方面需要设限，但不可否认，AI确实能提升学术圈的效率。

比如一些审查工作，AI可以快速搞定，而学者们就能更加专注于实验本身了，成果也能更快发表，从而推动整个学术圈的脚步走得更快。

甚至在一些创造性工作上，研究人员认为AI也能有用武之地。

> 1991年的一篇开创性论文提出，人和AI之间形成的“智能伙伴关系”，**可以胜过单独人类的智力和能力**。
> 这种关系能够将创新加速到无法想象的水平。但问题是，这种自动化能走多远？应该走多远？

因此，研究人员也呼吁，包括伦理学家在内的学者，必须就当今AI在知识内容生成方面的界限展开讨论，人类的创造力和原创性可能仍旧是进行创新研究必不可缺的因素。

{% asset_img 8.webp %}

#### 展开大辩论

鉴于当下LLM带来的影响，研究人员认为学界应该紧急组织一次大辩论。

他们呼吁，**每个研究小组都应该立即开组会，讨论并亲自试试ChatGPT**。大学老师应该主动和学生讨论ChatGPT的使用和伦理问题。

在早期规则还没有明确的阶段，对于研究小组负责人来说，重要的是如何号召大家更公开透明地使用ChatGPT，并开始形成一些规则。以及应该提醒所有研究人员，要对自己的工作负责，无论它是否由ChatGPT生成。

更进一步，研究人员认为要立即举办一个国际论坛，讨论LLM的研究和使用问题。

成员应该包括各个领域的科学家、科技公司、研究机构投资方、科学院、出版商、非政府组织以及法律和隐私方面的专家。

{% asset_img 9.webp %}

***

### Nature：ChatGPT和AIGC对科学意味着什么

兴奋又担忧，大概是许多研究人员对于ChatGPT的感受。

发展到现在，ChatGPT已经成为了许多学者的数字助手。

计算生物学家Casey Greene等人，用ChatGPT来修改论文。5分钟，AI就能审查完一份手稿，甚至连参考文献部分的问题也能发现。

来自冰岛的学者Hafsteinn Einarsson，几乎每天都在用ChatGPT来帮他做PPT、检查学生作业。

还有神经生物学家 Almira Osmanovic Thunström觉得，语言大模型可以被用来帮学者们写经费申请，科学家们能节省更多时间出来。

{% asset_img 10.webp %}

不过，Nature对ChatGPT输出内容做出了精辟总结：

> 流畅但不准确。

要知道，**ChatGPT的一大缺点，就是它生成的内容不一定是真实准确的**，这会影响它在学术圈的使用效果。

能解决吗？

从现在来看，答案有点扑朔迷离。

OpenAI的竞争对手Anthroic号称解决了ChatGPT的一些问题，不过他们没有接受Nature的采访。

Meta发布过一个名为Galactica的语言大模型，它由4800万篇学术论文、著作炼成，号称擅长生成学术方面内容，更懂研究问题。不过现在它的demo已经不开放了（代码还能用），因为用户在使用过程中发现它带有种族歧视。

即便是已经被调教“乖巧”的ChatGPT，也可能会在刻意引导下输出危险言论。

OpenAI让ChatGPT变乖的方法也很简单粗暴，就是去找非常多的人工给语料标注，有声音认为这种雇人看有毒语料的行为，也是一种剥削。

{% asset_img 11.webp %}

但无论如何，ChatGPT及生成式AI，开启了人类新的一扇想象之门。

医学学者埃里克·托普(Eric Topol)表示，他希望未来能有包含LLM的人工智能，可以交叉检查学术文献中的文本和图像，从而帮助人类诊断癌症、理解疾病。当然这一切要有专家做监督。

他说，真没想到我们在2023年年初，就看到了这样的趋势。

> 而这才只是开始。

***

### 参考链接

> <https://mp.weixin.qq.com/s/nElol1qC32Q32mh0dUsUxQ>
> <https://www.nature.com/articles/d41586-023-00340-6>
> <https://www.nature.com/articles/d41586-023-00288-7>
