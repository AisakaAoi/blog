---
title: Feature Pyramid Networks for Object Detection
categories:
  - 🌙进阶学习
  - ⭐脑机接口与混合智能研究团队（BCI团队）
  - 💫学习报告
abbrlink: 6674f972
date: 2022-12-16 20:41:39
tags:
---

本篇学习报告基于CVPR 2017的文章：[《Feature Pyramid Networks for Object Detection》](https://openaccess.thecvf.com/content_cvpr_2017/html/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.html)

### 概述

作者为目标检测任务提出了一种多尺度的特征融合算法：FPN（Feature Pyramid Networks），也就是近些年广泛运用的特征金字塔结构。原来多数的目标检测算法都只是采用顶层的特征图做预测。实际上我们只知道，低层的（low-level）特征图虽然语义信息较少，但是目标位置准确，与高层（high-level）特征图相反。之前其实也有一些多尺度特征融合算法，而FPN的特别之处在于融合前后用于预测的特征图个数是不变的，而在此之前的融合算法则是将多个不同尺度的特征图融合成一个进行检测。

<!--more-->

***

### 4种利用特征的方式

{% asset_img 1.webp %}
<div align='center'>图1.节点关系表示方法的比较</div>

上图展示了4种特征利用方式：
- (a)方法首先将图像缩放成不同的尺度（scale），对每一个尺度都生成一个对应的特征图用于预测，这种方法虽然检测的精度上去了，但是检测的速度是非常慢的，因为每个检测过程利用的特征计算都是完全独立的。
- (b)方法是检测速度最快的方法，仅采用单个特征图进行检测，像SPP net, Fast R-CNN以及Faster R-CNN就是采用的这种方法，这种方式在分类的精度上表现尚可但是在定位的准确性上表现较差。
- (c)方法是从网络的不同层（layer）抽取不同尺度的特征做预测，这种方式不会增加额外的计算量，像SSD(Single Shot Detector)就是采用的这种多尺度融合方式，没有上采样过程，作者认为这种方式将有助于检测小目标，同时提高定位的准确性，因为利用了较多低层（low-layer）的信息。
- (d)方法就是本文要说的FPN特征金字塔结构，高层特征通过上采样倒过来与低层特征相融合然后再进行预测，该方法能大大加强特征融合的效率，并且在检测的精度上也有显著的提高。

在FPN之前的特征融合方式如下图所示，和FPN一样采用了skip-connection的结构并且是自顶向下进行特征融合，但仅使用了最后一层融合结果用于预测。

{% asset_img 2.webp %}

FPN算法的大致结构如下图所示，一个「自底向上」的路线，一个「自顶向下」的路线，还有一个横向连接结构（lateral connection），图中放大区域就是横向连接，1\*1卷积核能够调整通道数使得不同层的特征图能够融合。自底向上其实就是网络的前向过程，在这个过程中，特征图（feature map）的大小在经过某些层后会改变，而经过其他一些层的时候不会改变，作者将不改变特征图大小的层归位一个stage，因此每次抽取的特征都是每个stage的最后一个层输出，这样就能够构成特征金字塔。自顶向下的过程采样上采样（upsampling）方式，而横向连接则是将上采样的结果和自底向上生成的相同大小的特征图进行融合（merge）。实际上，在融合之后还会再采用3\*3的卷积核对每个融合结果进行卷积，目的是为了消除上采样的混叠效应（aliasing effect）。

{% asset_img 3.webp %}

我们用ResNet举一个例子来说明什么是stage，下图是ResNet的网络结构组成示意图，可以看到第二列output size共变化了5次（FC层不算），其实就分别对应着5个stage，比如conv2_x这一层的输出就是P2，P是指Pyramid，特征金字塔自底向上的第2层。

{% asset_img 4.webp %}

***

### 使用FPN结构的效果

作者将FPN结构放在RPN（Region Proposal Network）中用于生成proposal（原意为“建议”，这里指可能含有目标的区域），原来的RPN网络是以主网络的某个卷积层输出的feature map作为输入，简单讲就是只用这一个尺度的feature map。但是现在要将FPN嵌在RPN网络中，生成不同尺度特征并融合作为RPN网络的输入。在每一个scale层，都定义了不同大小的anchor，对于P2，P3，P4，P5，P6这些层，定义anchor的大小分别为32\*32, 64\*64, 128\*128, 256\*256，512\*512，另外每个scale层都有3个长宽对比度：1:2，1:1，2:1，所以整个特征金字塔有15种anchor。正负样本的界定和Faster R-CNN差不多，如果某个anchor和一个给定的ground truth有最高的IOU或者和任意一个Ground truth的IOU都大于0.7，则是正样本，如果一个anchor和任意一个ground truth的IOU都小于0.3，则为负样本，其余的丢弃。

接下来看看加入FPN的RPN网络的有效性，如下表Table1。网络这些结果都是基于ResNet-50。评价标准采用AR，AR表示Average Recall，AR右上角的100表示每张图像有100个anchor，AR的右下角s，m，l表示COCO数据集中object的大小分别是小，中，大。feature列的大括号{}表示每层独立预测。从（a）（b）（c）的对比可以看出FPN的作用确实很明显。另外（a）和（b）的对比可以看出高层特征并非比低一层的特征有效。（d）表示只有横向连接，而没有自顶向下的过程，也就是仅仅对自底向上（bottom-up）的每一层结果做一个1\*1的横向连接和3\*3的卷积得到最终的结果，有点像Fig1的（b）。从feature列可以看出预测还是分层独立的。作者推测（d）的结果并不好的原因在于在自底向上的不同层之间的semantic gaps比较大。（e）表示有自顶向下的过程，但是没有横向连接，即向下过程没有融合原来的特征。这样效果也不好的原因在于目标的location特征在经过多次降采样和上采样过程后变得更加不准确。（f）采用仅最后一层的输出做预测，即经过多次特征上采样和融合到最后一步生成的特征用于预测，主要是为了证明金字塔分层独立预测的表达能力。显然效果不如FPN好，原因在于RPN网络是一个窗口大小固定的滑动窗口检测器，因此在金字塔的不同层滑动可以增加其对尺度变化的鲁棒性。另外（f）有更多的anchor，说明增加anchor的数量并不能有效提高准确率。

{% asset_img 5.webp %}

文中的其他类似实验就不一一解读了。

***

### 总结

作者提出的FPN（Feature Pyramid Network）结构同时利用低层特征高分辨率和高层特征的高语义信息，通过融合这些不同层的特征达到预测的效果。并且预测是在每个融合后的特征层上单独进行的，这和常规的特征融合方式不同。

***

### 原文链接

> <https://www.scholat.com/teamwork/showPostMessage.html?id=12864>
