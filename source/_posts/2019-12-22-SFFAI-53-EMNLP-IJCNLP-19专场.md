---
title: SFFAI 53 | EMNLP-IJCNLP'19专场
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: 65d8e2e
date: 2019-12-22 04:24:26
tags:
---

SFFAI53 - 刘乾《一种基于拆分与重组的上下文改写方法》

<iframe src="//player.bilibili.com/player.html?aid=80355162&bvid=BV1fJ411s7KD&cid=137484960&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<!--more-->

SFFAI53 - 吴雨婷《异构知识图谱实体对齐和关系对齐的联合学习》

<iframe src="//player.bilibili.com/player.html?aid=80355162&bvid=BV1fJ411s7KD&cid=137492893&p=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

关注微信号：人工智能前沿讲习，回复“刘乾”，“吴雨婷”获取讲者PPT资料。
EMNLP是自然语言处理领域的顶级会议，由 ACL 学会下属特殊兴趣小组 SIGDAT组织，每年召开一次。EMNLP 如今已成为自然语言处理，特别是统计自然语言处理领域的学术盛会。2019 年的 EMNLP 联合 IJCNLP 一同召开，所以会议统称为 EMNLP-IJCNLP 2019。本期论坛我们邀请了两位EMNLP-IJCNLP 2019论文作者，来分享他们工作中的思考与创想。

***

### 讲者介绍

**刘乾：**北京航空航天大学与微软亚洲研究院联合培养博士，主要研究方向为对话系统中的语义解析(将文本解析成SQL语言)，目前已在AAAI与EMNLP等会议上发表论文3篇。

**报告题目：**一种基于拆分与重组的上下文改写方法

**报告摘要：**对话系统中的语义解析是一项重要而具有挑战性的任务，其中一大挑战就是相关训练语料的不足。而近些年语义解析领域在飞速发展，这启发我们将对话系统中的语义解析任务拆解为两个子任务：上下文重写和语义解析。子任务一旨在改写对话中的语句，从而消解其指代，补充其省略内容；子任务二则可以直接利用一个已经训练好的上下文无关的语义解析器，来生成对话对应的SQL语句。本篇论文主要聚焦在第一个任务上，为了完成这个任务，我们提出了一种新颖的基于拆分与重组两个阶段的强化学习方法。不同于直接利用原始语句生成改写句，这种方法引入span作为改写的基本单位，再利用span间的语义冲突重组生成改写句。在FollowUp数据集上进行的实验表明，我们方法的性能远远超过CopyNet，端到端指代消解网络等强大的基线模型。除此之外，我们还将在SQA数据集上探索了我们提出方法的可扩展性。

**Spotlight：**
1. 提出结合上下文改写与上下文无关的语义解析器完成对话中语义解析的任务；
2. 为上下文改写引入一种中间表示，极大地提升了上下文改写的性能；
3. 介绍的基于强化学习的方法是普适的，有较大可扩展性。

**吴雨婷：**北京大学信息科学技术学院直博三年级，主要研究方向为信息抽取，知识图谱（实体对齐、实体链接），图神经网络。

**报告题目：**异构知识图谱实体对齐和关系对齐的联合学习

**报告摘要：**实体对齐是实现异构知识图谱知识融合的有效手段。最近主流的实体对齐方法大都是基于嵌入表示的方法，即利用知识图谱的表示学习模型去建模知识图谱的结构信息，得到实体表示，从而通过计算不同知识图谱的实体表示间的距离来判断是否对齐。然而，目前绝大部分工作都没有尝试显式地利用关系表示去辅助实体对齐，而我们的论文证明这是一个提升实体对齐效果的简单且非常有效的方法。这篇论文提出了一个新颖的实体对齐联合学习框架。我们方法的核心是一个同时学习实体和关系表示的图卷积神经网络框架。我们的方法并不需要预先对齐的关系去学习关系表示，而是首先通过图卷积神经网络学到实体表示，然后利用实体表示去近似关系表示，进一步，我们将关系表示融合进实体表示中，从而迭代地学习两者更好的表示。我们在三个现实世界中的跨语言数据集上测试了我们的模型，实验结果显示我们的方法大幅度地超过了目前的state-of-the-art模型。

**Spotlight：**
1. 提出了一个新颖的针对实体对齐任务的联合学习框架，可以同时实现实体对齐和关系对齐；
2. 我们的模型不需要预先对齐关系，仅依赖一小部分种子对齐实体去得到实体和关系表示。且我们的联合学习框架可以灵活地应用于现有的实体对齐模型上；
3. 我们的模型效果在实体对齐和关系对齐任务上都超过了现有的state-of-the-art模型。

***

### 论文推荐

1. Incorporating Copying Mechanism in Sequence-to-Sequence Learning

    **推荐理由：**这篇论文非常出名，由于上下文改写任务本身的特殊性，一般生成的语句与原始句子有很大部分的重叠，所以带有复制机制的网络(CopyNet)非常适合应用在此任务中。

2. Unsupervised Context Rewriting for Open Domain Conversation

    **推荐理由：**除了语义解析领域外，常见的还需要上下文改写的场景还包括开放领域的聊天机器人。这篇论文旨在无监督地生成上下文改写训练语料，并以此提升下游任务的精度。

3. Learning to Map Context-Dependent Sentences to Executable Formal Queries

    **推荐理由：**这篇论文是一篇典型的用端到端的方式训练对话系统中语义解析器，也是NAACL2018的Outstanding Paper。与我们论文场景不同的是，这篇论文面向的是单领域的语义解析任务，而我们的论文面临的是跨领域的语义解析任务。

4. Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks

    **推荐理由：**这是第一篇尝试利用图卷积神经网络解决实体对齐任务的论文，在基于TransE学习知识图谱表示之外，给我们新的思路启发，为后面的利用图神经网络实现实体对齐的工作奠定的坚实的基础。

5. Relation-Aware Entity Alignment for Heterogeneous Knowledge Graphs

    **推荐理由：**该文章通过引入对偶关系图去建模知识图谱中复杂的关系信息。模型核心是一个对偶图卷积网络，模型输入是待对齐的知识图谱和它们的对偶关系图，通过原始图和关系图的交互，利用关系信息去增强实体表示，从而实现精准的实体对齐。

6. Dual-Primal Graph Convolutional Networks

    **推荐理由：**这篇文章提出了一个对偶图卷积神经网络（上面的那篇实体对齐工作正是受到了这篇论文的启发），该模型可以同时学的图的顶点表示和边表示，泛化了之前的Graph Attention Network(GAT),并在多个任务上取得了state-of-the-art效果。

***

### 参考资料

> <https://www.bilibili.com/video/BV1fJ411s7KD/>
