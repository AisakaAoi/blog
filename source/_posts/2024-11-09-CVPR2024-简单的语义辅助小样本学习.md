---
title: CVPR2024 | 简单的语义辅助小样本学习
categories:
  - 🌙进阶学习
  - ⭐脑机接口与混合智能研究团队（BCI团队）
  - 💫学习报告
abbrlink: ac397f56
date: 2024-11-09 05:17:37
tags:
---

{% asset_img 1.webp %}

该论文发表于2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)（CCF A类），题目为《Simple Semantic-Aided Few-Shot Learning》。

四川大学的张海为此文第一作者，四川大学的徐浚哲为共同第一作者。四川大学的贺喆南教授为此文的通讯作者。

论文链接：https://ieeexplore.ieee.org/document/10658397

<!--more-->

***

### 论文概要

小样本学习（Few-Shot Learning）是一项旨在从有限数据中进行学习的计算机视觉任务，具有较高的挑战性。现有的一些小样本学习方法依赖语义信息以弥补数据稀少带来的特征不足。但传统的语义（如类名）容易引入偏差，且从外部知识库获取丰富语义成本较高。为此，本文提出了一种语义辅助小样本学习（Semantic-Aided Few-Shot Learning, SemFew）框架，通过语义进化（Semantic Evolution）自动生成高质量语义，减少对复杂网络结构的依赖；采用两层语义对齐网络（Semantic Alignment Network）将语义和视觉特征转换为具有丰富判别特征的鲁棒类原型。SemFew整体架构如图1。

{% asset_img 2.webp %}
<div align='center'>图1 SemFew整体架构</div>

***

### 研究背景

小样本学习面临的主要挑战是如何从少量数据中学习有效的特征。在传统的视觉特征提取方法中，由于样本数量有限，模型难以捕捉到足够的判别性特征，导致分类不准确。而语义信息作为辅助特征可以弥补视觉信息的不足。然而，现有的基于语义的方法要么依赖于简洁的类名作为语义源，存在歧义；要么使用离散属性标签作为类名的替代，但收集困难且成本高。因此，如何有效收集和利用高质量的语义成为亟待解决的研究需求。

***

### 研究方法

本文提出的语义辅助小样本学习（SemFew）框架，旨在解决小样本学习中因数据有限导致的分类困难问题。该框架主要由语义进化和语义对齐网络两部分组成，通过语义进化模块，自动收集丰富的语义信息，通过语义对齐网络，将语义和视觉特征转换为具有丰富判别特征的鲁棒类原型。图1是 Semantic-Aided Few-Shot Learning（SemFew）的整体架构。

***

#### 语义进化

首先从词网（WordNet）中检索与图像内容匹配的类名定义，得到一段简短的描述，由于描述相对简短，可能会忽略关键的视觉信息，所以进一步利用预训练的大语言模型（LLMs），根据特定提示扩充定义，从而自动生成详细准确且不泄露信息的高质量语义，为后续分类任务提供更丰富的语义信息。图2为语义进化流程图。

{% asset_img 3.webp %}
<div align='center'>图2 语义进化（Semantic Evolution）流程图</div>

***

#### 语义对齐网络

语义对齐网络（SemAlign）是一个两层网络结构，包含线性层W1、W2和激活函数σ，具体细节见图1。在获得高质量语义后，语义对齐网络将视觉特征与语义特征融合以重构鲁棒类原型。在训练阶段，将数据集图像经预训练的视觉编码器编码，高质量语义描述经文本编码器编码，然后将两者编码特征拼接后输入语义对齐网络进行原型重构，训练时通过损失函数监督重构原型与聚类中心的距离，公式如下：

{% asset_img 4.webp %}

具体来说，假设数据集中的第i幅图像表示为xi，其标签和语义分别表示为yi和si 。首先，xi由一个视觉编码器f（如ResNet-12）编码，该编码器在基集上进行预训练。此外，语义描述si由现成的文本编码器g（如CLIP或BERT）编码。然后，将编码后的视觉特征和文本特征拼接在一起，输入到语义对齐网络 h中重构原型。其中h(f (xi), g(si)) = σ([f (xi) · g(si)]⊤W1)W2是具有可学习权重W1和W2的语义对齐网络h，语义对齐网络h的输出即为生成的重构原型，c为聚类中心，||⋅||1​ 表示 ℓ1范数，计算了SemAlign模型输出的特征与类中心 cyi之间的差异。

在测试阶段，从新颖集（novel set）中随机采样N-way-K-shot支持集，对于第t类，通过语义进化模块获得类别t的高质量语义描述st，用视觉编码器f和文本编码器g分别对支持图像x和语义描述st进行编码，然后输入h得到t类的重构原型rt，公式如下：

{% asset_img 5.webp %}

随后，为了确保重建原型与真实原型进一步对齐，生成的重构原型rt再与支持图像的均值ut以凸组合方式融合得到最终分类原型pt，公式如下：

{% asset_img 6.webp %}

最后使用余弦距离计算查询样本与原型的距离，通过概率公式为查询样本分配标签，公式如下：

{% asset_img 7.webp %}

其中d(·, ·)表示距离度量，设置为余弦距离，N表示类的数量。

***

### 实验结果

本文提出的方法与之前的方法在基准数据集MiniImageNet和TieredImageNet上的比较结果如图3，在基准数据集CIFAR-FS和FC100上的结果如图4，结果表明，本文所提出的SemFew方法在5-way 1-shot和5-way 5-shot设置下的分类性能优于当前的最先进方法。Places和CUB 是用于跨领域场景测试的数据集，本文的方法在跨域任务上也取得了显著的效果，结果如图5。综合表明，高质量的语义信息在少样本学习中能有效提升分类性能，即便使用简单的网络结构。

{% asset_img 8.webp %}
<div align='center'>图3 SemFew方法与其他方法在MiniImageNet和TieredImageNet的实验结果</div>

{% asset_img 9.webp %}
<div align='center'>图4 SemFew方法与其他方法在CIFAR-FS和FC100的实验结果</div>

{% asset_img 10.webp %}
<div align='center'>图5 SemFew方法与其他方法在Places和CUB的实验结果</div>

***

### 结论

本文提出了一种有效的小样本学习框架，即简单语义辅助小样本学习。通过语义进化自动生成高质量语义，设计语义对齐网络将视觉和语义特征转换为鲁棒类原型，验证了简单网络在高质量语义支持下的强大性能，为未来小样本学习提供了新的方向。

***

### 原文链接

> <https://www.scholat.com/teamwork/showPostMessage.html?id=16395>
