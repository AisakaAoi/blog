---
title: 脑机接口里程碑进展！全身瘫痪者交流速度大幅接近自然水平，甚至还能做表情
categories:
  - 🌙进阶学习
  - ⭐脑机接口与混合智能研究团队（BCI团队）
  - 💫新闻
abbrlink: ed7b8ec6
date: 2023-09-12 01:25:20
tags:
---

2023年8月23日，《Nature》杂志同时发表了两篇脑机接口技术（BCI）的重磅文章，为帮助那些因脑损伤和疾病而失去语言能力的人恢复语言能力迈出了重要一步，为我们带来了前沿领域的最新进展。

一篇名为《A high-performance speech neuroprosthesis》的文章研究使用了植入的微电极阵列（MEA）识别受试者说话时口面动作相关的脑区神经信号，经机器学习模型解码，最终令受试者可以以每分钟62词的速度与人交流，这是以往同类技术最高速度的3倍，已经大大接近了无语言障碍者的自然交流速度（160词/分钟）。

另一篇名为《A high-performance neuroprosthesis for speech decoding and avatar control》的文章研究利用了皮层电描记术（ECoG）来记录控制口腔和面部肌肉的运动皮层神经活动，同样以机器学习解码，其交流速度达到每分钟78词，而且该技术还允许虚拟形象根据神经活动模拟出说话者的口型和面部表情，提供了交流中的视觉反馈，大大丰富了受试者的交流能力。

<!--more-->

***

### 背景

脑机接口的发展其实已经铺垫多年。

1969年，人类首次在恒河猴中证明，通过训练可以增加单个神经元的活动，以实现特定的行为。

20世纪90年代末，人体试验开始了。人类首次将电极植入了一名因肌萎缩性侧索硬化症（ALS）引起闭锁综合征的患者神经元。

2006年，毫米级的微电极阵列（MEA）出现了，它被植入一名脊髓损伤患者的大脑中。MEA能够记录运动皮层中数百个神经元的活动，从而控制机械手臂。也是从那时候开始，人们尝试使用MEA来解码写字过程中的手部运动，完成语言交流的任务。

同时，脑电图（EEG）及其衍生技术也在蓬勃发展。1999年开始，脑电图就被用于记录大脑活动，并通过自定义的拼写软件来协助瘫痪者交流。在此基础上，放置于大脑皮层表面的电极能够比头皮电极获得更高质量的信号，由此，皮层电描记术（ECoG）诞生了。

MEA和ECoG两项技术成为了脑机接口的基础。如今，有约50名不同程度的瘫痪患者能够通过脑机接口进行交流。

{% asset_img 1.webp %}
<div align='center'>图1 左为ECoG脑机接口，右为MEA脑机接口</div>

***

### 突破技术

在《A high-performance speech neuroprosthesis》的研究中，团队尝试给运动神经元疾病（运动神经元疾病，也被称为肌萎缩侧索硬化症，这种疾病会导致肌肉逐渐失去控制，导致行动和说话困难，即保留了一些有限的口面部运动和发声能力，但无法产生可理解的言语）患者的大脑体感运动皮层植入了阵列电极(共包含128个电极)，用于收集单个神经元活动。参与者在BrainGate2试点临床试验中根究显示器上的提示试图做出个人的口面部运动(图2a,b)，说出单个音素或说出单个单词。研究人员记录了四个微电极阵列的神经活动——两个在6v区(腹侧运动前皮层)10，两个在44区(布罗卡区的一部分)。

{% asset_img 2.webp %}
<div align='center'>图2 口面部运动和尝试言语的神经表征</div>

随后，研究人员利用RNN网络对采集到的大脑信号进行解码，并且搭配一个语言模型共同用于从神经元活动中预测发声。

最终结果非常惊人，利用该系统，患者能够以平均每分钟62个单词的速度进行交流，而且125000个词汇量中错误率为23.8%，50个单词的词汇错误率为9.1%。

在《A high-performance neuroprosthesis for speech decoding and avatar control》的研究中，47岁的Ann在18年前由于脑干中风后失去了说话的能力。研究人员在大脑皮层表面放置嵌入了253个 ECoG 电极的阵列，可以同时记录数千个神经元的平均活动(图3a)。并通过手术植入感觉运动皮层的左侧“面部区域”——大脑中服务于口腔和面部肌肉(包括声道)的部分。

在该研究中，参与者在屏幕上看到一个句子作为文本提示，并被指示在视觉提示后默默地尝试说出这个句子(具体来说，她试图默默地说出这句话，而不发出任何声音)。这与想象或内心语言不同，因为她试图尽其所能地使用她的发音器。同时，研究人员对所有253个ECoG电极记录的神经信号进行处理，提取高伽马活动(HGA;70 ~ 150Hz)和低频信号(0.3 ~ 17Hz)。之后训练循环神经网络模型来学习这些ECoG特征与手机、语音特征和发音手势之间的映射，然后分别使用它们来输出文本、合成语音音频和动画虚拟化身(图3a)。该模型以每分钟78个单词的速度从1024个单词组成句子，单词错误率为25.5%。或者，将大脑信号直接翻译成合成语音，对于1024个单词的词汇，单词错误率为54.4%；当词汇量小一些，错误率有所下降(119个单词的词汇量为8.2%)。

{% asset_img 3.webp %}
<div align='center'>图3 声道麻痹参与者的多模态语音解码</div>

该团队尝试解码面部表情，并使用数字化身再现，这样可以为文本或语音提供视觉反馈，极大地丰富了参与者的沟通能力。与之前报道的基于ECoG脑机接口相比，该项研究在词汇量、通信速度和语音解码的多功能性方面都有显著的提升。

***

### 意义与影响

两篇论文带来的新技术不失为脑机接口的里程碑进展，不过仍旧有许多问题等待下一步研究解答。例如两项技术都通过识别受试者的口头表达运动来解码语言，这两位患者均有微弱的语言能力保留，但对于那些病情更加严重的患者是否有用还未可知；而脑机接口目前仍然无法做到“无线”，如何在未来取消患者头顶的“天线”也是个非常值得探究的方向。

总而言之，这两篇论文推动了神经科学的进步，也为因病失去语言能力的患者提供了希望。

***

### 参考链接

> <https://www.scholat.com/teamwork/showPostMessage.html?id=14267>
> Willett, F.R., Kunz, E.M., Fan, C. et al. A high-performance speech neuroprosthesis. Nature(2023).  https://doi.org/10.1038/s41586-023-06377-x
> Metzger, S.L., Littlejohn, K.T., Silva, A.B. et al.A high-performance neuroprosthesis for speech decoding and avatar control.Nature(2023). https://doi.org/10.1038/s41586-023-06443-4
> <https://www.nature.com/articles/d41586-023-02546-0>
> <https://new.qq.com/rain/a/20230824A093L700>
> <https://www.thepaper.cn/newsDetail_forward_24348264>
