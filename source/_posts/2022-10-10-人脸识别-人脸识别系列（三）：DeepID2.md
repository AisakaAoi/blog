---
title: 人脸识别-人脸识别系列（三）：DeepID2
categories:
  - 🌙进阶学习
  - ⭐人工智能 Artificial Intelligence
  - 💫研究领域 Research Area
  - 🛰️计算机视觉 Computer Vision
tags:
  - ☄️人脸识别 Face Recognition
abbrlink: d5ea2bb7
date: 2022-10-10 00:45:36
---

论文地址：[Deep Learning Face Representation by Joint Identification-Verification](https://arxiv.org/abs/1406.4773)

### 文章思想

**reducing** the **intra-personal variations** while **enlarging** the **inter-personal differences** is a central topic in face recognition

分类任务，我们需要的是减少类内差距，增加类间差距。

The **identification supervisory** signal tends to **pull apart** the DeepID2 features of **different identities** since they have to be classified into different classes

分类的监督信号可以增大类间差距

However, the identification signal has a **relatively weak constraint** on DeepID2 features extracted from **the same identity**, since dissimilar DeepID2 features could be mapped to the same identity through function g(·) ，This leads to problems when DeepID2 features are generalized to new tasks and new identities in test where g is not applicable anymore

但是却对类内差距影响不大

We solve this by using an additional face verification signal, which requires that every two DeepID2 feature
vectors extracted from the same identity are close to each other while those extracted from different
identities are kept away

而增加验证的监督信号，就可以减少类内差距。

<!--more-->

***

### 网络结构

{% asset_img 1.webp %}

网络结构类似DeepID1,不同之处在于使用了两种不同的损失函数

***

### 损失函数

#### 分类信号

{% asset_img 2.webp %}

Softmax函数的**交叉熵**，类似于一般的卷积神经网络

#### 验证信号

{% asset_img 3.webp %}

使用**l2范数**距离表示，m为阈值，括号内的θve={m}

（这一损失函数在后面的人脸识别论文中通常会被称为contrastive loss）

***

### 训练过程

{% asset_img 4.webp %}

其中m不参于训练

过程简单概括为

1. 一次使用2个输入，计算了他们的L(Ident)和L(Verif),总损失L为二者通过λ加权求和
2. 通过L来执行梯度下降更新卷积参数
3. 通过L(Ident)来更新softmax层的参数

#### 多patches操作

每张图片使用了21 facial landmarks

分成200patches（20regions*5scales*2RGB&Gray），水平翻转后变为400patches

使用了200个卷积神经网络，提取400（200*2）个Deepid2特征

（一个神经网络对应的是一个patch与它的翻转对应的Patch）

使用 Adaptive forward-backward greedy algorithm降为25个Deepid2特征

使用PCA将25*160Deepid2特征降为180维

输入联合贝叶斯算法中，进行验证。

***

### 实验

在celebrate+上训练

在LFW上进行验证。

#### λ对类间与类内特征的影响**

{% asset_img 5.webp %}

文中选取λ=0.05
验证信号使用什么计算方法的试验：

{% asset_img 6.webp %}

可以看出来联合贝叶斯算法略优于L2距离。

#### 最终试验结果

选择效果最好的25个patches对应的25个网络，在LFW上得到的最终准确率是98.97%

{% asset_img 7.webp %}

之后，重复使用贪婪的方式寻找其他6组patches（每组25个），得到7组25Paches,用联合贝叶斯算法计算相应的神经网络输出特征可以得到7个得分，使用SVM融合这7个得分来得到最终的准确率是99.15%

（论文没有提到怎么融合的，猜测具体的融合方法大概是构建一个7维的向量，然后根据该得分向量来分类）

***

### 参考资料

> 版权声明：本文为CSDN博主「Fire_Light_」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
> 原文链接：https://blog.csdn.net/Fire_Light_/article/details/79559051
