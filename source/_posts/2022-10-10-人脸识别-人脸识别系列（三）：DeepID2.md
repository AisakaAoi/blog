---
title: äººè„¸è¯†åˆ«-äººè„¸è¯†åˆ«ç³»åˆ—ï¼ˆä¸‰ï¼‰ï¼šDeepID2
categories:
  - ğŸŒ™è¿›é˜¶å­¦ä¹ 
  - â­äººå·¥æ™ºèƒ½ Artificial Intelligence
  - ğŸ’«ç ”ç©¶é¢†åŸŸ Research Area
  - ğŸ›°ï¸è®¡ç®—æœºè§†è§‰ Computer Vision
tags:
  - â˜„ï¸äººè„¸è¯†åˆ« Face Recognition
abbrlink: d5ea2bb7
date: 2022-10-10 00:45:36
---

è®ºæ–‡åœ°å€ï¼š[Deep Learning Face Representation by Joint Identification-Verification](https://arxiv.org/abs/1406.4773)

### æ–‡ç« æ€æƒ³

**reducing** the **intra-personal variations** while **enlarging** the **inter-personal differences** is a central topic in face recognition

åˆ†ç±»ä»»åŠ¡ï¼Œæˆ‘ä»¬éœ€è¦çš„æ˜¯å‡å°‘ç±»å†…å·®è·ï¼Œå¢åŠ ç±»é—´å·®è·ã€‚

The **identification supervisory** signal tends to **pull apart** the DeepID2 features of **different identities** since they have to be classified into different classes

åˆ†ç±»çš„ç›‘ç£ä¿¡å·å¯ä»¥å¢å¤§ç±»é—´å·®è·

However, the identification signal has a **relatively weak constraint** on DeepID2 features extracted from **the same identity**, since dissimilar DeepID2 features could be mapped to the same identity through function g(Â·) ï¼ŒThis leads to problems when DeepID2 features are generalized to new tasks and new identities in test where g is not applicable anymore

ä½†æ˜¯å´å¯¹ç±»å†…å·®è·å½±å“ä¸å¤§

We solve this by using an additional face verification signal, which requires that every two DeepID2 feature
vectors extracted from the same identity are close to each other while those extracted from different
identities are kept away

è€Œå¢åŠ éªŒè¯çš„ç›‘ç£ä¿¡å·ï¼Œå°±å¯ä»¥å‡å°‘ç±»å†…å·®è·ã€‚

<!--more-->

***

### ç½‘ç»œç»“æ„

{% asset_img 1.webp %}

ç½‘ç»œç»“æ„ç±»ä¼¼DeepID1,ä¸åŒä¹‹å¤„åœ¨äºä½¿ç”¨äº†ä¸¤ç§ä¸åŒçš„æŸå¤±å‡½æ•°

***

### æŸå¤±å‡½æ•°

#### åˆ†ç±»ä¿¡å·

{% asset_img 2.webp %}

Softmaxå‡½æ•°çš„**äº¤å‰ç†µ**ï¼Œç±»ä¼¼äºä¸€èˆ¬çš„å·ç§¯ç¥ç»ç½‘ç»œ

#### éªŒè¯ä¿¡å·

{% asset_img 3.webp %}

ä½¿ç”¨**l2èŒƒæ•°**è·ç¦»è¡¨ç¤ºï¼Œmä¸ºé˜ˆå€¼ï¼Œæ‹¬å·å†…çš„Î¸ve={m}

ï¼ˆè¿™ä¸€æŸå¤±å‡½æ•°åœ¨åé¢çš„äººè„¸è¯†åˆ«è®ºæ–‡ä¸­é€šå¸¸ä¼šè¢«ç§°ä¸ºcontrastive lossï¼‰

***

### è®­ç»ƒè¿‡ç¨‹

{% asset_img 4.webp %}

å…¶ä¸­mä¸å‚äºè®­ç»ƒ

è¿‡ç¨‹ç®€å•æ¦‚æ‹¬ä¸º

1. ä¸€æ¬¡ä½¿ç”¨2ä¸ªè¾“å…¥ï¼Œè®¡ç®—äº†ä»–ä»¬çš„L(Ident)å’ŒL(Verif),æ€»æŸå¤±Lä¸ºäºŒè€…é€šè¿‡Î»åŠ æƒæ±‚å’Œ
2. é€šè¿‡Læ¥æ‰§è¡Œæ¢¯åº¦ä¸‹é™æ›´æ–°å·ç§¯å‚æ•°
3. é€šè¿‡L(Ident)æ¥æ›´æ–°softmaxå±‚çš„å‚æ•°

#### å¤špatchesæ“ä½œ

æ¯å¼ å›¾ç‰‡ä½¿ç”¨äº†21 facial landmarks

åˆ†æˆ200patchesï¼ˆ20regions*5scales*2RGB&Grayï¼‰ï¼Œæ°´å¹³ç¿»è½¬åå˜ä¸º400patches

ä½¿ç”¨äº†200ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œæå–400ï¼ˆ200*2ï¼‰ä¸ªDeepid2ç‰¹å¾

ï¼ˆä¸€ä¸ªç¥ç»ç½‘ç»œå¯¹åº”çš„æ˜¯ä¸€ä¸ªpatchä¸å®ƒçš„ç¿»è½¬å¯¹åº”çš„Patchï¼‰

ä½¿ç”¨ Adaptive forward-backward greedy algorithmé™ä¸º25ä¸ªDeepid2ç‰¹å¾

ä½¿ç”¨PCAå°†25*160Deepid2ç‰¹å¾é™ä¸º180ç»´

è¾“å…¥è”åˆè´å¶æ–¯ç®—æ³•ä¸­ï¼Œè¿›è¡ŒéªŒè¯ã€‚

***

### å®éªŒ

åœ¨celebrate+ä¸Šè®­ç»ƒ

åœ¨LFWä¸Šè¿›è¡ŒéªŒè¯ã€‚

#### Î»å¯¹ç±»é—´ä¸ç±»å†…ç‰¹å¾çš„å½±å“**

{% asset_img 5.webp %}

æ–‡ä¸­é€‰å–Î»=0.05
éªŒè¯ä¿¡å·ä½¿ç”¨ä»€ä¹ˆè®¡ç®—æ–¹æ³•çš„è¯•éªŒï¼š

{% asset_img 6.webp %}

å¯ä»¥çœ‹å‡ºæ¥è”åˆè´å¶æ–¯ç®—æ³•ç•¥ä¼˜äºL2è·ç¦»ã€‚

#### æœ€ç»ˆè¯•éªŒç»“æœ

é€‰æ‹©æ•ˆæœæœ€å¥½çš„25ä¸ªpatcheså¯¹åº”çš„25ä¸ªç½‘ç»œï¼Œåœ¨LFWä¸Šå¾—åˆ°çš„æœ€ç»ˆå‡†ç¡®ç‡æ˜¯98.97%

{% asset_img 7.webp %}

ä¹‹åï¼Œé‡å¤ä½¿ç”¨è´ªå©ªçš„æ–¹å¼å¯»æ‰¾å…¶ä»–6ç»„patchesï¼ˆæ¯ç»„25ä¸ªï¼‰ï¼Œå¾—åˆ°7ç»„25Paches,ç”¨è”åˆè´å¶æ–¯ç®—æ³•è®¡ç®—ç›¸åº”çš„ç¥ç»ç½‘ç»œè¾“å‡ºç‰¹å¾å¯ä»¥å¾—åˆ°7ä¸ªå¾—åˆ†ï¼Œä½¿ç”¨SVMèåˆè¿™7ä¸ªå¾—åˆ†æ¥å¾—åˆ°æœ€ç»ˆçš„å‡†ç¡®ç‡æ˜¯99.15%

ï¼ˆè®ºæ–‡æ²¡æœ‰æåˆ°æ€ä¹ˆèåˆçš„ï¼ŒçŒœæµ‹å…·ä½“çš„èåˆæ–¹æ³•å¤§æ¦‚æ˜¯æ„å»ºä¸€ä¸ª7ç»´çš„å‘é‡ï¼Œç„¶åæ ¹æ®è¯¥å¾—åˆ†å‘é‡æ¥åˆ†ç±»ï¼‰

***

### å‚è€ƒèµ„æ–™

> ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºCSDNåšä¸»ã€ŒFire_Light_ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚
> åŸæ–‡é“¾æ¥ï¼šhttps://blog.csdn.net/Fire_Light_/article/details/79559051
