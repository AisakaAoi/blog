---
title: 'FiLM: Visual Reasoning with a General Conditioning Layer'
categories:
  - 🌙进阶学习
  - ⭐脑机接口与混合智能研究团队（BCI团队）
  - 💫学习报告
abbrlink: 46f326e6
date: 2022-12-08 20:46:25
tags:
---

本篇学习报告的内容来自《FiLM: Visual Reasoning with a General Conditioning Layer》，该文章收录于AAAI 2018。文章提出了一种特征层面的线性调节方式，在视觉推理(visual reasoning)任务中有很好的效果，可以用于特征合并，例如处理模型的多输入问题。插入FiLM的模型有能力进行各种visual reasoning，包括计数，比较，等等。在某种程度上，可以将FiLM视为使用一个网络生成另一个网络的参数，使其成为超网络的一种形式。

<!--more-->

***

### 研究背景

Visual reasoning（视觉推理）指对图片信息进行分析，并做出一定的推理。其重点在于对于图片内容有逻辑上的理解。例如，普通分类器能够分出图片上是个球还是正方体，而visual reasoning需要做的任务是数出图片中有多少紫色的球，多少黄色的正方体。再比如，一张图片中有一个黄色大正方体，一堆不同颜色的小正方体、小球，小圆柱体，visual reasoning需要找出与大正方体颜色相同的小物体的颜色。概括来说，给出一幅图片和一个问题，visual reasoning就是根据图片回答问题。但是，视觉推理这个任务对普通的深度学习方法来说比较困难，属于一个多步骤、高层次的过程。而FiLM层在CLEVR的基准上提高了精度，对具有挑战性

***

### 实验模型与方法

#### 方法

FiLM层通过学习，自适应性地用仿射变换（线性变化＋平移，Ax＋b x和b为向量）影响着网络的输出。具体来说，FiLM对于输入学习两个函数f和h，并输出γi,c和​βi,c​ ：

下标表示第i个输入的第c个特征。用Fi,c表示网络的activation，γ和β通过特征仿射变换调节神经网络的激活F，可以表示为：

γi,c = fc(xi) βi,c = hc(xi), (1)

f和h可以是任意函数，比如两个神经网络。实际应用中，这两个函数可以看作一个函数，输出一个向量，因为f和h​共享参数对训练有帮助。这个合体后的函数就称作FiLM generator。整个大网络模型叫做Feature-wise Linearly Modulated network（FiLM-ed network）。FiLM generator可以对FiLM-ed network的feature maps特征图进行操作(放缩、提高或者下降域值（当跟在ReLU后边时候）)。对于CNN来说f和h根据不可知的空间位置，调节激活每个特征图分布。

FiLM(Fi,c|γi,c, βi,c) = γi,cFi,c + βi,c. (2)

***

#### 模型

一个CNN的单一FiLM层如图1所示。

{% asset_img 1.webp %}

将问题用GRU编码后得到的表示作为FiLM的输入，通过两个神经网络学习（和）得到缩放和偏差，接着对CNN学到的中间特征做仿射变换。γ和β的各种组合可以以各种方式调节单个特征图。FiLM会插入到每一个ResBlock中，对每一层CNN学到的特征进行modulation。点表示阿达玛德积。阿达玛德积不同于传统矩阵相乘计算方式，它是**对应矩阵元素相乘**，值得注意的是两个相乘的矩阵必须**行列数相同**。FiLM模型如图2所示。

{% asset_img 2.webp %}

阿达玛德积运算过程如图3所示。

{% asset_img 3.webp %}

FiLM模型由一个**FiLM生成语言管道**和一个**FiLM生成视觉管道**组成。即两个部分：理解问题(NLP),理解图片(CV)。

- **NLP部分**：首先对于一个输入问题xi，使用GRU网络来学习其语义信息。最后一层GRU是question embedding，模型对第n个残差模块通过仿射变换预测(γin，βin)。生成器使用门通循环单元(GRU)网络处理一个问题，该网络包含4096个隐藏单元，其中包含已学习的200维单词嵌入。最终的GRU隐藏状态是一个问题嵌入，模型从中进行预测。
- **CV部分**：同时，模型也会从输入图片中利用特征提取器（比如CNN）提取信息，一起加入到残差模块中进行学习。 可视管道从调整大小的224×224image输入中提取128个14×14image特征图，使用从头训练的CNN或使用固定的，预先训练的特征提取与学习层3×3的卷积。 从头开始训练的CNN由4个层(每个层有128个4× 4核)、ReLU激活和批处理归一化组成。固定的特征提取器输出在ImageNet 上预先训练的ResNet101 的conv4层，以匹配先前在clever上的工作。利用128个特征图和一个分类器，我们的模型- FiLM-ed残差块(ResBlocks)由4个图像特征块进行处理。该分类器由1×1卷积到512个特征映射、全局最大池和带有1024个隐藏单元的两层MLP组成，该MLP对最终答案输出softmax分布。

***

### 实验

实验部分可查看原文。

论文：https://arxiv.org/abs/1709.07871

代码：https://github.com/ethanjperez/film

***

### 实验结果与总结

FiLM在CLEVR数据集上达到了新的整体水平，超过了人类和以前的方法，其中包括那些使用明确的推理模型推理、监督学习又或是数据增强的方法。该结构由于其良好的鲁棒性，以及小样本环境下的能力，被应用到一些小样本分类工作中。比如simple CNAPS，一种改进小样本视觉分类的方法，在特征提取部分就使用了ResNet18+FiLM层。另外，该模型只是一层网络结构，故没有太多耦合问题，可以自己搭积木，应用到不同网络中去。

***

### 原文链接

> <https://www.scholat.com/teamwork/showPostMessage.html?id=12813>
