---
title: å›¾åƒä¿®å¤-æ·±åº¦å­¦ä¹ å›¾åƒä¿®å¤Image Inpainting | è®ºæ–‡æ•´ç† 2016-2022 | é™„è®ºæ–‡åŠä»£ç é“¾æ¥
categories:
  - ğŸŒ™è¿›é˜¶å­¦ä¹ 
  - â­äººå·¥æ™ºèƒ½ Artificial Intelligence
  - ğŸ’«ç ”ç©¶é¢†åŸŸ Research Area
  - ğŸ›°ï¸è®¡ç®—æœºè§†è§‰ Computer Vision
tags:
  - â˜„ï¸å›¾åƒä¿®å¤ Image Inpainting
abbrlink: a326acb1
date: 2022-06-30 04:30:21
---

{% asset_img 1.webp %}

å›¾åƒä¿®å¤(Image Inpainting)ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯å°†å›¾åƒä¸­æŸåçš„éƒ¨åˆ†ä¿®å¤èµ·æ¥ã€‚è¯¥æŠ€æœ¯å¯ä»¥åº”ç”¨åœ¨å›¾åƒç¼–è¾‘ä¸Šï¼Œä¾‹å¦‚ç§»é™¤ç‰©ä½“(remove unwanted object), å›¾åƒè¡¥å…¨ï¼Œä¿®å¤è€ç…§ç‰‡ç­‰ã€‚ä¼ ç»Ÿçš„å›¾åƒä¿®å¤æ–¹æ³•æœ‰diffusion-basedå’Œpatch-basedä¸¤ç§ï¼Œè€Œè¿‘äº›å¹´æ¥çš„æ–¹æ³•å¤šæ•°éƒ½æ˜¯åŸºäºæ·±åº¦å­¦ä¹ æ¥åšçš„ã€‚ä»Šå¤©å°±ä¸ºå¤§å®¶æ•´ç†2016-2022å¹´å›¾åƒä¿®å¤é¢†åŸŸçš„é‡è¦è®ºæ–‡ã€‚

<!--more-->

***

### ã€ŠContext Encoders: Feature Learning by Inpaintingã€‹â€”â€”æ·±åº¦å­¦ä¹ å›¾åƒä¿®å¤çš„å¼€å±±ä¹‹ä½œ

- ä¼šè®®/æœŸåˆŠï¼šCVPR 2016
- è®ºæ–‡é“¾æ¥ï¼š[CVPR 2016 Open Access Repository](https://openaccess.thecvf.com/content_cvpr_2016/html/Pathak_Context_Encoders_Feature_CVPR_2016_paper.html)
- ä»£ç é“¾æ¥ï¼š[GitHub - BoyuanJiang/context_encoder_pytorch: PyTorch Implement of Context Encoders: Feature Learning by Inpainting](https://github.com/BoyuanJiang/context_encoder_pytorch)
- ä½œè€…ï¼šDeepak Pathakï¼Œ Philipp Krahenbuhlï¼Œ Jeff Donahueï¼Œ Trevor Darrellï¼Œ Alexei A. Efros
- å•ä½ï¼šUniversity of California, Berkeley

{% asset_img 2.webp %}

***

### ã€ŠGlobally and Locally Consistent Image Completionã€‹â€”â€”å…¨å±€åˆ¤åˆ«å™¨å’Œå±€éƒ¨åˆ¤åˆ«å™¨è¿›è¡Œè®­ç»ƒ

- ä¼šè®®/æœŸåˆŠï¼šACM TOG 2017
- è®ºæ–‡é“¾æ¥ï¼š[https://dl.acm.org/doi/abs/10.1145/3072959.3073659](https://dl.acm.org/doi/abs/10.1145/3072959.3073659)
- ä»£ç é“¾æ¥ï¼š[GitHub - otenim/GLCIC-PyTorch: A High-Quality PyTorch Implementation of "Globally and Locally Consistent Image Completion".](https://github.com/otenim/GLCIC-PyTorch)
- ä½œè€…ï¼šSATOSHI IIZUKA, EDGAR SIMO-SERRA, HIROSHI ISHIKAWA
- å•ä½ï¼šWaseda University

{% asset_img 3.webp %}

***

### ã€ŠImage Inpainting for Irregular Holes Using Partial Convolutionsã€‹â€”â€”ä½¿ç”¨æ”¹è¿›çš„éƒ¨åˆ†å·ç§¯è¿›è¡Œä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šECCV 2018
- è®ºæ–‡é“¾æ¥ï¼š[ECCV 2018 Open Access Repository](https://openaccess.thecvf.com/content_ECCV_2018/html/Guilin_Liu_Image_Inpainting_for_ECCV_2018_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/tanimutomo/partialconv](https://github.com/tanimutomo/partialconv)
- ä½œè€…ï¼šGuilin Liuï¼Œ Fitsum A. Redaï¼Œ Kevin J. Shihï¼Œ Ting-Chun Wangï¼Œ Andrew Taoï¼Œ Bryan Catanzaro
- å•ä½ï¼šNVIDIA Corporation

{% asset_img 4.webp %}

{% asset_img 5.webp %}

åšæ–‡è®²è§£: [å¡å¡çŒ¡ç‰¹ï¼šè¯¦è§£Partial Convolution ï¼ˆä¸€ï¼‰ | å›¾åƒä¿®å¤é¢†åŸŸç»å…¸ä¹‹ä½œ | è¿ç®—æœºåˆ¶åŠæ¨¡å‹ç»“æ„](https://zhuanlan.zhihu.com/p/519446359)

***

### ã€ŠGenerative Image Inpainting with Contextual Attentionã€‹â€”â€”æ³¨æ„åŠ›æœºåˆ¶æ”¹è¿›Contextual Attention

- ä¼šè®®/æœŸåˆŠï¼šCVPR 2018
- è®ºæ–‡é“¾æ¥ï¼š[CVPR 2018 Open Access Repository](https://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Generative_Image_Inpainting_CVPR_2018_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/JiahuiYu/generative_inpainting](https://github.com/JiahuiYu/generative_inpainting)
- ä½œè€…ï¼šJiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, Thomas S. Huang
- å•ä½ï¼šUniversity of Illinois at Urbana-Champaign, Adobe Research

{% asset_img 6.webp %}
{% asset_img 7.webp %}

***

### ã€ŠEdgeConnect: Structure Guided Image Inpainting using Edge Predictionã€‹â€”â€”æ ¹æ®ç»“æ„è¾¹ç¼˜ä¿®å¤å›¾åƒ

- ä¼šè®®/æœŸåˆŠï¼šICCV workshop 2019
- è®ºæ–‡é“¾æ¥ï¼š[http://openaccess.thecvf.com/content_ICCVW_2019/html/AIM/Nazeri_EdgeConnect_Structure_Guided_Image_Inpainting_using_Edge_Prediction_ICCVW_2019_paper.html](https://openaccess.thecvf.com/content_ICCVW_2019/html/AIM/Nazeri_EdgeConnect_Structure_Guided_Image_Inpainting_using_Edge_Prediction_ICCVW_2019_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/knazeri/edge-connect](https://github.com/knazeri/edge-connect)
- ä½œè€…ï¼šKamyar Nazeri, Eric Ng, Tony Joseph, Faisal Z. Qureshi, and Mehran Ebrahimi
- å•ä½ï¼šUniversity of Ontario Institute of Technology, Canada

{% asset_img 8.webp %}

***

### ã€ŠFree-Form Image Inpainting with Gated Convolutionã€‹â€”â€”ä½¿ç”¨æ”¹è¿›çš„Gated Convolutionè¿›è¡Œä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šICCV 2019
- è®ºæ–‡é“¾æ¥ï¼š[https://openaccess.thecvf.com/content_ICCV_2019/html/Yu_Free-Form_Image_Inpainting_With_Gated_Convolution_ICCV_2019_paper.html](https://openaccess.thecvf.com/content_ICCV_2019/html/Yu_Free-Form_Image_Inpainting_With_Gated_Convolution_ICCV_2019_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/JiahuiYu/generative_inpainting](https://github.com/JiahuiYu/generative_inpainting)
- ä½œè€…ï¼šJiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, Thomas Huang
- å•ä½ï¼šUniversity of Illinois at Urbana-Champaign, Adobe Research, ByteDance AI Lab

***

### ã€ŠFree-Form Image Inpainting with Gated Convolutionã€‹â€”â€”ä½¿ç”¨æ”¹è¿›çš„Gated Convolutionè¿›è¡Œä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šICCV 2019
- è®ºæ–‡é“¾æ¥ï¼š[https://openaccess.thecvf.com/content_ICCV_2019/html/Yu_Free-Form_Image_Inpainting_With_Gated_Convolution_ICCV_2019_paper.html](https://openaccess.thecvf.com/content_ICCV_2019/html/Yu_Free-Form_Image_Inpainting_With_Gated_Convolution_ICCV_2019_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/JiahuiYu/generative_inpainting](https://github.com/JiahuiYu/generative_inpainting)
- ä½œè€…ï¼šJiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, Thomas Huang
- å•ä½ï¼šUniversity of Illinois at Urbana-Champaign, Adobe Research, ByteDance AI Lab\

{% asset_img 9.webp %}

***

### ã€ŠLearning Pyramid-Context Encoder Network for High-Quality Image Inpaintingã€‹â€”â€”é‡‘å­—å¡”å¼é€å±‚ä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šCVPR 2019
- è®ºæ–‡é“¾æ¥ï¼š[CVPR 2019 Open Access Repository](https://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Learning_Pyramid-Context_Encoder_Network_for_High-Quality_Image_Inpainting_CVPR_2019_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/researchmm/PEN-Net-for-Inpainting](https://github.com/researchmm/PEN-Net-for-Inpainting)
- ä½œè€…ï¼šYanhong Zeng, Jianlong Fu, Hongyang Chao, Baining Guo
- å•ä½ï¼šSun Yat-sen University, Microsoft Research

{% asset_img 10.webp %}

***

### ã€ŠPluralistic Image Completionã€‹â€”â€”æå‡ºå›¾åƒå¤šæ ·åŒ–ä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šCVPR 2019
- è®ºæ–‡é“¾æ¥ï¼š[CVPR 2019 Open Access Repository](https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Pluralistic_Image_Completion_CVPR_2019_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/lyndonzheng/Pluralistic-Inpainting](https://github.com/lyndonzheng/Pluralistic-Inpainting)
- ä½œè€…ï¼šChuanxia Zhengï¼Œ Tat-Jen Chamï¼Œ Jianfei Cai
- å•ä½ï¼šNanyang Technological University, Singapore

{% asset_img 11.webp %}

***

### ã€ŠBringing Old Photos Back to Lifeã€‹â€”â€”ä¿®å¤è€ç…§ç‰‡

- ä¼šè®®/æœŸåˆŠï¼šCVPR 2020
- è®ºæ–‡é“¾æ¥ï¼š[CVPR 2020 Open Access Repository](https://openaccess.thecvf.com/content_CVPR_2020/html/Wan_Bringing_Old_Photos_Back_to_Life_CVPR_2020_paper.html)
- ä»£ç é“¾æ¥ï¼š[GitHub - microsoft/Bringing-Old-Photos-Back-to-Life: Bringing Old Photo Back to Life (CVPR 2020 oral)](https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life)
- ä½œè€…ï¼šZiyu Wan1âˆ—, Bo Zhang2, Dongdong Chen3, Pan Zhang4, Dong Chen2, Jing Liao1â€ , Fang Wen2
- å•ä½ï¼š1.City University of Hong Kong. 2.Microsoft Research Asia. 3.Microsoft Cloud + AI. 4.University of Science and Technology of China

{% asset_img 12.webp %}

***

### ã€ŠPD-GAN: Probabilistic Diverse GAN for Image Inpaintingã€‹â€”â€”æå‡ºSPDNormè¿›è¡Œå¤šæ ·ä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šCVPR 2021
- è®ºæ–‡é“¾æ¥ï¼š[CVPR 2021 Open Access Repository](https://openaccess.thecvf.com/content/CVPR2021/html/Liu_PD-GAN_Probabilistic_Diverse_GAN_for_Image_Inpainting_CVPR_2021_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/KumapowerLIU/PD-GAN](https://github.com/KumapowerLIU/PD-GAN)
- ä½œè€…ï¼šHongyu Liu1, Ziyu Wan2, Wei Huang3, Yibing Song4, Xintong Han1*, Jing Liao2
- å•ä½ï¼š1.Huya Inc 2.City University of Hong Kong 3.Hunan University 4.Tencent AI Lab

{% asset_img 13.webp %}

***

### ã€ŠHigh-Fidelity Pluralistic Image Completion with Transformersã€‹â€”â€”ä½¿ç”¨Transformerè¿›è¡Œå¤šæ ·ä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šICCV 2021
- è®ºæ–‡é“¾æ¥ï¼š[ICCV 2021 Open Access Repository](https://openaccess.thecvf.com/content/ICCV2021/html/Wan_High-Fidelity_Pluralistic_Image_Completion_With_Transformers_ICCV_2021_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/raywzy/ICT](https://github.com/raywzy/ICT)
- ä½œè€…ï¼šZiyu Wan1, Jingbo Zhang1, Dongdong Chen2, Jing Liao1*
- å•ä½ï¼š1City University of Hong Kong 2Microsoft Cloud + AI

{% asset_img 14.webp %}

***

### ã€ŠCR-Fill: Generative Image Inpainting with Auxiliary Contextual Reconstructionã€‹â€”â€”æå‡ºè¯­å¢ƒé‡æ„è¾…åŠ©ä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šICCV 2021
- è®ºæ–‡é“¾æ¥ï¼š[https://openaccess.thecvf.com/content/ICCV2021/html/Zeng_CR-Fill_Generative_Image_Inpainting_With_Auxiliary_Contextual_Reconstruction_ICCV_2021_paper.html](https://openaccess.thecvf.com/content/ICCV2021/html/Zeng_CR-Fill_Generative_Image_Inpainting_With_Auxiliary_Contextual_Reconstruction_ICCV_2021_paper.html)
- ä»£ç é“¾æ¥ï¼š[https://github.com/zengxianyu/crfill](https://github.com/zengxianyu/crfill)
- ä½œè€…ï¼šYu Zeng1ï¼Œ Zhe Lin2ï¼Œ Huchuan Lu3,4ï¼Œ Vishal M. Patel1
- å•ä½ï¼š1. Johns Hopkins University 2. Adobe Research 3. Dalian University of Technology 4. Peng Cheng Lab

{% asset_img 15.webp %}

***

### ã€ŠBridging Global Context Interactions for High-Fidelity Image Completionã€‹â€”â€”ä½¿ç”¨Transformerè¿›è¡Œé•¿è·ç¦»æ³¨æ„åŠ›

- ä¼šè®®/æœŸåˆŠï¼šCVPR 2022
- è®ºæ–‡é“¾æ¥ï¼š[Bridging Global Context Interactions for High-Fidelity Image Completion](https://arxiv.org/abs/2104.00845)
- ä»£ç é“¾æ¥ï¼š[GitHub - lyndonzheng/TFill: CVPR2022:"Bridging Global Context Interactions for High-Fidelity Image Completion"](https://github.com/lyndonzheng/TFill)
- ä½œè€…ï¼šChuanxia Zheng, Tat-Jen Cham, Jianfei Cai, Dinh Phung
- å•ä½ï¼šNanyang Technological University, Singapore, Monash University, Australia

{% asset_img 16.webp %}

***

### ã€ŠImage Inpainting with Local and Global Refinementã€‹â€”â€”é€šè¿‡å…¨å±€åŠå±€éƒ¨ä¼˜åŒ–è¿›è¡Œä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šIEEE TIP 2022
- è®ºæ–‡é“¾æ¥ï¼š[https://ieeexplore.ieee.org/abstract/document/9730792/](https://ieeexplore.ieee.org/abstract/document/9730792/)
- ä»£ç é“¾æ¥ï¼š[https://github.com/weizequan/LGNet.git](https://github.com/weizequan/LGNet)
- ä½œè€…ï¼šWeize Quan, Ruisong Zhang, Yong Zhang, Zhifeng Li, Jue Wang, and Dong-Ming Yan
- å•ä½ï¼šInstitute of Automation, Chinese Academy of Sciences

{% asset_img 17.webp %}

***

### ã€ŠHigh-Quality Pluralistic Image Completion via Code Shared VQGANã€‹â€”â€”ä½¿ç”¨VQGANè¿›è¡Œå¤šæ ·å›¾åƒä¿®å¤

- ä¼šè®®/æœŸåˆŠï¼šarxiv 2022
- è®ºæ–‡é“¾æ¥ï¼š[https://arxiv.org/abs/2204.01931](https://arxiv.org/abs/2204.01931)
- ä»£ç é“¾æ¥ï¼šï¼ˆå¾…æ›´æ–°ï¼‰
- ä½œè€…ï¼šChuanxia Zheng,Guoxian Song,Tat-Jen Cham,Jianfei Cai,Dinh Phung,Linjie Luo
- å•ä½ï¼šMonash University, Australiaï¼›Nanyang Technological University, Singaporeï¼›ByteDance Inc, USA

{% asset_img 18.webp %}

***

### ã€ŠAggregated Contextual Transformations for High-Resolution Image Inpaintingã€‹â€”â€”æå‡ºäº†ä¸€ç§Aggregated COntextual-Transformation GANçš„é«˜åˆ†è¾¨ç‡å›¾åƒä¿®å¤æ–¹æ³•

- ä¼šè®®/æœŸåˆŠï¼šIEEE TIP 2022
- è®ºæ–‡é“¾æ¥ï¼š[https://ieeexplore.ieee.org/abstract/document/9729564](https://ieeexplore.ieee.org/abstract/document/9729564)
- ä»£ç é“¾æ¥ï¼š[https://github.com/researchmm/AOT-GAN-for-Inpainting](https://github.com/researchmm/AOT-GAN-for-Inpainting)
- ä½œè€…ï¼šYanhong Zeng, Jianlong Fu, Hongyang Chao, and Baining Guo
- å•ä½ï¼šMicrosoft Research, Sun Yat-sen University

{% asset_img 19.webp %}
{% asset_img 20.webp %}

***

### å‚è€ƒèµ„æ–™

> <https://zhuanlan.zhihu.com/p/520255427>
