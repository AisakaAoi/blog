---
title: SFFAI 134 | 关系抽取专题《崔立：一种基于关系原型表示的持续关系抽取方法》
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: ef2d8f98
date: 2022-01-04 02:18:30
tags:
---

<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=296956968&bvid=BV1JF411b7yk&cid=519328440&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>

<!--more-->

SFFAI论坛网站已开放注册，详情点击查看：https://bbs.sffai.com/d/312

关注公众号：【人工智能前沿讲习】，回复【SFFAI134】获取讲者PPT资料，入交流群，推荐论文下载。

相较于传统的关系抽取任务，持续学习背景下的关系抽取任务不预先设定关系类别，其最大的挑战在于如何使得模型在学习新关系的同时，保持对旧关系的分类能力。本期论坛我们邀请到了来自复旦大学的崔立同学，他提出获取优质的关系原型表示可以帮助模型更好地记忆旧关系的特征，从而维持稳定的表现。

***

### 讲者介绍

**崔立：**复旦大学大数据学院统计学硕士，现就职于北京字节跳动科技有限公司。主要研究方向为知识图谱构建中的关系抽取任务，目前已在ACL与IJCAI等会议上发表论文3篇。

**报告题目：**一种基于关系原型表示的持续关系抽取方法

**报告摘要：**本文通过选取并记忆各个关系标签下的典型样本生成关系原型表示并将其用于样本表示优化。本文方法在FewRel以及Tacred数据集上相较EMAR+BERT取得了超过10%的性能提升，且降低了56%的时间消耗。而对比实验进一步说明本文的持续关系抽取方法对典型样本的数量依赖显著地低于其他方法。

**论文题目：**Refining Sample Embeddings with Relation Prototypes to Enhance Continual Relation Extraction

**分享亮点：**
1. 本文提出了一种全新的基于关系原型表示的持续关系抽取方法；
2. 本文方法基于关系原型优化样本表示，显著地缓解了持续学习中的灾难性遗忘问题；
3. 本文方法对存储典型样本的数量依赖显著地低于其他基于记忆的方法。

***

### 论文推荐

1. Distant supervision for relation extraction without labeled data [Mike Mintz, et al.]

    这篇论文将远程监督的思想引入到关系抽取任务中，基于现有的知识库从语料中获取了大量的标注数据。

2. Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks [Daojian Zeng, et al.]

    这篇论文将卷积神经网络应用于关系抽取任务，同时引入多示例学习以解决远程监督带来的样本错误标注的问题。

3. Enriching Pre-trained Language Model with Entity Information for Relation Classification [Shanchan Wu, et al.]

    这篇论文通过BERT学习实体在句子中对应描述的向量化表示，并将其整合用于关系抽取任务。

4. Matching the Blanks: Distributional Similarity for Relation Learning [Livio Baldini Soares, et al.]

    这篇论文在应用BERT增强关系抽取模型表示能力的同时探究了不同的样本表示策略对于关系抽取模型性能的影响。

5. Prototypical networks for few-shot learning [Jake Snell, et al.]

    这篇论文在小样本学习的分类任务背景下提出了原型网络，基于各个类别的支持样本，生成对应的原型表示用于新样本分类。

6. Continual Relation Learning via Episodic Memory Activation and Reconsolidation [Xu Han, et al.]

    这篇论文基于原型网络的思想，抽取并存储各个关系标签的典型样本，基于Memory Replay的思想，解决持续关系抽取任务中的灾难性遗忘问题。

***

### 参考资料

> <https://www.bilibili.com/video/BV1JF411b7yk/>
