---
title: è®ºæ–‡é˜…è¯»-U-NetåŸç†åˆ†æä¸ä»£ç è§£è¯»
categories:
  - ğŸŒ™è¿›é˜¶å­¦ä¹ 
  - â­äººå·¥æ™ºèƒ½ Artificial Intelligence
  - ğŸ’«ç½‘ç»œæ¨¡å‹ Networks Model
abbrlink: 8607332c
date: 2022-07-13 16:36:15
tags:
---

### åŸæ–‡

{% pdf ./file/paper/2015-U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation.pdf %}

**U-Net** è®ºæ–‡é“¾æ¥ï¼š<https://arxiv.org/pdf/1505.04597.pdf>

<!--more-->

***

### Unet èƒŒæ™¯ä»‹ç»

Unet å‘è¡¨äº 2015 å¹´ï¼Œå±äº FCN çš„ä¸€ç§å˜ä½“ã€‚Unet çš„åˆè¡·æ˜¯ä¸ºäº†è§£å†³ç”Ÿç‰©åŒ»å­¦å›¾åƒæ–¹é¢çš„é—®é¢˜ï¼Œç”±äºæ•ˆæœç¡®å®å¾ˆå¥½åæ¥ä¹Ÿè¢«å¹¿æ³›çš„åº”ç”¨åœ¨è¯­ä¹‰åˆ†å‰²çš„å„ä¸ªæ–¹å‘ï¼Œæ¯”å¦‚å«æ˜Ÿå›¾åƒåˆ†å‰²ï¼Œå·¥ä¸šç‘•ç–µæ£€æµ‹ç­‰ã€‚

Unet è·Ÿ FCN éƒ½æ˜¯ Encoder-Decoder ç»“æ„ï¼Œç»“æ„ç®€å•ä½†å¾ˆæœ‰æ•ˆã€‚Encoder è´Ÿè´£ç‰¹å¾æå–ï¼Œä½ å¯ä»¥å°†è‡ªå·±ç†Ÿæ‚‰çš„å„ç§ç‰¹å¾æå–ç½‘ç»œæ”¾åœ¨è¿™ä¸ªä½ç½®ã€‚ç”±äºåœ¨åŒ»å­¦æ–¹é¢ï¼Œæ ·æœ¬æ”¶é›†è¾ƒä¸ºå›°éš¾ï¼Œä½œè€…ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œåº”ç”¨äº†å›¾åƒå¢å¼ºçš„æ–¹æ³•ï¼Œåœ¨æ•°æ®é›†æœ‰é™çš„æƒ…å†µä¸‹è·å¾—äº†ä¸é”™çš„ç²¾åº¦ã€‚

***

### Unet ç½‘ç»œç»“æ„ä¸ç»†èŠ‚

#### Encoder

{% asset_img 1.jpg %}

å¦‚ä¸Šå›¾ï¼ŒUnet ç½‘ç»œç»“æ„æ˜¯å¯¹ç§°çš„ï¼Œå½¢ä¼¼è‹±æ–‡å­—æ¯ U æ‰€ä»¥è¢«ç§°ä¸º Unetã€‚æ•´å¼ å›¾éƒ½æ˜¯ç”±è“/ç™½è‰²æ¡†ä¸å„ç§é¢œè‰²çš„ç®­å¤´ç»„æˆï¼Œå…¶ä¸­ï¼Œ**è“/ç™½è‰²æ¡†è¡¨ç¤º feature mapï¼›è“è‰²ç®­å¤´è¡¨ç¤º 3x3 å·ç§¯ï¼Œç”¨äºç‰¹å¾æå–ï¼›ç°è‰²ç®­å¤´è¡¨ç¤º skip-connectionï¼Œç”¨äºç‰¹å¾èåˆï¼›çº¢è‰²ç®­å¤´è¡¨ç¤ºæ± åŒ– poolingï¼Œç”¨äºé™ä½ç»´åº¦ï¼›ç»¿è‰²ç®­å¤´è¡¨ç¤ºä¸Šé‡‡æ · upsampleï¼Œç”¨äºæ¢å¤ç»´åº¦ï¼›é’è‰²ç®­å¤´è¡¨ç¤º 1x1 å·ç§¯ï¼Œç”¨äºè¾“å‡ºç»“æœã€‚**å…¶ä¸­ç°è‰²ç®­å¤´ copy and crop ä¸­çš„ copy å°±æ˜¯ concatenate è€Œ crop æ˜¯ä¸ºäº†è®©ä¸¤è€…çš„é•¿å®½ä¸€è‡´

å¯èƒ½ä½ ä¼šé—®ä¸ºå•¥æ˜¯ 5 å±‚è€Œä¸æ˜¯ 4 å±‚æˆ–è€… 6 å±‚ï¼Œemmmï¼Œè¿™åº”è¯¥å»é—®ä½œè€…æœ¬äººï¼Œå¯èƒ½å¯¹äºå½“æ—¶ä½œè€…æ‹¿åˆ°çš„æ•°æ®é›†æ¥è¯´ï¼Œè¿™ä¸ªå±‚æ•°çš„è¡¨ç°æ›´å¥½ï¼Œä½†ä¸ä»£è¡¨æ‰€æœ‰çš„æ•°æ®é›†è¿™ä¸ªç»“æ„éƒ½é€‚åˆã€‚æˆ‘ä»¬è¯¥å¤šå…³æ³¨è¿™ç§ Encoder-Decoder çš„è®¾è®¡æ€æƒ³ï¼Œå…·ä½“å®ç°åˆ™åº”è¯¥å› æ•°æ®é›†è€Œå¼‚ã€‚

Encoder ç”±å·ç§¯æ“ä½œå’Œä¸‹é‡‡æ ·æ“ä½œç»„æˆï¼Œæ–‡ä¸­æ‰€ç”¨çš„å·ç§¯ç»“æ„ç»Ÿä¸€ä¸º **3x3 çš„å·ç§¯æ ¸ï¼Œpadding ä¸º 0 ï¼Œstriding ä¸º 1**ã€‚æ²¡æœ‰ padding æ‰€ä»¥æ¯æ¬¡å·ç§¯ä¹‹å feature map çš„ H å’Œ W å˜å°äº†ï¼Œåœ¨ skip-connection æ—¶è¦æ³¨æ„ feature map çš„ç»´åº¦(å…¶å®ä¹Ÿå¯ä»¥å°† padding è®¾ç½®ä¸º 1 é¿å…ç»´åº¦ä¸å¯¹åº”é—®é¢˜)ï¼Œpytorch ä»£ç ï¼š

``` python
nn.Sequential(nn.Conv2d(in_channels, out_channels, 3),
              nn.BatchNorm2d(out_channels),
              nn.ReLU(inplace=True))
```

ä¸Šè¿°çš„ä¸¤æ¬¡å·ç§¯ä¹‹åæ˜¯ä¸€ä¸ª **stride ä¸º 2 çš„ max pooling**ï¼Œè¾“å‡ºå¤§å°å˜ä¸º 1/2 *(H, W)ï¼š

{% asset_img 2.jpg %}

pytorch ä»£ç ï¼š

``` python
nn.MaxPool2d(kernel_size=2, stride=2)
```

ä¸Šé¢çš„æ­¥éª¤é‡å¤ 5 æ¬¡ï¼Œæœ€åä¸€æ¬¡æ²¡æœ‰ max-poolingï¼Œç›´æ¥å°†å¾—åˆ°çš„ feature map é€å…¥ Decoderã€‚

***

#### Decoder

feature map ç»è¿‡ Decoder æ¢å¤åŸå§‹åˆ†è¾¨ç‡ï¼Œè¯¥è¿‡ç¨‹é™¤äº†å·ç§¯æ¯”è¾ƒå…³é”®çš„æ­¥éª¤å°±æ˜¯ upsampling ä¸ skip-connectionã€‚

Upsampling ä¸Šé‡‡æ ·å¸¸ç”¨çš„æ–¹å¼æœ‰ä¸¤ç§ï¼š**1.[FCN](https://zhuanlan.zhihu.com/p/77201674) ä¸­ä»‹ç»çš„åå·ç§¯ï¼›2. æ’å€¼ã€‚**è¿™é‡Œä»‹ç»æ–‡ä¸­ä½¿ç”¨çš„æ’å€¼æ–¹å¼ã€‚åœ¨æ’å€¼å®ç°æ–¹å¼ä¸­ï¼Œbilinear åŒçº¿æ€§æ’å€¼çš„ç»¼åˆè¡¨ç°è¾ƒå¥½ä¹Ÿè¾ƒä¸ºå¸¸è§ ã€‚

åŒçº¿æ€§æ’å€¼çš„è®¡ç®—è¿‡ç¨‹æ²¡æœ‰éœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œå®é™…å°±æ˜¯å¥—å…¬å¼ï¼Œè¿™é‡Œä¸¾ä¸ªä¾‹å­æ–¹ä¾¿å¤§å®¶ç†è§£(ä¾‹å­ä»‹ç»çš„æ˜¯å‚æ•° align_corners ä¸º Fasle çš„æƒ…å†µ)ã€‚

{% asset_img 3.jpg %}

ä¾‹å­ä¸­æ˜¯å°†ä¸€ä¸ª 2x2 çš„çŸ©é˜µé€šè¿‡æ’å€¼çš„æ–¹å¼å¾—åˆ° 4x4 çš„çŸ©é˜µï¼Œé‚£ä¹ˆå°† 2x2 çš„çŸ©é˜µç§°ä¸ºæºçŸ©é˜µï¼Œ4x4 çš„çŸ©é˜µç§°ä¸ºç›®æ ‡çŸ©é˜µã€‚åŒçº¿æ€§æ’å€¼ä¸­ï¼Œç›®æ ‡ç‚¹çš„å€¼æ˜¯ç”±ç¦»ä»–æœ€è¿‘çš„ 4 ä¸ªç‚¹çš„å€¼è®¡ç®—å¾—åˆ°çš„ï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»å¦‚ä½•æ‰¾åˆ°ç›®æ ‡ç‚¹å‘¨å›´çš„ 4 ä¸ªç‚¹ï¼Œä»¥ P2 ä¸ºä¾‹ã€‚

{% asset_img 4.jpg %}

ç¬¬ä¸€ä¸ªå…¬å¼ï¼Œç›®æ ‡çŸ©é˜µåˆ°æºçŸ©é˜µçš„åæ ‡æ˜ å°„ï¼š

{% asset_img 5.svg %}
{% asset_img 6.svg %}

ä¸ºäº†æ‰¾åˆ°é‚£ 4 ä¸ªç‚¹ï¼Œé¦–å…ˆè¦æ‰¾åˆ°ç›®æ ‡ç‚¹åœ¨æºçŸ©é˜µä¸­çš„**ç›¸å¯¹ä½ç½®**ï¼Œä¸Šé¢çš„å…¬å¼å°±æ˜¯ç”¨æ¥ç®—è¿™ä¸ªçš„ã€‚P2 åœ¨ç›®æ ‡çŸ©é˜µä¸­çš„åæ ‡æ˜¯ (0, 1)ï¼Œå¯¹åº”åˆ°æºçŸ©é˜µä¸­çš„åæ ‡å°±æ˜¯ (-0.25, 0.25)ã€‚åæ ‡é‡Œé¢å±…ç„¶æœ‰å°æ•°è·Ÿè´Ÿæ•°ï¼Œä¸æ€¥æˆ‘ä»¬ä¸€ä¸ªä¸€ä¸ªæ¥å¤„ç†ã€‚æˆ‘ä»¬çŸ¥é“åŒçº¿æ€§æ’å€¼æ˜¯ä»åæ ‡å‘¨å›´çš„ 4 ä¸ªç‚¹æ¥è®¡ç®—è¯¥åæ ‡çš„å€¼ï¼Œ(-0.25, 0.25) è¿™ä¸ªç‚¹å‘¨å›´çš„ 4 ä¸ªç‚¹æ˜¯(-1, 0), (-1, 1), (0, 0), (0, 1)ã€‚ä¸ºäº†æ‰¾åˆ°è´Ÿæ•°åæ ‡ç‚¹ï¼Œæˆ‘ä»¬å°†æºçŸ©é˜µæ‰©å±•ä¸ºä¸‹é¢çš„å½¢å¼ï¼Œä¸­é—´çº¢è‰²çš„éƒ¨åˆ†ä¸ºæºçŸ©é˜µã€‚

{% asset_img 7.png %}

æˆ‘ä»¬è§„å®š f(i, j) è¡¨ç¤º (i, j)åæ ‡ç‚¹å¤„çš„åƒç´ å€¼ï¼Œå¯¹äºè®¡ç®—å‡ºæ¥çš„å¯¹åº”çš„åæ ‡ï¼Œæˆ‘ä»¬ç»Ÿä¸€å†™æˆ (i+u, j+v) çš„å½¢å¼ã€‚é‚£ä¹ˆè¿™æ—¶ i=-1, u=0.75, j=0, v=0.25ã€‚æŠŠè¿™ 4 ä¸ªç‚¹å•ç‹¬ç”»å‡ºæ¥ï¼Œå¯ä»¥çœ‹åˆ°ç›®æ ‡ç‚¹ P2 å¯¹åº”åˆ°æºçŸ©é˜µä¸­çš„**ç›¸å¯¹ä½ç½®**ã€‚

{% asset_img 8.jpg %}

ç¬¬äºŒä¸ªå…¬å¼ï¼Œä¹Ÿæ˜¯æœ€åä¸€ä¸ªã€‚

**f(i + u, j + v) = (1 - u) (1 - v) f(i, j) + (1 - u) v f(i, j + 1) + u (1 - v) f(i + 1, j) + u v f(i + 1, j + 1)**

ç›®æ ‡ç‚¹çš„åƒç´ å€¼å°±æ˜¯å‘¨å›´ 4 ä¸ªç‚¹åƒç´ å€¼çš„åŠ æƒå’Œï¼Œæ˜æ˜¾å¯ä»¥çœ‹å‡ºç¦»å¾—è¿‘çš„æƒå€¼æ¯”è¾ƒå¤§ä¾‹å¦‚ (0, 0) ç‚¹çš„æƒå€¼å°±æ˜¯ 0.75 * 0.75ï¼Œç¦»å¾—è¿œçš„å¦‚ (-1, 1) æƒå€¼å°±æ¯”è¾ƒå°ï¼Œä¸º 0.25 * 0.25ï¼Œè¿™ä¹Ÿæ¯”è¾ƒç¬¦åˆå¸¸ç†å§ã€‚æŠŠå€¼å¸¦å…¥è®¡ç®—å°±å¯ä»¥å¾—åˆ° P2 ç‚¹çš„å€¼äº†ï¼Œç»“æœæ˜¯ 12.5 ä¸ä»£ç å»åˆä¸Šäº†ï¼Œniceã€‚

pytorch é‡Œä½¿ç”¨ bilinear æ’å€¼ï¼š

``` python
nn.Upsample(scale_factor=2, mode='bilinear')
```

CNN ç½‘ç»œè¦æƒ³è·å¾—å¥½æ•ˆæœï¼Œskip-connection åŸºæœ¬å¿…ä¸å¯å°‘ã€‚Unet ä¸­è¿™ä¸€å…³é”®æ­¥éª¤èåˆäº†åº•å±‚ä¿¡æ¯çš„ä½ç½®ä¿¡æ¯ä¸æ·±å±‚ç‰¹å¾çš„è¯­ä¹‰ä¿¡æ¯ï¼Œpytorch ä»£ç ï¼š

``` python
torch.cat([low_layer_features, deep_layer_features], dim=1)
```

è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ**FCN ä¸­æ·±å±‚ä¿¡æ¯ä¸æµ…å±‚ä¿¡æ¯èåˆæ˜¯é€šè¿‡å¯¹åº”åƒç´ ç›¸åŠ çš„æ–¹å¼ï¼Œè€Œ Unet æ˜¯é€šè¿‡æ‹¼æ¥çš„æ–¹å¼ã€‚**

é‚£ä¹ˆè¿™ä¸¤è€…æœ‰ä»€ä¹ˆåŒºåˆ«å‘¢ï¼Œå…¶å® åœ¨ ResNet ä¸ DenseNet ä¸­ä¹Ÿæœ‰ä¸€æ ·çš„åŒºåˆ«ï¼ŒResnet ä½¿ç”¨äº†å¯¹åº”å€¼ç›¸åŠ ï¼ŒDenseNet ä½¿ç”¨äº†æ‹¼æ¥ã€‚**ä¸ªäººç†è§£åœ¨ç›¸åŠ çš„æ–¹å¼ä¸‹ï¼Œfeature map çš„ç»´åº¦æ²¡æœ‰å˜åŒ–ï¼Œä½†æ¯ä¸ªç»´åº¦éƒ½åŒ…å«äº†æ›´å¤šç‰¹å¾ï¼Œå¯¹äºæ™®é€šçš„åˆ†ç±»ä»»åŠ¡è¿™ç§ä¸éœ€è¦ä» feature map å¤åŸåˆ°åŸå§‹åˆ†è¾¨ç‡çš„ä»»åŠ¡æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„é€‰æ‹©ï¼›è€Œæ‹¼æ¥åˆ™ä¿ç•™äº†æ›´å¤šçš„ç»´åº¦/ä½ç½® ä¿¡æ¯ï¼Œè¿™ä½¿å¾—åé¢çš„ layer å¯ä»¥åœ¨æµ…å±‚ç‰¹å¾ä¸æ·±å±‚ç‰¹å¾è‡ªç”±é€‰æ‹©ï¼Œè¿™å¯¹è¯­ä¹‰åˆ†å‰²ä»»åŠ¡æ¥è¯´æ›´æœ‰ä¼˜åŠ¿ã€‚**

***

### ä»£ç è§£è¯»

#### ç½‘ç»œæ¨¡å—å®šä¹‰

``` python
import torch
import torch.nn as nn
import torch.nn.functional as F


class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""

    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class up(nn.Module):
    ''' up path
        conv_transpose => double_conv
    '''
    def __init__(self, in_ch, out_ch, Transpose=False):
        super(up, self).__init__()

        #  would be a nice idea if the upsampling could be learned too,
        #  but my machine do not have enough memory to handle all those weights
        if Transpose:
            self.up = nn.ConvTranspose2d(in_ch, in_ch//2, 2, stride=2)
        else:
            # self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.up = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
                                    nn.Conv2d(in_ch, in_ch//2, kernel_size=1, padding=0),
                                    nn.ReLU(inplace=True))
        self.conv = double_conv(in_ch, out_ch)
        self.up.apply(self.init_weights)

    def forward(self, x1, x2):
        ''' 
            conv output shape = (input_shape - Filter_shape + 2 * padding)/stride + 1
        '''

        x1 = self.up(x1)

        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = nn.functional.pad(x1, (diffX // 2, diffX - diffX//2,
                                    diffY // 2, diffY - diffY//2))

        x = torch.cat([x2,x1], dim=1)
        x = self.conv(x)
        return x

    @staticmethod
    def init_weights(m):
        if type(m) == nn.Conv2d:
            init.xavier_normal(m.weight)
            init.constant(m.bias,0)



class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)
```

***

#### ç½‘ç»œç»“æ„æ•´ä½“å®šä¹‰

``` python
class Unet(nn.Module):
    def __init__(self, in_ch, out_ch, gpu_ids=[]):
        super(Unet, self).__init__()
        self.loss_stack = 0
        self.matrix_iou_stack = 0
        self.stack_count = 0
        self.display_names = ['loss_stack', 'matrix_iou_stack']
        self.gpu_ids = gpu_ids
        self.bce_loss = nn.BCELoss()
        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if torch.cuda.is_available() else torch.device('cpu')
        self.inc = inconv(in_ch, 64)
        self.down1 = down(64, 128)
        # print(list(self.down1.parameters()))
        self.down2 = down(128, 256)
        self.down3 = down(256, 512)
        self.drop3 = nn.Dropout2d(0.5)
        self.down4 = down(512, 1024)
        self.drop4 = nn.Dropout2d(0.5)
        self.up1 = up(1024, 512, False)
        self.up2 = up(512, 256, False)
        self.up3 = up(256, 128, False)
        self.up4 = up(128, 64, False)
        self.outc = outconv(64, 1)
        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)
        # self.optimizer = torch.optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0005)

    def forward(self):
        x1 = self.inc(self.x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x4 = self.drop3(x4)
        x5 = self.down4(x4)
        x5 = self.drop4(x5)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        x = self.outc(x)
        self.pred_y = nn.functional.sigmoid(x)

    def set_input(self, x, y):
        self.x = x.to(self.device)
        self.y = y.to(self.device)

    def optimize_params(self):
        self.forward()
        self._bce_iou_loss()
        _ = self.accu_iou()
        self.stack_count += 1
        self.zero_grad()
        self.loss.backward()
        self.optimizer.step()

    def accu_iou(self):
        # B is the mask pred, A is the malanoma 
        y_pred = (self.pred_y > 0.5) * 1.0
        y_true = (self.y > 0.5) * 1.0
        pred_flat = y_pred.view(y_pred.numel())
        true_flat = y_true.view(y_true.numel())

        intersection = float(torch.sum(pred_flat * true_flat)) + 1e-7
        denominator = float(torch.sum(pred_flat + true_flat)) - intersection + 2e-7

        self.matrix_iou = intersection/denominator
        self.matrix_iou_stack += self.matrix_iou
        return self.matrix_iou

    def _bce_iou_loss(self):
        y_pred = self.pred_y
        y_true = self.y
        pred_flat = y_pred.view(y_pred.numel())
        true_flat = y_true.view(y_true.numel())

        intersection = torch.sum(pred_flat * true_flat) + 1e-7
        denominator = torch.sum(pred_flat + true_flat) - intersection + 1e-7
        iou = torch.div(intersection, denominator)
        bce_loss = self.bce_loss(pred_flat, true_flat)
        self.loss = bce_loss - iou + 1
        self.loss_stack += self.loss
        
    def get_current_losses(self):
        errors_ret = {}
        for name in self.display_names:
            if isinstance(name, str):
                errors_ret[name] = float(getattr(self, name)) / self.stack_count
        self.loss_stack = 0
        self.matrix_iou_stack = 0
        self.stack_count = 0
        return errors_ret
        
    def eval_iou(self):
        with torch.no_grad():
            self.forward()
            self._bce_iou_loss()
            _ = self.accu_iou()
            self.stack_count += 1
```

***

#### å°ç»“

Unet åŸºäº Encoder-Decoder ç»“æ„ï¼Œé€šè¿‡æ‹¼æ¥çš„æ–¹å¼å®ç°ç‰¹å¾èåˆï¼Œç»“æ„ç®€æ˜ä¸”ç¨³å®šã€‚

***

### å‚è€ƒèµ„æ–™

> <https://zhuanlan.zhihu.com/p/79204199>
> <https://zhuanlan.zhihu.com/p/150579454>
