---
title: SFFAI 11 | 自注意力机制在计算机视觉中的应用
categories:
  - 🌙逢坂杂谈与搬运
  - ⭐一些讲座
abbrlink: dc7419b1
date: 2018-12-02 22:57:00
tags:
---

<iframe src="//player.bilibili.com/player.html?aid=38598844&bvid=BV1ct411Y7BD&cid=67834583&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

关注微信公众号：人工智能前沿讲习班，公众号对话框回复“蒋正锴”获取视频PPT。
在神经网络中，我们知道卷积层通过卷积核和原始特征的线性结合得到输出特征，由于卷积核通常是局部的，为了增加感受野，往往采取堆叠卷积层的方式，实际上这种处理方式并不高效。同时，计算机视觉的很多任务都是由于语义信息不足从而影响最终的性能。自注意力机制通过捕捉全局的信息来获得更大的感受野和上下文信息。这次的分享主要从自注意力的角度分析最近的一些发展，以及相应的改进方案。

<!--more-->

***

### 讲者介绍

**蒋正锴：**自动化研究所模式识别国家重点实验室研究生二年级在读，本科毕业于东北大学自动化专业。目前的研究方向为Object Detection and Segmentation. 以第一作者发表AAAI论文一篇。

**报告题目：**Self-Attention and It’s Application on Computer Vision

**报告摘要：**Transform在Language Model中取得了很大的成功。与此同时，Non-local Neural Network and Relation Networks都是它在计算机视觉中的很成功的应用。此次分享将介绍Self-Attention在视频检测以及神经网络结构上的应用。

**Spotlight：**
1. Self-Attention优缺点分析；
2. 计算机视觉中的Self-Attention,从目标检测到网络结构。

***

### 参考资料

> <https://www.bilibili.com/video/BV1ct411Y7BD/>
> <https://bbs.sffai.com/d/30-self-attention-and-its-application-on-computer-vision>
