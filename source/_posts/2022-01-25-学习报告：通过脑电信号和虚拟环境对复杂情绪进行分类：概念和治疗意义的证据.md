---
title: 学习报告：通过脑电信号和虚拟环境对复杂情绪进行分类：概念和治疗意义的证据
categories:
  - 🌙进阶学习
  - ⭐脑机接口与混合智能研究团队（BCI团队）
  - 💫学习报告
abbrlink: d9f350f3
date: 2022-01-25 20:18:35
tags:
---

西班牙庞培法布拉大学Eleonora De Filippi 等人在研究建立一种方法来分类离散的复杂情绪（例如，柔和、痛苦），这些情绪是通过虚拟现实的场景引发的，在未来可用于脑电图神经反馈。该论文于2021年8月发表在 SCI期刊《Frontiers in Human Neuroscience》 上。原文题目为Classification of Complex Emotions Using EEG and Virtual Environment: Proof of Concept and Therapeutic Implication。本文将会对论文中的内容进行介绍以及自己的总结。

{% asset_img 1.webp %}

<!--more-->

***

### 介绍

鉴于情绪对一系列心理社会过程的重要性，心理治疗方法已将痛苦情绪的训练作为治疗过程的一部分。实时fMRI-神经反馈训练（Real-time fMRI-Neurofeedback, NFB）是一种闭环脑机接口，已经在复杂情绪状态的自我调节方面进行了探索。最近，Lorenzetti 等人[1]证明，通过针对下丘脑中隔网络，可以对痛苦和柔和进行自我调节，参与从属感觉。在他们的实验中，Lorenzetti 及其同事验证了一种将 NFB 与多模式、沉浸式虚拟环境 BCI 和音乐相结合的新方法，可以向参与者提供情绪的反馈。然而，功能磁共振成像有几个缺点，例如信号延迟、高扫描成本以及不舒服的环境。相比之下，EEG 提供了更高的时间分辨率和信息处理的直接测量。它更便宜且使用相对简单，使其成为更易于使用的临床环境工具。

该研究采用了带有音频输入的多感官虚拟现实（Virtual Reality , VR）场景来引发复杂的情绪。音乐已被证明是在实验室环境中唤起真实感受的有效刺激物[2]。此外，VR的使用在过去几年中大幅增加，其对脑机接口（Brain-Computer Interfaces , BCI）应用的有效性已得到证明[3]。例如Johnson 等人[4]展示了使用VR-BCI训练进行中风后运动恢复的可行性。

迄今为止，使用EEG信号进行情绪分类的研究主要集中在基于心理模型的情绪分类上，主要采用“circumplex模型”，它描述了不同的情绪，二维空间中的情绪类型，包括效价和唤醒。另一种模型，离散情绪模型，主要用于探索基本情绪，即高兴、悲伤、愤怒、惊讶、恐惧和厌恶等。目前已有很多研究[5][6]尝试使用机器学习算法通过EEG特征进行区分积极和消极情绪。

最近，越来越多的研究使用深度学习算法研究情绪识别。特别是卷积神经网络显示出较好的结果，在区分情绪状态方面优于传统的机器学习模型[7][8]。然而，由于可用的训练数据有限，这些模型仍处于起步阶段，并且对基于EEG的BCI分类存在各种限制。

该研究，进行了概念验证研究，以建立一种可靠的方法，该方法可应用于基于EEG的NFB，用于复杂情绪状态的自我调节。该研究选择传统的机器学习方法线性支持向量机进行分类。该研究提取了正面阿尔法不对称特征（frontal-alpha asymmetry，FAA）和时间频率，以及整个头皮的相关特征。通过应用交叉验证方法来测试模型的性能和泛化特性，使用特征排序算法降低数据集的维度。

***

### 相关研究

使用虚拟场景实现了多模式刺激，这是 Unity 3D 资产秋季自然包，并附有特定情感的音乐。虚拟环境显示了丘陵和玉米地景观的第一人称视角，根据所引发的情绪不同的颜色：紫色表示痛苦，橙色表示舒缓，如图1所示。

{% asset_img 2.webp %}
<div align='center'>图1 虚拟现实场景</div>

连同这些视觉刺激，参与者听了不同的46秒的器乐片段。在所有的柔和实验中，该研究演奏了一段柔和的音乐。在进行痛苦实验，主要演奏让人不愉悦的声音。在中性试验中，风景则为彩色但是没有背景音乐。

该研究一共招募了11名的健康人作为被试参与实验，所有参与者都需要签署同意书并填写状态特征焦虑量表(State-Trait Anxiety Inventory , STAI)以及积极和消极影响表(The Positive and Negative Affect Schedule ,PANAS)。该研究在实验过程中使用一些特定话语和个人回忆记忆来促进情绪自我感应。

在进行情绪识别过程，首先，该实验的预处理包括将信号下采样到 250 Hz 并应用 0.01-45 Hz 的带通巴特沃斯滤波器。通过独立成分分析 (ICA) 算法校正眨眼和肌肉伪影。使用复杂的Morlet小波卷积将脑电信号数据转换为时频域，该研究使用MATLAB R2019b Statistics and Machine Learning Toolbox 对数据进行分类和可视化。选择了线性支持向量机 (SVM) 算法来对特征数组进行二进制分类，并使用8折交叉验证方法进行训练和验证分类器。该研究使用Wilcoxon rank-sum 方法对精度分布进行了统计分析，以了解哪种类型的特征表现更好。

***

### 结果

每个参与者的所有交叉验证运行的结果如图2所示。表1总结了每个场景的相应平均准确度。使用 Wilcoxon 秩和检验比较了两种类型的特征或特征数组（即整个特征集和所选特征的子集）的准确度分布，以及相应的p值。其中该研究使用的时频和FAA特征，准确率在59.2%到92.9%之间。

{% asset_img 3.webp %}
<div align='center'>图2. 使用时频/FAA 分析(1A,1B)和幅度时间序列相关分析(2A,2B)提取的特征的分类结果。使用所有可用特征(1A,2A)和针对每种特征提取方法仅使用 100 个选定特征(1B,2B)进行分类。作者进行了 10 次八折交叉验证，箱线图描绘了每个参与者 10 次分类运行的结果。</div>

{% asset_img 4.webp %}
<div align='center'>表1. 每个参与者特征提取方法和特征数量的分类准确率</div>

为了了解受试者表现的可变性，该研究使用t-SNE绘制两个参与者的数据集。如图3所示。

{% asset_img 5.webp %}
<div align='center'>图3. 受试者1和受试者5的数据集的T-SNE可视化，分别具有最佳性能（1A，2A）和最差的分类性能之一（1B，2B）。在痛苦和柔和两类的样本分别以紫色和橙色绘制。上面的两个图（1A，1B）描绘了时频分析数据集。下面的两个图（2A，2B）显示了两个参与者的幅度时间序列相关特征。</div>

***

### 总结与讨论

该研究证明了使用EEG和ML工具使用沉浸式的情绪刺激范式来区分复杂情绪状态。关于情感过程的神经影像学研究的一个关键挑战通常是参与者在实验环境中难以参与和维持有效的情绪状态，尤其是在试图引发复杂情绪是。该研究通过使用多模态虚拟现实（VR）尽可能通过提供更吸引人的场景来缓解和鼓励参与者参与实验。最后，通过个性化的语句进行自我诱导情绪状态可能会是的离散情绪分类有很好的结果。该研究所提出的一种适用于实时数据处理的基于EEG的BCI和NFB应用程序在识别复杂情绪会有不错的效果。

该研究也有一定的缺陷，由于个人音乐品味的差异，对所有受试者使用相同的音乐曲目可能会对参与者的情感激发产生不同的影响。以及作者在两种不同情感状态的分类中发现的高受试者间变异性。

***

> [1] Lorenzetti, V., Melo, B., Basilio, R., Suo, C., Yücel, M., Tierra-Criollo, C. J., et al. (2018). Emotion regulation using virtual environments and real-time fmri neurofeedback. Front. Neurol. 9:390. doi: 10.3389/fneur.2018.00390
> [2] Ribeiro, F. S., Santos, F. H., Albuquerque, P. B., and Oliveira-Silva, P. (2019). Emotional induction through music: measuring cardiac and electrodermal responses of emotional states and their persistence. Front. Psychol. 10:451. doi: 10.3389/fpsyg.2019.00451
> [3] Coogan, C. G., and He, B. (2018). Brain-computer interface control in a virtual reality environment and applications for the internet of things. IEEE Access 6, 10840–10849. doi: 10.1109/ACCESS.2018.2809453
> [4] Johnson, N., Carey, J., Edelman, B., Doud, A., Grande, A., Lakshminarayan, K., et al. (2018). Combined rtms and virtual reality brain-computer interface training for motor recovery after stroke. J. Neural Eng. 15:016009. doi: 10.1088/1741-2552/aa8ce3
> [5] Zhao, G., Zhang, Y., and Ge, Y. (2018a). Frontal EEG asymmetry and middle line power difference in discrete emotions. Front. Behav. Neurosci. 12:225. doi: 10.3389/fnbeh.2018.00225
> [6] Zhao, G., Zhang, Y., Ge, Y., Zheng, Y., Sun, X., and Zhang, K. (2018b). Asymmetric hemisphere activation in tenderness: evidence from EEG signals. Sci. Rep. 8, 1–9. doi: 10.1038/s41598-018-26133-w
> [7] Aloysius, N., and Geetha, M. (2017). “A review on deep convolutional neural networks,” in 2017 International Conference on Communication and Signal Processing (ICCSP) (Chennai: IEEE), 588–592. doi: 10.1109/ICCSP.2017.8286426
> [8] Li, J., Zhang, Z., and He, H. (2018). Hierarchical convolutional neural networks for EEG-based emotion recognition. Cogn. Comput. 10, 368–380. doi: 10.1007/s12559-017-9533-x

***

### 原文链接

> <https://www.scholat.com/teamwork/showPostMessage.html?id=11168>
